Please review the code below for security defects using the CWE (Common Weakness Enumeration) as a reference standard. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are detected, state: 'No security defects are detected in the code'.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import copy
32 import functools
33 import inspect
34 import sys
35 import time
36 import traceback
37 
38 from cinderclient import exceptions as cinder_exception
39 from cursive import exception as cursive_exception
40 import eventlet.event
41 from eventlet import greenthread
42 import eventlet.semaphore
43 import eventlet.timeout
44 import futurist
45 from keystoneauth1 import exceptions as keystone_exception
46 import os_traits
47 from oslo_log import log as logging
48 import oslo_messaging as messaging
49 from oslo_serialization import jsonutils
50 from oslo_service import loopingcall
51 from oslo_service import periodic_task
52 from oslo_utils import excutils
53 from oslo_utils import strutils
54 from oslo_utils import timeutils
55 from oslo_utils import units
56 import six
57 from six.moves import range
58 
59 from nova import block_device
60 from nova.compute import api as compute
61 from nova.compute import build_results
62 from nova.compute import claims
63 from nova.compute import power_state
64 from nova.compute import resource_tracker
65 from nova.compute import rpcapi as compute_rpcapi
66 from nova.compute import task_states
67 from nova.compute import utils as compute_utils
68 from nova.compute.utils import wrap_instance_event
69 from nova.compute import vm_states
70 from nova import conductor
71 import nova.conf
72 from nova.console import rpcapi as console_rpcapi
73 import nova.context
74 from nova import exception
75 from nova import exception_wrapper
76 from nova import hooks
77 from nova.i18n import _
78 from nova import image
79 from nova import manager
80 from nova import network
81 from nova.network import base_api as base_net_api
82 from nova.network import model as network_model
83 from nova.network.security_group import openstack_driver
84 from nova import objects
85 from nova.objects import base as obj_base
86 from nova.objects import fields
87 from nova.objects import instance as obj_instance
88 from nova.objects import migrate_data as migrate_data_obj
89 from nova.pci import request as pci_req_module
90 from nova.pci import whitelist
91 from nova import rpc
92 from nova import safe_utils
93 from nova.scheduler.client import query
94 from nova.scheduler.client import report
95 from nova import utils
96 from nova.virt import block_device as driver_block_device
97 from nova.virt import configdrive
98 from nova.virt import driver
99 from nova.virt import event as virtevent
100 from nova.virt import storage_users
101 from nova.virt import virtapi
102 from nova.volume import cinder
103 
104 CONF = nova.conf.CONF
105 
106 LOG = logging.getLogger(__name__)
107 
108 get_notifier = functools.partial(rpc.get_notifier, service='compute')
109 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
110                                    get_notifier=get_notifier,
111                                    binary='nova-compute')
112 
113 
114 @contextlib.contextmanager
115 def errors_out_migration_ctxt(migration):
116     """Context manager to error out migration on failure."""
117 
118     try:
119         yield
120     except Exception:
121         with excutils.save_and_reraise_exception():
122             if migration:
123                 # We may have been passed None for our migration if we're
124                 # receiving from an older client. The migration will be
125                 # errored via the legacy path.
126                 migration.status = 'error'
127                 try:
128                     migration.save()
129                 except Exception:
130                     LOG.debug(
131                         'Error setting migration status for instance %s.',
132                         migration.instance_uuid, exc_info=True)
133 
134 
135 @utils.expects_func_args('migration')
136 def errors_out_migration(function):
137     """Decorator to error out migration on failure."""
138 
139     @functools.wraps(function)
140     def decorated_function(self, context, *args, **kwargs):
141         wrapped_func = safe_utils.get_wrapped_function(function)
142         keyed_args = inspect.getcallargs(wrapped_func, self, context,
143                                          *args, **kwargs)
144         migration = keyed_args['migration']
145         with errors_out_migration_ctxt(migration):
146             return function(self, context, *args, **kwargs)
147 
148     return decorated_function
149 
150 
151 @utils.expects_func_args('instance')
152 def reverts_task_state(function):
153     """Decorator to revert task_state on failure."""
154 
155     @functools.wraps(function)
156     def decorated_function(self, context, *args, **kwargs):
157         try:
158             return function(self, context, *args, **kwargs)
159         except exception.UnexpectedTaskStateError as e:
160             # Note(maoy): unexpected task state means the current
161             # task is preempted. Do not clear task state in this
162             # case.
163             with excutils.save_and_reraise_exception():
164                 LOG.info("Task possibly preempted: %s",
165                          e.format_message())
166         except Exception:
167             with excutils.save_and_reraise_exception():
168                 wrapped_func = safe_utils.get_wrapped_function(function)
169                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
170                                                  *args, **kwargs)
171                 # NOTE(mriedem): 'instance' must be in keyed_args because we
172                 # have utils.expects_func_args('instance') decorating this
173                 # method.
174                 instance = keyed_args['instance']
175                 original_task_state = instance.task_state
176                 try:
177                     self._instance_update(context, instance, task_state=None)
178                     LOG.info("Successfully reverted task state from %s on "
179                              "failure for instance.",
180                              original_task_state, instance=instance)
181                 except exception.InstanceNotFound:
182                     # We might delete an instance that failed to build shortly
183                     # after it errored out this is an expected case and we
184                     # should not trace on it.
185                     pass
186                 except Exception as e:
187                     LOG.warning("Failed to revert task state for instance. "
188                                 "Error: %s", e, instance=instance)
189 
190     return decorated_function
191 
192 
193 @utils.expects_func_args('instance')
194 def wrap_instance_fault(function):
195     """Wraps a method to catch exceptions related to instances.
196 
197     This decorator wraps a method to catch any exceptions having to do with
198     an instance that may get thrown. It then logs an instance fault in the db.
199     """
200 
201     @functools.wraps(function)
202     def decorated_function(self, context, *args, **kwargs):
203         try:
204             return function(self, context, *args, **kwargs)
205         except exception.InstanceNotFound:
206             raise
207         except Exception as e:
208             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
209             # we will get a KeyError exception which will cover up the real
210             # exception. So, we update kwargs with the values from args first.
211             # then, we can get 'instance' from kwargs easily.
212             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
213 
214             with excutils.save_and_reraise_exception():
215                 compute_utils.add_instance_fault_from_exc(context,
216                         kwargs['instance'], e, sys.exc_info())
217 
218     return decorated_function
219 
220 
221 @utils.expects_func_args('image_id', 'instance')
222 def delete_image_on_error(function):
223     """Used for snapshot related method to ensure the image created in
224     compute.api is deleted when an error occurs.
225     """
226 
227     @functools.wraps(function)
228     def decorated_function(self, context, image_id, instance,
229                            *args, **kwargs):
230         try:
231             return function(self, context, image_id, instance,
232                             *args, **kwargs)
233         except Exception:
234             with excutils.save_and_reraise_exception():
235                 LOG.debug("Cleaning up image %s", image_id,
236                           exc_info=True, instance=instance)
237                 try:
238                     self.image_api.delete(context, image_id)
239                 except exception.ImageNotFound:
240                     # Since we're trying to cleanup an image, we don't care if
241                     # if it's already gone.
242                     pass
243                 except Exception:
244                     LOG.exception("Error while trying to clean up image %s",
245                                   image_id, instance=instance)
246 
247     return decorated_function
248 
249 
250 # TODO(danms): Remove me after Icehouse
251 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
252 # NOTE(mikal): if the method being decorated has more than one decorator, then
253 # put this one first. Otherwise the various exception handling decorators do
254 # not function correctly.
255 def object_compat(function):
256     """Wraps a method that expects a new-world instance
257 
258     This provides compatibility for callers passing old-style dict
259     instances.
260     """
261 
262     @functools.wraps(function)
263     def decorated_function(self, context, *args, **kwargs):
264         def _load_instance(instance_or_dict):
265             if isinstance(instance_or_dict, dict):
266                 # try to get metadata and system_metadata for most cases but
267                 # only attempt to load those if the db instance already has
268                 # those fields joined
269                 metas = [meta for meta in ('metadata', 'system_metadata')
270                          if meta in instance_or_dict]
271                 instance = objects.Instance._from_db_object(
272                     context, objects.Instance(), instance_or_dict,
273                     expected_attrs=metas)
274                 instance._context = context
275                 return instance
276             return instance_or_dict
277 
278         try:
279             kwargs['instance'] = _load_instance(kwargs['instance'])
280         except KeyError:
281             args = (_load_instance(args[0]),) + args[1:]
282 
283         migration = kwargs.get('migration')
284         if isinstance(migration, dict):
285             migration = objects.Migration._from_db_object(
286                     context.elevated(), objects.Migration(),
287                     migration)
288             kwargs['migration'] = migration
289 
290         return function(self, context, *args, **kwargs)
291 
292     return decorated_function
293 
294 
295 class InstanceEvents(object):
296     def __init__(self):
297         self._events = {}
298 
299     @staticmethod
300     def _lock_name(instance):
301         return '%s-%s' % (instance.uuid, 'events')
302 
303     def prepare_for_instance_event(self, instance, name, tag):
304         """Prepare to receive an event for an instance.
305 
306         This will register an event for the given instance that we will
307         wait on later. This should be called before initiating whatever
308         action will trigger the event. The resulting eventlet.event.Event
309         object should be wait()'d on to ensure completion.
310 
311         :param instance: the instance for which the event will be generated
312         :param name: the name of the event we're expecting
313         :param tag: the tag associated with the event we're expecting
314         :returns: an event object that should be wait()'d on
315         """
316         if self._events is None:
317             # NOTE(danms): We really should have a more specific error
318             # here, but this is what we use for our default error case
319             raise exception.NovaException('In shutdown, no new events '
320                                           'can be scheduled')
321 
322         @utils.synchronized(self._lock_name(instance))
323         def _create_or_get_event():
324             instance_events = self._events.setdefault(instance.uuid, {})
325             return instance_events.setdefault((name, tag),
326                                               eventlet.event.Event())
327         LOG.debug('Preparing to wait for external event %(name)s-%(tag)s',
328                   {'name': name, 'tag': tag}, instance=instance)
329         return _create_or_get_event()
330 
331     def pop_instance_event(self, instance, event):
332         """Remove a pending event from the wait list.
333 
334         This will remove a pending event from the wait list so that it
335         can be used to signal the waiters to wake up.
336 
337         :param instance: the instance for which the event was generated
338         :param event: the nova.objects.external_event.InstanceExternalEvent
339                       that describes the event
340         :returns: the eventlet.event.Event object on which the waiters
341                   are blocked
342         """
343         no_events_sentinel = object()
344         no_matching_event_sentinel = object()
345 
346         @utils.synchronized(self._lock_name(instance))
347         def _pop_event():
348             if self._events is None:
349                 LOG.debug('Unexpected attempt to pop events during shutdown',
350                           instance=instance)
351                 return no_events_sentinel
352             events = self._events.get(instance.uuid)
353             if not events:
354                 return no_events_sentinel
355             _event = events.pop((event.name, event.tag), None)
356             if not events:
357                 del self._events[instance.uuid]
358             if _event is None:
359                 return no_matching_event_sentinel
360             return _event
361 
362         result = _pop_event()
363         if result is no_events_sentinel:
364             LOG.debug('No waiting events found dispatching %(event)s',
365                       {'event': event.key},
366                       instance=instance)
367             return None
368         elif result is no_matching_event_sentinel:
369             LOG.debug('No event matching %(event)s in %(events)s',
370                       {'event': event.key,
371                        'events': self._events.get(instance.uuid, {}).keys()},
372                       instance=instance)
373             return None
374         else:
375             return result
376 
377     def clear_events_for_instance(self, instance):
378         """Remove all pending events for an instance.
379 
380         This will remove all events currently pending for an instance
381         and return them (indexed by event name).
382 
383         :param instance: the instance for which events should be purged
384         :returns: a dictionary of {event_name: eventlet.event.Event}
385         """
386         @utils.synchronized(self._lock_name(instance))
387         def _clear_events():
388             if self._events is None:
389                 LOG.debug('Unexpected attempt to clear events during shutdown',
390                           instance=instance)
391                 return dict()
392             # NOTE(danms): We have historically returned the raw internal
393             # format here, which is {event.key: [events, ...])} so just
394             # trivially convert it here.
395             return {'%s-%s' % k: e
396                     for k, e in self._events.pop(instance.uuid, {}).items()}
397         return _clear_events()
398 
399     def cancel_all_events(self):
400         if self._events is None:
401             LOG.debug('Unexpected attempt to cancel events during shutdown.')
402             return
403         our_events = self._events
404         # NOTE(danms): Block new events
405         self._events = None
406 
407         for instance_uuid, events in our_events.items():
408             for (name, tag), eventlet_event in events.items():
409                 LOG.debug('Canceling in-flight event %(name)s-%(tag)s for '
410                           'instance %(instance_uuid)s',
411                           {'name': name,
412                            'tag': tag,
413                            'instance_uuid': instance_uuid})
414                 event = objects.InstanceExternalEvent(
415                     instance_uuid=instance_uuid,
416                     name=name, status='failed',
417                     tag=tag, data={})
418                 eventlet_event.send(event)
419 
420 
421 class ComputeVirtAPI(virtapi.VirtAPI):
422     def __init__(self, compute):
423         super(ComputeVirtAPI, self).__init__()
424         self._compute = compute
425         self.reportclient = compute.reportclient
426 
427     def _default_error_callback(self, event_name, instance):
428         raise exception.NovaException(_('Instance event failed'))
429 
430     @contextlib.contextmanager
431     def wait_for_instance_event(self, instance, event_names, deadline=300,
432                                 error_callback=None):
433         """Plan to wait for some events, run some code, then wait.
434 
435         This context manager will first create plans to wait for the
436         provided event_names, yield, and then wait for all the scheduled
437         events to complete.
438 
439         Note that this uses an eventlet.timeout.Timeout to bound the
440         operation, so callers should be prepared to catch that
441         failure and handle that situation appropriately.
442 
443         If the event is not received by the specified timeout deadline,
444         eventlet.timeout.Timeout is raised.
445 
446         If the event is received but did not have a 'completed'
447         status, a NovaException is raised.  If an error_callback is
448         provided, instead of raising an exception as detailed above
449         for the failure case, the callback will be called with the
450         event_name and instance, and can return True to continue
451         waiting for the rest of the events, False to stop processing,
452         or raise an exception which will bubble up to the waiter.
453 
454         :param instance: The instance for which an event is expected
455         :param event_names: A list of event names. Each element is a
456                             tuple of strings to indicate (name, tag),
457                             where name is required, but tag may be None.
458         :param deadline: Maximum number of seconds we should wait for all
459                          of the specified events to arrive.
460         :param error_callback: A function to be called if an event arrives
461 
462         """
463 
464         if error_callback is None:
465             error_callback = self._default_error_callback
466         events = {}
467         for event_name in event_names:
468             name, tag = event_name
469             event_name = objects.InstanceExternalEvent.make_key(name, tag)
470             try:
471                 events[event_name] = (
472                     self._compute.instance_events.prepare_for_instance_event(
473                         instance, name, tag))
474             except exception.NovaException:
475                 error_callback(event_name, instance)
476                 # NOTE(danms): Don't wait for any of the events. They
477                 # should all be canceled and fired immediately below,
478                 # but don't stick around if not.
479                 deadline = 0
480         yield
481         with eventlet.timeout.Timeout(deadline):
482             for event_name, event in events.items():
483                 actual_event = event.wait()
484                 if actual_event.status == 'completed':
485                     continue
486                 decision = error_callback(event_name, instance)
487                 if decision is False:
488                     break
489 
490     def update_compute_provider_status(self, context, rp_uuid, enabled):
491         """Used to add/remove the COMPUTE_STATUS_DISABLED trait on the provider
492 
493         :param context: nova auth RequestContext
494         :param rp_uuid: UUID of a compute node resource provider in Placement
495         :param enabled: True if the node is enabled in which case the trait
496             would be removed, False if the node is disabled in which case
497             the trait would be added.
498         :raises: ResourceProviderTraitRetrievalFailed
499         :raises: ResourceProviderUpdateConflict
500         :raises: ResourceProviderUpdateFailed
501         :raises: TraitRetrievalFailed
502         :raises: keystoneauth1.exceptions.ClientException
503         """
504         trait_name = os_traits.COMPUTE_STATUS_DISABLED
505         # Get the current traits (and generation) for the provider.
506         # TODO(mriedem): Leverage the ProviderTree cache in get_provider_traits
507         trait_info = self.reportclient.get_provider_traits(context, rp_uuid)
508         # If the host is enabled, remove the trait (if set), else add
509         # the trait if it doesn't already exist.
510         original_traits = trait_info.traits
511         new_traits = None
512         if enabled and trait_name in original_traits:
513             new_traits = original_traits - {trait_name}
514             LOG.debug('Removing trait %s from compute node resource '
515                       'provider %s in placement.', trait_name, rp_uuid)
516         elif not enabled and trait_name not in original_traits:
517             new_traits = original_traits | {trait_name}
518             LOG.debug('Adding trait %s to compute node resource '
519                       'provider %s in placement.', trait_name, rp_uuid)
520 
521         if new_traits is not None:
522             self.reportclient.set_traits_for_provider(
523                 context, rp_uuid, new_traits)
524 
525 
526 class ComputeManager(manager.Manager):
527     """Manages the running instances from creation to destruction."""
528 
529     target = messaging.Target(version='5.1')
530 
531     def __init__(self, compute_driver=None, *args, **kwargs):
532         """Load configuration options and connect to the hypervisor."""
533         # We want the ComputeManager, ResourceTracker and ComputeVirtAPI all
534         # using the same instance of SchedulerReportClient which has the
535         # ProviderTree cache for this compute service.
536         self.reportclient = report.SchedulerReportClient()
537         self.virtapi = ComputeVirtAPI(self)
538         self.network_api = network.API()
539         self.volume_api = cinder.API()
540         self.image_api = image.API()
541         self._last_bw_usage_poll = 0
542         self._bw_usage_supported = True
543         self._last_bw_usage_cell_update = 0
544         self.compute_api = compute.API()
545         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
546         self.compute_task_api = conductor.ComputeTaskAPI()
547         self.is_neutron_security_groups = (
548             openstack_driver.is_neutron_security_groups())
549         self.query_client = query.SchedulerQueryClient()
550         self.instance_events = InstanceEvents()
551         self._sync_power_pool = eventlet.GreenPool(
552             size=CONF.sync_power_state_pool_size)
553         self._syncs_in_progress = {}
554         self.send_instance_updates = (
555             CONF.filter_scheduler.track_instance_changes)
556         if CONF.max_concurrent_builds != 0:
557             self._build_semaphore = eventlet.semaphore.Semaphore(
558                 CONF.max_concurrent_builds)
559         else:
560             self._build_semaphore = compute_utils.UnlimitedSemaphore()
561         if CONF.max_concurrent_live_migrations > 0:
562             self._live_migration_executor = futurist.GreenThreadPoolExecutor(
563                 max_workers=CONF.max_concurrent_live_migrations)
564         else:
565             # CONF.max_concurrent_live_migrations is 0 (unlimited)
566             self._live_migration_executor = futurist.GreenThreadPoolExecutor()
567         # This is a dict, keyed by instance uuid, to a two-item tuple of
568         # migration object and Future for the queued live migration.
569         self._waiting_live_migrations = {}
570 
571         super(ComputeManager, self).__init__(service_name="compute",
572                                              *args, **kwargs)
573 
574         # NOTE(russellb) Load the driver last.  It may call back into the
575         # compute manager via the virtapi, so we want it to be fully
576         # initialized before that happens.
577         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
578         self.use_legacy_block_device_info = \
579                             self.driver.need_legacy_block_device_info
580         self.rt = resource_tracker.ResourceTracker(
581             self.host, self.driver, reportclient=self.reportclient)
582 
583     def reset(self):
584         LOG.info('Reloading compute RPC API')
585         compute_rpcapi.reset_globals()
586         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
587         self.reportclient.clear_provider_cache()
588 
589     def _update_resource_tracker(self, context, instance):
590         """Let the resource tracker know that an instance has changed state."""
591 
592         if instance.host == self.host:
593             self.rt.update_usage(context, instance, instance.node)
594 
595     def _instance_update(self, context, instance, **kwargs):
596         """Update an instance in the database using kwargs as value."""
597 
598         for k, v in kwargs.items():
599             setattr(instance, k, v)
600         instance.save()
601         self._update_resource_tracker(context, instance)
602 
603     def _nil_out_instance_obj_host_and_node(self, instance):
604         # NOTE(jwcroppe): We don't do instance.save() here for performance
605         # reasons; a call to this is expected to be immediately followed by
606         # another call that does instance.save(), thus avoiding two writes
607         # to the database layer.
608         instance.host = None
609         instance.node = None
610         # If the instance is not on a host, it's not in an aggregate and
611         # therefore is not in an availability zone.
612         instance.availability_zone = None
613 
614     def _set_instance_obj_error_state(self, context, instance,
615                                       clean_task_state=False):
616         try:
617             instance.vm_state = vm_states.ERROR
618             if clean_task_state:
619                 instance.task_state = None
620             instance.save()
621         except exception.InstanceNotFound:
622             LOG.debug('Instance has been destroyed from under us while '
623                       'trying to set it to ERROR', instance=instance)
624 
625     def _get_instances_on_driver(self, context, filters=None):
626         """Return a list of instance records for the instances found
627         on the hypervisor which satisfy the specified filters. If filters=None
628         return a list of instance records for all the instances found on the
629         hypervisor.
630         """
631         if not filters:
632             filters = {}
633         try:
634             driver_uuids = self.driver.list_instance_uuids()
635             if len(driver_uuids) == 0:
636                 # Short circuit, don't waste a DB call
637                 return objects.InstanceList()
638             filters['uuid'] = driver_uuids
639             local_instances = objects.InstanceList.get_by_filters(
640                 context, filters, use_slave=True)
641             return local_instances
642         except NotImplementedError:
643             pass
644 
645         # The driver doesn't support uuids listing, so we'll have
646         # to brute force.
647         driver_instances = self.driver.list_instances()
648         # NOTE(mjozefcz): In this case we need to apply host filter.
649         # Without this all instance data would be fetched from db.
650         filters['host'] = self.host
651         instances = objects.InstanceList.get_by_filters(context, filters,
652                                                         use_slave=True)
653         name_map = {instance.name: instance for instance in instances}
654         local_instances = []
655         for driver_instance in driver_instances:
656             instance = name_map.get(driver_instance)
657             if not instance:
658                 continue
659             local_instances.append(instance)
660         return local_instances
661 
662     def _destroy_evacuated_instances(self, context):
663         """Destroys evacuated instances.
664 
665         While nova-compute was down, the instances running on it could be
666         evacuated to another host. This method looks for evacuation migration
667         records where this is the source host and which were either started
668         (accepted), in-progress (pre-migrating) or migrated (done). From those
669         migration records, local instances reported by the hypervisor are
670         compared to the instances for the migration records and those local
671         guests are destroyed, along with instance allocation records in
672         Placement for this node.
673         Then allocations are removed from Placement for every instance that is
674         evacuated from this host regardless if the instance is reported by the
675         hypervisor or not.
676         """
677         filters = {
678             'source_compute': self.host,
679             # NOTE(mriedem): Migration records that have been accepted are
680             # included in case the source node comes back up while instances
681             # are being evacuated to another host. We don't want the same
682             # instance being reported from multiple hosts.
683             # NOTE(lyarwood): pre-migrating is also included here as the
684             # source compute can come back online shortly after the RT
685             # claims on the destination that in-turn moves the migration to
686             # pre-migrating. If the evacuate fails on the destination host,
687             # the user can rebuild the instance (in ERROR state) on the source
688             # host.
689             'status': ['accepted', 'pre-migrating', 'done'],
690             'migration_type': 'evacuation',
691         }
692         with utils.temporary_mutation(context, read_deleted='yes'):
693             evacuations = objects.MigrationList.get_by_filters(context,
694                                                                filters)
695         if not evacuations:
696             return
697         evacuations = {mig.instance_uuid: mig for mig in evacuations}
698 
699         # TODO(mriedem): We could optimize by pre-loading the joined fields
700         # we know we'll use, like info_cache and flavor.
701         local_instances = self._get_instances_on_driver(context)
702         evacuated_local_instances = {inst.uuid: inst
703                                      for inst in local_instances
704                                      if inst.uuid in evacuations}
705 
706         for instance in evacuated_local_instances.values():
707             LOG.info('Destroying instance as it has been evacuated from '
708                      'this host but still exists in the hypervisor',
709                      instance=instance)
710             try:
711                 network_info = self.network_api.get_instance_nw_info(
712                     context, instance)
713                 bdi = self._get_instance_block_device_info(context,
714                                                            instance)
715                 destroy_disks = not (self._is_instance_storage_shared(
716                     context, instance))
717             except exception.InstanceNotFound:
718                 network_info = network_model.NetworkInfo()
719                 bdi = {}
720                 LOG.info('Instance has been marked deleted already, '
721                          'removing it from the hypervisor.',
722                          instance=instance)
723                 # always destroy disks if the instance was deleted
724                 destroy_disks = True
725             self.driver.destroy(context, instance,
726                                 network_info,
727                                 bdi, destroy_disks)
728 
729         # NOTE(gibi): We are called from init_host and at this point the
730         # compute_nodes of the resource tracker has not been populated yet so
731         # we cannot rely on the resource tracker here.
732         compute_nodes = {}
733 
734         for instance_uuid, migration in evacuations.items():
735             try:
736                 if instance_uuid in evacuated_local_instances:
737                     # Avoid the db call if we already have the instance loaded
738                     # above
739                     instance = evacuated_local_instances[instance_uuid]
740                 else:
741                     instance = objects.Instance.get_by_uuid(
742                         context, instance_uuid)
743             except exception.InstanceNotFound:
744                 # The instance already deleted so we expect that every
745                 # allocation of that instance has already been cleaned up
746                 continue
747 
748             LOG.info('Cleaning up allocations of the instance as it has been '
749                      'evacuated from this host',
750                      instance=instance)
751             if migration.source_node not in compute_nodes:
752                 try:
753                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
754                         context, self.host, migration.source_node).uuid
755                     compute_nodes[migration.source_node] = cn_uuid
756                 except exception.ComputeHostNotFound:
757                     LOG.error("Failed to clean allocation of evacuated "
758                               "instance as the source node %s is not found",
759                               migration.source_node, instance=instance)
760                     continue
761             cn_uuid = compute_nodes[migration.source_node]
762 
763             # If the instance was deleted in the interim, assume its
764             # allocations were properly cleaned up (either by its hosting
765             # compute service or the API).
766             if (not instance.deleted and
767                     not self.reportclient.
768                         remove_provider_tree_from_instance_allocation(
769                             context, instance.uuid, cn_uuid)):
770                 LOG.error("Failed to clean allocation of evacuated instance "
771                           "on the source node %s",
772                           cn_uuid, instance=instance)
773 
774             migration.status = 'completed'
775             migration.save()
776         return evacuations
777 
778     def _is_instance_storage_shared(self, context, instance, host=None):
779         shared_storage = True
780         data = None
781         try:
782             data = self.driver.check_instance_shared_storage_local(context,
783                                                        instance)
784             if data:
785                 shared_storage = (self.compute_rpcapi.
786                                   check_instance_shared_storage(context,
787                                   instance, data, host=host))
788         except NotImplementedError:
789             LOG.debug('Hypervisor driver does not support '
790                       'instance shared storage check, '
791                       'assuming it\'s not on shared storage',
792                       instance=instance)
793             shared_storage = False
794         except Exception:
795             LOG.exception('Failed to check if instance shared',
796                           instance=instance)
797         finally:
798             if data:
799                 self.driver.check_instance_shared_storage_cleanup(context,
800                                                                   data)
801         return shared_storage
802 
803     def _complete_partial_deletion(self, context, instance):
804         """Complete deletion for instances in DELETED status but not marked as
805         deleted in the DB
806         """
807         instance.destroy()
808         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
809                 context, instance.uuid)
810         self._complete_deletion(context,
811                                 instance)
812         self._notify_about_instance_usage(context, instance, "delete.end")
813         compute_utils.notify_about_instance_action(context, instance,
814                 self.host, action=fields.NotificationAction.DELETE,
815                 phase=fields.NotificationPhase.END, bdms=bdms)
816 
817     def _complete_deletion(self, context, instance):
818         self._update_resource_tracker(context, instance)
819 
820         self.reportclient.delete_allocation_for_instance(context,
821                                                          instance.uuid)
822 
823         self._clean_instance_console_tokens(context, instance)
824         self._delete_scheduler_instance_info(context, instance.uuid)
825 
826     def _init_instance(self, context, instance):
827         """Initialize this instance during service init."""
828 
829         # NOTE(danms): If the instance appears to not be owned by this
830         # host, it may have been evacuated away, but skipped by the
831         # evacuation cleanup code due to configuration. Thus, if that
832         # is a possibility, don't touch the instance in any way, but
833         # log the concern. This will help avoid potential issues on
834         # startup due to misconfiguration.
835         if instance.host != self.host:
836             LOG.warning('Instance %(uuid)s appears to not be owned '
837                         'by this host, but by %(host)s. Startup '
838                         'processing is being skipped.',
839                         {'uuid': instance.uuid,
840                          'host': instance.host})
841             return
842 
843         # Instances that are shut down, or in an error state can not be
844         # initialized and are not attempted to be recovered. The exception
845         # to this are instances that are in RESIZE_MIGRATING or DELETING,
846         # which are dealt with further down.
847         if (instance.vm_state == vm_states.SOFT_DELETED or
848             (instance.vm_state == vm_states.ERROR and
849             instance.task_state not in
850             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
851             LOG.debug("Instance is in %s state.",
852                       instance.vm_state, instance=instance)
853             return
854 
855         if instance.vm_state == vm_states.DELETED:
856             try:
857                 self._complete_partial_deletion(context, instance)
858             except Exception:
859                 # we don't want that an exception blocks the init_host
860                 LOG.exception('Failed to complete a deletion',
861                               instance=instance)
862             return
863 
864         if (instance.vm_state == vm_states.BUILDING or
865             instance.task_state in [task_states.SCHEDULING,
866                                     task_states.BLOCK_DEVICE_MAPPING,
867                                     task_states.NETWORKING,
868                                     task_states.SPAWNING]):
869             # NOTE(dave-mcnally) compute stopped before instance was fully
870             # spawned so set to ERROR state. This is safe to do as the state
871             # may be set by the api but the host is not so if we get here the
872             # instance has already been scheduled to this particular host.
873             LOG.debug("Instance failed to spawn correctly, "
874                       "setting to ERROR state", instance=instance)
875             instance.task_state = None
876             instance.vm_state = vm_states.ERROR
877             instance.save()
878             return
879 
880         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
881             instance.task_state in [task_states.REBUILDING,
882                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
883                                     task_states.REBUILD_SPAWNING]):
884             # NOTE(jichenjc) compute stopped before instance was fully
885             # spawned so set to ERROR state. This is consistent to BUILD
886             LOG.debug("Instance failed to rebuild correctly, "
887                       "setting to ERROR state", instance=instance)
888             instance.task_state = None
889             instance.vm_state = vm_states.ERROR
890             instance.save()
891             return
892 
893         if (instance.vm_state != vm_states.ERROR and
894             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
895                                     task_states.IMAGE_PENDING_UPLOAD,
896                                     task_states.IMAGE_UPLOADING,
897                                     task_states.IMAGE_SNAPSHOT]):
898             LOG.debug("Instance in transitional state %s at start-up "
899                       "clearing task state",
900                       instance.task_state, instance=instance)
901             try:
902                 self._post_interrupted_snapshot_cleanup(context, instance)
903             except Exception:
904                 # we don't want that an exception blocks the init_host
905                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
906             instance.task_state = None
907             instance.save()
908 
909         if (instance.vm_state != vm_states.ERROR and
910             instance.task_state in [task_states.RESIZE_PREP]):
911             LOG.debug("Instance in transitional state %s at start-up "
912                       "clearing task state",
913                       instance['task_state'], instance=instance)
914             instance.task_state = None
915             instance.save()
916 
917         if instance.task_state == task_states.DELETING:
918             try:
919                 LOG.info('Service started deleting the instance during '
920                          'the previous run, but did not finish. Restarting'
921                          ' the deletion now.', instance=instance)
922                 instance.obj_load_attr('metadata')
923                 instance.obj_load_attr('system_metadata')
924                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
925                         context, instance.uuid)
926                 self._delete_instance(context, instance, bdms)
927             except Exception:
928                 # we don't want that an exception blocks the init_host
929                 LOG.exception('Failed to complete a deletion',
930                               instance=instance)
931                 self._set_instance_obj_error_state(context, instance)
932             return
933 
934         current_power_state = self._get_power_state(context, instance)
935         try_reboot, reboot_type = self._retry_reboot(context, instance,
936                                                      current_power_state)
937 
938         if try_reboot:
939             LOG.debug("Instance in transitional state (%(task_state)s) at "
940                       "start-up and power state is (%(power_state)s), "
941                       "triggering reboot",
942                       {'task_state': instance.task_state,
943                        'power_state': current_power_state},
944                       instance=instance)
945 
946             # NOTE(mikal): if the instance was doing a soft reboot that got as
947             # far as shutting down the instance but not as far as starting it
948             # again, then we've just become a hard reboot. That means the
949             # task state for the instance needs to change so that we're in one
950             # of the expected task states for a hard reboot.
951             if (instance.task_state in task_states.soft_reboot_states and
952                 reboot_type == 'HARD'):
953                 instance.task_state = task_states.REBOOT_PENDING_HARD
954                 instance.save()
955 
956             self.reboot_instance(context, instance, block_device_info=None,
957                                  reboot_type=reboot_type)
958             return
959 
960         elif (current_power_state == power_state.RUNNING and
961               instance.task_state in [task_states.REBOOT_STARTED,
962                                       task_states.REBOOT_STARTED_HARD,
963                                       task_states.PAUSING,
964                                       task_states.UNPAUSING]):
965             LOG.warning("Instance in transitional state "
966                         "(%(task_state)s) at start-up and power state "
967                         "is (%(power_state)s), clearing task state",
968                         {'task_state': instance.task_state,
969                          'power_state': current_power_state},
970                         instance=instance)
971             instance.task_state = None
972             instance.vm_state = vm_states.ACTIVE
973             instance.save()
974         elif (current_power_state == power_state.PAUSED and
975               instance.task_state == task_states.UNPAUSING):
976             LOG.warning("Instance in transitional state "
977                         "(%(task_state)s) at start-up and power state "
978                         "is (%(power_state)s), clearing task state "
979                         "and unpausing the instance",
980                         {'task_state': instance.task_state,
981                          'power_state': current_power_state},
982                         instance=instance)
983             try:
984                 self.unpause_instance(context, instance)
985             except NotImplementedError:
986                 # Some virt driver didn't support pause and unpause
987                 pass
988             except Exception:
989                 LOG.exception('Failed to unpause instance', instance=instance)
990             return
991 
992         if instance.task_state == task_states.POWERING_OFF:
993             try:
994                 LOG.debug("Instance in transitional state %s at start-up "
995                           "retrying stop request",
996                           instance.task_state, instance=instance)
997                 self.stop_instance(context, instance, True)
998             except Exception:
999                 # we don't want that an exception blocks the init_host
1000                 LOG.exception('Failed to stop instance', instance=instance)
1001             return
1002 
1003         if instance.task_state == task_states.POWERING_ON:
1004             try:
1005                 LOG.debug("Instance in transitional state %s at start-up "
1006                           "retrying start request",
1007                           instance.task_state, instance=instance)
1008                 self.start_instance(context, instance)
1009             except Exception:
1010                 # we don't want that an exception blocks the init_host
1011                 LOG.exception('Failed to start instance', instance=instance)
1012             return
1013 
1014         net_info = instance.get_network_info()
1015         try:
1016             self.driver.plug_vifs(instance, net_info)
1017         except NotImplementedError as e:
1018             LOG.debug(e, instance=instance)
1019         except exception.VirtualInterfacePlugException:
1020             # NOTE(mriedem): If we get here, it could be because the vif_type
1021             # in the cache is "binding_failed" or "unbound".
1022             # The periodic task _heal_instance_info_cache checks for this
1023             # condition. It should fix this by binding the ports again when
1024             # it gets to this instance.
1025             LOG.exception('Virtual interface plugging failed for instance. '
1026                           'The port binding:host_id may need to be manually '
1027                           'updated.', instance=instance)
1028             self._set_instance_obj_error_state(context, instance)
1029             return
1030 
1031         if instance.task_state == task_states.RESIZE_MIGRATING:
1032             # We crashed during resize/migration, so roll back for safety
1033             try:
1034                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
1035                 # not in system_metadata we default to True for backwards
1036                 # compatibility
1037                 power_on = (instance.system_metadata.get('old_vm_state') !=
1038                             vm_states.STOPPED)
1039 
1040                 block_dev_info = self._get_instance_block_device_info(context,
1041                                                                       instance)
1042 
1043                 self.driver.finish_revert_migration(context,
1044                     instance, net_info, block_dev_info, power_on)
1045 
1046             except Exception:
1047                 LOG.exception('Failed to revert crashed migration',
1048                               instance=instance)
1049             finally:
1050                 LOG.info('Instance found in migrating state during '
1051                          'startup. Resetting task_state',
1052                          instance=instance)
1053                 instance.task_state = None
1054                 instance.save()
1055         if instance.task_state == task_states.MIGRATING:
1056             # Live migration did not complete, but instance is on this
1057             # host, so reset the state.
1058             instance.task_state = None
1059             instance.save(expected_task_state=[task_states.MIGRATING])
1060 
1061         db_state = instance.power_state
1062         drv_state = self._get_power_state(context, instance)
1063         expect_running = (db_state == power_state.RUNNING and
1064                           drv_state != db_state)
1065 
1066         LOG.debug('Current state is %(drv_state)s, state in DB is '
1067                   '%(db_state)s.',
1068                   {'drv_state': drv_state, 'db_state': db_state},
1069                   instance=instance)
1070 
1071         if expect_running and CONF.resume_guests_state_on_host_boot:
1072             self._resume_guests_state(context, instance, net_info)
1073         elif drv_state == power_state.RUNNING:
1074             # VMwareAPI drivers will raise an exception
1075             try:
1076                 self.driver.ensure_filtering_rules_for_instance(
1077                                        instance, net_info)
1078             except NotImplementedError:
1079                 LOG.debug('Hypervisor driver does not support '
1080                           'firewall rules', instance=instance)
1081 
1082     def _resume_guests_state(self, context, instance, net_info):
1083         LOG.info('Rebooting instance after nova-compute restart.',
1084                  instance=instance)
1085         block_device_info = \
1086             self._get_instance_block_device_info(context, instance)
1087 
1088         try:
1089             self.driver.resume_state_on_host_boot(
1090                 context, instance, net_info, block_device_info)
1091         except NotImplementedError:
1092             LOG.warning('Hypervisor driver does not support '
1093                         'resume guests', instance=instance)
1094         except Exception:
1095             # NOTE(vish): The instance failed to resume, so we set the
1096             #             instance to error and attempt to continue.
1097             LOG.warning('Failed to resume instance',
1098                         instance=instance)
1099             self._set_instance_obj_error_state(context, instance)
1100 
1101     def _retry_reboot(self, context, instance, current_power_state):
1102         current_task_state = instance.task_state
1103         retry_reboot = False
1104         reboot_type = compute_utils.get_reboot_type(current_task_state,
1105                                                     current_power_state)
1106 
1107         pending_soft = (
1108             current_task_state == task_states.REBOOT_PENDING and
1109             instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1110         pending_hard = (
1111             current_task_state == task_states.REBOOT_PENDING_HARD and
1112             instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1113         started_not_running = (current_task_state in
1114                                [task_states.REBOOT_STARTED,
1115                                 task_states.REBOOT_STARTED_HARD] and
1116                                current_power_state != power_state.RUNNING)
1117 
1118         if pending_soft or pending_hard or started_not_running:
1119             retry_reboot = True
1120 
1121         return retry_reboot, reboot_type
1122 
1123     def handle_lifecycle_event(self, event):
1124         LOG.info("VM %(state)s (Lifecycle Event)",
1125                  {'state': event.get_name()},
1126                  instance_uuid=event.get_instance_uuid())
1127         context = nova.context.get_admin_context(read_deleted='yes')
1128         vm_power_state = None
1129         event_transition = event.get_transition()
1130         if event_transition == virtevent.EVENT_LIFECYCLE_STOPPED:
1131             vm_power_state = power_state.SHUTDOWN
1132         elif event_transition == virtevent.EVENT_LIFECYCLE_STARTED:
1133             vm_power_state = power_state.RUNNING
1134         elif event_transition in (
1135                 virtevent.EVENT_LIFECYCLE_PAUSED,
1136                 virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED,
1137                 virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED):
1138             vm_power_state = power_state.PAUSED
1139         elif event_transition == virtevent.EVENT_LIFECYCLE_RESUMED:
1140             vm_power_state = power_state.RUNNING
1141         elif event_transition == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1142             vm_power_state = power_state.SUSPENDED
1143         else:
1144             LOG.warning("Unexpected lifecycle event: %d", event_transition)
1145 
1146         migrate_finish_statuses = {
1147             # This happens on the source node and indicates live migration
1148             # entered post-copy mode.
1149             virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED: 'running (post-copy)',
1150             # Suspended for offline migration.
1151             virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED: 'running'
1152         }
1153 
1154         expected_attrs = []
1155         if event_transition in migrate_finish_statuses:
1156             # Join on info_cache since that's needed in migrate_instance_start.
1157             expected_attrs.append('info_cache')
1158         instance = objects.Instance.get_by_uuid(context,
1159                                                 event.get_instance_uuid(),
1160                                                 expected_attrs=expected_attrs)
1161 
1162         # Note(lpetrut): The event may be delayed, thus not reflecting
1163         # the current instance power state. In that case, ignore the event.
1164         current_power_state = self._get_power_state(context, instance)
1165         if current_power_state == vm_power_state:
1166             LOG.debug('Synchronizing instance power state after lifecycle '
1167                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1168                       'current task_state: %(task_state)s, current DB '
1169                       'power_state: %(db_power_state)s, VM power_state: '
1170                       '%(vm_power_state)s',
1171                       {'event': event.get_name(),
1172                        'vm_state': instance.vm_state,
1173                        'task_state': instance.task_state,
1174                        'db_power_state': instance.power_state,
1175                        'vm_power_state': vm_power_state},
1176                       instance_uuid=instance.uuid)
1177             self._sync_instance_power_state(context,
1178                                             instance,
1179                                             vm_power_state)
1180 
1181         # The following checks are for live migration. We want to activate
1182         # the port binding for the destination host before the live migration
1183         # is resumed on the destination host in order to reduce network
1184         # downtime. Otherwise the ports are bound to the destination host
1185         # in post_live_migration_at_destination.
1186         # TODO(danms): Explore options for using a different live migration
1187         # specific callback for this instead of piggy-backing on the
1188         # handle_lifecycle_event callback.
1189         if (instance.task_state == task_states.MIGRATING and
1190                 event_transition in migrate_finish_statuses):
1191             status = migrate_finish_statuses[event_transition]
1192             try:
1193                 migration = objects.Migration.get_by_instance_and_status(
1194                             context, instance.uuid, status)
1195                 LOG.debug('Binding ports to destination host: %s',
1196                           migration.dest_compute, instance=instance)
1197                 # For neutron, migrate_instance_start will activate the
1198                 # destination host port bindings, if there are any created by
1199                 # conductor before live migration started.
1200                 self.network_api.migrate_instance_start(
1201                     context, instance, migration)
1202             except exception.MigrationNotFoundByStatus:
1203                 LOG.warning("Unable to find migration record with status "
1204                             "'%s' for instance. Port binding will happen in "
1205                             "post live migration.", status, instance=instance)
1206 
1207     def handle_events(self, event):
1208         if isinstance(event, virtevent.LifecycleEvent):
1209             try:
1210                 self.handle_lifecycle_event(event)
1211             except exception.InstanceNotFound:
1212                 LOG.debug("Event %s arrived for non-existent instance. The "
1213                           "instance was probably deleted.", event)
1214         else:
1215             LOG.debug("Ignoring event %s", event)
1216 
1217     def init_virt_events(self):
1218         if CONF.workarounds.handle_virt_lifecycle_events:
1219             self.driver.register_event_listener(self.handle_events)
1220         else:
1221             # NOTE(mriedem): If the _sync_power_states periodic task is
1222             # disabled we should emit a warning in the logs.
1223             if CONF.sync_power_state_interval < 0:
1224                 LOG.warning('Instance lifecycle events from the compute '
1225                             'driver have been disabled. Note that lifecycle '
1226                             'changes to an instance outside of the compute '
1227                             'service will not be synchronized '
1228                             'automatically since the _sync_power_states '
1229                             'periodic task is also disabled.')
1230             else:
1231                 LOG.info('Instance lifecycle events from the compute '
1232                          'driver have been disabled. Note that lifecycle '
1233                          'changes to an instance outside of the compute '
1234                          'service will only be synchronized by the '
1235                          '_sync_power_states periodic task.')
1236 
1237     def init_host(self):
1238         """Initialization for a standalone compute service."""
1239 
1240         if CONF.pci.passthrough_whitelist:
1241             # Simply loading the PCI passthrough whitelist will do a bunch of
1242             # validation that would otherwise wait until the PciDevTracker is
1243             # constructed when updating available resources for the compute
1244             # node(s) in the resource tracker, effectively killing that task.
1245             # So load up the whitelist when starting the compute service to
1246             # flush any invalid configuration early so we can kill the service
1247             # if the configuration is wrong.
1248             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1249 
1250         nova.conf.neutron.register_dynamic_opts(CONF)
1251 
1252         # Override the number of concurrent disk operations allowed if the
1253         # user has specified a limit.
1254         if CONF.compute.max_concurrent_disk_ops != 0:
1255             compute_utils.disk_ops_semaphore = \
1256                 eventlet.semaphore.BoundedSemaphore(
1257                     CONF.compute.max_concurrent_disk_ops)
1258 
1259         self.driver.init_host(host=self.host)
1260         context = nova.context.get_admin_context()
1261         instances = objects.InstanceList.get_by_host(
1262             context, self.host, expected_attrs=['info_cache', 'metadata'])
1263 
1264         if CONF.defer_iptables_apply:
1265             self.driver.filter_defer_apply_on()
1266 
1267         self.init_virt_events()
1268 
1269         try:
1270             # checking that instance was not already evacuated to other host
1271             evacuated_instances = self._destroy_evacuated_instances(context)
1272 
1273             # Initialise instances on the host that are not evacuating
1274             for instance in instances:
1275                 if (not evacuated_instances or
1276                         instance.uuid not in evacuated_instances):
1277                     self._init_instance(context, instance)
1278 
1279         finally:
1280             if CONF.defer_iptables_apply:
1281                 self.driver.filter_defer_apply_off()
1282             if instances:
1283                 # We only send the instance info to the scheduler on startup
1284                 # if there is anything to send, otherwise this host might
1285                 # not be mapped yet in a cell and the scheduler may have
1286                 # issues dealing with the information. Later changes to
1287                 # instances on this host will update the scheduler, or the
1288                 # _sync_scheduler_instance_info periodic task will.
1289                 self._update_scheduler_instance_info(context, instances)
1290 
1291     def cleanup_host(self):
1292         self.driver.register_event_listener(None)
1293         self.instance_events.cancel_all_events()
1294         self.driver.cleanup_host(host=self.host)
1295         self._cleanup_live_migrations_in_pool()
1296 
1297     def _cleanup_live_migrations_in_pool(self):
1298         # Shutdown the pool so we don't get new requests.
1299         self._live_migration_executor.shutdown(wait=False)
1300         # For any queued migrations, cancel the migration and update
1301         # its status.
1302         for migration, future in self._waiting_live_migrations.values():
1303             # If we got here before the Future was submitted then we need
1304             # to move on since there isn't anything we can do.
1305             if future is None:
1306                 continue
1307             if future.cancel():
1308                 self._set_migration_status(migration, 'cancelled')
1309                 LOG.info('Successfully cancelled queued live migration.',
1310                          instance_uuid=migration.instance_uuid)
1311             else:
1312                 LOG.warning('Unable to cancel live migration.',
1313                             instance_uuid=migration.instance_uuid)
1314         self._waiting_live_migrations.clear()
1315 
1316     def pre_start_hook(self):
1317         """After the service is initialized, but before we fully bring
1318         the service up by listening on RPC queues, make sure to update
1319         our available resources (and indirectly our available nodes).
1320         """
1321         self.update_available_resource(nova.context.get_admin_context(),
1322                                        startup=True)
1323 
1324     def _get_power_state(self, context, instance):
1325         """Retrieve the power state for the given instance."""
1326         LOG.debug('Checking state', instance=instance)
1327         try:
1328             return self.driver.get_info(instance, use_cache=False).state
1329         except exception.InstanceNotFound:
1330             return power_state.NOSTATE
1331 
1332     def get_console_topic(self, context):
1333         """Retrieves the console host for a project on this host.
1334 
1335         Currently this is just set in the flags for each compute host.
1336 
1337         """
1338         # TODO(mdragon): perhaps make this variable by console_type?
1339         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1340 
1341     @wrap_exception()
1342     def get_console_pool_info(self, context, console_type):
1343         return self.driver.get_console_pool_info(console_type)
1344 
1345     @wrap_exception()
1346     def refresh_instance_security_rules(self, context, instance):
1347         """Tell the virtualization driver to refresh security rules for
1348         an instance.
1349 
1350         Passes straight through to the virtualization driver.
1351 
1352         Synchronize the call because we may still be in the middle of
1353         creating the instance.
1354         """
1355         @utils.synchronized(instance.uuid)
1356         def _sync_refresh():
1357             try:
1358                 return self.driver.refresh_instance_security_rules(instance)
1359             except NotImplementedError:
1360                 LOG.debug('Hypervisor driver does not support '
1361                           'security groups.', instance=instance)
1362 
1363         return _sync_refresh()
1364 
1365     def _await_block_device_map_created(self, context, vol_id):
1366         # TODO(yamahata): creating volume simultaneously
1367         #                 reduces creation time?
1368         # TODO(yamahata): eliminate dumb polling
1369         start = time.time()
1370         retries = CONF.block_device_allocate_retries
1371         # (1) if the configured value is 0, one attempt should be made
1372         # (2) if the configured value is > 0, then the total number attempts
1373         #      is (retries + 1)
1374         attempts = 1
1375         if retries >= 1:
1376             attempts = retries + 1
1377         for attempt in range(1, attempts + 1):
1378             volume = self.volume_api.get(context, vol_id)
1379             volume_status = volume['status']
1380             if volume_status not in ['creating', 'downloading']:
1381                 if volume_status == 'available':
1382                     return attempt
1383                 LOG.warning("Volume id: %(vol_id)s finished being "
1384                             "created but its status is %(vol_status)s.",
1385                             {'vol_id': vol_id,
1386                              'vol_status': volume_status})
1387                 break
1388             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1389         raise exception.VolumeNotCreated(volume_id=vol_id,
1390                                          seconds=int(time.time() - start),
1391                                          attempts=attempt,
1392                                          volume_status=volume_status)
1393 
1394     def _decode_files(self, injected_files):
1395         """Base64 decode the list of files to inject."""
1396         if not injected_files:
1397             return []
1398 
1399         def _decode(f):
1400             path, contents = f
1401             # Py3 raises binascii.Error instead of TypeError as in Py27
1402             try:
1403                 decoded = base64.b64decode(contents)
1404                 return path, decoded
1405             except (TypeError, binascii.Error):
1406                 raise exception.Base64Exception(path=path)
1407 
1408         return [_decode(f) for f in injected_files]
1409 
1410     def _validate_instance_group_policy(self, context, instance,
1411                                         scheduler_hints):
1412         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1413         # However, there is a race condition with the enforcement of
1414         # the policy.  Since more than one instance may be scheduled at the
1415         # same time, it's possible that more than one instance with an
1416         # anti-affinity policy may end up here.  It's also possible that
1417         # multiple instances with an affinity policy could end up on different
1418         # hosts.  This is a validation step to make sure that starting the
1419         # instance here doesn't violate the policy.
1420         group_hint = scheduler_hints.get('group')
1421         if not group_hint:
1422             return
1423 
1424         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1425         # to check the type on the value and pull the single entry out. The
1426         # API request schema validates that the 'group' hint is a single value.
1427         if isinstance(group_hint, list):
1428             group_hint = group_hint[0]
1429 
1430         @utils.synchronized(group_hint)
1431         def _do_validation(context, instance, group_hint):
1432             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1433             if group.policy and 'anti-affinity' == group.policy:
1434                 instances_uuids = objects.InstanceList.get_uuids_by_host(
1435                     context, self.host)
1436                 ins_on_host = set(instances_uuids)
1437                 members = set(group.members)
1438                 # Determine the set of instance group members on this host
1439                 # which are not the instance in question. This is used to
1440                 # determine how many other members from the same anti-affinity
1441                 # group can be on this host.
1442                 members_on_host = ins_on_host & members - set([instance.uuid])
1443                 rules = group.rules
1444                 if rules and 'max_server_per_host' in rules:
1445                     max_server = rules['max_server_per_host']
1446                 else:
1447                     max_server = 1
1448                 if len(members_on_host) >= max_server:
1449                     msg = _("Anti-affinity instance group policy "
1450                             "was violated.")
1451                     raise exception.RescheduledException(
1452                             instance_uuid=instance.uuid,
1453                             reason=msg)
1454             elif group.policy and 'affinity' == group.policy:
1455                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1456                 if group_hosts and self.host not in group_hosts:
1457                     msg = _("Affinity instance group policy was violated.")
1458                     raise exception.RescheduledException(
1459                             instance_uuid=instance.uuid,
1460                             reason=msg)
1461 
1462         if not CONF.workarounds.disable_group_policy_check_upcall:
1463             _do_validation(context, instance, group_hint)
1464 
1465     def _log_original_error(self, exc_info, instance_uuid):
1466         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1467                   exc_info=exc_info)
1468 
1469     @periodic_task.periodic_task
1470     def _check_instance_build_time(self, context):
1471         """Ensure that instances are not stuck in build."""
1472         timeout = CONF.instance_build_timeout
1473         if timeout == 0:
1474             return
1475 
1476         filters = {'vm_state': vm_states.BUILDING,
1477                    'host': self.host}
1478 
1479         building_insts = objects.InstanceList.get_by_filters(context,
1480                            filters, expected_attrs=[], use_slave=True)
1481 
1482         for instance in building_insts:
1483             if timeutils.is_older_than(instance.created_at, timeout):
1484                 self._set_instance_obj_error_state(context, instance)
1485                 LOG.warning("Instance build timed out. Set to error "
1486                             "state.", instance=instance)
1487 
1488     def _check_instance_exists(self, context, instance):
1489         """Ensure an instance with the same name is not already present."""
1490         if self.driver.instance_exists(instance):
1491             raise exception.InstanceExists(name=instance.name)
1492 
1493     def _allocate_network_async(self, context, instance, requested_networks,
1494                                 security_groups, is_vpn,
1495                                 resource_provider_mapping):
1496         """Method used to allocate networks in the background.
1497 
1498         Broken out for testing.
1499         """
1500         # First check to see if we're specifically not supposed to allocate
1501         # networks because if so, we can exit early.
1502         if requested_networks and requested_networks.no_allocate:
1503             LOG.debug("Not allocating networking since 'none' was specified.",
1504                       instance=instance)
1505             return network_model.NetworkInfo([])
1506 
1507         LOG.debug("Allocating IP information in the background.",
1508                   instance=instance)
1509         retries = CONF.network_allocate_retries
1510         attempts = retries + 1
1511         retry_time = 1
1512         bind_host_id = self.driver.network_binding_host_id(context, instance)
1513         for attempt in range(1, attempts + 1):
1514             try:
1515                 nwinfo = self.network_api.allocate_for_instance(
1516                         context, instance, vpn=is_vpn,
1517                         requested_networks=requested_networks,
1518                         security_groups=security_groups,
1519                         bind_host_id=bind_host_id,
1520                         resource_provider_mapping=resource_provider_mapping)
1521                 LOG.debug('Instance network_info: |%s|', nwinfo,
1522                           instance=instance)
1523                 instance.system_metadata['network_allocated'] = 'True'
1524                 # NOTE(JoshNang) do not save the instance here, as it can cause
1525                 # races. The caller shares a reference to instance and waits
1526                 # for this async greenthread to finish before calling
1527                 # instance.save().
1528                 return nwinfo
1529             except Exception:
1530                 exc_info = sys.exc_info()
1531                 log_info = {'attempt': attempt,
1532                             'attempts': attempts}
1533                 if attempt == attempts:
1534                     LOG.exception('Instance failed network setup '
1535                                   'after %(attempts)d attempt(s)',
1536                                   log_info)
1537                     six.reraise(*exc_info)
1538                 LOG.warning('Instance failed network setup '
1539                             '(attempt %(attempt)d of %(attempts)d)',
1540                             log_info, instance=instance)
1541                 time.sleep(retry_time)
1542                 retry_time *= 2
1543                 if retry_time > 30:
1544                     retry_time = 30
1545         # Not reached.
1546 
1547     def _build_networks_for_instance(self, context, instance,
1548             requested_networks, security_groups, resource_provider_mapping):
1549 
1550         # If we're here from a reschedule the network may already be allocated.
1551         if strutils.bool_from_string(
1552                 instance.system_metadata.get('network_allocated', 'False')):
1553             # NOTE(alex_xu): The network_allocated is True means the network
1554             # resource already allocated at previous scheduling, and the
1555             # network setup is cleanup at previous. After rescheduling, the
1556             # network resource need setup on the new host.
1557             self.network_api.setup_instance_network_on_host(
1558                 context, instance, instance.host)
1559             return self.network_api.get_instance_nw_info(context, instance)
1560 
1561         if not self.is_neutron_security_groups:
1562             security_groups = []
1563 
1564         network_info = self._allocate_network(context, instance,
1565                 requested_networks, security_groups,
1566                 resource_provider_mapping)
1567 
1568         return network_info
1569 
1570     def _allocate_network(self, context, instance, requested_networks,
1571                           security_groups, resource_provider_mapping):
1572         """Start network allocation asynchronously.  Return an instance
1573         of NetworkInfoAsyncWrapper that can be used to retrieve the
1574         allocated networks when the operation has finished.
1575         """
1576         # NOTE(comstud): Since we're allocating networks asynchronously,
1577         # this task state has little meaning, as we won't be in this
1578         # state for very long.
1579         instance.vm_state = vm_states.BUILDING
1580         instance.task_state = task_states.NETWORKING
1581         instance.save(expected_task_state=[None])
1582 
1583         is_vpn = False
1584         return network_model.NetworkInfoAsyncWrapper(
1585                 self._allocate_network_async, context, instance,
1586                 requested_networks, security_groups, is_vpn,
1587                 resource_provider_mapping)
1588 
1589     def _default_root_device_name(self, instance, image_meta, root_bdm):
1590         """Gets a default root device name from the driver.
1591 
1592         :param nova.objects.Instance instance:
1593             The instance for which to get the root device name.
1594         :param nova.objects.ImageMeta image_meta:
1595             The metadata of the image of the instance.
1596         :param nova.objects.BlockDeviceMapping root_bdm:
1597             The description of the root device.
1598         :returns: str -- The default root device name.
1599         :raises: InternalError, TooManyDiskDevices
1600         """
1601         try:
1602             return self.driver.default_root_device_name(instance,
1603                                                         image_meta,
1604                                                         root_bdm)
1605         except NotImplementedError:
1606             return compute_utils.get_next_device_name(instance, [])
1607 
1608     def _default_device_names_for_instance(self, instance,
1609                                            root_device_name,
1610                                            *block_device_lists):
1611         """Default the missing device names in the BDM from the driver.
1612 
1613         :param nova.objects.Instance instance:
1614             The instance for which to get default device names.
1615         :param str root_device_name: The root device name.
1616         :param list block_device_lists: List of block device mappings.
1617         :returns: None
1618         :raises: InternalError, TooManyDiskDevices
1619         """
1620         try:
1621             self.driver.default_device_names_for_instance(instance,
1622                                                           root_device_name,
1623                                                           *block_device_lists)
1624         except NotImplementedError:
1625             compute_utils.default_device_names_for_instance(
1626                 instance, root_device_name, *block_device_lists)
1627 
1628     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1629         """Get the next device name from the driver, based on the BDM.
1630 
1631         :param nova.objects.Instance instance:
1632             The instance whose volume is requesting a device name.
1633         :param nova.objects.BlockDeviceMappingList bdms:
1634             The block device mappings for the instance.
1635         :param nova.objects.BlockDeviceMapping block_device_obj:
1636             A block device mapping containing info about the requested block
1637             device.
1638         :returns: The next device name.
1639         :raises: InternalError, TooManyDiskDevices
1640         """
1641         # NOTE(ndipanov): Copy obj to avoid changing the original
1642         block_device_obj = block_device_obj.obj_clone()
1643         try:
1644             return self.driver.get_device_name_for_instance(
1645                 instance, bdms, block_device_obj)
1646         except NotImplementedError:
1647             return compute_utils.get_device_name_for_instance(
1648                 instance, bdms, block_device_obj.get("device_name"))
1649 
1650     def _default_block_device_names(self, instance, image_meta, block_devices):
1651         """Verify that all the devices have the device_name set. If not,
1652         provide a default name.
1653 
1654         It also ensures that there is a root_device_name and is set to the
1655         first block device in the boot sequence (boot_index=0).
1656         """
1657         root_bdm = block_device.get_root_bdm(block_devices)
1658         if not root_bdm:
1659             return
1660 
1661         # Get the root_device_name from the root BDM or the instance
1662         root_device_name = None
1663         update_root_bdm = False
1664 
1665         if root_bdm.device_name:
1666             root_device_name = root_bdm.device_name
1667             instance.root_device_name = root_device_name
1668         elif instance.root_device_name:
1669             root_device_name = instance.root_device_name
1670             root_bdm.device_name = root_device_name
1671             update_root_bdm = True
1672         else:
1673             root_device_name = self._default_root_device_name(instance,
1674                                                               image_meta,
1675                                                               root_bdm)
1676 
1677             instance.root_device_name = root_device_name
1678             root_bdm.device_name = root_device_name
1679             update_root_bdm = True
1680 
1681         if update_root_bdm:
1682             root_bdm.save()
1683 
1684         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1685                             block_devices))
1686         swap = list(filter(block_device.new_format_is_swap,
1687                       block_devices))
1688         block_device_mapping = list(filter(
1689               driver_block_device.is_block_device_mapping, block_devices))
1690 
1691         self._default_device_names_for_instance(instance,
1692                                                 root_device_name,
1693                                                 ephemerals,
1694                                                 swap,
1695                                                 block_device_mapping)
1696 
1697     def _block_device_info_to_legacy(self, block_device_info):
1698         """Convert BDI to the old format for drivers that need it."""
1699 
1700         if self.use_legacy_block_device_info:
1701             ephemerals = driver_block_device.legacy_block_devices(
1702                 driver.block_device_info_get_ephemerals(block_device_info))
1703             mapping = driver_block_device.legacy_block_devices(
1704                 driver.block_device_info_get_mapping(block_device_info))
1705             swap = block_device_info['swap']
1706             if swap:
1707                 swap = swap.legacy()
1708 
1709             block_device_info.update({
1710                 'ephemerals': ephemerals,
1711                 'swap': swap,
1712                 'block_device_mapping': mapping})
1713 
1714     def _add_missing_dev_names(self, bdms, instance):
1715         for bdm in bdms:
1716             if bdm.device_name is not None:
1717                 continue
1718 
1719             device_name = self._get_device_name_for_instance(instance,
1720                                                              bdms, bdm)
1721             values = {'device_name': device_name}
1722             bdm.update(values)
1723             bdm.save()
1724 
1725     def _prep_block_device(self, context, instance, bdms):
1726         """Set up the block device for an instance with error logging."""
1727         try:
1728             self._add_missing_dev_names(bdms, instance)
1729             block_device_info = driver.get_block_device_info(instance, bdms)
1730             mapping = driver.block_device_info_get_mapping(block_device_info)
1731             driver_block_device.attach_block_devices(
1732                 mapping, context, instance, self.volume_api, self.driver,
1733                 wait_func=self._await_block_device_map_created)
1734 
1735             self._block_device_info_to_legacy(block_device_info)
1736             return block_device_info
1737 
1738         except exception.OverQuota as e:
1739             LOG.warning('Failed to create block device for instance due'
1740                         ' to exceeding volume related resource quota.'
1741                         ' Error: %s', e.message, instance=instance)
1742             raise
1743 
1744         except Exception as ex:
1745             LOG.exception('Instance failed block device setup',
1746                           instance=instance)
1747             # InvalidBDM will eventually result in a BuildAbortException when
1748             # booting from volume, and will be recorded as an instance fault.
1749             # Maintain the original exception message which most likely has
1750             # useful details which the standard InvalidBDM error message lacks.
1751             raise exception.InvalidBDM(six.text_type(ex))
1752 
1753     def _update_instance_after_spawn(self, context, instance):
1754         instance.power_state = self._get_power_state(context, instance)
1755         instance.vm_state = vm_states.ACTIVE
1756         instance.task_state = None
1757         instance.launched_at = timeutils.utcnow()
1758         configdrive.update_instance(instance)
1759 
1760     def _update_scheduler_instance_info(self, context, instance):
1761         """Sends an InstanceList with created or updated Instance objects to
1762         the Scheduler client.
1763 
1764         In the case of init_host, the value passed will already be an
1765         InstanceList. Other calls will send individual Instance objects that
1766         have been created or resized. In this case, we create an InstanceList
1767         object containing that Instance.
1768         """
1769         if not self.send_instance_updates:
1770             return
1771         if isinstance(instance, obj_instance.Instance):
1772             instance = objects.InstanceList(objects=[instance])
1773         context = context.elevated()
1774         self.query_client.update_instance_info(context, self.host,
1775                                                instance)
1776 
1777     def _delete_scheduler_instance_info(self, context, instance_uuid):
1778         """Sends the uuid of the deleted Instance to the Scheduler client."""
1779         if not self.send_instance_updates:
1780             return
1781         context = context.elevated()
1782         self.query_client.delete_instance_info(context, self.host,
1783                                                instance_uuid)
1784 
1785     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1786     def _sync_scheduler_instance_info(self, context):
1787         if not self.send_instance_updates:
1788             return
1789         context = context.elevated()
1790         instances = objects.InstanceList.get_by_host(context, self.host,
1791                                                      expected_attrs=[],
1792                                                      use_slave=True)
1793         uuids = [instance.uuid for instance in instances]
1794         self.query_client.sync_instance_info(context, self.host, uuids)
1795 
1796     def _notify_about_instance_usage(self, context, instance, event_suffix,
1797                                      network_info=None, extra_usage_info=None,
1798                                      fault=None):
1799         compute_utils.notify_about_instance_usage(
1800             self.notifier, context, instance, event_suffix,
1801             network_info=network_info,
1802             extra_usage_info=extra_usage_info, fault=fault)
1803 
1804     def _deallocate_network(self, context, instance,
1805                             requested_networks=None):
1806         # If we were told not to allocate networks let's save ourselves
1807         # the trouble of calling the network API.
1808         if requested_networks and requested_networks.no_allocate:
1809             LOG.debug("Skipping network deallocation for instance since "
1810                       "networking was not requested.", instance=instance)
1811             return
1812 
1813         LOG.debug('Deallocating network for instance', instance=instance)
1814         with timeutils.StopWatch() as timer:
1815             self.network_api.deallocate_for_instance(
1816                 context, instance, requested_networks=requested_networks)
1817         # nova-network does an rpc call so we're OK tracking time spent here
1818         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1819                  timer.elapsed(), instance=instance)
1820 
1821     def _get_instance_block_device_info(self, context, instance,
1822                                         refresh_conn_info=False,
1823                                         bdms=None):
1824         """Transform block devices to the driver block_device format."""
1825 
1826         if bdms is None:
1827             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1828                     context, instance.uuid)
1829         block_device_info = driver.get_block_device_info(instance, bdms)
1830 
1831         if not refresh_conn_info:
1832             # if the block_device_mapping has no value in connection_info
1833             # (returned as None), don't include in the mapping
1834             block_device_info['block_device_mapping'] = [
1835                 bdm for bdm in driver.block_device_info_get_mapping(
1836                                     block_device_info)
1837                 if bdm.get('connection_info')]
1838         else:
1839             driver_block_device.refresh_conn_infos(
1840                 driver.block_device_info_get_mapping(block_device_info),
1841                 context, instance, self.volume_api, self.driver)
1842 
1843         self._block_device_info_to_legacy(block_device_info)
1844 
1845         return block_device_info
1846 
1847     def _build_failed(self, node):
1848         if CONF.compute.consecutive_build_service_disable_threshold:
1849             # NOTE(danms): Update our counter, but wait for the next
1850             # update_available_resource() periodic to flush it to the DB
1851             self.rt.build_failed(node)
1852 
1853     def _build_succeeded(self, node):
1854         self.rt.build_succeeded(node)
1855 
1856     @wrap_exception()
1857     @reverts_task_state
1858     @wrap_instance_fault
1859     def build_and_run_instance(self, context, instance, image, request_spec,
1860                      filter_properties, admin_password=None,
1861                      injected_files=None, requested_networks=None,
1862                      security_groups=None, block_device_mapping=None,
1863                      node=None, limits=None, host_list=None):
1864 
1865         @utils.synchronized(instance.uuid)
1866         def _locked_do_build_and_run_instance(*args, **kwargs):
1867             # NOTE(danms): We grab the semaphore with the instance uuid
1868             # locked because we could wait in line to build this instance
1869             # for a while and we want to make sure that nothing else tries
1870             # to do anything with this instance while we wait.
1871             with self._build_semaphore:
1872                 try:
1873                     result = self._do_build_and_run_instance(*args, **kwargs)
1874                 except Exception:
1875                     # NOTE(mriedem): This should really only happen if
1876                     # _decode_files in _do_build_and_run_instance fails, and
1877                     # that's before a guest is spawned so it's OK to remove
1878                     # allocations for the instance for this node from Placement
1879                     # below as there is no guest consuming resources anyway.
1880                     # The _decode_files case could be handled more specifically
1881                     # but that's left for another day.
1882                     result = build_results.FAILED
1883                     raise
1884                 finally:
1885                     if result == build_results.FAILED:
1886                         # Remove the allocation records from Placement for the
1887                         # instance if the build failed. The instance.host is
1888                         # likely set to None in _do_build_and_run_instance
1889                         # which means if the user deletes the instance, it
1890                         # will be deleted in the API, not the compute service.
1891                         # Setting the instance.host to None in
1892                         # _do_build_and_run_instance means that the
1893                         # ResourceTracker will no longer consider this instance
1894                         # to be claiming resources against it, so we want to
1895                         # reflect that same thing in Placement.  No need to
1896                         # call this for a reschedule, as the allocations will
1897                         # have already been removed in
1898                         # self._do_build_and_run_instance().
1899                         self.reportclient.delete_allocation_for_instance(
1900                             context, instance.uuid)
1901 
1902                     if result in (build_results.FAILED,
1903                                   build_results.RESCHEDULED):
1904                         self._build_failed(node)
1905                     else:
1906                         self._build_succeeded(node)
1907 
1908         # NOTE(danms): We spawn here to return the RPC worker thread back to
1909         # the pool. Since what follows could take a really long time, we don't
1910         # want to tie up RPC workers.
1911         utils.spawn_n(_locked_do_build_and_run_instance,
1912                       context, instance, image, request_spec,
1913                       filter_properties, admin_password, injected_files,
1914                       requested_networks, security_groups,
1915                       block_device_mapping, node, limits, host_list)
1916 
1917     def _check_device_tagging(self, requested_networks, block_device_mapping):
1918         tagging_requested = False
1919         if requested_networks:
1920             for net in requested_networks:
1921                 if 'tag' in net and net.tag is not None:
1922                     tagging_requested = True
1923                     break
1924         if block_device_mapping and not tagging_requested:
1925             for bdm in block_device_mapping:
1926                 if 'tag' in bdm and bdm.tag is not None:
1927                     tagging_requested = True
1928                     break
1929         if (tagging_requested and
1930                 not self.driver.capabilities.get('supports_device_tagging',
1931                                                  False)):
1932             raise exception.BuildAbortException('Attempt to boot guest with '
1933                                                 'tagged devices on host that '
1934                                                 'does not support tagging.')
1935 
1936     def _check_trusted_certs(self, instance):
1937         if (instance.trusted_certs and
1938                 not self.driver.capabilities.get('supports_trusted_certs',
1939                                                  False)):
1940             raise exception.BuildAbortException(
1941                 'Trusted image certificates provided on host that does not '
1942                 'support certificate validation.')
1943 
1944     @hooks.add_hook('build_instance')
1945     @wrap_exception()
1946     @reverts_task_state
1947     @wrap_instance_event(prefix='compute')
1948     @wrap_instance_fault
1949     def _do_build_and_run_instance(self, context, instance, image,
1950             request_spec, filter_properties, admin_password, injected_files,
1951             requested_networks, security_groups, block_device_mapping,
1952             node=None, limits=None, host_list=None):
1953 
1954         try:
1955             LOG.debug('Starting instance...', instance=instance)
1956             instance.vm_state = vm_states.BUILDING
1957             instance.task_state = None
1958             instance.save(expected_task_state=
1959                     (task_states.SCHEDULING, None))
1960         except exception.InstanceNotFound:
1961             msg = 'Instance disappeared before build.'
1962             LOG.debug(msg, instance=instance)
1963             return build_results.FAILED
1964         except exception.UnexpectedTaskStateError as e:
1965             LOG.debug(e.format_message(), instance=instance)
1966             return build_results.FAILED
1967 
1968         # b64 decode the files to inject:
1969         decoded_files = self._decode_files(injected_files)
1970 
1971         if limits is None:
1972             limits = {}
1973 
1974         if node is None:
1975             node = self._get_nodename(instance, refresh=True)
1976 
1977         try:
1978             with timeutils.StopWatch() as timer:
1979                 self._build_and_run_instance(context, instance, image,
1980                         decoded_files, admin_password, requested_networks,
1981                         security_groups, block_device_mapping, node, limits,
1982                         filter_properties, request_spec)
1983             LOG.info('Took %0.2f seconds to build instance.',
1984                      timer.elapsed(), instance=instance)
1985             return build_results.ACTIVE
1986         except exception.RescheduledException as e:
1987             retry = filter_properties.get('retry')
1988             if not retry:
1989                 # no retry information, do not reschedule.
1990                 LOG.debug("Retry info not present, will not reschedule",
1991                     instance=instance)
1992                 self._cleanup_allocated_networks(context, instance,
1993                     requested_networks)
1994                 self._cleanup_volumes(context, instance,
1995                     block_device_mapping, raise_exc=False)
1996                 compute_utils.add_instance_fault_from_exc(context,
1997                         instance, e, sys.exc_info(),
1998                         fault_message=e.kwargs['reason'])
1999                 self._nil_out_instance_obj_host_and_node(instance)
2000                 self._set_instance_obj_error_state(context, instance,
2001                                                    clean_task_state=True)
2002                 return build_results.FAILED
2003             LOG.debug(e.format_message(), instance=instance)
2004             # This will be used for logging the exception
2005             retry['exc'] = traceback.format_exception(*sys.exc_info())
2006             # This will be used for setting the instance fault message
2007             retry['exc_reason'] = e.kwargs['reason']
2008             # NOTE(comstud): Deallocate networks if the driver wants
2009             # us to do so.
2010             # NOTE(mriedem): Always deallocate networking when using Neutron.
2011             # This is to unbind any ports that the user supplied in the server
2012             # create request, or delete any ports that nova created which were
2013             # meant to be bound to this host. This check intentionally bypasses
2014             # the result of deallocate_networks_on_reschedule because the
2015             # default value in the driver is False, but that method was really
2016             # only meant for Ironic and should be removed when nova-network is
2017             # removed (since is_neutron() will then always be True).
2018             # NOTE(vladikr): SR-IOV ports should be deallocated to
2019             # allow new sriov pci devices to be allocated on a new host.
2020             # Otherwise, if devices with pci addresses are already allocated
2021             # on the destination host, the instance will fail to spawn.
2022             # info_cache.network_info should be present at this stage.
2023             if (self.driver.deallocate_networks_on_reschedule(instance) or
2024                 utils.is_neutron() or
2025                 self.deallocate_sriov_ports_on_reschedule(instance)):
2026                 self._cleanup_allocated_networks(context, instance,
2027                         requested_networks)
2028             else:
2029                 # NOTE(alex_xu): Network already allocated and we don't
2030                 # want to deallocate them before rescheduling. But we need
2031                 # to cleanup those network resources setup on this host before
2032                 # rescheduling.
2033                 self.network_api.cleanup_instance_network_on_host(
2034                     context, instance, self.host)
2035 
2036             self._nil_out_instance_obj_host_and_node(instance)
2037             instance.task_state = task_states.SCHEDULING
2038             instance.save()
2039             # The instance will have already claimed resources from this host
2040             # before this build was attempted. Now that it has failed, we need
2041             # to unclaim those resources before casting to the conductor, so
2042             # that if there are alternate hosts available for a retry, it can
2043             # claim resources on that new host for the instance.
2044             self.reportclient.delete_allocation_for_instance(context,
2045                                                              instance.uuid)
2046 
2047             self.compute_task_api.build_instances(context, [instance],
2048                     image, filter_properties, admin_password,
2049                     injected_files, requested_networks, security_groups,
2050                     block_device_mapping, request_spec=request_spec,
2051                     host_lists=[host_list])
2052             return build_results.RESCHEDULED
2053         except (exception.InstanceNotFound,
2054                 exception.UnexpectedDeletingTaskStateError):
2055             msg = 'Instance disappeared during build.'
2056             LOG.debug(msg, instance=instance)
2057             self._cleanup_allocated_networks(context, instance,
2058                     requested_networks)
2059             return build_results.FAILED
2060         except Exception as e:
2061             if isinstance(e, exception.BuildAbortException):
2062                 LOG.error(e.format_message(), instance=instance)
2063             else:
2064                 # Should not reach here.
2065                 LOG.exception('Unexpected build failure, not rescheduling '
2066                               'build.', instance=instance)
2067             self._cleanup_allocated_networks(context, instance,
2068                     requested_networks)
2069             self._cleanup_volumes(context, instance,
2070                     block_device_mapping, raise_exc=False)
2071             compute_utils.add_instance_fault_from_exc(context, instance,
2072                     e, sys.exc_info())
2073             self._nil_out_instance_obj_host_and_node(instance)
2074             self._set_instance_obj_error_state(context, instance,
2075                                                clean_task_state=True)
2076             return build_results.FAILED
2077 
2078     def deallocate_sriov_ports_on_reschedule(self, instance):
2079         """Determine if networks are needed to be deallocated before reschedule
2080 
2081         Check the cached network info for any assigned SR-IOV ports.
2082         SR-IOV ports should be deallocated prior to rescheduling
2083         in order to allow new sriov pci devices to be allocated on a new host.
2084         """
2085         info_cache = instance.info_cache
2086 
2087         def _has_sriov_port(vif):
2088             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
2089 
2090         if (info_cache and info_cache.network_info):
2091             for vif in info_cache.network_info:
2092                 if _has_sriov_port(vif):
2093                     return True
2094         return False
2095 
2096     @staticmethod
2097     def _get_scheduler_hints(filter_properties, request_spec=None):
2098         """Helper method to get scheduler hints.
2099 
2100         This method prefers to get the hints out of the request spec, but that
2101         might not be provided. Conductor will pass request_spec down to the
2102         first compute chosen for a build but older computes will not pass
2103         the request_spec to conductor's build_instances method for a
2104         a reschedule, so if we're on a host via a retry, request_spec may not
2105         be provided so we need to fallback to use the filter_properties
2106         to get scheduler hints.
2107         """
2108         hints = {}
2109         if request_spec is not None and 'scheduler_hints' in request_spec:
2110             hints = request_spec.scheduler_hints
2111         if not hints:
2112             hints = filter_properties.get('scheduler_hints') or {}
2113         return hints
2114 
2115     @staticmethod
2116     def _get_request_group_mapping(request_spec):
2117         """Return request group resource - provider mapping. This is currently
2118         used for Neutron ports that have resource request due to the port
2119         having QoS minimum bandwidth policy rule attached.
2120 
2121         :param request_spec: A RequestSpec object
2122         :returns: A dict keyed by RequestGroup requester_id, currently Neutron
2123         port_id, to resource provider UUID that provides resource for that
2124         RequestGroup.
2125         """
2126 
2127         if (request_spec and
2128                 'requested_resources' in request_spec and
2129                 request_spec.requested_resources is not None):
2130             return {
2131                 group.requester_id: group.provider_uuids
2132                 for group in request_spec.requested_resources
2133             }
2134         else:
2135             return None
2136 
2137     def _update_pci_request_spec_with_allocated_interface_name(
2138             self, context, instance, request_group_resource_providers_mapping):
2139         if not instance.pci_requests:
2140             return
2141 
2142         def needs_update(pci_request, mapping):
2143             return (pci_request.requester_id and
2144                     pci_request.requester_id in mapping)
2145 
2146         modified = False
2147         for pci_request in instance.pci_requests.requests:
2148             if needs_update(
2149                     pci_request, request_group_resource_providers_mapping):
2150 
2151                 provider_uuids = request_group_resource_providers_mapping[
2152                     pci_request.requester_id]
2153 
2154                 if len(provider_uuids) != 1:
2155                     reason = (
2156                         'Allocating resources from more than one resource '
2157                         'providers %(providers)s for a single pci request '
2158                         '%(requester)s is not supported.' %
2159                         {'providers': provider_uuids,
2160                          'requester': pci_request.requester_id})
2161                     raise exception.BuildAbortException(
2162                         instance_uuid=instance.uuid,
2163                         reason=reason)
2164 
2165                 dev_rp_name = self.reportclient.get_resource_provider_name(
2166                     context,
2167                     provider_uuids[0])
2168 
2169                 # NOTE(gibi): the device RP name reported by neutron is
2170                 # structured like <hostname>:<agentname>:<interfacename>
2171                 rp_name_pieces = dev_rp_name.split(':')
2172                 if len(rp_name_pieces) != 3:
2173                     reason = (
2174                         'Resource provider %(provider)s used to allocate '
2175                         'resources for the pci request %(requester)s does not '
2176                         'have properly formatted name. Expected name format '
2177                         'is <hostname>:<agentname>:<interfacename>, but got '
2178                         '%(provider_name)s' %
2179                         {'provider': provider_uuids[0],
2180                          'requester': pci_request.requester_id,
2181                          'provider_name': dev_rp_name})
2182                     raise exception.BuildAbortException(
2183                         instance_uuid=instance.uuid,
2184                         reason=reason)
2185 
2186                 for spec in pci_request.spec:
2187                     spec['parent_ifname'] = rp_name_pieces[2]
2188                     modified = True
2189         if modified:
2190             instance.save()
2191 
2192     def _build_and_run_instance(self, context, instance, image, injected_files,
2193             admin_password, requested_networks, security_groups,
2194             block_device_mapping, node, limits, filter_properties,
2195             request_spec=None):
2196 
2197         image_name = image.get('name')
2198         self._notify_about_instance_usage(context, instance, 'create.start',
2199                 extra_usage_info={'image_name': image_name})
2200         compute_utils.notify_about_instance_create(
2201             context, instance, self.host,
2202             phase=fields.NotificationPhase.START,
2203             bdms=block_device_mapping)
2204 
2205         # NOTE(mikal): cache the keystone roles associated with the instance
2206         # at boot time for later reference
2207         instance.system_metadata.update(
2208             {'boot_roles': ','.join(context.roles)})
2209 
2210         self._check_device_tagging(requested_networks, block_device_mapping)
2211         self._check_trusted_certs(instance)
2212 
2213         request_group_resource_providers_mapping = \
2214             self._get_request_group_mapping(request_spec)
2215 
2216         if request_group_resource_providers_mapping:
2217             self._update_pci_request_spec_with_allocated_interface_name(
2218                 context, instance, request_group_resource_providers_mapping)
2219 
2220         try:
2221             scheduler_hints = self._get_scheduler_hints(filter_properties,
2222                                                         request_spec)
2223             with self.rt.instance_claim(context, instance, node, limits):
2224                 # NOTE(russellb) It's important that this validation be done
2225                 # *after* the resource tracker instance claim, as that is where
2226                 # the host is set on the instance.
2227                 self._validate_instance_group_policy(context, instance,
2228                                                      scheduler_hints)
2229                 image_meta = objects.ImageMeta.from_dict(image)
2230 
2231                 request_group_resource_providers_mapping = \
2232                     self._get_request_group_mapping(request_spec)
2233 
2234                 with self._build_resources(context, instance,
2235                         requested_networks, security_groups, image_meta,
2236                         block_device_mapping,
2237                         request_group_resource_providers_mapping) as resources:
2238                     instance.vm_state = vm_states.BUILDING
2239                     instance.task_state = task_states.SPAWNING
2240                     # NOTE(JoshNang) This also saves the changes to the
2241                     # instance from _allocate_network_async, as they aren't
2242                     # saved in that function to prevent races.
2243                     instance.save(expected_task_state=
2244                             task_states.BLOCK_DEVICE_MAPPING)
2245                     block_device_info = resources['block_device_info']
2246                     network_info = resources['network_info']
2247                     allocs = resources['allocations']
2248                     LOG.debug('Start spawning the instance on the hypervisor.',
2249                               instance=instance)
2250                     with timeutils.StopWatch() as timer:
2251                         self.driver.spawn(context, instance, image_meta,
2252                                           injected_files, admin_password,
2253                                           allocs, network_info=network_info,
2254                                           block_device_info=block_device_info)
2255                     LOG.info('Took %0.2f seconds to spawn the instance on '
2256                              'the hypervisor.', timer.elapsed(),
2257                              instance=instance)
2258         except (exception.InstanceNotFound,
2259                 exception.UnexpectedDeletingTaskStateError) as e:
2260             with excutils.save_and_reraise_exception():
2261                 self._notify_about_instance_usage(context, instance,
2262                     'create.error', fault=e)
2263                 tb = traceback.format_exc()
2264                 compute_utils.notify_about_instance_create(
2265                     context, instance, self.host,
2266                     phase=fields.NotificationPhase.ERROR, exception=e,
2267                     bdms=block_device_mapping, tb=tb)
2268         except exception.ComputeResourcesUnavailable as e:
2269             LOG.debug(e.format_message(), instance=instance)
2270             self._notify_about_instance_usage(context, instance,
2271                     'create.error', fault=e)
2272             tb = traceback.format_exc()
2273             compute_utils.notify_about_instance_create(
2274                     context, instance, self.host,
2275                     phase=fields.NotificationPhase.ERROR, exception=e,
2276                     bdms=block_device_mapping, tb=tb)
2277             raise exception.RescheduledException(
2278                     instance_uuid=instance.uuid, reason=e.format_message())
2279         except exception.BuildAbortException as e:
2280             with excutils.save_and_reraise_exception():
2281                 LOG.debug(e.format_message(), instance=instance)
2282                 self._notify_about_instance_usage(context, instance,
2283                     'create.error', fault=e)
2284                 tb = traceback.format_exc()
2285                 compute_utils.notify_about_instance_create(
2286                     context, instance, self.host,
2287                     phase=fields.NotificationPhase.ERROR, exception=e,
2288                     bdms=block_device_mapping, tb=tb)
2289         except (exception.FixedIpLimitExceeded,
2290                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2291             LOG.warning('No more network or fixed IP to be allocated',
2292                         instance=instance)
2293             self._notify_about_instance_usage(context, instance,
2294                     'create.error', fault=e)
2295             tb = traceback.format_exc()
2296             compute_utils.notify_about_instance_create(
2297                     context, instance, self.host,
2298                     phase=fields.NotificationPhase.ERROR, exception=e,
2299                     bdms=block_device_mapping, tb=tb)
2300             msg = _('Failed to allocate the network(s) with error %s, '
2301                     'not rescheduling.') % e.format_message()
2302             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2303                     reason=msg)
2304         except (exception.VirtualInterfaceCreateException,
2305                 exception.VirtualInterfaceMacAddressException,
2306                 exception.FixedIpInvalidOnHost,
2307                 exception.UnableToAutoAllocateNetwork,
2308                 exception.NetworksWithQoSPolicyNotSupported) as e:
2309             LOG.exception('Failed to allocate network(s)',
2310                           instance=instance)
2311             self._notify_about_instance_usage(context, instance,
2312                     'create.error', fault=e)
2313             tb = traceback.format_exc()
2314             compute_utils.notify_about_instance_create(
2315                     context, instance, self.host,
2316                     phase=fields.NotificationPhase.ERROR, exception=e,
2317                     bdms=block_device_mapping, tb=tb)
2318             msg = _('Failed to allocate the network(s), not rescheduling.')
2319             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2320                     reason=msg)
2321         except (exception.FlavorDiskTooSmall,
2322                 exception.FlavorMemoryTooSmall,
2323                 exception.ImageNotActive,
2324                 exception.ImageUnacceptable,
2325                 exception.InvalidDiskInfo,
2326                 exception.InvalidDiskFormat,
2327                 cursive_exception.SignatureVerificationError,
2328                 exception.CertificateValidationFailed,
2329                 exception.VolumeEncryptionNotSupported,
2330                 exception.InvalidInput,
2331                 # TODO(mriedem): We should be validating RequestedVRamTooHigh
2332                 # in the API during server create and rebuild.
2333                 exception.RequestedVRamTooHigh) as e:
2334             self._notify_about_instance_usage(context, instance,
2335                     'create.error', fault=e)
2336             tb = traceback.format_exc()
2337             compute_utils.notify_about_instance_create(
2338                     context, instance, self.host,
2339                     phase=fields.NotificationPhase.ERROR, exception=e,
2340                     bdms=block_device_mapping, tb=tb)
2341             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2342                     reason=e.format_message())
2343         except Exception as e:
2344             self._notify_about_instance_usage(context, instance,
2345                     'create.error', fault=e)
2346             tb = traceback.format_exc()
2347             compute_utils.notify_about_instance_create(
2348                     context, instance, self.host,
2349                     phase=fields.NotificationPhase.ERROR, exception=e,
2350                     bdms=block_device_mapping, tb=tb)
2351             raise exception.RescheduledException(
2352                     instance_uuid=instance.uuid, reason=six.text_type(e))
2353 
2354         # NOTE(alaski): This is only useful during reschedules, remove it now.
2355         instance.system_metadata.pop('network_allocated', None)
2356 
2357         # If CONF.default_access_ip_network_name is set, grab the
2358         # corresponding network and set the access ip values accordingly.
2359         network_name = CONF.default_access_ip_network_name
2360         if (network_name and not instance.access_ip_v4 and
2361                 not instance.access_ip_v6):
2362             # Note that when there are multiple ips to choose from, an
2363             # arbitrary one will be chosen.
2364             for vif in network_info:
2365                 if vif['network']['label'] == network_name:
2366                     for ip in vif.fixed_ips():
2367                         if not instance.access_ip_v4 and ip['version'] == 4:
2368                             instance.access_ip_v4 = ip['address']
2369                         if not instance.access_ip_v6 and ip['version'] == 6:
2370                             instance.access_ip_v6 = ip['address']
2371                     break
2372 
2373         self._update_instance_after_spawn(context, instance)
2374 
2375         try:
2376             instance.save(expected_task_state=task_states.SPAWNING)
2377         except (exception.InstanceNotFound,
2378                 exception.UnexpectedDeletingTaskStateError) as e:
2379             with excutils.save_and_reraise_exception():
2380                 self._notify_about_instance_usage(context, instance,
2381                     'create.error', fault=e)
2382                 tb = traceback.format_exc()
2383                 compute_utils.notify_about_instance_create(
2384                     context, instance, self.host,
2385                     phase=fields.NotificationPhase.ERROR, exception=e,
2386                     bdms=block_device_mapping, tb=tb)
2387 
2388         self._update_scheduler_instance_info(context, instance)
2389         self._notify_about_instance_usage(context, instance, 'create.end',
2390                 extra_usage_info={'message': _('Success')},
2391                 network_info=network_info)
2392         compute_utils.notify_about_instance_create(context, instance,
2393                 self.host, phase=fields.NotificationPhase.END,
2394                 bdms=block_device_mapping)
2395 
2396     @contextlib.contextmanager
2397     def _build_resources(self, context, instance, requested_networks,
2398                          security_groups, image_meta, block_device_mapping,
2399                          resource_provider_mapping):
2400         resources = {}
2401         network_info = None
2402         try:
2403             LOG.debug('Start building networks asynchronously for instance.',
2404                       instance=instance)
2405             network_info = self._build_networks_for_instance(context, instance,
2406                     requested_networks, security_groups,
2407                     resource_provider_mapping)
2408             resources['network_info'] = network_info
2409         except (exception.InstanceNotFound,
2410                 exception.UnexpectedDeletingTaskStateError):
2411             raise
2412         except exception.UnexpectedTaskStateError as e:
2413             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2414                     reason=e.format_message())
2415         except Exception:
2416             # Because this allocation is async any failures are likely to occur
2417             # when the driver accesses network_info during spawn().
2418             LOG.exception('Failed to allocate network(s)',
2419                           instance=instance)
2420             msg = _('Failed to allocate the network(s), not rescheduling.')
2421             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2422                     reason=msg)
2423 
2424         try:
2425             # Perform any driver preparation work for the driver.
2426             self.driver.prepare_for_spawn(instance)
2427 
2428             # Depending on a virt driver, some network configuration is
2429             # necessary before preparing block devices.
2430             self.driver.prepare_networks_before_block_device_mapping(
2431                 instance, network_info)
2432 
2433             # Verify that all the BDMs have a device_name set and assign a
2434             # default to the ones missing it with the help of the driver.
2435             self._default_block_device_names(instance, image_meta,
2436                                              block_device_mapping)
2437 
2438             LOG.debug('Start building block device mappings for instance.',
2439                       instance=instance)
2440             instance.vm_state = vm_states.BUILDING
2441             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2442             instance.save()
2443 
2444             block_device_info = self._prep_block_device(context, instance,
2445                     block_device_mapping)
2446             resources['block_device_info'] = block_device_info
2447         except (exception.InstanceNotFound,
2448                 exception.UnexpectedDeletingTaskStateError):
2449             with excutils.save_and_reraise_exception():
2450                 # Make sure the async call finishes
2451                 if network_info is not None:
2452                     network_info.wait(do_raise=False)
2453                     self.driver.clean_networks_preparation(instance,
2454                                                            network_info)
2455                 self.driver.failed_spawn_cleanup(instance)
2456         except (exception.UnexpectedTaskStateError,
2457                 exception.OverQuota, exception.InvalidBDM) as e:
2458             # Make sure the async call finishes
2459             if network_info is not None:
2460                 network_info.wait(do_raise=False)
2461                 self.driver.clean_networks_preparation(instance, network_info)
2462             self.driver.failed_spawn_cleanup(instance)
2463             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2464                     reason=e.format_message())
2465         except Exception:
2466             LOG.exception('Failure prepping block device',
2467                           instance=instance)
2468             # Make sure the async call finishes
2469             if network_info is not None:
2470                 network_info.wait(do_raise=False)
2471                 self.driver.clean_networks_preparation(instance, network_info)
2472             self.driver.failed_spawn_cleanup(instance)
2473             msg = _('Failure prepping block device.')
2474             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2475                     reason=msg)
2476 
2477         try:
2478             resources['allocations'] = (
2479                 self.reportclient.get_allocations_for_consumer(context,
2480                                                                instance.uuid))
2481         except Exception:
2482             LOG.exception('Failure retrieving placement allocations',
2483                           instance=instance)
2484             # Make sure the async call finishes
2485             if network_info is not None:
2486                 network_info.wait(do_raise=False)
2487             self.driver.failed_spawn_cleanup(instance)
2488             msg = _('Failure retrieving placement allocations')
2489             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2490                                                 reason=msg)
2491 
2492         try:
2493             yield resources
2494         except Exception as exc:
2495             with excutils.save_and_reraise_exception() as ctxt:
2496                 if not isinstance(exc, (
2497                         exception.InstanceNotFound,
2498                         exception.UnexpectedDeletingTaskStateError)):
2499                     LOG.exception('Instance failed to spawn',
2500                                   instance=instance)
2501                 # Make sure the async call finishes
2502                 if network_info is not None:
2503                     network_info.wait(do_raise=False)
2504                 # if network_info is empty we're likely here because of
2505                 # network allocation failure. Since nothing can be reused on
2506                 # rescheduling it's better to deallocate network to eliminate
2507                 # the chance of orphaned ports in neutron
2508                 deallocate_networks = False if network_info else True
2509                 try:
2510                     self._shutdown_instance(context, instance,
2511                             block_device_mapping, requested_networks,
2512                             try_deallocate_networks=deallocate_networks)
2513                 except Exception as exc2:
2514                     ctxt.reraise = False
2515                     LOG.warning('Could not clean up failed build,'
2516                                 ' not rescheduling. Error: %s',
2517                                 six.text_type(exc2))
2518                     raise exception.BuildAbortException(
2519                             instance_uuid=instance.uuid,
2520                             reason=six.text_type(exc))
2521 
2522     def _cleanup_allocated_networks(self, context, instance,
2523             requested_networks):
2524         try:
2525             self._deallocate_network(context, instance, requested_networks)
2526         except Exception:
2527             LOG.exception('Failed to deallocate networks', instance=instance)
2528             return
2529 
2530         instance.system_metadata['network_allocated'] = 'False'
2531         try:
2532             instance.save()
2533         except exception.InstanceNotFound:
2534             # NOTE(alaski): It's possible that we're cleaning up the networks
2535             # because the instance was deleted.  If that's the case then this
2536             # exception will be raised by instance.save()
2537             pass
2538 
2539     def _try_deallocate_network(self, context, instance,
2540                                 requested_networks=None):
2541 
2542         # During auto-scale cleanup, we could be deleting a large number
2543         # of servers at the same time and overloading parts of the system,
2544         # so we retry a few times in case of connection failures to the
2545         # networking service.
2546         @loopingcall.RetryDecorator(
2547             max_retry_count=3, inc_sleep_time=2, max_sleep_time=12,
2548             exceptions=(keystone_exception.connection.ConnectFailure,))
2549         def _deallocate_network_with_retries():
2550             try:
2551                 self._deallocate_network(
2552                     context, instance, requested_networks)
2553             except keystone_exception.connection.ConnectFailure as e:
2554                 # Provide a warning that something is amiss.
2555                 with excutils.save_and_reraise_exception():
2556                     LOG.warning('Failed to deallocate network for instance; '
2557                                 'retrying. Error: %s', six.text_type(e),
2558                                 instance=instance)
2559 
2560         try:
2561             # tear down allocated network structure
2562             _deallocate_network_with_retries()
2563         except Exception as ex:
2564             with excutils.save_and_reraise_exception():
2565                 LOG.error('Failed to deallocate network for instance. '
2566                           'Error: %s', ex, instance=instance)
2567                 self._set_instance_obj_error_state(context, instance)
2568 
2569     def _get_power_off_values(self, context, instance, clean_shutdown):
2570         """Get the timing configuration for powering down this instance."""
2571         if clean_shutdown:
2572             timeout = compute_utils.get_value_from_system_metadata(instance,
2573                           key='image_os_shutdown_timeout', type=int,
2574                           default=CONF.shutdown_timeout)
2575             retry_interval = CONF.compute.shutdown_retry_interval
2576         else:
2577             timeout = 0
2578             retry_interval = 0
2579 
2580         return timeout, retry_interval
2581 
2582     def _power_off_instance(self, context, instance, clean_shutdown=True):
2583         """Power off an instance on this host."""
2584         timeout, retry_interval = self._get_power_off_values(context,
2585                                         instance, clean_shutdown)
2586         self.driver.power_off(instance, timeout, retry_interval)
2587 
2588     def _shutdown_instance(self, context, instance,
2589                            bdms, requested_networks=None, notify=True,
2590                            try_deallocate_networks=True):
2591         """Shutdown an instance on this host.
2592 
2593         :param:context: security context
2594         :param:instance: a nova.objects.Instance object
2595         :param:bdms: the block devices for the instance to be torn
2596                      down
2597         :param:requested_networks: the networks on which the instance
2598                                    has ports
2599         :param:notify: true if a final usage notification should be
2600                        emitted
2601         :param:try_deallocate_networks: false if we should avoid
2602                                         trying to teardown networking
2603         """
2604         context = context.elevated()
2605         LOG.info('Terminating instance', instance=instance)
2606 
2607         if notify:
2608             self._notify_about_instance_usage(context, instance,
2609                                               "shutdown.start")
2610             compute_utils.notify_about_instance_action(context, instance,
2611                     self.host, action=fields.NotificationAction.SHUTDOWN,
2612                     phase=fields.NotificationPhase.START, bdms=bdms)
2613 
2614         network_info = instance.get_network_info()
2615 
2616         # NOTE(arnaudmorin) to avoid nova destroying the instance without
2617         # unplugging the interface, refresh network_info if it is empty.
2618         if not network_info:
2619             network_info = self.network_api.get_instance_nw_info(
2620                 context, instance)
2621 
2622         # NOTE(vish) get bdms before destroying the instance
2623         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2624         block_device_info = self._get_instance_block_device_info(
2625             context, instance, bdms=bdms)
2626 
2627         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2628         #                want to keep ip allocated for certain failures
2629         try:
2630             LOG.debug('Start destroying the instance on the hypervisor.',
2631                       instance=instance)
2632             with timeutils.StopWatch() as timer:
2633                 self.driver.destroy(context, instance, network_info,
2634                                     block_device_info)
2635             LOG.info('Took %0.2f seconds to destroy the instance on the '
2636                      'hypervisor.', timer.elapsed(), instance=instance)
2637         except exception.InstancePowerOffFailure:
2638             # if the instance can't power off, don't release the ip
2639             with excutils.save_and_reraise_exception():
2640                 pass
2641         except Exception:
2642             with excutils.save_and_reraise_exception():
2643                 # deallocate ip and fail without proceeding to
2644                 # volume api calls, preserving current behavior
2645                 if try_deallocate_networks:
2646                     self._try_deallocate_network(context, instance,
2647                                                  requested_networks)
2648 
2649         if try_deallocate_networks:
2650             self._try_deallocate_network(context, instance, requested_networks)
2651 
2652         timer.restart()
2653         for bdm in vol_bdms:
2654             try:
2655                 if bdm.attachment_id:
2656                     self.volume_api.attachment_delete(context,
2657                                                       bdm.attachment_id)
2658                 else:
2659                     # NOTE(vish): actual driver detach done in driver.destroy,
2660                     #             so just tell cinder that we are done with it.
2661                     connector = self.driver.get_volume_connector(instance)
2662                     self.volume_api.terminate_connection(context,
2663                                                          bdm.volume_id,
2664                                                          connector)
2665                     self.volume_api.detach(context, bdm.volume_id,
2666                                            instance.uuid)
2667 
2668             except exception.VolumeAttachmentNotFound as exc:
2669                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2670                           instance=instance)
2671             except exception.DiskNotFound as exc:
2672                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2673                           instance=instance)
2674             except exception.VolumeNotFound as exc:
2675                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2676                           instance=instance)
2677             except (cinder_exception.EndpointNotFound,
2678                     keystone_exception.EndpointNotFound) as exc:
2679                 LOG.warning('Ignoring EndpointNotFound for '
2680                             'volume %(volume_id)s: %(exc)s',
2681                             {'exc': exc, 'volume_id': bdm.volume_id},
2682                             instance=instance)
2683             except cinder_exception.ClientException as exc:
2684                 LOG.warning('Ignoring unknown cinder exception for '
2685                             'volume %(volume_id)s: %(exc)s',
2686                             {'exc': exc, 'volume_id': bdm.volume_id},
2687                             instance=instance)
2688             except Exception as exc:
2689                 LOG.warning('Ignoring unknown exception for '
2690                             'volume %(volume_id)s: %(exc)s',
2691                             {'exc': exc, 'volume_id': bdm.volume_id},
2692                             instance=instance)
2693         if vol_bdms:
2694             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2695                      'for instance.',
2696                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2697                      instance=instance)
2698 
2699         if notify:
2700             self._notify_about_instance_usage(context, instance,
2701                                               "shutdown.end")
2702             compute_utils.notify_about_instance_action(context, instance,
2703                     self.host, action=fields.NotificationAction.SHUTDOWN,
2704                     phase=fields.NotificationPhase.END, bdms=bdms)
2705 
2706     def _cleanup_volumes(self, context, instance, bdms, raise_exc=True,
2707                          detach=True):
2708         exc_info = None
2709         for bdm in bdms:
2710             if detach and bdm.volume_id:
2711                 try:
2712                     LOG.debug("Detaching volume: %s", bdm.volume_id,
2713                               instance_uuid=instance.uuid)
2714                     destroy = bdm.delete_on_termination
2715                     self._detach_volume(context, bdm, instance,
2716                                         destroy_bdm=destroy)
2717                 except Exception as exc:
2718                     exc_info = sys.exc_info()
2719                     LOG.warning('Failed to detach volume: %(volume_id)s '
2720                                 'due to %(exc)s',
2721                                 {'volume_id': bdm.volume_id, 'exc': exc})
2722 
2723             if bdm.volume_id and bdm.delete_on_termination:
2724                 try:
2725                     LOG.debug("Deleting volume: %s", bdm.volume_id,
2726                               instance_uuid=instance.uuid)
2727                     self.volume_api.delete(context, bdm.volume_id)
2728                 except Exception as exc:
2729                     exc_info = sys.exc_info()
2730                     LOG.warning('Failed to delete volume: %(volume_id)s '
2731                                 'due to %(exc)s',
2732                                 {'volume_id': bdm.volume_id, 'exc': exc})
2733         if exc_info is not None and raise_exc:
2734             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2735 
2736     @hooks.add_hook("delete_instance")
2737     def _delete_instance(self, context, instance, bdms):
2738         """Delete an instance on this host.
2739 
2740         :param context: nova request context
2741         :param instance: nova.objects.instance.Instance object
2742         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2743         """
2744         events = self.instance_events.clear_events_for_instance(instance)
2745         if events:
2746             LOG.debug('Events pending at deletion: %(events)s',
2747                       {'events': ','.join(events.keys())},
2748                       instance=instance)
2749         self._notify_about_instance_usage(context, instance,
2750                                           "delete.start")
2751         compute_utils.notify_about_instance_action(context, instance,
2752                 self.host, action=fields.NotificationAction.DELETE,
2753                 phase=fields.NotificationPhase.START, bdms=bdms)
2754 
2755         self._shutdown_instance(context, instance, bdms)
2756 
2757         # NOTE(vish): We have already deleted the instance, so we have
2758         #             to ignore problems cleaning up the volumes. It
2759         #             would be nice to let the user know somehow that
2760         #             the volume deletion failed, but it is not
2761         #             acceptable to have an instance that can not be
2762         #             deleted. Perhaps this could be reworked in the
2763         #             future to set an instance fault the first time
2764         #             and to only ignore the failure if the instance
2765         #             is already in ERROR.
2766 
2767         # NOTE(ameeda): The volumes already detached during the above
2768         #               _shutdown_instance() call and this is why
2769         #               detach is not requested from _cleanup_volumes()
2770         #               in this case
2771 
2772         self._cleanup_volumes(context, instance, bdms,
2773                 raise_exc=False, detach=False)
2774         # if a delete task succeeded, always update vm state and task
2775         # state without expecting task state to be DELETING
2776         instance.vm_state = vm_states.DELETED
2777         instance.task_state = None
2778         instance.power_state = power_state.NOSTATE
2779         instance.terminated_at = timeutils.utcnow()
2780         instance.save()
2781 
2782         self._complete_deletion(context, instance)
2783         # only destroy the instance in the db if the _complete_deletion
2784         # doesn't raise and therefore allocation is successfully
2785         # deleted in placement
2786         instance.destroy()
2787 
2788         self._notify_about_instance_usage(context, instance, "delete.end")
2789         compute_utils.notify_about_instance_action(context, instance,
2790                 self.host, action=fields.NotificationAction.DELETE,
2791                 phase=fields.NotificationPhase.END, bdms=bdms)
2792 
2793     @wrap_exception()
2794     @reverts_task_state
2795     @wrap_instance_event(prefix='compute')
2796     @wrap_instance_fault
2797     def terminate_instance(self, context, instance, bdms):
2798         """Terminate an instance on this host."""
2799         @utils.synchronized(instance.uuid)
2800         def do_terminate_instance(instance, bdms):
2801             # NOTE(mriedem): If we are deleting the instance while it was
2802             # booting from volume, we could be racing with a database update of
2803             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2804             # to compute here, the BDMs may be stale at this point. So check
2805             # for any volume BDMs that don't have volume_id set and if we
2806             # detect that, we need to refresh the BDM list before proceeding.
2807             # TODO(mriedem): Move this into _delete_instance and make the bdms
2808             # parameter optional.
2809             for bdm in list(bdms):
2810                 if bdm.is_volume and not bdm.volume_id:
2811                     LOG.debug('There are potentially stale BDMs during '
2812                               'delete, refreshing the BlockDeviceMappingList.',
2813                               instance=instance)
2814                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2815                         context, instance.uuid)
2816                     break
2817             try:
2818                 self._delete_instance(context, instance, bdms)
2819             except exception.InstanceNotFound:
2820                 LOG.info("Instance disappeared during terminate",
2821                          instance=instance)
2822             except Exception:
2823                 # As we're trying to delete always go to Error if something
2824                 # goes wrong that _delete_instance can't handle.
2825                 with excutils.save_and_reraise_exception():
2826                     LOG.exception('Setting instance vm_state to ERROR',
2827                                   instance=instance)
2828                     self._set_instance_obj_error_state(context, instance)
2829 
2830         do_terminate_instance(instance, bdms)
2831 
2832     # NOTE(johannes): This is probably better named power_off_instance
2833     # so it matches the driver method, but because of other issues, we
2834     # can't use that name in grizzly.
2835     @wrap_exception()
2836     @reverts_task_state
2837     @wrap_instance_event(prefix='compute')
2838     @wrap_instance_fault
2839     def stop_instance(self, context, instance, clean_shutdown):
2840         """Stopping an instance on this host."""
2841 
2842         @utils.synchronized(instance.uuid)
2843         def do_stop_instance():
2844             current_power_state = self._get_power_state(context, instance)
2845             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2846                       'current task_state: %(task_state)s, current DB '
2847                       'power_state: %(db_power_state)s, current VM '
2848                       'power_state: %(current_power_state)s',
2849                       {'vm_state': instance.vm_state,
2850                        'task_state': instance.task_state,
2851                        'db_power_state': instance.power_state,
2852                        'current_power_state': current_power_state},
2853                       instance_uuid=instance.uuid)
2854 
2855             # NOTE(mriedem): If the instance is already powered off, we are
2856             # possibly tearing down and racing with other operations, so we can
2857             # expect the task_state to be None if something else updates the
2858             # instance and we're not locking it.
2859             expected_task_state = [task_states.POWERING_OFF]
2860             # The list of power states is from _sync_instance_power_state.
2861             if current_power_state in (power_state.NOSTATE,
2862                                        power_state.SHUTDOWN,
2863                                        power_state.CRASHED):
2864                 LOG.info('Instance is already powered off in the '
2865                          'hypervisor when stop is called.',
2866                          instance=instance)
2867                 expected_task_state.append(None)
2868 
2869             self._notify_about_instance_usage(context, instance,
2870                                               "power_off.start")
2871 
2872             compute_utils.notify_about_instance_action(context, instance,
2873                         self.host, action=fields.NotificationAction.POWER_OFF,
2874                         phase=fields.NotificationPhase.START)
2875 
2876             self._power_off_instance(context, instance, clean_shutdown)
2877             instance.power_state = self._get_power_state(context, instance)
2878             instance.vm_state = vm_states.STOPPED
2879             instance.task_state = None
2880             instance.save(expected_task_state=expected_task_state)
2881             self._notify_about_instance_usage(context, instance,
2882                                               "power_off.end")
2883 
2884             compute_utils.notify_about_instance_action(context, instance,
2885                         self.host, action=fields.NotificationAction.POWER_OFF,
2886                         phase=fields.NotificationPhase.END)
2887 
2888         do_stop_instance()
2889 
2890     def _power_on(self, context, instance):
2891         network_info = self.network_api.get_instance_nw_info(context, instance)
2892         block_device_info = self._get_instance_block_device_info(context,
2893                                                                  instance)
2894         self.driver.power_on(context, instance,
2895                              network_info,
2896                              block_device_info)
2897 
2898     def _delete_snapshot_of_shelved_instance(self, context, instance,
2899                                              snapshot_id):
2900         """Delete snapshot of shelved instance."""
2901         try:
2902             self.image_api.delete(context, snapshot_id)
2903         except (exception.ImageNotFound,
2904                 exception.ImageNotAuthorized) as exc:
2905             LOG.warning("Failed to delete snapshot "
2906                         "from shelved instance (%s).",
2907                         exc.format_message(), instance=instance)
2908         except Exception:
2909             LOG.exception("Something wrong happened when trying to "
2910                           "delete snapshot from shelved instance.",
2911                           instance=instance)
2912 
2913     # NOTE(johannes): This is probably better named power_on_instance
2914     # so it matches the driver method, but because of other issues, we
2915     # can't use that name in grizzly.
2916     @wrap_exception()
2917     @reverts_task_state
2918     @wrap_instance_event(prefix='compute')
2919     @wrap_instance_fault
2920     def start_instance(self, context, instance):
2921         """Starting an instance on this host."""
2922         self._notify_about_instance_usage(context, instance, "power_on.start")
2923         compute_utils.notify_about_instance_action(context, instance,
2924             self.host, action=fields.NotificationAction.POWER_ON,
2925             phase=fields.NotificationPhase.START)
2926         self._power_on(context, instance)
2927         instance.power_state = self._get_power_state(context, instance)
2928         instance.vm_state = vm_states.ACTIVE
2929         instance.task_state = None
2930 
2931         # Delete an image(VM snapshot) for a shelved instance
2932         snapshot_id = instance.system_metadata.get('shelved_image_id')
2933         if snapshot_id:
2934             self._delete_snapshot_of_shelved_instance(context, instance,
2935                                                       snapshot_id)
2936 
2937         # Delete system_metadata for a shelved instance
2938         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2939 
2940         instance.save(expected_task_state=task_states.POWERING_ON)
2941         self._notify_about_instance_usage(context, instance, "power_on.end")
2942         compute_utils.notify_about_instance_action(context, instance,
2943             self.host, action=fields.NotificationAction.POWER_ON,
2944             phase=fields.NotificationPhase.END)
2945 
2946     @messaging.expected_exceptions(NotImplementedError,
2947                                    exception.TriggerCrashDumpNotSupported,
2948                                    exception.InstanceNotRunning)
2949     @wrap_exception()
2950     @wrap_instance_event(prefix='compute')
2951     @wrap_instance_fault
2952     def trigger_crash_dump(self, context, instance):
2953         """Trigger crash dump in an instance."""
2954 
2955         self._notify_about_instance_usage(context, instance,
2956                                           "trigger_crash_dump.start")
2957         compute_utils.notify_about_instance_action(context, instance,
2958                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2959                 phase=fields.NotificationPhase.START)
2960 
2961         # This method does not change task_state and power_state because the
2962         # effect of a trigger depends on user's configuration.
2963         self.driver.trigger_crash_dump(instance)
2964 
2965         self._notify_about_instance_usage(context, instance,
2966                                           "trigger_crash_dump.end")
2967         compute_utils.notify_about_instance_action(context, instance,
2968                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2969                 phase=fields.NotificationPhase.END)
2970 
2971     @wrap_exception()
2972     @reverts_task_state
2973     @wrap_instance_event(prefix='compute')
2974     @wrap_instance_fault
2975     def soft_delete_instance(self, context, instance):
2976         """Soft delete an instance on this host."""
2977         with compute_utils.notify_about_instance_delete(
2978                 self.notifier, context, instance, 'soft_delete',
2979                 source=fields.NotificationSource.COMPUTE):
2980             try:
2981                 self.driver.soft_delete(instance)
2982             except NotImplementedError:
2983                 # Fallback to just powering off the instance if the
2984                 # hypervisor doesn't implement the soft_delete method
2985                 self.driver.power_off(instance)
2986             instance.power_state = self._get_power_state(context, instance)
2987             instance.vm_state = vm_states.SOFT_DELETED
2988             instance.task_state = None
2989             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2990 
2991     @wrap_exception()
2992     @reverts_task_state
2993     @wrap_instance_event(prefix='compute')
2994     @wrap_instance_fault
2995     def restore_instance(self, context, instance):
2996         """Restore a soft-deleted instance on this host."""
2997         self._notify_about_instance_usage(context, instance, "restore.start")
2998         compute_utils.notify_about_instance_action(context, instance,
2999             self.host, action=fields.NotificationAction.RESTORE,
3000             phase=fields.NotificationPhase.START)
3001         try:
3002             self.driver.restore(instance)
3003         except NotImplementedError:
3004             # Fallback to just powering on the instance if the hypervisor
3005             # doesn't implement the restore method
3006             self._power_on(context, instance)
3007         instance.power_state = self._get_power_state(context, instance)
3008         instance.vm_state = vm_states.ACTIVE
3009         instance.task_state = None
3010         instance.save(expected_task_state=task_states.RESTORING)
3011         self._notify_about_instance_usage(context, instance, "restore.end")
3012         compute_utils.notify_about_instance_action(context, instance,
3013             self.host, action=fields.NotificationAction.RESTORE,
3014             phase=fields.NotificationPhase.END)
3015 
3016     @staticmethod
3017     def _set_migration_status(migration, status):
3018         """Set the status, and guard against a None being passed in.
3019 
3020         This is useful as some of the compute RPC calls will not pass
3021         a migration object in older versions. The check can be removed when
3022         we move past 4.x major version of the RPC API.
3023         """
3024         if migration:
3025             migration.status = status
3026             migration.save()
3027 
3028     def _rebuild_default_impl(self, context, instance, image_meta,
3029                               injected_files, admin_password, allocations,
3030                               bdms, detach_block_devices, attach_block_devices,
3031                               network_info=None,
3032                               evacuate=False, block_device_info=None,
3033                               preserve_ephemeral=False):
3034         if preserve_ephemeral:
3035             # The default code path does not support preserving ephemeral
3036             # partitions.
3037             raise exception.PreserveEphemeralNotSupported()
3038 
3039         if evacuate:
3040             detach_block_devices(context, bdms)
3041         else:
3042             self._power_off_instance(context, instance, clean_shutdown=True)
3043             detach_block_devices(context, bdms)
3044             self.driver.destroy(context, instance,
3045                                 network_info=network_info,
3046                                 block_device_info=block_device_info)
3047 
3048         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
3049         instance.save(expected_task_state=[task_states.REBUILDING])
3050 
3051         new_block_device_info = attach_block_devices(context, instance, bdms)
3052 
3053         instance.task_state = task_states.REBUILD_SPAWNING
3054         instance.save(
3055             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
3056 
3057         with instance.mutated_migration_context():
3058             self.driver.spawn(context, instance, image_meta, injected_files,
3059                               admin_password, allocations,
3060                               network_info=network_info,
3061                               block_device_info=new_block_device_info)
3062 
3063     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
3064         tb = traceback.format_exc()
3065         self._notify_about_instance_usage(context, instance,
3066                                           'rebuild.error', fault=error)
3067         compute_utils.notify_about_instance_rebuild(
3068             context, instance, self.host,
3069             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms,
3070             tb=tb)
3071 
3072     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
3073     @wrap_exception()
3074     @reverts_task_state
3075     @wrap_instance_event(prefix='compute')
3076     @wrap_instance_fault
3077     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
3078                          injected_files, new_pass, orig_sys_metadata,
3079                          bdms, recreate, on_shared_storage,
3080                          preserve_ephemeral, migration,
3081                          scheduled_node, limits, request_spec):
3082         """Destroy and re-make this instance.
3083 
3084         A 'rebuild' effectively purges all existing data from the system and
3085         remakes the VM with given 'metadata' and 'personalities'.
3086 
3087         :param context: `nova.RequestContext` object
3088         :param instance: Instance object
3089         :param orig_image_ref: Original image_ref before rebuild
3090         :param image_ref: New image_ref for rebuild
3091         :param injected_files: Files to inject
3092         :param new_pass: password to set on rebuilt instance
3093         :param orig_sys_metadata: instance system metadata from pre-rebuild
3094         :param bdms: block-device-mappings to use for rebuild
3095         :param recreate: True if the instance is being recreated (e.g. the
3096             hypervisor it was on failed) - cleanup of old state will be
3097             skipped.
3098         :param on_shared_storage: True if instance files on shared storage.
3099                                   If not provided then information from the
3100                                   driver will be used to decide if the instance
3101                                   files are available or not on the target host
3102         :param preserve_ephemeral: True if the default ephemeral storage
3103                                    partition must be preserved on rebuild
3104         :param migration: a Migration object if one was created for this
3105                           rebuild operation (if it's a part of evacuate)
3106         :param scheduled_node: A node of the host chosen by the scheduler. If a
3107                                host was specified by the user, this will be
3108                                None
3109         :param limits: Overcommit limits set by the scheduler. If a host was
3110                        specified by the user, this will be None
3111         :param request_spec: a RequestSpec object used to schedule the instance
3112 
3113         """
3114         # recreate=True means the instance is being evacuated from a failed
3115         # host to a new destination host (this host). The 'recreate' variable
3116         # name is confusing, so rename it to evacuate here at the top, which
3117         # is simpler than renaming a parameter in an RPC versioned method.
3118         evacuate = recreate
3119         context = context.elevated()
3120 
3121         if evacuate:
3122             LOG.info("Evacuating instance", instance=instance)
3123         else:
3124             LOG.info("Rebuilding instance", instance=instance)
3125 
3126         if evacuate:
3127             # This is an evacuation to a new host, so we need to perform a
3128             # resource claim.
3129             rebuild_claim = self.rt.rebuild_claim
3130         else:
3131             # This is a rebuild to the same host, so we don't need to make
3132             # a claim since the instance is already on this host.
3133             rebuild_claim = claims.NopClaim
3134 
3135         if image_ref:
3136             image_meta = objects.ImageMeta.from_image_ref(
3137                 context, self.image_api, image_ref)
3138         elif evacuate:
3139             # For evacuate the API does not send down the image_ref since the
3140             # image does not change so just get it from what was stashed in
3141             # the instance system_metadata when the instance was created (or
3142             # last rebuilt). This also works for volume-backed instances.
3143             image_meta = instance.image_meta
3144         else:
3145             image_meta = objects.ImageMeta()
3146 
3147         # NOTE(mriedem): On an evacuate, we need to update
3148         # the instance's host and node properties to reflect it's
3149         # destination node for the evacuate.
3150         if not scheduled_node:
3151             if evacuate:
3152                 try:
3153                     compute_node = self._get_compute_info(context, self.host)
3154                     scheduled_node = compute_node.hypervisor_hostname
3155                 except exception.ComputeHostNotFound:
3156                     LOG.exception('Failed to get compute_info for %s',
3157                                   self.host)
3158             else:
3159                 scheduled_node = instance.node
3160 
3161         with self._error_out_instance_on_exception(context, instance):
3162             try:
3163                 claim_ctxt = rebuild_claim(
3164                     context, instance, scheduled_node,
3165                     limits=limits, image_meta=image_meta,
3166                     migration=migration)
3167                 self._do_rebuild_instance_with_claim(
3168                     claim_ctxt, context, instance, orig_image_ref,
3169                     image_meta, injected_files, new_pass, orig_sys_metadata,
3170                     bdms, evacuate, on_shared_storage, preserve_ephemeral,
3171                     migration, request_spec)
3172             except (exception.ComputeResourcesUnavailable,
3173                     exception.RescheduledException) as e:
3174                 if isinstance(e, exception.ComputeResourcesUnavailable):
3175                     LOG.debug("Could not rebuild instance on this host, not "
3176                               "enough resources available.", instance=instance)
3177                 else:
3178                     # RescheduledException is raised by the late server group
3179                     # policy check during evacuation if a parallel scheduling
3180                     # violated the policy.
3181                     # We catch the RescheduledException here but we don't have
3182                     # the plumbing to do an actual reschedule so we abort the
3183                     # operation.
3184                     LOG.debug("Could not rebuild instance on this host, "
3185                               "late server group check failed.",
3186                               instance=instance)
3187                 # NOTE(ndipanov): We just abort the build for now and leave a
3188                 # migration record for potential cleanup later
3189                 self._set_migration_status(migration, 'failed')
3190                 # Since the claim failed, we need to remove the allocation
3191                 # created against the destination node. Note that we can only
3192                 # get here when evacuating to a destination node. Rebuilding
3193                 # on the same host (not evacuate) uses the NopClaim which will
3194                 # not raise ComputeResourcesUnavailable.
3195                 self.rt.delete_allocation_for_evacuated_instance(
3196                     context, instance, scheduled_node, node_type='destination')
3197                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3198                 raise exception.BuildAbortException(
3199                     instance_uuid=instance.uuid, reason=e.format_message())
3200             except (exception.InstanceNotFound,
3201                     exception.UnexpectedDeletingTaskStateError) as e:
3202                 LOG.debug('Instance was deleted while rebuilding',
3203                           instance=instance)
3204                 self._set_migration_status(migration, 'failed')
3205                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3206             except Exception as e:
3207                 self._set_migration_status(migration, 'failed')
3208                 if evacuate or scheduled_node is not None:
3209                     self.rt.delete_allocation_for_evacuated_instance(
3210                         context, instance, scheduled_node,
3211                         node_type='destination')
3212                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3213                 raise
3214             else:
3215                 instance.apply_migration_context()
3216                 # NOTE (ndipanov): This save will now update the host and node
3217                 # attributes making sure that next RT pass is consistent since
3218                 # it will be based on the instance and not the migration DB
3219                 # entry.
3220                 instance.host = self.host
3221                 instance.node = scheduled_node
3222                 instance.save()
3223                 instance.drop_migration_context()
3224 
3225                 # NOTE (ndipanov): Mark the migration as done only after we
3226                 # mark the instance as belonging to this host.
3227                 self._set_migration_status(migration, 'done')
3228 
3229     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
3230         """Helper to avoid deep nesting in the top-level method."""
3231 
3232         with claim_context:
3233             self._do_rebuild_instance(*args, **kwargs)
3234 
3235     @staticmethod
3236     def _get_image_name(image_meta):
3237         if image_meta.obj_attr_is_set("name"):
3238             return image_meta.name
3239         else:
3240             return ''
3241 
3242     def _do_rebuild_instance(self, context, instance, orig_image_ref,
3243                              image_meta, injected_files, new_pass,
3244                              orig_sys_metadata, bdms, evacuate,
3245                              on_shared_storage, preserve_ephemeral,
3246                              migration, request_spec):
3247         orig_vm_state = instance.vm_state
3248 
3249         if evacuate:
3250             if request_spec:
3251                 # NOTE(gibi): Do a late check of server group policy as
3252                 # parallel scheduling could violate such policy. This will
3253                 # cause the evacuate to fail as rebuild does not implement
3254                 # reschedule.
3255                 hints = self._get_scheduler_hints({}, request_spec)
3256                 self._validate_instance_group_policy(context, instance, hints)
3257 
3258             if not self.driver.capabilities.get("supports_evacuate", False):
3259                 raise exception.InstanceEvacuateNotSupported
3260 
3261             self._check_instance_exists(context, instance)
3262 
3263             if on_shared_storage is None:
3264                 LOG.debug('on_shared_storage is not provided, using driver '
3265                           'information to decide if the instance needs to '
3266                           'be evacuated')
3267                 on_shared_storage = self.driver.instance_on_disk(instance)
3268 
3269             elif (on_shared_storage !=
3270                     self.driver.instance_on_disk(instance)):
3271                 # To cover case when admin expects that instance files are
3272                 # on shared storage, but not accessible and vice versa
3273                 raise exception.InvalidSharedStorage(
3274                         _("Invalid state of instance files on shared"
3275                             " storage"))
3276 
3277             if on_shared_storage:
3278                 LOG.info('disk on shared storage, evacuating using'
3279                          ' existing disk')
3280             elif instance.image_ref:
3281                 orig_image_ref = instance.image_ref
3282                 LOG.info("disk not on shared storage, evacuating from "
3283                          "image: '%s'", str(orig_image_ref))
3284             else:
3285                 LOG.info('disk on volume, evacuating using existing '
3286                          'volume')
3287 
3288         # We check trusted certs capabilities for both evacuate (rebuild on
3289         # another host) and rebuild (rebuild on the same host) because for
3290         # evacuate we need to make sure an instance with trusted certs can
3291         # have the image verified with those certs during rebuild, and for
3292         # rebuild we could be rebuilding a server that started out with no
3293         # trusted certs on this host, and then was rebuilt with trusted certs
3294         # for a new image, in which case we need to validate that new image
3295         # with the trusted certs during the rebuild.
3296         self._check_trusted_certs(instance)
3297 
3298         # This instance.exists message should contain the original
3299         # image_ref, not the new one.  Since the DB has been updated
3300         # to point to the new one... we have to override it.
3301         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
3302                                                                context)
3303         extra_usage_info = {'image_ref_url': orig_image_ref_url}
3304         compute_utils.notify_usage_exists(
3305                 self.notifier, context, instance, self.host,
3306                 current_period=True, system_metadata=orig_sys_metadata,
3307                 extra_usage_info=extra_usage_info)
3308 
3309         # This message should contain the new image_ref
3310         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
3311         self._notify_about_instance_usage(context, instance,
3312                 "rebuild.start", extra_usage_info=extra_usage_info)
3313         # NOTE: image_name is not included in the versioned notification
3314         # because we already provide the image_uuid in the notification
3315         # payload and the image details can be looked up via the uuid.
3316         compute_utils.notify_about_instance_rebuild(
3317             context, instance, self.host,
3318             phase=fields.NotificationPhase.START,
3319             bdms=bdms)
3320 
3321         instance.power_state = self._get_power_state(context, instance)
3322         instance.task_state = task_states.REBUILDING
3323         instance.save(expected_task_state=[task_states.REBUILDING])
3324 
3325         if evacuate:
3326             self.network_api.setup_networks_on_host(
3327                     context, instance, self.host)
3328             # For nova-network this is needed to move floating IPs
3329             # For neutron this updates the host in the port binding
3330             # TODO(cfriesen): this network_api call and the one above
3331             # are so similar, we should really try to unify them.
3332             self.network_api.setup_instance_network_on_host(
3333                     context, instance, self.host, migration)
3334             # TODO(mriedem): Consider decorating setup_instance_network_on_host
3335             # with @base_api.refresh_cache and then we wouldn't need this
3336             # explicit call to get_instance_nw_info.
3337             network_info = self.network_api.get_instance_nw_info(context,
3338                                                                  instance)
3339         else:
3340             network_info = instance.get_network_info()
3341 
3342         allocations = self.reportclient.get_allocations_for_consumer(
3343             context, instance.uuid)
3344 
3345         if bdms is None:
3346             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3347                     context, instance.uuid)
3348 
3349         block_device_info = \
3350             self._get_instance_block_device_info(
3351                     context, instance, bdms=bdms)
3352 
3353         def detach_block_devices(context, bdms):
3354             for bdm in bdms:
3355                 if bdm.is_volume:
3356                     # NOTE (ildikov): Having the attachment_id set in the BDM
3357                     # means that it's the new Cinder attach/detach flow
3358                     # (available from v3.44). In that case we explicitly
3359                     # attach and detach the volumes through attachment level
3360                     # operations. In this scenario _detach_volume will delete
3361                     # the existing attachment which would make the volume
3362                     # status change to 'available' if we don't pre-create
3363                     # another empty attachment before deleting the old one.
3364                     attachment_id = None
3365                     if bdm.attachment_id:
3366                         attachment_id = self.volume_api.attachment_create(
3367                             context, bdm['volume_id'], instance.uuid)['id']
3368                     self._detach_volume(context, bdm, instance,
3369                                         destroy_bdm=False)
3370                     if attachment_id:
3371                         bdm.attachment_id = attachment_id
3372                         bdm.save()
3373 
3374         files = self._decode_files(injected_files)
3375 
3376         kwargs = dict(
3377             context=context,
3378             instance=instance,
3379             image_meta=image_meta,
3380             injected_files=files,
3381             admin_password=new_pass,
3382             allocations=allocations,
3383             bdms=bdms,
3384             detach_block_devices=detach_block_devices,
3385             attach_block_devices=self._prep_block_device,
3386             block_device_info=block_device_info,
3387             network_info=network_info,
3388             preserve_ephemeral=preserve_ephemeral,
3389             evacuate=evacuate)
3390         try:
3391             with instance.mutated_migration_context():
3392                 self.driver.rebuild(**kwargs)
3393         except NotImplementedError:
3394             # NOTE(rpodolyaka): driver doesn't provide specialized version
3395             # of rebuild, fall back to the default implementation
3396             self._rebuild_default_impl(**kwargs)
3397         self._update_instance_after_spawn(context, instance)
3398         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3399 
3400         if orig_vm_state == vm_states.STOPPED:
3401             LOG.info("bringing vm to original state: '%s'",
3402                      orig_vm_state, instance=instance)
3403             instance.vm_state = vm_states.ACTIVE
3404             instance.task_state = task_states.POWERING_OFF
3405             instance.progress = 0
3406             instance.save()
3407             self.stop_instance(context, instance, False)
3408         # TODO(melwitt): We should clean up instance console tokens here in the
3409         # case of evacuate. The instance is on a new host and will need to
3410         # establish a new console connection.
3411         self._update_scheduler_instance_info(context, instance)
3412         self._notify_about_instance_usage(
3413                 context, instance, "rebuild.end",
3414                 network_info=network_info,
3415                 extra_usage_info=extra_usage_info)
3416         compute_utils.notify_about_instance_rebuild(
3417             context, instance, self.host,
3418             phase=fields.NotificationPhase.END,
3419             bdms=bdms)
3420 
3421     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3422                                      block_device_info):
3423         """Handle cases where the virt-layer had to detach non-working volumes
3424         in order to complete an operation.
3425         """
3426         for bdm in block_device_info['block_device_mapping']:
3427             if bdm.get('mount_device') in bad_devices:
3428                 try:
3429                     volume_id = bdm['connection_info']['data']['volume_id']
3430                 except KeyError:
3431                     continue
3432 
3433                 # NOTE(sirp): ideally we'd just call
3434                 # `compute_api.detach_volume` here but since that hits the
3435                 # DB directly, that's off limits from within the
3436                 # compute-manager.
3437                 #
3438                 # API-detach
3439                 LOG.info("Detaching from volume api: %s", volume_id)
3440                 self.volume_api.begin_detaching(context, volume_id)
3441 
3442                 # Manager-detach
3443                 self.detach_volume(context, volume_id, instance)
3444 
3445     @wrap_exception()
3446     @reverts_task_state
3447     @wrap_instance_event(prefix='compute')
3448     @wrap_instance_fault
3449     def reboot_instance(self, context, instance, block_device_info,
3450                         reboot_type):
3451         """Reboot an instance on this host."""
3452         # acknowledge the request made it to the manager
3453         if reboot_type == "SOFT":
3454             instance.task_state = task_states.REBOOT_PENDING
3455             expected_states = task_states.soft_reboot_states
3456         else:
3457             instance.task_state = task_states.REBOOT_PENDING_HARD
3458             expected_states = task_states.hard_reboot_states
3459 
3460         context = context.elevated()
3461         LOG.info("Rebooting instance", instance=instance)
3462 
3463         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3464             context, instance.uuid)
3465         block_device_info = self._get_instance_block_device_info(
3466             context, instance, bdms=bdms)
3467 
3468         network_info = self.network_api.get_instance_nw_info(context, instance)
3469 
3470         self._notify_about_instance_usage(context, instance, "reboot.start")
3471         compute_utils.notify_about_instance_action(
3472             context, instance, self.host,
3473             action=fields.NotificationAction.REBOOT,
3474             phase=fields.NotificationPhase.START,
3475             bdms=bdms
3476         )
3477 
3478         instance.power_state = self._get_power_state(context, instance)
3479         instance.save(expected_task_state=expected_states)
3480 
3481         if instance.power_state != power_state.RUNNING:
3482             state = instance.power_state
3483             running = power_state.RUNNING
3484             LOG.warning('trying to reboot a non-running instance:'
3485                         ' (state: %(state)s expected: %(running)s)',
3486                         {'state': state, 'running': running},
3487                         instance=instance)
3488 
3489         def bad_volumes_callback(bad_devices):
3490             self._handle_bad_volumes_detached(
3491                     context, instance, bad_devices, block_device_info)
3492 
3493         try:
3494             # Don't change it out of rescue mode
3495             if instance.vm_state == vm_states.RESCUED:
3496                 new_vm_state = vm_states.RESCUED
3497             else:
3498                 new_vm_state = vm_states.ACTIVE
3499             new_power_state = None
3500             if reboot_type == "SOFT":
3501                 instance.task_state = task_states.REBOOT_STARTED
3502                 expected_state = task_states.REBOOT_PENDING
3503             else:
3504                 instance.task_state = task_states.REBOOT_STARTED_HARD
3505                 expected_state = task_states.REBOOT_PENDING_HARD
3506             instance.save(expected_task_state=expected_state)
3507             self.driver.reboot(context, instance,
3508                                network_info,
3509                                reboot_type,
3510                                block_device_info=block_device_info,
3511                                bad_volumes_callback=bad_volumes_callback)
3512 
3513         except Exception as error:
3514             with excutils.save_and_reraise_exception() as ctxt:
3515                 exc_info = sys.exc_info()
3516                 # if the reboot failed but the VM is running don't
3517                 # put it into an error state
3518                 new_power_state = self._get_power_state(context, instance)
3519                 if new_power_state == power_state.RUNNING:
3520                     LOG.warning('Reboot failed but instance is running',
3521                                 instance=instance)
3522                     compute_utils.add_instance_fault_from_exc(context,
3523                             instance, error, exc_info)
3524                     self._notify_about_instance_usage(context, instance,
3525                             'reboot.error', fault=error)
3526                     tb = traceback.format_exc()
3527                     compute_utils.notify_about_instance_action(
3528                         context, instance, self.host,
3529                         action=fields.NotificationAction.REBOOT,
3530                         phase=fields.NotificationPhase.ERROR,
3531                         exception=error, bdms=bdms, tb=tb
3532                     )
3533                     ctxt.reraise = False
3534                 else:
3535                     LOG.error('Cannot reboot instance: %s', error,
3536                               instance=instance)
3537                     self._set_instance_obj_error_state(context, instance)
3538 
3539         if not new_power_state:
3540             new_power_state = self._get_power_state(context, instance)
3541         try:
3542             instance.power_state = new_power_state
3543             instance.vm_state = new_vm_state
3544             instance.task_state = None
3545             instance.save()
3546         except exception.InstanceNotFound:
3547             LOG.warning("Instance disappeared during reboot",
3548                         instance=instance)
3549 
3550         self._notify_about_instance_usage(context, instance, "reboot.end")
3551         compute_utils.notify_about_instance_action(
3552             context, instance, self.host,
3553             action=fields.NotificationAction.REBOOT,
3554             phase=fields.NotificationPhase.END,
3555             bdms=bdms
3556         )
3557 
3558     @delete_image_on_error
3559     def _do_snapshot_instance(self, context, image_id, instance):
3560         self._snapshot_instance(context, image_id, instance,
3561                                 task_states.IMAGE_BACKUP)
3562 
3563     @wrap_exception()
3564     @reverts_task_state
3565     @wrap_instance_event(prefix='compute')
3566     @wrap_instance_fault
3567     def backup_instance(self, context, image_id, instance, backup_type,
3568                         rotation):
3569         """Backup an instance on this host.
3570 
3571         :param backup_type: daily | weekly
3572         :param rotation: int representing how many backups to keep around
3573         """
3574         self._do_snapshot_instance(context, image_id, instance)
3575         self._rotate_backups(context, instance, backup_type, rotation)
3576 
3577     @wrap_exception()
3578     @reverts_task_state
3579     @wrap_instance_event(prefix='compute')
3580     @wrap_instance_fault
3581     @delete_image_on_error
3582     def snapshot_instance(self, context, image_id, instance):
3583         """Snapshot an instance on this host.
3584 
3585         :param context: security context
3586         :param image_id: glance.db.sqlalchemy.models.Image.Id
3587         :param instance: a nova.objects.instance.Instance object
3588         """
3589         # NOTE(dave-mcnally) the task state will already be set by the api
3590         # but if the compute manager has crashed/been restarted prior to the
3591         # request getting here the task state may have been cleared so we set
3592         # it again and things continue normally
3593         try:
3594             instance.task_state = task_states.IMAGE_SNAPSHOT
3595             instance.save(
3596                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3597         except exception.InstanceNotFound:
3598             # possibility instance no longer exists, no point in continuing
3599             LOG.debug("Instance not found, could not set state %s "
3600                       "for instance.",
3601                       task_states.IMAGE_SNAPSHOT, instance=instance)
3602             return
3603 
3604         except exception.UnexpectedDeletingTaskStateError:
3605             LOG.debug("Instance being deleted, snapshot cannot continue",
3606                       instance=instance)
3607             return
3608 
3609         self._snapshot_instance(context, image_id, instance,
3610                                 task_states.IMAGE_SNAPSHOT)
3611 
3612     def _snapshot_instance(self, context, image_id, instance,
3613                            expected_task_state):
3614         context = context.elevated()
3615 
3616         instance.power_state = self._get_power_state(context, instance)
3617         try:
3618             instance.save()
3619 
3620             LOG.info('instance snapshotting', instance=instance)
3621 
3622             if instance.power_state != power_state.RUNNING:
3623                 state = instance.power_state
3624                 running = power_state.RUNNING
3625                 LOG.warning('trying to snapshot a non-running instance: '
3626                             '(state: %(state)s expected: %(running)s)',
3627                             {'state': state, 'running': running},
3628                             instance=instance)
3629 
3630             self._notify_about_instance_usage(
3631                 context, instance, "snapshot.start")
3632             compute_utils.notify_about_instance_snapshot(context, instance,
3633                 self.host, phase=fields.NotificationPhase.START,
3634                 snapshot_image_id=image_id)
3635 
3636             def update_task_state(task_state,
3637                                   expected_state=expected_task_state):
3638                 instance.task_state = task_state
3639                 instance.save(expected_task_state=expected_state)
3640 
3641             with timeutils.StopWatch() as timer:
3642                 self.driver.snapshot(context, instance, image_id,
3643                                      update_task_state)
3644             LOG.info('Took %0.2f seconds to snapshot the instance on '
3645                      'the hypervisor.', timer.elapsed(), instance=instance)
3646 
3647             instance.task_state = None
3648             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3649 
3650             self._notify_about_instance_usage(context, instance,
3651                                               "snapshot.end")
3652             compute_utils.notify_about_instance_snapshot(context, instance,
3653                 self.host, phase=fields.NotificationPhase.END,
3654                 snapshot_image_id=image_id)
3655         except (exception.InstanceNotFound,
3656                 exception.UnexpectedDeletingTaskStateError):
3657             # the instance got deleted during the snapshot
3658             # Quickly bail out of here
3659             msg = 'Instance disappeared during snapshot'
3660             LOG.debug(msg, instance=instance)
3661             try:
3662                 image = self.image_api.get(context, image_id)
3663                 if image['status'] != 'active':
3664                     self.image_api.delete(context, image_id)
3665             except exception.ImageNotFound:
3666                 LOG.debug('Image not found during clean up %s', image_id)
3667             except Exception:
3668                 LOG.warning("Error while trying to clean up image %s",
3669                             image_id, instance=instance)
3670         except exception.ImageNotFound:
3671             instance.task_state = None
3672             instance.save()
3673             LOG.warning("Image not found during snapshot", instance=instance)
3674 
3675     def _post_interrupted_snapshot_cleanup(self, context, instance):
3676         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3677 
3678     @messaging.expected_exceptions(NotImplementedError)
3679     @wrap_exception()
3680     def volume_snapshot_create(self, context, instance, volume_id,
3681                                create_info):
3682         self.driver.volume_snapshot_create(context, instance, volume_id,
3683                                            create_info)
3684 
3685     @messaging.expected_exceptions(NotImplementedError)
3686     @wrap_exception()
3687     def volume_snapshot_delete(self, context, instance, volume_id,
3688                                snapshot_id, delete_info):
3689         self.driver.volume_snapshot_delete(context, instance, volume_id,
3690                                            snapshot_id, delete_info)
3691 
3692     @wrap_instance_fault
3693     def _rotate_backups(self, context, instance, backup_type, rotation):
3694         """Delete excess backups associated to an instance.
3695 
3696         Instances are allowed a fixed number of backups (the rotation number);
3697         this method deletes the oldest backups that exceed the rotation
3698         threshold.
3699 
3700         :param context: security context
3701         :param instance: Instance dict
3702         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3703         :param rotation: int representing how many backups to keep around;
3704             None if rotation shouldn't be used (as in the case of snapshots)
3705         """
3706         filters = {'property-image_type': 'backup',
3707                    'property-backup_type': backup_type,
3708                    'property-instance_uuid': instance.uuid}
3709 
3710         images = self.image_api.get_all(context, filters=filters,
3711                                         sort_key='created_at', sort_dir='desc')
3712         num_images = len(images)
3713         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3714                   {'num_images': num_images, 'rotation': rotation},
3715                   instance=instance)
3716 
3717         if num_images > rotation:
3718             # NOTE(sirp): this deletes all backups that exceed the rotation
3719             # limit
3720             excess = len(images) - rotation
3721             LOG.debug("Rotating out %d backups", excess,
3722                       instance=instance)
3723             for i in range(excess):
3724                 image = images.pop()
3725                 image_id = image['id']
3726                 LOG.debug("Deleting image %s", image_id,
3727                           instance=instance)
3728                 try:
3729                     self.image_api.delete(context, image_id)
3730                 except exception.ImageNotFound:
3731                     LOG.info("Failed to find image %(image_id)s to "
3732                              "delete", {'image_id': image_id},
3733                              instance=instance)
3734                 except (exception.ImageDeleteConflict, Exception) as exc:
3735                     LOG.info("Failed to delete image %(image_id)s during "
3736                              "deleting excess backups. "
3737                              "Continuing for next image.. %(exc)s",
3738                              {'image_id': image_id, 'exc': exc},
3739                              instance=instance)
3740 
3741     @wrap_exception()
3742     @reverts_task_state
3743     @wrap_instance_event(prefix='compute')
3744     @wrap_instance_fault
3745     def set_admin_password(self, context, instance, new_pass):
3746         """Set the root/admin password for an instance on this host.
3747 
3748         This is generally only called by API password resets after an
3749         image has been built.
3750 
3751         @param context: Nova auth context.
3752         @param instance: Nova instance object.
3753         @param new_pass: The admin password for the instance.
3754         """
3755 
3756         context = context.elevated()
3757         if new_pass is None:
3758             # Generate a random password
3759             new_pass = utils.generate_password()
3760 
3761         current_power_state = self._get_power_state(context, instance)
3762         expected_state = power_state.RUNNING
3763 
3764         if current_power_state != expected_state:
3765             instance.task_state = None
3766             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3767             _msg = _('instance %s is not running') % instance.uuid
3768             raise exception.InstancePasswordSetFailed(
3769                 instance=instance.uuid, reason=_msg)
3770 
3771         try:
3772             self.driver.set_admin_password(instance, new_pass)
3773             LOG.info("Admin password set", instance=instance)
3774             instance.task_state = None
3775             instance.save(
3776                 expected_task_state=task_states.UPDATING_PASSWORD)
3777         except exception.InstanceAgentNotEnabled:
3778             with excutils.save_and_reraise_exception():
3779                 LOG.debug('Guest agent is not enabled for the instance.',
3780                           instance=instance)
3781                 instance.task_state = None
3782                 instance.save(
3783                     expected_task_state=task_states.UPDATING_PASSWORD)
3784         except exception.SetAdminPasswdNotSupported:
3785             with excutils.save_and_reraise_exception():
3786                 LOG.info('set_admin_password is not supported '
3787                          'by this driver or guest instance.',
3788                          instance=instance)
3789                 instance.task_state = None
3790                 instance.save(
3791                     expected_task_state=task_states.UPDATING_PASSWORD)
3792         except NotImplementedError:
3793             LOG.warning('set_admin_password is not implemented '
3794                         'by this driver or guest instance.',
3795                         instance=instance)
3796             instance.task_state = None
3797             instance.save(
3798                 expected_task_state=task_states.UPDATING_PASSWORD)
3799             raise NotImplementedError(_('set_admin_password is not '
3800                                         'implemented by this driver or guest '
3801                                         'instance.'))
3802         except exception.UnexpectedTaskStateError:
3803             # interrupted by another (most likely delete) task
3804             # do not retry
3805             raise
3806         except Exception:
3807             # Catch all here because this could be anything.
3808             LOG.exception('set_admin_password failed', instance=instance)
3809             # We create a new exception here so that we won't
3810             # potentially reveal password information to the
3811             # API caller.  The real exception is logged above
3812             _msg = _('error setting admin password')
3813             raise exception.InstancePasswordSetFailed(
3814                 instance=instance.uuid, reason=_msg)
3815 
3816     @wrap_exception()
3817     @reverts_task_state
3818     @wrap_instance_fault
3819     def inject_file(self, context, path, file_contents, instance):
3820         """Write a file to the specified path in an instance on this host."""
3821         # NOTE(russellb) Remove this method, as well as the underlying virt
3822         # driver methods, when the compute rpc interface is bumped to 4.x
3823         # as it is no longer used.
3824         context = context.elevated()
3825         current_power_state = self._get_power_state(context, instance)
3826         expected_state = power_state.RUNNING
3827         if current_power_state != expected_state:
3828             LOG.warning('trying to inject a file into a non-running '
3829                         '(state: %(current_state)s expected: '
3830                         '%(expected_state)s)',
3831                         {'current_state': current_power_state,
3832                          'expected_state': expected_state},
3833                         instance=instance)
3834         LOG.info('injecting file to %s', path, instance=instance)
3835         self.driver.inject_file(instance, path, file_contents)
3836 
3837     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3838         """Determine what image should be used to boot the rescue VM."""
3839         # 1. If rescue_image_ref is passed in, use that for rescue.
3840         # 2. Else, use the base image associated with instance's current image.
3841         #       The idea here is to provide the customer with a rescue
3842         #       environment which they are familiar with.
3843         #       So, if they built their instance off of a Debian image,
3844         #       their rescue VM will also be Debian.
3845         # 3. As a last resort, use instance's current image.
3846         if not rescue_image_ref:
3847             system_meta = utils.instance_sys_meta(instance)
3848             rescue_image_ref = system_meta.get('image_base_image_ref')
3849 
3850         if not rescue_image_ref:
3851             LOG.warning('Unable to find a different image to use for '
3852                         'rescue VM, using instance\'s current image',
3853                         instance=instance)
3854             rescue_image_ref = instance.image_ref
3855 
3856         return objects.ImageMeta.from_image_ref(
3857             context, self.image_api, rescue_image_ref)
3858 
3859     @wrap_exception()
3860     @reverts_task_state
3861     @wrap_instance_event(prefix='compute')
3862     @wrap_instance_fault
3863     def rescue_instance(self, context, instance, rescue_password,
3864                         rescue_image_ref, clean_shutdown):
3865         context = context.elevated()
3866         LOG.info('Rescuing', instance=instance)
3867 
3868         admin_password = (rescue_password if rescue_password else
3869                       utils.generate_password())
3870 
3871         network_info = self.network_api.get_instance_nw_info(context, instance)
3872 
3873         rescue_image_meta = self._get_rescue_image(context, instance,
3874                                                    rescue_image_ref)
3875 
3876         extra_usage_info = {'rescue_image_name':
3877                             self._get_image_name(rescue_image_meta)}
3878         self._notify_about_instance_usage(context, instance,
3879                 "rescue.start", extra_usage_info=extra_usage_info,
3880                 network_info=network_info)
3881         compute_utils.notify_about_instance_rescue_action(
3882             context, instance, self.host, rescue_image_ref,
3883             phase=fields.NotificationPhase.START)
3884 
3885         try:
3886             self._power_off_instance(context, instance, clean_shutdown)
3887 
3888             self.driver.rescue(context, instance,
3889                                network_info,
3890                                rescue_image_meta, admin_password)
3891         except Exception as e:
3892             LOG.exception("Error trying to Rescue Instance",
3893                           instance=instance)
3894             self._set_instance_obj_error_state(context, instance)
3895             raise exception.InstanceNotRescuable(
3896                 instance_id=instance.uuid,
3897                 reason=_("Driver Error: %s") % e)
3898 
3899         compute_utils.notify_usage_exists(self.notifier, context, instance,
3900                                           self.host, current_period=True)
3901 
3902         instance.vm_state = vm_states.RESCUED
3903         instance.task_state = None
3904         instance.power_state = self._get_power_state(context, instance)
3905         instance.launched_at = timeutils.utcnow()
3906         instance.save(expected_task_state=task_states.RESCUING)
3907 
3908         self._notify_about_instance_usage(context, instance,
3909                 "rescue.end", extra_usage_info=extra_usage_info,
3910                 network_info=network_info)
3911         compute_utils.notify_about_instance_rescue_action(
3912             context, instance, self.host, rescue_image_ref,
3913             phase=fields.NotificationPhase.END)
3914 
3915     @wrap_exception()
3916     @reverts_task_state
3917     @wrap_instance_event(prefix='compute')
3918     @wrap_instance_fault
3919     def unrescue_instance(self, context, instance):
3920         context = context.elevated()
3921         LOG.info('Unrescuing', instance=instance)
3922 
3923         network_info = self.network_api.get_instance_nw_info(context, instance)
3924         self._notify_about_instance_usage(context, instance,
3925                 "unrescue.start", network_info=network_info)
3926         compute_utils.notify_about_instance_action(context, instance,
3927             self.host, action=fields.NotificationAction.UNRESCUE,
3928             phase=fields.NotificationPhase.START)
3929 
3930         with self._error_out_instance_on_exception(context, instance):
3931             self.driver.unrescue(instance,
3932                                  network_info)
3933 
3934         instance.vm_state = vm_states.ACTIVE
3935         instance.task_state = None
3936         instance.power_state = self._get_power_state(context, instance)
3937         instance.save(expected_task_state=task_states.UNRESCUING)
3938 
3939         self._notify_about_instance_usage(context,
3940                                           instance,
3941                                           "unrescue.end",
3942                                           network_info=network_info)
3943         compute_utils.notify_about_instance_action(context, instance,
3944             self.host, action=fields.NotificationAction.UNRESCUE,
3945             phase=fields.NotificationPhase.END)
3946 
3947     @wrap_exception()
3948     @wrap_instance_fault
3949     def change_instance_metadata(self, context, diff, instance):
3950         """Update the metadata published to the instance."""
3951         LOG.debug("Changing instance metadata according to %r",
3952                   diff, instance=instance)
3953         self.driver.change_instance_metadata(context, instance, diff)
3954 
3955     @wrap_exception()
3956     @wrap_instance_event(prefix='compute')
3957     @errors_out_migration
3958     @wrap_instance_fault
3959     def confirm_resize(self, context, instance, migration):
3960         """Confirms a migration/resize and deletes the 'old' instance.
3961 
3962         This is called from the API and runs on the source host.
3963 
3964         Nothing needs to happen on the destination host at this point since
3965         the instance is already running there. This routine just cleans up the
3966         source host.
3967         """
3968         @utils.synchronized(instance.uuid)
3969         def do_confirm_resize(context, instance, migration_id):
3970             # NOTE(wangpan): Get the migration status from db, if it has been
3971             #                confirmed, we do nothing and return here
3972             LOG.debug("Going to confirm migration %s", migration_id,
3973                       instance=instance)
3974             try:
3975                 # TODO(russellb) Why are we sending the migration object just
3976                 # to turn around and look it up from the db again?
3977                 migration = objects.Migration.get_by_id(
3978                                     context.elevated(), migration_id)
3979             except exception.MigrationNotFound:
3980                 LOG.error("Migration %s is not found during confirmation",
3981                           migration_id, instance=instance)
3982                 return
3983 
3984             if migration.status == 'confirmed':
3985                 LOG.info("Migration %s is already confirmed",
3986                          migration_id, instance=instance)
3987                 return
3988             elif migration.status not in ('finished', 'confirming'):
3989                 LOG.warning("Unexpected confirmation status '%(status)s' "
3990                             "of migration %(id)s, exit confirmation process",
3991                             {"status": migration.status, "id": migration_id},
3992                             instance=instance)
3993                 return
3994 
3995             # NOTE(wangpan): Get the instance from db, if it has been
3996             #                deleted, we do nothing and return here
3997             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3998             try:
3999                 instance = objects.Instance.get_by_uuid(
4000                         context, instance.uuid,
4001                         expected_attrs=expected_attrs)
4002             except exception.InstanceNotFound:
4003                 LOG.info("Instance is not found during confirmation",
4004                          instance=instance)
4005                 return
4006 
4007             with self._error_out_instance_on_exception(context, instance):
4008                 try:
4009                     self._confirm_resize(
4010                         context, instance, migration=migration)
4011                 except Exception:
4012                     # Something failed when cleaning up the source host so
4013                     # log a traceback and leave a hint about hard rebooting
4014                     # the server to correct its state in the DB.
4015                     with excutils.save_and_reraise_exception(logger=LOG):
4016                         LOG.exception(
4017                             'Confirm resize failed on source host %s. '
4018                             'Resource allocations in the placement service '
4019                             'will be removed regardless because the instance '
4020                             'is now on the destination host %s. You can try '
4021                             'hard rebooting the instance to correct its '
4022                             'state.', self.host, migration.dest_compute,
4023                             instance=instance)
4024                 finally:
4025                     # Whether an error occurred or not, at this point the
4026                     # instance is on the dest host so to avoid leaking
4027                     # allocations in placement, delete them here.
4028                     self._delete_allocation_after_move(
4029                         context, instance, migration)
4030 
4031         do_confirm_resize(context, instance, migration.id)
4032 
4033     def _get_updated_nw_info_with_pci_mapping(self, nw_info, pci_mapping):
4034         # NOTE(adrianc): This method returns a copy of nw_info if modifications
4035         # are made else it returns the original nw_info.
4036         updated_nw_info = nw_info
4037         if nw_info and pci_mapping:
4038             updated_nw_info = copy.deepcopy(nw_info)
4039             for vif in updated_nw_info:
4040                 if vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV:
4041                     try:
4042                         vif_pci_addr = vif['profile']['pci_slot']
4043                         new_addr = pci_mapping[vif_pci_addr].address
4044                         vif['profile']['pci_slot'] = new_addr
4045                         LOG.debug("Updating VIF's PCI address for VIF %(id)s. "
4046                                   "Original value %(orig_val)s, "
4047                                   "new value %(new_val)s",
4048                                   {'id': vif['id'],
4049                                    'orig_val': vif_pci_addr,
4050                                    'new_val': new_addr})
4051                     except (KeyError, AttributeError):
4052                         with excutils.save_and_reraise_exception():
4053                             # NOTE(adrianc): This should never happen. If we
4054                             # get here it means there is some inconsistency
4055                             # with either 'nw_info' or 'pci_mapping'.
4056                             LOG.error("Unexpected error when updating network "
4057                                       "information with PCI mapping.")
4058         return updated_nw_info
4059 
4060     def _confirm_resize(self, context, instance, migration=None):
4061         """Destroys the source instance."""
4062         self._notify_about_instance_usage(context, instance,
4063                                           "resize.confirm.start")
4064         compute_utils.notify_about_instance_action(context, instance,
4065             self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
4066             phase=fields.NotificationPhase.START)
4067 
4068         # NOTE(danms): delete stashed migration information
4069         old_instance_type = instance.old_flavor
4070         instance.old_flavor = None
4071         instance.new_flavor = None
4072         instance.system_metadata.pop('old_vm_state', None)
4073         instance.save()
4074 
4075         # NOTE(tr3buchet): tear down networks on source host
4076         self.network_api.setup_networks_on_host(context, instance,
4077                            migration.source_compute, teardown=True)
4078         network_info = self.network_api.get_instance_nw_info(context,
4079                                                              instance)
4080 
4081         # NOTE(adrianc): Populate old PCI device in VIF profile
4082         # to allow virt driver to properly unplug it from Hypervisor.
4083         pci_mapping = (instance.migration_context.
4084                        get_pci_mapping_for_migration(True))
4085         network_info = self._get_updated_nw_info_with_pci_mapping(
4086             network_info, pci_mapping)
4087 
4088         # TODO(mriedem): Get BDMs here and pass them to the driver.
4089         self.driver.confirm_migration(context, migration, instance,
4090                                       network_info)
4091 
4092         migration.status = 'confirmed'
4093         migration.save()
4094 
4095         # NOTE(mriedem): drop_move_claim relies on
4096         # instance.migration_context so make sure to not call
4097         # instance.drop_migration_context() until after drop_move_claim
4098         # is called.
4099         self.rt.drop_move_claim(context, instance, migration.source_node,
4100                                 old_instance_type, prefix='old_')
4101         instance.drop_migration_context()
4102 
4103         # NOTE(mriedem): The old_vm_state could be STOPPED but the user
4104         # might have manually powered up the instance to confirm the
4105         # resize/migrate, so we need to check the current power state
4106         # on the instance and set the vm_state appropriately. We default
4107         # to ACTIVE because if the power state is not SHUTDOWN, we
4108         # assume _sync_instance_power_state will clean it up.
4109         p_state = instance.power_state
4110         vm_state = None
4111         if p_state == power_state.SHUTDOWN:
4112             vm_state = vm_states.STOPPED
4113             LOG.debug("Resized/migrated instance is powered off. "
4114                       "Setting vm_state to '%s'.", vm_state,
4115                       instance=instance)
4116         else:
4117             vm_state = vm_states.ACTIVE
4118 
4119         instance.vm_state = vm_state
4120         instance.task_state = None
4121         instance.save(expected_task_state=[None, task_states.DELETING,
4122                                            task_states.SOFT_DELETING])
4123 
4124         self._notify_about_instance_usage(
4125             context, instance, "resize.confirm.end",
4126             network_info=network_info)
4127         compute_utils.notify_about_instance_action(context, instance,
4128                self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
4129                phase=fields.NotificationPhase.END)
4130 
4131     def _delete_allocation_after_move(self, context, instance, migration):
4132         """Deletes resource allocations held by the migration record against
4133         the source compute node resource provider after a confirmed cold /
4134         successful live migration.
4135         """
4136         try:
4137             # NOTE(danms): We're finishing on the source node, so try
4138             # to delete the allocation based on the migration uuid
4139             self.reportclient.delete_allocation_for_instance(
4140                 context, migration.uuid, consumer_type='migration')
4141         except exception.AllocationDeleteFailed:
4142             LOG.error('Deleting allocation in placement for migration '
4143                       '%(migration_uuid)s failed. The instance '
4144                       '%(instance_uuid)s will be put to ERROR state '
4145                       'but the allocation held by the migration is '
4146                       'leaked.',
4147                       {'instance_uuid': instance.uuid,
4148                        'migration_uuid': migration.uuid})
4149             raise
4150 
4151     @wrap_exception()
4152     @reverts_task_state
4153     @wrap_instance_event(prefix='compute')
4154     @errors_out_migration
4155     @wrap_instance_fault
4156     def revert_resize(self, context, instance, migration):
4157         """Destroys the new instance on the destination machine.
4158 
4159         Reverts the model changes, and powers on the old instance on the
4160         source machine.
4161 
4162         """
4163         # NOTE(comstud): A revert_resize is essentially a resize back to
4164         # the old size, so we need to send a usage event here.
4165         compute_utils.notify_usage_exists(self.notifier, context, instance,
4166                                           self.host, current_period=True)
4167 
4168         with self._error_out_instance_on_exception(context, instance):
4169             # NOTE(tr3buchet): tear down networks on destination host
4170             self.network_api.setup_networks_on_host(context, instance,
4171                                                     teardown=True)
4172 
4173             migration_p = obj_base.obj_to_primitive(migration)
4174             self.network_api.migrate_instance_start(context,
4175                                                     instance,
4176                                                     migration_p)
4177 
4178             network_info = self.network_api.get_instance_nw_info(context,
4179                                                                  instance)
4180             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4181                     context, instance.uuid)
4182             block_device_info = self._get_instance_block_device_info(
4183                                 context, instance, bdms=bdms)
4184 
4185             destroy_disks = not self._is_instance_storage_shared(
4186                 context, instance, host=migration.source_compute)
4187             self.driver.destroy(context, instance, network_info,
4188                                 block_device_info, destroy_disks)
4189 
4190             self._terminate_volume_connections(context, instance, bdms)
4191 
4192             migration.status = 'reverted'
4193             migration.save()
4194 
4195             # NOTE(ndipanov): We need to do this here because dropping the
4196             # claim means we lose the migration_context data. We really should
4197             # fix this by moving the drop_move_claim call to the
4198             # finish_revert_resize method as this is racy (revert is dropped,
4199             # but instance resources will be tracked with the new flavor until
4200             # it gets rolled back in finish_revert_resize, which is
4201             # potentially wrong for a period of time).
4202             instance.revert_migration_context()
4203             instance.save()
4204 
4205             self.rt.drop_move_claim(context, instance, instance.node)
4206 
4207             # RPC cast back to the source host to finish the revert there.
4208             self.compute_rpcapi.finish_revert_resize(context, instance,
4209                     migration, migration.source_compute)
4210 
4211     def _finish_revert_resize_network_migrate_finish(self, context, instance,
4212                                                      migration):
4213         """Causes port binding to be updated. In some Neutron or port
4214         configurations - see NetworkModel.get_bind_time_events() - we
4215         expect the vif-plugged event from Neutron immediately and wait for it.
4216         The rest of the time, the event is expected further along in the
4217         virt driver, so we don't wait here.
4218 
4219         :param context: The request context.
4220         :param instance: The instance undergoing the revert resize.
4221         :param migration: The Migration object of the resize being reverted.
4222         :raises: eventlet.timeout.Timeout or
4223                  exception.VirtualInterfacePlugException.
4224         """
4225         network_info = instance.get_network_info()
4226         events = []
4227         deadline = CONF.vif_plugging_timeout
4228         if deadline and utils.is_neutron() and network_info:
4229             events = network_info.get_bind_time_events(migration)
4230             if events:
4231                 LOG.debug('Will wait for bind-time events: %s', events)
4232         error_cb = self._neutron_failed_migration_callback
4233         try:
4234             with self.virtapi.wait_for_instance_event(instance, events,
4235                                                       deadline=deadline,
4236                                                       error_callback=error_cb):
4237                 # NOTE(hanrong): we need to change migration.dest_compute to
4238                 # source host temporarily.
4239                 # "network_api.migrate_instance_finish" will setup the network
4240                 # for the instance on the destination host. For revert resize,
4241                 # the instance will back to the source host, the setup of the
4242                 # network for instance should be on the source host. So set
4243                 # the migration.dest_compute to source host at here.
4244                 with utils.temporary_mutation(
4245                         migration, dest_compute=migration.source_compute):
4246                     self.network_api.migrate_instance_finish(context,
4247                                                              instance,
4248                                                              migration)
4249         except eventlet.timeout.Timeout:
4250             with excutils.save_and_reraise_exception():
4251                 LOG.error('Timeout waiting for Neutron events: %s', events,
4252                           instance=instance)
4253 
4254     @wrap_exception()
4255     @reverts_task_state
4256     @wrap_instance_event(prefix='compute')
4257     @errors_out_migration
4258     @wrap_instance_fault
4259     def finish_revert_resize(self, context, instance, migration):
4260         """Finishes the second half of reverting a resize on the source host.
4261 
4262         Bring the original source instance state back (active/shutoff) and
4263         revert the resized attributes in the database.
4264 
4265         """
4266         with self._error_out_instance_on_exception(context, instance):
4267             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4268                 context, instance.uuid)
4269             self._notify_about_instance_usage(
4270                     context, instance, "resize.revert.start")
4271             compute_utils.notify_about_instance_action(context, instance,
4272                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4273                     phase=fields.NotificationPhase.START, bdms=bdms)
4274 
4275             # NOTE(mriedem): delete stashed old_vm_state information; we
4276             # default to ACTIVE for backwards compatibility if old_vm_state
4277             # is not set
4278             old_vm_state = instance.system_metadata.pop('old_vm_state',
4279                                                         vm_states.ACTIVE)
4280 
4281             self._set_instance_info(instance, instance.old_flavor)
4282             instance.old_flavor = None
4283             instance.new_flavor = None
4284             instance.host = migration.source_compute
4285             instance.node = migration.source_node
4286             instance.save()
4287 
4288             try:
4289                 self._revert_allocation(context, instance, migration)
4290             except exception.AllocationMoveFailed:
4291                 LOG.error('Reverting allocation in placement for migration '
4292                           '%(migration_uuid)s failed. The instance '
4293                           '%(instance_uuid)s will be put into ERROR state but '
4294                           'the allocation held by the migration is leaked.',
4295                           {'instance_uuid': instance.uuid,
4296                            'migration_uuid': migration.uuid})
4297                 raise
4298 
4299             self.network_api.setup_networks_on_host(context, instance,
4300                                                     migration.source_compute)
4301             self._finish_revert_resize_network_migrate_finish(
4302                 context, instance, migration)
4303             network_info = self.network_api.get_instance_nw_info(context,
4304                                                                  instance)
4305 
4306             # revert_resize deleted any volume attachments for the instance
4307             # and created new ones to be used on this host, but we
4308             # have to update those attachments with the host connector so the
4309             # BDM.connection_info will get set in the call to
4310             # _get_instance_block_device_info below with refresh_conn_info=True
4311             # and then the volumes can be re-connected via the driver on this
4312             # host.
4313             self._update_volume_attachments(context, instance, bdms)
4314 
4315             block_device_info = self._get_instance_block_device_info(
4316                     context, instance, refresh_conn_info=True, bdms=bdms)
4317 
4318             power_on = old_vm_state != vm_states.STOPPED
4319             self.driver.finish_revert_migration(context, instance,
4320                                        network_info,
4321                                        block_device_info, power_on)
4322 
4323             instance.drop_migration_context()
4324             instance.launched_at = timeutils.utcnow()
4325             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
4326 
4327             # Complete any volume attachments so the volumes are in-use.
4328             self._complete_volume_attachments(context, bdms)
4329 
4330             # if the original vm state was STOPPED, set it back to STOPPED
4331             LOG.info("Updating instance to original state: '%s'",
4332                      old_vm_state, instance=instance)
4333             if power_on:
4334                 instance.vm_state = vm_states.ACTIVE
4335                 instance.task_state = None
4336                 instance.save()
4337             else:
4338                 instance.task_state = task_states.POWERING_OFF
4339                 instance.save()
4340                 self.stop_instance(context, instance=instance,
4341                                    clean_shutdown=True)
4342 
4343             self._notify_about_instance_usage(
4344                     context, instance, "resize.revert.end")
4345             compute_utils.notify_about_instance_action(context, instance,
4346                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4347                     phase=fields.NotificationPhase.END, bdms=bdms)
4348 
4349     def _revert_allocation(self, context, instance, migration):
4350         """Revert an allocation that is held by migration to our instance."""
4351 
4352         # Fetch the original allocation that the instance had on the source
4353         # node, which are now held by the migration
4354         orig_alloc = self.reportclient.get_allocations_for_consumer(
4355             context, migration.uuid)
4356         if not orig_alloc:
4357             LOG.error('Did not find resource allocations for migration '
4358                       '%s on source node %s. Unable to revert source node '
4359                       'allocations back to the instance.',
4360                       migration.uuid, migration.source_node, instance=instance)
4361             return False
4362 
4363         if len(orig_alloc) > 1:
4364             # NOTE(danms): This may change later if we have other allocations
4365             # against other providers that need to be held by the migration
4366             # as well. Perhaps something like shared storage resources that
4367             # will actually be duplicated during a resize type operation.
4368             LOG.error('Migration %(mig)s has allocations against '
4369                       'more than one provider %(rps)s. This should not be '
4370                       'possible, but reverting it anyway.',
4371                       {'mig': migration.uuid,
4372                        'rps': ','.join(orig_alloc.keys())},
4373                       instance=instance)
4374 
4375         # We only have a claim against one provider, it is the source node
4376         cn_uuid = list(orig_alloc.keys())[0]
4377 
4378         # FIXME(danms): This method is flawed in that it asssumes allocations
4379         # against only one provider. So, this may overwite allocations against
4380         # a shared provider, if we had one.
4381         LOG.info('Swapping old allocation on %(node)s held by migration '
4382                  '%(mig)s for instance',
4383                  {'node': cn_uuid, 'mig': migration.uuid},
4384                  instance=instance)
4385         # TODO(cdent): Should we be doing anything with return values here?
4386         self.reportclient.move_allocations(context, migration.uuid,
4387                                            instance.uuid)
4388         return True
4389 
4390     def _prep_resize(self, context, image, instance, instance_type,
4391                      filter_properties, node, migration, clean_shutdown=True):
4392 
4393         if not filter_properties:
4394             filter_properties = {}
4395 
4396         if not instance.host:
4397             self._set_instance_obj_error_state(context, instance)
4398             msg = _('Instance has no source host')
4399             raise exception.MigrationError(reason=msg)
4400 
4401         same_host = instance.host == self.host
4402         # if the flavor IDs match, it's migrate; otherwise resize
4403         if same_host and instance_type.id == instance['instance_type_id']:
4404             # check driver whether support migrate to same host
4405             if not self.driver.capabilities.get(
4406                     'supports_migrate_to_same_host', False):
4407                 # Raise InstanceFaultRollback so that the
4408                 # _error_out_instance_on_exception context manager in
4409                 # prep_resize will set the instance.vm_state properly.
4410                 raise exception.InstanceFaultRollback(
4411                     inner_exception=exception.UnableToMigrateToSelf(
4412                         instance_id=instance.uuid, host=self.host))
4413 
4414         # NOTE(danms): Stash the new instance_type to avoid having to
4415         # look it up in the database later
4416         instance.new_flavor = instance_type
4417         # NOTE(mriedem): Stash the old vm_state so we can set the
4418         # resized/reverted instance back to the same state later.
4419         vm_state = instance.vm_state
4420         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4421         instance.system_metadata['old_vm_state'] = vm_state
4422         instance.save()
4423 
4424         limits = filter_properties.get('limits', {})
4425         with self.rt.resize_claim(context, instance, instance_type, node,
4426                                   migration, image_meta=image,
4427                                   limits=limits) as claim:
4428             LOG.info('Migrating', instance=instance)
4429             # RPC cast to the source host to start the actual resize/migration.
4430             self.compute_rpcapi.resize_instance(
4431                     context, instance, claim.migration, image,
4432                     instance_type, clean_shutdown)
4433 
4434     def _send_prep_resize_notifications(
4435             self, context, instance, phase, flavor):
4436         """Send "resize.prep.*" notifications.
4437 
4438         :param context: nova auth request context
4439         :param instance: The instance being resized
4440         :param phase: The phase of the action (NotificationPhase enum)
4441         :param flavor: The (new) flavor for the resize (same as existing
4442             instance.flavor for a cold migration)
4443         """
4444         # Only send notify_usage_exists if it's the "start" phase.
4445         if phase == fields.NotificationPhase.START:
4446             compute_utils.notify_usage_exists(
4447                 self.notifier, context, instance, self.host,
4448                 current_period=True)
4449 
4450         # Send extra usage info about the flavor if it's the "end" phase for
4451         # the legacy unversioned notification.
4452         extra_usage_info = None
4453         if phase == fields.NotificationPhase.END:
4454             extra_usage_info = dict(
4455                 new_instance_type=flavor.name,
4456                 new_instance_type_id=flavor.id)
4457         self._notify_about_instance_usage(
4458             context, instance, "resize.prep.%s" % phase,
4459             extra_usage_info=extra_usage_info)
4460 
4461         # Send the versioned notification.
4462         compute_utils.notify_about_resize_prep_instance(
4463             context, instance, self.host, phase, flavor)
4464 
4465     @wrap_exception()
4466     @reverts_task_state
4467     @wrap_instance_event(prefix='compute')
4468     @wrap_instance_fault
4469     def prep_resize(self, context, image, instance, instance_type,
4470                     request_spec, filter_properties, node,
4471                     clean_shutdown, migration, host_list):
4472         """Initiates the process of moving a running instance to another host.
4473 
4474         Possibly changes the VCPU, RAM and disk size in the process.
4475 
4476         This is initiated from conductor and runs on the destination host.
4477 
4478         The main purpose of this method is performing some checks on the
4479         destination host and making a claim for resources. If the claim fails
4480         then a reschedule to another host may be attempted which involves
4481         calling back to conductor to start the process over again.
4482         """
4483         if node is None:
4484             node = self._get_nodename(instance, refresh=True)
4485 
4486         # Pass instance_state=instance.vm_state because we can resize
4487         # a STOPPED server and we don't want to set it back to ACTIVE
4488         # in case _prep_resize fails.
4489         instance_state = instance.vm_state
4490         with self._error_out_instance_on_exception(
4491                 context, instance, instance_state=instance_state),\
4492                 errors_out_migration_ctxt(migration):
4493             self._send_prep_resize_notifications(
4494                 context, instance, fields.NotificationPhase.START,
4495                 instance_type)
4496             try:
4497                 self._prep_resize(context, image, instance,
4498                                   instance_type, filter_properties,
4499                                   node, migration, clean_shutdown)
4500             except Exception:
4501                 # Since we hit a failure, we're either rescheduling or dead
4502                 # and either way we need to cleanup any allocations created
4503                 # by the scheduler for the destination node.
4504                 self._revert_allocation(context, instance, migration)
4505                 # try to re-schedule the resize elsewhere:
4506                 exc_info = sys.exc_info()
4507                 self._reschedule_resize_or_reraise(context, instance,
4508                         exc_info, instance_type, request_spec,
4509                         filter_properties, host_list)
4510             finally:
4511                 self._send_prep_resize_notifications(
4512                     context, instance, fields.NotificationPhase.END,
4513                     instance_type)
4514 
4515     def _reschedule_resize_or_reraise(self, context, instance, exc_info,
4516             instance_type, request_spec, filter_properties, host_list):
4517         """Try to re-schedule the resize or re-raise the original error to
4518         error out the instance.
4519         """
4520         if not filter_properties:
4521             filter_properties = {}
4522 
4523         rescheduled = False
4524         instance_uuid = instance.uuid
4525 
4526         try:
4527             retry = filter_properties.get('retry')
4528             if retry:
4529                 LOG.debug('Rescheduling, attempt %d', retry['num_attempts'],
4530                           instance_uuid=instance_uuid)
4531 
4532                 # reset the task state
4533                 task_state = task_states.RESIZE_PREP
4534                 self._instance_update(context, instance, task_state=task_state)
4535 
4536                 if exc_info:
4537                     # stringify to avoid circular ref problem in json
4538                     # serialization
4539                     retry['exc'] = traceback.format_exception_only(
4540                         exc_info[0], exc_info[1])
4541 
4542                 scheduler_hint = {'filter_properties': filter_properties}
4543 
4544                 self.compute_task_api.resize_instance(
4545                     context, instance, scheduler_hint, instance_type,
4546                     request_spec=request_spec, host_list=host_list)
4547 
4548                 rescheduled = True
4549             else:
4550                 # no retry information, do not reschedule.
4551                 LOG.debug('Retry info not present, will not reschedule',
4552                           instance_uuid=instance_uuid)
4553                 rescheduled = False
4554         except Exception as error:
4555             rescheduled = False
4556             LOG.exception("Error trying to reschedule",
4557                           instance_uuid=instance_uuid)
4558             compute_utils.add_instance_fault_from_exc(context,
4559                     instance, error,
4560                     exc_info=sys.exc_info())
4561             self._notify_about_instance_usage(context, instance,
4562                     'resize.error', fault=error)
4563             compute_utils.notify_about_instance_action(
4564                 context, instance, self.host,
4565                 action=fields.NotificationAction.RESIZE,
4566                 phase=fields.NotificationPhase.ERROR,
4567                 exception=error,
4568                 tb=','.join(traceback.format_exception(*exc_info)))
4569 
4570         if rescheduled:
4571             self._log_original_error(exc_info, instance_uuid)
4572             compute_utils.add_instance_fault_from_exc(context,
4573                     instance, exc_info[1], exc_info=exc_info)
4574             self._notify_about_instance_usage(context, instance,
4575                     'resize.error', fault=exc_info[1])
4576             compute_utils.notify_about_instance_action(
4577                 context, instance, self.host,
4578                 action=fields.NotificationAction.RESIZE,
4579                 phase=fields.NotificationPhase.ERROR,
4580                 exception=exc_info[1],
4581                 tb=','.join(traceback.format_exception(*exc_info)))
4582         else:
4583             # not re-scheduling
4584             six.reraise(*exc_info)
4585 
4586     @wrap_exception()
4587     @reverts_task_state
4588     @wrap_instance_event(prefix='compute')
4589     @wrap_instance_fault
4590     def resize_instance(self, context, instance, image,
4591                         migration, instance_type, clean_shutdown):
4592         """Starts the migration of a running instance to another host.
4593 
4594         This is initiated from the destination host's ``prep_resize`` routine
4595         and runs on the source host.
4596         """
4597         try:
4598             self._resize_instance(context, instance, image, migration,
4599                                   instance_type, clean_shutdown)
4600         except Exception:
4601             with excutils.save_and_reraise_exception():
4602                 self._revert_allocation(context, instance, migration)
4603 
4604     def _resize_instance(self, context, instance, image,
4605                          migration, instance_type, clean_shutdown):
4606         with self._error_out_instance_on_exception(context, instance), \
4607              errors_out_migration_ctxt(migration):
4608             network_info = self.network_api.get_instance_nw_info(context,
4609                                                                  instance)
4610 
4611             migration.status = 'migrating'
4612             migration.save()
4613 
4614             instance.task_state = task_states.RESIZE_MIGRATING
4615             instance.save(expected_task_state=task_states.RESIZE_PREP)
4616 
4617             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4618                     context, instance.uuid)
4619             self._send_resize_instance_notifications(
4620                 context, instance, bdms, network_info,
4621                 fields.NotificationPhase.START)
4622 
4623             block_device_info = self._get_instance_block_device_info(
4624                                 context, instance, bdms=bdms)
4625 
4626             timeout, retry_interval = self._get_power_off_values(context,
4627                                             instance, clean_shutdown)
4628             disk_info = self.driver.migrate_disk_and_power_off(
4629                     context, instance, migration.dest_host,
4630                     instance_type, network_info,
4631                     block_device_info,
4632                     timeout, retry_interval)
4633 
4634             self._terminate_volume_connections(context, instance, bdms)
4635 
4636             migration_p = obj_base.obj_to_primitive(migration)
4637             self.network_api.migrate_instance_start(context,
4638                                                     instance,
4639                                                     migration_p)
4640 
4641             migration.status = 'post-migrating'
4642             migration.save()
4643 
4644             instance.host = migration.dest_compute
4645             instance.node = migration.dest_node
4646             instance.task_state = task_states.RESIZE_MIGRATED
4647             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4648 
4649             # RPC cast to the destination host to finish the resize/migration.
4650             self.compute_rpcapi.finish_resize(context, instance,
4651                     migration, image, disk_info, migration.dest_compute)
4652 
4653         self._send_resize_instance_notifications(
4654             context, instance, bdms, network_info,
4655             fields.NotificationPhase.END)
4656         self.instance_events.clear_events_for_instance(instance)
4657 
4658     def _send_resize_instance_notifications(
4659             self, context, instance, bdms, network_info, phase):
4660         """Send "resize.(start|end)" notifications.
4661 
4662         :param context: nova auth request context
4663         :param instance: The instance being resized
4664         :param bdms: BlockDeviceMappingList for the BDMs associated with the
4665             instance
4666         :param network_info: NetworkInfo for the instance info cache of ports
4667         :param phase: The phase of the action (NotificationPhase enum, either
4668             ``start`` or ``end``)
4669         """
4670         action = fields.NotificationAction.RESIZE
4671         # Send the legacy unversioned notification.
4672         self._notify_about_instance_usage(
4673             context, instance, "%s.%s" % (action, phase),
4674             network_info=network_info)
4675         # Send the versioned notification.
4676         compute_utils.notify_about_instance_action(
4677             context, instance, self.host, action=action, phase=phase,
4678             bdms=bdms)
4679 
4680     def _terminate_volume_connections(self, context, instance, bdms):
4681         connector = None
4682         for bdm in bdms:
4683             if bdm.is_volume:
4684                 if bdm.attachment_id:
4685                     # NOTE(jdg): So here's the thing, the idea behind the new
4686                     # attach API's was to have a new code fork/path that we
4687                     # followed, we're not going to do that so we have to do
4688                     # some extra work in here to make it *behave* just like the
4689                     # old code. Cinder doesn't allow disconnect/reconnect (you
4690                     # just delete the attachment and get a new one)
4691                     # attachments in the new attach code so we have to do
4692                     # a delete and create without a connector (reserve),
4693                     # in other words, beware
4694                     attachment_id = self.volume_api.attachment_create(
4695                         context, bdm.volume_id, instance.uuid)['id']
4696                     self.volume_api.attachment_delete(context,
4697                                                       bdm.attachment_id)
4698                     bdm.attachment_id = attachment_id
4699                     bdm.save()
4700 
4701                 else:
4702                     if connector is None:
4703                         connector = self.driver.get_volume_connector(instance)
4704                     self.volume_api.terminate_connection(context,
4705                                                          bdm.volume_id,
4706                                                          connector)
4707 
4708     @staticmethod
4709     def _set_instance_info(instance, instance_type):
4710         instance.instance_type_id = instance_type.id
4711         instance.memory_mb = instance_type.memory_mb
4712         instance.vcpus = instance_type.vcpus
4713         instance.root_gb = instance_type.root_gb
4714         instance.ephemeral_gb = instance_type.ephemeral_gb
4715         instance.flavor = instance_type
4716 
4717     def _update_volume_attachments(self, context, instance, bdms):
4718         """Updates volume attachments using the virt driver host connector.
4719 
4720         :param context: nova.context.RequestContext - user request context
4721         :param instance: nova.objects.Instance
4722         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4723                      device mappings for the given instance
4724         """
4725         if bdms:
4726             connector = None
4727             for bdm in bdms:
4728                 if bdm.is_volume and bdm.attachment_id:
4729                     if connector is None:
4730                         connector = self.driver.get_volume_connector(instance)
4731                     self.volume_api.attachment_update(
4732                         context, bdm.attachment_id, connector, bdm.device_name)
4733 
4734     def _complete_volume_attachments(self, context, bdms):
4735         """Completes volume attachments for the instance
4736 
4737         :param context: nova.context.RequestContext - user request context
4738         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4739                      device mappings for the given instance
4740         """
4741         if bdms:
4742             for bdm in bdms:
4743                 if bdm.is_volume and bdm.attachment_id:
4744                     self.volume_api.attachment_complete(
4745                         context, bdm.attachment_id)
4746 
4747     def _finish_resize(self, context, instance, migration, disk_info,
4748                        image_meta, bdms):
4749         resize_instance = False  # indicates disks have been resized
4750         old_instance_type_id = migration['old_instance_type_id']
4751         new_instance_type_id = migration['new_instance_type_id']
4752         old_flavor = instance.flavor  # the current flavor is now old
4753         # NOTE(mriedem): Get the old_vm_state so we know if we should
4754         # power on the instance. If old_vm_state is not set we need to default
4755         # to ACTIVE for backwards compatibility
4756         old_vm_state = instance.system_metadata.get('old_vm_state',
4757                                                     vm_states.ACTIVE)
4758         instance.old_flavor = old_flavor
4759 
4760         if old_instance_type_id != new_instance_type_id:
4761             new_flavor = instance.new_flavor  # this is set in _prep_resize
4762             # Set the flavor-related fields on the instance object including
4763             # making instance.flavor = new_flavor.
4764             self._set_instance_info(instance, new_flavor)
4765             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4766                 if old_flavor[key] != new_flavor[key]:
4767                     resize_instance = True
4768                     break
4769         instance.apply_migration_context()
4770 
4771         # NOTE(tr3buchet): setup networks on destination host
4772         self.network_api.setup_networks_on_host(context, instance,
4773                                                 migration.dest_compute)
4774         # For neutron, migrate_instance_finish updates port bindings for this
4775         # host including any PCI devices claimed for SR-IOV ports.
4776         self.network_api.migrate_instance_finish(context,
4777                                                  instance,
4778                                                  migration)
4779 
4780         network_info = self.network_api.get_instance_nw_info(context, instance)
4781 
4782         instance.task_state = task_states.RESIZE_FINISH
4783         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4784 
4785         self._send_finish_resize_notifications(
4786             context, instance, bdms, network_info,
4787             fields.NotificationPhase.START)
4788 
4789         # We need to update any volume attachments using the destination
4790         # host connector so that we can update the BDM.connection_info
4791         # before calling driver.finish_migration otherwise the driver
4792         # won't know how to connect the volumes to this host.
4793         # Note that _get_instance_block_device_info with
4794         # refresh_conn_info=True will update the BDM.connection_info value
4795         # in the database so we must do this before calling that method.
4796         self._update_volume_attachments(context, instance, bdms)
4797 
4798         block_device_info = self._get_instance_block_device_info(
4799             context, instance, refresh_conn_info=True, bdms=bdms)
4800 
4801         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4802         # automatically power on the instance after it's migrated
4803         power_on = old_vm_state != vm_states.STOPPED
4804 
4805         try:
4806             self.driver.finish_migration(context, migration, instance,
4807                                          disk_info,
4808                                          network_info,
4809                                          image_meta, resize_instance,
4810                                          block_device_info, power_on)
4811         except Exception:
4812             # Note that we do not rollback port bindings to the source host
4813             # because resize_instance (on the source host) updated the
4814             # instance.host to point to *this* host (the destination host)
4815             # so the port bindings pointing at this host are correct even
4816             # though we failed to create the guest.
4817             with excutils.save_and_reraise_exception():
4818                 # If we failed to create the guest on this host, reset the
4819                 # instance flavor-related fields to the old flavor. An
4820                 # error handler like reverts_task_state will save the changes.
4821                 if old_instance_type_id != new_instance_type_id:
4822                     self._set_instance_info(instance, old_flavor)
4823 
4824         # Now complete any volume attachments that were previously updated.
4825         self._complete_volume_attachments(context, bdms)
4826 
4827         migration.status = 'finished'
4828         migration.save()
4829 
4830         instance.vm_state = vm_states.RESIZED
4831         instance.task_state = None
4832         instance.launched_at = timeutils.utcnow()
4833         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4834 
4835         return network_info
4836 
4837     @wrap_exception()
4838     @reverts_task_state
4839     @wrap_instance_event(prefix='compute')
4840     @errors_out_migration
4841     @wrap_instance_fault
4842     def finish_resize(self, context, disk_info, image, instance,
4843                       migration):
4844         """Completes the migration process.
4845 
4846         Sets up the newly transferred disk and turns on the instance at its
4847         new host machine.
4848 
4849         """
4850         try:
4851             self._finish_resize_helper(context, disk_info, image, instance,
4852                                        migration)
4853         except Exception:
4854             with excutils.save_and_reraise_exception():
4855                 # At this point, resize_instance (which runs on the source) has
4856                 # already updated the instance host/node values to point to
4857                 # this (the dest) compute, so we need to leave the allocations
4858                 # against the dest node resource provider intact and drop the
4859                 # allocations against the source node resource provider. If the
4860                 # user tries to recover the server by hard rebooting it, it
4861                 # will happen on this host so that's where the allocations
4862                 # should go. Note that this is the same method called from
4863                 # confirm_resize to cleanup the source node allocations held
4864                 # by the migration record.
4865                 LOG.info('Deleting allocations for old flavor on source node '
4866                          '%s after finish_resize failure. You may be able to '
4867                          'recover the instance by hard rebooting it.',
4868                          migration.source_compute, instance=instance)
4869                 self._delete_allocation_after_move(
4870                     context, instance, migration)
4871 
4872     def _finish_resize_helper(self, context, disk_info, image, instance,
4873                               migration):
4874         """Completes the migration process.
4875 
4876         The caller must revert the instance's allocations if the migration
4877         process failed.
4878         """
4879         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4880             context, instance.uuid)
4881 
4882         with self._error_out_instance_on_exception(context, instance):
4883             image_meta = objects.ImageMeta.from_dict(image)
4884             network_info = self._finish_resize(context, instance, migration,
4885                                                disk_info, image_meta, bdms)
4886 
4887         # TODO(melwitt): We should clean up instance console tokens here. The
4888         # instance is on a new host and will need to establish a new console
4889         # connection.
4890         self._update_scheduler_instance_info(context, instance)
4891         self._send_finish_resize_notifications(
4892             context, instance, bdms, network_info,
4893             fields.NotificationPhase.END)
4894 
4895     def _send_finish_resize_notifications(
4896             self, context, instance, bdms, network_info, phase):
4897         """Send notifications for the finish_resize flow.
4898 
4899         :param context: nova auth request context
4900         :param instance: The instance being resized
4901         :param bdms: BlockDeviceMappingList for the BDMs associated with the
4902             instance
4903         :param network_info: NetworkInfo for the instance info cache of ports
4904         :param phase: The phase of the action (NotificationPhase enum, either
4905             ``start`` or ``end``)
4906         """
4907         # Send the legacy unversioned notification.
4908         self._notify_about_instance_usage(
4909             context, instance, "finish_resize.%s" % phase,
4910             network_info=network_info)
4911         # Send the versioned notification.
4912         compute_utils.notify_about_instance_action(
4913             context, instance, self.host,
4914             action=fields.NotificationAction.RESIZE_FINISH, phase=phase,
4915             bdms=bdms)
4916 
4917     @wrap_exception()
4918     @wrap_instance_fault
4919     def add_fixed_ip_to_instance(self, context, network_id, instance):
4920         """Calls network_api to add new fixed_ip to instance
4921         then injects the new network info and resets instance networking.
4922 
4923         """
4924         self._notify_about_instance_usage(
4925                 context, instance, "create_ip.start")
4926 
4927         network_info = self.network_api.add_fixed_ip_to_instance(context,
4928                                                                  instance,
4929                                                                  network_id)
4930         self._inject_network_info(context, instance, network_info)
4931         self.reset_network(context, instance)
4932 
4933         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4934         instance.updated_at = timeutils.utcnow()
4935         instance.save()
4936 
4937         self._notify_about_instance_usage(
4938             context, instance, "create_ip.end", network_info=network_info)
4939 
4940     @wrap_exception()
4941     @wrap_instance_fault
4942     def remove_fixed_ip_from_instance(self, context, address, instance):
4943         """Calls network_api to remove existing fixed_ip from instance
4944         by injecting the altered network info and resetting
4945         instance networking.
4946         """
4947         self._notify_about_instance_usage(
4948                 context, instance, "delete_ip.start")
4949 
4950         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4951                                                                       instance,
4952                                                                       address)
4953         self._inject_network_info(context, instance, network_info)
4954         self.reset_network(context, instance)
4955 
4956         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4957         instance.updated_at = timeutils.utcnow()
4958         instance.save()
4959 
4960         self._notify_about_instance_usage(
4961             context, instance, "delete_ip.end", network_info=network_info)
4962 
4963     @wrap_exception()
4964     @reverts_task_state
4965     @wrap_instance_event(prefix='compute')
4966     @wrap_instance_fault
4967     def pause_instance(self, context, instance):
4968         """Pause an instance on this host."""
4969         context = context.elevated()
4970         LOG.info('Pausing', instance=instance)
4971         self._notify_about_instance_usage(context, instance, 'pause.start')
4972         compute_utils.notify_about_instance_action(context, instance,
4973                self.host, action=fields.NotificationAction.PAUSE,
4974                phase=fields.NotificationPhase.START)
4975         self.driver.pause(instance)
4976         instance.power_state = self._get_power_state(context, instance)
4977         instance.vm_state = vm_states.PAUSED
4978         instance.task_state = None
4979         instance.save(expected_task_state=task_states.PAUSING)
4980         self._notify_about_instance_usage(context, instance, 'pause.end')
4981         compute_utils.notify_about_instance_action(context, instance,
4982                self.host, action=fields.NotificationAction.PAUSE,
4983                phase=fields.NotificationPhase.END)
4984 
4985     @wrap_exception()
4986     @reverts_task_state
4987     @wrap_instance_event(prefix='compute')
4988     @wrap_instance_fault
4989     def unpause_instance(self, context, instance):
4990         """Unpause a paused instance on this host."""
4991         context = context.elevated()
4992         LOG.info('Unpausing', instance=instance)
4993         self._notify_about_instance_usage(context, instance, 'unpause.start')
4994         compute_utils.notify_about_instance_action(context, instance,
4995             self.host, action=fields.NotificationAction.UNPAUSE,
4996             phase=fields.NotificationPhase.START)
4997         self.driver.unpause(instance)
4998         instance.power_state = self._get_power_state(context, instance)
4999         instance.vm_state = vm_states.ACTIVE
5000         instance.task_state = None
5001         instance.save(expected_task_state=task_states.UNPAUSING)
5002         self._notify_about_instance_usage(context, instance, 'unpause.end')
5003         compute_utils.notify_about_instance_action(context, instance,
5004             self.host, action=fields.NotificationAction.UNPAUSE,
5005             phase=fields.NotificationPhase.END)
5006 
5007     @wrap_exception()
5008     def host_power_action(self, context, action):
5009         """Reboots, shuts down or powers up the host."""
5010         return self.driver.host_power_action(action)
5011 
5012     @wrap_exception()
5013     def host_maintenance_mode(self, context, host, mode):
5014         """Start/Stop host maintenance window. On start, it triggers
5015         guest VMs evacuation.
5016         """
5017         return self.driver.host_maintenance_mode(host, mode)
5018 
5019     def _update_compute_provider_status(self, context, enabled):
5020         """Adds or removes the COMPUTE_STATUS_DISABLED trait for this host.
5021 
5022         For each ComputeNode managed by this service, adds or removes the
5023         COMPUTE_STATUS_DISABLED traits to/from the associated resource provider
5024         in Placement.
5025 
5026         :param context: nova auth RequestContext
5027         :param enabled: True if the node is enabled in which case the trait
5028             would be removed, False if the node is disabled in which case
5029             the trait would be added.
5030         :raises: ComputeHostNotFound if there are no compute nodes found in
5031             the ResourceTracker for this service.
5032         """
5033         # Get the compute node(s) on this host. Remember that ironic can be
5034         # managing more than one compute node.
5035         nodes = self.rt.compute_nodes.values()
5036         if not nodes:
5037             raise exception.ComputeHostNotFound(host=self.host)
5038         # For each node, we want to add (or remove) the COMPUTE_STATUS_DISABLED
5039         # trait on the related resource provider in placement so the scheduler
5040         # (pre-)filters the provider based on its status.
5041         for node in nodes:
5042             try:
5043                 self.virtapi.update_compute_provider_status(
5044                     context, node.uuid, enabled)
5045             except (exception.ResourceProviderTraitRetrievalFailed,
5046                     exception.ResourceProviderUpdateConflict,
5047                     exception.ResourceProviderUpdateFailed,
5048                     exception.TraitRetrievalFailed) as e:
5049                 # This is best effort so just log a warning and continue.
5050                 LOG.warning('An error occurred while updating '
5051                             'COMPUTE_STATUS_DISABLED trait on compute node '
5052                             'resource provider %s. The trait will be '
5053                             'synchronized when the update_available_resource '
5054                             'periodic task runs. Error: %s',
5055                             node.uuid, e.format_message())
5056             except Exception:
5057                 LOG.exception('An error occurred while updating '
5058                               'COMPUTE_STATUS_DISABLED trait on compute node '
5059                               'resource provider %s. The trait will be '
5060                               'synchronized when the '
5061                               'update_available_resource periodic task runs.',
5062                               node.uuid)
5063 
5064     @wrap_exception()
5065     def set_host_enabled(self, context, enabled):
5066         """Sets the specified host's ability to accept new instances.
5067 
5068         This method will add or remove the COMPUTE_STATUS_DISABLED trait
5069         to/from the associated compute node resource provider(s) for this
5070         compute service.
5071         """
5072         try:
5073             self._update_compute_provider_status(context, enabled)
5074         except exception.ComputeHostNotFound:
5075             LOG.warning('Unable to add/remove trait COMPUTE_STATUS_DISABLED. '
5076                         'No ComputeNode(s) found for host: %s', self.host)
5077 
5078         try:
5079             return self.driver.set_host_enabled(enabled)
5080         except NotImplementedError:
5081             # Only the xenapi driver implements set_host_enabled but we don't
5082             # want NotImplementedError to get raised back to the API. We still
5083             # need to honor the compute RPC API contract and return 'enabled'
5084             # or 'disabled' though.
5085             return 'enabled' if enabled else 'disabled'
5086 
5087     @wrap_exception()
5088     def get_host_uptime(self, context):
5089         """Returns the result of calling "uptime" on the target host."""
5090         return self.driver.get_host_uptime()
5091 
5092     @wrap_exception()
5093     @wrap_instance_fault
5094     def get_diagnostics(self, context, instance):
5095         """Retrieve diagnostics for an instance on this host."""
5096         current_power_state = self._get_power_state(context, instance)
5097         if current_power_state == power_state.RUNNING:
5098             LOG.info("Retrieving diagnostics", instance=instance)
5099             return self.driver.get_diagnostics(instance)
5100         else:
5101             raise exception.InstanceInvalidState(
5102                 attr='power state',
5103                 instance_uuid=instance.uuid,
5104                 state=power_state.STATE_MAP[instance.power_state],
5105                 method='get_diagnostics')
5106 
5107     @wrap_exception()
5108     @wrap_instance_fault
5109     def get_instance_diagnostics(self, context, instance):
5110         """Retrieve diagnostics for an instance on this host."""
5111         current_power_state = self._get_power_state(context, instance)
5112         if current_power_state == power_state.RUNNING:
5113             LOG.info("Retrieving diagnostics", instance=instance)
5114             return self.driver.get_instance_diagnostics(instance)
5115         else:
5116             raise exception.InstanceInvalidState(
5117                 attr='power state',
5118                 instance_uuid=instance.uuid,
5119                 state=power_state.STATE_MAP[instance.power_state],
5120                 method='get_diagnostics')
5121 
5122     @wrap_exception()
5123     @reverts_task_state
5124     @wrap_instance_event(prefix='compute')
5125     @wrap_instance_fault
5126     def suspend_instance(self, context, instance):
5127         """Suspend the given instance."""
5128         context = context.elevated()
5129 
5130         # Store the old state
5131         instance.system_metadata['old_vm_state'] = instance.vm_state
5132         self._notify_about_instance_usage(context, instance, 'suspend.start')
5133         compute_utils.notify_about_instance_action(context, instance,
5134                 self.host, action=fields.NotificationAction.SUSPEND,
5135                 phase=fields.NotificationPhase.START)
5136         with self._error_out_instance_on_exception(context, instance,
5137              instance_state=instance.vm_state):
5138             self.driver.suspend(context, instance)
5139         instance.power_state = self._get_power_state(context, instance)
5140         instance.vm_state = vm_states.SUSPENDED
5141         instance.task_state = None
5142         instance.save(expected_task_state=task_states.SUSPENDING)
5143         self._notify_about_instance_usage(context, instance, 'suspend.end')
5144         compute_utils.notify_about_instance_action(context, instance,
5145                 self.host, action=fields.NotificationAction.SUSPEND,
5146                 phase=fields.NotificationPhase.END)
5147 
5148     @wrap_exception()
5149     @reverts_task_state
5150     @wrap_instance_event(prefix='compute')
5151     @wrap_instance_fault
5152     def resume_instance(self, context, instance):
5153         """Resume the given suspended instance."""
5154         context = context.elevated()
5155         LOG.info('Resuming', instance=instance)
5156 
5157         self._notify_about_instance_usage(context, instance, 'resume.start')
5158 
5159         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5160             context, instance.uuid)
5161         block_device_info = self._get_instance_block_device_info(
5162             context, instance, bdms=bdms)
5163 
5164         compute_utils.notify_about_instance_action(context, instance,
5165             self.host, action=fields.NotificationAction.RESUME,
5166             phase=fields.NotificationPhase.START, bdms=bdms)
5167 
5168         network_info = self.network_api.get_instance_nw_info(context, instance)
5169 
5170         with self._error_out_instance_on_exception(context, instance,
5171              instance_state=instance.vm_state):
5172             self.driver.resume(context, instance, network_info,
5173                                block_device_info)
5174 
5175         instance.power_state = self._get_power_state(context, instance)
5176 
5177         # We default to the ACTIVE state for backwards compatibility
5178         instance.vm_state = instance.system_metadata.pop('old_vm_state',
5179                                                          vm_states.ACTIVE)
5180 
5181         instance.task_state = None
5182         instance.save(expected_task_state=task_states.RESUMING)
5183         self._notify_about_instance_usage(context, instance, 'resume.end')
5184         compute_utils.notify_about_instance_action(context, instance,
5185             self.host, action=fields.NotificationAction.RESUME,
5186             phase=fields.NotificationPhase.END, bdms=bdms)
5187 
5188     @wrap_exception()
5189     @reverts_task_state
5190     @wrap_instance_event(prefix='compute')
5191     @wrap_instance_fault
5192     def shelve_instance(self, context, instance, image_id,
5193                         clean_shutdown):
5194         """Shelve an instance.
5195 
5196         This should be used when you want to take a snapshot of the instance.
5197         It also adds system_metadata that can be used by a periodic task to
5198         offload the shelved instance after a period of time.
5199 
5200         :param context: request context
5201         :param instance: an Instance object
5202         :param image_id: an image id to snapshot to.
5203         :param clean_shutdown: give the GuestOS a chance to stop
5204         """
5205 
5206         @utils.synchronized(instance.uuid)
5207         def do_shelve_instance():
5208             self._shelve_instance(context, instance, image_id, clean_shutdown)
5209         do_shelve_instance()
5210 
5211     def _shelve_instance(self, context, instance, image_id,
5212                          clean_shutdown):
5213         LOG.info('Shelving', instance=instance)
5214         offload = CONF.shelved_offload_time == 0
5215         if offload:
5216             # Get the BDMs early so we can pass them into versioned
5217             # notifications since _shelve_offload_instance needs the
5218             # BDMs anyway.
5219             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5220                 context, instance.uuid)
5221         else:
5222             bdms = None
5223         compute_utils.notify_usage_exists(self.notifier, context, instance,
5224                                           self.host, current_period=True)
5225         self._notify_about_instance_usage(context, instance, 'shelve.start')
5226         compute_utils.notify_about_instance_action(context, instance,
5227                 self.host, action=fields.NotificationAction.SHELVE,
5228                 phase=fields.NotificationPhase.START, bdms=bdms)
5229 
5230         def update_task_state(task_state, expected_state=task_states.SHELVING):
5231             shelving_state_map = {
5232                     task_states.IMAGE_PENDING_UPLOAD:
5233                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
5234                     task_states.IMAGE_UPLOADING:
5235                         task_states.SHELVING_IMAGE_UPLOADING,
5236                     task_states.SHELVING: task_states.SHELVING}
5237             task_state = shelving_state_map[task_state]
5238             expected_state = shelving_state_map[expected_state]
5239             instance.task_state = task_state
5240             instance.save(expected_task_state=expected_state)
5241         # Do not attempt a clean shutdown of a paused guest since some
5242         # hypervisors will fail the clean shutdown if the guest is not
5243         # running.
5244         if instance.power_state == power_state.PAUSED:
5245             clean_shutdown = False
5246         self._power_off_instance(context, instance, clean_shutdown)
5247         self.driver.snapshot(context, instance, image_id, update_task_state)
5248 
5249         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
5250         instance.system_metadata['shelved_image_id'] = image_id
5251         instance.system_metadata['shelved_host'] = self.host
5252         instance.vm_state = vm_states.SHELVED
5253         instance.task_state = None
5254         if CONF.shelved_offload_time == 0:
5255             instance.task_state = task_states.SHELVING_OFFLOADING
5256         instance.power_state = self._get_power_state(context, instance)
5257         instance.save(expected_task_state=[
5258                 task_states.SHELVING,
5259                 task_states.SHELVING_IMAGE_UPLOADING])
5260 
5261         self._notify_about_instance_usage(context, instance, 'shelve.end')
5262         compute_utils.notify_about_instance_action(context, instance,
5263                 self.host, action=fields.NotificationAction.SHELVE,
5264                 phase=fields.NotificationPhase.END, bdms=bdms)
5265 
5266         if offload:
5267             self._shelve_offload_instance(context, instance,
5268                                           clean_shutdown=False, bdms=bdms)
5269 
5270     @wrap_exception()
5271     @reverts_task_state
5272     @wrap_instance_event(prefix='compute')
5273     @wrap_instance_fault
5274     def shelve_offload_instance(self, context, instance, clean_shutdown):
5275         """Remove a shelved instance from the hypervisor.
5276 
5277         This frees up those resources for use by other instances, but may lead
5278         to slower unshelve times for this instance.  This method is used by
5279         volume backed instances since restoring them doesn't involve the
5280         potentially large download of an image.
5281 
5282         :param context: request context
5283         :param instance: nova.objects.instance.Instance
5284         :param clean_shutdown: give the GuestOS a chance to stop
5285         """
5286 
5287         @utils.synchronized(instance.uuid)
5288         def do_shelve_offload_instance():
5289             self._shelve_offload_instance(context, instance, clean_shutdown)
5290         do_shelve_offload_instance()
5291 
5292     def _shelve_offload_instance(self, context, instance, clean_shutdown,
5293                                  bdms=None):
5294         LOG.info('Shelve offloading', instance=instance)
5295         if bdms is None:
5296             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5297                 context, instance.uuid)
5298         self._notify_about_instance_usage(context, instance,
5299                 'shelve_offload.start')
5300         compute_utils.notify_about_instance_action(context, instance,
5301                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
5302                 phase=fields.NotificationPhase.START, bdms=bdms)
5303 
5304         self._power_off_instance(context, instance, clean_shutdown)
5305         current_power_state = self._get_power_state(context, instance)
5306 
5307         self.network_api.cleanup_instance_network_on_host(context, instance,
5308                                                           instance.host)
5309         network_info = self.network_api.get_instance_nw_info(context, instance)
5310 
5311         block_device_info = self._get_instance_block_device_info(context,
5312                                                                  instance,
5313                                                                  bdms=bdms)
5314         self.driver.destroy(context, instance, network_info,
5315                 block_device_info)
5316 
5317         # the instance is going to be removed from the host so we want to
5318         # terminate all the connections with the volume server and the host
5319         self._terminate_volume_connections(context, instance, bdms)
5320 
5321         # Free up the resource allocations in the placement service.
5322         # This should happen *before* the vm_state is changed to
5323         # SHELVED_OFFLOADED in case client-side code is polling the API to
5324         # schedule more instances (or unshelve) once this server is offloaded.
5325         self.rt.delete_allocation_for_shelve_offloaded_instance(context,
5326                                                                 instance)
5327 
5328         instance.power_state = current_power_state
5329         # NOTE(mriedem): The vm_state has to be set before updating the
5330         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
5331         # values cannot be nulled out until after updating the resource tracker
5332         # though.
5333         instance.vm_state = vm_states.SHELVED_OFFLOADED
5334         instance.task_state = None
5335         instance.save(expected_task_state=[task_states.SHELVING,
5336                                            task_states.SHELVING_OFFLOADING])
5337 
5338         # NOTE(ndipanov): Free resources from the resource tracker
5339         self._update_resource_tracker(context, instance)
5340 
5341         # NOTE(sfinucan): RPC calls should no longer be attempted against this
5342         # instance, so ensure any calls result in errors
5343         self._nil_out_instance_obj_host_and_node(instance)
5344         instance.save(expected_task_state=None)
5345 
5346         # TODO(melwitt): We should clean up instance console tokens here. The
5347         # instance has no host at this point and will need to establish a new
5348         # console connection in the future after it is unshelved.
5349         self._delete_scheduler_instance_info(context, instance.uuid)
5350         self._notify_about_instance_usage(context, instance,
5351                 'shelve_offload.end')
5352         compute_utils.notify_about_instance_action(context, instance,
5353                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
5354                 phase=fields.NotificationPhase.END, bdms=bdms)
5355 
5356     @wrap_exception()
5357     @reverts_task_state
5358     @wrap_instance_event(prefix='compute')
5359     @wrap_instance_fault
5360     def unshelve_instance(self, context, instance, image,
5361                           filter_properties, node):
5362         """Unshelve the instance.
5363 
5364         :param context: request context
5365         :param instance: a nova.objects.instance.Instance object
5366         :param image: an image to build from.  If None we assume a
5367             volume backed instance.
5368         :param filter_properties: dict containing limits, retry info etc.
5369         :param node: target compute node
5370         """
5371         if filter_properties is None:
5372             filter_properties = {}
5373 
5374         @utils.synchronized(instance.uuid)
5375         def do_unshelve_instance():
5376             self._unshelve_instance(context, instance, image,
5377                                     filter_properties, node)
5378         do_unshelve_instance()
5379 
5380     def _unshelve_instance_key_scrub(self, instance):
5381         """Remove data from the instance that may cause side effects."""
5382         cleaned_keys = dict(
5383                 key_data=instance.key_data,
5384                 auto_disk_config=instance.auto_disk_config)
5385         instance.key_data = None
5386         instance.auto_disk_config = False
5387         return cleaned_keys
5388 
5389     def _unshelve_instance_key_restore(self, instance, keys):
5390         """Restore previously scrubbed keys before saving the instance."""
5391         instance.update(keys)
5392 
5393     def _unshelve_instance(self, context, instance, image, filter_properties,
5394                            node):
5395         LOG.info('Unshelving', instance=instance)
5396         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5397                 context, instance.uuid)
5398 
5399         self._notify_about_instance_usage(context, instance, 'unshelve.start')
5400         compute_utils.notify_about_instance_action(context, instance,
5401                 self.host, action=fields.NotificationAction.UNSHELVE,
5402                 phase=fields.NotificationPhase.START, bdms=bdms)
5403 
5404         instance.task_state = task_states.SPAWNING
5405         instance.save()
5406 
5407         block_device_info = self._prep_block_device(context, instance, bdms)
5408         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
5409 
5410         if node is None:
5411             node = self._get_nodename(instance)
5412 
5413         limits = filter_properties.get('limits', {})
5414 
5415         allocations = self.reportclient.get_allocations_for_consumer(
5416             context, instance.uuid)
5417 
5418         shelved_image_ref = instance.image_ref
5419         if image:
5420             instance.image_ref = image['id']
5421             image_meta = objects.ImageMeta.from_dict(image)
5422         else:
5423             image_meta = objects.ImageMeta.from_dict(
5424                 utils.get_image_from_system_metadata(
5425                     instance.system_metadata))
5426 
5427         self.network_api.setup_instance_network_on_host(context, instance,
5428                                                         self.host)
5429         network_info = self.network_api.get_instance_nw_info(context, instance)
5430         try:
5431             with self.rt.instance_claim(context, instance, node, limits):
5432                 self.driver.spawn(context, instance, image_meta,
5433                                   injected_files=[],
5434                                   admin_password=None,
5435                                   allocations=allocations,
5436                                   network_info=network_info,
5437                                   block_device_info=block_device_info)
5438         except Exception:
5439             with excutils.save_and_reraise_exception(logger=LOG):
5440                 LOG.exception('Instance failed to spawn',
5441                               instance=instance)
5442                 # Cleanup allocations created by the scheduler on this host
5443                 # since we failed to spawn the instance. We do this both if
5444                 # the instance claim failed with ComputeResourcesUnavailable
5445                 # or if we did claim but the spawn failed, because aborting the
5446                 # instance claim will not remove the allocations.
5447                 self.reportclient.delete_allocation_for_instance(context,
5448                                                                  instance.uuid)
5449                 # FIXME: Umm, shouldn't we be rolling back port bindings too?
5450                 self._terminate_volume_connections(context, instance, bdms)
5451                 # The reverts_task_state decorator on unshelve_instance will
5452                 # eventually save these updates.
5453                 self._nil_out_instance_obj_host_and_node(instance)
5454 
5455         if image:
5456             instance.image_ref = shelved_image_ref
5457             self._delete_snapshot_of_shelved_instance(context, instance,
5458                                                       image['id'])
5459 
5460         self._unshelve_instance_key_restore(instance, scrubbed_keys)
5461         self._update_instance_after_spawn(context, instance)
5462         # Delete system_metadata for a shelved instance
5463         compute_utils.remove_shelved_keys_from_system_metadata(instance)
5464 
5465         instance.save(expected_task_state=task_states.SPAWNING)
5466         self._update_scheduler_instance_info(context, instance)
5467         self._notify_about_instance_usage(context, instance, 'unshelve.end')
5468         compute_utils.notify_about_instance_action(context, instance,
5469                 self.host, action=fields.NotificationAction.UNSHELVE,
5470                 phase=fields.NotificationPhase.END, bdms=bdms)
5471 
5472     @messaging.expected_exceptions(NotImplementedError)
5473     @wrap_instance_fault
5474     def reset_network(self, context, instance):
5475         """Reset networking on the given instance."""
5476         LOG.debug('Reset network', instance=instance)
5477         self.driver.reset_network(instance)
5478 
5479     def _inject_network_info(self, context, instance, network_info):
5480         """Inject network info for the given instance."""
5481         LOG.debug('Inject network info', instance=instance)
5482         LOG.debug('network_info to inject: |%s|', network_info,
5483                   instance=instance)
5484 
5485         self.driver.inject_network_info(instance,
5486                                         network_info)
5487 
5488     @wrap_instance_fault
5489     def inject_network_info(self, context, instance):
5490         """Inject network info, but don't return the info."""
5491         network_info = self.network_api.get_instance_nw_info(context, instance)
5492         self._inject_network_info(context, instance, network_info)
5493 
5494     @messaging.expected_exceptions(NotImplementedError,
5495                                    exception.ConsoleNotAvailable,
5496                                    exception.InstanceNotFound)
5497     @wrap_exception()
5498     @wrap_instance_fault
5499     def get_console_output(self, context, instance, tail_length):
5500         """Send the console output for the given instance."""
5501         context = context.elevated()
5502         LOG.info("Get console output", instance=instance)
5503         output = self.driver.get_console_output(context, instance)
5504 
5505         if type(output) is six.text_type:
5506             output = six.b(output)
5507 
5508         if tail_length is not None:
5509             output = self._tail_log(output, tail_length)
5510 
5511         return output.decode('ascii', 'replace')
5512 
5513     def _tail_log(self, log, length):
5514         try:
5515             length = int(length)
5516         except ValueError:
5517             length = 0
5518 
5519         if length == 0:
5520             return b''
5521         else:
5522             return b'\n'.join(log.split(b'\n')[-int(length):])
5523 
5524     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5525                                    exception.InstanceNotReady,
5526                                    exception.InstanceNotFound,
5527                                    exception.ConsoleTypeUnavailable,
5528                                    NotImplementedError)
5529     @wrap_exception()
5530     @wrap_instance_fault
5531     def get_vnc_console(self, context, console_type, instance):
5532         """Return connection information for a vnc console."""
5533         context = context.elevated()
5534         LOG.debug("Getting vnc console", instance=instance)
5535 
5536         if not CONF.vnc.enabled:
5537             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5538 
5539         if console_type == 'novnc':
5540             # For essex, novncproxy_base_url must include the full path
5541             # including the html file (like http://myhost/vnc_auto.html)
5542             access_url_base = CONF.vnc.novncproxy_base_url
5543         elif console_type == 'xvpvnc':
5544             access_url_base = CONF.vnc.xvpvncproxy_base_url
5545         else:
5546             raise exception.ConsoleTypeInvalid(console_type=console_type)
5547 
5548         try:
5549             # Retrieve connect info from driver, and then decorate with our
5550             # access info token
5551             console = self.driver.get_vnc_console(context, instance)
5552             console_auth = objects.ConsoleAuthToken(
5553                 context=context,
5554                 console_type=console_type,
5555                 host=console.host,
5556                 port=console.port,
5557                 internal_access_path=console.internal_access_path,
5558                 instance_uuid=instance.uuid,
5559                 access_url_base=access_url_base,
5560             )
5561             console_auth.authorize(CONF.consoleauth.token_ttl)
5562             connect_info = console.get_connection_info(
5563                 console_auth.token, console_auth.access_url)
5564 
5565         except exception.InstanceNotFound:
5566             if instance.vm_state != vm_states.BUILDING:
5567                 raise
5568             raise exception.InstanceNotReady(instance_id=instance.uuid)
5569 
5570         return connect_info
5571 
5572     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5573                                    exception.InstanceNotReady,
5574                                    exception.InstanceNotFound,
5575                                    exception.ConsoleTypeUnavailable,
5576                                    NotImplementedError)
5577     @wrap_exception()
5578     @wrap_instance_fault
5579     def get_spice_console(self, context, console_type, instance):
5580         """Return connection information for a spice console."""
5581         context = context.elevated()
5582         LOG.debug("Getting spice console", instance=instance)
5583 
5584         if not CONF.spice.enabled:
5585             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5586 
5587         if console_type != 'spice-html5':
5588             raise exception.ConsoleTypeInvalid(console_type=console_type)
5589 
5590         try:
5591             # Retrieve connect info from driver, and then decorate with our
5592             # access info token
5593             console = self.driver.get_spice_console(context, instance)
5594             console_auth = objects.ConsoleAuthToken(
5595                 context=context,
5596                 console_type=console_type,
5597                 host=console.host,
5598                 port=console.port,
5599                 internal_access_path=console.internal_access_path,
5600                 instance_uuid=instance.uuid,
5601                 access_url_base=CONF.spice.html5proxy_base_url,
5602             )
5603             console_auth.authorize(CONF.consoleauth.token_ttl)
5604             connect_info = console.get_connection_info(
5605                 console_auth.token, console_auth.access_url)
5606 
5607         except exception.InstanceNotFound:
5608             if instance.vm_state != vm_states.BUILDING:
5609                 raise
5610             raise exception.InstanceNotReady(instance_id=instance.uuid)
5611 
5612         return connect_info
5613 
5614     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5615                                    exception.InstanceNotReady,
5616                                    exception.InstanceNotFound,
5617                                    exception.ConsoleTypeUnavailable,
5618                                    NotImplementedError)
5619     @wrap_exception()
5620     @wrap_instance_fault
5621     def get_rdp_console(self, context, console_type, instance):
5622         """Return connection information for a RDP console."""
5623         context = context.elevated()
5624         LOG.debug("Getting RDP console", instance=instance)
5625 
5626         if not CONF.rdp.enabled:
5627             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5628 
5629         if console_type != 'rdp-html5':
5630             raise exception.ConsoleTypeInvalid(console_type=console_type)
5631 
5632         try:
5633             # Retrieve connect info from driver, and then decorate with our
5634             # access info token
5635             console = self.driver.get_rdp_console(context, instance)
5636             console_auth = objects.ConsoleAuthToken(
5637                 context=context,
5638                 console_type=console_type,
5639                 host=console.host,
5640                 port=console.port,
5641                 internal_access_path=console.internal_access_path,
5642                 instance_uuid=instance.uuid,
5643                 access_url_base=CONF.rdp.html5_proxy_base_url,
5644             )
5645             console_auth.authorize(CONF.consoleauth.token_ttl)
5646             connect_info = console.get_connection_info(
5647                 console_auth.token, console_auth.access_url)
5648 
5649         except exception.InstanceNotFound:
5650             if instance.vm_state != vm_states.BUILDING:
5651                 raise
5652             raise exception.InstanceNotReady(instance_id=instance.uuid)
5653 
5654         return connect_info
5655 
5656     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5657                                    exception.InstanceNotReady,
5658                                    exception.InstanceNotFound,
5659                                    exception.ConsoleTypeUnavailable,
5660                                    NotImplementedError)
5661     @wrap_exception()
5662     @wrap_instance_fault
5663     def get_mks_console(self, context, console_type, instance):
5664         """Return connection information for a MKS console."""
5665         context = context.elevated()
5666         LOG.debug("Getting MKS console", instance=instance)
5667 
5668         if not CONF.mks.enabled:
5669             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5670 
5671         if console_type != 'webmks':
5672             raise exception.ConsoleTypeInvalid(console_type=console_type)
5673 
5674         try:
5675             # Retrieve connect info from driver, and then decorate with our
5676             # access info token
5677             console = self.driver.get_mks_console(context, instance)
5678             console_auth = objects.ConsoleAuthToken(
5679                 context=context,
5680                 console_type=console_type,
5681                 host=console.host,
5682                 port=console.port,
5683                 internal_access_path=console.internal_access_path,
5684                 instance_uuid=instance.uuid,
5685                 access_url_base=CONF.mks.mksproxy_base_url,
5686             )
5687             console_auth.authorize(CONF.consoleauth.token_ttl)
5688             connect_info = console.get_connection_info(
5689                 console_auth.token, console_auth.access_url)
5690 
5691         except exception.InstanceNotFound:
5692             if instance.vm_state != vm_states.BUILDING:
5693                 raise
5694             raise exception.InstanceNotReady(instance_id=instance.uuid)
5695 
5696         return connect_info
5697 
5698     @messaging.expected_exceptions(
5699         exception.ConsoleTypeInvalid,
5700         exception.InstanceNotReady,
5701         exception.InstanceNotFound,
5702         exception.ConsoleTypeUnavailable,
5703         exception.SocketPortRangeExhaustedException,
5704         exception.ImageSerialPortNumberInvalid,
5705         exception.ImageSerialPortNumberExceedFlavorValue,
5706         NotImplementedError)
5707     @wrap_exception()
5708     @wrap_instance_fault
5709     def get_serial_console(self, context, console_type, instance):
5710         """Returns connection information for a serial console."""
5711 
5712         LOG.debug("Getting serial console", instance=instance)
5713 
5714         if not CONF.serial_console.enabled:
5715             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5716 
5717         context = context.elevated()
5718 
5719         try:
5720             # Retrieve connect info from driver, and then decorate with our
5721             # access info token
5722             console = self.driver.get_serial_console(context, instance)
5723             console_auth = objects.ConsoleAuthToken(
5724                 context=context,
5725                 console_type=console_type,
5726                 host=console.host,
5727                 port=console.port,
5728                 internal_access_path=console.internal_access_path,
5729                 instance_uuid=instance.uuid,
5730                 access_url_base=CONF.serial_console.base_url,
5731             )
5732             console_auth.authorize(CONF.consoleauth.token_ttl)
5733             connect_info = console.get_connection_info(
5734                 console_auth.token, console_auth.access_url)
5735 
5736         except exception.InstanceNotFound:
5737             if instance.vm_state != vm_states.BUILDING:
5738                 raise
5739             raise exception.InstanceNotReady(instance_id=instance.uuid)
5740 
5741         return connect_info
5742 
5743     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5744                                    exception.InstanceNotReady,
5745                                    exception.InstanceNotFound)
5746     @wrap_exception()
5747     @wrap_instance_fault
5748     def validate_console_port(self, ctxt, instance, port, console_type):
5749         if console_type == "spice-html5":
5750             console_info = self.driver.get_spice_console(ctxt, instance)
5751         elif console_type == "rdp-html5":
5752             console_info = self.driver.get_rdp_console(ctxt, instance)
5753         elif console_type == "serial":
5754             console_info = self.driver.get_serial_console(ctxt, instance)
5755         elif console_type == "webmks":
5756             console_info = self.driver.get_mks_console(ctxt, instance)
5757         else:
5758             console_info = self.driver.get_vnc_console(ctxt, instance)
5759 
5760         # Some drivers may return an int on console_info.port but the port
5761         # variable in this method is a string, so cast to be sure we are
5762         # comparing the correct types.
5763         return str(console_info.port) == port
5764 
5765     @wrap_exception()
5766     @reverts_task_state
5767     @wrap_instance_fault
5768     def reserve_block_device_name(self, context, instance, device,
5769                                   volume_id, disk_bus, device_type, tag,
5770                                   multiattach):
5771         if (tag and not
5772                 self.driver.capabilities.get('supports_tagged_attach_volume',
5773                                              False)):
5774             raise exception.VolumeTaggedAttachNotSupported()
5775 
5776         if (multiattach and not
5777                 self.driver.capabilities.get('supports_multiattach', False)):
5778             raise exception.MultiattachNotSupportedByVirtDriver(
5779                 volume_id=volume_id)
5780 
5781         @utils.synchronized(instance.uuid)
5782         def do_reserve():
5783             bdms = (
5784                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5785                     context, instance.uuid))
5786 
5787             # NOTE(ndipanov): We need to explicitly set all the fields on the
5788             #                 object so that obj_load_attr does not fail
5789             new_bdm = objects.BlockDeviceMapping(
5790                     context=context,
5791                     source_type='volume', destination_type='volume',
5792                     instance_uuid=instance.uuid, boot_index=None,
5793                     volume_id=volume_id,
5794                     device_name=device, guest_format=None,
5795                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5796 
5797             new_bdm.device_name = self._get_device_name_for_instance(
5798                     instance, bdms, new_bdm)
5799 
5800             # NOTE(vish): create bdm here to avoid race condition
5801             new_bdm.create()
5802             return new_bdm
5803 
5804         return do_reserve()
5805 
5806     @wrap_exception()
5807     @wrap_instance_event(prefix='compute')
5808     @wrap_instance_fault
5809     def attach_volume(self, context, instance, bdm):
5810         """Attach a volume to an instance."""
5811         driver_bdm = driver_block_device.convert_volume(bdm)
5812 
5813         @utils.synchronized(instance.uuid)
5814         def do_attach_volume(context, instance, driver_bdm):
5815             try:
5816                 return self._attach_volume(context, instance, driver_bdm)
5817             except Exception:
5818                 with excutils.save_and_reraise_exception():
5819                     bdm.destroy()
5820 
5821         do_attach_volume(context, instance, driver_bdm)
5822 
5823     def _attach_volume(self, context, instance, bdm):
5824         context = context.elevated()
5825         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5826                  {'volume_id': bdm.volume_id,
5827                   'mountpoint': bdm['mount_device']},
5828                  instance=instance)
5829         compute_utils.notify_about_volume_attach_detach(
5830             context, instance, self.host,
5831             action=fields.NotificationAction.VOLUME_ATTACH,
5832             phase=fields.NotificationPhase.START,
5833             volume_id=bdm.volume_id)
5834         try:
5835             bdm.attach(context, instance, self.volume_api, self.driver,
5836                        do_driver_attach=True)
5837         except Exception as e:
5838             with excutils.save_and_reraise_exception():
5839                 LOG.exception("Failed to attach %(volume_id)s "
5840                               "at %(mountpoint)s",
5841                               {'volume_id': bdm.volume_id,
5842                                'mountpoint': bdm['mount_device']},
5843                               instance=instance)
5844                 if bdm['attachment_id']:
5845                     # Try to delete the attachment to make the volume
5846                     # available again. Note that DriverVolumeBlockDevice
5847                     # may have already deleted the attachment so ignore
5848                     # VolumeAttachmentNotFound.
5849                     try:
5850                         self.volume_api.attachment_delete(
5851                             context, bdm['attachment_id'])
5852                     except exception.VolumeAttachmentNotFound as exc:
5853                         LOG.debug('Ignoring VolumeAttachmentNotFound: %s',
5854                                   exc, instance=instance)
5855                 else:
5856                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5857                 tb = traceback.format_exc()
5858                 compute_utils.notify_about_volume_attach_detach(
5859                     context, instance, self.host,
5860                     action=fields.NotificationAction.VOLUME_ATTACH,
5861                     phase=fields.NotificationPhase.ERROR,
5862                     exception=e,
5863                     volume_id=bdm.volume_id, tb=tb)
5864 
5865         info = {'volume_id': bdm.volume_id}
5866         self._notify_about_instance_usage(
5867             context, instance, "volume.attach", extra_usage_info=info)
5868         compute_utils.notify_about_volume_attach_detach(
5869             context, instance, self.host,
5870             action=fields.NotificationAction.VOLUME_ATTACH,
5871             phase=fields.NotificationPhase.END,
5872             volume_id=bdm.volume_id)
5873 
5874     def _notify_volume_usage_detach(self, context, instance, bdm):
5875         if CONF.volume_usage_poll_interval <= 0:
5876             return
5877 
5878         mp = bdm.device_name
5879         # Handle bootable volumes which will not contain /dev/
5880         if '/dev/' in mp:
5881             mp = mp[5:]
5882         try:
5883             vol_stats = self.driver.block_stats(instance, mp)
5884             if vol_stats is None:
5885                 return
5886         except NotImplementedError:
5887             return
5888 
5889         LOG.debug("Updating volume usage cache with totals", instance=instance)
5890         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5891         vol_usage = objects.VolumeUsage(context)
5892         vol_usage.volume_id = bdm.volume_id
5893         vol_usage.instance_uuid = instance.uuid
5894         vol_usage.project_id = instance.project_id
5895         vol_usage.user_id = instance.user_id
5896         vol_usage.availability_zone = instance.availability_zone
5897         vol_usage.curr_reads = rd_req
5898         vol_usage.curr_read_bytes = rd_bytes
5899         vol_usage.curr_writes = wr_req
5900         vol_usage.curr_write_bytes = wr_bytes
5901         vol_usage.save(update_totals=True)
5902         self.notifier.info(context, 'volume.usage', vol_usage.to_dict())
5903         compute_utils.notify_about_volume_usage(context, vol_usage, self.host)
5904 
5905     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5906                        attachment_id=None):
5907         """Detach a volume from an instance.
5908 
5909         :param context: security context
5910         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5911         :param instance: the Instance object to detach the volume from
5912         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5913                             as deleted. Disabling this is useful for operations
5914                             like rebuild, when we don't want to destroy BDM
5915         :param attachment_id: The volume attachment_id for the given instance
5916                               and volume.
5917         """
5918         volume_id = bdm.volume_id
5919         compute_utils.notify_about_volume_attach_detach(
5920             context, instance, self.host,
5921             action=fields.NotificationAction.VOLUME_DETACH,
5922             phase=fields.NotificationPhase.START,
5923             volume_id=volume_id)
5924 
5925         self._notify_volume_usage_detach(context, instance, bdm)
5926 
5927         LOG.info('Detaching volume %(volume_id)s',
5928                  {'volume_id': volume_id}, instance=instance)
5929 
5930         driver_bdm = driver_block_device.convert_volume(bdm)
5931         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5932                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5933 
5934         info = dict(volume_id=volume_id)
5935         self._notify_about_instance_usage(
5936             context, instance, "volume.detach", extra_usage_info=info)
5937         compute_utils.notify_about_volume_attach_detach(
5938             context, instance, self.host,
5939             action=fields.NotificationAction.VOLUME_DETACH,
5940             phase=fields.NotificationPhase.END,
5941             volume_id=volume_id)
5942 
5943         if 'tag' in bdm and bdm.tag:
5944             self._delete_disk_metadata(instance, bdm)
5945         if destroy_bdm:
5946             bdm.destroy()
5947 
5948     def _delete_disk_metadata(self, instance, bdm):
5949         for device in instance.device_metadata.devices:
5950             if isinstance(device, objects.DiskMetadata):
5951                 if 'serial' in device:
5952                     if device.serial == bdm.volume_id:
5953                         instance.device_metadata.devices.remove(device)
5954                         instance.save()
5955                         break
5956                 else:
5957                     # NOTE(artom) We log the entire device object because all
5958                     # fields are nullable and may not be set
5959                     LOG.warning('Unable to determine whether to clean up '
5960                                 'device metadata for disk %s', device,
5961                                 instance=instance)
5962 
5963     @wrap_exception()
5964     @wrap_instance_event(prefix='compute')
5965     @wrap_instance_fault
5966     def detach_volume(self, context, volume_id, instance, attachment_id):
5967         """Detach a volume from an instance.
5968 
5969         :param context: security context
5970         :param volume_id: the volume id
5971         :param instance: the Instance object to detach the volume from
5972         :param attachment_id: The volume attachment_id for the given instance
5973                               and volume.
5974 
5975         """
5976         @utils.synchronized(instance.uuid)
5977         def do_detach_volume(context, volume_id, instance, attachment_id):
5978             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5979                     context, volume_id, instance.uuid)
5980             self._detach_volume(context, bdm, instance,
5981                                 attachment_id=attachment_id)
5982 
5983         do_detach_volume(context, volume_id, instance, attachment_id)
5984 
5985     def _init_volume_connection(self, context, new_volume,
5986                                 old_volume_id, connector, bdm,
5987                                 new_attachment_id, mountpoint):
5988         new_volume_id = new_volume['id']
5989         if new_attachment_id is None:
5990             # We're dealing with an old-style attachment so initialize the
5991             # connection so we can get the connection_info.
5992             new_cinfo = self.volume_api.initialize_connection(context,
5993                                                               new_volume_id,
5994                                                               connector)
5995         else:
5996             # Check for multiattach on the new volume and if True, check to
5997             # see if the virt driver supports multiattach.
5998             # TODO(mriedem): This is copied from DriverVolumeBlockDevice
5999             # and should be consolidated into some common code at some point.
6000             vol_multiattach = new_volume.get('multiattach', False)
6001             virt_multiattach = self.driver.capabilities.get(
6002                 'supports_multiattach', False)
6003             if vol_multiattach and not virt_multiattach:
6004                 raise exception.MultiattachNotSupportedByVirtDriver(
6005                     volume_id=new_volume_id)
6006 
6007             # This is a new style attachment and the API created the new
6008             # volume attachment and passed the id to the compute over RPC.
6009             # At this point we need to update the new volume attachment with
6010             # the host connector, which will give us back the new attachment
6011             # connection_info.
6012             new_cinfo = self.volume_api.attachment_update(
6013                 context, new_attachment_id, connector,
6014                 mountpoint)['connection_info']
6015 
6016             if vol_multiattach:
6017                 # This will be used by the volume driver to determine the
6018                 # proper disk configuration.
6019                 new_cinfo['multiattach'] = True
6020 
6021         old_cinfo = jsonutils.loads(bdm['connection_info'])
6022         if old_cinfo and 'serial' not in old_cinfo:
6023             old_cinfo['serial'] = old_volume_id
6024         # NOTE(lyarwood): serial is not always present in the returned
6025         # connection_info so set it if it is missing as we do in
6026         # DriverVolumeBlockDevice.attach().
6027         if 'serial' not in new_cinfo:
6028             new_cinfo['serial'] = new_volume_id
6029         return (old_cinfo, new_cinfo)
6030 
6031     def _swap_volume(self, context, instance, bdm, connector,
6032                      old_volume_id, new_volume, resize_to,
6033                      new_attachment_id, is_cinder_migration):
6034         new_volume_id = new_volume['id']
6035         mountpoint = bdm['device_name']
6036         failed = False
6037         new_cinfo = None
6038         try:
6039             old_cinfo, new_cinfo = self._init_volume_connection(
6040                 context, new_volume, old_volume_id, connector,
6041                 bdm, new_attachment_id, mountpoint)
6042             # NOTE(lyarwood): The Libvirt driver, the only virt driver
6043             # currently implementing swap_volume, will modify the contents of
6044             # new_cinfo when connect_volume is called. This is then saved to
6045             # the BDM in swap_volume for future use outside of this flow.
6046             msg = ("swap_volume: Calling driver volume swap with "
6047                    "connection infos: new: %(new_cinfo)s; "
6048                    "old: %(old_cinfo)s" %
6049                    {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo})
6050             # Both new and old info might contain password
6051             LOG.debug(strutils.mask_password(msg), instance=instance)
6052 
6053             self.driver.swap_volume(context, old_cinfo, new_cinfo, instance,
6054                                     mountpoint, resize_to)
6055             if new_attachment_id:
6056                 self.volume_api.attachment_complete(context, new_attachment_id)
6057             msg = ("swap_volume: Driver volume swap returned, new "
6058                    "connection_info is now : %(new_cinfo)s" %
6059                    {'new_cinfo': new_cinfo})
6060             LOG.debug(strutils.mask_password(msg))
6061         except Exception as ex:
6062             failed = True
6063             with excutils.save_and_reraise_exception():
6064                 tb = traceback.format_exc()
6065                 compute_utils.notify_about_volume_swap(
6066                     context, instance, self.host,
6067                     fields.NotificationPhase.ERROR,
6068                     old_volume_id, new_volume_id, ex, tb)
6069                 if new_cinfo:
6070                     msg = ("Failed to swap volume %(old_volume_id)s "
6071                            "for %(new_volume_id)s")
6072                     LOG.exception(msg, {'old_volume_id': old_volume_id,
6073                                         'new_volume_id': new_volume_id},
6074                                   instance=instance)
6075                 else:
6076                     msg = ("Failed to connect to volume %(volume_id)s "
6077                            "with volume at %(mountpoint)s")
6078                     LOG.exception(msg, {'volume_id': new_volume_id,
6079                                         'mountpoint': bdm['device_name']},
6080                                   instance=instance)
6081 
6082                 # The API marked the volume as 'detaching' for the old volume
6083                 # so we need to roll that back so the volume goes back to
6084                 # 'in-use' state.
6085                 self.volume_api.roll_detaching(context, old_volume_id)
6086 
6087                 if new_attachment_id is None:
6088                     # The API reserved the new volume so it would be in
6089                     # 'attaching' status, so we need to unreserve it so it
6090                     # goes back to 'available' status.
6091                     self.volume_api.unreserve_volume(context, new_volume_id)
6092                 else:
6093                     # This is a new style attachment for the new volume, which
6094                     # was created in the API. We just need to delete it here
6095                     # to put the new volume back into 'available' status.
6096                     self.volume_api.attachment_delete(
6097                         context, new_attachment_id)
6098         finally:
6099             # TODO(mriedem): This finally block is terribly confusing and is
6100             # trying to do too much. We should consider removing the finally
6101             # block and move whatever needs to happen on success and failure
6102             # into the blocks above for clarity, even if it means a bit of
6103             # redundant code.
6104             conn_volume = new_volume_id if failed else old_volume_id
6105             if new_cinfo:
6106                 LOG.debug("swap_volume: removing Cinder connection "
6107                           "for volume %(volume)s", {'volume': conn_volume},
6108                           instance=instance)
6109                 if bdm.attachment_id is None:
6110                     # This is the pre-3.44 flow for new-style volume
6111                     # attachments so just terminate the connection.
6112                     self.volume_api.terminate_connection(context,
6113                                                          conn_volume,
6114                                                          connector)
6115                 else:
6116                     # This is a new style volume attachment. If we failed, then
6117                     # the new attachment was already deleted above in the
6118                     # exception block and we have nothing more to do here. If
6119                     # swap_volume was successful in the driver, then we need to
6120                     # "detach" the original attachment by deleting it.
6121                     if not failed:
6122                         self.volume_api.attachment_delete(
6123                             context, bdm.attachment_id)
6124 
6125             # Need to make some decisions based on whether this was
6126             # a Cinder initiated migration or not. The callback to
6127             # migration completion isn't needed in the case of a
6128             # nova initiated simple swap of two volume
6129             # "volume-update" call so skip that. The new attachment
6130             # scenarios will give us a new attachment record and
6131             # that's what we want.
6132             if bdm.attachment_id and not is_cinder_migration:
6133                 # we don't callback to cinder
6134                 comp_ret = {'save_volume_id': new_volume_id}
6135             else:
6136                 # NOTE(lyarwood): The following call to
6137                 # os-migrate-volume-completion returns a dict containing
6138                 # save_volume_id, this volume id has two possible values :
6139                 # 1. old_volume_id if we are migrating (retyping) volumes
6140                 # 2. new_volume_id if we are swapping between two existing
6141                 #    volumes
6142                 # This volume id is later used to update the volume_id and
6143                 # connection_info['serial'] of the BDM.
6144                 comp_ret = self.volume_api.migrate_volume_completion(
6145                                                           context,
6146                                                           old_volume_id,
6147                                                           new_volume_id,
6148                                                           error=failed)
6149                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
6150                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
6151                           instance=instance)
6152 
6153         return (comp_ret, new_cinfo)
6154 
6155     @wrap_exception()
6156     @wrap_instance_event(prefix='compute')
6157     @wrap_instance_fault
6158     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
6159                     new_attachment_id):
6160         """Swap volume for an instance."""
6161         context = context.elevated()
6162 
6163         compute_utils.notify_about_volume_swap(
6164             context, instance, self.host,
6165             fields.NotificationPhase.START,
6166             old_volume_id, new_volume_id)
6167 
6168         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
6169                 context, old_volume_id, instance.uuid)
6170         connector = self.driver.get_volume_connector(instance)
6171 
6172         resize_to = 0
6173         old_volume = self.volume_api.get(context, old_volume_id)
6174         # Yes this is a tightly-coupled state check of what's going on inside
6175         # cinder, but we need this while we still support old (v1/v2) and
6176         # new style attachments (v3.44). Once we drop support for old style
6177         # attachments we could think about cleaning up the cinder-initiated
6178         # swap volume API flows.
6179         is_cinder_migration = False
6180         if 'migration_status' in old_volume:
6181             is_cinder_migration = old_volume['migration_status'] == 'migrating'
6182         old_vol_size = old_volume['size']
6183         new_volume = self.volume_api.get(context, new_volume_id)
6184         new_vol_size = new_volume['size']
6185         if new_vol_size > old_vol_size:
6186             resize_to = new_vol_size
6187 
6188         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
6189                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
6190                  instance=instance)
6191         comp_ret, new_cinfo = self._swap_volume(context,
6192                                                 instance,
6193                                                 bdm,
6194                                                 connector,
6195                                                 old_volume_id,
6196                                                 new_volume,
6197                                                 resize_to,
6198                                                 new_attachment_id,
6199                                                 is_cinder_migration)
6200 
6201         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
6202         # correct volume_id returned by Cinder.
6203         save_volume_id = comp_ret['save_volume_id']
6204         new_cinfo['serial'] = save_volume_id
6205         values = {
6206             'connection_info': jsonutils.dumps(new_cinfo),
6207             'source_type': 'volume',
6208             'destination_type': 'volume',
6209             'snapshot_id': None,
6210             'volume_id': save_volume_id,
6211             'no_device': None}
6212 
6213         if resize_to:
6214             values['volume_size'] = resize_to
6215 
6216         if new_attachment_id is not None:
6217             # This was a volume swap for a new-style attachment so we
6218             # need to update the BDM attachment_id for the new attachment.
6219             values['attachment_id'] = new_attachment_id
6220 
6221         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
6222                   "%(updates)s", {'volume_id': bdm.volume_id,
6223                                   'updates': values},
6224                   instance=instance)
6225         bdm.update(values)
6226         bdm.save()
6227 
6228         compute_utils.notify_about_volume_swap(
6229             context, instance, self.host,
6230             fields.NotificationPhase.END,
6231             old_volume_id, new_volume_id)
6232 
6233     @wrap_exception()
6234     def remove_volume_connection(self, context, volume_id, instance):
6235         """Remove the volume connection on this host
6236 
6237         Detach the volume from this instance on this host, and if this is
6238         the cinder v2 flow, call cinder to terminate the connection.
6239         """
6240         try:
6241             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
6242                     context, volume_id, instance.uuid)
6243             driver_bdm = driver_block_device.convert_volume(bdm)
6244             driver_bdm.driver_detach(context, instance,
6245                                      self.volume_api, self.driver)
6246             if bdm.attachment_id is None:
6247                 # cinder v2 api flow
6248                 connector = self.driver.get_volume_connector(instance)
6249                 self.volume_api.terminate_connection(context, volume_id,
6250                                                      connector)
6251         except exception.NotFound:
6252             pass
6253 
6254     def _deallocate_port_for_instance(self, context, instance, port_id,
6255                                       raise_on_failure=False):
6256         try:
6257             result = self.network_api.deallocate_port_for_instance(
6258                 context, instance, port_id)
6259             __, port_allocation = result
6260         except Exception as ex:
6261             with excutils.save_and_reraise_exception(
6262                     reraise=raise_on_failure):
6263                 LOG.warning('Failed to deallocate port %(port_id)s '
6264                             'for instance. Error: %(error)s',
6265                             {'port_id': port_id, 'error': ex},
6266                             instance=instance)
6267         else:
6268             if port_allocation:
6269                 # Deallocate the resources in placement that were used by the
6270                 # detached port.
6271                 try:
6272                     client = self.reportclient
6273                     client.remove_resources_from_instance_allocation(
6274                         context, instance.uuid, port_allocation)
6275                 except Exception as ex:
6276                     # We always raise here as it is not a race condition where
6277                     # somebody has already deleted the port we want to cleanup.
6278                     # Here we see that the port exists, the allocation exists,
6279                     # but we cannot clean it up so we will actually leak
6280                     # allocations.
6281                     with excutils.save_and_reraise_exception():
6282                         LOG.warning('Failed to remove resource allocation '
6283                                     'of port %(port_id)s for instance. Error: '
6284                                     '%(error)s',
6285                                     {'port_id': port_id, 'error': ex},
6286                                     instance=instance)
6287 
6288     @wrap_exception()
6289     @wrap_instance_event(prefix='compute')
6290     @wrap_instance_fault
6291     def attach_interface(self, context, instance, network_id, port_id,
6292                          requested_ip, tag):
6293         """Use hotplug to add an network adapter to an instance."""
6294         if not self.driver.capabilities.get('supports_attach_interface',
6295                                             False):
6296             raise exception.AttachInterfaceNotSupported(
6297                 instance_uuid=instance.uuid)
6298         if (tag and not
6299             self.driver.capabilities.get('supports_tagged_attach_interface',
6300                                          False)):
6301             raise exception.NetworkInterfaceTaggedAttachNotSupported()
6302 
6303         compute_utils.notify_about_instance_action(
6304             context, instance, self.host,
6305             action=fields.NotificationAction.INTERFACE_ATTACH,
6306             phase=fields.NotificationPhase.START)
6307 
6308         bind_host_id = self.driver.network_binding_host_id(context, instance)
6309         network_info = self.network_api.allocate_port_for_instance(
6310             context, instance, port_id, network_id, requested_ip,
6311             bind_host_id=bind_host_id, tag=tag)
6312         if len(network_info) != 1:
6313             LOG.error('allocate_port_for_instance returned %(ports)s '
6314                       'ports', {'ports': len(network_info)})
6315             # TODO(elod.illes): an instance.interface_attach.error notification
6316             # should be sent here
6317             raise exception.InterfaceAttachFailed(
6318                     instance_uuid=instance.uuid)
6319         image_meta = objects.ImageMeta.from_instance(instance)
6320 
6321         try:
6322             self.driver.attach_interface(context, instance, image_meta,
6323                                          network_info[0])
6324         except exception.NovaException as ex:
6325             port_id = network_info[0].get('id')
6326             LOG.warning("attach interface failed , try to deallocate "
6327                         "port %(port_id)s, reason: %(msg)s",
6328                         {'port_id': port_id, 'msg': ex},
6329                         instance=instance)
6330             self._deallocate_port_for_instance(context, instance, port_id)
6331 
6332             tb = traceback.format_exc()
6333             compute_utils.notify_about_instance_action(
6334                 context, instance, self.host,
6335                 action=fields.NotificationAction.INTERFACE_ATTACH,
6336                 phase=fields.NotificationPhase.ERROR,
6337                 exception=ex, tb=tb)
6338 
6339             raise exception.InterfaceAttachFailed(
6340                 instance_uuid=instance.uuid)
6341 
6342         compute_utils.notify_about_instance_action(
6343             context, instance, self.host,
6344             action=fields.NotificationAction.INTERFACE_ATTACH,
6345             phase=fields.NotificationPhase.END)
6346 
6347         return network_info[0]
6348 
6349     @wrap_exception()
6350     @wrap_instance_event(prefix='compute')
6351     @wrap_instance_fault
6352     def detach_interface(self, context, instance, port_id):
6353         """Detach a network adapter from an instance."""
6354         network_info = instance.info_cache.network_info
6355         condemned = None
6356         for vif in network_info:
6357             if vif['id'] == port_id:
6358                 condemned = vif
6359                 break
6360         if condemned is None:
6361             raise exception.PortNotFound(_("Port %s is not "
6362                                            "attached") % port_id)
6363 
6364         compute_utils.notify_about_instance_action(
6365             context, instance, self.host,
6366             action=fields.NotificationAction.INTERFACE_DETACH,
6367             phase=fields.NotificationPhase.START)
6368 
6369         try:
6370             self.driver.detach_interface(context, instance, condemned)
6371         except exception.NovaException as ex:
6372             # If the instance was deleted before the interface was detached,
6373             # just log it at debug.
6374             log_level = (logging.DEBUG
6375                          if isinstance(ex, exception.InstanceNotFound)
6376                          else logging.WARNING)
6377             LOG.log(log_level,
6378                     "Detach interface failed, port_id=%(port_id)s, reason: "
6379                     "%(msg)s", {'port_id': port_id, 'msg': ex},
6380                     instance=instance)
6381             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
6382         else:
6383             self._deallocate_port_for_instance(
6384                 context, instance, port_id, raise_on_failure=True)
6385 
6386         compute_utils.notify_about_instance_action(
6387             context, instance, self.host,
6388             action=fields.NotificationAction.INTERFACE_DETACH,
6389             phase=fields.NotificationPhase.END)
6390 
6391     def _get_compute_info(self, context, host):
6392         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
6393             context, host)
6394 
6395     @wrap_exception()
6396     def check_instance_shared_storage(self, ctxt, instance, data):
6397         """Check if the instance files are shared
6398 
6399         :param ctxt: security context
6400         :param instance: dict of instance data
6401         :param data: result of driver.check_instance_shared_storage_local
6402 
6403         Returns True if instance disks located on shared storage and
6404         False otherwise.
6405         """
6406         return self.driver.check_instance_shared_storage_remote(ctxt, data)
6407 
6408     @wrap_exception()
6409     @wrap_instance_event(prefix='compute')
6410     @wrap_instance_fault
6411     def check_can_live_migrate_destination(self, ctxt, instance,
6412                                            block_migration, disk_over_commit):
6413         """Check if it is possible to execute live migration.
6414 
6415         This runs checks on the destination host, and then calls
6416         back to the source host to check the results.
6417 
6418         :param context: security context
6419         :param instance: dict of instance data
6420         :param block_migration: if true, prepare for block migration
6421                                 if None, calculate it in driver
6422         :param disk_over_commit: if true, allow disk over commit
6423                                  if None, ignore disk usage checking
6424         :returns: a LiveMigrateData object (hypervisor-dependent)
6425         """
6426         src_compute_info = obj_base.obj_to_primitive(
6427             self._get_compute_info(ctxt, instance.host))
6428         dst_compute_info = obj_base.obj_to_primitive(
6429             self._get_compute_info(ctxt, CONF.host))
6430         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
6431             instance, src_compute_info, dst_compute_info,
6432             block_migration, disk_over_commit)
6433         LOG.debug('destination check data is %s', dest_check_data)
6434         try:
6435             migrate_data = self.compute_rpcapi.\
6436                                 check_can_live_migrate_source(ctxt, instance,
6437                                                               dest_check_data)
6438             # Create migrate_data vifs
6439             migrate_data.vifs = \
6440                 migrate_data_obj.VIFMigrateData.create_skeleton_migrate_vifs(
6441                     instance.get_network_info())
6442             # Claim PCI devices for VIFs on destination (if needed)
6443             port_id_to_pci = self._claim_pci_for_instance_vifs(ctxt, instance)
6444             # Update migrate VIFs with the newly claimed PCI devices
6445             self._update_migrate_vifs_profile_with_pci(migrate_data.vifs,
6446                                                        port_id_to_pci)
6447         finally:
6448             self.driver.cleanup_live_migration_destination_check(ctxt,
6449                     dest_check_data)
6450         return migrate_data
6451 
6452     @wrap_exception()
6453     @wrap_instance_event(prefix='compute')
6454     @wrap_instance_fault
6455     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
6456         """Check if it is possible to execute live migration.
6457 
6458         This checks if the live migration can succeed, based on the
6459         results from check_can_live_migrate_destination.
6460 
6461         :param ctxt: security context
6462         :param instance: dict of instance data
6463         :param dest_check_data: result of check_can_live_migrate_destination
6464         :returns: a LiveMigrateData object
6465         """
6466         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6467             ctxt, instance.uuid)
6468         is_volume_backed = compute_utils.is_volume_backed_instance(
6469             ctxt, instance, bdms)
6470         dest_check_data.is_volume_backed = is_volume_backed
6471         block_device_info = self._get_instance_block_device_info(
6472                             ctxt, instance, refresh_conn_info=False, bdms=bdms)
6473         result = self.driver.check_can_live_migrate_source(ctxt, instance,
6474                                                            dest_check_data,
6475                                                            block_device_info)
6476         LOG.debug('source check data is %s', result)
6477         return result
6478 
6479     @wrap_exception()
6480     @wrap_instance_event(prefix='compute')
6481     @wrap_instance_fault
6482     def pre_live_migration(self, context, instance, block_migration, disk,
6483                            migrate_data):
6484         """Preparations for live migration at dest host.
6485 
6486         :param context: security context
6487         :param instance: dict of instance data
6488         :param block_migration: if true, prepare for block migration
6489         :param disk: disk info of instance
6490         :param migrate_data: A dict or LiveMigrateData object holding data
6491                              required for live migration without shared
6492                              storage.
6493         :returns: migrate_data containing additional migration info
6494         """
6495         LOG.debug('pre_live_migration data is %s', migrate_data)
6496 
6497         migrate_data.old_vol_attachment_ids = {}
6498         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6499             context, instance.uuid)
6500         network_info = self.network_api.get_instance_nw_info(context, instance)
6501         self._notify_about_instance_usage(
6502             context, instance, "live_migration.pre.start",
6503             network_info=network_info)
6504         compute_utils.notify_about_instance_action(
6505             context, instance, self.host,
6506             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6507             phase=fields.NotificationPhase.START, bdms=bdms)
6508 
6509         connector = self.driver.get_volume_connector(instance)
6510         try:
6511             for bdm in bdms:
6512                 if bdm.is_volume and bdm.attachment_id is not None:
6513                     # This bdm uses the new cinder v3.44 API.
6514                     # We will create a new attachment for this
6515                     # volume on this migration destination host. The old
6516                     # attachment will be deleted on the source host
6517                     # when the migration succeeds. The old attachment_id
6518                     # is stored in dict with the key being the bdm.volume_id
6519                     # so it can be restored on rollback.
6520                     #
6521                     # Also note that attachment_update is not needed as we
6522                     # are providing the connector in the create call.
6523                     attach_ref = self.volume_api.attachment_create(
6524                         context, bdm.volume_id, bdm.instance_uuid,
6525                         connector=connector, mountpoint=bdm.device_name)
6526 
6527                     # save current attachment so we can detach it on success,
6528                     # or restore it on a rollback.
6529                     # NOTE(mdbooth): This data is no longer used by the source
6530                     # host since change I0390c9ff. We can't remove it until we
6531                     # are sure the source host has been upgraded.
6532                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
6533                         bdm.attachment_id
6534 
6535                     # update the bdm with the new attachment_id.
6536                     bdm.attachment_id = attach_ref['id']
6537                     bdm.save()
6538 
6539             block_device_info = self._get_instance_block_device_info(
6540                                 context, instance, refresh_conn_info=True,
6541                                 bdms=bdms)
6542 
6543             # The driver pre_live_migration will plug vifs on the host. We call
6544             # plug_vifs before calling ensure_filtering_rules_for_instance, to
6545             # ensure bridge is set up.
6546             migrate_data = self.driver.pre_live_migration(context,
6547                                            instance,
6548                                            block_device_info,
6549                                            network_info,
6550                                            disk,
6551                                            migrate_data)
6552             LOG.debug('driver pre_live_migration data is %s', migrate_data)
6553             # driver.pre_live_migration is what plugs vifs on the destination
6554             # host so now we can set the wait_for_vif_plugged flag in the
6555             # migrate_data object which the source compute will use to
6556             # determine if it should wait for a 'network-vif-plugged' event
6557             # from neutron before starting the actual guest transfer in the
6558             # hypervisor
6559             migrate_data.wait_for_vif_plugged = (
6560                 CONF.compute.live_migration_wait_for_vif_plug)
6561 
6562             # NOTE(tr3buchet): setup networks on destination host
6563             self.network_api.setup_networks_on_host(context, instance,
6564                                                              self.host)
6565 
6566             # Creating filters to hypervisors and firewalls.
6567             # An example is that nova-instance-instance-xxx,
6568             # which is written to libvirt.xml(Check "virsh nwfilter-list")
6569             # This nwfilter is necessary on the destination host.
6570             # In addition, this method is creating filtering rule
6571             # onto destination host.
6572             self.driver.ensure_filtering_rules_for_instance(instance,
6573                                                 network_info)
6574         except Exception:
6575             # If we raise, migrate_data with the updated attachment ids
6576             # will not be returned to the source host for rollback.
6577             # So we need to rollback new attachments here.
6578             with excutils.save_and_reraise_exception():
6579                 old_attachments = migrate_data.old_vol_attachment_ids
6580                 for bdm in bdms:
6581                     if (bdm.is_volume and bdm.attachment_id is not None and
6582                             bdm.volume_id in old_attachments):
6583                         self.volume_api.attachment_delete(context,
6584                                                           bdm.attachment_id)
6585                         bdm.attachment_id = old_attachments[bdm.volume_id]
6586                         bdm.save()
6587 
6588         # Volume connections are complete, tell cinder that all the
6589         # attachments have completed.
6590         for bdm in bdms:
6591             if bdm.is_volume and bdm.attachment_id is not None:
6592                 self.volume_api.attachment_complete(context,
6593                                                     bdm.attachment_id)
6594 
6595         self._notify_about_instance_usage(
6596                      context, instance, "live_migration.pre.end",
6597                      network_info=network_info)
6598         compute_utils.notify_about_instance_action(
6599             context, instance, self.host,
6600             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6601             phase=fields.NotificationPhase.END, bdms=bdms)
6602 
6603         LOG.debug('pre_live_migration result data is %s', migrate_data)
6604         return migrate_data
6605 
6606     @staticmethod
6607     def _neutron_failed_migration_callback(event_name, instance):
6608         msg = ('Neutron reported failure during migration '
6609                'with %(event)s for instance %(uuid)s')
6610         msg_args = {'event': event_name, 'uuid': instance.uuid}
6611         if CONF.vif_plugging_is_fatal:
6612             raise exception.VirtualInterfacePlugException(msg % msg_args)
6613         LOG.error(msg, msg_args)
6614 
6615     @staticmethod
6616     def _get_neutron_events_for_live_migration(instance):
6617         # We don't generate events if CONF.vif_plugging_timeout=0
6618         # meaning that the operator disabled using them.
6619         if CONF.vif_plugging_timeout and utils.is_neutron():
6620             return [('network-vif-plugged', vif['id'])
6621                     for vif in instance.get_network_info()]
6622         else:
6623             return []
6624 
6625     def _cleanup_pre_live_migration(self, context, dest, instance,
6626                                     migration, migrate_data, source_bdms):
6627         """Helper method for when pre_live_migration fails
6628 
6629         Sets the migration status to "error" and rolls back the live migration
6630         setup on the destination host.
6631 
6632         :param context: The user request context.
6633         :type context: nova.context.RequestContext
6634         :param dest: The live migration destination hostname.
6635         :type dest: str
6636         :param instance: The instance being live migrated.
6637         :type instance: nova.objects.Instance
6638         :param migration: The migration record tracking this live migration.
6639         :type migration: nova.objects.Migration
6640         :param migrate_data: Data about the live migration, populated from
6641                              the destination host.
6642         :type migrate_data: Subclass of nova.objects.LiveMigrateData
6643         :param source_bdms: BDMs prior to modification by the destination
6644                             compute host. Set by _do_live_migration and not
6645                             part of the callback interface, so this is never
6646                             None
6647         """
6648         self._set_migration_status(migration, 'error')
6649         # Make sure we set this for _rollback_live_migration()
6650         # so it can find it, as expected if it was called later
6651         migrate_data.migration = migration
6652         self._rollback_live_migration(context, instance, dest,
6653                                       migrate_data=migrate_data,
6654                                       source_bdms=source_bdms)
6655 
6656     def _do_live_migration(self, context, dest, instance, block_migration,
6657                            migration, migrate_data):
6658         # NOTE(danms): We should enhance the RT to account for migrations
6659         # and use the status field to denote when the accounting has been
6660         # done on source/destination. For now, this is just here for status
6661         # reporting
6662         self._set_migration_status(migration, 'preparing')
6663         source_bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6664                 context, instance.uuid)
6665 
6666         class _BreakWaitForInstanceEvent(Exception):
6667             """Used as a signal to stop waiting for the network-vif-plugged
6668             event when we discover that
6669             [compute]/live_migration_wait_for_vif_plug is not set on the
6670             destination.
6671             """
6672             pass
6673 
6674         events = self._get_neutron_events_for_live_migration(instance)
6675         try:
6676             if ('block_migration' in migrate_data and
6677                     migrate_data.block_migration):
6678                 block_device_info = self._get_instance_block_device_info(
6679                     context, instance, bdms=source_bdms)
6680                 disk = self.driver.get_instance_disk_info(
6681                     instance, block_device_info=block_device_info)
6682             else:
6683                 disk = None
6684 
6685             deadline = CONF.vif_plugging_timeout
6686             error_cb = self._neutron_failed_migration_callback
6687             # In order to avoid a race with the vif plugging that the virt
6688             # driver does on the destination host, we register our events
6689             # to wait for before calling pre_live_migration. Then if the
6690             # dest host reports back that we shouldn't wait, we can break
6691             # out of the context manager using _BreakWaitForInstanceEvent.
6692             with self.virtapi.wait_for_instance_event(
6693                     instance, events, deadline=deadline,
6694                     error_callback=error_cb):
6695                 with timeutils.StopWatch() as timer:
6696                     migrate_data = self.compute_rpcapi.pre_live_migration(
6697                         context, instance,
6698                         block_migration, disk, dest, migrate_data)
6699                 LOG.info('Took %0.2f seconds for pre_live_migration on '
6700                          'destination host %s.',
6701                          timer.elapsed(), dest, instance=instance)
6702                 wait_for_vif_plugged = (
6703                     'wait_for_vif_plugged' in migrate_data and
6704                     migrate_data.wait_for_vif_plugged)
6705                 if events and not wait_for_vif_plugged:
6706                     raise _BreakWaitForInstanceEvent
6707         except _BreakWaitForInstanceEvent:
6708             if events:
6709                 LOG.debug('Not waiting for events after pre_live_migration: '
6710                           '%s. ', events, instance=instance)
6711             # This is a bit weird, but we need to clear sys.exc_info() so that
6712             # oslo.log formatting does not inadvertently use it later if an
6713             # error message is logged without an explicit exc_info. This is
6714             # only a problem with python 2.
6715             if six.PY2:
6716                 sys.exc_clear()
6717         except exception.VirtualInterfacePlugException:
6718             with excutils.save_and_reraise_exception():
6719                 LOG.exception('Failed waiting for network virtual interfaces '
6720                               'to be plugged on the destination host %s.',
6721                               dest, instance=instance)
6722                 self._cleanup_pre_live_migration(
6723                     context, dest, instance, migration, migrate_data,
6724                     source_bdms)
6725         except eventlet.timeout.Timeout:
6726             # We only get here if wait_for_vif_plugged is True which means
6727             # live_migration_wait_for_vif_plug=True on the destination host.
6728             msg = (
6729                 'Timed out waiting for events: %(events)s. If these timeouts '
6730                 'are a persistent issue it could mean the networking backend '
6731                 'on host %(dest)s does not support sending these events '
6732                 'unless there are port binding host changes which does not '
6733                 'happen at this point in the live migration process. You may '
6734                 'need to disable the live_migration_wait_for_vif_plug option '
6735                 'on host %(dest)s.')
6736             subs = {'events': events, 'dest': dest}
6737             LOG.warning(msg, subs, instance=instance)
6738             if CONF.vif_plugging_is_fatal:
6739                 self._cleanup_pre_live_migration(
6740                     context, dest, instance, migration, migrate_data,
6741                     source_bdms)
6742                 raise exception.MigrationError(reason=msg % subs)
6743         except Exception:
6744             with excutils.save_and_reraise_exception():
6745                 LOG.exception('Pre live migration failed at %s',
6746                               dest, instance=instance)
6747                 self._cleanup_pre_live_migration(
6748                     context, dest, instance, migration, migrate_data,
6749                     source_bdms)
6750 
6751         # Set migrate_data.migration because that is how _post_live_migration
6752         # and _rollback_live_migration get the migration object for cleanup.
6753         # Yes this is gross but changing the _post_live_migration and
6754         # _rollback_live_migration interfaces would also mean changing how the
6755         # virt drivers call them from the driver.live_migration method, i.e.
6756         # we would have to pass the migration object through the driver (or
6757         # consider using a partial but some do not like that pattern).
6758         migrate_data.migration = migration
6759 
6760         # NOTE(Kevin_Zheng): Pop the migration from the waiting queue
6761         # if it exist in the queue, then we are good to moving on, if
6762         # not, some other process must have aborted it, then we should
6763         # rollback.
6764         try:
6765             self._waiting_live_migrations.pop(instance.uuid)
6766         except KeyError:
6767             LOG.debug('Migration %s aborted by another process, rollback.',
6768                       migration.uuid, instance=instance)
6769             self._rollback_live_migration(context, instance, dest,
6770                                           migrate_data, 'cancelled',
6771                                           source_bdms=source_bdms)
6772             self._notify_live_migrate_abort_end(context, instance)
6773             return
6774 
6775         self._set_migration_status(migration, 'running')
6776 
6777         # NOTE(mdbooth): pre_live_migration will update connection_info and
6778         # attachment_id on all volume BDMS to reflect the new destination
6779         # host attachment. We fetch BDMs before that to retain connection_info
6780         # and attachment_id relating to the source host for post migration
6781         # cleanup.
6782         post_live_migration = functools.partial(self._post_live_migration,
6783                                                 source_bdms=source_bdms)
6784         rollback_live_migration = functools.partial(
6785             self._rollback_live_migration, source_bdms=source_bdms)
6786 
6787         LOG.debug('live_migration data is %s', migrate_data)
6788         try:
6789             self.driver.live_migration(context, instance, dest,
6790                                        post_live_migration,
6791                                        rollback_live_migration,
6792                                        block_migration, migrate_data)
6793         except Exception:
6794             LOG.exception('Live migration failed.', instance=instance)
6795             with excutils.save_and_reraise_exception():
6796                 # Put instance and migration into error state,
6797                 # as its almost certainly too late to rollback
6798                 self._set_migration_status(migration, 'error')
6799                 # first refresh instance as it may have got updated by
6800                 # post_live_migration_at_destination
6801                 instance.refresh()
6802                 self._set_instance_obj_error_state(context, instance,
6803                                                    clean_task_state=True)
6804 
6805     @wrap_exception()
6806     @wrap_instance_event(prefix='compute')
6807     @errors_out_migration
6808     @wrap_instance_fault
6809     def live_migration(self, context, dest, instance, block_migration,
6810                        migration, migrate_data):
6811         """Executing live migration.
6812 
6813         :param context: security context
6814         :param dest: destination host
6815         :param instance: a nova.objects.instance.Instance object
6816         :param block_migration: if true, prepare for block migration
6817         :param migration: an nova.objects.Migration object
6818         :param migrate_data: implementation specific params
6819 
6820         """
6821         self._set_migration_status(migration, 'queued')
6822         # NOTE(Kevin_Zheng): Submit the live_migration job to the pool and
6823         # put the returned Future object into dict mapped with migration.uuid
6824         # in order to be able to track and abort it in the future.
6825         self._waiting_live_migrations[instance.uuid] = (None, None)
6826         try:
6827             future = self._live_migration_executor.submit(
6828                 self._do_live_migration, context, dest, instance,
6829                 block_migration, migration, migrate_data)
6830             self._waiting_live_migrations[instance.uuid] = (migration, future)
6831         except RuntimeError:
6832             # GreenThreadPoolExecutor.submit will raise RuntimeError if the
6833             # pool is shutdown, which happens in
6834             # _cleanup_live_migrations_in_pool.
6835             LOG.info('Migration %s failed to submit as the compute service '
6836                      'is shutting down.', migration.uuid, instance=instance)
6837             raise exception.LiveMigrationNotSubmitted(
6838                 migration_uuid=migration.uuid, instance_uuid=instance.uuid)
6839 
6840     @wrap_exception()
6841     @wrap_instance_event(prefix='compute')
6842     @wrap_instance_fault
6843     def live_migration_force_complete(self, context, instance):
6844         """Force live migration to complete.
6845 
6846         :param context: Security context
6847         :param instance: The instance that is being migrated
6848         """
6849 
6850         self._notify_about_instance_usage(
6851             context, instance, 'live.migration.force.complete.start')
6852         compute_utils.notify_about_instance_action(
6853             context, instance, self.host,
6854             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6855             phase=fields.NotificationPhase.START)
6856         self.driver.live_migration_force_complete(instance)
6857         self._notify_about_instance_usage(
6858             context, instance, 'live.migration.force.complete.end')
6859         compute_utils.notify_about_instance_action(
6860             context, instance, self.host,
6861             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6862             phase=fields.NotificationPhase.END)
6863 
6864     def _notify_live_migrate_abort_end(self, context, instance):
6865         self._notify_about_instance_usage(
6866             context, instance, 'live.migration.abort.end')
6867         compute_utils.notify_about_instance_action(
6868             context, instance, self.host,
6869             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6870             phase=fields.NotificationPhase.END)
6871 
6872     @wrap_exception()
6873     @wrap_instance_event(prefix='compute')
6874     @wrap_instance_fault
6875     def live_migration_abort(self, context, instance, migration_id):
6876         """Abort an in-progress live migration.
6877 
6878         :param context: Security context
6879         :param instance: The instance that is being migrated
6880         :param migration_id: ID of in-progress live migration
6881 
6882         """
6883         self._notify_about_instance_usage(
6884             context, instance, 'live.migration.abort.start')
6885         compute_utils.notify_about_instance_action(
6886             context, instance, self.host,
6887             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6888             phase=fields.NotificationPhase.START)
6889         # NOTE(Kevin_Zheng): Pop the migration out from the queue, this might
6890         # lead to 3 scenarios:
6891         # 1. The selected migration is still in queue, and the future.cancel()
6892         #    succeed, then the abort action is succeed, mark the migration
6893         #    status to 'cancelled'.
6894         # 2. The selected migration is still in queue, but the future.cancel()
6895         #    failed, then the _do_live_migration() has started executing, and
6896         #    the migration status is 'preparing', then we just pop it from the
6897         #    queue, and the migration process will handle it later. And the
6898         #    migration status couldn't be 'running' in this scenario because
6899         #    if _do_live_migration has started executing and we've already
6900         #    popped it from the queue and set the migration status to
6901         #    'running' at this point, popping it here will raise KeyError at
6902         #    which point we check if it's running and if so, we abort the old
6903         #    way.
6904         # 3. The selected migration is not in the queue, then the migration
6905         #    status is 'running', let the driver handle it.
6906         try:
6907             migration, future = (
6908                 self._waiting_live_migrations.pop(instance.uuid))
6909             if future and future.cancel():
6910                 # If we got here, we've successfully aborted the queued
6911                 # migration and _do_live_migration won't run so we need
6912                 # to set the migration status to cancelled and send the
6913                 # notification. If Future.cancel() fails, it means
6914                 # _do_live_migration is running and the migration status
6915                 # is preparing, and _do_live_migration() itself will attempt
6916                 # to pop the queued migration, hit a KeyError, and rollback,
6917                 # set the migration to cancelled and send the
6918                 # live.migration.abort.end notification.
6919                 self._set_migration_status(migration, 'cancelled')
6920         except KeyError:
6921             migration = objects.Migration.get_by_id(context, migration_id)
6922             if migration.status != 'running':
6923                 raise exception.InvalidMigrationState(
6924                     migration_id=migration_id, instance_uuid=instance.uuid,
6925                     state=migration.status, method='abort live migration')
6926             self.driver.live_migration_abort(instance)
6927         self._notify_live_migrate_abort_end(context, instance)
6928 
6929     def _live_migration_cleanup_flags(self, migrate_data):
6930         """Determine whether disks or instance path need to be cleaned up after
6931         live migration (at source on success, at destination on rollback)
6932 
6933         Block migration needs empty image at destination host before migration
6934         starts, so if any failure occurs, any empty images has to be deleted.
6935 
6936         Also Volume backed live migration w/o shared storage needs to delete
6937         newly created instance-xxx dir on the destination as a part of its
6938         rollback process
6939 
6940         :param migrate_data: implementation specific data
6941         :returns: (bool, bool) -- do_cleanup, destroy_disks
6942         """
6943         # NOTE(pkoniszewski): block migration specific params are set inside
6944         # migrate_data objects for drivers that expose block live migration
6945         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6946         # cleanup is not needed.
6947         do_cleanup = False
6948         destroy_disks = False
6949         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6950             # No instance booting at source host, but instance dir
6951             # must be deleted for preparing next block migration
6952             # must be deleted for preparing next live migration w/o shared
6953             # storage
6954             do_cleanup = not migrate_data.is_shared_instance_path
6955             destroy_disks = not migrate_data.is_shared_block_storage
6956         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6957             do_cleanup = migrate_data.block_migration
6958             destroy_disks = migrate_data.block_migration
6959         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6960             # NOTE(claudiub): We need to cleanup any zombie Planned VM.
6961             do_cleanup = True
6962             destroy_disks = not migrate_data.is_shared_instance_path
6963 
6964         return (do_cleanup, destroy_disks)
6965 
6966     @wrap_exception()
6967     @wrap_instance_fault
6968     def _post_live_migration(self, ctxt, instance, dest,
6969                              block_migration=False, migrate_data=None,
6970                              source_bdms=None):
6971         """Post operations for live migration.
6972 
6973         This method is called from live_migration
6974         and mainly updating database record.
6975 
6976         :param ctxt: security context
6977         :param instance: instance dict
6978         :param dest: destination host
6979         :param block_migration: if true, prepare for block migration
6980         :param migrate_data: if not None, it is a dict which has data
6981         :param source_bdms: BDMs prior to modification by the destination
6982                             compute host. Set by _do_live_migration and not
6983                             part of the callback interface, so this is never
6984                             None
6985         required for live migration without shared storage
6986 
6987         """
6988         LOG.info('_post_live_migration() is started..',
6989                  instance=instance)
6990 
6991         # Cleanup source host post live-migration
6992         block_device_info = self._get_instance_block_device_info(
6993                             ctxt, instance, bdms=source_bdms)
6994         self.driver.post_live_migration(ctxt, instance, block_device_info,
6995                                         migrate_data)
6996 
6997         # Detaching volumes.
6998         connector = self.driver.get_volume_connector(instance)
6999         for bdm in source_bdms:
7000             if bdm.is_volume:
7001                 # Detaching volumes is a call to an external API that can fail.
7002                 # If it does, we need to handle it gracefully so that the call
7003                 # to post_live_migration_at_destination - where we set instance
7004                 # host and task state - still happens. We need to rethink the
7005                 # current approach of setting instance host and task state
7006                 # AFTER a whole bunch of things that could fail in unhandled
7007                 # ways, but that is left as a TODO(artom).
7008                 try:
7009                     if bdm.attachment_id is None:
7010                         # Prior to cinder v3.44:
7011                         # We don't want to actually mark the volume detached,
7012                         # or delete the bdm, just remove the connection from
7013                         # this host.
7014                         #
7015                         # remove the volume connection without detaching from
7016                         # hypervisor because the instance is not running
7017                         # anymore on the current host
7018                         self.volume_api.terminate_connection(ctxt,
7019                                                              bdm.volume_id,
7020                                                              connector)
7021                     else:
7022                         # cinder v3.44 api flow - delete the old attachment
7023                         # for the source host
7024                         self.volume_api.attachment_delete(ctxt,
7025                                                           bdm.attachment_id)
7026 
7027                 except Exception as e:
7028                     if bdm.attachment_id is None:
7029                         LOG.error('Connection for volume %s not terminated on '
7030                                   'source host %s during post_live_migration: '
7031                                    '%s', bdm.volume_id, self.host,
7032                                    six.text_type(e), instance=instance)
7033                     else:
7034                         LOG.error('Volume attachment %s not deleted on source '
7035                                   'host %s during post_live_migration: %s',
7036                                   bdm.attachment_id, self.host,
7037                                   six.text_type(e), instance=instance)
7038 
7039         # Releasing vlan.
7040         # (not necessary in current implementation?)
7041 
7042         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
7043 
7044         self._notify_about_instance_usage(ctxt, instance,
7045                                           "live_migration._post.start",
7046                                           network_info=network_info)
7047         compute_utils.notify_about_instance_action(
7048             ctxt, instance, self.host,
7049             action=fields.NotificationAction.LIVE_MIGRATION_POST,
7050             phase=fields.NotificationPhase.START)
7051         # Releasing security group ingress rule.
7052         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
7053                   instance=instance)
7054         self.driver.unfilter_instance(instance,
7055                                       network_info)
7056 
7057         migration = {'source_compute': self.host,
7058                      'dest_compute': dest, }
7059         # For neutron, migrate_instance_start will activate the destination
7060         # host port bindings, if there are any created by conductor before live
7061         # migration started.
7062         self.network_api.migrate_instance_start(ctxt,
7063                                                 instance,
7064                                                 migration)
7065 
7066         destroy_vifs = False
7067         try:
7068             # It's possible that the vif type changed on the destination
7069             # host and is already bound and active, so we need to use the
7070             # stashed source vifs in migrate_data.vifs (if present) to unplug
7071             # on the source host.
7072             unplug_nw_info = network_info
7073             if migrate_data and 'vifs' in migrate_data:
7074                 nw_info = []
7075                 for migrate_vif in migrate_data.vifs:
7076                     nw_info.append(migrate_vif.source_vif)
7077                 unplug_nw_info = network_model.NetworkInfo.hydrate(nw_info)
7078                 LOG.debug('Calling driver.post_live_migration_at_source '
7079                           'with original source VIFs from migrate_data: %s',
7080                           unplug_nw_info, instance=instance)
7081             self.driver.post_live_migration_at_source(ctxt, instance,
7082                                                       unplug_nw_info)
7083         except NotImplementedError as ex:
7084             LOG.debug(ex, instance=instance)
7085             # For all hypervisors other than libvirt, there is a possibility
7086             # they are unplugging networks from source node in the cleanup
7087             # method
7088             destroy_vifs = True
7089 
7090         # Free instance allocations on source before claims are allocated on
7091         # destination node
7092         self.rt.free_pci_device_allocations_for_instance(ctxt, instance)
7093         # NOTE(danms): Save source node before calling post method on
7094         # destination, which will update it
7095         source_node = instance.node
7096 
7097         # Define domain at destination host, without doing it,
7098         # pause/suspend/terminate do not work.
7099         post_at_dest_success = True
7100         try:
7101             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
7102                     instance, block_migration, dest)
7103         except Exception as error:
7104             post_at_dest_success = False
7105             # We don't want to break _post_live_migration() if
7106             # post_live_migration_at_destination() fails as it should never
7107             # affect cleaning up source node.
7108             LOG.exception("Post live migration at destination %s failed",
7109                           dest, instance=instance, error=error)
7110 
7111         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
7112                 migrate_data)
7113 
7114         if do_cleanup:
7115             LOG.debug('Calling driver.cleanup from _post_live_migration',
7116                       instance=instance)
7117             self.driver.cleanup(ctxt, instance, unplug_nw_info,
7118                                 destroy_disks=destroy_disks,
7119                                 migrate_data=migrate_data,
7120                                 destroy_vifs=destroy_vifs)
7121 
7122         self.instance_events.clear_events_for_instance(instance)
7123 
7124         # NOTE(timello): make sure we update available resources on source
7125         # host even before next periodic task.
7126         self.update_available_resource(ctxt)
7127 
7128         self._update_scheduler_instance_info(ctxt, instance)
7129         self._notify_about_instance_usage(ctxt, instance,
7130                                           "live_migration._post.end",
7131                                           network_info=network_info)
7132         compute_utils.notify_about_instance_action(
7133             ctxt, instance, self.host,
7134             action=fields.NotificationAction.LIVE_MIGRATION_POST,
7135             phase=fields.NotificationPhase.END)
7136         if post_at_dest_success:
7137             LOG.info('Migrating instance to %s finished successfully.',
7138                      dest, instance=instance)
7139 
7140         self._clean_instance_console_tokens(ctxt, instance)
7141         if migrate_data and migrate_data.obj_attr_is_set('migration'):
7142             migrate_data.migration.status = 'completed'
7143             migrate_data.migration.save()
7144             self._delete_allocation_after_move(ctxt,
7145                                                instance,
7146                                                migrate_data.migration)
7147         else:
7148             # We didn't have data on a migration, which means we can't
7149             # look up to see if we had new-style migration-based
7150             # allocations. This should really only happen in cases of
7151             # a buggy virt driver. Log a warning so we know it happened.
7152             LOG.warning('Live migration ended with no migrate_data '
7153                         'record. Unable to clean up migration-based '
7154                         'allocations for node %s which is almost certainly '
7155                         'not an expected situation.', source_node,
7156                         instance=instance)
7157 
7158     def _consoles_enabled(self):
7159         """Returns whether a console is enable."""
7160         return (CONF.vnc.enabled or CONF.spice.enabled or
7161                 CONF.rdp.enabled or CONF.serial_console.enabled or
7162                 CONF.mks.enabled)
7163 
7164     def _clean_instance_console_tokens(self, ctxt, instance):
7165         """Clean console tokens stored for an instance."""
7166         # If the database backend isn't in use, don't bother trying to clean
7167         # tokens.
7168         if self._consoles_enabled():
7169             objects.ConsoleAuthToken.\
7170                 clean_console_auths_for_instance(ctxt, instance.uuid)
7171 
7172     @wrap_exception()
7173     @wrap_instance_event(prefix='compute')
7174     @wrap_instance_fault
7175     def post_live_migration_at_destination(self, context, instance,
7176                                            block_migration):
7177         """Post operations for live migration .
7178 
7179         :param context: security context
7180         :param instance: Instance dict
7181         :param block_migration: if true, prepare for block migration
7182 
7183         """
7184         LOG.info('Post operation of migration started',
7185                  instance=instance)
7186 
7187         # NOTE(tr3buchet): setup networks on destination host
7188         #                  this is called a second time because
7189         #                  multi_host does not create the bridge in
7190         #                  plug_vifs
7191         # NOTE(mriedem): This is a no-op for neutron.
7192         self.network_api.setup_networks_on_host(context, instance,
7193                                                          self.host)
7194         migration = {'source_compute': instance.host,
7195                      'dest_compute': self.host,
7196                      'migration_type': 'live-migration'}
7197         self.network_api.migrate_instance_finish(context,
7198                                                  instance,
7199                                                  migration)
7200 
7201         network_info = self.network_api.get_instance_nw_info(context, instance)
7202         self._notify_about_instance_usage(
7203                      context, instance, "live_migration.post.dest.start",
7204                      network_info=network_info)
7205         compute_utils.notify_about_instance_action(context, instance,
7206                 self.host,
7207                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
7208                 phase=fields.NotificationPhase.START)
7209         block_device_info = self._get_instance_block_device_info(context,
7210                                                                  instance)
7211         # Allocate the claimed PCI resources at destination.
7212         self.rt.allocate_pci_devices_for_instance(context, instance)
7213 
7214         try:
7215             self.driver.post_live_migration_at_destination(
7216                 context, instance, network_info, block_migration,
7217                 block_device_info)
7218         except Exception:
7219             with excutils.save_and_reraise_exception():
7220                 instance.vm_state = vm_states.ERROR
7221                 LOG.error('Unexpected error during post live migration at '
7222                           'destination host.', instance=instance)
7223         finally:
7224             # Restore instance state and update host
7225             current_power_state = self._get_power_state(context, instance)
7226             node_name = None
7227             prev_host = instance.host
7228             try:
7229                 compute_node = self._get_compute_info(context, self.host)
7230                 node_name = compute_node.hypervisor_hostname
7231             except exception.ComputeHostNotFound:
7232                 LOG.exception('Failed to get compute_info for %s', self.host)
7233             finally:
7234                 instance.host = self.host
7235                 instance.power_state = current_power_state
7236                 instance.task_state = None
7237                 instance.node = node_name
7238                 instance.progress = 0
7239                 instance.save(expected_task_state=task_states.MIGRATING)
7240 
7241         # NOTE(tr3buchet): tear down networks on source host (nova-net)
7242         # NOTE(mriedem): For neutron, this will delete any inactive source
7243         # host port bindings.
7244         try:
7245             self.network_api.setup_networks_on_host(context, instance,
7246                                                     prev_host, teardown=True)
7247         except exception.PortBindingDeletionFailed as e:
7248             # Removing the inactive port bindings from the source host is not
7249             # critical so just log an error but don't fail.
7250             LOG.error('Network cleanup failed for source host %s during post '
7251                       'live migration. You may need to manually clean up '
7252                       'resources in the network service. Error: %s',
7253                       prev_host, six.text_type(e))
7254         # NOTE(vish): this is necessary to update dhcp for nova-network
7255         # NOTE(mriedem): This is a no-op for neutron.
7256         self.network_api.setup_networks_on_host(context, instance, self.host)
7257         self._notify_about_instance_usage(
7258                      context, instance, "live_migration.post.dest.end",
7259                      network_info=network_info)
7260         compute_utils.notify_about_instance_action(context, instance,
7261                 self.host,
7262                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
7263                 phase=fields.NotificationPhase.END)
7264 
7265     @wrap_exception()
7266     @wrap_instance_fault
7267     def _rollback_live_migration(self, context, instance,
7268                                  dest, migrate_data=None,
7269                                  migration_status='error',
7270                                  source_bdms=None):
7271         """Recovers Instance/volume state from migrating -> running.
7272 
7273         :param context: security context
7274         :param instance: nova.objects.instance.Instance object
7275         :param dest:
7276             This method is called from live migration src host.
7277             This param specifies destination host.
7278         :param migrate_data:
7279             if not none, contains implementation specific data.
7280         :param migration_status:
7281             Contains the status we want to set for the migration object
7282         :param source_bdms: BDMs prior to modification by the destination
7283                             compute host. Set by _do_live_migration and not
7284                             part of the callback interface, so this is never
7285                             None
7286 
7287         """
7288         if (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
7289               migrate_data.obj_attr_is_set('migration')):
7290             migration = migrate_data.migration
7291         else:
7292             migration = None
7293 
7294         if migration:
7295             # Remove allocations created in Placement for the dest node.
7296             # If migration is None, the virt driver didn't pass it which is
7297             # a bug.
7298             self._revert_allocation(context, instance, migration)
7299         else:
7300             LOG.error('Unable to revert allocations during live migration '
7301                       'rollback; compute driver did not provide migrate_data',
7302                       instance=instance)
7303 
7304         instance.task_state = None
7305         instance.progress = 0
7306         instance.save(expected_task_state=[task_states.MIGRATING])
7307 
7308         # NOTE(tr3buchet): setup networks on source host (really it's re-setup
7309         #                  for nova-network)
7310         # NOTE(mriedem): This is a no-op for neutron.
7311         self.network_api.setup_networks_on_host(context, instance, self.host)
7312         self.driver.rollback_live_migration_at_source(context, instance,
7313                                                       migrate_data)
7314 
7315         source_bdms_by_volid = {bdm.volume_id: bdm for bdm in source_bdms
7316                                 if bdm.is_volume}
7317 
7318         # NOTE(lyarwood): Fetch the current list of BDMs and delete any volume
7319         # attachments used by the destination host before rolling back to the
7320         # original and still valid source host volume attachments.
7321         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7322                 context, instance.uuid)
7323         for bdm in bdms:
7324             if bdm.is_volume:
7325                 # remove the connection on the destination host
7326                 # NOTE(lyarwood): This actually calls the cinderv2
7327                 # os-terminate_connection API if required.
7328                 self.compute_rpcapi.remove_volume_connection(
7329                         context, instance, bdm.volume_id, dest)
7330 
7331                 if bdm.attachment_id:
7332                     # 3.44 cinder api flow. Set the bdm's
7333                     # attachment_id to the old attachment of the source
7334                     # host. If old_attachments is not there, then
7335                     # there was an error before the new attachment was made.
7336                     # TODO(lyarwood): migrate_data.old_vol_attachment_ids can
7337                     # be removed now as we can lookup the original
7338                     # attachment_ids from the source_bdms list here.
7339                     old_attachments = migrate_data.old_vol_attachment_ids \
7340                         if 'old_vol_attachment_ids' in migrate_data else None
7341                     if old_attachments and bdm.volume_id in old_attachments:
7342                         self.volume_api.attachment_delete(context,
7343                                                           bdm.attachment_id)
7344                         bdm.attachment_id = old_attachments[bdm.volume_id]
7345 
7346                 # NOTE(lyarwood): Rollback the connection_info stored within
7347                 # the BDM to that used by the source and not the destination.
7348                 source_bdm = source_bdms_by_volid[bdm.volume_id]
7349                 bdm.connection_info = source_bdm.connection_info
7350                 bdm.save()
7351 
7352         self._notify_about_instance_usage(context, instance,
7353                                           "live_migration._rollback.start")
7354         compute_utils.notify_about_instance_action(context, instance,
7355                 self.host,
7356                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
7357                 phase=fields.NotificationPhase.START,
7358                 bdms=bdms)
7359 
7360         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
7361                 migrate_data)
7362 
7363         if do_cleanup:
7364             self.compute_rpcapi.rollback_live_migration_at_destination(
7365                     context, instance, dest, destroy_disks=destroy_disks,
7366                     migrate_data=migrate_data)
7367         elif utils.is_neutron():
7368             # The port binding profiles need to be cleaned up.
7369             with errors_out_migration_ctxt(migration):
7370                 try:
7371                     # This call will delete any inactive destination host
7372                     # port bindings.
7373                     self.network_api.setup_networks_on_host(
7374                         context, instance, host=dest, teardown=True)
7375                 except exception.PortBindingDeletionFailed as e:
7376                     # Removing the inactive port bindings from the destination
7377                     # host is not critical so just log an error but don't fail.
7378                     LOG.error(
7379                         'Network cleanup failed for destination host %s '
7380                         'during live migration rollback. You may need to '
7381                         'manually clean up resources in the network service. '
7382                         'Error: %s', dest, six.text_type(e))
7383                 except Exception:
7384                     with excutils.save_and_reraise_exception():
7385                         LOG.exception(
7386                             'An error occurred while cleaning up networking '
7387                             'during live migration rollback.',
7388                             instance=instance)
7389 
7390         self._notify_about_instance_usage(context, instance,
7391                                           "live_migration._rollback.end")
7392         compute_utils.notify_about_instance_action(context, instance,
7393                 self.host,
7394                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
7395                 phase=fields.NotificationPhase.END,
7396                 bdms=bdms)
7397 
7398         self._set_migration_status(migration, migration_status)
7399 
7400     @wrap_exception()
7401     @wrap_instance_event(prefix='compute')
7402     @wrap_instance_fault
7403     def rollback_live_migration_at_destination(self, context, instance,
7404                                                destroy_disks,
7405                                                migrate_data):
7406         """Cleaning up image directory that is created pre_live_migration.
7407 
7408         :param context: security context
7409         :param instance: a nova.objects.instance.Instance object sent over rpc
7410         :param destroy_disks: whether to destroy volumes or not
7411         :param migrate_data: contains migration info
7412         """
7413         network_info = self.network_api.get_instance_nw_info(context, instance)
7414         self._notify_about_instance_usage(
7415                       context, instance, "live_migration.rollback.dest.start",
7416                       network_info=network_info)
7417         compute_utils.notify_about_instance_action(
7418             context, instance, self.host,
7419             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
7420             phase=fields.NotificationPhase.START)
7421         try:
7422             # NOTE(tr3buchet): tear down networks on dest host (nova-net)
7423             # NOTE(mriedem): For neutron, this call will delete any
7424             # destination host port bindings.
7425             # TODO(mriedem): We should eventually remove this call from
7426             # this method (rollback_live_migration_at_destination) since this
7427             # method is only called conditionally based on whether or not the
7428             # instance is running on shared storage. _rollback_live_migration
7429             # already calls this method for neutron if we are running on
7430             # shared storage.
7431             self.network_api.setup_networks_on_host(context, instance,
7432                                                     self.host, teardown=True)
7433         except exception.PortBindingDeletionFailed as e:
7434             # Removing the inactive port bindings from the destination
7435             # host is not critical so just log an error but don't fail.
7436             LOG.error(
7437                 'Network cleanup failed for destination host %s '
7438                 'during live migration rollback. You may need to '
7439                 'manually clean up resources in the network service. '
7440                 'Error: %s', self.host, six.text_type(e))
7441         except Exception:
7442             with excutils.save_and_reraise_exception():
7443                 # NOTE(tdurakov): even if teardown networks fails driver
7444                 # should try to rollback live migration on destination.
7445                 LOG.exception('An error occurred while deallocating network.',
7446                               instance=instance)
7447         finally:
7448             # always run this even if setup_networks_on_host fails
7449             # NOTE(vish): The mapping is passed in so the driver can disconnect
7450             #             from remote volumes if necessary
7451             block_device_info = self._get_instance_block_device_info(context,
7452                                                                      instance)
7453             # free any instance PCI claims done on destination during
7454             # check_can_live_migrate_destination()
7455             self.rt.free_pci_device_claims_for_instance(context, instance)
7456 
7457             self.driver.rollback_live_migration_at_destination(
7458                 context, instance, network_info, block_device_info,
7459                 destroy_disks=destroy_disks, migrate_data=migrate_data)
7460 
7461         self._notify_about_instance_usage(
7462                         context, instance, "live_migration.rollback.dest.end",
7463                         network_info=network_info)
7464         compute_utils.notify_about_instance_action(
7465             context, instance, self.host,
7466             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
7467             phase=fields.NotificationPhase.END)
7468 
7469     def _require_nw_info_update(self, context, instance):
7470         """Detect whether there is a mismatch in binding:host_id, or
7471         binding_failed or unbound binding:vif_type for any of the instances
7472         ports.
7473         """
7474         # Only update port bindings if compute manager does manage port
7475         # bindings instead of the compute driver. For example IronicDriver
7476         # manages the port binding for baremetal instance ports, hence,
7477         # external intervention with the binding is not desired.
7478         if (not utils.is_neutron() or
7479                 self.driver.manages_network_binding_host_id()):
7480             return False
7481 
7482         search_opts = {'device_id': instance.uuid,
7483                        'fields': ['binding:host_id', 'binding:vif_type']}
7484         ports = self.network_api.list_ports(context, **search_opts)
7485         for p in ports['ports']:
7486             if p.get('binding:host_id') != self.host:
7487                 return True
7488             vif_type = p.get('binding:vif_type')
7489             if (vif_type == network_model.VIF_TYPE_UNBOUND or
7490                     vif_type == network_model.VIF_TYPE_BINDING_FAILED):
7491                 return True
7492         return False
7493 
7494     @periodic_task.periodic_task(
7495         spacing=CONF.heal_instance_info_cache_interval)
7496     def _heal_instance_info_cache(self, context):
7497         """Called periodically.  On every call, try to update the
7498         info_cache's network information for another instance by
7499         calling to the network manager.
7500 
7501         This is implemented by keeping a cache of uuids of instances
7502         that live on this host.  On each call, we pop one off of a
7503         list, pull the DB record, and try the call to the network API.
7504         If anything errors don't fail, as it's possible the instance
7505         has been deleted, etc.
7506         """
7507         heal_interval = CONF.heal_instance_info_cache_interval
7508         if not heal_interval:
7509             return
7510 
7511         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
7512         instance = None
7513 
7514         LOG.debug('Starting heal instance info cache')
7515 
7516         if not instance_uuids:
7517             # The list of instances to heal is empty so rebuild it
7518             LOG.debug('Rebuilding the list of instances to heal')
7519             db_instances = objects.InstanceList.get_by_host(
7520                 context, self.host, expected_attrs=[], use_slave=True)
7521             for inst in db_instances:
7522                 # We don't want to refresh the cache for instances
7523                 # which are building or deleting so don't put them
7524                 # in the list. If they are building they will get
7525                 # added to the list next time we build it.
7526                 if (inst.vm_state == vm_states.BUILDING):
7527                     LOG.debug('Skipping network cache update for instance '
7528                               'because it is Building.', instance=inst)
7529                     continue
7530                 if (inst.task_state == task_states.DELETING):
7531                     LOG.debug('Skipping network cache update for instance '
7532                               'because it is being deleted.', instance=inst)
7533                     continue
7534 
7535                 if not instance:
7536                     # Save the first one we find so we don't
7537                     # have to get it again
7538                     instance = inst
7539                 else:
7540                     instance_uuids.append(inst['uuid'])
7541 
7542             self._instance_uuids_to_heal = instance_uuids
7543         else:
7544             # Find the next valid instance on the list
7545             while instance_uuids:
7546                 try:
7547                     inst = objects.Instance.get_by_uuid(
7548                             context, instance_uuids.pop(0),
7549                             expected_attrs=['system_metadata', 'info_cache',
7550                                             'flavor'],
7551                             use_slave=True)
7552                 except exception.InstanceNotFound:
7553                     # Instance is gone.  Try to grab another.
7554                     continue
7555 
7556                 # Check the instance hasn't been migrated
7557                 if inst.host != self.host:
7558                     LOG.debug('Skipping network cache update for instance '
7559                               'because it has been migrated to another '
7560                               'host.', instance=inst)
7561                 # Check the instance isn't being deleting
7562                 elif inst.task_state == task_states.DELETING:
7563                     LOG.debug('Skipping network cache update for instance '
7564                               'because it is being deleted.', instance=inst)
7565                 else:
7566                     instance = inst
7567                     break
7568 
7569         if instance:
7570             # We have an instance now to refresh
7571             try:
7572                 # Fix potential mismatch in port binding if evacuation failed
7573                 # after reassigning the port binding to the dest host but
7574                 # before the instance host is changed.
7575                 # Do this only when instance has no pending task.
7576                 if instance.task_state is None and \
7577                         self._require_nw_info_update(context, instance):
7578                     LOG.info("Updating ports in neutron", instance=instance)
7579                     self.network_api.setup_instance_network_on_host(
7580                         context, instance, self.host)
7581                 # Call to network API to get instance info.. this will
7582                 # force an update to the instance's info_cache
7583                 self.network_api.get_instance_nw_info(
7584                     context, instance, force_refresh=True)
7585                 LOG.debug('Updated the network info_cache for instance',
7586                           instance=instance)
7587             except exception.InstanceNotFound:
7588                 # Instance is gone.
7589                 LOG.debug('Instance no longer exists. Unable to refresh',
7590                           instance=instance)
7591                 return
7592             except exception.InstanceInfoCacheNotFound:
7593                 # InstanceInfoCache is gone.
7594                 LOG.debug('InstanceInfoCache no longer exists. '
7595                           'Unable to refresh', instance=instance)
7596             except Exception:
7597                 LOG.error('An error occurred while refreshing the network '
7598                           'cache.', instance=instance, exc_info=True)
7599         else:
7600             LOG.debug("Didn't find any instances for network info cache "
7601                       "update.")
7602 
7603     @periodic_task.periodic_task
7604     def _poll_rebooting_instances(self, context):
7605         if CONF.reboot_timeout > 0:
7606             filters = {'task_state':
7607                        [task_states.REBOOTING,
7608                         task_states.REBOOT_STARTED,
7609                         task_states.REBOOT_PENDING],
7610                        'host': self.host}
7611             rebooting = objects.InstanceList.get_by_filters(
7612                 context, filters, expected_attrs=[], use_slave=True)
7613 
7614             to_poll = []
7615             for instance in rebooting:
7616                 if timeutils.is_older_than(instance.updated_at,
7617                                            CONF.reboot_timeout):
7618                     to_poll.append(instance)
7619 
7620             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
7621 
7622     @periodic_task.periodic_task
7623     def _poll_rescued_instances(self, context):
7624         if CONF.rescue_timeout > 0:
7625             filters = {'vm_state': vm_states.RESCUED,
7626                        'host': self.host}
7627             rescued_instances = objects.InstanceList.get_by_filters(
7628                 context, filters, expected_attrs=["system_metadata"],
7629                 use_slave=True)
7630 
7631             to_unrescue = []
7632             for instance in rescued_instances:
7633                 if timeutils.is_older_than(instance.launched_at,
7634                                            CONF.rescue_timeout):
7635                     to_unrescue.append(instance)
7636 
7637             for instance in to_unrescue:
7638                 self.compute_api.unrescue(context, instance)
7639 
7640     @periodic_task.periodic_task
7641     def _poll_unconfirmed_resizes(self, context):
7642         if CONF.resize_confirm_window == 0:
7643             return
7644 
7645         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
7646                 context, CONF.resize_confirm_window, self.host,
7647                 use_slave=True)
7648 
7649         migrations_info = dict(migration_count=len(migrations),
7650                 confirm_window=CONF.resize_confirm_window)
7651 
7652         if migrations_info["migration_count"] > 0:
7653             LOG.info("Found %(migration_count)d unconfirmed migrations "
7654                      "older than %(confirm_window)d seconds",
7655                      migrations_info)
7656 
7657         def _set_migration_to_error(migration, reason, **kwargs):
7658             LOG.warning("Setting migration %(migration_id)s to error: "
7659                         "%(reason)s",
7660                         {'migration_id': migration['id'], 'reason': reason},
7661                         **kwargs)
7662             migration.status = 'error'
7663             migration.save()
7664 
7665         for migration in migrations:
7666             instance_uuid = migration.instance_uuid
7667             LOG.info("Automatically confirming migration "
7668                      "%(migration_id)s for instance %(instance_uuid)s",
7669                      {'migration_id': migration.id,
7670                       'instance_uuid': instance_uuid})
7671             expected_attrs = ['metadata', 'system_metadata']
7672             try:
7673                 instance = objects.Instance.get_by_uuid(context,
7674                             instance_uuid, expected_attrs=expected_attrs,
7675                             use_slave=True)
7676             except exception.InstanceNotFound:
7677                 reason = (_("Instance %s not found") %
7678                           instance_uuid)
7679                 _set_migration_to_error(migration, reason)
7680                 continue
7681             if instance.vm_state == vm_states.ERROR:
7682                 reason = _("In ERROR state")
7683                 _set_migration_to_error(migration, reason,
7684                                         instance=instance)
7685                 continue
7686             # race condition: The instance in DELETING state should not be
7687             # set the migration state to error, otherwise the instance in
7688             # to be deleted which is in RESIZED state
7689             # will not be able to confirm resize
7690             if instance.task_state in [task_states.DELETING,
7691                                        task_states.SOFT_DELETING]:
7692                 msg = ("Instance being deleted or soft deleted during resize "
7693                        "confirmation. Skipping.")
7694                 LOG.debug(msg, instance=instance)
7695                 continue
7696 
7697             # race condition: This condition is hit when this method is
7698             # called between the save of the migration record with a status of
7699             # finished and the save of the instance object with a state of
7700             # RESIZED. The migration record should not be set to error.
7701             if instance.task_state == task_states.RESIZE_FINISH:
7702                 msg = ("Instance still resizing during resize "
7703                        "confirmation. Skipping.")
7704                 LOG.debug(msg, instance=instance)
7705                 continue
7706 
7707             vm_state = instance.vm_state
7708             task_state = instance.task_state
7709             if vm_state != vm_states.RESIZED or task_state is not None:
7710                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
7711                            "RESIZED/None") %
7712                           {'vm_state': vm_state,
7713                            'task_state': task_state})
7714                 _set_migration_to_error(migration, reason,
7715                                         instance=instance)
7716                 continue
7717             try:
7718                 self.compute_api.confirm_resize(context, instance,
7719                                                 migration=migration)
7720             except Exception as e:
7721                 LOG.info("Error auto-confirming resize: %s. "
7722                          "Will retry later.", e, instance=instance)
7723 
7724     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
7725     def _poll_shelved_instances(self, context):
7726 
7727         if CONF.shelved_offload_time <= 0:
7728             return
7729 
7730         filters = {'vm_state': vm_states.SHELVED,
7731                    'task_state': None,
7732                    'host': self.host}
7733         shelved_instances = objects.InstanceList.get_by_filters(
7734             context, filters=filters, expected_attrs=['system_metadata'],
7735             use_slave=True)
7736 
7737         to_gc = []
7738         for instance in shelved_instances:
7739             sys_meta = instance.system_metadata
7740             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
7741             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
7742                 to_gc.append(instance)
7743 
7744         for instance in to_gc:
7745             try:
7746                 instance.task_state = task_states.SHELVING_OFFLOADING
7747                 instance.save(expected_task_state=(None,))
7748                 self.shelve_offload_instance(context, instance,
7749                                              clean_shutdown=False)
7750             except Exception:
7751                 LOG.exception('Periodic task failed to offload instance.',
7752                               instance=instance)
7753 
7754     @periodic_task.periodic_task
7755     def _instance_usage_audit(self, context):
7756         if not CONF.instance_usage_audit:
7757             return
7758 
7759         begin, end = utils.last_completed_audit_period()
7760         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
7761                                self.host):
7762             return
7763 
7764         instances = objects.InstanceList.get_active_by_window_joined(
7765             context, begin, end, host=self.host,
7766             expected_attrs=['system_metadata', 'info_cache', 'metadata',
7767                             'flavor'],
7768             use_slave=True)
7769         num_instances = len(instances)
7770         errors = 0
7771         successes = 0
7772         LOG.info("Running instance usage audit for host %(host)s "
7773                  "from %(begin_time)s to %(end_time)s. "
7774                  "%(number_instances)s instances.",
7775                  {'host': self.host,
7776                   'begin_time': begin,
7777                   'end_time': end,
7778                   'number_instances': num_instances})
7779         start_time = time.time()
7780         task_log = objects.TaskLog(context)
7781         task_log.task_name = 'instance_usage_audit'
7782         task_log.period_beginning = begin
7783         task_log.period_ending = end
7784         task_log.host = self.host
7785         task_log.task_items = num_instances
7786         task_log.message = 'Instance usage audit started...'
7787         task_log.begin_task()
7788         for instance in instances:
7789             try:
7790                 compute_utils.notify_usage_exists(
7791                     self.notifier, context, instance, self.host,
7792                     ignore_missing_network_data=False)
7793                 successes += 1
7794             except Exception:
7795                 LOG.exception('Failed to generate usage '
7796                               'audit for instance '
7797                               'on host %s', self.host,
7798                               instance=instance)
7799                 errors += 1
7800         task_log.errors = errors
7801         task_log.message = (
7802             'Instance usage audit ran for host %s, %s instances in %s seconds.'
7803             % (self.host, num_instances, time.time() - start_time))
7804         task_log.end_task()
7805 
7806     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
7807     def _poll_bandwidth_usage(self, context):
7808 
7809         if not self._bw_usage_supported:
7810             return
7811 
7812         prev_time, start_time = utils.last_completed_audit_period()
7813 
7814         curr_time = time.time()
7815         if (curr_time - self._last_bw_usage_poll >
7816                 CONF.bandwidth_poll_interval):
7817             self._last_bw_usage_poll = curr_time
7818             LOG.info("Updating bandwidth usage cache")
7819 
7820             instances = objects.InstanceList.get_by_host(context,
7821                                                               self.host,
7822                                                               use_slave=True)
7823             try:
7824                 bw_counters = self.driver.get_all_bw_counters(instances)
7825             except NotImplementedError:
7826                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
7827                 # implemented yet.  If they don't it doesn't break anything,
7828                 # they just don't get the info in the usage events.
7829                 # NOTE(PhilDay): Record that its not supported so we can
7830                 # skip fast on future calls rather than waste effort getting
7831                 # the list of instances.
7832                 LOG.info("Bandwidth usage not supported by %(driver)s.",
7833                          {'driver': CONF.compute_driver})
7834                 self._bw_usage_supported = False
7835                 return
7836 
7837             refreshed = timeutils.utcnow()
7838             for bw_ctr in bw_counters:
7839                 # Allow switching of greenthreads between queries.
7840                 greenthread.sleep(0)
7841                 bw_in = 0
7842                 bw_out = 0
7843                 last_ctr_in = None
7844                 last_ctr_out = None
7845                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
7846                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
7847                     start_period=start_time, use_slave=True)
7848                 if usage:
7849                     bw_in = usage.bw_in
7850                     bw_out = usage.bw_out
7851                     last_ctr_in = usage.last_ctr_in
7852                     last_ctr_out = usage.last_ctr_out
7853                 else:
7854                     usage = (objects.BandwidthUsage.
7855                              get_by_instance_uuid_and_mac(
7856                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
7857                         start_period=prev_time, use_slave=True))
7858                     if usage:
7859                         last_ctr_in = usage.last_ctr_in
7860                         last_ctr_out = usage.last_ctr_out
7861 
7862                 if last_ctr_in is not None:
7863                     if bw_ctr['bw_in'] < last_ctr_in:
7864                         # counter rollover
7865                         bw_in += bw_ctr['bw_in']
7866                     else:
7867                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
7868 
7869                 if last_ctr_out is not None:
7870                     if bw_ctr['bw_out'] < last_ctr_out:
7871                         # counter rollover
7872                         bw_out += bw_ctr['bw_out']
7873                     else:
7874                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
7875 
7876                 objects.BandwidthUsage(context=context).create(
7877                                               bw_ctr['uuid'],
7878                                               bw_ctr['mac_address'],
7879                                               bw_in,
7880                                               bw_out,
7881                                               bw_ctr['bw_in'],
7882                                               bw_ctr['bw_out'],
7883                                               start_period=start_time,
7884                                               last_refreshed=refreshed)
7885 
7886     def _get_host_volume_bdms(self, context, use_slave=False):
7887         """Return all block device mappings on a compute host."""
7888         compute_host_bdms = []
7889         instances = objects.InstanceList.get_by_host(context, self.host,
7890             use_slave=use_slave)
7891         for instance in instances:
7892             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7893                     context, instance.uuid, use_slave=use_slave)
7894             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
7895             compute_host_bdms.append(dict(instance=instance,
7896                                           instance_bdms=instance_bdms))
7897 
7898         return compute_host_bdms
7899 
7900     def _update_volume_usage_cache(self, context, vol_usages):
7901         """Updates the volume usage cache table with a list of stats."""
7902         for usage in vol_usages:
7903             # Allow switching of greenthreads between queries.
7904             greenthread.sleep(0)
7905             vol_usage = objects.VolumeUsage(context)
7906             vol_usage.volume_id = usage['volume']
7907             vol_usage.instance_uuid = usage['instance'].uuid
7908             vol_usage.project_id = usage['instance'].project_id
7909             vol_usage.user_id = usage['instance'].user_id
7910             vol_usage.availability_zone = usage['instance'].availability_zone
7911             vol_usage.curr_reads = usage['rd_req']
7912             vol_usage.curr_read_bytes = usage['rd_bytes']
7913             vol_usage.curr_writes = usage['wr_req']
7914             vol_usage.curr_write_bytes = usage['wr_bytes']
7915             vol_usage.save()
7916             self.notifier.info(context, 'volume.usage', vol_usage.to_dict())
7917             compute_utils.notify_about_volume_usage(context, vol_usage,
7918                                                     self.host)
7919 
7920     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
7921     def _poll_volume_usage(self, context):
7922         if CONF.volume_usage_poll_interval == 0:
7923             return
7924 
7925         compute_host_bdms = self._get_host_volume_bdms(context,
7926                                                        use_slave=True)
7927         if not compute_host_bdms:
7928             return
7929 
7930         LOG.debug("Updating volume usage cache")
7931         try:
7932             vol_usages = self.driver.get_all_volume_usage(context,
7933                                                           compute_host_bdms)
7934         except NotImplementedError:
7935             return
7936 
7937         self._update_volume_usage_cache(context, vol_usages)
7938 
7939     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
7940                                  run_immediately=True)
7941     def _sync_power_states(self, context):
7942         """Align power states between the database and the hypervisor.
7943 
7944         To sync power state data we make a DB call to get the number of
7945         virtual machines known by the hypervisor and if the number matches the
7946         number of virtual machines known by the database, we proceed in a lazy
7947         loop, one database record at a time, checking if the hypervisor has the
7948         same power state as is in the database.
7949         """
7950         db_instances = objects.InstanceList.get_by_host(context, self.host,
7951                                                         expected_attrs=[],
7952                                                         use_slave=True)
7953 
7954         try:
7955             num_vm_instances = self.driver.get_num_instances()
7956         except exception.VirtDriverNotReady as e:
7957             # If the virt driver is not ready, like ironic-api not being up
7958             # yet in the case of ironic, just log it and exit.
7959             LOG.info('Skipping _sync_power_states periodic task due to: %s', e)
7960             return
7961 
7962         num_db_instances = len(db_instances)
7963 
7964         if num_vm_instances != num_db_instances:
7965             LOG.warning("While synchronizing instance power states, found "
7966                         "%(num_db_instances)s instances in the database "
7967                         "and %(num_vm_instances)s instances on the "
7968                         "hypervisor.",
7969                         {'num_db_instances': num_db_instances,
7970                          'num_vm_instances': num_vm_instances})
7971 
7972         def _sync(db_instance):
7973             # NOTE(melwitt): This must be synchronized as we query state from
7974             #                two separate sources, the driver and the database.
7975             #                They are set (in stop_instance) and read, in sync.
7976             @utils.synchronized(db_instance.uuid)
7977             def query_driver_power_state_and_sync():
7978                 self._query_driver_power_state_and_sync(context, db_instance)
7979 
7980             try:
7981                 query_driver_power_state_and_sync()
7982             except Exception:
7983                 LOG.exception("Periodic sync_power_state task had an "
7984                               "error while processing an instance.",
7985                               instance=db_instance)
7986 
7987             self._syncs_in_progress.pop(db_instance.uuid)
7988 
7989         for db_instance in db_instances:
7990             # process syncs asynchronously - don't want instance locking to
7991             # block entire periodic task thread
7992             uuid = db_instance.uuid
7993             if uuid in self._syncs_in_progress:
7994                 LOG.debug('Sync already in progress for %s', uuid)
7995             else:
7996                 LOG.debug('Triggering sync for uuid %s', uuid)
7997                 self._syncs_in_progress[uuid] = True
7998                 self._sync_power_pool.spawn_n(_sync, db_instance)
7999 
8000     def _query_driver_power_state_and_sync(self, context, db_instance):
8001         if db_instance.task_state is not None:
8002             LOG.info("During sync_power_state the instance has a "
8003                      "pending task (%(task)s). Skip.",
8004                      {'task': db_instance.task_state}, instance=db_instance)
8005             return
8006         # No pending tasks. Now try to figure out the real vm_power_state.
8007         try:
8008             vm_instance = self.driver.get_info(db_instance)
8009             vm_power_state = vm_instance.state
8010         except exception.InstanceNotFound:
8011             vm_power_state = power_state.NOSTATE
8012         # Note(maoy): the above get_info call might take a long time,
8013         # for example, because of a broken libvirt driver.
8014         try:
8015             self._sync_instance_power_state(context,
8016                                             db_instance,
8017                                             vm_power_state,
8018                                             use_slave=True)
8019         except exception.InstanceNotFound:
8020             # NOTE(hanlind): If the instance gets deleted during sync,
8021             # silently ignore.
8022             pass
8023 
8024     def _stop_unexpected_shutdown_instance(self, context, vm_state,
8025                                            db_instance, orig_db_power_state):
8026         # this is an exceptional case; make sure our data is up
8027         # to date before slamming through a power off
8028         vm_instance = self.driver.get_info(db_instance,
8029                                            use_cache=False)
8030         vm_power_state = vm_instance.state
8031 
8032         # if it still looks off, go ahead and call stop()
8033         if vm_power_state in (power_state.SHUTDOWN,
8034                               power_state.CRASHED):
8035 
8036             LOG.warning("Instance shutdown by itself. Calling the "
8037                         "stop API. Current vm_state: %(vm_state)s, "
8038                         "current task_state: %(task_state)s, "
8039                         "original DB power_state: %(db_power_state)s, "
8040                         "current VM power_state: %(vm_power_state)s",
8041                         {'vm_state': vm_state,
8042                          'task_state': db_instance.task_state,
8043                          'db_power_state': orig_db_power_state,
8044                          'vm_power_state': vm_power_state},
8045                         instance=db_instance)
8046             try:
8047                 # Note(maoy): here we call the API instead of
8048                 # brutally updating the vm_state in the database
8049                 # to allow all the hooks and checks to be performed.
8050                 if db_instance.shutdown_terminate:
8051                     self.compute_api.delete(context, db_instance)
8052                 else:
8053                     self.compute_api.stop(context, db_instance)
8054             except Exception:
8055                 # Note(maoy): there is no need to propagate the error
8056                 # because the same power_state will be retrieved next
8057                 # time and retried.
8058                 # For example, there might be another task scheduled.
8059                 LOG.exception("error during stop() in sync_power_state.",
8060                               instance=db_instance)
8061 
8062     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
8063                                    use_slave=False):
8064         """Align instance power state between the database and hypervisor.
8065 
8066         If the instance is not found on the hypervisor, but is in the database,
8067         then a stop() API will be called on the instance.
8068         """
8069 
8070         # We re-query the DB to get the latest instance info to minimize
8071         # (not eliminate) race condition.
8072         db_instance.refresh(use_slave=use_slave)
8073         db_power_state = db_instance.power_state
8074         vm_state = db_instance.vm_state
8075 
8076         if self.host != db_instance.host:
8077             # on the sending end of nova-compute _sync_power_state
8078             # may have yielded to the greenthread performing a live
8079             # migration; this in turn has changed the resident-host
8080             # for the VM; However, the instance is still active, it
8081             # is just in the process of migrating to another host.
8082             # This implies that the compute source must relinquish
8083             # control to the compute destination.
8084             LOG.info("During the sync_power process the "
8085                      "instance has moved from "
8086                      "host %(src)s to host %(dst)s",
8087                      {'src': db_instance.host,
8088                       'dst': self.host},
8089                      instance=db_instance)
8090             return
8091         elif db_instance.task_state is not None:
8092             # on the receiving end of nova-compute, it could happen
8093             # that the DB instance already report the new resident
8094             # but the actual VM has not showed up on the hypervisor
8095             # yet. In this case, let's allow the loop to continue
8096             # and run the state sync in a later round
8097             LOG.info("During sync_power_state the instance has a "
8098                      "pending task (%(task)s). Skip.",
8099                      {'task': db_instance.task_state},
8100                      instance=db_instance)
8101             return
8102 
8103         orig_db_power_state = db_power_state
8104         if vm_power_state != db_power_state:
8105             LOG.info('During _sync_instance_power_state the DB '
8106                      'power_state (%(db_power_state)s) does not match '
8107                      'the vm_power_state from the hypervisor '
8108                      '(%(vm_power_state)s). Updating power_state in the '
8109                      'DB to match the hypervisor.',
8110                      {'db_power_state': db_power_state,
8111                       'vm_power_state': vm_power_state},
8112                      instance=db_instance)
8113             # power_state is always updated from hypervisor to db
8114             db_instance.power_state = vm_power_state
8115             db_instance.save()
8116             db_power_state = vm_power_state
8117 
8118         # Note(maoy): Now resolve the discrepancy between vm_state and
8119         # vm_power_state. We go through all possible vm_states.
8120         if vm_state in (vm_states.BUILDING,
8121                         vm_states.RESCUED,
8122                         vm_states.RESIZED,
8123                         vm_states.SUSPENDED,
8124                         vm_states.ERROR):
8125             # TODO(maoy): we ignore these vm_state for now.
8126             pass
8127         elif vm_state == vm_states.ACTIVE:
8128             # The only rational power state should be RUNNING
8129             if vm_power_state in (power_state.SHUTDOWN,
8130                                   power_state.CRASHED):
8131                 self._stop_unexpected_shutdown_instance(
8132                     context, vm_state, db_instance, orig_db_power_state)
8133             elif vm_power_state == power_state.SUSPENDED:
8134                 LOG.warning("Instance is suspended unexpectedly. Calling "
8135                             "the stop API.", instance=db_instance)
8136                 try:
8137                     self.compute_api.stop(context, db_instance)
8138                 except Exception:
8139                     LOG.exception("error during stop() in sync_power_state.",
8140                                   instance=db_instance)
8141             elif vm_power_state == power_state.PAUSED:
8142                 # Note(maoy): a VM may get into the paused state not only
8143                 # because the user request via API calls, but also
8144                 # due to (temporary) external instrumentations.
8145                 # Before the virt layer can reliably report the reason,
8146                 # we simply ignore the state discrepancy. In many cases,
8147                 # the VM state will go back to running after the external
8148                 # instrumentation is done. See bug 1097806 for details.
8149                 LOG.warning("Instance is paused unexpectedly. Ignore.",
8150                             instance=db_instance)
8151             elif vm_power_state == power_state.NOSTATE:
8152                 # Occasionally, depending on the status of the hypervisor,
8153                 # which could be restarting for example, an instance may
8154                 # not be found.  Therefore just log the condition.
8155                 LOG.warning("Instance is unexpectedly not found. Ignore.",
8156                             instance=db_instance)
8157         elif vm_state == vm_states.STOPPED:
8158             if vm_power_state not in (power_state.NOSTATE,
8159                                       power_state.SHUTDOWN,
8160                                       power_state.CRASHED):
8161                 LOG.warning("Instance is not stopped. Calling "
8162                             "the stop API. Current vm_state: %(vm_state)s,"
8163                             " current task_state: %(task_state)s, "
8164                             "original DB power_state: %(db_power_state)s, "
8165                             "current VM power_state: %(vm_power_state)s",
8166                             {'vm_state': vm_state,
8167                              'task_state': db_instance.task_state,
8168                              'db_power_state': orig_db_power_state,
8169                              'vm_power_state': vm_power_state},
8170                             instance=db_instance)
8171                 try:
8172                     # NOTE(russellb) Force the stop, because normally the
8173                     # compute API would not allow an attempt to stop a stopped
8174                     # instance.
8175                     self.compute_api.force_stop(context, db_instance)
8176                 except Exception:
8177                     LOG.exception("error during stop() in sync_power_state.",
8178                                   instance=db_instance)
8179         elif vm_state == vm_states.PAUSED:
8180             if vm_power_state in (power_state.SHUTDOWN,
8181                                   power_state.CRASHED):
8182                 LOG.warning("Paused instance shutdown by itself. Calling "
8183                             "the stop API.", instance=db_instance)
8184                 try:
8185                     self.compute_api.force_stop(context, db_instance)
8186                 except Exception:
8187                     LOG.exception("error during stop() in sync_power_state.",
8188                                   instance=db_instance)
8189         elif vm_state in (vm_states.SOFT_DELETED,
8190                           vm_states.DELETED):
8191             if vm_power_state not in (power_state.NOSTATE,
8192                                       power_state.SHUTDOWN):
8193                 # Note(maoy): this should be taken care of periodically in
8194                 # _cleanup_running_deleted_instances().
8195                 LOG.warning("Instance is not (soft-)deleted.",
8196                             instance=db_instance)
8197 
8198     @periodic_task.periodic_task
8199     def _reclaim_queued_deletes(self, context):
8200         """Reclaim instances that are queued for deletion."""
8201         interval = CONF.reclaim_instance_interval
8202         if interval <= 0:
8203             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
8204             return
8205 
8206         filters = {'vm_state': vm_states.SOFT_DELETED,
8207                    'task_state': None,
8208                    'host': self.host}
8209         instances = objects.InstanceList.get_by_filters(
8210             context, filters,
8211             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
8212             use_slave=True)
8213         for instance in instances:
8214             if self._deleted_old_enough(instance, interval):
8215                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
8216                         context, instance.uuid)
8217                 LOG.info('Reclaiming deleted instance', instance=instance)
8218                 try:
8219                     self._delete_instance(context, instance, bdms)
8220                 except Exception as e:
8221                     LOG.warning("Periodic reclaim failed to delete "
8222                                 "instance: %s",
8223                                 e, instance=instance)
8224 
8225     def _get_nodename(self, instance, refresh=False):
8226         """Helper method to get the name of the first available node
8227         on this host. This method should not be used with any operations
8228         on ironic instances since it does not handle multiple nodes.
8229         """
8230         node = self.driver.get_available_nodes(refresh=refresh)[0]
8231         LOG.debug("No node specified, defaulting to %s", node,
8232                   instance=instance)
8233         return node
8234 
8235     def _update_available_resource_for_node(self, context, nodename,
8236                                             startup=False):
8237 
8238         try:
8239             self.rt.update_available_resource(context, nodename,
8240                                               startup=startup)
8241         except exception.ComputeHostNotFound:
8242             LOG.warning("Compute node '%s' not found in "
8243                         "update_available_resource.", nodename)
8244         except exception.ReshapeFailed:
8245             # We're only supposed to get here on startup, if a reshape was
8246             # needed, was attempted, and failed. We want to kill the service.
8247             with excutils.save_and_reraise_exception():
8248                 LOG.critical("Resource provider data migration failed "
8249                              "fatally during startup for node %s.", nodename)
8250         except exception.ReshapeNeeded:
8251             # This exception should only find its way here if the virt driver's
8252             # update_provider_tree raised it incorrectly: either
8253             # a) After the resource tracker already caught it once and
8254             # reinvoked update_provider_tree with allocations. At this point
8255             # the driver is just supposed to *do* the reshape, so if it raises
8256             # ReshapeNeeded, it's a bug, and we want to kill the compute
8257             # service.
8258             # b) On periodic rather than startup (we only allow reshapes to
8259             # happen on startup). In this case we'll just make the logs red and
8260             # go again at the next periodic interval, where the same thing may
8261             # or may not happen again. Depending on the previous and intended
8262             # shape of the providers/inventories, this may not actually cause
8263             # any immediately visible symptoms (in terms of scheduling, etc.)
8264             # If this becomes a problem, we may wish to make it pop immediately
8265             # (e.g. disable the service).
8266             with excutils.save_and_reraise_exception():
8267                 LOG.exception("ReshapeNeeded exception is unexpected here!")
8268         except Exception:
8269             LOG.exception("Error updating resources for node %(node)s.",
8270                           {'node': nodename})
8271 
8272     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
8273     def update_available_resource(self, context, startup=False):
8274         """See driver.get_available_resource()
8275 
8276         Periodic process that keeps that the compute host's understanding of
8277         resource availability and usage in sync with the underlying hypervisor.
8278 
8279         :param context: security context
8280         :param startup: True if this is being called when the nova-compute
8281             service is starting, False otherwise.
8282         """
8283 
8284         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
8285                                                             use_slave=True,
8286                                                             startup=startup)
8287         try:
8288             nodenames = set(self.driver.get_available_nodes())
8289         except exception.VirtDriverNotReady:
8290             LOG.warning("Virt driver is not ready.")
8291             return
8292 
8293         # Delete orphan compute node not reported by driver but still in db
8294         for cn in compute_nodes_in_db:
8295             if cn.hypervisor_hostname not in nodenames:
8296                 LOG.info("Deleting orphan compute node %(id)s "
8297                          "hypervisor host is %(hh)s, "
8298                          "nodes are %(nodes)s",
8299                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
8300                           'nodes': nodenames})
8301                 cn.destroy()
8302                 self.rt.remove_node(cn.hypervisor_hostname)
8303                 # Delete the corresponding resource provider in placement,
8304                 # along with any associated allocations and inventory.
8305                 self.reportclient.delete_resource_provider(context, cn,
8306                                                            cascade=True)
8307 
8308         for nodename in nodenames:
8309             self._update_available_resource_for_node(context, nodename,
8310                                                      startup=startup)
8311 
8312     def _get_compute_nodes_in_db(self, context, use_slave=False,
8313                                  startup=False):
8314         try:
8315             return objects.ComputeNodeList.get_all_by_host(context, self.host,
8316                                                            use_slave=use_slave)
8317         except exception.NotFound:
8318             if startup:
8319                 LOG.warning(
8320                     "No compute node record found for host %s. If this is "
8321                     "the first time this service is starting on this "
8322                     "host, then you can ignore this warning.", self.host)
8323             else:
8324                 LOG.error("No compute node record for host %s", self.host)
8325             return []
8326 
8327     @periodic_task.periodic_task(
8328         spacing=CONF.running_deleted_instance_poll_interval,
8329         run_immediately=True)
8330     def _cleanup_running_deleted_instances(self, context):
8331         """Cleanup any instances which are erroneously still running after
8332         having been deleted.
8333 
8334         Valid actions to take are:
8335 
8336             1. noop - do nothing
8337             2. log - log which instances are erroneously running
8338             3. reap - shutdown and cleanup any erroneously running instances
8339             4. shutdown - power off *and disable* any erroneously running
8340                           instances
8341 
8342         The use-case for this cleanup task is: for various reasons, it may be
8343         possible for the database to show an instance as deleted but for that
8344         instance to still be running on a host machine (see bug
8345         https://bugs.launchpad.net/nova/+bug/911366).
8346 
8347         This cleanup task is a cross-hypervisor utility for finding these
8348         zombied instances and either logging the discrepancy (likely what you
8349         should do in production), or automatically reaping the instances (more
8350         appropriate for dev environments).
8351         """
8352         action = CONF.running_deleted_instance_action
8353 
8354         if action == "noop":
8355             return
8356 
8357         # NOTE(sirp): admin contexts don't ordinarily return deleted records
8358         with utils.temporary_mutation(context, read_deleted="yes"):
8359             for instance in self._running_deleted_instances(context):
8360                 if action == "log":
8361                     LOG.warning("Detected instance with name label "
8362                                 "'%s' which is marked as "
8363                                 "DELETED but still present on host.",
8364                                 instance.name, instance=instance)
8365 
8366                 elif action == 'shutdown':
8367                     LOG.info("Powering off instance with name label "
8368                              "'%s' which is marked as "
8369                              "DELETED but still present on host.",
8370                              instance.name, instance=instance)
8371                     try:
8372                         try:
8373                             # disable starting the instance
8374                             self.driver.set_bootable(instance, False)
8375                         except NotImplementedError:
8376                             LOG.debug("set_bootable is not implemented "
8377                                       "for the current driver")
8378                         # and power it off
8379                         self.driver.power_off(instance)
8380                     except Exception:
8381                         LOG.warning("Failed to power off instance",
8382                                     instance=instance, exc_info=True)
8383 
8384                 elif action == 'reap':
8385                     LOG.info("Destroying instance with name label "
8386                              "'%s' which is marked as "
8387                              "DELETED but still present on host.",
8388                              instance.name, instance=instance)
8389                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
8390                         context, instance.uuid, use_slave=True)
8391                     self.instance_events.clear_events_for_instance(instance)
8392                     try:
8393                         self._shutdown_instance(context, instance, bdms,
8394                                                 notify=False)
8395                         self._cleanup_volumes(context, instance, bdms,
8396                                               detach=False)
8397                     except Exception as e:
8398                         LOG.warning("Periodic cleanup failed to delete "
8399                                     "instance: %s",
8400                                     e, instance=instance)
8401                 else:
8402                     raise Exception(_("Unrecognized value '%s'"
8403                                       " for CONF.running_deleted_"
8404                                       "instance_action") % action)
8405 
8406     def _running_deleted_instances(self, context):
8407         """Returns a list of instances nova thinks is deleted,
8408         but the hypervisor thinks is still running.
8409         """
8410         timeout = CONF.running_deleted_instance_timeout
8411         filters = {'deleted': True,
8412                    'soft_deleted': False}
8413         instances = self._get_instances_on_driver(context, filters)
8414         return [i for i in instances if self._deleted_old_enough(i, timeout)]
8415 
8416     def _deleted_old_enough(self, instance, timeout):
8417         deleted_at = instance.deleted_at
8418         if deleted_at:
8419             deleted_at = deleted_at.replace(tzinfo=None)
8420         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
8421 
8422     @contextlib.contextmanager
8423     def _error_out_instance_on_exception(self, context, instance,
8424                                          instance_state=vm_states.ACTIVE):
8425         """Context manager to set instance.vm_state after some operation raises
8426 
8427         Used to handle NotImplementedError and InstanceFaultRollback errors
8428         and reset the instance vm_state and task_state. The vm_state is set
8429         to the $instance_state parameter and task_state is set to None.
8430         For all other types of exceptions, the vm_state is set to ERROR and
8431         the task_state is left unchanged (although most callers will have the
8432         @reverts_task_state decorator which will set the task_state to None).
8433 
8434         Re-raises the original exception *except* in the case of
8435         InstanceFaultRollback in which case the wrapped `inner_exception` is
8436         re-raised.
8437 
8438         :param context: The nova auth request context for the operation.
8439         :param instance: The instance to update. The vm_state will be set by
8440             this context manager when an exception is raised.
8441         :param instance_state: For NotImplementedError and
8442             InstanceFaultRollback this is the vm_state to set the instance to
8443             when handling one of those types of exceptions. By default the
8444             instance will be set to ACTIVE, but the caller should control this
8445             in case there have been no changes to the running state of the
8446             instance. For example, resizing a stopped server where prep_resize
8447             fails early and does not change the power state of the guest should
8448             not set the instance status to ACTIVE but remain STOPPED.
8449             This parameter is ignored for all other types of exceptions and the
8450             instance vm_state is set to ERROR.
8451         """
8452         # NOTE(mriedem): Why doesn't this method just save off the
8453         # original instance.vm_state here rather than use a parameter? Or use
8454         # instance_state=None as an override but default to the current
8455         # vm_state when rolling back.
8456         instance_uuid = instance.uuid
8457         try:
8458             yield
8459         except (NotImplementedError, exception.InstanceFaultRollback) as error:
8460             # Use reraise=False to determine if we want to raise the original
8461             # exception or something else.
8462             with excutils.save_and_reraise_exception(reraise=False) as ctxt:
8463                 LOG.info("Setting instance back to %(state)s after: %(error)s",
8464                          {'state': instance_state, 'error': error},
8465                          instance_uuid=instance_uuid)
8466                 self._instance_update(context, instance,
8467                                       vm_state=instance_state,
8468                                       task_state=None)
8469                 if isinstance(error, exception.InstanceFaultRollback):
8470                     # Raise the wrapped exception.
8471                     raise error.inner_exception
8472                 # Else re-raise the NotImplementedError.
8473                 ctxt.reraise = True
8474         except Exception:
8475             LOG.exception('Setting instance vm_state to ERROR',
8476                           instance_uuid=instance_uuid)
8477             with excutils.save_and_reraise_exception():
8478                 # NOTE(mriedem): Why don't we pass clean_task_state=True here?
8479                 self._set_instance_obj_error_state(context, instance)
8480 
8481     @wrap_exception()
8482     def add_aggregate_host(self, context, aggregate, host, slave_info):
8483         """Notify hypervisor of change (for hypervisor pools)."""
8484         try:
8485             self.driver.add_to_aggregate(context, aggregate, host,
8486                                          slave_info=slave_info)
8487         except NotImplementedError:
8488             LOG.debug('Hypervisor driver does not support '
8489                       'add_aggregate_host')
8490         except exception.AggregateError:
8491             with excutils.save_and_reraise_exception():
8492                 self.driver.undo_aggregate_operation(
8493                                     context,
8494                                     aggregate.delete_host,
8495                                     aggregate, host)
8496 
8497     @wrap_exception()
8498     def remove_aggregate_host(self, context, host, slave_info, aggregate):
8499         """Removes a host from a physical hypervisor pool."""
8500         try:
8501             self.driver.remove_from_aggregate(context, aggregate, host,
8502                                               slave_info=slave_info)
8503         except NotImplementedError:
8504             LOG.debug('Hypervisor driver does not support '
8505                       'remove_aggregate_host')
8506         except (exception.AggregateError,
8507                 exception.InvalidAggregateAction) as e:
8508             with excutils.save_and_reraise_exception():
8509                 self.driver.undo_aggregate_operation(
8510                                     context,
8511                                     aggregate.add_host,
8512                                     aggregate, host,
8513                                     isinstance(e, exception.AggregateError))
8514 
8515     def _process_instance_event(self, instance, event):
8516         _event = self.instance_events.pop_instance_event(instance, event)
8517         if _event:
8518             LOG.debug('Processing event %(event)s',
8519                       {'event': event.key}, instance=instance)
8520             _event.send(event)
8521         else:
8522             # If it's a network-vif-unplugged event and the instance is being
8523             # deleted or live migrated then we don't need to make this a
8524             # warning as it's expected. There are other expected things which
8525             # could trigger this event like detaching an interface, but we
8526             # don't have a task state for that.
8527             # TODO(mriedem): We have other move operations and things like
8528             # hard reboot (probably rebuild as well) which trigger this event
8529             # but nothing listens for network-vif-unplugged. We should either
8530             # handle those other known cases or consider just not logging a
8531             # warning if we get this event and the instance is undergoing some
8532             # task state transition.
8533             if (event.name == 'network-vif-unplugged' and
8534                     instance.task_state in (
8535                         task_states.DELETING, task_states.MIGRATING)):
8536                 LOG.debug('Received event %s for instance with task_state %s.',
8537                           event.key, instance.task_state, instance=instance)
8538             else:
8539                 LOG.warning('Received unexpected event %(event)s for '
8540                             'instance with vm_state %(vm_state)s and '
8541                             'task_state %(task_state)s.',
8542                             {'event': event.key,
8543                              'vm_state': instance.vm_state,
8544                              'task_state': instance.task_state},
8545                             instance=instance)
8546 
8547     def _process_instance_vif_deleted_event(self, context, instance,
8548                                             deleted_vif_id):
8549         # If an attached port is deleted by neutron, it needs to
8550         # be detached from the instance.
8551         # And info cache needs to be updated.
8552         network_info = instance.info_cache.network_info
8553         for index, vif in enumerate(network_info):
8554             if vif['id'] == deleted_vif_id:
8555                 LOG.info('Neutron deleted interface %(intf)s; '
8556                          'detaching it from the instance and '
8557                          'deleting it from the info cache',
8558                          {'intf': vif['id']},
8559                          instance=instance)
8560                 profile = vif.get('profile', {}) or {}  # profile can be None
8561                 if profile.get('allocation'):
8562                     LOG.error(
8563                         'The bound port %(port_id)s is deleted in Neutron but '
8564                         'the resource allocation on the resource provider '
8565                         '%(rp_uuid)s is leaked until the server '
8566                         '%(server_uuid)s is deleted.',
8567                         {'port_id': vif['id'],
8568                          'rp_uuid': vif['profile']['allocation'],
8569                          'server_uuid': instance.uuid})
8570 
8571                 del network_info[index]
8572                 base_net_api.update_instance_cache_with_nw_info(
8573                                  self.network_api, context,
8574                                  instance,
8575                                  nw_info=network_info)
8576                 try:
8577                     self.driver.detach_interface(context, instance, vif)
8578                 except NotImplementedError:
8579                     # Not all virt drivers support attach/detach of interfaces
8580                     # yet (like Ironic), so just ignore this.
8581                     pass
8582                 except exception.NovaException as ex:
8583                     # If the instance was deleted before the interface was
8584                     # detached, just log it at debug.
8585                     log_level = (logging.DEBUG
8586                                  if isinstance(ex, exception.InstanceNotFound)
8587                                  else logging.WARNING)
8588                     LOG.log(log_level,
8589                             "Detach interface failed, "
8590                             "port_id=%(port_id)s, reason: %(msg)s",
8591                             {'port_id': deleted_vif_id, 'msg': ex},
8592                             instance=instance)
8593                 break
8594 
8595     @wrap_instance_event(prefix='compute')
8596     @wrap_instance_fault
8597     def extend_volume(self, context, instance, extended_volume_id):
8598 
8599         # If an attached volume is extended by cinder, it needs to
8600         # be extended by virt driver so host can detect its new size.
8601         # And bdm needs to be updated.
8602         LOG.debug('Handling volume-extended event for volume %(vol)s',
8603                   {'vol': extended_volume_id}, instance=instance)
8604 
8605         try:
8606             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
8607                    context, extended_volume_id, instance.uuid)
8608         except exception.NotFound:
8609             LOG.warning('Extend volume failed, '
8610                         'volume %(vol)s is not attached to instance.',
8611                         {'vol': extended_volume_id},
8612                         instance=instance)
8613             return
8614 
8615         LOG.info('Cinder extended volume %(vol)s; '
8616                  'extending it to detect new size',
8617                  {'vol': extended_volume_id},
8618                  instance=instance)
8619         volume = self.volume_api.get(context, bdm.volume_id)
8620 
8621         if bdm.connection_info is None:
8622             LOG.warning('Extend volume failed, '
8623                         'attached volume %(vol)s has no connection_info',
8624                         {'vol': extended_volume_id},
8625                         instance=instance)
8626             return
8627 
8628         connection_info = jsonutils.loads(bdm.connection_info)
8629         bdm.volume_size = volume['size']
8630         bdm.save()
8631 
8632         if not self.driver.capabilities.get('supports_extend_volume', False):
8633             raise exception.ExtendVolumeNotSupported()
8634 
8635         try:
8636             self.driver.extend_volume(connection_info,
8637                                       instance,
8638                                       bdm.volume_size * units.Gi)
8639         except Exception as ex:
8640             LOG.warning('Extend volume failed, '
8641                         'volume_id=%(volume_id)s, reason: %(msg)s',
8642                         {'volume_id': extended_volume_id, 'msg': ex},
8643                         instance=instance)
8644             raise
8645 
8646     @wrap_exception()
8647     @reverts_task_state
8648     @wrap_instance_event(prefix='compute')
8649     @wrap_instance_fault
8650     def power_update(self, context, instance, target_power_state):
8651         LOG.debug('Handling power-update event for instance',
8652                   instance=instance)
8653         if target_power_state == "POWER_ON":
8654             self._notify_about_instance_usage(context, instance,
8655                                               "power_on.start")
8656             compute_utils.notify_about_instance_action(context, instance,
8657                 self.host, action=fields.NotificationAction.POWER_ON,
8658                 phase=fields.NotificationPhase.START)
8659             self.driver.power_update_event(
8660                 context, instance, target_power_state)
8661             self._notify_about_instance_usage(context, instance,
8662                                               "power_on.end")
8663             compute_utils.notify_about_instance_action(context, instance,
8664                 self.host, action=fields.NotificationAction.POWER_ON,
8665                 phase=fields.NotificationPhase.END)
8666         else:
8667             self._notify_about_instance_usage(context, instance,
8668                                               "power_off.start")
8669             compute_utils.notify_about_instance_action(context, instance,
8670                         self.host, action=fields.NotificationAction.POWER_OFF,
8671                         phase=fields.NotificationPhase.START)
8672             self.driver.power_update_event(
8673                 context, instance, target_power_state)
8674             self._notify_about_instance_usage(context, instance,
8675                                               "power_off.end")
8676             compute_utils.notify_about_instance_action(context, instance,
8677                         self.host, action=fields.NotificationAction.POWER_OFF,
8678                         phase=fields.NotificationPhase.END)
8679 
8680     @wrap_exception()
8681     def external_instance_event(self, context, instances, events):
8682         # NOTE(danms): Some event types are handled by the manager, such
8683         # as when we're asked to update the instance's info_cache. If it's
8684         # not one of those, look for some thread(s) waiting for the event and
8685         # unblock them if so.
8686         for event in events:
8687             instance = [inst for inst in instances
8688                         if inst.uuid == event.instance_uuid][0]
8689             LOG.debug('Received event %(event)s',
8690                       {'event': event.key},
8691                       instance=instance)
8692             if event.name == 'network-changed':
8693                 try:
8694                     LOG.debug('Refreshing instance network info cache due to '
8695                               'event %s.', event.key, instance=instance)
8696                     self.network_api.get_instance_nw_info(
8697                         context, instance, refresh_vif_id=event.tag)
8698                 except exception.NotFound as e:
8699                     LOG.info('Failed to process external instance event '
8700                              '%(event)s due to: %(error)s',
8701                              {'event': event.key, 'error': six.text_type(e)},
8702                              instance=instance)
8703             elif event.name == 'network-vif-deleted':
8704                 try:
8705                     self._process_instance_vif_deleted_event(context,
8706                                                              instance,
8707                                                              event.tag)
8708                 except exception.NotFound as e:
8709                     LOG.info('Failed to process external instance event '
8710                              '%(event)s due to: %(error)s',
8711                              {'event': event.key, 'error': six.text_type(e)},
8712                              instance=instance)
8713             elif event.name == 'volume-extended':
8714                 self.extend_volume(context, instance, event.tag)
8715             elif event.name == 'power-update':
8716                 self.power_update(context, instance, event.tag)
8717             else:
8718                 self._process_instance_event(instance, event)
8719 
8720     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
8721                                  external_process_ok=True)
8722     def _run_image_cache_manager_pass(self, context):
8723         """Run a single pass of the image cache manager."""
8724 
8725         if not self.driver.capabilities.get("has_imagecache", False):
8726             return
8727 
8728         # Determine what other nodes use this storage
8729         storage_users.register_storage_use(CONF.instances_path, CONF.host)
8730         nodes = storage_users.get_storage_users(CONF.instances_path)
8731 
8732         # Filter all_instances to only include those nodes which share this
8733         # storage path.
8734         # TODO(mikal): this should be further refactored so that the cache
8735         # cleanup code doesn't know what those instances are, just a remote
8736         # count, and then this logic should be pushed up the stack.
8737         filters = {'deleted': False,
8738                    'soft_deleted': True,
8739                    'host': nodes}
8740         filtered_instances = objects.InstanceList.get_by_filters(context,
8741                                  filters, expected_attrs=[], use_slave=True)
8742 
8743         self.driver.manage_image_cache(context, filtered_instances)
8744 
8745     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8746     def _run_pending_deletes(self, context):
8747         """Retry any pending instance file deletes."""
8748         LOG.debug('Cleaning up deleted instances')
8749         filters = {'deleted': True,
8750                    'soft_deleted': False,
8751                    'host': CONF.host,
8752                    'cleaned': False}
8753         attrs = ['system_metadata']
8754         with utils.temporary_mutation(context, read_deleted='yes'):
8755             instances = objects.InstanceList.get_by_filters(
8756                 context, filters, expected_attrs=attrs, use_slave=True)
8757         LOG.debug('There are %d instances to clean', len(instances))
8758 
8759         for instance in instances:
8760             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
8761             LOG.debug('Instance has had %(attempts)s of %(max)s '
8762                       'cleanup attempts',
8763                       {'attempts': attempts,
8764                        'max': CONF.maximum_instance_delete_attempts},
8765                       instance=instance)
8766             if attempts < CONF.maximum_instance_delete_attempts:
8767                 success = self.driver.delete_instance_files(instance)
8768 
8769                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
8770                 if success:
8771                     instance.cleaned = True
8772                 with utils.temporary_mutation(context, read_deleted='yes'):
8773                     instance.save()
8774 
8775     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8776     def _cleanup_incomplete_migrations(self, context):
8777         """Delete instance files on failed resize/revert-resize operation
8778 
8779         During resize/revert-resize operation, if that instance gets deleted
8780         in-between then instance files might remain either on source or
8781         destination compute node because of race condition.
8782         """
8783         LOG.debug('Cleaning up deleted instances with incomplete migration ')
8784         migration_filters = {'host': CONF.host,
8785                              'status': 'error'}
8786         migrations = objects.MigrationList.get_by_filters(context,
8787                                                           migration_filters)
8788 
8789         if not migrations:
8790             return
8791 
8792         inst_uuid_from_migrations = set([migration.instance_uuid for migration
8793                                          in migrations])
8794 
8795         inst_filters = {'deleted': True, 'soft_deleted': False,
8796                         'uuid': inst_uuid_from_migrations}
8797         attrs = ['info_cache', 'security_groups', 'system_metadata']
8798         with utils.temporary_mutation(context, read_deleted='yes'):
8799             instances = objects.InstanceList.get_by_filters(
8800                 context, inst_filters, expected_attrs=attrs, use_slave=True)
8801 
8802         for instance in instances:
8803             if instance.host != CONF.host:
8804                 for migration in migrations:
8805                     if instance.uuid == migration.instance_uuid:
8806                         # Delete instance files if not cleanup properly either
8807                         # from the source or destination compute nodes when
8808                         # the instance is deleted during resizing.
8809                         self.driver.delete_instance_files(instance)
8810                         try:
8811                             migration.status = 'failed'
8812                             migration.save()
8813                         except exception.MigrationNotFound:
8814                             LOG.warning("Migration %s is not found.",
8815                                         migration.id,
8816                                         instance=instance)
8817                         break
8818 
8819     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8820                                    exception.QemuGuestAgentNotEnabled,
8821                                    exception.NovaException,
8822                                    NotImplementedError)
8823     @wrap_exception()
8824     def quiesce_instance(self, context, instance):
8825         """Quiesce an instance on this host."""
8826         context = context.elevated()
8827         image_meta = objects.ImageMeta.from_instance(instance)
8828         self.driver.quiesce(context, instance, image_meta)
8829 
8830     def _wait_for_snapshots_completion(self, context, mapping):
8831         for mapping_dict in mapping:
8832             if mapping_dict.get('source_type') == 'snapshot':
8833 
8834                 def _wait_snapshot():
8835                     snapshot = self.volume_api.get_snapshot(
8836                         context, mapping_dict['snapshot_id'])
8837                     if snapshot.get('status') != 'creating':
8838                         raise loopingcall.LoopingCallDone()
8839 
8840                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
8841                 timer.start(interval=0.5).wait()
8842 
8843     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8844                                    exception.QemuGuestAgentNotEnabled,
8845                                    exception.NovaException,
8846                                    NotImplementedError)
8847     @wrap_exception()
8848     def unquiesce_instance(self, context, instance, mapping=None):
8849         """Unquiesce an instance on this host.
8850 
8851         If snapshots' image mapping is provided, it waits until snapshots are
8852         completed before unqueiscing.
8853         """
8854         context = context.elevated()
8855         if mapping:
8856             try:
8857                 self._wait_for_snapshots_completion(context, mapping)
8858             except Exception as error:
8859                 LOG.exception("Exception while waiting completion of "
8860                               "volume snapshots: %s",
8861                               error, instance=instance)
8862         image_meta = objects.ImageMeta.from_instance(instance)
8863         self.driver.unquiesce(context, instance, image_meta)
8864 
8865     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8866     def _cleanup_expired_console_auth_tokens(self, context):
8867         """Remove expired console auth tokens for this host.
8868 
8869         Console authorization tokens and their connection data are stored
8870         in the database when a user asks for a console connection to an
8871         instance. After a time they expire. We periodically remove any expired
8872         tokens from the database.
8873         """
8874         objects.ConsoleAuthToken.clean_expired_console_auths_for_host(
8875             context, self.host)
8876 
8877     def _claim_pci_for_instance_vifs(self, ctxt, instance):
8878         """Claim PCI devices for the instance's VIFs on the compute node
8879 
8880         :param ctxt: Context
8881         :param instance: Instance object
8882         :return: <port ID: PciDevice> mapping for the VIFs that yielded a
8883                 PCI claim on the compute node
8884         """
8885         pci_req_id_to_port_id = {}
8886         pci_reqs = []
8887         port_id_to_pci_dev = {}
8888 
8889         for vif in instance.get_network_info():
8890             pci_req = pci_req_module.get_instance_pci_request_from_vif(
8891                 ctxt,
8892                 instance,
8893                 vif)
8894             if pci_req:
8895                 pci_req_id_to_port_id[pci_req.request_id] = vif['id']
8896                 pci_reqs.append(pci_req)
8897 
8898         if pci_reqs:
8899             # Create PCI requests and claim against PCI resource tracker
8900             # NOTE(adrianc): We claim against the same requests as on the
8901             # source node.
8902             vif_pci_requests = objects.InstancePCIRequests(
8903                 requests=pci_reqs,
8904                 instance_uuid=instance.uuid)
8905 
8906             claimed_pci_devices_objs = self.rt.claim_pci_devices(
8907                 ctxt,
8908                 vif_pci_requests)
8909 
8910             # Update VIFMigrateData profile with the newly claimed PCI
8911             # device
8912             for pci_dev in claimed_pci_devices_objs:
8913                 LOG.debug("PCI device: %s Claimed on destination node",
8914                           pci_dev.address)
8915                 port_id = pci_req_id_to_port_id[pci_dev.request_id]
8916                 port_id_to_pci_dev[port_id] = pci_dev
8917 
8918         return port_id_to_pci_dev
8919 
8920     def _update_migrate_vifs_profile_with_pci(self,
8921                                               migrate_vifs,
8922                                               port_id_to_pci_dev):
8923         """Update migrate vifs profile with the claimed PCI devices
8924 
8925         :param migrate_vifs: list of VIFMigrateData objects
8926         :param port_id_to_pci_dev: a <port_id: PciDevice> mapping
8927         :return: None.
8928         """
8929         for mig_vif in migrate_vifs:
8930             port_id = mig_vif.port_id
8931             if port_id not in port_id_to_pci_dev:
8932                 continue
8933 
8934             pci_dev = port_id_to_pci_dev[port_id]
8935             profile = copy.deepcopy(mig_vif.source_vif['profile'])
8936             profile['pci_slot'] = pci_dev.address
8937             profile['pci_vendor_info'] = ':'.join([pci_dev.vendor_id,
8938                                                    pci_dev.product_id])
8939             mig_vif.profile = profile
8940             LOG.debug("Updating migrate VIF profile for port %(port_id)s:"
8941                       "%(profile)s", {'port_id': port_id,
8942                                       'profile': profile})
