Please review the code below for security defects using the CWE (Common Weakness Enumeration) as a reference standard. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are detected, state: 'No security defects are detected in the code'.

1 # Copyright (c) 2011 X.commerce, a business unit of eBay Inc.
2 # Copyright 2010 United States Government as represented by the
3 # Administrator of the National Aeronautics and Space Administration.
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Implementation of SQLAlchemy backend."""
19 
20 import collections
21 import copy
22 import datetime
23 import functools
24 import inspect
25 import traceback
26 
27 from oslo_db import api as oslo_db_api
28 from oslo_db import exception as db_exc
29 from oslo_db.sqlalchemy import enginefacade
30 from oslo_db.sqlalchemy import update_match
31 from oslo_db.sqlalchemy import utils as sqlalchemyutils
32 from oslo_log import log as logging
33 from oslo_utils import excutils
34 from oslo_utils import importutils
35 from oslo_utils import timeutils
36 from oslo_utils import uuidutils
37 import sqlalchemy as sa
38 from sqlalchemy import exc as sqla_exc
39 from sqlalchemy import orm
40 from sqlalchemy import schema
41 from sqlalchemy import sql
42 from sqlalchemy.sql import expression
43 from sqlalchemy.sql import func
44 
45 from nova import block_device
46 from nova.compute import task_states
47 from nova.compute import vm_states
48 import nova.conf
49 import nova.context
50 from nova.db.main import models
51 from nova.db import utils as db_utils
52 from nova.db.utils import require_context
53 from nova import exception
54 from nova.i18n import _
55 from nova import safe_utils
56 
57 profiler_sqlalchemy = importutils.try_import('osprofiler.sqlalchemy')
58 
59 CONF = nova.conf.CONF
60 LOG = logging.getLogger(__name__)
61 
62 DISABLE_DB_ACCESS = False
63 
64 context_manager = enginefacade.transaction_context()
65 
66 
67 def _get_db_conf(conf_group, connection=None):
68     kw = dict(conf_group.items())
69     if connection is not None:
70         kw['connection'] = connection
71     return kw
72 
73 
74 def _context_manager_from_context(context):
75     if context:
76         try:
77             return context.db_connection
78         except AttributeError:
79             pass
80 
81 
82 def _joinedload_all(lead_entity, column):
83     """Do a nested load.
84 
85     For example, resolve the following::
86 
87         _joinedload_all(models.SecurityGroup, 'instances.info_cache')
88 
89     to:
90 
91         orm.joinedload(
92             models.SecurityGroup.instances
93         ).joinedload(
94             Instance.info_cache
95         )
96     """
97     elements = column.split('.')
98     relationship_attr = getattr(lead_entity, elements.pop(0))
99     joined = orm.joinedload(relationship_attr)
100     for element in elements:
101         relationship_entity = relationship_attr.entity.class_
102         relationship_attr = getattr(relationship_entity, element)
103         joined = joined.joinedload(relationship_attr)
104 
105     return joined
106 
107 
108 def configure(conf):
109     context_manager.configure(**_get_db_conf(conf.database))
110 
111     if (
112         profiler_sqlalchemy and
113         CONF.profiler.enabled and
114         CONF.profiler.trace_sqlalchemy
115     ):
116         context_manager.append_on_engine_create(
117             lambda eng: profiler_sqlalchemy.add_tracing(sa, eng, "db"))
118 
119 
120 def create_context_manager(connection=None):
121     """Create a database context manager object for a cell database connection.
122 
123     :param connection: The database connection string
124     """
125     ctxt_mgr = enginefacade.transaction_context()
126     ctxt_mgr.configure(**_get_db_conf(CONF.database, connection=connection))
127     return ctxt_mgr
128 
129 
130 def get_context_manager(context):
131     """Get a database context manager object.
132 
133     :param context: The request context that can contain a context manager
134     """
135     return _context_manager_from_context(context) or context_manager
136 
137 
138 def get_engine(use_slave=False, context=None):
139     """Get a database engine object.
140 
141     :param use_slave: Whether to use the slave connection
142     :param context: The request context that can contain a context manager
143     """
144     ctxt_mgr = get_context_manager(context)
145     if use_slave:
146         return ctxt_mgr.reader.get_engine()
147     return ctxt_mgr.writer.get_engine()
148 
149 
150 _SHADOW_TABLE_PREFIX = 'shadow_'
151 _DEFAULT_QUOTA_NAME = 'default'
152 PER_PROJECT_QUOTAS = ['fixed_ips', 'floating_ips', 'networks']
153 
154 
155 def select_db_reader_mode(f):
156     """Decorator to select synchronous or asynchronous reader mode.
157 
158     The kwarg argument 'use_slave' defines reader mode. Asynchronous reader
159     will be used if 'use_slave' is True and synchronous reader otherwise.
160     If 'use_slave' is not specified default value 'False' will be used.
161 
162     Wrapped function must have a context in the arguments.
163     """
164 
165     @functools.wraps(f)
166     def wrapper(*args, **kwargs):
167         wrapped_func = safe_utils.get_wrapped_function(f)
168         keyed_args = inspect.getcallargs(wrapped_func, *args, **kwargs)
169 
170         context = keyed_args['context']
171         use_slave = keyed_args.get('use_slave', False)
172 
173         if use_slave:
174             reader_mode = get_context_manager(context).async_
175         else:
176             reader_mode = get_context_manager(context).reader
177 
178         with reader_mode.using(context):
179             return f(*args, **kwargs)
180     wrapper.__signature__ = inspect.signature(f)
181     return wrapper
182 
183 
184 def _check_db_access():
185     # disable all database access if required
186     if DISABLE_DB_ACCESS:
187         service_name = 'nova-compute'
188         stacktrace = ''.join(traceback.format_stack())
189         LOG.error(
190             'No DB access allowed in %(service_name)s: %(stacktrace)s',
191             {'service_name': service_name, 'stacktrace': stacktrace})
192         raise exception.DBNotAllowed(binary=service_name)
193 
194 
195 def pick_context_manager_writer(f):
196     """Decorator to use a writer db context manager.
197 
198     The db context manager will be picked from the RequestContext.
199 
200     Wrapped function must have a RequestContext in the arguments.
201     """
202     @functools.wraps(f)
203     def wrapper(context, *args, **kwargs):
204         _check_db_access()
205         ctxt_mgr = get_context_manager(context)
206         with ctxt_mgr.writer.using(context):
207             return f(context, *args, **kwargs)
208     wrapper.__signature__ = inspect.signature(f)
209     return wrapper
210 
211 
212 def pick_context_manager_reader(f):
213     """Decorator to use a reader db context manager.
214 
215     The db context manager will be picked from the RequestContext.
216 
217     Wrapped function must have a RequestContext in the arguments.
218     """
219     @functools.wraps(f)
220     def wrapper(context, *args, **kwargs):
221         _check_db_access()
222         ctxt_mgr = get_context_manager(context)
223         with ctxt_mgr.reader.using(context):
224             return f(context, *args, **kwargs)
225     wrapper.__signature__ = inspect.signature(f)
226     return wrapper
227 
228 
229 def pick_context_manager_reader_allow_async(f):
230     """Decorator to use a reader.allow_async db context manager.
231 
232     The db context manager will be picked from the RequestContext.
233 
234     Wrapped function must have a RequestContext in the arguments.
235     """
236     @functools.wraps(f)
237     def wrapper(context, *args, **kwargs):
238         _check_db_access()
239         ctxt_mgr = get_context_manager(context)
240         with ctxt_mgr.reader.allow_async.using(context):
241             return f(context, *args, **kwargs)
242     wrapper.__signature__ = inspect.signature(f)
243     return wrapper
244 
245 
246 def model_query(
247     context, model, args=None, read_deleted=None, project_only=False,
248 ):
249     """Query helper that accounts for context's `read_deleted` field.
250 
251     :param context: The request context that can contain a context manager
252     :param model: Model to query. Must be a subclass of ModelBase.
253     :param args: Arguments to query. If None - model is used.
254     :param read_deleted: If not None, overrides context's read_deleted field.
255          Permitted values are 'no', which does not return deleted values;
256          'only', which only returns deleted values; and 'yes', which does not
257          filter deleted values.
258     :param project_only: If set and context is user-type, then restrict
259          query to match the context's project_id. If set to 'allow_none',
260          restriction includes project_id = None.
261     """
262 
263     if read_deleted is None:
264         read_deleted = context.read_deleted
265 
266     query_kwargs = {}
267     if 'no' == read_deleted:
268         query_kwargs['deleted'] = False
269     elif 'only' == read_deleted:
270         query_kwargs['deleted'] = True
271     elif 'yes' == read_deleted:
272         pass
273     else:
274         raise ValueError(_("Unrecognized read_deleted value '%s'")
275                            % read_deleted)
276 
277     query = sqlalchemyutils.model_query(
278         model, context.session, args, **query_kwargs)
279 
280     # We can't use oslo.db model_query's project_id here, as it doesn't allow
281     # us to return both our projects and unowned projects.
282     if nova.context.is_user_context(context) and project_only:
283         if project_only == 'allow_none':
284             query = query.filter(sql.or_(
285                 model.project_id == context.project_id,
286                 model.project_id == sql.null()
287             ))
288         else:
289             query = query.filter_by(project_id=context.project_id)
290 
291     return query
292 
293 
294 def convert_objects_related_datetimes(values, *datetime_keys):
295     if not datetime_keys:
296         datetime_keys = ('created_at', 'deleted_at', 'updated_at')
297 
298     for key in datetime_keys:
299         if key in values and values[key]:
300             if isinstance(values[key], str):
301                 try:
302                     values[key] = timeutils.parse_strtime(values[key])
303                 except ValueError:
304                     # Try alternate parsing since parse_strtime will fail
305                     # with say converting '2015-05-28T19:59:38+00:00'
306                     values[key] = timeutils.parse_isotime(values[key])
307             # NOTE(danms): Strip UTC timezones from datetimes, since they're
308             # stored that way in the database
309             values[key] = values[key].replace(tzinfo=None)
310     return values
311 
312 
313 ###################
314 
315 
316 def constraint(**conditions):
317     """Return a constraint object suitable for use with some updates."""
318     return Constraint(conditions)
319 
320 
321 def equal_any(*values):
322     """Return an equality condition object suitable for use in a constraint.
323 
324     Equal_any conditions require that a model object's attribute equal any
325     one of the given values.
326     """
327     return EqualityCondition(values)
328 
329 
330 def not_equal(*values):
331     """Return an inequality condition object suitable for use in a constraint.
332 
333     Not_equal conditions require that a model object's attribute differs from
334     all of the given values.
335     """
336     return InequalityCondition(values)
337 
338 
339 class Constraint(object):
340 
341     def __init__(self, conditions):
342         self.conditions = conditions
343 
344     def apply(self, model, query):
345         for key, condition in self.conditions.items():
346             for clause in condition.clauses(getattr(model, key)):
347                 query = query.filter(clause)
348         return query
349 
350 
351 class EqualityCondition(object):
352 
353     def __init__(self, values):
354         self.values = values
355 
356     def clauses(self, field):
357         # method signature requires us to return an iterable even if for OR
358         # operator this will actually be a single clause
359         return [sql.or_(*[field == value for value in self.values])]
360 
361 
362 class InequalityCondition(object):
363 
364     def __init__(self, values):
365         self.values = values
366 
367     def clauses(self, field):
368         return [field != value for value in self.values]
369 
370 
371 ###################
372 
373 
374 @pick_context_manager_writer
375 def service_destroy(context, service_id):
376     """Destroy the service or raise if it does not exist."""
377     service = service_get(context, service_id)
378 
379     model_query(context, models.Service).\
380                 filter_by(id=service_id).\
381                 soft_delete(synchronize_session=False)
382 
383     if service.binary == 'nova-compute':
384         # TODO(sbauza): Remove the service_id filter in a later release
385         # once we are sure that all compute nodes report the host field
386         model_query(context, models.ComputeNode).\
387             filter(sql.or_(
388                 models.ComputeNode.service_id == service_id,
389                 models.ComputeNode.host == service['host'])).\
390             soft_delete(synchronize_session=False)
391 
392 
393 @pick_context_manager_reader
394 def service_get(context, service_id):
395     """Get a service or raise if it does not exist."""
396     query = model_query(context, models.Service).filter_by(id=service_id)
397 
398     result = query.first()
399     if not result:
400         raise exception.ServiceNotFound(service_id=service_id)
401 
402     return result
403 
404 
405 @pick_context_manager_reader
406 def service_get_by_uuid(context, service_uuid):
407     """Get a service by it's uuid or raise ServiceNotFound if it does not
408     exist.
409     """
410     query = model_query(context, models.Service).filter_by(uuid=service_uuid)
411 
412     result = query.first()
413     if not result:
414         raise exception.ServiceNotFound(service_id=service_uuid)
415 
416     return result
417 
418 
419 @pick_context_manager_reader_allow_async
420 def service_get_minimum_version(context, binaries):
421     """Get the minimum service version in the database."""
422     min_versions = context.session.query(
423         models.Service.binary,
424         func.min(models.Service.version)).\
425                          filter(models.Service.binary.in_(binaries)).\
426                          filter(models.Service.deleted == 0).\
427                          filter(models.Service.forced_down == sql.false()).\
428                          group_by(models.Service.binary)
429     return dict(min_versions)
430 
431 
432 @pick_context_manager_reader
433 def service_get_all(context, disabled=None):
434     """Get all services."""
435     query = model_query(context, models.Service)
436 
437     if disabled is not None:
438         query = query.filter_by(disabled=disabled)
439 
440     return query.all()
441 
442 
443 @pick_context_manager_reader
444 def service_get_all_by_topic(context, topic):
445     """Get all services for a given topic."""
446     return model_query(context, models.Service, read_deleted="no").\
447                 filter_by(disabled=False).\
448                 filter_by(topic=topic).\
449                 all()
450 
451 
452 @pick_context_manager_reader
453 def service_get_by_host_and_topic(context, host, topic):
454     """Get a service by hostname and topic it listens to."""
455     return model_query(context, models.Service, read_deleted="no").\
456                 filter_by(disabled=False).\
457                 filter_by(host=host).\
458                 filter_by(topic=topic).\
459                 first()
460 
461 
462 @pick_context_manager_reader
463 def service_get_all_by_binary(context, binary, include_disabled=False):
464     """Get services for a given binary.
465 
466     Includes disabled services if 'include_disabled' parameter is True
467     """
468     query = model_query(context, models.Service).filter_by(binary=binary)
469     if not include_disabled:
470         query = query.filter_by(disabled=False)
471     return query.all()
472 
473 
474 @pick_context_manager_reader
475 def service_get_all_computes_by_hv_type(context, hv_type,
476                                         include_disabled=False):
477     """Get all compute services for a given hypervisor type.
478 
479     Includes disabled services if 'include_disabled' parameter is True.
480     """
481     query = model_query(context, models.Service, read_deleted="no").\
482                     filter_by(binary='nova-compute')
483     if not include_disabled:
484         query = query.filter_by(disabled=False)
485     query = query.join(models.ComputeNode,
486                        models.Service.host == models.ComputeNode.host).\
487                   filter(models.ComputeNode.hypervisor_type == hv_type).\
488                   distinct()
489     return query.all()
490 
491 
492 @pick_context_manager_reader
493 def service_get_by_host_and_binary(context, host, binary):
494     """Get a service by hostname and binary."""
495     result = model_query(context, models.Service, read_deleted="no").\
496                     filter_by(host=host).\
497                     filter_by(binary=binary).\
498                     first()
499 
500     if not result:
501         raise exception.HostBinaryNotFound(host=host, binary=binary)
502 
503     return result
504 
505 
506 @pick_context_manager_reader
507 def service_get_all_by_host(context, host):
508     """Get all services for a given host."""
509     return model_query(context, models.Service, read_deleted="no").\
510                 filter_by(host=host).\
511                 all()
512 
513 
514 @pick_context_manager_reader_allow_async
515 def service_get_by_compute_host(context, host):
516     """Get the service entry for a given compute host.
517 
518     Returns the service entry joined with the compute_node entry.
519     """
520     result = model_query(context, models.Service, read_deleted="no").\
521                 filter_by(host=host).\
522                 filter_by(binary='nova-compute').\
523                 first()
524 
525     if not result:
526         raise exception.ComputeHostNotFound(host=host)
527 
528     return result
529 
530 
531 @pick_context_manager_writer
532 def service_create(context, values):
533     """Create a service from the values dictionary."""
534     service_ref = models.Service()
535     service_ref.update(values)
536     # We only auto-disable nova-compute services since those are the only
537     # ones that can be enabled using the os-services REST API and they are
538     # the only ones where being disabled means anything. It does
539     # not make sense to be able to disable non-compute services like
540     # nova-scheduler or nova-osapi_compute since that does nothing.
541     if not CONF.enable_new_services and values.get('binary') == 'nova-compute':
542         msg = _("New compute service disabled due to config option.")
543         service_ref.disabled = True
544         service_ref.disabled_reason = msg
545     try:
546         service_ref.save(context.session)
547     except db_exc.DBDuplicateEntry as e:
548         if 'binary' in e.columns:
549             raise exception.ServiceBinaryExists(host=values.get('host'),
550                         binary=values.get('binary'))
551         raise exception.ServiceTopicExists(host=values.get('host'),
552                         topic=values.get('topic'))
553     return service_ref
554 
555 
556 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
557 @pick_context_manager_writer
558 def service_update(context, service_id, values):
559     """Set the given properties on a service and update it.
560 
561     :raises: NotFound if service does not exist.
562     """
563     service_ref = service_get(context, service_id)
564     # Only servicegroup.drivers.db.DbDriver._report_state() updates
565     # 'report_count', so if that value changes then store the timestamp
566     # as the last time we got a state report.
567     if 'report_count' in values:
568         if values['report_count'] > service_ref.report_count:
569             service_ref.last_seen_up = timeutils.utcnow()
570     service_ref.update(values)
571 
572     return service_ref
573 
574 
575 ###################
576 
577 
578 def _compute_node_select(context, filters=None, limit=None, marker=None):
579     if filters is None:
580         filters = {}
581 
582     cn_tbl = models.ComputeNode.__table__.alias('cn')
583     select = sa.select(cn_tbl)
584 
585     if context.read_deleted == "no":
586         select = select.where(cn_tbl.c.deleted == 0)
587     if "compute_id" in filters:
588         select = select.where(cn_tbl.c.id == filters["compute_id"])
589     if "service_id" in filters:
590         select = select.where(cn_tbl.c.service_id == filters["service_id"])
591     if "host" in filters:
592         select = select.where(cn_tbl.c.host == filters["host"])
593     if "hypervisor_hostname" in filters:
594         hyp_hostname = filters["hypervisor_hostname"]
595         select = select.where(cn_tbl.c.hypervisor_hostname == hyp_hostname)
596     if "mapped" in filters:
597         select = select.where(cn_tbl.c.mapped < filters['mapped'])
598     if marker is not None:
599         try:
600             compute_node_get(context, marker)
601         except exception.ComputeHostNotFound:
602             raise exception.MarkerNotFound(marker=marker)
603         select = select.where(cn_tbl.c.id > marker)
604     if limit is not None:
605         select = select.limit(limit)
606     # Explicitly order by id, so we're not dependent on the native sort
607     # order of the underlying DB.
608     select = select.order_by(expression.asc("id"))
609     return select
610 
611 
612 def _compute_node_fetchall(context, filters=None, limit=None, marker=None):
613     select = _compute_node_select(context, filters, limit=limit, marker=marker)
614     engine = get_engine(context=context)
615 
616     with engine.connect() as conn, conn.begin():
617         results = conn.execute(select).fetchall()
618 
619     # Callers expect dict-like objects, not SQLAlchemy RowProxy objects...
620     results = [dict(r._mapping) for r in results]
621     conn.close()
622     return results
623 
624 
625 @pick_context_manager_reader
626 def compute_node_get(context, compute_id):
627     """Get a compute node by its id.
628 
629     :param context: The security context
630     :param compute_id: ID of the compute node
631 
632     :returns: Dictionary-like object containing properties of the compute node
633     :raises: ComputeHostNotFound if compute node with the given ID doesn't
634         exist.
635     """
636     results = _compute_node_fetchall(context, {"compute_id": compute_id})
637     if not results:
638         raise exception.ComputeHostNotFound(host=compute_id)
639     return results[0]
640 
641 
642 # TODO(edleafe): remove once the compute node resource provider migration is
643 # complete, and this distinction is no longer necessary.
644 @pick_context_manager_reader
645 def compute_node_get_model(context, compute_id):
646     """Get a compute node sqlalchemy model object by its id.
647 
648     :param context: The security context
649     :param compute_id: ID of the compute node
650 
651     :returns: Sqlalchemy model object containing properties of the compute node
652     :raises: ComputeHostNotFound if compute node with the given ID doesn't
653         exist.
654     """
655     result = model_query(context, models.ComputeNode).\
656             filter_by(id=compute_id).\
657             first()
658     if not result:
659         raise exception.ComputeHostNotFound(host=compute_id)
660     return result
661 
662 
663 @pick_context_manager_reader
664 def compute_nodes_get_by_service_id(context, service_id):
665     """Get a list of compute nodes by their associated service id.
666 
667     :param context: The security context
668     :param service_id: ID of the associated service
669 
670     :returns: List of dictionary-like objects, each containing properties of
671         the compute node, including its corresponding service and statistics
672     :raises: ServiceNotFound if service with the given ID doesn't exist.
673     """
674     results = _compute_node_fetchall(context, {"service_id": service_id})
675     if not results:
676         raise exception.ServiceNotFound(service_id=service_id)
677     return results
678 
679 
680 @pick_context_manager_reader
681 def compute_node_get_by_host_and_nodename(context, host, nodename):
682     """Get a compute node by its associated host and nodename.
683 
684     :param context: The security context (admin)
685     :param host: Name of the host
686     :param nodename: Name of the node
687 
688     :returns: Dictionary-like object containing properties of the compute node,
689         including its statistics
690     :raises: ComputeHostNotFound if host with the given name doesn't exist.
691     """
692     results = _compute_node_fetchall(context,
693             {"host": host, "hypervisor_hostname": nodename})
694     if not results:
695         raise exception.ComputeHostNotFound(host=host)
696     return results[0]
697 
698 
699 @pick_context_manager_reader
700 def compute_node_get_by_nodename(context, hypervisor_hostname):
701     """Get a compute node by hypervisor_hostname.
702 
703     :param context: The security context (admin)
704     :param hypervisor_hostname: Name of the node
705 
706     :returns: Dictionary-like object containing properties of the compute node,
707         including its statistics
708     :raises: ComputeHostNotFound if hypervisor_hostname with the given name
709         doesn't exist.
710     """
711     results = _compute_node_fetchall(context,
712             {"hypervisor_hostname": hypervisor_hostname})
713     if not results:
714         raise exception.ComputeHostNotFound(host=hypervisor_hostname)
715     return results[0]
716 
717 
718 @pick_context_manager_reader
719 def compute_node_get_all(context):
720     """Get all compute nodes.
721 
722     :param context: The security context
723 
724     :returns: List of dictionaries each containing compute node properties
725     """
726     return _compute_node_fetchall(context)
727 
728 
729 @pick_context_manager_reader_allow_async
730 def compute_node_get_all_by_host(context, host):
731     """Get all compute nodes by host name.
732 
733     :param context: The security context (admin)
734     :param host: Name of the host
735 
736     :returns: List of dictionaries each containing compute node properties
737     """
738     results = _compute_node_fetchall(context, {"host": host})
739     if not results:
740         raise exception.ComputeHostNotFound(host=host)
741     return results
742 
743 
744 @pick_context_manager_reader
745 def compute_node_get_all_mapped_less_than(context, mapped_less_than):
746     """Get all compute nodes with specific mapped values.
747 
748     :param context: The security context
749     :param mapped_less_than: Get compute nodes with mapped less than this value
750 
751     :returns: List of dictionaries each containing compute node properties
752     """
753     return _compute_node_fetchall(context,
754                                   {'mapped': mapped_less_than})
755 
756 
757 @pick_context_manager_reader
758 def compute_node_get_all_by_pagination(context, limit=None, marker=None):
759     """Get all compute nodes by pagination.
760 
761     :param context: The security context
762     :param limit: Maximum number of items to return
763     :param marker: The last item of the previous page, the next results after
764         this value will be returned
765 
766     :returns: List of dictionaries each containing compute node properties
767     """
768     return _compute_node_fetchall(context, limit=limit, marker=marker)
769 
770 
771 @pick_context_manager_reader
772 def compute_node_search_by_hypervisor(context, hypervisor_match):
773     """Get all compute nodes by hypervisor hostname.
774 
775     :param context: The security context
776     :param hypervisor_match: The hypervisor hostname
777 
778     :returns: List of dictionary-like objects each containing compute node
779         properties
780     """
781     field = models.ComputeNode.hypervisor_hostname
782     return model_query(context, models.ComputeNode).\
783             filter(field.like('%%%s%%' % hypervisor_match)).\
784             all()
785 
786 
787 @pick_context_manager_writer
788 def _compute_node_create(context, values):
789     """Create a compute node from the values dictionary.
790 
791     :param context: The security context
792     :param values: Dictionary containing compute node properties
793 
794     :returns: Dictionary-like object containing the properties of the created
795         node, including its corresponding service and statistics
796     """
797     convert_objects_related_datetimes(values)
798 
799     compute_node_ref = models.ComputeNode()
800     compute_node_ref.update(values)
801     compute_node_ref.save(context.session)
802     return compute_node_ref
803 
804 
805 # NOTE(mgoddard): We avoid decorating this with @pick_context_manager_writer,
806 # so that we get a separate transaction in the exception handler. This avoids
807 # an error message about inactive DB sessions during a transaction rollback.
808 # See https://bugs.launchpad.net/nova/+bug/1853159.
809 def compute_node_create(context, values):
810     """Creates a new ComputeNode and populates the capacity fields
811     with the most recent data. Will restore a soft deleted compute node if a
812     UUID has been explicitly requested.
813     """
814     try:
815         compute_node_ref = _compute_node_create(context, values)
816     except db_exc.DBDuplicateEntry:
817         with excutils.save_and_reraise_exception(logger=LOG) as err_ctx:
818             # Check to see if we have a (soft) deleted ComputeNode with the
819             # same UUID and if so just update it and mark as no longer (soft)
820             # deleted. See bug 1839560 for details.
821             if 'uuid' in values:
822                 # Get a fresh context for a new DB session and allow it to
823                 # get a deleted record.
824                 ctxt = nova.context.get_admin_context(read_deleted='yes')
825                 compute_node_ref = _compute_node_get_and_update_deleted(
826                     ctxt, values)
827                 # If we didn't get anything back we failed to find the node
828                 # by uuid and update it so re-raise the DBDuplicateEntry.
829                 if compute_node_ref:
830                     err_ctx.reraise = False
831 
832     return compute_node_ref
833 
834 
835 @pick_context_manager_writer
836 def _compute_node_get_and_update_deleted(context, values):
837     """Find a compute node by uuid, update and un-delete it.
838 
839     This is a special case from the ``compute_node_create`` method which
840     needs to be separate to get a new Session.
841 
842     This method will update the ComputeNode, if found, to have deleted=0 and
843     deleted_at=None values.
844 
845     :param context: request auth context which should be able to read deleted
846         records
847     :param values: values used to update the ComputeNode record - must include
848         uuid
849     :return: updated ComputeNode sqlalchemy model object if successfully found
850         and updated, None otherwise
851     """
852     cn = model_query(
853         context, models.ComputeNode).filter_by(uuid=values['uuid']).first()
854     if cn:
855         # Update with the provided values but un-soft-delete.
856         update_values = copy.deepcopy(values)
857         update_values['deleted'] = 0
858         update_values['deleted_at'] = None
859         return compute_node_update(context, cn.id, update_values)
860 
861 
862 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
863 @pick_context_manager_writer
864 def compute_node_update(context, compute_id, values):
865     """Set the given properties on a compute node and update it.
866 
867     :param context: The security context
868     :param compute_id: ID of the compute node
869     :param values: Dictionary containing compute node properties to be updated
870 
871     :returns: Dictionary-like object containing the properties of the updated
872         compute node, including its corresponding service and statistics
873     :raises: ComputeHostNotFound if compute node with the given ID doesn't
874         exist.
875     """
876     compute_ref = compute_node_get_model(context, compute_id)
877     # Always update this, even if there's going to be no other
878     # changes in data.  This ensures that we invalidate the
879     # scheduler cache of compute node data in case of races.
880     values['updated_at'] = timeutils.utcnow()
881     convert_objects_related_datetimes(values)
882     compute_ref.update(values)
883 
884     return compute_ref
885 
886 
887 @pick_context_manager_writer
888 def compute_node_delete(context, compute_id, constraint=None):
889     """Delete a compute node from the database.
890 
891     :param context: The security context
892     :param compute_id: ID of the compute node
893     :param constraint: a constraint object
894 
895     :raises: ComputeHostNotFound if compute node with the given ID doesn't
896         exist.
897     :raises: ConstraintNotMet if a constraint was specified and it was not met.
898     """
899     query = model_query(context, models.ComputeNode).filter_by(id=compute_id)
900 
901     if constraint is not None:
902         query = constraint.apply(models.ComputeNode, query)
903 
904     result = query.soft_delete(synchronize_session=False)
905 
906     if not result:
907         # The soft_delete could fail for one of two reasons:
908         # 1) The compute node no longer exists
909         # 2) The constraint, if specified, was not met
910         # Try to read the compute node and let it raise ComputeHostNotFound if
911         # 1) happened.
912         compute_node_get(context, compute_id)
913         # Else, raise ConstraintNotMet if 2) happened.
914         raise exception.ConstraintNotMet()
915 
916 
917 @pick_context_manager_reader
918 def compute_node_statistics(context):
919     """Get aggregate statistics over all compute nodes.
920 
921     :param context: The security context
922 
923     :returns: Dictionary containing compute node characteristics summed up
924         over all the compute nodes, e.g. 'vcpus', 'free_ram_mb' etc.
925     """
926     engine = get_engine(context=context)
927     services_tbl = models.Service.__table__
928 
929     inner_sel = _compute_node_select(context).alias('inner_sel')
930 
931     # TODO(sbauza): Remove the service_id filter in a later release
932     # once we are sure that all compute nodes report the host field
933     j = sa.join(
934         inner_sel, services_tbl,
935         sql.and_(
936             sql.or_(
937                 inner_sel.c.host == services_tbl.c.host,
938                 inner_sel.c.service_id == services_tbl.c.id
939             ),
940             services_tbl.c.disabled == sql.false(),
941             services_tbl.c.binary == 'nova-compute',
942             services_tbl.c.deleted == 0
943         )
944     )
945 
946     # NOTE(jaypipes): This COALESCE() stuff is temporary while the data
947     # migration to the new resource providers inventories and allocations
948     # tables is completed.
949     agg_cols = [
950         func.count().label('count'),
951         sql.func.sum(
952             inner_sel.c.vcpus
953         ).label('vcpus'),
954         sql.func.sum(
955             inner_sel.c.memory_mb
956         ).label('memory_mb'),
957         sql.func.sum(
958             inner_sel.c.local_gb
959         ).label('local_gb'),
960         sql.func.sum(
961             inner_sel.c.vcpus_used
962         ).label('vcpus_used'),
963         sql.func.sum(
964             inner_sel.c.memory_mb_used
965         ).label('memory_mb_used'),
966         sql.func.sum(
967             inner_sel.c.local_gb_used
968         ).label('local_gb_used'),
969         sql.func.sum(
970             inner_sel.c.free_ram_mb
971         ).label('free_ram_mb'),
972         sql.func.sum(
973             inner_sel.c.free_disk_gb
974         ).label('free_disk_gb'),
975         sql.func.sum(
976             inner_sel.c.current_workload
977         ).label('current_workload'),
978         sql.func.sum(
979             inner_sel.c.running_vms
980         ).label('running_vms'),
981         sql.func.sum(
982             inner_sel.c.disk_available_least
983         ).label('disk_available_least'),
984     ]
985     select = sql.select(*agg_cols).select_from(j)
986 
987     with engine.connect() as conn, conn.begin():
988         results = conn.execute(select).fetchone()
989 
990     # Build a dict of the info--making no assumptions about result
991     fields = ('count', 'vcpus', 'memory_mb', 'local_gb', 'vcpus_used',
992               'memory_mb_used', 'local_gb_used', 'free_ram_mb', 'free_disk_gb',
993               'current_workload', 'running_vms', 'disk_available_least')
994     results = {field: int(results[idx] or 0)
995                for idx, field in enumerate(fields)}
996     return results
997 
998 
999 ###################
1000 
1001 
1002 @pick_context_manager_writer
1003 def certificate_create(context, values):
1004     """Create a certificate from the values dictionary."""
1005     certificate_ref = models.Certificate()
1006     for (key, value) in values.items():
1007         certificate_ref[key] = value
1008     certificate_ref.save(context.session)
1009     return certificate_ref
1010 
1011 
1012 @pick_context_manager_reader
1013 def certificate_get_all_by_project(context, project_id):
1014     """Get all certificates for a project."""
1015     return model_query(context, models.Certificate, read_deleted="no").\
1016                    filter_by(project_id=project_id).\
1017                    all()
1018 
1019 
1020 @pick_context_manager_reader
1021 def certificate_get_all_by_user(context, user_id):
1022     """Get all certificates for a user."""
1023     return model_query(context, models.Certificate, read_deleted="no").\
1024                    filter_by(user_id=user_id).\
1025                    all()
1026 
1027 
1028 @pick_context_manager_reader
1029 def certificate_get_all_by_user_and_project(context, user_id, project_id):
1030     """Get all certificates for a user and project."""
1031     return model_query(context, models.Certificate, read_deleted="no").\
1032                    filter_by(user_id=user_id).\
1033                    filter_by(project_id=project_id).\
1034                    all()
1035 
1036 
1037 ###################
1038 
1039 
1040 @require_context
1041 @pick_context_manager_writer
1042 def virtual_interface_create(context, values):
1043     """Create a new virtual interface record.
1044 
1045     :param values: Dict containing column values.
1046     """
1047     try:
1048         vif_ref = models.VirtualInterface()
1049         vif_ref.update(values)
1050         vif_ref.save(context.session)
1051     except db_exc.DBError:
1052         LOG.exception("VIF creation failed with a database error.")
1053         raise exception.VirtualInterfaceCreateException()
1054 
1055     return vif_ref
1056 
1057 
1058 def _virtual_interface_query(context):
1059     return model_query(context, models.VirtualInterface, read_deleted="no")
1060 
1061 
1062 @require_context
1063 @pick_context_manager_writer
1064 def virtual_interface_update(context, address, values):
1065     """Create a virtual interface record in the database."""
1066     vif_ref = virtual_interface_get_by_address(context, address)
1067     vif_ref.update(values)
1068     vif_ref.save(context.session)
1069     return vif_ref
1070 
1071 
1072 @require_context
1073 @pick_context_manager_reader
1074 def virtual_interface_get(context, vif_id):
1075     """Get a virtual interface by ID.
1076 
1077     :param vif_id: ID of the virtual interface.
1078     """
1079     vif_ref = _virtual_interface_query(context).\
1080                       filter_by(id=vif_id).\
1081                       first()
1082     return vif_ref
1083 
1084 
1085 @require_context
1086 @pick_context_manager_reader
1087 def virtual_interface_get_by_address(context, address):
1088     """Get a virtual interface by address.
1089 
1090     :param address: The address of the interface you're looking to get.
1091     """
1092     try:
1093         vif_ref = _virtual_interface_query(context).\
1094                           filter_by(address=address).\
1095                           first()
1096     except db_exc.DBError:
1097         msg = _("Invalid virtual interface address %s in request") % address
1098         LOG.warning(msg)
1099         raise exception.InvalidIpAddressError(msg)
1100     return vif_ref
1101 
1102 
1103 @require_context
1104 @pick_context_manager_reader
1105 def virtual_interface_get_by_uuid(context, vif_uuid):
1106     """Get a virtual interface by UUID.
1107 
1108     :param vif_uuid: The uuid of the interface you're looking to get
1109     """
1110     vif_ref = _virtual_interface_query(context).\
1111                       filter_by(uuid=vif_uuid).\
1112                       first()
1113     return vif_ref
1114 
1115 
1116 @require_context
1117 @pick_context_manager_reader_allow_async
1118 def virtual_interface_get_by_instance(context, instance_uuid):
1119     """Gets all virtual interfaces for instance.
1120 
1121     :param instance_uuid: UUID of the instance to filter on.
1122     """
1123     vif_refs = _virtual_interface_query(context).\
1124         filter_by(instance_uuid=instance_uuid).\
1125         order_by(expression.asc("created_at"), expression.asc("id")).\
1126         all()
1127     return vif_refs
1128 
1129 
1130 @require_context
1131 @pick_context_manager_reader
1132 def virtual_interface_get_by_instance_and_network(context, instance_uuid,
1133                                                   network_id):
1134     """Get all virtual interface for instance that's associated with
1135     network.
1136     """
1137     vif_ref = _virtual_interface_query(context).\
1138                       filter_by(instance_uuid=instance_uuid).\
1139                       filter_by(network_id=network_id).\
1140                       first()
1141     return vif_ref
1142 
1143 
1144 @require_context
1145 @pick_context_manager_writer
1146 def virtual_interface_delete_by_instance(context, instance_uuid):
1147     """Delete virtual interface records associated with instance.
1148 
1149     :param instance_uuid: UUID of the instance to filter on.
1150     """
1151     _virtual_interface_query(context).\
1152            filter_by(instance_uuid=instance_uuid).\
1153            soft_delete()
1154 
1155 
1156 @require_context
1157 @pick_context_manager_writer
1158 def virtual_interface_delete(context, id):
1159     """Delete a virtual interface records.
1160 
1161     :param id: ID of the interface.
1162     """
1163     _virtual_interface_query(context).\
1164         filter_by(id=id).\
1165         soft_delete()
1166 
1167 
1168 @require_context
1169 @pick_context_manager_reader
1170 def virtual_interface_get_all(context):
1171     """Get all virtual interface records."""
1172     vif_refs = _virtual_interface_query(context).all()
1173     return vif_refs
1174 
1175 
1176 ###################
1177 
1178 
1179 def _metadata_refs(metadata_dict, meta_class):
1180     metadata_refs = []
1181     if metadata_dict:
1182         for k, v in metadata_dict.items():
1183             metadata_ref = meta_class()
1184             metadata_ref['key'] = k
1185             metadata_ref['value'] = v
1186             metadata_refs.append(metadata_ref)
1187     return metadata_refs
1188 
1189 
1190 def _validate_unique_server_name(context, name):
1191     if not CONF.osapi_compute_unique_server_name_scope:
1192         return
1193 
1194     lowername = name.lower()
1195     base_query = model_query(context, models.Instance, read_deleted='no').\
1196             filter(func.lower(models.Instance.hostname) == lowername)
1197 
1198     if CONF.osapi_compute_unique_server_name_scope == 'project':
1199         instance_with_same_name = base_query.\
1200                         filter_by(project_id=context.project_id).\
1201                         count()
1202 
1203     elif CONF.osapi_compute_unique_server_name_scope == 'global':
1204         instance_with_same_name = base_query.count()
1205 
1206     else:
1207         return
1208 
1209     if instance_with_same_name > 0:
1210         raise exception.InstanceExists(name=lowername)
1211 
1212 
1213 def _handle_objects_related_type_conversions(values):
1214     """Make sure that certain things in values (which may have come from
1215     an objects.instance.Instance object) are in suitable form for the
1216     database.
1217     """
1218     # NOTE(danms): Make sure IP addresses are passed as strings to
1219     # the database engine
1220     for key in ('access_ip_v4', 'access_ip_v6'):
1221         if key in values and values[key] is not None:
1222             values[key] = str(values[key])
1223 
1224     datetime_keys = ('created_at', 'deleted_at', 'updated_at',
1225                      'launched_at', 'terminated_at')
1226     convert_objects_related_datetimes(values, *datetime_keys)
1227 
1228 
1229 def _check_instance_exists_in_project(context, instance_uuid):
1230     if not model_query(context, models.Instance, read_deleted="no",
1231                        project_only=True).filter_by(
1232                        uuid=instance_uuid).first():
1233         raise exception.InstanceNotFound(instance_id=instance_uuid)
1234 
1235 
1236 @require_context
1237 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
1238 @pick_context_manager_writer
1239 def instance_create(context, values):
1240     """Create an instance from the values dictionary.
1241 
1242     :param context: Request context object
1243     :param values: Dict containing column values.
1244     """
1245 
1246     default_group = security_group_ensure_default(context)
1247 
1248     values = values.copy()
1249     values['metadata'] = _metadata_refs(
1250             values.get('metadata'), models.InstanceMetadata)
1251 
1252     values['system_metadata'] = _metadata_refs(
1253             values.get('system_metadata'), models.InstanceSystemMetadata)
1254     _handle_objects_related_type_conversions(values)
1255 
1256     instance_ref = models.Instance()
1257     if not values.get('uuid'):
1258         values['uuid'] = uuidutils.generate_uuid()
1259     instance_ref['info_cache'] = models.InstanceInfoCache()
1260     info_cache = values.pop('info_cache', None)
1261     if info_cache is not None:
1262         instance_ref['info_cache'].update(info_cache)
1263     security_groups = values.pop('security_groups', [])
1264     instance_ref['extra'] = models.InstanceExtra()
1265     instance_ref['extra'].update(
1266         {'numa_topology': None,
1267          'pci_requests': None,
1268          'vcpu_model': None,
1269          'trusted_certs': None,
1270          'resources': None,
1271          })
1272     instance_ref['extra'].update(values.pop('extra', {}))
1273     instance_ref.update(values)
1274 
1275     # Gather the security groups for the instance
1276     sg_models = []
1277     if 'default' in security_groups:
1278         sg_models.append(default_group)
1279         # Generate a new list, so we don't modify the original
1280         security_groups = [x for x in security_groups if x != 'default']
1281     if security_groups:
1282         sg_models.extend(_security_group_get_by_names(
1283             context, security_groups))
1284 
1285     if 'hostname' in values:
1286         _validate_unique_server_name(context, values['hostname'])
1287     instance_ref.security_groups = sg_models
1288     context.session.add(instance_ref)
1289 
1290     # create the instance uuid to ec2_id mapping entry for instance
1291     ec2_instance_create(context, instance_ref['uuid'])
1292 
1293     # Parity with the return value of instance_get_all_by_filters_sort()
1294     # Obviously a newly-created instance record can't already have a fault
1295     # record because of the FK constraint, so this is fine.
1296     instance_ref.fault = None
1297 
1298     return instance_ref
1299 
1300 
1301 @require_context
1302 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
1303 @pick_context_manager_writer
1304 def instance_destroy(
1305     context, instance_uuid, constraint=None, hard_delete=False,
1306 ):
1307     """Destroy the instance or raise if it does not exist.
1308 
1309     :param context: request context object
1310     :param instance_uuid: uuid of the instance to delete
1311     :param constraint: a constraint object
1312     :param hard_delete: when set to True, removes all records related to the
1313         instance
1314     """
1315     if uuidutils.is_uuid_like(instance_uuid):
1316         instance_ref = _instance_get_by_uuid(context, instance_uuid)
1317     else:
1318         raise exception.InvalidUUID(uuid=instance_uuid)
1319 
1320     query = model_query(context, models.Instance).\
1321                     filter_by(uuid=instance_uuid)
1322     if constraint is not None:
1323         query = constraint.apply(models.Instance, query)
1324     # Either in hard or soft delete, we soft delete the instance first
1325     # to make sure that the constraints were met.
1326     count = query.soft_delete()
1327     if count == 0:
1328         # The failure to soft delete could be due to one of two things:
1329         # 1) A racing request has deleted the instance out from under us
1330         # 2) A constraint was not met
1331         # Try to read the instance back once more and let it raise
1332         # InstanceNotFound if 1) happened. This will give the caller an error
1333         # that more accurately reflects the reason for the failure.
1334         _instance_get_by_uuid(context, instance_uuid)
1335         # Else, raise ConstraintNotMet if 2) happened.
1336         raise exception.ConstraintNotMet()
1337 
1338     models_to_delete = [
1339         models.SecurityGroupInstanceAssociation, models.InstanceInfoCache,
1340         models.InstanceMetadata, models.InstanceFault, models.InstanceExtra,
1341         models.InstanceSystemMetadata, models.BlockDeviceMapping,
1342         models.Migration, models.VirtualInterface
1343     ]
1344 
1345     # For most referenced models we filter by the instance_uuid column, but for
1346     # these models we filter by the uuid column.
1347     filtered_by_uuid = [models.InstanceIdMapping]
1348 
1349     for model in models_to_delete + filtered_by_uuid:
1350         key = 'instance_uuid' if model not in filtered_by_uuid else 'uuid'
1351         filter_ = {key: instance_uuid}
1352         if hard_delete:
1353             # We need to read any soft-deleted related records to make sure
1354             # and clean those up as well otherwise we can fail with ForeignKey
1355             # constraint errors when hard deleting the instance.
1356             model_query(context, model, read_deleted='yes').filter_by(
1357                 **filter_).delete()
1358         else:
1359             model_query(context, model).filter_by(**filter_).soft_delete()
1360 
1361     # NOTE(snikitin): We can't use model_query here, because there is no
1362     # column 'deleted' in 'tags' or 'console_auth_tokens' tables.
1363     context.session.query(models.Tag).filter_by(
1364         resource_id=instance_uuid).delete()
1365     context.session.query(models.ConsoleAuthToken).filter_by(
1366         instance_uuid=instance_uuid).delete()
1367     # NOTE(cfriesen): We intentionally do not soft-delete entries in the
1368     # instance_actions or instance_actions_events tables because they
1369     # can be used by operators to find out what actions were performed on a
1370     # deleted instance.  Both of these tables are special-cased in
1371     # _archive_deleted_rows_for_table().
1372     if hard_delete:
1373         # NOTE(ttsiousts): In case of hard delete, we need to remove the
1374         # instance actions too since instance_uuid is a foreign key and
1375         # for this we need to delete the corresponding InstanceActionEvents
1376         actions = context.session.query(models.InstanceAction).filter_by(
1377             instance_uuid=instance_uuid).all()
1378         for action in actions:
1379             context.session.query(models.InstanceActionEvent).filter_by(
1380                 action_id=action.id).delete()
1381         context.session.query(models.InstanceAction).filter_by(
1382             instance_uuid=instance_uuid).delete()
1383         # NOTE(ttsiouts): The instance is the last thing to be deleted in
1384         # order to respect all constraints
1385         context.session.query(models.Instance).filter_by(
1386             uuid=instance_uuid).delete()
1387 
1388     return instance_ref
1389 
1390 
1391 @require_context
1392 @pick_context_manager_reader_allow_async
1393 def instance_get_by_uuid(context, uuid, columns_to_join=None):
1394     """Get an instance or raise if it does not exist."""
1395     return _instance_get_by_uuid(context, uuid,
1396                                  columns_to_join=columns_to_join)
1397 
1398 
1399 def _instance_get_by_uuid(context, uuid, columns_to_join=None):
1400     result = _build_instance_get(
1401         context, columns_to_join=columns_to_join
1402     ).filter_by(uuid=uuid).first()
1403 
1404     if not result:
1405         raise exception.InstanceNotFound(instance_id=uuid)
1406 
1407     return result
1408 
1409 
1410 @require_context
1411 @pick_context_manager_reader
1412 def instance_get(context, instance_id, columns_to_join=None):
1413     """Get an instance or raise if it does not exist."""
1414     try:
1415         result = _build_instance_get(context, columns_to_join=columns_to_join
1416                                      ).filter_by(id=instance_id).first()
1417 
1418         if not result:
1419             raise exception.InstanceNotFound(instance_id=instance_id)
1420 
1421         return result
1422     except db_exc.DBError:
1423         # NOTE(sdague): catch all in case the db engine chokes on the
1424         # id because it's too long of an int to store.
1425         LOG.warning("Invalid instance id %s in request", instance_id)
1426         raise exception.InvalidID(id=instance_id)
1427 
1428 
1429 def _build_instance_get(context, columns_to_join=None):
1430     query = model_query(
1431         context, models.Instance, project_only=True,
1432     ).options(
1433         orm.joinedload(
1434             models.Instance.security_groups
1435         ).joinedload(models.SecurityGroup.rules)
1436     ).options(orm.joinedload(models.Instance.info_cache))
1437     if columns_to_join is None:
1438         columns_to_join = ['metadata', 'system_metadata']
1439     for column in columns_to_join:
1440         if column in ['info_cache', 'security_groups']:
1441             # Already always joined above
1442             continue
1443         if 'extra.' in column:
1444             column_ref = getattr(models.InstanceExtra, column.split('.')[1])
1445             query = query.options(
1446                 orm.joinedload(models.Instance.extra).undefer(column_ref)
1447             )
1448         elif column in ['metadata', 'system_metadata']:
1449             # NOTE(melwitt): We use subqueryload() instead of joinedload() for
1450             # metadata and system_metadata because of the one-to-many
1451             # relationship of the data. Directly joining these columns can
1452             # result in a large number of additional rows being queried if an
1453             # instance has a large number of (system_)metadata items, resulting
1454             # in a large data transfer. Instead, the subqueryload() will
1455             # perform additional queries to obtain metadata and system_metadata
1456             # for the instance.
1457             column_ref = getattr(models.Instance, column)
1458             query = query.options(orm.subqueryload(column_ref))
1459         else:
1460             column_ref = getattr(models.Instance, column)
1461             query = query.options(orm.joinedload(column_ref))
1462     # NOTE(alaski) Stop lazy loading of columns not needed.
1463     for column in ['metadata', 'system_metadata']:
1464         if column not in columns_to_join:
1465             column_ref = getattr(models.Instance, column)
1466             query = query.options(orm.noload(column_ref))
1467     # NOTE(melwitt): We need to use order_by(<unique column>) so that the
1468     # additional queries emitted by subqueryload() include the same ordering as
1469     # used by the parent query.
1470     # https://docs.sqlalchemy.org/en/13/orm/loading_relationships.html#the-importance-of-ordering
1471     return query.order_by(models.Instance.id)
1472 
1473 
1474 def _instances_fill_metadata(context, instances, manual_joins=None):
1475     """Selectively fill instances with manually-joined metadata. Note that
1476     instance will be converted to a dict.
1477 
1478     :param context: security context
1479     :param instances: list of instances to fill
1480     :param manual_joins: list of tables to manually join (can be any
1481                          combination of 'metadata' and 'system_metadata' or
1482                          None to take the default of both)
1483     """
1484     uuids = [inst['uuid'] for inst in instances]
1485 
1486     if manual_joins is None:
1487         manual_joins = ['metadata', 'system_metadata']
1488 
1489     meta = collections.defaultdict(list)
1490     if 'metadata' in manual_joins:
1491         for row in _instance_metadata_get_multi(context, uuids):
1492             meta[row['instance_uuid']].append(row)
1493 
1494     sys_meta = collections.defaultdict(list)
1495     if 'system_metadata' in manual_joins:
1496         for row in _instance_system_metadata_get_multi(context, uuids):
1497             sys_meta[row['instance_uuid']].append(row)
1498 
1499     pcidevs = collections.defaultdict(list)
1500     if 'pci_devices' in manual_joins:
1501         for row in _instance_pcidevs_get_multi(context, uuids):
1502             pcidevs[row['instance_uuid']].append(row)
1503 
1504     if 'fault' in manual_joins:
1505         faults = instance_fault_get_by_instance_uuids(context, uuids,
1506                                                       latest=True)
1507     else:
1508         faults = {}
1509 
1510     filled_instances = []
1511     for inst in instances:
1512         inst = dict(inst)
1513         inst['system_metadata'] = sys_meta[inst['uuid']]
1514         inst['metadata'] = meta[inst['uuid']]
1515         if 'pci_devices' in manual_joins:
1516             inst['pci_devices'] = pcidevs[inst['uuid']]
1517         inst_faults = faults.get(inst['uuid'])
1518         inst['fault'] = inst_faults and inst_faults[0] or None
1519         filled_instances.append(inst)
1520 
1521     return filled_instances
1522 
1523 
1524 def _manual_join_columns(columns_to_join):
1525     """Separate manually joined columns from columns_to_join
1526 
1527     If columns_to_join contains 'metadata', 'system_metadata', 'fault', or
1528     'pci_devices' those columns are removed from columns_to_join and added
1529     to a manual_joins list to be used with the _instances_fill_metadata method.
1530 
1531     The columns_to_join formal parameter is copied and not modified, the return
1532     tuple has the modified columns_to_join list to be used with joinedload in
1533     a model query.
1534 
1535     :param:columns_to_join: List of columns to join in a model query.
1536     :return: tuple of (manual_joins, columns_to_join)
1537     """
1538     manual_joins = []
1539     columns_to_join_new = copy.copy(columns_to_join)
1540     for column in ('metadata', 'system_metadata', 'pci_devices', 'fault'):
1541         if column in columns_to_join_new:
1542             columns_to_join_new.remove(column)
1543             manual_joins.append(column)
1544     return manual_joins, columns_to_join_new
1545 
1546 
1547 @require_context
1548 @pick_context_manager_reader
1549 def instance_get_all(context, columns_to_join=None):
1550     """Get all instances."""
1551     if columns_to_join is None:
1552         columns_to_join_new = ['info_cache', 'security_groups']
1553         manual_joins = ['metadata', 'system_metadata']
1554     else:
1555         manual_joins, columns_to_join_new = (
1556             _manual_join_columns(columns_to_join))
1557     query = model_query(context, models.Instance)
1558     for column in columns_to_join_new:
1559         column_ref = getattr(models.Instance, column)
1560         query = query.options(orm.joinedload(column_ref))
1561     if not context.is_admin:
1562         # If we're not admin context, add appropriate filter..
1563         if context.project_id:
1564             query = query.filter_by(project_id=context.project_id)
1565         else:
1566             query = query.filter_by(user_id=context.user_id)
1567     instances = query.all()
1568     return _instances_fill_metadata(context, instances, manual_joins)
1569 
1570 
1571 @require_context
1572 @pick_context_manager_reader_allow_async
1573 def instance_get_all_by_filters(
1574     context, filters, sort_key='created_at', sort_dir='desc', limit=None,
1575     marker=None, columns_to_join=None,
1576 ):
1577     """Get all instances matching all filters sorted by the primary key.
1578 
1579     See instance_get_all_by_filters_sort for more information.
1580     """
1581     # Invoke the API with the multiple sort keys and directions using the
1582     # single sort key/direction
1583     return instance_get_all_by_filters_sort(context, filters, limit=limit,
1584                                             marker=marker,
1585                                             columns_to_join=columns_to_join,
1586                                             sort_keys=[sort_key],
1587                                             sort_dirs=[sort_dir])
1588 
1589 
1590 def _get_query_nova_resource_by_changes_time(query, filters, model_object):
1591     """Filter resources by changes-since or changes-before.
1592 
1593     Special keys are used to tweek the query further::
1594 
1595     |   'changes-since' - only return resources updated after
1596     |   'changes-before' - only return resources updated before
1597 
1598     Return query results.
1599 
1600     :param query: query to apply filters to.
1601     :param filters: dictionary of filters with regex values.
1602     :param model_object: object of the operation target.
1603     """
1604     for change_filter in ['changes-since', 'changes-before']:
1605         if filters and filters.get(change_filter):
1606             changes_filter_time = timeutils.normalize_time(
1607                 filters.get(change_filter))
1608             updated_at = getattr(model_object, 'updated_at')
1609             if change_filter == 'changes-since':
1610                 query = query.filter(updated_at >= changes_filter_time)
1611             else:
1612                 query = query.filter(updated_at <= changes_filter_time)
1613     return query
1614 
1615 
1616 @require_context
1617 @pick_context_manager_reader_allow_async
1618 def instance_get_all_by_filters_sort(context, filters, limit=None, marker=None,
1619                                      columns_to_join=None, sort_keys=None,
1620                                      sort_dirs=None):
1621     """Get all instances that match all filters sorted by the given keys.
1622 
1623     Deleted instances will be returned by default, unless there's a filter that
1624     says otherwise.
1625 
1626     Depending on the name of a filter, matching for that filter is
1627     performed using either exact matching or as regular expression
1628     matching. Exact matching is applied for the following filters::
1629 
1630     |   ['project_id', 'user_id', 'image_ref',
1631     |    'vm_state', 'instance_type_id', 'uuid',
1632     |    'metadata', 'host', 'system_metadata', 'locked', 'hidden']
1633 
1634     Hidden instances will *not* be returned by default, unless there's a
1635     filter that says otherwise.
1636 
1637     A third type of filter (also using exact matching), filters
1638     based on instance metadata tags when supplied under a special
1639     key named 'filter'::
1640 
1641     |   filters = {
1642     |       'filter': [
1643     |           {'name': 'tag-key', 'value': '<metakey>'},
1644     |           {'name': 'tag-value', 'value': '<metaval>'},
1645     |           {'name': 'tag:<metakey>', 'value': '<metaval>'}
1646     |       ]
1647     |   }
1648 
1649     Special keys are used to tweek the query further::
1650 
1651     |   'changes-since' - only return instances updated after
1652     |   'changes-before' - only return instances updated before
1653     |   'deleted' - only return (or exclude) deleted instances
1654     |   'soft_deleted' - modify behavior of 'deleted' to either
1655     |                    include or exclude instances whose
1656     |                    vm_state is SOFT_DELETED.
1657 
1658     A fourth type of filter (also using exact matching), filters
1659     based on instance tags (not metadata tags). There are two types
1660     of these tags:
1661 
1662     `tags` -- One or more strings that will be used to filter results
1663             in an AND expression: T1 AND T2
1664 
1665     `tags-any` -- One or more strings that will be used to filter results in
1666             an OR expression: T1 OR T2
1667 
1668     `not-tags` -- One or more strings that will be used to filter results in
1669             an NOT AND expression: NOT (T1 AND T2)
1670 
1671     `not-tags-any` -- One or more strings that will be used to filter results
1672             in an NOT OR expression: NOT (T1 OR T2)
1673 
1674     Tags should be represented as list::
1675 
1676     |    filters = {
1677     |        'tags': [some-tag, some-another-tag],
1678     |        'tags-any: [some-any-tag, some-another-any-tag],
1679     |        'not-tags: [some-not-tag, some-another-not-tag],
1680     |        'not-tags-any: [some-not-any-tag, some-another-not-any-tag]
1681     |    }
1682     """
1683     # NOTE(mriedem): If the limit is 0 there is no point in even going
1684     # to the database since nothing is going to be returned anyway.
1685     if limit == 0:
1686         return []
1687 
1688     sort_keys, sort_dirs = db_utils.process_sort_params(
1689         sort_keys, sort_dirs, default_dir='desc')
1690 
1691     if columns_to_join is None:
1692         columns_to_join_new = ['info_cache', 'security_groups']
1693         manual_joins = ['metadata', 'system_metadata']
1694     else:
1695         manual_joins, columns_to_join_new = (
1696             _manual_join_columns(columns_to_join))
1697 
1698     query_prefix = context.session.query(models.Instance)
1699     for column in columns_to_join_new:
1700         if 'extra.' in column:
1701             column_ref = getattr(models.InstanceExtra, column.split('.')[1])
1702             query_prefix = query_prefix.options(
1703                 orm.joinedload(models.Instance.extra).undefer(column_ref)
1704             )
1705         else:
1706             column_ref = getattr(models.Instance, column)
1707             query_prefix = query_prefix.options(orm.joinedload(column_ref))
1708 
1709     # Note: order_by is done in the sqlalchemy.utils.py paginate_query(),
1710     # no need to do it here as well
1711 
1712     # Make a copy of the filters dictionary to use going forward, as we'll
1713     # be modifying it and we shouldn't affect the caller's use of it.
1714     filters = copy.deepcopy(filters)
1715 
1716     model_object = models.Instance
1717     query_prefix = _get_query_nova_resource_by_changes_time(
1718         query_prefix, filters, model_object,
1719     )
1720 
1721     if 'deleted' in filters:
1722         # Instances can be soft or hard deleted and the query needs to
1723         # include or exclude both
1724         deleted = filters.pop('deleted')
1725         if deleted:
1726             if filters.pop('soft_deleted', True):
1727                 delete = sql.or_(
1728                     models.Instance.deleted == models.Instance.id,
1729                     models.Instance.vm_state == vm_states.SOFT_DELETED
1730                     )
1731                 query_prefix = query_prefix.filter(delete)
1732             else:
1733                 query_prefix = query_prefix.\
1734                     filter(models.Instance.deleted == models.Instance.id)
1735         else:
1736             query_prefix = query_prefix.filter_by(deleted=0)
1737             if not filters.pop('soft_deleted', False):
1738                 # It would be better to have vm_state not be nullable
1739                 # but until then we test it explicitly as a workaround.
1740                 not_soft_deleted = sql.or_(
1741                     models.Instance.vm_state != vm_states.SOFT_DELETED,
1742                     models.Instance.vm_state == sql.null()
1743                 )
1744                 query_prefix = query_prefix.filter(not_soft_deleted)
1745 
1746     if 'cleaned' in filters:
1747         cleaned = 1 if filters.pop('cleaned') else 0
1748         query_prefix = query_prefix.filter(models.Instance.cleaned == cleaned)
1749 
1750     if 'tags' in filters:
1751         tags = filters.pop('tags')
1752         # We build a JOIN ladder expression for each tag, JOIN'ing
1753         # the first tag to the instances table, and each subsequent
1754         # tag to the last JOIN'd tags table
1755         first_tag = tags.pop(0)
1756         query_prefix = query_prefix.join(models.Instance.tags)
1757         query_prefix = query_prefix.filter(models.Tag.tag == first_tag)
1758 
1759         for tag in tags:
1760             tag_alias = orm.aliased(models.Tag)
1761             query_prefix = query_prefix.join(tag_alias,
1762                                              models.Instance.tags)
1763             query_prefix = query_prefix.filter(tag_alias.tag == tag)
1764 
1765     if 'tags-any' in filters:
1766         tags = filters.pop('tags-any')
1767         tag_alias = orm.aliased(models.Tag)
1768         query_prefix = query_prefix.join(tag_alias, models.Instance.tags)
1769         query_prefix = query_prefix.filter(tag_alias.tag.in_(tags))
1770 
1771     if 'not-tags' in filters:
1772         tags = filters.pop('not-tags')
1773         first_tag = tags.pop(0)
1774         subq = query_prefix.session.query(models.Tag.resource_id)
1775         subq = subq.join(models.Instance.tags)
1776         subq = subq.filter(models.Tag.tag == first_tag)
1777 
1778         for tag in tags:
1779             tag_alias = orm.aliased(models.Tag)
1780             subq = subq.join(tag_alias, models.Instance.tags)
1781             subq = subq.filter(tag_alias.tag == tag)
1782 
1783         query_prefix = query_prefix.filter(~models.Instance.uuid.in_(subq))
1784 
1785     if 'not-tags-any' in filters:
1786         tags = filters.pop('not-tags-any')
1787         query_prefix = query_prefix.filter(~models.Instance.tags.any(
1788             models.Tag.tag.in_(tags)))
1789 
1790     if not context.is_admin:
1791         # If we're not admin context, add appropriate filter..
1792         if context.project_id:
1793             filters['project_id'] = context.project_id
1794         else:
1795             filters['user_id'] = context.user_id
1796 
1797     if filters.pop('hidden', False):
1798         query_prefix = query_prefix.filter(
1799             models.Instance.hidden == sql.true())
1800     else:
1801         # If the query should not include hidden instances, then
1802         # filter instances with hidden=False or hidden=NULL because
1803         # older records may have no value set.
1804         query_prefix = query_prefix.filter(sql.or_(
1805             models.Instance.hidden == sql.false(),
1806             models.Instance.hidden == sql.null()))
1807 
1808     # Filters for exact matches that we can do along with the SQL query...
1809     # For other filters that don't match this, we will do regexp matching
1810     exact_match_filter_names = ['project_id', 'user_id', 'image_ref',
1811                                 'vm_state', 'instance_type_id', 'uuid',
1812                                 'metadata', 'host', 'task_state',
1813                                 'system_metadata', 'locked', 'hidden']
1814 
1815     # Filter the query
1816     query_prefix = _exact_instance_filter(query_prefix,
1817                                 filters, exact_match_filter_names)
1818     if query_prefix is None:
1819         return []
1820     query_prefix = _regex_instance_filter(query_prefix, filters)
1821 
1822     # paginate query
1823     if marker is not None:
1824         try:
1825             marker = _instance_get_by_uuid(
1826                 context.elevated(read_deleted='yes'), marker,
1827             )
1828         except exception.InstanceNotFound:
1829             raise exception.MarkerNotFound(marker=marker)
1830     try:
1831         query_prefix = sqlalchemyutils.paginate_query(
1832             query_prefix,
1833             models.Instance,
1834             limit,
1835             sort_keys,
1836             marker=marker,
1837             sort_dirs=sort_dirs,
1838         )
1839     except db_exc.InvalidSortKey:
1840         raise exception.InvalidSortKey()
1841 
1842     instances = query_prefix.all()
1843 
1844     return _instances_fill_metadata(context, instances, manual_joins)
1845 
1846 
1847 @require_context
1848 @pick_context_manager_reader_allow_async
1849 def instance_get_by_sort_filters(context, sort_keys, sort_dirs, values):
1850     """Get the UUID of the first instance in a sort order.
1851 
1852     Attempt to get a single instance based on a combination of sort
1853     keys, directions and filter values. This is used to try to find a
1854     marker instance when we don't have a marker uuid.
1855 
1856     :returns: The UUID of the instance that matched, if any.
1857     """
1858 
1859     model = models.Instance
1860     return _model_get_uuid_by_sort_filters(context, model, sort_keys,
1861                                            sort_dirs, values)
1862 
1863 
1864 def _model_get_uuid_by_sort_filters(context, model, sort_keys, sort_dirs,
1865                                     values):
1866     query = context.session.query(model.uuid)
1867 
1868     # NOTE(danms): Below is a re-implementation of our
1869     # oslo_db.sqlalchemy.utils.paginate_query() utility. We can't use that
1870     # directly because it does not return the marker and we need it to.
1871     # The below is basically the same algorithm, stripped down to just what
1872     # we need, and augmented with the filter criteria required for us to
1873     # get back the instance that would correspond to our query.
1874 
1875     # This is our position in sort_keys,sort_dirs,values for the loop below
1876     key_index = 0
1877 
1878     # We build a list of criteria to apply to the query, which looks
1879     # approximately like this (assuming all ascending):
1880     #
1881     #  OR(row.key1 > val1,
1882     #     AND(row.key1 == val1, row.key2 > val2),
1883     #     AND(row.key1 == val1, row.key2 == val2, row.key3 >= val3),
1884     #  )
1885     #
1886     # The final key is compared with the "or equal" variant so that
1887     # a complete match instance is still returned.
1888     criteria = []
1889 
1890     for skey, sdir, val in zip(sort_keys, sort_dirs, values):
1891         # Apply ordering to our query for the key, direction we're processing
1892         if sdir == 'desc':
1893             query = query.order_by(expression.desc(getattr(model, skey)))
1894         else:
1895             query = query.order_by(expression.asc(getattr(model, skey)))
1896 
1897         # Build a list of equivalence requirements on keys we've already
1898         # processed through the loop. In other words, if we're adding
1899         # key2 > val2, make sure that key1 == val1
1900         crit_attrs = []
1901         for equal_attr in range(0, key_index):
1902             crit_attrs.append(
1903                 (getattr(model, sort_keys[equal_attr]) == values[equal_attr]))
1904 
1905         model_attr = getattr(model, skey)
1906         if isinstance(model_attr.type, sa.Boolean):
1907             model_attr = expression.cast(model_attr, sa.Integer)
1908             val = int(val)
1909 
1910         if skey == sort_keys[-1]:
1911             # If we are the last key, then we should use or-equal to
1912             # allow a complete match to be returned
1913             if sdir == 'asc':
1914                 crit = (model_attr >= val)
1915             else:
1916                 crit = (model_attr <= val)
1917         else:
1918             # If we're not the last key, then strict greater or less than
1919             # so we order strictly.
1920             if sdir == 'asc':
1921                 crit = (model_attr > val)
1922             else:
1923                 crit = (model_attr < val)
1924 
1925         # AND together all the above
1926         crit_attrs.append(crit)
1927         criteria.append(sql.and_(*crit_attrs))
1928         key_index += 1
1929 
1930     # OR together all the ANDs
1931     query = query.filter(sql.or_(*criteria))
1932 
1933     # We can't raise InstanceNotFound because we don't have a uuid to
1934     # be looking for, so just return nothing if no match.
1935     result = query.limit(1).first()
1936     if result:
1937         # We're querying for a single column, which means we get back a
1938         # tuple of one thing. Strip that out and just return the uuid
1939         # for our caller.
1940         return result[0]
1941     else:
1942         return result
1943 
1944 
1945 def _db_connection_type(db_connection):
1946     """Returns a lowercase symbol for the db type.
1947 
1948     This is useful when we need to change what we are doing per DB
1949     (like handling regexes). In a CellsV2 world it probably needs to
1950     do something better than use the database configuration string.
1951     """
1952 
1953     db_string = db_connection.split(':')[0].split('+')[0]
1954     return db_string.lower()
1955 
1956 
1957 def _safe_regex_mysql(raw_string):
1958     """Make regex safe to mysql.
1959 
1960     Certain items like '|' are interpreted raw by mysql REGEX. If you
1961     search for a single | then you trigger an error because it's
1962     expecting content on either side.
1963 
1964     For consistency sake we escape all '|'. This does mean we wouldn't
1965     support something like foo|bar to match completely different
1966     things, however, one can argue putting such complicated regex into
1967     name search probably means you are doing this wrong.
1968     """
1969     return raw_string.replace('|', '\\|')
1970 
1971 
1972 def _get_regexp_ops(connection):
1973     """Return safety filter and db opts for regex."""
1974     regexp_op_map = {
1975         'postgresql': '~',
1976         'mysql': 'REGEXP',
1977         'sqlite': 'REGEXP'
1978     }
1979     regex_safe_filters = {
1980         'mysql': _safe_regex_mysql
1981     }
1982     db_type = _db_connection_type(connection)
1983 
1984     return (regex_safe_filters.get(db_type, lambda x: x),
1985             regexp_op_map.get(db_type, 'LIKE'))
1986 
1987 
1988 def _regex_instance_filter(query, filters):
1989     """Applies regular expression filtering to an Instance query.
1990 
1991     Returns the updated query.
1992 
1993     :param query: query to apply filters to
1994     :param filters: dictionary of filters with regex values
1995     """
1996 
1997     model = models.Instance
1998     safe_regex_filter, db_regexp_op = _get_regexp_ops(CONF.database.connection)
1999     for filter_name in filters:
2000         try:
2001             column_attr = getattr(model, filter_name)
2002         except AttributeError:
2003             continue
2004         if 'property' == type(column_attr).__name__:
2005             continue
2006         filter_val = filters[filter_name]
2007         # Sometimes the REGEX filter value is not a string
2008         if not isinstance(filter_val, str):
2009             filter_val = str(filter_val)
2010         if db_regexp_op == 'LIKE':
2011             query = query.filter(column_attr.op(db_regexp_op)(
2012                                  u'%' + filter_val + u'%'))
2013         else:
2014             filter_val = safe_regex_filter(filter_val)
2015             query = query.filter(column_attr.op(db_regexp_op)(
2016                                  filter_val))
2017     return query
2018 
2019 
2020 def _exact_instance_filter(query, filters, legal_keys):
2021     """Applies exact match filtering to an Instance query.
2022 
2023     Returns the updated query.  Modifies filters argument to remove
2024     filters consumed.
2025 
2026     :param query: query to apply filters to
2027     :param filters: dictionary of filters; values that are lists,
2028                     tuples, sets, or frozensets cause an 'IN' test to
2029                     be performed, while exact matching ('==' operator)
2030                     is used for other values
2031     :param legal_keys: list of keys to apply exact filtering to
2032     """
2033 
2034     filter_dict = {}
2035     model = models.Instance
2036 
2037     # Walk through all the keys
2038     for key in legal_keys:
2039         # Skip ones we're not filtering on
2040         if key not in filters:
2041             continue
2042 
2043         # OK, filtering on this key; what value do we search for?
2044         value = filters.pop(key)
2045 
2046         if key in ('metadata', 'system_metadata'):
2047             column_attr = getattr(model, key)
2048             if isinstance(value, list):
2049                 for item in value:
2050                     for k, v in item.items():
2051                         query = query.filter(column_attr.any(key=k))
2052                         query = query.filter(column_attr.any(value=v))
2053 
2054             else:
2055                 for k, v in value.items():
2056                     query = query.filter(column_attr.any(key=k))
2057                     query = query.filter(column_attr.any(value=v))
2058         elif isinstance(value, (list, tuple, set, frozenset)):
2059             if not value:
2060                 return None  # empty IN-predicate; short circuit
2061             # Looking for values in a list; apply to query directly
2062             column_attr = getattr(model, key)
2063             query = query.filter(column_attr.in_(value))
2064         else:
2065             # OK, simple exact match; save for later
2066             filter_dict[key] = value
2067 
2068     # Apply simple exact matches
2069     if filter_dict:
2070         query = query.filter(*[getattr(models.Instance, k) == v
2071                                for k, v in filter_dict.items()])
2072     return query
2073 
2074 
2075 @require_context
2076 @pick_context_manager_reader_allow_async
2077 def instance_get_active_by_window_joined(context, begin, end=None,
2078                                          project_id=None, host=None,
2079                                          columns_to_join=None, limit=None,
2080                                          marker=None):
2081     """Get instances and joins active during a certain time window.
2082 
2083     Specifying a project_id will filter for a certain project.
2084     Specifying a host will filter for instances on a given compute host.
2085     """
2086     query = context.session.query(models.Instance)
2087 
2088     if columns_to_join is None:
2089         columns_to_join_new = ['info_cache', 'security_groups']
2090         manual_joins = ['metadata', 'system_metadata']
2091     else:
2092         manual_joins, columns_to_join_new = (
2093             _manual_join_columns(columns_to_join))
2094 
2095     for column in columns_to_join_new:
2096         if 'extra.' in column:
2097             column_ref = getattr(models.InstanceExtra, column.split('.')[1])
2098             query = query.options(
2099                 orm.joinedload(models.Instance.extra).undefer(column_ref)
2100             )
2101         else:
2102             column_ref = getattr(models.Instance, column)
2103             query = query.options(orm.joinedload(column_ref))
2104 
2105     query = query.filter(sql.or_(
2106         models.Instance.terminated_at == sql.null(),
2107         models.Instance.terminated_at > begin))
2108     if end:
2109         query = query.filter(models.Instance.launched_at < end)
2110     if project_id:
2111         query = query.filter_by(project_id=project_id)
2112     if host:
2113         query = query.filter_by(host=host)
2114 
2115     if marker is not None:
2116         try:
2117             marker = _instance_get_by_uuid(
2118                 context.elevated(read_deleted='yes'), marker)
2119         except exception.InstanceNotFound:
2120             raise exception.MarkerNotFound(marker=marker)
2121 
2122     query = sqlalchemyutils.paginate_query(
2123         query, models.Instance, limit, ['project_id', 'uuid'], marker=marker,
2124     )
2125     instances = query.all()
2126 
2127     return _instances_fill_metadata(context, instances, manual_joins)
2128 
2129 
2130 def _instance_get_all_query(context, project_only=False, joins=None):
2131     if joins is None:
2132         joins = ['info_cache', 'security_groups']
2133 
2134     query = model_query(
2135         context,
2136         models.Instance,
2137         project_only=project_only,
2138     )
2139     for column in joins:
2140         if 'extra.' in column:
2141             column_ref = getattr(models.InstanceExtra, column.split('.')[1])
2142             query = query.options(
2143                 orm.joinedload(models.Instance.extra).undefer(column_ref)
2144             )
2145         else:
2146             column_ref = getattr(models.Instance, column)
2147             query = query.options(orm.joinedload(column_ref))
2148     return query
2149 
2150 
2151 @pick_context_manager_reader_allow_async
2152 def instance_get_all_by_host(context, host, columns_to_join=None):
2153     """Get all instances belonging to a host."""
2154     query = _instance_get_all_query(context, joins=columns_to_join)
2155     instances = query.filter_by(host=host).all()
2156     return _instances_fill_metadata(
2157         context,
2158         instances,
2159         manual_joins=columns_to_join,
2160     )
2161 
2162 
2163 def _instance_get_all_uuids_by_hosts(context, hosts):
2164     itbl = models.Instance.__table__
2165     default_deleted_value = itbl.c.deleted.default.arg
2166     sel = sql.select(itbl.c.host, itbl.c.uuid)
2167     sel = sel.where(sql.and_(
2168             itbl.c.deleted == default_deleted_value,
2169             itbl.c.host.in_(sa.bindparam('hosts', expanding=True))))
2170 
2171     # group the instance UUIDs by hostname
2172     res = collections.defaultdict(list)
2173     for rec in context.session.execute(sel, {'hosts': hosts}).fetchall():
2174         res[rec[0]].append(rec[1])
2175     return res
2176 
2177 
2178 @pick_context_manager_reader
2179 def instance_get_all_uuids_by_hosts(context, hosts):
2180     """Get a dict, keyed by hostname, of a list of the instance UUIDs on the
2181     host for each supplied hostname, not Instance model objects.
2182 
2183     The dict is a defaultdict of list, thus inspecting the dict for a host not
2184     in the dict will return an empty list not a KeyError.
2185     """
2186     return _instance_get_all_uuids_by_hosts(context, hosts)
2187 
2188 
2189 @pick_context_manager_reader
2190 def instance_get_all_by_host_and_node(
2191     context, host, node, columns_to_join=None,
2192 ):
2193     """Get all instances belonging to a node."""
2194     if columns_to_join is None:
2195         manual_joins = []
2196     else:
2197         candidates = ['system_metadata', 'metadata']
2198         manual_joins = [x for x in columns_to_join if x in candidates]
2199         columns_to_join = list(set(columns_to_join) - set(candidates))
2200     instances = _instance_get_all_query(
2201         context,
2202         joins=columns_to_join,
2203     ).filter_by(host=host).filter_by(node=node).all()
2204     return _instances_fill_metadata(
2205         context,
2206         instances,
2207         manual_joins=manual_joins,
2208     )
2209 
2210 
2211 @pick_context_manager_reader
2212 def instance_get_all_by_host_and_not_type(context, host, type_id=None):
2213     """Get all instances belonging to a host with a different type_id."""
2214     instances = _instance_get_all_query(context).filter_by(
2215         host=host,
2216     ).filter(
2217         models.Instance.instance_type_id != type_id
2218     ).all()
2219     return _instances_fill_metadata(context, instances)
2220 
2221 
2222 # NOTE(hanlind): This method can be removed as conductor RPC API moves to v2.0.
2223 @pick_context_manager_reader
2224 def instance_get_all_hung_in_rebooting(context, reboot_window):
2225     """Get all instances stuck in a rebooting state."""
2226     reboot_window = (timeutils.utcnow() -
2227                      datetime.timedelta(seconds=reboot_window))
2228 
2229     # NOTE(danms): this is only used in the _poll_rebooting_instances()
2230     # call in compute/manager, so we can avoid the metadata lookups
2231     # explicitly
2232     instances = model_query(context, models.Instance).filter(
2233         models.Instance.updated_at <= reboot_window
2234     ).filter_by(task_state=task_states.REBOOTING).all()
2235     return _instances_fill_metadata(
2236         context,
2237         instances,
2238         manual_joins=[],
2239     )
2240 
2241 
2242 def _retry_instance_update():
2243     """Wrap with oslo_db_api.wrap_db_retry, and also retry on
2244     UnknownInstanceUpdateConflict.
2245     """
2246     exception_checker = \
2247         lambda exc: isinstance(exc, (exception.UnknownInstanceUpdateConflict,))
2248     return oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True,
2249                                      exception_checker=exception_checker)
2250 
2251 
2252 @require_context
2253 @_retry_instance_update()
2254 @pick_context_manager_writer
2255 def instance_update(context, instance_uuid, values, expected=None):
2256     """Set the given properties on an instance and update it.
2257 
2258     :raises: NotFound if instance does not exist.
2259     """
2260     return _instance_update(context, instance_uuid, values, expected)
2261 
2262 
2263 @require_context
2264 @_retry_instance_update()
2265 @pick_context_manager_writer
2266 def instance_update_and_get_original(context, instance_uuid, values,
2267                                      columns_to_join=None, expected=None):
2268     """Set the given properties on an instance and update it.
2269 
2270     Return a shallow copy of the original instance reference, as well as the
2271     updated one.
2272 
2273     If "expected_task_state" exists in values, the update can only happen
2274     when the task state before update matches expected_task_state. Otherwise
2275     a UnexpectedTaskStateError is thrown.
2276 
2277     :param context: request context object
2278     :param instance_uuid: instance uuid
2279     :param values: dict containing column values
2280     :returns: a tuple of the form (old_instance_ref, new_instance_ref)
2281     :raises: NotFound if instance does not exist.
2282     """
2283     instance_ref = _instance_get_by_uuid(context, instance_uuid,
2284                                          columns_to_join=columns_to_join)
2285     return (copy.copy(instance_ref), _instance_update(
2286         context, instance_uuid, values, expected, original=instance_ref))
2287 
2288 
2289 # NOTE(danms): This updates the instance's metadata list in-place and in
2290 # the database to avoid stale data and refresh issues. It assumes the
2291 # delete=True behavior of instance_metadata_update(...)
2292 def _instance_metadata_update_in_place(context, instance, metadata_type, model,
2293                                        metadata):
2294     metadata = dict(metadata)
2295     to_delete = []
2296     for keyvalue in instance[metadata_type]:
2297         key = keyvalue['key']
2298         if key in metadata:
2299             keyvalue['value'] = metadata.pop(key)
2300         elif key not in metadata:
2301             to_delete.append(keyvalue)
2302 
2303     # NOTE: we have to hard_delete here otherwise we will get more than one
2304     # system_metadata record when we read deleted for an instance;
2305     # regular metadata doesn't have the same problem because we don't
2306     # allow reading deleted regular metadata anywhere.
2307     if metadata_type == 'system_metadata':
2308         for condemned in to_delete:
2309             context.session.delete(condemned)
2310             instance[metadata_type].remove(condemned)
2311     else:
2312         for condemned in to_delete:
2313             condemned.soft_delete(context.session)
2314 
2315     for key, value in metadata.items():
2316         newitem = model()
2317         newitem.update({'key': key, 'value': value,
2318                         'instance_uuid': instance['uuid']})
2319         context.session.add(newitem)
2320         instance[metadata_type].append(newitem)
2321 
2322 
2323 def _instance_update(context, instance_uuid, values, expected, original=None):
2324     if not uuidutils.is_uuid_like(instance_uuid):
2325         raise exception.InvalidUUID(uuid=instance_uuid)
2326 
2327     # NOTE(mdbooth): We pop values from this dict below, so we copy it here to
2328     # ensure there are no side effects for the caller or if we retry the
2329     # function due to a db conflict.
2330     updates = copy.copy(values)
2331 
2332     if expected is None:
2333         expected = {}
2334     else:
2335         # Coerce all single values to singleton lists
2336         expected = {k: [None] if v is None else sqlalchemyutils.to_list(v)
2337                        for (k, v) in expected.items()}
2338 
2339     # Extract 'expected_' values from values dict, as these aren't actually
2340     # updates
2341     for field in ('task_state', 'vm_state'):
2342         expected_field = 'expected_%s' % field
2343         if expected_field in updates:
2344             value = updates.pop(expected_field, None)
2345             # Coerce all single values to singleton lists
2346             if value is None:
2347                 expected[field] = [None]
2348             else:
2349                 expected[field] = sqlalchemyutils.to_list(value)
2350 
2351     # Values which need to be updated separately
2352     metadata = updates.pop('metadata', None)
2353     system_metadata = updates.pop('system_metadata', None)
2354 
2355     _handle_objects_related_type_conversions(updates)
2356 
2357     # Hostname is potentially unique, but this is enforced in code rather
2358     # than the DB. The query below races, but the number of users of
2359     # osapi_compute_unique_server_name_scope is small, and a robust fix
2360     # will be complex. This is intentionally left as is for the moment.
2361     if 'hostname' in updates:
2362         _validate_unique_server_name(context, updates['hostname'])
2363 
2364     compare = models.Instance(uuid=instance_uuid, **expected)
2365     try:
2366         instance_ref = model_query(context, models.Instance,
2367                                    project_only=True).\
2368                        update_on_match(compare, 'uuid', updates)
2369     except update_match.NoRowsMatched:
2370         # Update failed. Try to find why and raise a specific error.
2371 
2372         # We should get here only because our expected values were not current
2373         # when update_on_match executed. Having failed, we now have a hint that
2374         # the values are out of date and should check them.
2375 
2376         # This code is made more complex because we are using repeatable reads.
2377         # If we have previously read the original instance in the current
2378         # transaction, reading it again will return the same data, even though
2379         # the above update failed because it has changed: it is not possible to
2380         # determine what has changed in this transaction. In this case we raise
2381         # UnknownInstanceUpdateConflict, which will cause the operation to be
2382         # retried in a new transaction.
2383 
2384         # Because of the above, if we have previously read the instance in the
2385         # current transaction it will have been passed as 'original', and there
2386         # is no point refreshing it. If we have not previously read the
2387         # instance, we can fetch it here and we will get fresh data.
2388         if original is None:
2389             original = _instance_get_by_uuid(context, instance_uuid)
2390 
2391         conflicts_expected = {}
2392         conflicts_actual = {}
2393         for (field, expected_values) in expected.items():
2394             actual = original[field]
2395             if actual not in expected_values:
2396                 conflicts_expected[field] = expected_values
2397                 conflicts_actual[field] = actual
2398 
2399         # Exception properties
2400         exc_props = {
2401             'instance_uuid': instance_uuid,
2402             'expected': conflicts_expected,
2403             'actual': conflicts_actual
2404         }
2405 
2406         # There was a conflict, but something (probably the MySQL read view,
2407         # but possibly an exceptionally unlikely second race) is preventing us
2408         # from seeing what it is. When we go round again we'll get a fresh
2409         # transaction and a fresh read view.
2410         if len(conflicts_actual) == 0:
2411             raise exception.UnknownInstanceUpdateConflict(**exc_props)
2412 
2413         # Task state gets special handling for convenience. We raise the
2414         # specific error UnexpectedDeletingTaskStateError or
2415         # UnexpectedTaskStateError as appropriate
2416         if 'task_state' in conflicts_actual:
2417             conflict_task_state = conflicts_actual['task_state']
2418             if conflict_task_state == task_states.DELETING:
2419                 exc = exception.UnexpectedDeletingTaskStateError
2420             else:
2421                 exc = exception.UnexpectedTaskStateError
2422 
2423         # Everything else is an InstanceUpdateConflict
2424         else:
2425             exc = exception.InstanceUpdateConflict
2426 
2427         raise exc(**exc_props)
2428 
2429     if metadata is not None:
2430         _instance_metadata_update_in_place(context, instance_ref,
2431                                            'metadata',
2432                                            models.InstanceMetadata,
2433                                            metadata)
2434 
2435     if system_metadata is not None:
2436         _instance_metadata_update_in_place(context, instance_ref,
2437                                            'system_metadata',
2438                                            models.InstanceSystemMetadata,
2439                                            system_metadata)
2440 
2441     return instance_ref
2442 
2443 
2444 @pick_context_manager_writer
2445 def instance_add_security_group(context, instance_uuid, security_group_id):
2446     """Associate the given security group with the given instance."""
2447     sec_group_ref = models.SecurityGroupInstanceAssociation()
2448     sec_group_ref.update({'instance_uuid': instance_uuid,
2449                           'security_group_id': security_group_id})
2450     sec_group_ref.save(context.session)
2451 
2452 
2453 @require_context
2454 @pick_context_manager_writer
2455 def instance_remove_security_group(context, instance_uuid, security_group_id):
2456     """Disassociate the given security group from the given instance."""
2457     model_query(context, models.SecurityGroupInstanceAssociation).\
2458                 filter_by(instance_uuid=instance_uuid).\
2459                 filter_by(security_group_id=security_group_id).\
2460                 soft_delete()
2461 
2462 
2463 ###################
2464 
2465 
2466 @require_context
2467 @pick_context_manager_reader
2468 def instance_info_cache_get(context, instance_uuid):
2469     """Gets an instance info cache from the table.
2470 
2471     :param instance_uuid: = uuid of the info cache's instance
2472     """
2473     return model_query(context, models.InstanceInfoCache).\
2474                          filter_by(instance_uuid=instance_uuid).\
2475                          first()
2476 
2477 
2478 @require_context
2479 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
2480 @pick_context_manager_writer
2481 def instance_info_cache_update(context, instance_uuid, values):
2482     """Update an instance info cache record in the table.
2483 
2484     :param instance_uuid: = uuid of info cache's instance
2485     :param values: = dict containing column values to update
2486     """
2487     convert_objects_related_datetimes(values)
2488 
2489     info_cache = model_query(context, models.InstanceInfoCache).\
2490                      filter_by(instance_uuid=instance_uuid).\
2491                      first()
2492     needs_create = False
2493     if info_cache and info_cache['deleted']:
2494         raise exception.InstanceInfoCacheNotFound(
2495                 instance_uuid=instance_uuid)
2496     elif not info_cache:
2497         # NOTE(tr3buchet): just in case someone blows away an instance's
2498         #                  cache entry, re-create it.
2499         values['instance_uuid'] = instance_uuid
2500         info_cache = models.InstanceInfoCache(**values)
2501         needs_create = True
2502 
2503     try:
2504         with get_context_manager(context).writer.savepoint.using(context):
2505             if needs_create:
2506                 info_cache.save(context.session)
2507             else:
2508                 info_cache.update(values)
2509     except db_exc.DBDuplicateEntry:
2510         # NOTE(sirp): Possible race if two greenthreads attempt to
2511         # recreate the instance cache entry at the same time. First one
2512         # wins.
2513         pass
2514 
2515     return info_cache
2516 
2517 
2518 @require_context
2519 @pick_context_manager_writer
2520 def instance_info_cache_delete(context, instance_uuid):
2521     """Deletes an existing instance_info_cache record
2522 
2523     :param instance_uuid: = uuid of the instance tied to the cache record
2524     """
2525     model_query(context, models.InstanceInfoCache).\
2526                          filter_by(instance_uuid=instance_uuid).\
2527                          soft_delete()
2528 
2529 
2530 ###################
2531 
2532 
2533 def _instance_extra_create(context, values):
2534     inst_extra_ref = models.InstanceExtra()
2535     inst_extra_ref.update(values)
2536     inst_extra_ref.save(context.session)
2537     return inst_extra_ref
2538 
2539 
2540 @pick_context_manager_writer
2541 def instance_extra_update_by_uuid(context, instance_uuid, updates):
2542     """Update the instance extra record by instance uuid
2543 
2544     :param instance_uuid: UUID of the instance tied to the record
2545     :param updates: A dict of updates to apply
2546     """
2547     rows_updated = model_query(context, models.InstanceExtra).\
2548         filter_by(instance_uuid=instance_uuid).\
2549         update(updates)
2550     if not rows_updated:
2551         LOG.debug("Created instance_extra for %s", instance_uuid)
2552         create_values = copy.copy(updates)
2553         create_values["instance_uuid"] = instance_uuid
2554         _instance_extra_create(context, create_values)
2555         rows_updated = 1
2556     return rows_updated
2557 
2558 
2559 @pick_context_manager_reader
2560 def instance_extra_get_by_instance_uuid(
2561     context, instance_uuid, columns=None,
2562 ):
2563     """Get the instance extra record
2564 
2565     :param instance_uuid: UUID of the instance tied to the topology record
2566     :param columns: A list of the columns to load, or None for 'all of them'
2567     """
2568     query = model_query(context, models.InstanceExtra).filter_by(
2569         instance_uuid=instance_uuid,
2570     )
2571     if columns is None:
2572         columns = ['numa_topology', 'pci_requests', 'flavor', 'vcpu_model',
2573                    'trusted_certs', 'resources', 'migration_context']
2574     for column in columns:
2575         column_ref = getattr(models.InstanceExtra, column)
2576         query = query.options(orm.undefer(column_ref))
2577     instance_extra = query.first()
2578     return instance_extra
2579 
2580 
2581 ###################
2582 
2583 
2584 @require_context
2585 @pick_context_manager_reader
2586 def quota_get(context, project_id, resource, user_id=None):
2587     """Retrieve a quota or raise if it does not exist."""
2588     model = models.ProjectUserQuota if user_id else models.Quota
2589     query = model_query(context, model).\
2590                     filter_by(project_id=project_id).\
2591                     filter_by(resource=resource)
2592     if user_id:
2593         query = query.filter_by(user_id=user_id)
2594 
2595     result = query.first()
2596     if not result:
2597         if user_id:
2598             raise exception.ProjectUserQuotaNotFound(project_id=project_id,
2599                                                      user_id=user_id)
2600         else:
2601             raise exception.ProjectQuotaNotFound(project_id=project_id)
2602 
2603     return result
2604 
2605 
2606 @require_context
2607 @pick_context_manager_reader
2608 def quota_get_all_by_project_and_user(context, project_id, user_id):
2609     """Retrieve all quotas associated with a given project and user."""
2610     user_quotas = model_query(context, models.ProjectUserQuota,
2611                               (models.ProjectUserQuota.resource,
2612                                models.ProjectUserQuota.hard_limit)).\
2613                    filter_by(project_id=project_id).\
2614                    filter_by(user_id=user_id).\
2615                    all()
2616 
2617     result = {'project_id': project_id, 'user_id': user_id}
2618     for user_quota in user_quotas:
2619         result[user_quota.resource] = user_quota.hard_limit
2620 
2621     return result
2622 
2623 
2624 @require_context
2625 @pick_context_manager_reader
2626 def quota_get_all_by_project(context, project_id):
2627     """Retrieve all quotas associated with a given project."""
2628     rows = model_query(context, models.Quota, read_deleted="no").\
2629                    filter_by(project_id=project_id).\
2630                    all()
2631 
2632     result = {'project_id': project_id}
2633     for row in rows:
2634         result[row.resource] = row.hard_limit
2635 
2636     return result
2637 
2638 
2639 @require_context
2640 @pick_context_manager_reader
2641 def quota_get_all(context, project_id):
2642     """Retrieve all user quotas associated with a given project."""
2643     result = model_query(context, models.ProjectUserQuota).\
2644                    filter_by(project_id=project_id).\
2645                    all()
2646 
2647     return result
2648 
2649 
2650 def quota_get_per_project_resources():
2651     """Retrieve the names of resources whose quotas are calculated on a
2652     per-project rather than a per-user basis.
2653     """
2654     return PER_PROJECT_QUOTAS
2655 
2656 
2657 @pick_context_manager_writer
2658 def quota_create(context, project_id, resource, limit, user_id=None):
2659     """Create a quota for the given project and resource."""
2660     per_user = user_id and resource not in PER_PROJECT_QUOTAS
2661     quota_ref = models.ProjectUserQuota() if per_user else models.Quota()
2662     if per_user:
2663         quota_ref.user_id = user_id
2664     quota_ref.project_id = project_id
2665     quota_ref.resource = resource
2666     quota_ref.hard_limit = limit
2667     try:
2668         quota_ref.save(context.session)
2669     except db_exc.DBDuplicateEntry:
2670         raise exception.QuotaExists(project_id=project_id, resource=resource)
2671     return quota_ref
2672 
2673 
2674 @pick_context_manager_writer
2675 def quota_update(context, project_id, resource, limit, user_id=None):
2676     """Update a quota or raise if it does not exist."""
2677     per_user = user_id and resource not in PER_PROJECT_QUOTAS
2678     model = models.ProjectUserQuota if per_user else models.Quota
2679     query = model_query(context, model).\
2680                 filter_by(project_id=project_id).\
2681                 filter_by(resource=resource)
2682     if per_user:
2683         query = query.filter_by(user_id=user_id)
2684 
2685     result = query.update({'hard_limit': limit})
2686     if not result:
2687         if per_user:
2688             raise exception.ProjectUserQuotaNotFound(project_id=project_id,
2689                                                      user_id=user_id)
2690         else:
2691             raise exception.ProjectQuotaNotFound(project_id=project_id)
2692 
2693 
2694 ###################
2695 
2696 
2697 @require_context
2698 @pick_context_manager_reader
2699 def quota_class_get(context, class_name, resource):
2700     """Retrieve a quota class or raise if it does not exist."""
2701     result = model_query(context, models.QuotaClass, read_deleted="no").\
2702                      filter_by(class_name=class_name).\
2703                      filter_by(resource=resource).\
2704                      first()
2705 
2706     if not result:
2707         raise exception.QuotaClassNotFound(class_name=class_name)
2708 
2709     return result
2710 
2711 
2712 @pick_context_manager_reader
2713 def quota_class_get_default(context):
2714     """Retrieve all default quotas."""
2715     rows = model_query(context, models.QuotaClass, read_deleted="no").\
2716                    filter_by(class_name=_DEFAULT_QUOTA_NAME).\
2717                    all()
2718 
2719     result = {'class_name': _DEFAULT_QUOTA_NAME}
2720     for row in rows:
2721         result[row.resource] = row.hard_limit
2722 
2723     return result
2724 
2725 
2726 @require_context
2727 @pick_context_manager_reader
2728 def quota_class_get_all_by_name(context, class_name):
2729     """Retrieve all quotas associated with a given quota class."""
2730     rows = model_query(context, models.QuotaClass, read_deleted="no").\
2731                    filter_by(class_name=class_name).\
2732                    all()
2733 
2734     result = {'class_name': class_name}
2735     for row in rows:
2736         result[row.resource] = row.hard_limit
2737 
2738     return result
2739 
2740 
2741 @pick_context_manager_writer
2742 def quota_class_create(context, class_name, resource, limit):
2743     """Create a quota class for the given name and resource."""
2744     quota_class_ref = models.QuotaClass()
2745     quota_class_ref.class_name = class_name
2746     quota_class_ref.resource = resource
2747     quota_class_ref.hard_limit = limit
2748     quota_class_ref.save(context.session)
2749     return quota_class_ref
2750 
2751 
2752 @pick_context_manager_writer
2753 def quota_class_update(context, class_name, resource, limit):
2754     """Update a quota class or raise if it does not exist."""
2755     result = model_query(context, models.QuotaClass, read_deleted="no").\
2756                      filter_by(class_name=class_name).\
2757                      filter_by(resource=resource).\
2758                      update({'hard_limit': limit})
2759 
2760     if not result:
2761         raise exception.QuotaClassNotFound(class_name=class_name)
2762 
2763 
2764 ###################
2765 
2766 
2767 @pick_context_manager_writer
2768 def quota_destroy_all_by_project_and_user(context, project_id, user_id):
2769     """Destroy all quotas associated with a given project and user."""
2770     model_query(context, models.ProjectUserQuota, read_deleted="no").\
2771         filter_by(project_id=project_id).\
2772         filter_by(user_id=user_id).\
2773         soft_delete(synchronize_session=False)
2774 
2775 
2776 @pick_context_manager_writer
2777 def quota_destroy_all_by_project(context, project_id):
2778     """Destroy all quotas associated with a given project."""
2779     model_query(context, models.Quota, read_deleted="no").\
2780         filter_by(project_id=project_id).\
2781         soft_delete(synchronize_session=False)
2782 
2783     model_query(context, models.ProjectUserQuota, read_deleted="no").\
2784         filter_by(project_id=project_id).\
2785         soft_delete(synchronize_session=False)
2786 
2787 
2788 ###################
2789 
2790 
2791 def _block_device_mapping_get_query(context, columns_to_join=None):
2792     if columns_to_join is None:
2793         columns_to_join = []
2794 
2795     query = model_query(context, models.BlockDeviceMapping)
2796 
2797     for column in columns_to_join:
2798         column_ref = getattr(models.BlockDeviceMapping, column)
2799         query = query.options(orm.joinedload(column_ref))
2800 
2801     return query
2802 
2803 
2804 def _scrub_empty_str_values(dct, keys_to_scrub):
2805     """Remove any keys found in sequence keys_to_scrub from the dict
2806     if they have the value ''.
2807     """
2808     for key in keys_to_scrub:
2809         if key in dct and dct[key] == '':
2810             del dct[key]
2811 
2812 
2813 def _from_legacy_values(values, legacy, allow_updates=False):
2814     if legacy:
2815         if allow_updates and block_device.is_safe_for_update(values):
2816             return values
2817         else:
2818             return block_device.BlockDeviceDict.from_legacy(values)
2819     else:
2820         return values
2821 
2822 
2823 def _set_or_validate_uuid(values):
2824     uuid = values.get('uuid')
2825 
2826     # values doesn't contain uuid, or it's blank
2827     if not uuid:
2828         values['uuid'] = uuidutils.generate_uuid()
2829 
2830     # values contains a uuid
2831     else:
2832         if not uuidutils.is_uuid_like(uuid):
2833             raise exception.InvalidUUID(uuid=uuid)
2834 
2835 
2836 @require_context
2837 @pick_context_manager_writer
2838 def block_device_mapping_create(context, values, legacy=True):
2839     """Create an entry of block device mapping."""
2840     _scrub_empty_str_values(values, ['volume_size'])
2841     values = _from_legacy_values(values, legacy)
2842     convert_objects_related_datetimes(values)
2843 
2844     _set_or_validate_uuid(values)
2845 
2846     bdm_ref = models.BlockDeviceMapping()
2847     bdm_ref.update(values)
2848     bdm_ref.save(context.session)
2849     return bdm_ref
2850 
2851 
2852 @require_context
2853 @pick_context_manager_writer
2854 def block_device_mapping_update(context, bdm_id, values, legacy=True):
2855     """Update an entry of block device mapping."""
2856     _scrub_empty_str_values(values, ['volume_size'])
2857     values = _from_legacy_values(values, legacy, allow_updates=True)
2858     convert_objects_related_datetimes(values)
2859 
2860     query = _block_device_mapping_get_query(context).filter_by(id=bdm_id)
2861     query.update(values)
2862     return query.first()
2863 
2864 
2865 @pick_context_manager_writer
2866 def block_device_mapping_update_or_create(context, values, legacy=True):
2867     """Update an entry of block device mapping.
2868 
2869     If not existed, create a new entry
2870     """
2871     # TODO(mdbooth): Remove this method entirely. Callers should know whether
2872     # they require update or create, and call the appropriate method.
2873 
2874     _scrub_empty_str_values(values, ['volume_size'])
2875     values = _from_legacy_values(values, legacy, allow_updates=True)
2876     convert_objects_related_datetimes(values)
2877 
2878     result = None
2879     # NOTE(xqueralt,danms): Only update a BDM when device_name or
2880     # uuid was provided. Prefer the uuid, if available, but fall
2881     # back to device_name if no uuid is provided, which can happen
2882     # for BDMs created before we had a uuid. We allow empty device
2883     # names so they will be set later by the manager.
2884     if 'uuid' in values:
2885         query = _block_device_mapping_get_query(context)
2886         result = query.filter_by(instance_uuid=values['instance_uuid'],
2887                                  uuid=values['uuid']).one_or_none()
2888 
2889     if not result and values['device_name']:
2890         query = _block_device_mapping_get_query(context)
2891         result = query.filter_by(instance_uuid=values['instance_uuid'],
2892                                  device_name=values['device_name']).first()
2893 
2894     if result:
2895         result.update(values)
2896     else:
2897         # Either the device_name or uuid doesn't exist in the database yet, or
2898         # neither was provided. Both cases mean creating a new BDM.
2899         _set_or_validate_uuid(values)
2900         result = models.BlockDeviceMapping(**values)
2901         result.save(context.session)
2902 
2903     # NOTE(xqueralt): Prevent from having multiple swap devices for the
2904     # same instance. This will delete all the existing ones.
2905     if block_device.new_format_is_swap(values):
2906         query = _block_device_mapping_get_query(context)
2907         query = query.filter_by(instance_uuid=values['instance_uuid'],
2908                                 source_type='blank', guest_format='swap')
2909         query = query.filter(models.BlockDeviceMapping.id != result.id)
2910         query.soft_delete()
2911 
2912     return result
2913 
2914 
2915 @require_context
2916 @pick_context_manager_reader_allow_async
2917 def block_device_mapping_get_all_by_instance_uuids(context, instance_uuids):
2918     """Get all block device mapping belonging to a list of instances."""
2919     if not instance_uuids:
2920         return []
2921     return _block_device_mapping_get_query(context).filter(
2922         models.BlockDeviceMapping.instance_uuid.in_(instance_uuids)).all()
2923 
2924 
2925 @require_context
2926 @pick_context_manager_reader_allow_async
2927 def block_device_mapping_get_all_by_instance(context, instance_uuid):
2928     """Get all block device mapping belonging to an instance."""
2929     return _block_device_mapping_get_query(context).\
2930                  filter_by(instance_uuid=instance_uuid).\
2931                  all()
2932 
2933 
2934 @require_context
2935 @pick_context_manager_reader
2936 def block_device_mapping_get_all_by_volume_id(
2937     context, volume_id, columns_to_join=None,
2938 ):
2939     """Get block device mapping for a given volume."""
2940     return _block_device_mapping_get_query(context,
2941             columns_to_join=columns_to_join).\
2942                  filter_by(volume_id=volume_id).\
2943                  all()
2944 
2945 
2946 @require_context
2947 @pick_context_manager_reader
2948 def block_device_mapping_get_by_instance_and_volume_id(
2949     context, volume_id, instance_uuid, columns_to_join=None,
2950 ):
2951     """Get block device mapping for a given volume ID and instance UUID."""
2952     return _block_device_mapping_get_query(context,
2953             columns_to_join=columns_to_join).\
2954                  filter_by(volume_id=volume_id).\
2955                  filter_by(instance_uuid=instance_uuid).\
2956                  first()
2957 
2958 
2959 @require_context
2960 @pick_context_manager_writer
2961 def block_device_mapping_destroy(context, bdm_id):
2962     """Destroy the block device mapping."""
2963     _block_device_mapping_get_query(context).\
2964             filter_by(id=bdm_id).\
2965             soft_delete()
2966 
2967 
2968 @require_context
2969 @pick_context_manager_writer
2970 def block_device_mapping_destroy_by_instance_and_volume(
2971     context, instance_uuid, volume_id,
2972 ):
2973     """Destroy the block device mapping."""
2974     _block_device_mapping_get_query(context).\
2975             filter_by(instance_uuid=instance_uuid).\
2976             filter_by(volume_id=volume_id).\
2977             soft_delete()
2978 
2979 
2980 @require_context
2981 @pick_context_manager_writer
2982 def block_device_mapping_destroy_by_instance_and_device(
2983     context, instance_uuid, device_name,
2984 ):
2985     """Destroy the block device mapping."""
2986     _block_device_mapping_get_query(context).\
2987             filter_by(instance_uuid=instance_uuid).\
2988             filter_by(device_name=device_name).\
2989             soft_delete()
2990 
2991 
2992 ###################
2993 
2994 
2995 @require_context
2996 @pick_context_manager_writer
2997 def security_group_create(context, values):
2998     """Create a new security group."""
2999     security_group_ref = models.SecurityGroup()
3000     # FIXME(devcamcar): Unless I do this, rules fails with lazy load exception
3001     # once save() is called.  This will get cleaned up in next orm pass.
3002     security_group_ref.rules = []
3003     security_group_ref.update(values)
3004     try:
3005         with get_context_manager(context).writer.savepoint.using(context):
3006             security_group_ref.save(context.session)
3007     except db_exc.DBDuplicateEntry:
3008         raise exception.SecurityGroupExists(
3009                 project_id=values['project_id'],
3010                 security_group_name=values['name'])
3011     return security_group_ref
3012 
3013 
3014 def _security_group_get_query(context, read_deleted=None,
3015                               project_only=False, join_rules=True):
3016     query = model_query(
3017         context,
3018         models.SecurityGroup,
3019         read_deleted=read_deleted,
3020         project_only=project_only,
3021     )
3022     if join_rules:
3023         query = query.options(
3024             orm.joinedload(
3025                 models.SecurityGroup.rules
3026             ).joinedload(models.SecurityGroupIngressRule.grantee_group)
3027         )
3028     return query
3029 
3030 
3031 def _security_group_get_by_names(context, group_names):
3032     """Get security group models for a project by a list of names.
3033     Raise SecurityGroupNotFoundForProject for a name not found.
3034     """
3035     query = _security_group_get_query(context, read_deleted="no",
3036                                       join_rules=False).\
3037             filter_by(project_id=context.project_id).\
3038             filter(models.SecurityGroup.name.in_(group_names))
3039     sg_models = query.all()
3040     if len(sg_models) == len(group_names):
3041         return sg_models
3042     # Find the first one missing and raise
3043     group_names_from_models = [x.name for x in sg_models]
3044     for group_name in group_names:
3045         if group_name not in group_names_from_models:
3046             raise exception.SecurityGroupNotFoundForProject(
3047                 project_id=context.project_id, security_group_id=group_name)
3048     # Not Reached
3049 
3050 
3051 @require_context
3052 @pick_context_manager_reader
3053 def security_group_get_all(context):
3054     """Get all security groups."""
3055     return _security_group_get_query(context).all()
3056 
3057 
3058 @require_context
3059 @pick_context_manager_reader
3060 def security_group_get(context, security_group_id, columns_to_join=None):
3061     """Get security group by its ID."""
3062     join_rules = columns_to_join and 'rules' in columns_to_join
3063     if join_rules:
3064         columns_to_join.remove('rules')
3065     query = _security_group_get_query(context, project_only=True,
3066                                       join_rules=join_rules).\
3067                     filter_by(id=security_group_id)
3068 
3069     if columns_to_join is None:
3070         columns_to_join = []
3071     for column in columns_to_join:
3072         query = query.options(_joinedload_all(models.SecurityGroup, column))
3073 
3074     result = query.first()
3075     if not result:
3076         raise exception.SecurityGroupNotFound(
3077                 security_group_id=security_group_id)
3078 
3079     return result
3080 
3081 
3082 @require_context
3083 @pick_context_manager_reader
3084 def security_group_get_by_name(context, project_id, group_name):
3085     """Returns a security group with the specified name from a project."""
3086     query = _security_group_get_query(
3087         context, read_deleted="no", join_rules=False,
3088     ).filter_by(
3089         project_id=project_id,
3090     ).filter_by(
3091         name=group_name,
3092     ).options(
3093         orm.joinedload(models.SecurityGroup.instances)
3094     ).options(
3095         orm.joinedload(
3096             models.SecurityGroup.rules
3097         ).joinedload(models.SecurityGroupIngressRule.grantee_group)
3098     )
3099 
3100     result = query.first()
3101     if not result:
3102         raise exception.SecurityGroupNotFoundForProject(
3103             project_id=project_id, security_group_id=group_name,
3104         )
3105 
3106     return result
3107 
3108 
3109 @require_context
3110 @pick_context_manager_reader
3111 def security_group_get_by_project(context, project_id):
3112     """Get all security groups belonging to a project."""
3113     return _security_group_get_query(context, read_deleted="no").\
3114                         filter_by(project_id=project_id).\
3115                         all()
3116 
3117 
3118 @require_context
3119 @pick_context_manager_reader
3120 def security_group_get_by_instance(context, instance_uuid):
3121     """Get security groups to which the instance is assigned."""
3122     return _security_group_get_query(context, read_deleted="no").\
3123                    join(models.SecurityGroup.instances).\
3124                    filter_by(uuid=instance_uuid).\
3125                    all()
3126 
3127 
3128 @require_context
3129 @pick_context_manager_reader
3130 def security_group_in_use(context, group_id):
3131     """Indicates if a security group is currently in use."""
3132     # Are there any instances that haven't been deleted
3133     # that include this group?
3134     inst_assoc = model_query(context,
3135                              models.SecurityGroupInstanceAssociation,
3136                              read_deleted="no").\
3137                     filter_by(security_group_id=group_id).\
3138                     all()
3139     for ia in inst_assoc:
3140         num_instances = model_query(context, models.Instance,
3141                                     read_deleted="no").\
3142                     filter_by(uuid=ia.instance_uuid).\
3143                     count()
3144         if num_instances:
3145             return True
3146 
3147     return False
3148 
3149 
3150 @require_context
3151 @pick_context_manager_writer
3152 def security_group_update(context, security_group_id, values):
3153     """Update a security group."""
3154     query = model_query(context, models.SecurityGroup).filter_by(
3155         id=security_group_id,
3156     )
3157     security_group_ref = query.first()
3158 
3159     if not security_group_ref:
3160         raise exception.SecurityGroupNotFound(
3161                 security_group_id=security_group_id)
3162     security_group_ref.update(values)
3163     name = security_group_ref['name']
3164     project_id = security_group_ref['project_id']
3165     try:
3166         security_group_ref.save(context.session)
3167     except db_exc.DBDuplicateEntry:
3168         raise exception.SecurityGroupExists(
3169                 project_id=project_id,
3170                 security_group_name=name)
3171     return security_group_ref
3172 
3173 
3174 def security_group_ensure_default(context):
3175     """Ensure default security group exists for a project_id.
3176 
3177     Returns a tuple with the first element being a bool indicating
3178     if the default security group previously existed. Second
3179     element is the dict used to create the default security group.
3180     """
3181 
3182     try:
3183         # NOTE(rpodolyaka): create the default security group, if it doesn't
3184         # exist. This must be done in a separate transaction, so that
3185         # this one is not aborted in case a concurrent one succeeds first
3186         # and the unique constraint for security group names is violated
3187         # by a concurrent INSERT
3188         with get_context_manager(context).writer.independent.using(context):
3189             return _security_group_ensure_default(context)
3190     except exception.SecurityGroupExists:
3191         # NOTE(rpodolyaka): a concurrent transaction has succeeded first,
3192         # suppress the error and proceed
3193         return security_group_get_by_name(context, context.project_id,
3194                                           'default')
3195 
3196 
3197 @pick_context_manager_writer
3198 def _security_group_ensure_default(context):
3199     try:
3200         default_group = _security_group_get_by_names(context, ['default'])[0]
3201     except exception.NotFound:
3202         values = {'name': 'default',
3203                   'description': 'default',
3204                   'user_id': context.user_id,
3205                   'project_id': context.project_id}
3206         default_group = security_group_create(context, values)
3207     return default_group
3208 
3209 
3210 @require_context
3211 @pick_context_manager_writer
3212 def security_group_destroy(context, security_group_id):
3213     """Deletes a security group."""
3214     model_query(context, models.SecurityGroup).\
3215             filter_by(id=security_group_id).\
3216             soft_delete()
3217     model_query(context, models.SecurityGroupInstanceAssociation).\
3218             filter_by(security_group_id=security_group_id).\
3219             soft_delete()
3220     model_query(context, models.SecurityGroupIngressRule).\
3221             filter_by(group_id=security_group_id).\
3222             soft_delete()
3223     model_query(context, models.SecurityGroupIngressRule).\
3224             filter_by(parent_group_id=security_group_id).\
3225             soft_delete()
3226 
3227 
3228 ###################
3229 
3230 
3231 @pick_context_manager_writer
3232 def migration_create(context, values):
3233     """Create a migration record."""
3234     migration = models.Migration()
3235     migration.update(values)
3236     migration.save(context.session)
3237     return migration
3238 
3239 
3240 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
3241 @pick_context_manager_writer
3242 def migration_update(context, migration_id, values):
3243     """Update a migration instance."""
3244     migration = migration_get(context, migration_id)
3245     migration.update(values)
3246 
3247     return migration
3248 
3249 
3250 @pick_context_manager_reader
3251 def migration_get(context, migration_id):
3252     """Finds a migration by the ID."""
3253     result = model_query(context, models.Migration, read_deleted="yes").\
3254                      filter_by(id=migration_id).\
3255                      first()
3256 
3257     if not result:
3258         raise exception.MigrationNotFound(migration_id=migration_id)
3259 
3260     return result
3261 
3262 
3263 @pick_context_manager_reader
3264 def migration_get_by_uuid(context, migration_uuid):
3265     """Finds a migration by the migration UUID."""
3266     result = model_query(context, models.Migration, read_deleted="yes").\
3267                      filter_by(uuid=migration_uuid).\
3268                      first()
3269 
3270     if not result:
3271         raise exception.MigrationNotFound(migration_id=migration_uuid)
3272 
3273     return result
3274 
3275 
3276 @pick_context_manager_reader
3277 def migration_get_by_id_and_instance(context, migration_id, instance_uuid):
3278     """Finds a migration by the migration ID and the instance UUID."""
3279     result = model_query(context, models.Migration).\
3280                      filter_by(id=migration_id).\
3281                      filter_by(instance_uuid=instance_uuid).\
3282                      first()
3283 
3284     if not result:
3285         raise exception.MigrationNotFoundForInstance(
3286             migration_id=migration_id, instance_id=instance_uuid)
3287 
3288     return result
3289 
3290 
3291 @pick_context_manager_reader
3292 def migration_get_by_instance_and_status(context, instance_uuid, status):
3293     """Finds a migration by the instance UUID it's migrating."""
3294     result = model_query(context, models.Migration, read_deleted="yes").\
3295                      filter_by(instance_uuid=instance_uuid).\
3296                      filter_by(status=status).\
3297                      first()
3298 
3299     if not result:
3300         raise exception.MigrationNotFoundByStatus(instance_id=instance_uuid,
3301                                                   status=status)
3302 
3303     return result
3304 
3305 
3306 @pick_context_manager_reader_allow_async
3307 def migration_get_unconfirmed_by_dest_compute(
3308     context, confirm_window, dest_compute,
3309 ):
3310     """Finds all unconfirmed migrations within the confirmation window for
3311     a specific destination compute host.
3312     """
3313     confirm_window = (timeutils.utcnow() -
3314                       datetime.timedelta(seconds=confirm_window))
3315 
3316     return model_query(context, models.Migration, read_deleted="yes").\
3317              filter(models.Migration.updated_at <= confirm_window).\
3318              filter_by(status="finished").\
3319              filter_by(dest_compute=dest_compute).\
3320              all()
3321 
3322 
3323 @pick_context_manager_reader
3324 def migration_get_in_progress_by_host_and_node(context, host, node):
3325     """Finds all migrations for the given host + node  that are not yet
3326     confirmed or reverted.
3327     """
3328     # TODO(mriedem): Tracking what various code flows set for
3329     # migration status is nutty, since it happens all over the place
3330     # and several of the statuses are redundant (done and completed).
3331     # We need to define these in an enum somewhere and just update
3332     # that one central place that defines what "in progress" means.
3333     # NOTE(mriedem): The 'finished' status is not in this list because
3334     # 'finished' means a resize is finished on the destination host
3335     # and the instance is in VERIFY_RESIZE state, so the end state
3336     # for a resize is actually 'confirmed' or 'reverted'.
3337     return model_query(
3338         context, models.Migration,
3339     ).filter(
3340         sql.or_(
3341             sql.and_(
3342                 models.Migration.source_compute == host,
3343                 models.Migration.source_node == node,
3344             ),
3345             sql.and_(
3346                 models.Migration.dest_compute == host,
3347                 models.Migration.dest_node == node,
3348             ),
3349         )
3350     ).filter(
3351         ~models.Migration.status.in_(
3352             [
3353                 'confirmed',
3354                 'reverted',
3355                 'error',
3356                 'failed',
3357                 'completed',
3358                 'cancelled',
3359                 'done',
3360             ]
3361         )
3362     ).options(
3363         orm.joinedload(
3364             models.Migration.instance
3365         ).joinedload(models.Instance.system_metadata)
3366     ).all()
3367 
3368 
3369 @pick_context_manager_reader
3370 def migration_get_in_progress_by_instance(context, instance_uuid,
3371                                           migration_type=None):
3372     """Finds all migrations of an instance in progress."""
3373     # TODO(Shaohe Feng) we should share the in-progress list.
3374     # TODO(Shaohe Feng) will also summarize all status to a new
3375     # MigrationStatus class.
3376     query = model_query(context, models.Migration).\
3377             filter_by(instance_uuid=instance_uuid).\
3378             filter(models.Migration.status.in_(['queued', 'preparing',
3379                                                 'running',
3380                                                 'post-migrating']))
3381     if migration_type:
3382         query = query.filter(models.Migration.migration_type == migration_type)
3383 
3384     return query.all()
3385 
3386 
3387 @pick_context_manager_reader
3388 def migration_get_all_by_filters(context, filters,
3389                                  sort_keys=None, sort_dirs=None,
3390                                  limit=None, marker=None):
3391     """Finds all migrations using the provided filters."""
3392     if limit == 0:
3393         return []
3394 
3395     query = model_query(context, models.Migration)
3396     if "uuid" in filters:
3397         # The uuid filter is here for the MigrationLister and multi-cell
3398         # paging support in the compute API.
3399         uuid = filters["uuid"]
3400         uuid = [uuid] if isinstance(uuid, str) else uuid
3401         query = query.filter(models.Migration.uuid.in_(uuid))
3402 
3403     model_object = models.Migration
3404     query = _get_query_nova_resource_by_changes_time(query,
3405                                                      filters,
3406                                                      model_object)
3407 
3408     if "status" in filters:
3409         status = filters["status"]
3410         status = [status] if isinstance(status, str) else status
3411         query = query.filter(models.Migration.status.in_(status))
3412     if "host" in filters:
3413         host = filters["host"]
3414         query = query.filter(sql.or_(
3415             models.Migration.source_compute == host,
3416             models.Migration.dest_compute == host))
3417     elif "source_compute" in filters:
3418         host = filters['source_compute']
3419         query = query.filter(models.Migration.source_compute == host)
3420     if "node" in filters:
3421         node = filters['node']
3422         query = query.filter(sql.or_(
3423             models.Migration.source_node == node,
3424             models.Migration.dest_node == node))
3425     if "migration_type" in filters:
3426         migtype = filters["migration_type"]
3427         query = query.filter(models.Migration.migration_type == migtype)
3428     if "hidden" in filters:
3429         hidden = filters["hidden"]
3430         query = query.filter(models.Migration.hidden == hidden)
3431     if "instance_uuid" in filters:
3432         instance_uuid = filters["instance_uuid"]
3433         query = query.filter(models.Migration.instance_uuid == instance_uuid)
3434     if 'user_id' in filters:
3435         user_id = filters['user_id']
3436         query = query.filter(models.Migration.user_id == user_id)
3437     if 'project_id' in filters:
3438         project_id = filters['project_id']
3439         query = query.filter(models.Migration.project_id == project_id)
3440 
3441     if marker:
3442         try:
3443             marker = migration_get_by_uuid(context, marker)
3444         except exception.MigrationNotFound:
3445             raise exception.MarkerNotFound(marker=marker)
3446     if limit or marker or sort_keys or sort_dirs:
3447         # Default sort by desc(['created_at', 'id'])
3448         sort_keys, sort_dirs = db_utils.process_sort_params(
3449             sort_keys, sort_dirs, default_dir='desc')
3450         return sqlalchemyutils.paginate_query(query,
3451                                               models.Migration,
3452                                               limit=limit,
3453                                               sort_keys=sort_keys,
3454                                               marker=marker,
3455                                               sort_dirs=sort_dirs).all()
3456     else:
3457         return query.all()
3458 
3459 
3460 @require_context
3461 @pick_context_manager_reader_allow_async
3462 def migration_get_by_sort_filters(context, sort_keys, sort_dirs, values):
3463     """Get the uuid of the first migration in a sort order.
3464 
3465     Return the first migration (uuid) of the set where each column value
3466     is greater than or equal to the matching one in @values, for each key
3467     in @sort_keys. This is used to try to find a marker migration when we don't
3468     have a marker uuid.
3469 
3470     :returns: A UUID of the migration that matched.
3471     """
3472     model = models.Migration
3473     return _model_get_uuid_by_sort_filters(context, model, sort_keys,
3474                                            sort_dirs, values)
3475 
3476 
3477 @pick_context_manager_writer
3478 def migration_migrate_to_uuid(context, count):
3479     # Avoid circular import
3480     from nova import objects
3481 
3482     db_migrations = model_query(context, models.Migration).filter_by(
3483         uuid=None).limit(count).all()
3484 
3485     done = 0
3486     for db_migration in db_migrations:
3487         mig = objects.Migration(context)
3488         mig._from_db_object(context, mig, db_migration)
3489         done += 1
3490 
3491     # We don't have any situation where we can (detectably) not
3492     # migrate a thing, so report anything that matched as "completed".
3493     return done, done
3494 
3495 
3496 @pick_context_manager_reader
3497 def migration_get_in_progress_and_error_by_host_and_node(context, host, node):
3498     """Finds all in progress migrations and error migrations for the given
3499     host and node.
3500     """
3501     return model_query(
3502         context, models.Migration,
3503     ).filter(
3504         sql.or_(
3505             sql.and_(
3506                 models.Migration.source_compute == host,
3507                 models.Migration.source_node == node),
3508             sql.and_(
3509                 models.Migration.dest_compute == host,
3510                 models.Migration.dest_node == node,
3511             ),
3512         )
3513     ).filter(
3514         ~models.Migration.status.in_([
3515             'confirmed',
3516             'reverted',
3517             'failed',
3518             'completed',
3519             'cancelled',
3520             'done',
3521         ])
3522     ).options(
3523         orm.joinedload(
3524             models.Migration.instance
3525         ).joinedload(models.Instance.system_metadata)
3526     ).all()
3527 
3528 
3529 ########################
3530 # User-provided metadata
3531 
3532 def _instance_metadata_get_multi(context, instance_uuids):
3533     if not instance_uuids:
3534         return []
3535     return model_query(context, models.InstanceMetadata).filter(
3536         models.InstanceMetadata.instance_uuid.in_(instance_uuids))
3537 
3538 
3539 def _instance_metadata_get_query(context, instance_uuid):
3540     return model_query(context, models.InstanceMetadata, read_deleted="no").\
3541                     filter_by(instance_uuid=instance_uuid)
3542 
3543 
3544 @require_context
3545 @pick_context_manager_reader
3546 def instance_metadata_get(context, instance_uuid):
3547     """Get all metadata for an instance."""
3548     rows = _instance_metadata_get_query(context, instance_uuid).all()
3549     return {row['key']: row['value'] for row in rows}
3550 
3551 
3552 @require_context
3553 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
3554 @pick_context_manager_writer
3555 def instance_metadata_delete(context, instance_uuid, key):
3556     """Delete the given metadata item."""
3557     _instance_metadata_get_query(context, instance_uuid).\
3558         filter_by(key=key).\
3559         soft_delete()
3560 
3561 
3562 @require_context
3563 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
3564 @pick_context_manager_writer
3565 def instance_metadata_update(context, instance_uuid, metadata, delete):
3566     """Update metadata if it exists, otherwise create it."""
3567     all_keys = metadata.keys()
3568     if delete:
3569         _instance_metadata_get_query(context, instance_uuid).\
3570             filter(~models.InstanceMetadata.key.in_(all_keys)).\
3571             soft_delete(synchronize_session=False)
3572 
3573     already_existing_keys = []
3574     meta_refs = _instance_metadata_get_query(context, instance_uuid).\
3575         filter(models.InstanceMetadata.key.in_(all_keys)).\
3576         all()
3577 
3578     for meta_ref in meta_refs:
3579         already_existing_keys.append(meta_ref.key)
3580         meta_ref.update({"value": metadata[meta_ref.key]})
3581 
3582     new_keys = set(all_keys) - set(already_existing_keys)
3583     for key in new_keys:
3584         meta_ref = models.InstanceMetadata()
3585         meta_ref.update({"key": key, "value": metadata[key],
3586                          "instance_uuid": instance_uuid})
3587         context.session.add(meta_ref)
3588 
3589     return metadata
3590 
3591 
3592 #######################
3593 # System-owned metadata
3594 
3595 
3596 def _instance_system_metadata_get_multi(context, instance_uuids):
3597     if not instance_uuids:
3598         return []
3599     return model_query(context, models.InstanceSystemMetadata,
3600                        read_deleted='yes').filter(
3601         models.InstanceSystemMetadata.instance_uuid.in_(instance_uuids))
3602 
3603 
3604 def _instance_system_metadata_get_query(context, instance_uuid):
3605     return model_query(context, models.InstanceSystemMetadata).\
3606                     filter_by(instance_uuid=instance_uuid)
3607 
3608 
3609 @require_context
3610 @pick_context_manager_reader
3611 def instance_system_metadata_get(context, instance_uuid):
3612     """Get all system metadata for an instance."""
3613     rows = _instance_system_metadata_get_query(context, instance_uuid).all()
3614     return {row['key']: row['value'] for row in rows}
3615 
3616 
3617 @require_context
3618 @pick_context_manager_writer
3619 def instance_system_metadata_update(context, instance_uuid, metadata, delete):
3620     """Update metadata if it exists, otherwise create it."""
3621     all_keys = metadata.keys()
3622     if delete:
3623         _instance_system_metadata_get_query(context, instance_uuid).\
3624             filter(~models.InstanceSystemMetadata.key.in_(all_keys)).\
3625             soft_delete(synchronize_session=False)
3626 
3627     already_existing_keys = []
3628     meta_refs = _instance_system_metadata_get_query(context, instance_uuid).\
3629         filter(models.InstanceSystemMetadata.key.in_(all_keys)).\
3630         all()
3631 
3632     for meta_ref in meta_refs:
3633         already_existing_keys.append(meta_ref.key)
3634         meta_ref.update({"value": metadata[meta_ref.key]})
3635 
3636     new_keys = set(all_keys) - set(already_existing_keys)
3637     for key in new_keys:
3638         meta_ref = models.InstanceSystemMetadata()
3639         meta_ref.update({"key": key, "value": metadata[key],
3640                          "instance_uuid": instance_uuid})
3641         context.session.add(meta_ref)
3642 
3643     return metadata
3644 
3645 
3646 ####################
3647 
3648 
3649 @require_context
3650 @pick_context_manager_reader
3651 def vol_get_usage_by_time(context, begin):
3652     """Return volumes usage that have been updated after a specified time."""
3653     return model_query(context, models.VolumeUsage, read_deleted="yes").\
3654         filter(sql.or_(
3655             models.VolumeUsage.tot_last_refreshed == sql.null(),
3656             models.VolumeUsage.tot_last_refreshed > begin,
3657             models.VolumeUsage.curr_last_refreshed == sql.null(),
3658             models.VolumeUsage.curr_last_refreshed > begin,
3659         )).all()
3660 
3661 
3662 @require_context
3663 @pick_context_manager_writer
3664 def vol_usage_update(
3665     context, id, rd_req, rd_bytes, wr_req, wr_bytes,
3666     instance_id, project_id, user_id, availability_zone,
3667     update_totals=False,
3668 ):
3669     """Update cached volume usage for a volume
3670 
3671     Creates new record if needed.
3672     """
3673 
3674     refreshed = timeutils.utcnow()
3675 
3676     values = {}
3677     # NOTE(dricco): We will be mostly updating current usage records vs
3678     # updating total or creating records. Optimize accordingly.
3679     if not update_totals:
3680         values = {'curr_last_refreshed': refreshed,
3681                   'curr_reads': rd_req,
3682                   'curr_read_bytes': rd_bytes,
3683                   'curr_writes': wr_req,
3684                   'curr_write_bytes': wr_bytes,
3685                   'instance_uuid': instance_id,
3686                   'project_id': project_id,
3687                   'user_id': user_id,
3688                   'availability_zone': availability_zone}
3689     else:
3690         values = {'tot_last_refreshed': refreshed,
3691                   'tot_reads': models.VolumeUsage.tot_reads + rd_req,
3692                   'tot_read_bytes': models.VolumeUsage.tot_read_bytes +
3693                                     rd_bytes,
3694                   'tot_writes': models.VolumeUsage.tot_writes + wr_req,
3695                   'tot_write_bytes': models.VolumeUsage.tot_write_bytes +
3696                                      wr_bytes,
3697                   'curr_reads': 0,
3698                   'curr_read_bytes': 0,
3699                   'curr_writes': 0,
3700                   'curr_write_bytes': 0,
3701                   'instance_uuid': instance_id,
3702                   'project_id': project_id,
3703                   'user_id': user_id,
3704                   'availability_zone': availability_zone}
3705 
3706     current_usage = model_query(context, models.VolumeUsage,
3707                         read_deleted="yes").\
3708                         filter_by(volume_id=id).\
3709                         first()
3710     if current_usage:
3711         if (rd_req < current_usage['curr_reads'] or
3712             rd_bytes < current_usage['curr_read_bytes'] or
3713             wr_req < current_usage['curr_writes'] or
3714                 wr_bytes < current_usage['curr_write_bytes']):
3715             LOG.info("Volume(%s) has lower stats then what is in "
3716                      "the database. Instance must have been rebooted "
3717                      "or crashed. Updating totals.", id)
3718             if not update_totals:
3719                 values['tot_reads'] = (models.VolumeUsage.tot_reads +
3720                                        current_usage['curr_reads'])
3721                 values['tot_read_bytes'] = (
3722                     models.VolumeUsage.tot_read_bytes +
3723                     current_usage['curr_read_bytes'])
3724                 values['tot_writes'] = (models.VolumeUsage.tot_writes +
3725                                         current_usage['curr_writes'])
3726                 values['tot_write_bytes'] = (
3727                     models.VolumeUsage.tot_write_bytes +
3728                     current_usage['curr_write_bytes'])
3729             else:
3730                 values['tot_reads'] = (models.VolumeUsage.tot_reads +
3731                                        current_usage['curr_reads'] +
3732                                        rd_req)
3733                 values['tot_read_bytes'] = (
3734                     models.VolumeUsage.tot_read_bytes +
3735                     current_usage['curr_read_bytes'] + rd_bytes)
3736                 values['tot_writes'] = (models.VolumeUsage.tot_writes +
3737                                         current_usage['curr_writes'] +
3738                                         wr_req)
3739                 values['tot_write_bytes'] = (
3740                     models.VolumeUsage.tot_write_bytes +
3741                     current_usage['curr_write_bytes'] + wr_bytes)
3742 
3743         current_usage.update(values)
3744         current_usage.save(context.session)
3745         context.session.refresh(current_usage)
3746         return current_usage
3747 
3748     vol_usage = models.VolumeUsage()
3749     vol_usage.volume_id = id
3750     vol_usage.instance_uuid = instance_id
3751     vol_usage.project_id = project_id
3752     vol_usage.user_id = user_id
3753     vol_usage.availability_zone = availability_zone
3754 
3755     if not update_totals:
3756         vol_usage.curr_last_refreshed = refreshed
3757         vol_usage.curr_reads = rd_req
3758         vol_usage.curr_read_bytes = rd_bytes
3759         vol_usage.curr_writes = wr_req
3760         vol_usage.curr_write_bytes = wr_bytes
3761     else:
3762         vol_usage.tot_last_refreshed = refreshed
3763         vol_usage.tot_reads = rd_req
3764         vol_usage.tot_read_bytes = rd_bytes
3765         vol_usage.tot_writes = wr_req
3766         vol_usage.tot_write_bytes = wr_bytes
3767 
3768     vol_usage.save(context.session)
3769 
3770     return vol_usage
3771 
3772 
3773 ####################
3774 
3775 
3776 @pick_context_manager_reader
3777 def s3_image_get(context, image_id):
3778     """Find local s3 image represented by the provided id."""
3779     result = model_query(context, models.S3Image, read_deleted="yes").\
3780                  filter_by(id=image_id).\
3781                  first()
3782 
3783     if not result:
3784         raise exception.ImageNotFound(image_id=image_id)
3785 
3786     return result
3787 
3788 
3789 @pick_context_manager_reader
3790 def s3_image_get_by_uuid(context, image_uuid):
3791     """Find local s3 image represented by the provided uuid."""
3792     result = model_query(context, models.S3Image, read_deleted="yes").\
3793                  filter_by(uuid=image_uuid).\
3794                  first()
3795 
3796     if not result:
3797         raise exception.ImageNotFound(image_id=image_uuid)
3798 
3799     return result
3800 
3801 
3802 @pick_context_manager_writer
3803 def s3_image_create(context, image_uuid):
3804     """Create local s3 image represented by provided uuid."""
3805     try:
3806         s3_image_ref = models.S3Image()
3807         s3_image_ref.update({'uuid': image_uuid})
3808         s3_image_ref.save(context.session)
3809     except Exception as e:
3810         raise db_exc.DBError(e)
3811 
3812     return s3_image_ref
3813 
3814 
3815 ####################
3816 
3817 
3818 @pick_context_manager_writer
3819 def instance_fault_create(context, values):
3820     """Create a new instance fault."""
3821     fault_ref = models.InstanceFault()
3822     fault_ref.update(values)
3823     fault_ref.save(context.session)
3824     return dict(fault_ref)
3825 
3826 
3827 @pick_context_manager_reader
3828 def instance_fault_get_by_instance_uuids(
3829     context, instance_uuids, latest=False,
3830 ):
3831     """Get all instance faults for the provided instance_uuids.
3832 
3833     :param instance_uuids: List of UUIDs of instances to grab faults for
3834     :param latest: Optional boolean indicating we should only return the latest
3835         fault for the instance
3836     """
3837     if not instance_uuids:
3838         return {}
3839 
3840     faults_tbl = models.InstanceFault.__table__
3841     # NOTE(rpodolyaka): filtering by instance_uuids is performed in both
3842     # code branches below for the sake of a better query plan. On change,
3843     # make sure to update the other one as well.
3844     query = model_query(context, models.InstanceFault,
3845                         [faults_tbl],
3846                         read_deleted='no')
3847 
3848     if latest:
3849         # NOTE(jaypipes): We join instance_faults to a derived table of the
3850         # latest faults per instance UUID. The SQL produced below looks like
3851         # this:
3852         #
3853         #  SELECT instance_faults.*
3854         #  FROM instance_faults
3855         #  JOIN (
3856         #    SELECT instance_uuid, MAX(id) AS max_id
3857         #    FROM instance_faults
3858         #    WHERE instance_uuid IN ( ... )
3859         #    AND deleted = 0
3860         #    GROUP BY instance_uuid
3861         #  ) AS latest_faults
3862         #    ON instance_faults.id = latest_faults.max_id;
3863         latest_faults = model_query(
3864             context, models.InstanceFault,
3865             [faults_tbl.c.instance_uuid,
3866              sql.func.max(faults_tbl.c.id).label('max_id')],
3867             read_deleted='no'
3868         ).filter(
3869             faults_tbl.c.instance_uuid.in_(instance_uuids)
3870         ).group_by(
3871             faults_tbl.c.instance_uuid
3872         ).subquery(name="latest_faults")
3873 
3874         query = query.join(latest_faults,
3875                            faults_tbl.c.id == latest_faults.c.max_id)
3876     else:
3877         query = query.filter(
3878             models.InstanceFault.instance_uuid.in_(instance_uuids)
3879         ).order_by(expression.desc("id"))
3880 
3881     output = {}
3882     for instance_uuid in instance_uuids:
3883         output[instance_uuid] = []
3884 
3885     for row in query:
3886         output[row.instance_uuid].append(row._asdict())
3887 
3888     return output
3889 
3890 
3891 ##################
3892 
3893 
3894 @pick_context_manager_writer
3895 def action_start(context, values):
3896     """Start an action for an instance."""
3897     convert_objects_related_datetimes(values, 'start_time', 'updated_at')
3898     action_ref = models.InstanceAction()
3899     action_ref.update(values)
3900     action_ref.save(context.session)
3901     return action_ref
3902 
3903 
3904 @pick_context_manager_writer
3905 def action_finish(context, values):
3906     """Finish an action for an instance."""
3907     convert_objects_related_datetimes(values, 'start_time', 'finish_time',
3908                                       'updated_at')
3909     query = model_query(context, models.InstanceAction).\
3910                         filter_by(instance_uuid=values['instance_uuid']).\
3911                         filter_by(request_id=values['request_id'])
3912     if query.update(values) != 1:
3913         raise exception.InstanceActionNotFound(
3914                                     request_id=values['request_id'],
3915                                     instance_uuid=values['instance_uuid'])
3916     return query.one()
3917 
3918 
3919 @pick_context_manager_reader
3920 def actions_get(context, instance_uuid, limit=None, marker=None,
3921                 filters=None):
3922     """Get all instance actions for the provided instance and filters."""
3923     if limit == 0:
3924         return []
3925 
3926     sort_keys = ['created_at', 'id']
3927     sort_dirs = ['desc', 'desc']
3928 
3929     query_prefix = model_query(context, models.InstanceAction).\
3930         filter_by(instance_uuid=instance_uuid)
3931 
3932     model_object = models.InstanceAction
3933     query_prefix = _get_query_nova_resource_by_changes_time(query_prefix,
3934                                                             filters,
3935                                                             model_object)
3936 
3937     if marker is not None:
3938         marker = action_get_by_request_id(context, instance_uuid, marker)
3939         if not marker:
3940             raise exception.MarkerNotFound(marker=marker)
3941     actions = sqlalchemyutils.paginate_query(query_prefix,
3942                                              models.InstanceAction, limit,
3943                                              sort_keys, marker=marker,
3944                                              sort_dirs=sort_dirs).all()
3945     return actions
3946 
3947 
3948 @pick_context_manager_reader
3949 def action_get_by_request_id(context, instance_uuid, request_id):
3950     """Get the action by request_id and given instance."""
3951     action = _action_get_by_request_id(context, instance_uuid, request_id)
3952     return action
3953 
3954 
3955 def _action_get_by_request_id(context, instance_uuid, request_id):
3956     result = model_query(context, models.InstanceAction).\
3957         filter_by(instance_uuid=instance_uuid).\
3958         filter_by(request_id=request_id).\
3959         order_by(expression.desc("created_at"), expression.desc("id")).\
3960         first()
3961     return result
3962 
3963 
3964 def _action_get_last_created_by_instance_uuid(context, instance_uuid):
3965     result = model_query(context, models.InstanceAction).\
3966         filter_by(instance_uuid=instance_uuid).\
3967         order_by(expression.desc("created_at"), expression.desc("id")).\
3968         first()
3969     return result
3970 
3971 
3972 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
3973 @pick_context_manager_writer
3974 def action_event_start(context, values):
3975     """Start an event on an instance action."""
3976     convert_objects_related_datetimes(values, 'start_time')
3977     action = _action_get_by_request_id(context, values['instance_uuid'],
3978                                        values['request_id'])
3979     # When nova-compute restarts, the context is generated again in
3980     # init_host workflow, the request_id was different with the request_id
3981     # recorded in InstanceAction, so we can't get the original record
3982     # according to request_id. Try to get the last created action so that
3983     # init_instance can continue to finish the recovery action, like:
3984     # powering_off, unpausing, and so on.
3985     update_action = True
3986     if not action and not context.project_id:
3987         action = _action_get_last_created_by_instance_uuid(
3988             context, values['instance_uuid'])
3989         # If we couldn't find an action by the request_id, we don't want to
3990         # update this action since it likely represents an inactive action.
3991         update_action = False
3992 
3993     if not action:
3994         raise exception.InstanceActionNotFound(
3995                                     request_id=values['request_id'],
3996                                     instance_uuid=values['instance_uuid'])
3997 
3998     values['action_id'] = action['id']
3999 
4000     event_ref = models.InstanceActionEvent()
4001     event_ref.update(values)
4002     context.session.add(event_ref)
4003 
4004     # Update action updated_at.
4005     if update_action:
4006         action.update({'updated_at': values['start_time']})
4007         action.save(context.session)
4008 
4009     return event_ref
4010 
4011 
4012 # NOTE: We need the retry_on_deadlock decorator for cases like resize where
4013 # a lot of events are happening at once between multiple hosts trying to
4014 # update the same action record in a small time window.
4015 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
4016 @pick_context_manager_writer
4017 def action_event_finish(context, values):
4018     """Finish an event on an instance action."""
4019     convert_objects_related_datetimes(values, 'start_time', 'finish_time')
4020     action = _action_get_by_request_id(context, values['instance_uuid'],
4021                                        values['request_id'])
4022     # When nova-compute restarts, the context is generated again in
4023     # init_host workflow, the request_id was different with the request_id
4024     # recorded in InstanceAction, so we can't get the original record
4025     # according to request_id. Try to get the last created action so that
4026     # init_instance can continue to finish the recovery action, like:
4027     # powering_off, unpausing, and so on.
4028     update_action = True
4029     if not action and not context.project_id:
4030         action = _action_get_last_created_by_instance_uuid(
4031             context, values['instance_uuid'])
4032         # If we couldn't find an action by the request_id, we don't want to
4033         # update this action since it likely represents an inactive action.
4034         update_action = False
4035 
4036     if not action:
4037         raise exception.InstanceActionNotFound(
4038                                     request_id=values['request_id'],
4039                                     instance_uuid=values['instance_uuid'])
4040 
4041     event_ref = model_query(context, models.InstanceActionEvent).\
4042                             filter_by(action_id=action['id']).\
4043                             filter_by(event=values['event']).\
4044                             first()
4045 
4046     if not event_ref:
4047         raise exception.InstanceActionEventNotFound(action_id=action['id'],
4048                                                     event=values['event'])
4049     event_ref.update(values)
4050 
4051     if values['result'].lower() == 'error':
4052         action.update({'message': 'Error'})
4053 
4054     # Update action updated_at.
4055     if update_action:
4056         action.update({'updated_at': values['finish_time']})
4057         action.save(context.session)
4058 
4059     return event_ref
4060 
4061 
4062 @pick_context_manager_reader
4063 def action_events_get(context, action_id):
4064     """Get the events by action id."""
4065     events = model_query(context, models.InstanceActionEvent).\
4066         filter_by(action_id=action_id).\
4067         order_by(expression.desc("created_at"), expression.desc("id")).\
4068         all()
4069 
4070     return events
4071 
4072 
4073 @pick_context_manager_reader
4074 def action_event_get_by_id(context, action_id, event_id):
4075     event = model_query(context, models.InstanceActionEvent).\
4076                         filter_by(action_id=action_id).\
4077                         filter_by(id=event_id).\
4078                         first()
4079 
4080     return event
4081 
4082 
4083 ##################
4084 
4085 
4086 @require_context
4087 @pick_context_manager_writer
4088 def ec2_instance_create(context, instance_uuid, id=None):
4089     """Create the EC2 ID to instance UUID mapping on demand."""
4090     ec2_instance_ref = models.InstanceIdMapping()
4091     ec2_instance_ref.update({'uuid': instance_uuid})
4092     if id is not None:
4093         ec2_instance_ref.update({'id': id})
4094 
4095     ec2_instance_ref.save(context.session)
4096 
4097     return ec2_instance_ref
4098 
4099 
4100 @require_context
4101 @pick_context_manager_reader
4102 def ec2_instance_get_by_uuid(context, instance_uuid):
4103     """Get UUID through EC2 ID from instance_id_mappings table."""
4104     result = _ec2_instance_get_query(context).\
4105                     filter_by(uuid=instance_uuid).\
4106                     first()
4107 
4108     if not result:
4109         raise exception.InstanceNotFound(instance_id=instance_uuid)
4110 
4111     return result
4112 
4113 
4114 @require_context
4115 @pick_context_manager_reader
4116 def ec2_instance_get_by_id(context, instance_id):
4117     result = _ec2_instance_get_query(context).\
4118                     filter_by(id=instance_id).\
4119                     first()
4120 
4121     if not result:
4122         raise exception.InstanceNotFound(instance_id=instance_id)
4123 
4124     return result
4125 
4126 
4127 @require_context
4128 @pick_context_manager_reader
4129 def get_instance_uuid_by_ec2_id(context, ec2_id):
4130     """Get UUID through EC2 ID from instance_id_mappings table."""
4131     result = ec2_instance_get_by_id(context, ec2_id)
4132     return result['uuid']
4133 
4134 
4135 def _ec2_instance_get_query(context):
4136     return model_query(context, models.InstanceIdMapping, read_deleted='yes')
4137 
4138 
4139 ##################
4140 
4141 
4142 def _task_log_get_query(context, task_name, period_beginning,
4143                         period_ending, host=None, state=None):
4144     values = {'period_beginning': period_beginning,
4145               'period_ending': period_ending}
4146     values = convert_objects_related_datetimes(values, *values.keys())
4147 
4148     query = model_query(context, models.TaskLog).\
4149                      filter_by(task_name=task_name).\
4150                      filter_by(period_beginning=values['period_beginning']).\
4151                      filter_by(period_ending=values['period_ending'])
4152     if host is not None:
4153         query = query.filter_by(host=host)
4154     if state is not None:
4155         query = query.filter_by(state=state)
4156     return query
4157 
4158 
4159 @pick_context_manager_reader
4160 def task_log_get(context, task_name, period_beginning, period_ending, host,
4161                  state=None):
4162     return _task_log_get_query(context, task_name, period_beginning,
4163                                period_ending, host, state).first()
4164 
4165 
4166 @pick_context_manager_reader
4167 def task_log_get_all(context, task_name, period_beginning, period_ending,
4168                      host=None, state=None):
4169     return _task_log_get_query(context, task_name, period_beginning,
4170                                period_ending, host, state).all()
4171 
4172 
4173 @pick_context_manager_writer
4174 def task_log_begin_task(
4175     context, task_name, period_beginning, period_ending, host, task_items=None,
4176     message=None,
4177 ):
4178     """Mark a task as started for a given host/time period."""
4179     values = {'period_beginning': period_beginning,
4180               'period_ending': period_ending}
4181     values = convert_objects_related_datetimes(values, *values.keys())
4182 
4183     task = models.TaskLog()
4184     task.task_name = task_name
4185     task.period_beginning = values['period_beginning']
4186     task.period_ending = values['period_ending']
4187     task.host = host
4188     task.state = "RUNNING"
4189     if message:
4190         task.message = message
4191     if task_items:
4192         task.task_items = task_items
4193     try:
4194         task.save(context.session)
4195     except db_exc.DBDuplicateEntry:
4196         raise exception.TaskAlreadyRunning(task_name=task_name, host=host)
4197 
4198 
4199 @pick_context_manager_writer
4200 def task_log_end_task(
4201     context, task_name, period_beginning, period_ending, host, errors,
4202     message=None,
4203 ):
4204     """Mark a task as complete for a given host/time period."""
4205     values = dict(state="DONE", errors=errors)
4206     if message:
4207         values["message"] = message
4208 
4209     rows = _task_log_get_query(context, task_name, period_beginning,
4210                                period_ending, host).update(values)
4211     if rows == 0:
4212         # It's not running!
4213         raise exception.TaskNotRunning(task_name=task_name, host=host)
4214 
4215 
4216 ##################
4217 
4218 
4219 def _get_tables_with_fk_to_table(table):
4220     """Get a list of tables that refer to the given table by foreign key (FK).
4221 
4222     :param table: Table object (parent) for which to find references by FK
4223 
4224     :returns: A list of Table objects that refer to the specified table by FK
4225     """
4226     tables = []
4227     for t in models.BASE.metadata.tables.values():
4228         for fk in t.foreign_keys:
4229             if fk.references(table):
4230                 tables.append(t)
4231     return tables
4232 
4233 
4234 def _get_fk_stmts(metadata, conn, table, column, records):
4235     """Find records related to this table by foreign key (FK) and create and
4236     return insert/delete statements for them.
4237 
4238     Logic is: find the tables that reference the table passed to this method
4239     and walk the tree of references by FK. As child records are found, prepend
4240     them to deques to execute later in a single database transaction (to avoid
4241     orphaning related records if any one insert/delete fails or the archive
4242     process is otherwise interrupted).
4243 
4244     :param metadata: Metadata object to use to construct a shadow Table object
4245     :param conn: Connection object to use to select records related by FK
4246     :param table: Table object (parent) for which to find references by FK
4247     :param column: Column object (parent) to use to select records related by
4248         FK
4249     :param records: A list of records (column values) to use to select records
4250         related by FK
4251 
4252     :returns: tuple of (insert statements, delete statements) for records
4253         related by FK to insert into shadow tables and delete from main tables
4254     """
4255     inserts = collections.deque()
4256     deletes = collections.deque()
4257     fk_tables = _get_tables_with_fk_to_table(table)
4258     for fk_table in fk_tables:
4259         # Create the shadow table for the referencing table.
4260         fk_shadow_tablename = _SHADOW_TABLE_PREFIX + fk_table.name
4261         try:
4262             fk_shadow_table = schema.Table(
4263                 fk_shadow_tablename, metadata, autoload_with=conn)
4264         except sqla_exc.NoSuchTableError:
4265             # No corresponding shadow table; skip it.
4266             continue
4267 
4268         # TODO(stephenfin): Drop this when we drop the table
4269         if fk_table.name == "dns_domains":
4270             # We have one table (dns_domains) where the key is called
4271             # "domain" rather than "id"
4272             fk_column = fk_table.c.domain
4273         else:
4274             fk_column = fk_table.c.id
4275 
4276         for fk in fk_table.foreign_keys:
4277             # We need to find the records in the referring (child) table that
4278             # correspond to the records in our (parent) table so we can archive
4279             # them.
4280 
4281             # First, select the column in the parent referenced by the child
4282             # table that corresponds to the parent table records that were
4283             # passed in.
4284             # Example: table = 'instances' and fk_table = 'instance_extra'
4285             #          fk.parent = instance_extra.instance_uuid
4286             #          fk.column = instances.uuid
4287             #          SELECT instances.uuid FROM instances, instance_extra
4288             #              WHERE instance_extra.instance_uuid = instances.uuid
4289             #              AND instance.id IN (<ids>)
4290             #          We need the instance uuids for the <ids> in order to
4291             #          look up the matching instance_extra records.
4292             select = sql.select(fk.column).where(
4293                 sql.and_(fk.parent == fk.column, column.in_(records))
4294             )
4295             with conn.begin():
4296                 rows = conn.execute(select).fetchall()
4297             p_records = [r[0] for r in rows]
4298             # Then, select rows in the child table that correspond to the
4299             # parent table records that were passed in.
4300             # Example: table = 'instances' and fk_table = 'instance_extra'
4301             #          fk.parent = instance_extra.instance_uuid
4302             #          fk.column = instances.uuid
4303             #          SELECT instance_extra.id FROM instance_extra, instances
4304             #              WHERE instance_extra.instance_uuid = instances.uuid
4305             #              AND instances.uuid IN (<uuids>)
4306             #          We will get the instance_extra ids we need to archive
4307             #          them.
4308             fk_select = sql.select(fk_column).where(
4309                 sql.and_(fk.parent == fk.column, fk.column.in_(p_records))
4310             )
4311             with conn.begin():
4312                 fk_rows = conn.execute(fk_select).fetchall()
4313             fk_records = [r[0] for r in fk_rows]
4314             if fk_records:
4315                 # If we found any records in the child table, create shadow
4316                 # table insert statements for them and prepend them to the
4317                 # deque.
4318                 fk_columns = [c.name for c in fk_table.c]
4319                 fk_insert = fk_shadow_table.insert().from_select(
4320                     fk_columns,
4321                     sql.select(fk_table).where(fk_column.in_(fk_records))
4322                 ).inline()
4323                 inserts.appendleft(fk_insert)
4324                 # Create main table delete statements and prepend them to the
4325                 # deque.
4326                 fk_delete = fk_table.delete().where(fk_column.in_(fk_records))
4327                 deletes.appendleft(fk_delete)
4328         # Repeat for any possible nested child tables.
4329         i, d = _get_fk_stmts(metadata, conn, fk_table, fk_column, fk_records)
4330         inserts.extendleft(i)
4331         deletes.extendleft(d)
4332 
4333     return inserts, deletes
4334 
4335 
4336 def _archive_deleted_rows_for_table(
4337     metadata, engine, tablename, max_rows, before, task_log,
4338 ):
4339     """Move up to max_rows rows from one tables to the corresponding
4340     shadow table.
4341 
4342     Will also follow FK constraints and archive all referring rows.
4343     Example: archving a record from the 'instances' table will also archive
4344     the 'instance_extra' record before archiving the 'instances' record.
4345 
4346     :returns: 3-item tuple:
4347 
4348         - number of rows archived
4349         - list of UUIDs of instances that were archived
4350         - number of extra rows archived (due to FK constraints)
4351           dict of {tablename: rows_archived}
4352     """
4353     conn = engine.connect()
4354     # NOTE(tdurakov): table metadata should be received
4355     # from models, not db tables. Default value specified by SoftDeleteMixin
4356     # is known only by models, not DB layer.
4357     # IMPORTANT: please do not change source of metadata information for table.
4358     table = models.BASE.metadata.tables[tablename]
4359 
4360     shadow_tablename = _SHADOW_TABLE_PREFIX + tablename
4361     rows_archived = 0
4362     deleted_instance_uuids = []
4363     try:
4364         shadow_table = schema.Table(
4365             shadow_tablename, metadata, autoload_with=conn)
4366     except sqla_exc.NoSuchTableError:
4367         # No corresponding shadow table; skip it.
4368         return rows_archived, deleted_instance_uuids, {}
4369 
4370     # TODO(stephenfin): Drop this when we drop the table
4371     if tablename == "dns_domains":
4372         # We have one table (dns_domains) where the key is called
4373         # "domain" rather than "id"
4374         column = table.c.domain
4375     else:
4376         column = table.c.id
4377 
4378     deleted_column = table.c.deleted
4379     columns = [c.name for c in table.c]
4380 
4381     select = sql.select(column).where(
4382         deleted_column != deleted_column.default.arg
4383     )
4384 
4385     if tablename == "task_log" and task_log:
4386         # task_log table records are never deleted by anything, so we won't
4387         # base our select statement on the 'deleted' column status.
4388         select = sql.select(column)
4389 
4390     if before:
4391         if tablename != "task_log":
4392             select = select.where(table.c.deleted_at < before)
4393         elif task_log:
4394             # task_log table records are never deleted by anything, so we won't
4395             # base our select statement on the 'deleted_at' column status.
4396             select = select.where(table.c.updated_at < before)
4397 
4398     select = select.order_by(column).limit(max_rows)
4399     with conn.begin():
4400         rows = conn.execute(select).fetchall()
4401     records = [r[0] for r in rows]
4402 
4403     # We will archive deleted rows for this table and also generate insert and
4404     # delete statements for extra rows we may archive by following FK
4405     # relationships. Because we are iterating over the sorted_tables (list of
4406     # Table objects sorted in order of foreign key dependency), new inserts and
4407     # deletes ("leaves") will be added to the fronts of the deques created in
4408     # _get_fk_stmts. This way, we make sure we delete child table records
4409     # before we delete their parent table records.
4410 
4411     # Keep track of any extra tablenames to number of rows that we archive by
4412     # following FK relationships.
4413     # {tablename: extra_rows_archived}
4414     extras = collections.defaultdict(int)
4415     if records:
4416         insert = shadow_table.insert().from_select(
4417             columns, sql.select(table).where(column.in_(records))
4418         ).inline()
4419         delete = table.delete().where(column.in_(records))
4420         # Walk FK relationships and add insert/delete statements for rows that
4421         # refer to this table via FK constraints. fk_inserts and fk_deletes
4422         # will be prepended to by _get_fk_stmts if referring rows are found by
4423         # FK constraints.
4424         fk_inserts, fk_deletes = _get_fk_stmts(
4425             metadata, conn, table, column, records)
4426 
4427         # NOTE(tssurya): In order to facilitate the deletion of records from
4428         # instance_mappings, request_specs and instance_group_member tables in
4429         # the nova_api DB, the rows of deleted instances from the instances
4430         # table are stored prior to their deletion. Basically the uuids of the
4431         # archived instances are queried and returned.
4432         if tablename == "instances":
4433             query_select = sql.select(table.c.uuid).where(
4434                 table.c.id.in_(records)
4435             )
4436             with conn.begin():
4437                 rows = conn.execute(query_select).fetchall()
4438             deleted_instance_uuids = [r[0] for r in rows]
4439 
4440         try:
4441             # Group the insert and delete in a transaction.
4442             with conn.begin():
4443                 for fk_insert in fk_inserts:
4444                     conn.execute(fk_insert)
4445                 for fk_delete in fk_deletes:
4446                     result_fk_delete = conn.execute(fk_delete)
4447                     extras[fk_delete.table.name] += result_fk_delete.rowcount
4448                 conn.execute(insert)
4449                 result_delete = conn.execute(delete)
4450             rows_archived += result_delete.rowcount
4451         except db_exc.DBReferenceError as ex:
4452             # A foreign key constraint keeps us from deleting some of
4453             # these rows until we clean up a dependent table.  Just
4454             # skip this table for now; we'll come back to it later.
4455             LOG.warning("IntegrityError detected when archiving table "
4456                         "%(tablename)s: %(error)s",
4457                         {'tablename': tablename, 'error': str(ex)})
4458 
4459     conn.close()
4460 
4461     return rows_archived, deleted_instance_uuids, extras
4462 
4463 
4464 def archive_deleted_rows(context=None, max_rows=None, before=None,
4465                          task_log=False):
4466     """Move up to max_rows rows from production tables to the corresponding
4467     shadow tables.
4468 
4469     :param context: nova.context.RequestContext for database access
4470     :param max_rows: Maximum number of rows to archive (required)
4471     :param before: optional datetime which when specified filters the records
4472         to only archive those records deleted before the given date
4473     :param task_log: Optional for whether to archive task_log table records
4474     :returns: 3-item tuple:
4475 
4476         - dict that maps table name to number of rows archived from that table,
4477           for example::
4478 
4479             {
4480                 'instances': 5,
4481                 'block_device_mapping': 5,
4482                 'pci_devices': 2,
4483             }
4484         - list of UUIDs of instances that were archived
4485         - total number of rows that were archived
4486     """
4487     table_to_rows_archived = collections.defaultdict(int)
4488     deleted_instance_uuids = []
4489     total_rows_archived = 0
4490     meta = sa.MetaData()
4491     engine = get_engine(use_slave=True, context=context)
4492     meta.reflect(bind=engine)
4493     # Get the sorted list of tables in order of foreign key dependency.
4494     # Process the parent tables and find their dependent records in order to
4495     # archive the related records in a single database transactions. The goal
4496     # is to avoid a situation where, for example, an 'instances' table record
4497     # is missing its corresponding 'instance_extra' record due to running the
4498     # archive_deleted_rows command with max_rows.
4499     for table in meta.sorted_tables:
4500         tablename = table.name
4501         rows_archived = 0
4502         # skip the special sqlalchemy-migrate migrate_version table and any
4503         # shadow tables
4504         # TODO(stephenfin): Drop 'migrate_version' once we remove support for
4505         # the legacy sqlalchemy-migrate migrations
4506         if (
4507             tablename in ('migrate_version', 'alembic_version') or
4508             tablename.startswith(_SHADOW_TABLE_PREFIX)
4509         ):
4510             continue
4511 
4512         # skip the tables that we've since removed the models for
4513         if tablename in models.REMOVED_TABLES:
4514             continue
4515 
4516         rows_archived, _deleted_instance_uuids, extras = (
4517             _archive_deleted_rows_for_table(
4518                 meta, engine, tablename,
4519                 max_rows=max_rows - total_rows_archived,
4520                 before=before,
4521                 task_log=task_log))
4522         total_rows_archived += rows_archived
4523         if tablename == 'instances':
4524             deleted_instance_uuids = _deleted_instance_uuids
4525         # Only report results for tables that had updates.
4526         if rows_archived:
4527             table_to_rows_archived[tablename] = rows_archived
4528             for tablename, extra_rows_archived in extras.items():
4529                 table_to_rows_archived[tablename] += extra_rows_archived
4530                 total_rows_archived += extra_rows_archived
4531         if total_rows_archived >= max_rows:
4532             break
4533     return table_to_rows_archived, deleted_instance_uuids, total_rows_archived
4534 
4535 
4536 def _purgeable_tables(metadata):
4537     return [t for t in metadata.sorted_tables
4538             if (t.name.startswith(_SHADOW_TABLE_PREFIX) and not
4539                 t.name.endswith('migrate_version'))]
4540 
4541 
4542 def purge_shadow_tables(context, before_date, status_fn=None):
4543     engine = get_engine(context=context)
4544     conn = engine.connect()
4545     metadata = sa.MetaData()
4546     metadata.reflect(bind=engine)
4547     total_deleted = 0
4548 
4549     if status_fn is None:
4550         status_fn = lambda m: None
4551 
4552     # Some things never get formally deleted, and thus deleted_at
4553     # is never set. So, prefer specific timestamp columns here
4554     # for those special cases.
4555     overrides = {
4556         'shadow_instance_actions': 'created_at',
4557         'shadow_instance_actions_events': 'created_at',
4558         'shadow_task_log': 'updated_at',
4559     }
4560 
4561     for table in _purgeable_tables(metadata):
4562         if before_date is None:
4563             col = None
4564         elif table.name in overrides:
4565             col = getattr(table.c, overrides[table.name])
4566         elif hasattr(table.c, 'deleted_at'):
4567             col = table.c.deleted_at
4568         elif hasattr(table.c, 'updated_at'):
4569             col = table.c.updated_at
4570         elif hasattr(table.c, 'created_at'):
4571             col = table.c.created_at
4572         else:
4573             status_fn(_('Unable to purge table %(table)s because it '
4574                         'has no timestamp column') % {
4575                             'table': table.name})
4576             continue
4577 
4578         if col is not None:
4579             delete = table.delete().where(col < before_date)
4580         else:
4581             delete = table.delete()
4582 
4583         with conn.begin():
4584             deleted = conn.execute(delete)
4585         if deleted.rowcount > 0:
4586             status_fn(_('Deleted %(rows)i rows from %(table)s based on '
4587                         'timestamp column %(col)s') % {
4588                             'rows': deleted.rowcount,
4589                             'table': table.name,
4590                             'col': col is None and '(n/a)' or col.name})
4591         total_deleted += deleted.rowcount
4592 
4593     conn.close()
4594 
4595     return total_deleted
4596 
4597 
4598 ####################
4599 
4600 
4601 @pick_context_manager_reader
4602 def pci_device_get_by_addr(context, node_id, dev_addr):
4603     """Get PCI device by address."""
4604     pci_dev_ref = model_query(context, models.PciDevice).\
4605                         filter_by(compute_node_id=node_id).\
4606                         filter_by(address=dev_addr).\
4607                         first()
4608     if not pci_dev_ref:
4609         raise exception.PciDeviceNotFound(node_id=node_id, address=dev_addr)
4610     return pci_dev_ref
4611 
4612 
4613 @pick_context_manager_reader
4614 def pci_device_get_by_id(context, id):
4615     """Get PCI device by id."""
4616     pci_dev_ref = model_query(context, models.PciDevice).\
4617                         filter_by(id=id).\
4618                         first()
4619     if not pci_dev_ref:
4620         raise exception.PciDeviceNotFoundById(id=id)
4621     return pci_dev_ref
4622 
4623 
4624 @pick_context_manager_reader
4625 def pci_device_get_all_by_node(context, node_id):
4626     """Get all PCI devices for one host."""
4627     return model_query(context, models.PciDevice).\
4628                        filter_by(compute_node_id=node_id).\
4629                        all()
4630 
4631 
4632 @pick_context_manager_reader
4633 def pci_device_get_all_by_parent_addr(context, node_id, parent_addr):
4634     """Get all PCI devices by parent address."""
4635     return model_query(context, models.PciDevice).\
4636                        filter_by(compute_node_id=node_id).\
4637                        filter_by(parent_addr=parent_addr).\
4638                        all()
4639 
4640 
4641 @require_context
4642 @pick_context_manager_reader
4643 def pci_device_get_all_by_instance_uuid(context, instance_uuid):
4644     """Get PCI devices allocated to instance."""
4645     return model_query(context, models.PciDevice).\
4646                        filter_by(status='allocated').\
4647                        filter_by(instance_uuid=instance_uuid).\
4648                        all()
4649 
4650 
4651 @pick_context_manager_reader
4652 def _instance_pcidevs_get_multi(context, instance_uuids):
4653     if not instance_uuids:
4654         return []
4655     return model_query(context, models.PciDevice).\
4656         filter_by(status='allocated').\
4657         filter(models.PciDevice.instance_uuid.in_(instance_uuids))
4658 
4659 
4660 @pick_context_manager_writer
4661 def pci_device_destroy(context, node_id, address):
4662     """Delete a PCI device record."""
4663     result = model_query(context, models.PciDevice).\
4664                          filter_by(compute_node_id=node_id).\
4665                          filter_by(address=address).\
4666                          soft_delete()
4667     if not result:
4668         raise exception.PciDeviceNotFound(node_id=node_id, address=address)
4669 
4670 
4671 @pick_context_manager_writer
4672 def pci_device_update(context, node_id, address, values):
4673     """Update a pci device."""
4674     query = model_query(context, models.PciDevice, read_deleted="no").\
4675                     filter_by(compute_node_id=node_id).\
4676                     filter_by(address=address)
4677     if query.update(values) == 0:
4678         device = models.PciDevice()
4679         device.update(values)
4680         context.session.add(device)
4681     return query.one()
4682 
4683 
4684 ####################
4685 
4686 
4687 @pick_context_manager_writer
4688 def instance_tag_add(context, instance_uuid, tag):
4689     """Add tag to the instance."""
4690     tag_ref = models.Tag()
4691     tag_ref.resource_id = instance_uuid
4692     tag_ref.tag = tag
4693 
4694     try:
4695         _check_instance_exists_in_project(context, instance_uuid)
4696         with get_context_manager(context).writer.savepoint.using(context):
4697             context.session.add(tag_ref)
4698     except db_exc.DBDuplicateEntry:
4699         # NOTE(snikitin): We should ignore tags duplicates
4700         pass
4701 
4702     return tag_ref
4703 
4704 
4705 @pick_context_manager_writer
4706 def instance_tag_set(context, instance_uuid, tags):
4707     """Replace all of the instance tags with specified list of tags."""
4708     _check_instance_exists_in_project(context, instance_uuid)
4709 
4710     existing = context.session.query(models.Tag.tag).filter_by(
4711         resource_id=instance_uuid).all()
4712 
4713     existing = set(row.tag for row in existing)
4714     tags = set(tags)
4715     to_delete = existing - tags
4716     to_add = tags - existing
4717 
4718     if to_delete:
4719         context.session.query(models.Tag).filter_by(
4720             resource_id=instance_uuid).filter(
4721             models.Tag.tag.in_(to_delete)).delete(
4722             synchronize_session=False)
4723 
4724     if to_add:
4725         data = [
4726             {'resource_id': instance_uuid, 'tag': tag} for tag in to_add]
4727         context.session.execute(models.Tag.__table__.insert(None), data)
4728 
4729     return context.session.query(models.Tag).filter_by(
4730         resource_id=instance_uuid).all()
4731 
4732 
4733 @pick_context_manager_reader
4734 def instance_tag_get_by_instance_uuid(context, instance_uuid):
4735     """Get all tags for a given instance."""
4736     _check_instance_exists_in_project(context, instance_uuid)
4737     return context.session.query(models.Tag).filter_by(
4738         resource_id=instance_uuid).all()
4739 
4740 
4741 @pick_context_manager_writer
4742 def instance_tag_delete(context, instance_uuid, tag):
4743     """Delete specified tag from the instance."""
4744     _check_instance_exists_in_project(context, instance_uuid)
4745     result = context.session.query(models.Tag).filter_by(
4746         resource_id=instance_uuid, tag=tag).delete()
4747 
4748     if not result:
4749         raise exception.InstanceTagNotFound(instance_id=instance_uuid,
4750                                             tag=tag)
4751 
4752 
4753 @pick_context_manager_writer
4754 def instance_tag_delete_all(context, instance_uuid):
4755     """Delete all tags from the instance."""
4756     _check_instance_exists_in_project(context, instance_uuid)
4757     context.session.query(models.Tag).filter_by(
4758         resource_id=instance_uuid).delete()
4759 
4760 
4761 @pick_context_manager_reader
4762 def instance_tag_exists(context, instance_uuid, tag):
4763     """Check if specified tag exist on the instance."""
4764     _check_instance_exists_in_project(context, instance_uuid)
4765     q = context.session.query(models.Tag).filter_by(
4766         resource_id=instance_uuid, tag=tag)
4767     return context.session.query(q.exists()).scalar()
4768 
4769 
4770 ####################
4771 
4772 
4773 @pick_context_manager_writer
4774 def console_auth_token_create(context, values):
4775     """Create a console authorization."""
4776     instance_uuid = values.get('instance_uuid')
4777     _check_instance_exists_in_project(context, instance_uuid)
4778     token_ref = models.ConsoleAuthToken()
4779     token_ref.update(values)
4780     context.session.add(token_ref)
4781     return token_ref
4782 
4783 
4784 @pick_context_manager_reader
4785 def console_auth_token_get_valid(context, token_hash, instance_uuid=None):
4786     """Get a valid console authorization by token_hash and instance_uuid.
4787 
4788     The console authorizations expire at the time specified by their
4789     'expires' column. An expired console auth token will not be returned
4790     to the caller - it is treated as if it does not exist.
4791 
4792     If instance_uuid is specified, the token is validated against both
4793     expiry and instance_uuid.
4794 
4795     If instance_uuid is not specified, the token is validated against
4796     expiry only.
4797     """
4798     if instance_uuid is not None:
4799         _check_instance_exists_in_project(context, instance_uuid)
4800     query = context.session.query(models.ConsoleAuthToken).\
4801         filter_by(token_hash=token_hash)
4802     if instance_uuid is not None:
4803         query = query.filter_by(instance_uuid=instance_uuid)
4804     return query.filter(
4805         models.ConsoleAuthToken.expires > timeutils.utcnow_ts()).first()
4806 
4807 
4808 @pick_context_manager_writer
4809 def console_auth_token_destroy_all_by_instance(context, instance_uuid):
4810     """Delete all console authorizations belonging to the instance."""
4811     context.session.query(models.ConsoleAuthToken).\
4812         filter_by(instance_uuid=instance_uuid).delete()
4813 
4814 
4815 @pick_context_manager_writer
4816 def console_auth_token_destroy_expired(context):
4817     """Delete expired console authorizations.
4818 
4819     The console authorizations expire at the time specified by their
4820     'expires' column. This function is used to garbage collect expired tokens.
4821     """
4822     context.session.query(models.ConsoleAuthToken).\
4823         filter(models.ConsoleAuthToken.expires <= timeutils.utcnow_ts()).\
4824         delete()
4825 
4826 
4827 @pick_context_manager_writer
4828 def console_auth_token_destroy_expired_by_host(context, host):
4829     """Delete expired console authorizations belonging to the host.
4830 
4831     The console authorizations expire at the time specified by their
4832     'expires' column. This function is used to garbage collect expired
4833     tokens associated with the given host.
4834     """
4835     context.session.query(models.ConsoleAuthToken).\
4836         filter_by(host=host).\
4837         filter(models.ConsoleAuthToken.expires <= timeutils.utcnow_ts()).\
4838         delete()
