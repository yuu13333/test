Please review the code below for security defects using the CWE (Common Weakness Enumeration) as a reference standard. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are detected, state: 'No security defects are detected in the code'.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 # If py2, concurrent.futures comes from the futures library otherwise it
31 # comes from the py3 standard library.
32 from concurrent import futures
33 import contextlib
34 import functools
35 import inspect
36 import sys
37 import time
38 import traceback
39 
40 from cinderclient import exceptions as cinder_exception
41 from cursive import exception as cursive_exception
42 import eventlet.event
43 from eventlet import greenthread
44 import eventlet.semaphore
45 import eventlet.timeout
46 from keystoneauth1 import exceptions as keystone_exception
47 from oslo_log import log as logging
48 import oslo_messaging as messaging
49 from oslo_serialization import jsonutils
50 from oslo_service import loopingcall
51 from oslo_service import periodic_task
52 from oslo_utils import excutils
53 from oslo_utils import strutils
54 from oslo_utils import timeutils
55 import six
56 from six.moves import range
57 
58 from nova import block_device
59 from nova.cells import rpcapi as cells_rpcapi
60 from nova import compute
61 from nova.compute import build_results
62 from nova.compute import claims
63 from nova.compute import power_state
64 from nova.compute import resource_tracker
65 from nova.compute import rpcapi as compute_rpcapi
66 from nova.compute import task_states
67 from nova.compute import utils as compute_utils
68 from nova.compute.utils import wrap_instance_event
69 from nova.compute import vm_states
70 from nova import conductor
71 import nova.conf
72 from nova.console import rpcapi as console_rpcapi
73 import nova.context
74 from nova import exception
75 from nova import exception_wrapper
76 from nova import hooks
77 from nova.i18n import _
78 from nova import image
79 from nova import manager
80 from nova import network
81 from nova.network import base_api as base_net_api
82 from nova.network import model as network_model
83 from nova.network.security_group import openstack_driver
84 from nova import objects
85 from nova.objects import base as obj_base
86 from nova.objects import fields
87 from nova.objects import instance as obj_instance
88 from nova.objects import migrate_data as migrate_data_obj
89 from nova.pci import whitelist
90 from nova import rpc
91 from nova import safe_utils
92 from nova.scheduler import client as scheduler_client
93 from nova.scheduler import utils as scheduler_utils
94 from nova import utils
95 from nova.virt import block_device as driver_block_device
96 from nova.virt import configdrive
97 from nova.virt import driver
98 from nova.virt import event as virtevent
99 from nova.virt import storage_users
100 from nova.virt import virtapi
101 from nova.volume import cinder
102 
103 CONF = nova.conf.CONF
104 
105 LOG = logging.getLogger(__name__)
106 
107 get_notifier = functools.partial(rpc.get_notifier, service='compute')
108 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
109                                    get_notifier=get_notifier,
110                                    binary='nova-compute')
111 
112 
113 @contextlib.contextmanager
114 def errors_out_migration_ctxt(migration):
115     """Context manager to error out migration on failure."""
116 
117     try:
118         yield
119     except Exception:
120         with excutils.save_and_reraise_exception():
121             if migration:
122                 # We may have been passed None for our migration if we're
123                 # receiving from an older client. The migration will be
124                 # errored via the legacy path.
125                 migration.status = 'error'
126                 try:
127                     with migration.obj_as_admin():
128                         migration.save()
129                 except Exception:
130                     LOG.debug(
131                         'Error setting migration status for instance %s.',
132                         migration.instance_uuid, exc_info=True)
133 
134 
135 @utils.expects_func_args('migration')
136 def errors_out_migration(function):
137     """Decorator to error out migration on failure."""
138 
139     @functools.wraps(function)
140     def decorated_function(self, context, *args, **kwargs):
141         wrapped_func = safe_utils.get_wrapped_function(function)
142         keyed_args = inspect.getcallargs(wrapped_func, self, context,
143                                          *args, **kwargs)
144         migration = keyed_args['migration']
145         with errors_out_migration_ctxt(migration):
146             return function(self, context, *args, **kwargs)
147 
148     return decorated_function
149 
150 
151 @utils.expects_func_args('instance')
152 def reverts_task_state(function):
153     """Decorator to revert task_state on failure."""
154 
155     @functools.wraps(function)
156     def decorated_function(self, context, *args, **kwargs):
157         try:
158             return function(self, context, *args, **kwargs)
159         except exception.UnexpectedTaskStateError as e:
160             # Note(maoy): unexpected task state means the current
161             # task is preempted. Do not clear task state in this
162             # case.
163             with excutils.save_and_reraise_exception():
164                 LOG.info("Task possibly preempted: %s",
165                          e.format_message())
166         except Exception:
167             with excutils.save_and_reraise_exception():
168                 wrapped_func = safe_utils.get_wrapped_function(function)
169                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
170                                                  *args, **kwargs)
171                 # NOTE(mriedem): 'instance' must be in keyed_args because we
172                 # have utils.expects_func_args('instance') decorating this
173                 # method.
174                 instance = keyed_args['instance']
175                 original_task_state = instance.task_state
176                 try:
177                     self._instance_update(context, instance, task_state=None)
178                     LOG.info("Successfully reverted task state from %s on "
179                              "failure for instance.",
180                              original_task_state, instance=instance)
181                 except exception.InstanceNotFound:
182                     # We might delete an instance that failed to build shortly
183                     # after it errored out this is an expected case and we
184                     # should not trace on it.
185                     pass
186                 except Exception as e:
187                     LOG.warning("Failed to revert task state for instance. "
188                                 "Error: %s", e, instance=instance)
189 
190     return decorated_function
191 
192 
193 @utils.expects_func_args('instance')
194 def wrap_instance_fault(function):
195     """Wraps a method to catch exceptions related to instances.
196 
197     This decorator wraps a method to catch any exceptions having to do with
198     an instance that may get thrown. It then logs an instance fault in the db.
199     """
200 
201     @functools.wraps(function)
202     def decorated_function(self, context, *args, **kwargs):
203         try:
204             return function(self, context, *args, **kwargs)
205         except exception.InstanceNotFound:
206             raise
207         except Exception as e:
208             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
209             # we will get a KeyError exception which will cover up the real
210             # exception. So, we update kwargs with the values from args first.
211             # then, we can get 'instance' from kwargs easily.
212             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
213 
214             with excutils.save_and_reraise_exception():
215                 compute_utils.add_instance_fault_from_exc(context,
216                         kwargs['instance'], e, sys.exc_info())
217 
218     return decorated_function
219 
220 
221 @utils.expects_func_args('image_id', 'instance')
222 def delete_image_on_error(function):
223     """Used for snapshot related method to ensure the image created in
224     compute.api is deleted when an error occurs.
225     """
226 
227     @functools.wraps(function)
228     def decorated_function(self, context, image_id, instance,
229                            *args, **kwargs):
230         try:
231             return function(self, context, image_id, instance,
232                             *args, **kwargs)
233         except Exception:
234             with excutils.save_and_reraise_exception():
235                 LOG.debug("Cleaning up image %s", image_id,
236                           exc_info=True, instance=instance)
237                 try:
238                     self.image_api.delete(context, image_id)
239                 except exception.ImageNotFound:
240                     # Since we're trying to cleanup an image, we don't care if
241                     # if it's already gone.
242                     pass
243                 except Exception:
244                     LOG.exception("Error while trying to clean up image %s",
245                                   image_id, instance=instance)
246 
247     return decorated_function
248 
249 
250 # TODO(danms): Remove me after Icehouse
251 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
252 # NOTE(mikal): if the method being decorated has more than one decorator, then
253 # put this one first. Otherwise the various exception handling decorators do
254 # not function correctly.
255 def object_compat(function):
256     """Wraps a method that expects a new-world instance
257 
258     This provides compatibility for callers passing old-style dict
259     instances.
260     """
261 
262     @functools.wraps(function)
263     def decorated_function(self, context, *args, **kwargs):
264         def _load_instance(instance_or_dict):
265             if isinstance(instance_or_dict, dict):
266                 # try to get metadata and system_metadata for most cases but
267                 # only attempt to load those if the db instance already has
268                 # those fields joined
269                 metas = [meta for meta in ('metadata', 'system_metadata')
270                          if meta in instance_or_dict]
271                 instance = objects.Instance._from_db_object(
272                     context, objects.Instance(), instance_or_dict,
273                     expected_attrs=metas)
274                 instance._context = context
275                 return instance
276             return instance_or_dict
277 
278         try:
279             kwargs['instance'] = _load_instance(kwargs['instance'])
280         except KeyError:
281             args = (_load_instance(args[0]),) + args[1:]
282 
283         migration = kwargs.get('migration')
284         if isinstance(migration, dict):
285             migration = objects.Migration._from_db_object(
286                     context.elevated(), objects.Migration(),
287                     migration)
288             kwargs['migration'] = migration
289 
290         return function(self, context, *args, **kwargs)
291 
292     return decorated_function
293 
294 
295 class InstanceEvents(object):
296     def __init__(self):
297         self._events = {}
298 
299     @staticmethod
300     def _lock_name(instance):
301         return '%s-%s' % (instance.uuid, 'events')
302 
303     def prepare_for_instance_event(self, instance, name, tag):
304         """Prepare to receive an event for an instance.
305 
306         This will register an event for the given instance that we will
307         wait on later. This should be called before initiating whatever
308         action will trigger the event. The resulting eventlet.event.Event
309         object should be wait()'d on to ensure completion.
310 
311         :param instance: the instance for which the event will be generated
312         :param name: the name of the event we're expecting
313         :param tag: the tag associated with the event we're expecting
314         :returns: an event object that should be wait()'d on
315         """
316         if self._events is None:
317             # NOTE(danms): We really should have a more specific error
318             # here, but this is what we use for our default error case
319             raise exception.NovaException('In shutdown, no new events '
320                                           'can be scheduled')
321 
322         @utils.synchronized(self._lock_name(instance))
323         def _create_or_get_event():
324             instance_events = self._events.setdefault(instance.uuid, {})
325             return instance_events.setdefault((name, tag),
326                                               eventlet.event.Event())
327         LOG.debug('Preparing to wait for external event %(name)s-%(tag)s',
328                   {'name': name, 'tag': tag}, instance=instance)
329         return _create_or_get_event()
330 
331     def pop_instance_event(self, instance, event):
332         """Remove a pending event from the wait list.
333 
334         This will remove a pending event from the wait list so that it
335         can be used to signal the waiters to wake up.
336 
337         :param instance: the instance for which the event was generated
338         :param event: the nova.objects.external_event.InstanceExternalEvent
339                       that describes the event
340         :returns: the eventlet.event.Event object on which the waiters
341                   are blocked
342         """
343         no_events_sentinel = object()
344         no_matching_event_sentinel = object()
345 
346         @utils.synchronized(self._lock_name(instance))
347         def _pop_event():
348             if self._events is None:
349                 LOG.debug('Unexpected attempt to pop events during shutdown',
350                           instance=instance)
351                 return no_events_sentinel
352             events = self._events.get(instance.uuid)
353             if not events:
354                 return no_events_sentinel
355             _event = events.pop((event.name, event.tag), None)
356             if not events:
357                 del self._events[instance.uuid]
358             if _event is None:
359                 return no_matching_event_sentinel
360             return _event
361 
362         result = _pop_event()
363         if result is no_events_sentinel:
364             LOG.debug('No waiting events found dispatching %(event)s',
365                       {'event': event.key},
366                       instance=instance)
367             return None
368         elif result is no_matching_event_sentinel:
369             LOG.debug('No event matching %(event)s in %(events)s',
370                       {'event': event.key,
371                        'events': self._events.get(instance.uuid, {}).keys()},
372                       instance=instance)
373             return None
374         else:
375             return result
376 
377     def clear_events_for_instance(self, instance):
378         """Remove all pending events for an instance.
379 
380         This will remove all events currently pending for an instance
381         and return them (indexed by event name).
382 
383         :param instance: the instance for which events should be purged
384         :returns: a dictionary of {event_name: eventlet.event.Event}
385         """
386         @utils.synchronized(self._lock_name(instance))
387         def _clear_events():
388             if self._events is None:
389                 LOG.debug('Unexpected attempt to clear events during shutdown',
390                           instance=instance)
391                 return dict()
392             # NOTE(danms): We have historically returned the raw internal
393             # format here, which is {event.key: [events, ...])} so just
394             # trivially convert it here.
395             return {'%s-%s' % k: e
396                     for k, e in self._events.pop(instance.uuid, {}).items()}
397         return _clear_events()
398 
399     def cancel_all_events(self):
400         if self._events is None:
401             LOG.debug('Unexpected attempt to cancel events during shutdown.')
402             return
403         our_events = self._events
404         # NOTE(danms): Block new events
405         self._events = None
406 
407         for instance_uuid, events in our_events.items():
408             for (name, tag), eventlet_event in events.items():
409                 LOG.debug('Canceling in-flight event %(name)s-%(tag)s for '
410                           'instance %(instance_uuid)s',
411                           {'name': name,
412                            'tag': tag,
413                            'instance_uuid': instance_uuid})
414                 event = objects.InstanceExternalEvent(
415                     instance_uuid=instance_uuid,
416                     name=name, status='failed',
417                     tag=tag, data={})
418                 eventlet_event.send(event)
419 
420 
421 class ComputeVirtAPI(virtapi.VirtAPI):
422     def __init__(self, compute):
423         super(ComputeVirtAPI, self).__init__()
424         self._compute = compute
425 
426     def _default_error_callback(self, event_name, instance):
427         raise exception.NovaException(_('Instance event failed'))
428 
429     @contextlib.contextmanager
430     def wait_for_instance_event(self, instance, event_names, deadline=300,
431                                 error_callback=None):
432         """Plan to wait for some events, run some code, then wait.
433 
434         This context manager will first create plans to wait for the
435         provided event_names, yield, and then wait for all the scheduled
436         events to complete.
437 
438         Note that this uses an eventlet.timeout.Timeout to bound the
439         operation, so callers should be prepared to catch that
440         failure and handle that situation appropriately.
441 
442         If the event is not received by the specified timeout deadline,
443         eventlet.timeout.Timeout is raised.
444 
445         If the event is received but did not have a 'completed'
446         status, a NovaException is raised.  If an error_callback is
447         provided, instead of raising an exception as detailed above
448         for the failure case, the callback will be called with the
449         event_name and instance, and can return True to continue
450         waiting for the rest of the events, False to stop processing,
451         or raise an exception which will bubble up to the waiter.
452 
453         :param instance: The instance for which an event is expected
454         :param event_names: A list of event names. Each element is a
455                             tuple of strings to indicate (name, tag),
456                             where name is required, but tag may be None.
457         :param deadline: Maximum number of seconds we should wait for all
458                          of the specified events to arrive.
459         :param error_callback: A function to be called if an event arrives
460 
461         """
462 
463         if error_callback is None:
464             error_callback = self._default_error_callback
465         events = {}
466         for event_name in event_names:
467             name, tag = event_name
468             event_name = objects.InstanceExternalEvent.make_key(name, tag)
469             try:
470                 events[event_name] = (
471                     self._compute.instance_events.prepare_for_instance_event(
472                         instance, name, tag))
473             except exception.NovaException:
474                 error_callback(event_name, instance)
475                 # NOTE(danms): Don't wait for any of the events. They
476                 # should all be canceled and fired immediately below,
477                 # but don't stick around if not.
478                 deadline = 0
479         yield
480         with eventlet.timeout.Timeout(deadline):
481             for event_name, event in events.items():
482                 actual_event = event.wait()
483                 if actual_event.status == 'completed':
484                     continue
485                 decision = error_callback(event_name, instance)
486                 if decision is False:
487                     break
488 
489 
490 class ComputeManager(manager.Manager):
491     """Manages the running instances from creation to destruction."""
492 
493     target = messaging.Target(version='5.0')
494 
495     def __init__(self, compute_driver=None, *args, **kwargs):
496         """Load configuration options and connect to the hypervisor."""
497         self.virtapi = ComputeVirtAPI(self)
498         self.network_api = network.API()
499         self.volume_api = cinder.API()
500         self.image_api = image.API()
501         self._last_host_check = 0
502         self._last_bw_usage_poll = 0
503         self._bw_usage_supported = True
504         self._last_bw_usage_cell_update = 0
505         self.compute_api = compute.API()
506         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
507         self.conductor_api = conductor.API()
508         self.compute_task_api = conductor.ComputeTaskAPI()
509         self.is_neutron_security_groups = (
510             openstack_driver.is_neutron_security_groups())
511         self.cells_rpcapi = cells_rpcapi.CellsAPI()
512         self.scheduler_client = scheduler_client.SchedulerClient()
513         self.reportclient = self.scheduler_client.reportclient
514         self._resource_tracker = None
515         self.instance_events = InstanceEvents()
516         self._sync_power_pool = eventlet.GreenPool(
517             size=CONF.sync_power_state_pool_size)
518         self._syncs_in_progress = {}
519         self.send_instance_updates = (
520             CONF.filter_scheduler.track_instance_changes)
521         if CONF.max_concurrent_builds != 0:
522             self._build_semaphore = eventlet.semaphore.Semaphore(
523                 CONF.max_concurrent_builds)
524         else:
525             self._build_semaphore = compute_utils.UnlimitedSemaphore()
526         if max(CONF.max_concurrent_live_migrations, 0) != 0:
527             self._live_migration_executor = futures.ThreadPoolExecutor(
528                 max_workers=CONF.max_concurrent_live_migrations)
529         else:
530             # Starting in python 3.5, this is technically bounded, but it's
531             # ncpu * 5 which is probably much higher than anyone would sanely
532             # use for concurrently running live migrations.
533             self._live_migration_executor = futures.ThreadPoolExecutor()
534         # This is a dict, keyed by instance uuid, to a two-item tuple of
535         # migration object and Future for the queued live migration.
536         self._waiting_live_migrations = {}
537 
538         super(ComputeManager, self).__init__(service_name="compute",
539                                              *args, **kwargs)
540 
541         # NOTE(russellb) Load the driver last.  It may call back into the
542         # compute manager via the virtapi, so we want it to be fully
543         # initialized before that happens.
544         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
545         self.use_legacy_block_device_info = \
546                             self.driver.need_legacy_block_device_info
547 
548     def reset(self):
549         LOG.info('Reloading compute RPC API')
550         compute_rpcapi.LAST_VERSION = None
551         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
552 
553     def _get_resource_tracker(self):
554         if not self._resource_tracker:
555             rt = resource_tracker.ResourceTracker(self.host, self.driver)
556             self._resource_tracker = rt
557         return self._resource_tracker
558 
559     def _update_resource_tracker(self, context, instance):
560         """Let the resource tracker know that an instance has changed state."""
561 
562         if instance.host == self.host:
563             rt = self._get_resource_tracker()
564             rt.update_usage(context, instance, instance.node)
565 
566     def _instance_update(self, context, instance, **kwargs):
567         """Update an instance in the database using kwargs as value."""
568 
569         for k, v in kwargs.items():
570             setattr(instance, k, v)
571         instance.save()
572         self._update_resource_tracker(context, instance)
573 
574     def _nil_out_instance_obj_host_and_node(self, instance):
575         # NOTE(jwcroppe): We don't do instance.save() here for performance
576         # reasons; a call to this is expected to be immediately followed by
577         # another call that does instance.save(), thus avoiding two writes
578         # to the database layer.
579         instance.host = None
580         instance.node = None
581 
582     def _set_instance_obj_error_state(self, context, instance,
583                                       clean_task_state=False):
584         try:
585             instance.vm_state = vm_states.ERROR
586             if clean_task_state:
587                 instance.task_state = None
588             instance.save()
589         except exception.InstanceNotFound:
590             LOG.debug('Instance has been destroyed from under us while '
591                       'trying to set it to ERROR', instance=instance)
592 
593     def _get_instances_on_driver(self, context, filters=None):
594         """Return a list of instance records for the instances found
595         on the hypervisor which satisfy the specified filters. If filters=None
596         return a list of instance records for all the instances found on the
597         hypervisor.
598         """
599         if not filters:
600             filters = {}
601         try:
602             driver_uuids = self.driver.list_instance_uuids()
603             if len(driver_uuids) == 0:
604                 # Short circuit, don't waste a DB call
605                 return objects.InstanceList()
606             filters['uuid'] = driver_uuids
607             local_instances = objects.InstanceList.get_by_filters(
608                 context, filters, use_slave=True)
609             return local_instances
610         except NotImplementedError:
611             pass
612 
613         # The driver doesn't support uuids listing, so we'll have
614         # to brute force.
615         driver_instances = self.driver.list_instances()
616         # NOTE(mjozefcz): In this case we need to apply host filter.
617         # Without this all instance data would be fetched from db.
618         filters['host'] = self.host
619         instances = objects.InstanceList.get_by_filters(context, filters,
620                                                         use_slave=True)
621         name_map = {instance.name: instance for instance in instances}
622         local_instances = []
623         for driver_instance in driver_instances:
624             instance = name_map.get(driver_instance)
625             if not instance:
626                 continue
627             local_instances.append(instance)
628         return local_instances
629 
630     def _destroy_evacuated_instances(self, context):
631         """Destroys evacuated instances.
632 
633         While nova-compute was down, the instances running on it could be
634         evacuated to another host. This method looks for evacuation migration
635         records where this is the source host and which were either started
636         (accepted), in-progress (pre-migrating) or migrated (done). From those
637         migration records, local instances reported by the hypervisor are
638         compared to the instances for the migration records and those local
639         guests are destroyed, along with instance allocation records in
640         Placement for this node.
641         """
642         filters = {
643             'source_compute': self.host,
644             # NOTE(mriedem): Migration records that have been accepted are
645             # included in case the source node comes back up while instances
646             # are being evacuated to another host. We don't want the same
647             # instance being reported from multiple hosts.
648             # NOTE(lyarwood): pre-migrating is also included here as the
649             # source compute can come back online shortly after the RT
650             # claims on the destination that in-turn moves the migration to
651             # pre-migrating. If the evacuate fails on the destination host,
652             # the user can rebuild the instance (in ERROR state) on the source
653             # host.
654             'status': ['accepted', 'pre-migrating', 'done'],
655             'migration_type': 'evacuation',
656         }
657         with utils.temporary_mutation(context, read_deleted='yes'):
658             evacuations = objects.MigrationList.get_by_filters(context,
659                                                                filters)
660         if not evacuations:
661             return
662         evacuations = {mig.instance_uuid: mig for mig in evacuations}
663 
664         local_instances = self._get_instances_on_driver(context)
665         evacuated = [inst for inst in local_instances
666                      if inst.uuid in evacuations]
667 
668         # NOTE(gibi): We are called from init_host and at this point the
669         # compute_nodes of the resource tracker has not been populated yet so
670         # we cannot rely on the resource tracker here.
671         compute_nodes = {}
672 
673         for instance in evacuated:
674             migration = evacuations[instance.uuid]
675             LOG.info('Deleting instance as it has been evacuated from '
676                      'this host', instance=instance)
677             try:
678                 network_info = self.network_api.get_instance_nw_info(
679                     context, instance)
680                 bdi = self._get_instance_block_device_info(context,
681                                                            instance)
682                 destroy_disks = not (self._is_instance_storage_shared(
683                     context, instance))
684             except exception.InstanceNotFound:
685                 network_info = network_model.NetworkInfo()
686                 bdi = {}
687                 LOG.info('Instance has been marked deleted already, '
688                          'removing it from the hypervisor.',
689                          instance=instance)
690                 # always destroy disks if the instance was deleted
691                 destroy_disks = True
692             self.driver.destroy(context, instance,
693                                 network_info,
694                                 bdi, destroy_disks)
695 
696             # delete the allocation of the evacuated instance from this host
697             if migration.source_node not in compute_nodes:
698                 try:
699                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
700                         context, self.host, migration.source_node).uuid
701                     compute_nodes[migration.source_node] = cn_uuid
702                 except exception.ComputeHostNotFound:
703                     LOG.error("Failed to clean allocation of evacuated "
704                               "instance as the source node %s is not found",
705                               migration.source_node, instance=instance)
706                     continue
707             cn_uuid = compute_nodes[migration.source_node]
708 
709             if not scheduler_utils.remove_allocation_from_compute(
710                     context, instance, cn_uuid, self.reportclient):
711                 LOG.error("Failed to clean allocation of evacuated instance "
712                           "on the source node %s",
713                           cn_uuid, instance=instance)
714 
715             migration.status = 'completed'
716             migration.save()
717         return evacuations
718 
719     def _is_instance_storage_shared(self, context, instance, host=None):
720         shared_storage = True
721         data = None
722         try:
723             data = self.driver.check_instance_shared_storage_local(context,
724                                                        instance)
725             if data:
726                 shared_storage = (self.compute_rpcapi.
727                                   check_instance_shared_storage(context,
728                                   instance, data, host=host))
729         except NotImplementedError:
730             LOG.debug('Hypervisor driver does not support '
731                       'instance shared storage check, '
732                       'assuming it\'s not on shared storage',
733                       instance=instance)
734             shared_storage = False
735         except Exception:
736             LOG.exception('Failed to check if instance shared',
737                           instance=instance)
738         finally:
739             if data:
740                 self.driver.check_instance_shared_storage_cleanup(context,
741                                                                   data)
742         return shared_storage
743 
744     def _complete_partial_deletion(self, context, instance):
745         """Complete deletion for instances in DELETED status but not marked as
746         deleted in the DB
747         """
748         instance.destroy()
749         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
750                 context, instance.uuid)
751         self._complete_deletion(context,
752                                 instance,
753                                 bdms)
754 
755     def _complete_deletion(self, context, instance, bdms):
756         self._update_resource_tracker(context, instance)
757 
758         rt = self._get_resource_tracker()
759         rt.reportclient.delete_allocation_for_instance(context, instance.uuid)
760 
761         self._notify_about_instance_usage(context, instance, "delete.end")
762         compute_utils.notify_about_instance_action(context, instance,
763                 self.host, action=fields.NotificationAction.DELETE,
764                 phase=fields.NotificationPhase.END, bdms=bdms)
765         self._clean_instance_console_tokens(context, instance)
766         self._delete_scheduler_instance_info(context, instance.uuid)
767 
768     def _init_instance(self, context, instance):
769         """Initialize this instance during service init."""
770 
771         # NOTE(danms): If the instance appears to not be owned by this
772         # host, it may have been evacuated away, but skipped by the
773         # evacuation cleanup code due to configuration. Thus, if that
774         # is a possibility, don't touch the instance in any way, but
775         # log the concern. This will help avoid potential issues on
776         # startup due to misconfiguration.
777         if instance.host != self.host:
778             LOG.warning('Instance %(uuid)s appears to not be owned '
779                         'by this host, but by %(host)s. Startup '
780                         'processing is being skipped.',
781                         {'uuid': instance.uuid,
782                          'host': instance.host})
783             return
784 
785         # Instances that are shut down, or in an error state can not be
786         # initialized and are not attempted to be recovered. The exception
787         # to this are instances that are in RESIZE_MIGRATING or DELETING,
788         # which are dealt with further down.
789         if (instance.vm_state == vm_states.SOFT_DELETED or
790             (instance.vm_state == vm_states.ERROR and
791             instance.task_state not in
792             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
793             LOG.debug("Instance is in %s state.",
794                       instance.vm_state, instance=instance)
795             return
796 
797         if instance.vm_state == vm_states.DELETED:
798             try:
799                 self._complete_partial_deletion(context, instance)
800             except Exception:
801                 # we don't want that an exception blocks the init_host
802                 LOG.exception('Failed to complete a deletion',
803                               instance=instance)
804             return
805 
806         if (instance.vm_state == vm_states.BUILDING or
807             instance.task_state in [task_states.SCHEDULING,
808                                     task_states.BLOCK_DEVICE_MAPPING,
809                                     task_states.NETWORKING,
810                                     task_states.SPAWNING]):
811             # NOTE(dave-mcnally) compute stopped before instance was fully
812             # spawned so set to ERROR state. This is safe to do as the state
813             # may be set by the api but the host is not so if we get here the
814             # instance has already been scheduled to this particular host.
815             LOG.debug("Instance failed to spawn correctly, "
816                       "setting to ERROR state", instance=instance)
817             instance.task_state = None
818             instance.vm_state = vm_states.ERROR
819             instance.save()
820             return
821 
822         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
823             instance.task_state in [task_states.REBUILDING,
824                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
825                                     task_states.REBUILD_SPAWNING]):
826             # NOTE(jichenjc) compute stopped before instance was fully
827             # spawned so set to ERROR state. This is consistent to BUILD
828             LOG.debug("Instance failed to rebuild correctly, "
829                       "setting to ERROR state", instance=instance)
830             instance.task_state = None
831             instance.vm_state = vm_states.ERROR
832             instance.save()
833             return
834 
835         if (instance.vm_state != vm_states.ERROR and
836             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
837                                     task_states.IMAGE_PENDING_UPLOAD,
838                                     task_states.IMAGE_UPLOADING,
839                                     task_states.IMAGE_SNAPSHOT]):
840             LOG.debug("Instance in transitional state %s at start-up "
841                       "clearing task state",
842                       instance.task_state, instance=instance)
843             try:
844                 self._post_interrupted_snapshot_cleanup(context, instance)
845             except Exception:
846                 # we don't want that an exception blocks the init_host
847                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
848             instance.task_state = None
849             instance.save()
850 
851         if (instance.vm_state != vm_states.ERROR and
852             instance.task_state in [task_states.RESIZE_PREP]):
853             LOG.debug("Instance in transitional state %s at start-up "
854                       "clearing task state",
855                       instance['task_state'], instance=instance)
856             instance.task_state = None
857             instance.save()
858 
859         if instance.task_state == task_states.DELETING:
860             try:
861                 LOG.info('Service started deleting the instance during '
862                          'the previous run, but did not finish. Restarting'
863                          ' the deletion now.', instance=instance)
864                 instance.obj_load_attr('metadata')
865                 instance.obj_load_attr('system_metadata')
866                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
867                         context, instance.uuid)
868                 self._delete_instance(context, instance, bdms)
869             except Exception:
870                 # we don't want that an exception blocks the init_host
871                 LOG.exception('Failed to complete a deletion',
872                               instance=instance)
873                 self._set_instance_obj_error_state(context, instance)
874             return
875 
876         current_power_state = self._get_power_state(context, instance)
877         try_reboot, reboot_type = self._retry_reboot(context, instance,
878                                                      current_power_state)
879 
880         if try_reboot:
881             LOG.debug("Instance in transitional state (%(task_state)s) at "
882                       "start-up and power state is (%(power_state)s), "
883                       "triggering reboot",
884                       {'task_state': instance.task_state,
885                        'power_state': current_power_state},
886                       instance=instance)
887 
888             # NOTE(mikal): if the instance was doing a soft reboot that got as
889             # far as shutting down the instance but not as far as starting it
890             # again, then we've just become a hard reboot. That means the
891             # task state for the instance needs to change so that we're in one
892             # of the expected task states for a hard reboot.
893             if (instance.task_state in task_states.soft_reboot_states and
894                 reboot_type == 'HARD'):
895                 instance.task_state = task_states.REBOOT_PENDING_HARD
896                 instance.save()
897 
898             self.reboot_instance(context, instance, block_device_info=None,
899                                  reboot_type=reboot_type)
900             return
901 
902         elif (current_power_state == power_state.RUNNING and
903               instance.task_state in [task_states.REBOOT_STARTED,
904                                       task_states.REBOOT_STARTED_HARD,
905                                       task_states.PAUSING,
906                                       task_states.UNPAUSING]):
907             LOG.warning("Instance in transitional state "
908                         "(%(task_state)s) at start-up and power state "
909                         "is (%(power_state)s), clearing task state",
910                         {'task_state': instance.task_state,
911                          'power_state': current_power_state},
912                         instance=instance)
913             instance.task_state = None
914             instance.vm_state = vm_states.ACTIVE
915             instance.save()
916         elif (current_power_state == power_state.PAUSED and
917               instance.task_state == task_states.UNPAUSING):
918             LOG.warning("Instance in transitional state "
919                         "(%(task_state)s) at start-up and power state "
920                         "is (%(power_state)s), clearing task state "
921                         "and unpausing the instance",
922                         {'task_state': instance.task_state,
923                          'power_state': current_power_state},
924                         instance=instance)
925             try:
926                 self.unpause_instance(context, instance)
927             except NotImplementedError:
928                 # Some virt driver didn't support pause and unpause
929                 pass
930             except Exception:
931                 LOG.exception('Failed to unpause instance', instance=instance)
932             return
933 
934         if instance.task_state == task_states.POWERING_OFF:
935             try:
936                 LOG.debug("Instance in transitional state %s at start-up "
937                           "retrying stop request",
938                           instance.task_state, instance=instance)
939                 self.stop_instance(context, instance, True)
940             except Exception:
941                 # we don't want that an exception blocks the init_host
942                 LOG.exception('Failed to stop instance', instance=instance)
943             return
944 
945         if instance.task_state == task_states.POWERING_ON:
946             try:
947                 LOG.debug("Instance in transitional state %s at start-up "
948                           "retrying start request",
949                           instance.task_state, instance=instance)
950                 self.start_instance(context, instance)
951             except Exception:
952                 # we don't want that an exception blocks the init_host
953                 LOG.exception('Failed to start instance', instance=instance)
954             return
955 
956         net_info = instance.get_network_info()
957         try:
958             self.driver.plug_vifs(instance, net_info)
959         except NotImplementedError as e:
960             LOG.debug(e, instance=instance)
961         except exception.VirtualInterfacePlugException:
962             # we don't want an exception to block the init_host
963             LOG.exception("Vifs plug failed", instance=instance)
964             self._set_instance_obj_error_state(context, instance)
965             return
966 
967         if instance.task_state == task_states.RESIZE_MIGRATING:
968             # We crashed during resize/migration, so roll back for safety
969             try:
970                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
971                 # not in system_metadata we default to True for backwards
972                 # compatibility
973                 power_on = (instance.system_metadata.get('old_vm_state') !=
974                             vm_states.STOPPED)
975 
976                 block_dev_info = self._get_instance_block_device_info(context,
977                                                                       instance)
978 
979                 self.driver.finish_revert_migration(context,
980                     instance, net_info, block_dev_info, power_on)
981 
982             except Exception:
983                 LOG.exception('Failed to revert crashed migration',
984                               instance=instance)
985             finally:
986                 LOG.info('Instance found in migrating state during '
987                          'startup. Resetting task_state',
988                          instance=instance)
989                 instance.task_state = None
990                 instance.save()
991         if instance.task_state == task_states.MIGRATING:
992             # Live migration did not complete, but instance is on this
993             # host, so reset the state.
994             instance.task_state = None
995             instance.save(expected_task_state=[task_states.MIGRATING])
996 
997         db_state = instance.power_state
998         drv_state = self._get_power_state(context, instance)
999         expect_running = (db_state == power_state.RUNNING and
1000                           drv_state != db_state)
1001 
1002         LOG.debug('Current state is %(drv_state)s, state in DB is '
1003                   '%(db_state)s.',
1004                   {'drv_state': drv_state, 'db_state': db_state},
1005                   instance=instance)
1006 
1007         if expect_running and CONF.resume_guests_state_on_host_boot:
1008             self._resume_guests_state(context, instance, net_info)
1009         elif drv_state == power_state.RUNNING:
1010             # VMwareAPI drivers will raise an exception
1011             try:
1012                 self.driver.ensure_filtering_rules_for_instance(
1013                                        instance, net_info)
1014             except NotImplementedError:
1015                 LOG.debug('Hypervisor driver does not support '
1016                           'firewall rules', instance=instance)
1017 
1018     def _resume_guests_state(self, context, instance, net_info):
1019         LOG.info('Rebooting instance after nova-compute restart.',
1020                  instance=instance)
1021         block_device_info = \
1022             self._get_instance_block_device_info(context, instance)
1023 
1024         try:
1025             self.driver.resume_state_on_host_boot(
1026                 context, instance, net_info, block_device_info)
1027         except NotImplementedError:
1028             LOG.warning('Hypervisor driver does not support '
1029                         'resume guests', instance=instance)
1030         except Exception:
1031             # NOTE(vish): The instance failed to resume, so we set the
1032             #             instance to error and attempt to continue.
1033             LOG.warning('Failed to resume instance',
1034                         instance=instance)
1035             self._set_instance_obj_error_state(context, instance)
1036 
1037     def _retry_reboot(self, context, instance, current_power_state):
1038         current_task_state = instance.task_state
1039         retry_reboot = False
1040         reboot_type = compute_utils.get_reboot_type(current_task_state,
1041                                                     current_power_state)
1042 
1043         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1044                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1045         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1046                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1047         started_not_running = (current_task_state in
1048                                [task_states.REBOOT_STARTED,
1049                                 task_states.REBOOT_STARTED_HARD] and
1050                                current_power_state != power_state.RUNNING)
1051 
1052         if pending_soft or pending_hard or started_not_running:
1053             retry_reboot = True
1054 
1055         return retry_reboot, reboot_type
1056 
1057     def handle_lifecycle_event(self, event):
1058         LOG.info("VM %(state)s (Lifecycle Event)",
1059                  {'state': event.get_name()},
1060                  instance_uuid=event.get_instance_uuid())
1061         context = nova.context.get_admin_context(read_deleted='yes')
1062         vm_power_state = None
1063         event_transition = event.get_transition()
1064         if event_transition == virtevent.EVENT_LIFECYCLE_STOPPED:
1065             vm_power_state = power_state.SHUTDOWN
1066         elif event_transition == virtevent.EVENT_LIFECYCLE_STARTED:
1067             vm_power_state = power_state.RUNNING
1068         elif event_transition in (
1069                 virtevent.EVENT_LIFECYCLE_PAUSED,
1070                 virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED,
1071                 virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED):
1072             vm_power_state = power_state.PAUSED
1073         elif event_transition == virtevent.EVENT_LIFECYCLE_RESUMED:
1074             vm_power_state = power_state.RUNNING
1075         elif event_transition == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1076             vm_power_state = power_state.SUSPENDED
1077         else:
1078             LOG.warning("Unexpected lifecycle event: %d", event_transition)
1079 
1080         migrate_finish_statuses = {
1081             # This happens on the source node and indicates live migration
1082             # entered post-copy mode.
1083             virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED: 'running (post-copy)',
1084             # Suspended for offline migration.
1085             virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED: 'running'
1086         }
1087 
1088         expected_attrs = []
1089         if event_transition in migrate_finish_statuses:
1090             # Join on info_cache since that's needed in migrate_instance_start.
1091             expected_attrs.append('info_cache')
1092         instance = objects.Instance.get_by_uuid(context,
1093                                                 event.get_instance_uuid(),
1094                                                 expected_attrs=expected_attrs)
1095 
1096         # Note(lpetrut): The event may be delayed, thus not reflecting
1097         # the current instance power state. In that case, ignore the event.
1098         current_power_state = self._get_power_state(context, instance)
1099         if current_power_state == vm_power_state:
1100             LOG.debug('Synchronizing instance power state after lifecycle '
1101                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1102                       'current task_state: %(task_state)s, current DB '
1103                       'power_state: %(db_power_state)s, VM power_state: '
1104                       '%(vm_power_state)s',
1105                       {'event': event.get_name(),
1106                        'vm_state': instance.vm_state,
1107                        'task_state': instance.task_state,
1108                        'db_power_state': instance.power_state,
1109                        'vm_power_state': vm_power_state},
1110                       instance_uuid=instance.uuid)
1111             self._sync_instance_power_state(context,
1112                                             instance,
1113                                             vm_power_state)
1114 
1115         # The following checks are for live migration. We want to activate
1116         # the port binding for the destination host before the live migration
1117         # is resumed on the destination host in order to reduce network
1118         # downtime. Otherwise the ports are bound to the destination host
1119         # in post_live_migration_at_destination.
1120         # TODO(danms): Explore options for using a different live migration
1121         # specific callback for this instead of piggy-backing on the
1122         # handle_lifecycle_event callback.
1123         if (instance.task_state == task_states.MIGRATING and
1124                 event_transition in migrate_finish_statuses):
1125             status = migrate_finish_statuses[event_transition]
1126             try:
1127                 migration = objects.Migration.get_by_instance_and_status(
1128                             context, instance.uuid, status)
1129                 LOG.debug('Binding ports to destination host: %s',
1130                           migration.dest_compute, instance=instance)
1131                 # For neutron, migrate_instance_start will activate the
1132                 # destination host port bindings, if there are any created by
1133                 # conductor before live migration started.
1134                 self.network_api.migrate_instance_start(
1135                     context, instance, migration)
1136             except exception.MigrationNotFoundByStatus:
1137                 LOG.warning("Unable to find migration record with status "
1138                             "'%s' for instance. Port binding will happen in "
1139                             "post live migration.", status, instance=instance)
1140 
1141     def handle_events(self, event):
1142         if isinstance(event, virtevent.LifecycleEvent):
1143             try:
1144                 self.handle_lifecycle_event(event)
1145             except exception.InstanceNotFound:
1146                 LOG.debug("Event %s arrived for non-existent instance. The "
1147                           "instance was probably deleted.", event)
1148         else:
1149             LOG.debug("Ignoring event %s", event)
1150 
1151     def init_virt_events(self):
1152         if CONF.workarounds.handle_virt_lifecycle_events:
1153             self.driver.register_event_listener(self.handle_events)
1154         else:
1155             # NOTE(mriedem): If the _sync_power_states periodic task is
1156             # disabled we should emit a warning in the logs.
1157             if CONF.sync_power_state_interval < 0:
1158                 LOG.warning('Instance lifecycle events from the compute '
1159                             'driver have been disabled. Note that lifecycle '
1160                             'changes to an instance outside of the compute '
1161                             'service will not be synchronized '
1162                             'automatically since the _sync_power_states '
1163                             'periodic task is also disabled.')
1164             else:
1165                 LOG.info('Instance lifecycle events from the compute '
1166                          'driver have been disabled. Note that lifecycle '
1167                          'changes to an instance outside of the compute '
1168                          'service will only be synchronized by the '
1169                          '_sync_power_states periodic task.')
1170 
1171     def init_host(self):
1172         """Initialization for a standalone compute service."""
1173 
1174         if CONF.pci.passthrough_whitelist:
1175             # Simply loading the PCI passthrough whitelist will do a bunch of
1176             # validation that would otherwise wait until the PciDevTracker is
1177             # constructed when updating available resources for the compute
1178             # node(s) in the resource tracker, effectively killing that task.
1179             # So load up the whitelist when starting the compute service to
1180             # flush any invalid configuration early so we can kill the service
1181             # if the configuration is wrong.
1182             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1183 
1184         nova.conf.neutron.register_dynamic_opts(CONF)
1185 
1186         self.driver.init_host(host=self.host)
1187         context = nova.context.get_admin_context()
1188         instances = objects.InstanceList.get_by_host(
1189             context, self.host, expected_attrs=['info_cache', 'metadata'])
1190 
1191         if CONF.defer_iptables_apply:
1192             self.driver.filter_defer_apply_on()
1193 
1194         self.init_virt_events()
1195 
1196         try:
1197             # checking that instance was not already evacuated to other host
1198             evacuated_instances = self._destroy_evacuated_instances(context)
1199 
1200             # Initialise instances on the host that are not evacuating
1201             for instance in instances:
1202                 if (not evacuated_instances or
1203                         instance.uuid not in evacuated_instances):
1204                     self._init_instance(context, instance)
1205 
1206         finally:
1207             if CONF.defer_iptables_apply:
1208                 self.driver.filter_defer_apply_off()
1209             if instances:
1210                 # We only send the instance info to the scheduler on startup
1211                 # if there is anything to send, otherwise this host might
1212                 # not be mapped yet in a cell and the scheduler may have
1213                 # issues dealing with the information. Later changes to
1214                 # instances on this host will update the scheduler, or the
1215                 # _sync_scheduler_instance_info periodic task will.
1216                 self._update_scheduler_instance_info(context, instances)
1217 
1218     def cleanup_host(self):
1219         self.driver.register_event_listener(None)
1220         self.instance_events.cancel_all_events()
1221         self.driver.cleanup_host(host=self.host)
1222         self._cleanup_live_migrations_in_pool()
1223 
1224     def _cleanup_live_migrations_in_pool(self):
1225         # Shutdown the pool so we don't get new requests.
1226         self._live_migration_executor.shutdown(wait=False)
1227         # For any queued migrations, cancel the migration and update
1228         # its status.
1229         for migration, future in self._waiting_live_migrations.values():
1230             # If we got here before the Future was submitted then we need
1231             # to move on since there isn't anything we can do.
1232             if future is None:
1233                 continue
1234             if future.cancel():
1235                 self._set_migration_status(migration, 'cancelled')
1236                 LOG.info('Successfully cancelled queued live migration.',
1237                          instance_uuid=migration.instance_uuid)
1238             else:
1239                 LOG.warning('Unable to cancel live migration.',
1240                             instance_uuid=migration.instance_uuid)
1241         self._waiting_live_migrations.clear()
1242 
1243     def pre_start_hook(self):
1244         """After the service is initialized, but before we fully bring
1245         the service up by listening on RPC queues, make sure to update
1246         our available resources (and indirectly our available nodes).
1247         """
1248         self.update_available_resource(nova.context.get_admin_context(),
1249                                        startup=True)
1250 
1251     def _get_power_state(self, context, instance):
1252         """Retrieve the power state for the given instance."""
1253         LOG.debug('Checking state', instance=instance)
1254         try:
1255             return self.driver.get_info(instance).state
1256         except exception.InstanceNotFound:
1257             return power_state.NOSTATE
1258 
1259     def get_console_topic(self, context):
1260         """Retrieves the console host for a project on this host.
1261 
1262         Currently this is just set in the flags for each compute host.
1263 
1264         """
1265         # TODO(mdragon): perhaps make this variable by console_type?
1266         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1267 
1268     @wrap_exception()
1269     def get_console_pool_info(self, context, console_type):
1270         return self.driver.get_console_pool_info(console_type)
1271 
1272     @wrap_exception()
1273     def refresh_instance_security_rules(self, context, instance):
1274         """Tell the virtualization driver to refresh security rules for
1275         an instance.
1276 
1277         Passes straight through to the virtualization driver.
1278 
1279         Synchronize the call because we may still be in the middle of
1280         creating the instance.
1281         """
1282         @utils.synchronized(instance.uuid)
1283         def _sync_refresh():
1284             try:
1285                 return self.driver.refresh_instance_security_rules(instance)
1286             except NotImplementedError:
1287                 LOG.debug('Hypervisor driver does not support '
1288                           'security groups.', instance=instance)
1289 
1290         return _sync_refresh()
1291 
1292     def _await_block_device_map_created(self, context, vol_id):
1293         # TODO(yamahata): creating volume simultaneously
1294         #                 reduces creation time?
1295         # TODO(yamahata): eliminate dumb polling
1296         start = time.time()
1297         retries = CONF.block_device_allocate_retries
1298         if retries < 0:
1299             LOG.warning("Treating negative config value (%(retries)s) for "
1300                         "'block_device_retries' as 0.",
1301                         {'retries': retries})
1302         # (1) treat  negative config value as 0
1303         # (2) the configured value is 0, one attempt should be made
1304         # (3) the configured value is > 0, then the total number attempts
1305         #      is (retries + 1)
1306         attempts = 1
1307         if retries >= 1:
1308             attempts = retries + 1
1309         for attempt in range(1, attempts + 1):
1310             volume = self.volume_api.get(context, vol_id)
1311             volume_status = volume['status']
1312             if volume_status not in ['creating', 'downloading']:
1313                 if volume_status == 'available':
1314                     return attempt
1315                 LOG.warning("Volume id: %(vol_id)s finished being "
1316                             "created but its status is %(vol_status)s.",
1317                             {'vol_id': vol_id,
1318                              'vol_status': volume_status})
1319                 break
1320             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1321         raise exception.VolumeNotCreated(volume_id=vol_id,
1322                                          seconds=int(time.time() - start),
1323                                          attempts=attempt,
1324                                          volume_status=volume_status)
1325 
1326     def _decode_files(self, injected_files):
1327         """Base64 decode the list of files to inject."""
1328         if not injected_files:
1329             return []
1330 
1331         def _decode(f):
1332             path, contents = f
1333             # Py3 raises binascii.Error instead of TypeError as in Py27
1334             try:
1335                 decoded = base64.b64decode(contents)
1336                 return path, decoded
1337             except (TypeError, binascii.Error):
1338                 raise exception.Base64Exception(path=path)
1339 
1340         return [_decode(f) for f in injected_files]
1341 
1342     def _validate_instance_group_policy(self, context, instance,
1343                                         scheduler_hints):
1344         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1345         # However, there is a race condition with the enforcement of
1346         # the policy.  Since more than one instance may be scheduled at the
1347         # same time, it's possible that more than one instance with an
1348         # anti-affinity policy may end up here.  It's also possible that
1349         # multiple instances with an affinity policy could end up on different
1350         # hosts.  This is a validation step to make sure that starting the
1351         # instance here doesn't violate the policy.
1352         group_hint = scheduler_hints.get('group')
1353         if not group_hint:
1354             return
1355 
1356         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1357         # to check the type on the value and pull the single entry out. The
1358         # API request schema validates that the 'group' hint is a single value.
1359         if isinstance(group_hint, list):
1360             group_hint = group_hint[0]
1361 
1362         @utils.synchronized(group_hint)
1363         def _do_validation(context, instance, group_hint):
1364             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1365             if group.policy and 'anti-affinity' == group.policy:
1366                 instances_uuids = objects.InstanceList.get_uuids_by_host(
1367                     context, self.host)
1368                 ins_on_host = set(instances_uuids)
1369                 members = set(group.members)
1370                 # Determine the set of instance group members on this host
1371                 # which are not the instance in question. This is used to
1372                 # determine how many other members from the same anti-affinity
1373                 # group can be on this host.
1374                 members_on_host = ins_on_host & members - set([instance.uuid])
1375                 rules = group.rules
1376                 if rules and 'max_server_per_host' in rules:
1377                     max_server = rules['max_server_per_host']
1378                 else:
1379                     max_server = 1
1380                 if len(members_on_host) >= max_server:
1381                     msg = _("Anti-affinity instance group policy "
1382                             "was violated.")
1383                     raise exception.RescheduledException(
1384                             instance_uuid=instance.uuid,
1385                             reason=msg)
1386             elif group.policy and 'affinity' == group.policy:
1387                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1388                 if group_hosts and self.host not in group_hosts:
1389                     msg = _("Affinity instance group policy was violated.")
1390                     raise exception.RescheduledException(
1391                             instance_uuid=instance.uuid,
1392                             reason=msg)
1393 
1394         if not CONF.workarounds.disable_group_policy_check_upcall:
1395             _do_validation(context, instance, group_hint)
1396 
1397     def _log_original_error(self, exc_info, instance_uuid):
1398         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1399                   exc_info=exc_info)
1400 
1401     def _reschedule(self, context, request_spec, filter_properties,
1402             instance, reschedule_method, method_args, task_state,
1403             exc_info=None, host_list=None):
1404         """Attempt to re-schedule a compute operation."""
1405 
1406         instance_uuid = instance.uuid
1407         retry = filter_properties.get('retry')
1408         if not retry:
1409             # no retry information, do not reschedule.
1410             LOG.debug("Retry info not present, will not reschedule",
1411                       instance_uuid=instance_uuid)
1412             return
1413 
1414         if not request_spec:
1415             LOG.debug("No request spec, will not reschedule",
1416                       instance_uuid=instance_uuid)
1417             return
1418 
1419         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1420                   {'method': reschedule_method.__name__,
1421                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1422 
1423         # reset the task state:
1424         self._instance_update(context, instance, task_state=task_state)
1425 
1426         if exc_info:
1427             # stringify to avoid circular ref problem in json serialization:
1428             retry['exc'] = traceback.format_exception_only(exc_info[0],
1429                                     exc_info[1])
1430 
1431         reschedule_method(context, *method_args, host_list=host_list)
1432         return True
1433 
1434     @periodic_task.periodic_task
1435     def _check_instance_build_time(self, context):
1436         """Ensure that instances are not stuck in build."""
1437         timeout = CONF.instance_build_timeout
1438         if timeout == 0:
1439             return
1440 
1441         filters = {'vm_state': vm_states.BUILDING,
1442                    'host': self.host}
1443 
1444         building_insts = objects.InstanceList.get_by_filters(context,
1445                            filters, expected_attrs=[], use_slave=True)
1446 
1447         for instance in building_insts:
1448             if timeutils.is_older_than(instance.created_at, timeout):
1449                 self._set_instance_obj_error_state(context, instance)
1450                 LOG.warning("Instance build timed out. Set to error "
1451                             "state.", instance=instance)
1452 
1453     def _check_instance_exists(self, context, instance):
1454         """Ensure an instance with the same name is not already present."""
1455         if self.driver.instance_exists(instance):
1456             raise exception.InstanceExists(name=instance.name)
1457 
1458     def _allocate_network_async(self, context, instance, requested_networks,
1459                                 macs, security_groups, is_vpn):
1460         """Method used to allocate networks in the background.
1461 
1462         Broken out for testing.
1463         """
1464         # First check to see if we're specifically not supposed to allocate
1465         # networks because if so, we can exit early.
1466         if requested_networks and requested_networks.no_allocate:
1467             LOG.debug("Not allocating networking since 'none' was specified.",
1468                       instance=instance)
1469             return network_model.NetworkInfo([])
1470 
1471         LOG.debug("Allocating IP information in the background.",
1472                   instance=instance)
1473         retries = CONF.network_allocate_retries
1474         attempts = retries + 1
1475         retry_time = 1
1476         bind_host_id = self.driver.network_binding_host_id(context, instance)
1477         for attempt in range(1, attempts + 1):
1478             try:
1479                 nwinfo = self.network_api.allocate_for_instance(
1480                         context, instance, vpn=is_vpn,
1481                         requested_networks=requested_networks,
1482                         macs=macs,
1483                         security_groups=security_groups,
1484                         bind_host_id=bind_host_id)
1485                 LOG.debug('Instance network_info: |%s|', nwinfo,
1486                           instance=instance)
1487                 instance.system_metadata['network_allocated'] = 'True'
1488                 # NOTE(JoshNang) do not save the instance here, as it can cause
1489                 # races. The caller shares a reference to instance and waits
1490                 # for this async greenthread to finish before calling
1491                 # instance.save().
1492                 return nwinfo
1493             except Exception:
1494                 exc_info = sys.exc_info()
1495                 log_info = {'attempt': attempt,
1496                             'attempts': attempts}
1497                 if attempt == attempts:
1498                     LOG.exception('Instance failed network setup '
1499                                   'after %(attempts)d attempt(s)',
1500                                   log_info)
1501                     six.reraise(*exc_info)
1502                 LOG.warning('Instance failed network setup '
1503                             '(attempt %(attempt)d of %(attempts)d)',
1504                             log_info, instance=instance)
1505                 time.sleep(retry_time)
1506                 retry_time *= 2
1507                 if retry_time > 30:
1508                     retry_time = 30
1509         # Not reached.
1510 
1511     def _build_networks_for_instance(self, context, instance,
1512             requested_networks, security_groups):
1513 
1514         # If we're here from a reschedule the network may already be allocated.
1515         if strutils.bool_from_string(
1516                 instance.system_metadata.get('network_allocated', 'False')):
1517             # NOTE(alex_xu): The network_allocated is True means the network
1518             # resource already allocated at previous scheduling, and the
1519             # network setup is cleanup at previous. After rescheduling, the
1520             # network resource need setup on the new host.
1521             self.network_api.setup_instance_network_on_host(
1522                 context, instance, instance.host)
1523             return self.network_api.get_instance_nw_info(context, instance)
1524 
1525         if not self.is_neutron_security_groups:
1526             security_groups = []
1527 
1528         macs = self.driver.macs_for_instance(instance)
1529         network_info = self._allocate_network(context, instance,
1530                 requested_networks, macs, security_groups)
1531 
1532         return network_info
1533 
1534     def _allocate_network(self, context, instance, requested_networks, macs,
1535                           security_groups):
1536         """Start network allocation asynchronously.  Return an instance
1537         of NetworkInfoAsyncWrapper that can be used to retrieve the
1538         allocated networks when the operation has finished.
1539         """
1540         # NOTE(comstud): Since we're allocating networks asynchronously,
1541         # this task state has little meaning, as we won't be in this
1542         # state for very long.
1543         instance.vm_state = vm_states.BUILDING
1544         instance.task_state = task_states.NETWORKING
1545         instance.save(expected_task_state=[None])
1546 
1547         is_vpn = False
1548         return network_model.NetworkInfoAsyncWrapper(
1549                 self._allocate_network_async, context, instance,
1550                 requested_networks, macs, security_groups, is_vpn)
1551 
1552     def _default_root_device_name(self, instance, image_meta, root_bdm):
1553         try:
1554             return self.driver.default_root_device_name(instance,
1555                                                         image_meta,
1556                                                         root_bdm)
1557         except NotImplementedError:
1558             return compute_utils.get_next_device_name(instance, [])
1559 
1560     def _default_device_names_for_instance(self, instance,
1561                                            root_device_name,
1562                                            *block_device_lists):
1563         try:
1564             self.driver.default_device_names_for_instance(instance,
1565                                                           root_device_name,
1566                                                           *block_device_lists)
1567         except NotImplementedError:
1568             compute_utils.default_device_names_for_instance(
1569                 instance, root_device_name, *block_device_lists)
1570 
1571     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1572         # NOTE(ndipanov): Copy obj to avoid changing the original
1573         block_device_obj = block_device_obj.obj_clone()
1574         try:
1575             return self.driver.get_device_name_for_instance(
1576                 instance, bdms, block_device_obj)
1577         except NotImplementedError:
1578             return compute_utils.get_device_name_for_instance(
1579                 instance, bdms, block_device_obj.get("device_name"))
1580 
1581     def _default_block_device_names(self, instance, image_meta, block_devices):
1582         """Verify that all the devices have the device_name set. If not,
1583         provide a default name.
1584 
1585         It also ensures that there is a root_device_name and is set to the
1586         first block device in the boot sequence (boot_index=0).
1587         """
1588         root_bdm = block_device.get_root_bdm(block_devices)
1589         if not root_bdm:
1590             return
1591 
1592         # Get the root_device_name from the root BDM or the instance
1593         root_device_name = None
1594         update_root_bdm = False
1595 
1596         if root_bdm.device_name:
1597             root_device_name = root_bdm.device_name
1598             instance.root_device_name = root_device_name
1599         elif instance.root_device_name:
1600             root_device_name = instance.root_device_name
1601             root_bdm.device_name = root_device_name
1602             update_root_bdm = True
1603         else:
1604             root_device_name = self._default_root_device_name(instance,
1605                                                               image_meta,
1606                                                               root_bdm)
1607 
1608             instance.root_device_name = root_device_name
1609             root_bdm.device_name = root_device_name
1610             update_root_bdm = True
1611 
1612         if update_root_bdm:
1613             root_bdm.save()
1614 
1615         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1616                             block_devices))
1617         swap = list(filter(block_device.new_format_is_swap,
1618                       block_devices))
1619         block_device_mapping = list(filter(
1620               driver_block_device.is_block_device_mapping, block_devices))
1621 
1622         self._default_device_names_for_instance(instance,
1623                                                 root_device_name,
1624                                                 ephemerals,
1625                                                 swap,
1626                                                 block_device_mapping)
1627 
1628     def _block_device_info_to_legacy(self, block_device_info):
1629         """Convert BDI to the old format for drivers that need it."""
1630 
1631         if self.use_legacy_block_device_info:
1632             ephemerals = driver_block_device.legacy_block_devices(
1633                 driver.block_device_info_get_ephemerals(block_device_info))
1634             mapping = driver_block_device.legacy_block_devices(
1635                 driver.block_device_info_get_mapping(block_device_info))
1636             swap = block_device_info['swap']
1637             if swap:
1638                 swap = swap.legacy()
1639 
1640             block_device_info.update({
1641                 'ephemerals': ephemerals,
1642                 'swap': swap,
1643                 'block_device_mapping': mapping})
1644 
1645     def _add_missing_dev_names(self, bdms, instance):
1646         for bdm in bdms:
1647             if bdm.device_name is not None:
1648                 continue
1649 
1650             device_name = self._get_device_name_for_instance(instance,
1651                                                              bdms, bdm)
1652             values = {'device_name': device_name}
1653             bdm.update(values)
1654             bdm.save()
1655 
1656     def _prep_block_device(self, context, instance, bdms):
1657         """Set up the block device for an instance with error logging."""
1658         try:
1659             self._add_missing_dev_names(bdms, instance)
1660             block_device_info = driver.get_block_device_info(instance, bdms)
1661             mapping = driver.block_device_info_get_mapping(block_device_info)
1662             driver_block_device.attach_block_devices(
1663                 mapping, context, instance, self.volume_api, self.driver,
1664                 wait_func=self._await_block_device_map_created)
1665 
1666             self._block_device_info_to_legacy(block_device_info)
1667             return block_device_info
1668 
1669         except exception.OverQuota as e:
1670             LOG.warning('Failed to create block device for instance due'
1671                         ' to exceeding volume related resource quota.'
1672                         ' Error: %s', e.message, instance=instance)
1673             raise
1674 
1675         except Exception as ex:
1676             LOG.exception('Instance failed block device setup',
1677                           instance=instance)
1678             # InvalidBDM will eventually result in a BuildAbortException when
1679             # booting from volume, and will be recorded as an instance fault.
1680             # Maintain the original exception message which most likely has
1681             # useful details which the standard InvalidBDM error message lacks.
1682             raise exception.InvalidBDM(six.text_type(ex))
1683 
1684     def _update_instance_after_spawn(self, context, instance):
1685         instance.power_state = self._get_power_state(context, instance)
1686         instance.vm_state = vm_states.ACTIVE
1687         instance.task_state = None
1688         instance.launched_at = timeutils.utcnow()
1689         configdrive.update_instance(instance)
1690 
1691     def _update_scheduler_instance_info(self, context, instance):
1692         """Sends an InstanceList with created or updated Instance objects to
1693         the Scheduler client.
1694 
1695         In the case of init_host, the value passed will already be an
1696         InstanceList. Other calls will send individual Instance objects that
1697         have been created or resized. In this case, we create an InstanceList
1698         object containing that Instance.
1699         """
1700         if not self.send_instance_updates:
1701             return
1702         if isinstance(instance, obj_instance.Instance):
1703             instance = objects.InstanceList(objects=[instance])
1704         context = context.elevated()
1705         self.scheduler_client.update_instance_info(context, self.host,
1706                                                    instance)
1707 
1708     def _delete_scheduler_instance_info(self, context, instance_uuid):
1709         """Sends the uuid of the deleted Instance to the Scheduler client."""
1710         if not self.send_instance_updates:
1711             return
1712         context = context.elevated()
1713         self.scheduler_client.delete_instance_info(context, self.host,
1714                                                    instance_uuid)
1715 
1716     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1717     def _sync_scheduler_instance_info(self, context):
1718         if not self.send_instance_updates:
1719             return
1720         context = context.elevated()
1721         instances = objects.InstanceList.get_by_host(context, self.host,
1722                                                      expected_attrs=[],
1723                                                      use_slave=True)
1724         uuids = [instance.uuid for instance in instances]
1725         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1726 
1727     def _notify_about_instance_usage(self, context, instance, event_suffix,
1728                                      network_info=None, extra_usage_info=None,
1729                                      fault=None):
1730         compute_utils.notify_about_instance_usage(
1731             self.notifier, context, instance, event_suffix,
1732             network_info=network_info,
1733             extra_usage_info=extra_usage_info, fault=fault)
1734 
1735     def _deallocate_network(self, context, instance,
1736                             requested_networks=None):
1737         # If we were told not to allocate networks let's save ourselves
1738         # the trouble of calling the network API.
1739         if requested_networks and requested_networks.no_allocate:
1740             LOG.debug("Skipping network deallocation for instance since "
1741                       "networking was not requested.", instance=instance)
1742             return
1743 
1744         LOG.debug('Deallocating network for instance', instance=instance)
1745         with timeutils.StopWatch() as timer:
1746             self.network_api.deallocate_for_instance(
1747                 context, instance, requested_networks=requested_networks)
1748         # nova-network does an rpc call so we're OK tracking time spent here
1749         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1750                  timer.elapsed(), instance=instance)
1751 
1752     def _get_instance_block_device_info(self, context, instance,
1753                                         refresh_conn_info=False,
1754                                         bdms=None):
1755         """Transform block devices to the driver block_device format."""
1756 
1757         if not bdms:
1758             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1759                     context, instance.uuid)
1760         block_device_info = driver.get_block_device_info(instance, bdms)
1761 
1762         if not refresh_conn_info:
1763             # if the block_device_mapping has no value in connection_info
1764             # (returned as None), don't include in the mapping
1765             block_device_info['block_device_mapping'] = [
1766                 bdm for bdm in driver.block_device_info_get_mapping(
1767                                     block_device_info)
1768                 if bdm.get('connection_info')]
1769         else:
1770             driver_block_device.refresh_conn_infos(
1771                 driver.block_device_info_get_mapping(block_device_info),
1772                 context, instance, self.volume_api, self.driver)
1773 
1774         self._block_device_info_to_legacy(block_device_info)
1775 
1776         return block_device_info
1777 
1778     def _build_failed(self, node):
1779         if CONF.compute.consecutive_build_service_disable_threshold:
1780             rt = self._get_resource_tracker()
1781             # NOTE(danms): Update our counter, but wait for the next
1782             # update_available_resource() periodic to flush it to the DB
1783             rt.build_failed(node)
1784 
1785     def _build_succeeded(self, node):
1786         rt = self._get_resource_tracker()
1787         rt.build_succeeded(node)
1788 
1789     @wrap_exception()
1790     @reverts_task_state
1791     @wrap_instance_fault
1792     def build_and_run_instance(self, context, instance, image, request_spec,
1793                      filter_properties, admin_password=None,
1794                      injected_files=None, requested_networks=None,
1795                      security_groups=None, block_device_mapping=None,
1796                      node=None, limits=None, host_list=None):
1797 
1798         @utils.synchronized(instance.uuid)
1799         def _locked_do_build_and_run_instance(*args, **kwargs):
1800             # NOTE(danms): We grab the semaphore with the instance uuid
1801             # locked because we could wait in line to build this instance
1802             # for a while and we want to make sure that nothing else tries
1803             # to do anything with this instance while we wait.
1804             with self._build_semaphore:
1805                 try:
1806                     result = self._do_build_and_run_instance(*args, **kwargs)
1807                 except Exception:
1808                     # NOTE(mriedem): This should really only happen if
1809                     # _decode_files in _do_build_and_run_instance fails, and
1810                     # that's before a guest is spawned so it's OK to remove
1811                     # allocations for the instance for this node from Placement
1812                     # below as there is no guest consuming resources anyway.
1813                     # The _decode_files case could be handled more specifically
1814                     # but that's left for another day.
1815                     result = build_results.FAILED
1816                     raise
1817                 finally:
1818                     if result == build_results.FAILED:
1819                         # Remove the allocation records from Placement for the
1820                         # instance if the build failed. The instance.host is
1821                         # likely set to None in _do_build_and_run_instance
1822                         # which means if the user deletes the instance, it
1823                         # will be deleted in the API, not the compute service.
1824                         # Setting the instance.host to None in
1825                         # _do_build_and_run_instance means that the
1826                         # ResourceTracker will no longer consider this instance
1827                         # to be claiming resources against it, so we want to
1828                         # reflect that same thing in Placement.  No need to
1829                         # call this for a reschedule, as the allocations will
1830                         # have already been removed in
1831                         # self._do_build_and_run_instance().
1832                         self._delete_allocation_for_instance(context,
1833                                                              instance.uuid)
1834 
1835                     if result in (build_results.FAILED,
1836                                   build_results.RESCHEDULED):
1837                         self._build_failed(node)
1838                     else:
1839                         self._build_succeeded(node)
1840 
1841         # NOTE(danms): We spawn here to return the RPC worker thread back to
1842         # the pool. Since what follows could take a really long time, we don't
1843         # want to tie up RPC workers.
1844         utils.spawn_n(_locked_do_build_and_run_instance,
1845                       context, instance, image, request_spec,
1846                       filter_properties, admin_password, injected_files,
1847                       requested_networks, security_groups,
1848                       block_device_mapping, node, limits, host_list)
1849 
1850     def _delete_allocation_for_instance(self, context, instance_uuid):
1851         rt = self._get_resource_tracker()
1852         rt.reportclient.delete_allocation_for_instance(context, instance_uuid)
1853 
1854     def _check_device_tagging(self, requested_networks, block_device_mapping):
1855         tagging_requested = False
1856         if requested_networks:
1857             for net in requested_networks:
1858                 if 'tag' in net and net.tag is not None:
1859                     tagging_requested = True
1860                     break
1861         if block_device_mapping and not tagging_requested:
1862             for bdm in block_device_mapping:
1863                 if 'tag' in bdm and bdm.tag is not None:
1864                     tagging_requested = True
1865                     break
1866         if (tagging_requested and
1867                 not self.driver.capabilities.get('supports_device_tagging',
1868                                                  False)):
1869             raise exception.BuildAbortException('Attempt to boot guest with '
1870                                                 'tagged devices on host that '
1871                                                 'does not support tagging.')
1872 
1873     def _check_trusted_certs(self, instance):
1874         if (instance.trusted_certs and
1875                 not self.driver.capabilities.get('supports_trusted_certs',
1876                                                  False)):
1877             raise exception.BuildAbortException(
1878                 'Trusted image certificates provided on host that does not '
1879                 'support certificate validation.')
1880 
1881     @hooks.add_hook('build_instance')
1882     @wrap_exception()
1883     @reverts_task_state
1884     @wrap_instance_event(prefix='compute')
1885     @wrap_instance_fault
1886     def _do_build_and_run_instance(self, context, instance, image,
1887             request_spec, filter_properties, admin_password, injected_files,
1888             requested_networks, security_groups, block_device_mapping,
1889             node=None, limits=None, host_list=None):
1890 
1891         try:
1892             LOG.debug('Starting instance...', instance=instance)
1893             instance.vm_state = vm_states.BUILDING
1894             instance.task_state = None
1895             instance.save(expected_task_state=
1896                     (task_states.SCHEDULING, None))
1897         except exception.InstanceNotFound:
1898             msg = 'Instance disappeared before build.'
1899             LOG.debug(msg, instance=instance)
1900             return build_results.FAILED
1901         except exception.UnexpectedTaskStateError as e:
1902             LOG.debug(e.format_message(), instance=instance)
1903             return build_results.FAILED
1904 
1905         # b64 decode the files to inject:
1906         decoded_files = self._decode_files(injected_files)
1907 
1908         if limits is None:
1909             limits = {}
1910 
1911         if node is None:
1912             node = self._get_nodename(instance, refresh=True)
1913 
1914         try:
1915             with timeutils.StopWatch() as timer:
1916                 self._build_and_run_instance(context, instance, image,
1917                         decoded_files, admin_password, requested_networks,
1918                         security_groups, block_device_mapping, node, limits,
1919                         filter_properties, request_spec)
1920             LOG.info('Took %0.2f seconds to build instance.',
1921                      timer.elapsed(), instance=instance)
1922             return build_results.ACTIVE
1923         except exception.RescheduledException as e:
1924             retry = filter_properties.get('retry')
1925             if not retry:
1926                 # no retry information, do not reschedule.
1927                 LOG.debug("Retry info not present, will not reschedule",
1928                     instance=instance)
1929                 self._cleanup_allocated_networks(context, instance,
1930                     requested_networks)
1931                 self._cleanup_volumes(context, instance,
1932                     block_device_mapping, raise_exc=False)
1933                 compute_utils.add_instance_fault_from_exc(context,
1934                         instance, e, sys.exc_info(),
1935                         fault_message=e.kwargs['reason'])
1936                 self._nil_out_instance_obj_host_and_node(instance)
1937                 self._set_instance_obj_error_state(context, instance,
1938                                                    clean_task_state=True)
1939                 return build_results.FAILED
1940             LOG.debug(e.format_message(), instance=instance)
1941             # This will be used for logging the exception
1942             retry['exc'] = traceback.format_exception(*sys.exc_info())
1943             # This will be used for setting the instance fault message
1944             retry['exc_reason'] = e.kwargs['reason']
1945             # NOTE(comstud): Deallocate networks if the driver wants
1946             # us to do so.
1947             # NOTE(mriedem): Always deallocate networking when using Neutron.
1948             # This is to unbind any ports that the user supplied in the server
1949             # create request, or delete any ports that nova created which were
1950             # meant to be bound to this host. This check intentionally bypasses
1951             # the result of deallocate_networks_on_reschedule because the
1952             # default value in the driver is False, but that method was really
1953             # only meant for Ironic and should be removed when nova-network is
1954             # removed (since is_neutron() will then always be True).
1955             # NOTE(vladikr): SR-IOV ports should be deallocated to
1956             # allow new sriov pci devices to be allocated on a new host.
1957             # Otherwise, if devices with pci addresses are already allocated
1958             # on the destination host, the instance will fail to spawn.
1959             # info_cache.network_info should be present at this stage.
1960             if (self.driver.deallocate_networks_on_reschedule(instance) or
1961                 utils.is_neutron() or
1962                 self.deallocate_sriov_ports_on_reschedule(instance)):
1963                 self._cleanup_allocated_networks(context, instance,
1964                         requested_networks)
1965             else:
1966                 # NOTE(alex_xu): Network already allocated and we don't
1967                 # want to deallocate them before rescheduling. But we need
1968                 # to cleanup those network resources setup on this host before
1969                 # rescheduling.
1970                 self.network_api.cleanup_instance_network_on_host(
1971                     context, instance, self.host)
1972 
1973             self._nil_out_instance_obj_host_and_node(instance)
1974             instance.task_state = task_states.SCHEDULING
1975             instance.save()
1976             # The instance will have already claimed resources from this host
1977             # before this build was attempted. Now that it has failed, we need
1978             # to unclaim those resources before casting to the conductor, so
1979             # that if there are alternate hosts available for a retry, it can
1980             # claim resources on that new host for the instance.
1981             self._delete_allocation_for_instance(context, instance.uuid)
1982 
1983             self.compute_task_api.build_instances(context, [instance],
1984                     image, filter_properties, admin_password,
1985                     injected_files, requested_networks, security_groups,
1986                     block_device_mapping, request_spec=request_spec,
1987                     host_lists=[host_list])
1988             return build_results.RESCHEDULED
1989         except (exception.InstanceNotFound,
1990                 exception.UnexpectedDeletingTaskStateError):
1991             msg = 'Instance disappeared during build.'
1992             LOG.debug(msg, instance=instance)
1993             self._cleanup_allocated_networks(context, instance,
1994                     requested_networks)
1995             return build_results.FAILED
1996         except exception.BuildAbortException as e:
1997             LOG.error(e.format_message(), instance=instance)
1998             self._cleanup_allocated_networks(context, instance,
1999                     requested_networks)
2000             self._cleanup_volumes(context, instance,
2001                     block_device_mapping, raise_exc=False)
2002             compute_utils.add_instance_fault_from_exc(context, instance,
2003                     e, sys.exc_info())
2004             self._nil_out_instance_obj_host_and_node(instance)
2005             self._set_instance_obj_error_state(context, instance,
2006                                                clean_task_state=True)
2007             return build_results.FAILED
2008         except Exception as e:
2009             # Should not reach here.
2010             LOG.exception('Unexpected build failure, not rescheduling build.',
2011                           instance=instance)
2012             self._cleanup_allocated_networks(context, instance,
2013                     requested_networks)
2014             self._cleanup_volumes(context, instance,
2015                     block_device_mapping, raise_exc=False)
2016             compute_utils.add_instance_fault_from_exc(context, instance,
2017                     e, sys.exc_info())
2018             self._nil_out_instance_obj_host_and_node(instance)
2019             self._set_instance_obj_error_state(context, instance,
2020                                                clean_task_state=True)
2021             return build_results.FAILED
2022 
2023     def deallocate_sriov_ports_on_reschedule(self, instance):
2024         """Determine if networks are needed to be deallocated before reschedule
2025 
2026         Check the cached network info for any assigned SR-IOV ports.
2027         SR-IOV ports should be deallocated prior to rescheduling
2028         in order to allow new sriov pci devices to be allocated on a new host.
2029         """
2030         info_cache = instance.info_cache
2031 
2032         def _has_sriov_port(vif):
2033             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
2034 
2035         if (info_cache and info_cache.network_info):
2036             for vif in info_cache.network_info:
2037                 if _has_sriov_port(vif):
2038                     return True
2039         return False
2040 
2041     @staticmethod
2042     def _get_scheduler_hints(filter_properties, request_spec=None):
2043         """Helper method to get scheduler hints.
2044 
2045         This method prefers to get the hints out of the request spec, but that
2046         might not be provided. Conductor will pass request_spec down to the
2047         first compute chosen for a build but older computes will not pass
2048         the request_spec to conductor's build_instances method for a
2049         a reschedule, so if we're on a host via a retry, request_spec may not
2050         be provided so we need to fallback to use the filter_properties
2051         to get scheduler hints.
2052         """
2053         hints = {}
2054         if request_spec is not None and 'scheduler_hints' in request_spec:
2055             hints = request_spec.scheduler_hints
2056         if not hints:
2057             hints = filter_properties.get('scheduler_hints') or {}
2058         return hints
2059 
2060     def _build_and_run_instance(self, context, instance, image, injected_files,
2061             admin_password, requested_networks, security_groups,
2062             block_device_mapping, node, limits, filter_properties,
2063             request_spec=None):
2064 
2065         image_name = image.get('name')
2066         self._notify_about_instance_usage(context, instance, 'create.start',
2067                 extra_usage_info={'image_name': image_name})
2068         compute_utils.notify_about_instance_create(
2069             context, instance, self.host,
2070             phase=fields.NotificationPhase.START,
2071             bdms=block_device_mapping)
2072 
2073         # NOTE(mikal): cache the keystone roles associated with the instance
2074         # at boot time for later reference
2075         instance.system_metadata.update(
2076             {'boot_roles': ','.join(context.roles)})
2077 
2078         self._check_device_tagging(requested_networks, block_device_mapping)
2079         self._check_trusted_certs(instance)
2080 
2081         try:
2082             scheduler_hints = self._get_scheduler_hints(filter_properties,
2083                                                         request_spec)
2084             rt = self._get_resource_tracker()
2085             with rt.instance_claim(context, instance, node, limits):
2086                 # NOTE(russellb) It's important that this validation be done
2087                 # *after* the resource tracker instance claim, as that is where
2088                 # the host is set on the instance.
2089                 self._validate_instance_group_policy(context, instance,
2090                                                      scheduler_hints)
2091                 image_meta = objects.ImageMeta.from_dict(image)
2092                 with self._build_resources(context, instance,
2093                         requested_networks, security_groups, image_meta,
2094                         block_device_mapping) as resources:
2095                     instance.vm_state = vm_states.BUILDING
2096                     instance.task_state = task_states.SPAWNING
2097                     # NOTE(JoshNang) This also saves the changes to the
2098                     # instance from _allocate_network_async, as they aren't
2099                     # saved in that function to prevent races.
2100                     instance.save(expected_task_state=
2101                             task_states.BLOCK_DEVICE_MAPPING)
2102                     block_device_info = resources['block_device_info']
2103                     network_info = resources['network_info']
2104                     allocs = resources['allocations']
2105                     LOG.debug('Start spawning the instance on the hypervisor.',
2106                               instance=instance)
2107                     with timeutils.StopWatch() as timer:
2108                         self.driver.spawn(context, instance, image_meta,
2109                                           injected_files, admin_password,
2110                                           allocs, network_info=network_info,
2111                                           block_device_info=block_device_info)
2112                     LOG.info('Took %0.2f seconds to spawn the instance on '
2113                              'the hypervisor.', timer.elapsed(),
2114                              instance=instance)
2115         except (exception.InstanceNotFound,
2116                 exception.UnexpectedDeletingTaskStateError) as e:
2117             with excutils.save_and_reraise_exception():
2118                 self._notify_about_instance_usage(context, instance,
2119                     'create.error', fault=e)
2120                 tb = traceback.format_exc()
2121                 compute_utils.notify_about_instance_create(
2122                     context, instance, self.host,
2123                     phase=fields.NotificationPhase.ERROR, exception=e,
2124                     bdms=block_device_mapping, tb=tb)
2125         except exception.ComputeResourcesUnavailable as e:
2126             LOG.debug(e.format_message(), instance=instance)
2127             self._notify_about_instance_usage(context, instance,
2128                     'create.error', fault=e)
2129             tb = traceback.format_exc()
2130             compute_utils.notify_about_instance_create(
2131                     context, instance, self.host,
2132                     phase=fields.NotificationPhase.ERROR, exception=e,
2133                     bdms=block_device_mapping, tb=tb)
2134             raise exception.RescheduledException(
2135                     instance_uuid=instance.uuid, reason=e.format_message())
2136         except exception.BuildAbortException as e:
2137             with excutils.save_and_reraise_exception():
2138                 LOG.debug(e.format_message(), instance=instance)
2139                 self._notify_about_instance_usage(context, instance,
2140                     'create.error', fault=e)
2141                 tb = traceback.format_exc()
2142                 compute_utils.notify_about_instance_create(
2143                     context, instance, self.host,
2144                     phase=fields.NotificationPhase.ERROR, exception=e,
2145                     bdms=block_device_mapping, tb=tb)
2146         except (exception.FixedIpLimitExceeded,
2147                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2148             LOG.warning('No more network or fixed IP to be allocated',
2149                         instance=instance)
2150             self._notify_about_instance_usage(context, instance,
2151                     'create.error', fault=e)
2152             tb = traceback.format_exc()
2153             compute_utils.notify_about_instance_create(
2154                     context, instance, self.host,
2155                     phase=fields.NotificationPhase.ERROR, exception=e,
2156                     bdms=block_device_mapping, tb=tb)
2157             msg = _('Failed to allocate the network(s) with error %s, '
2158                     'not rescheduling.') % e.format_message()
2159             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2160                     reason=msg)
2161         except (exception.VirtualInterfaceCreateException,
2162                 exception.VirtualInterfaceMacAddressException,
2163                 exception.FixedIpInvalidOnHost,
2164                 exception.UnableToAutoAllocateNetwork) as e:
2165             LOG.exception('Failed to allocate network(s)',
2166                           instance=instance)
2167             self._notify_about_instance_usage(context, instance,
2168                     'create.error', fault=e)
2169             tb = traceback.format_exc()
2170             compute_utils.notify_about_instance_create(
2171                     context, instance, self.host,
2172                     phase=fields.NotificationPhase.ERROR, exception=e,
2173                     bdms=block_device_mapping, tb=tb)
2174             msg = _('Failed to allocate the network(s), not rescheduling.')
2175             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2176                     reason=msg)
2177         except (exception.FlavorDiskTooSmall,
2178                 exception.FlavorMemoryTooSmall,
2179                 exception.ImageNotActive,
2180                 exception.ImageUnacceptable,
2181                 exception.InvalidDiskInfo,
2182                 exception.InvalidDiskFormat,
2183                 cursive_exception.SignatureVerificationError,
2184                 exception.CertificateValidationFailed,
2185                 exception.VolumeEncryptionNotSupported,
2186                 exception.InvalidInput,
2187                 # TODO(mriedem): We should be validating RequestedVRamTooHigh
2188                 # in the API during server create and rebuild.
2189                 exception.RequestedVRamTooHigh) as e:
2190             self._notify_about_instance_usage(context, instance,
2191                     'create.error', fault=e)
2192             tb = traceback.format_exc()
2193             compute_utils.notify_about_instance_create(
2194                     context, instance, self.host,
2195                     phase=fields.NotificationPhase.ERROR, exception=e,
2196                     bdms=block_device_mapping, tb=tb)
2197             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2198                     reason=e.format_message())
2199         except Exception as e:
2200             self._notify_about_instance_usage(context, instance,
2201                     'create.error', fault=e)
2202             tb = traceback.format_exc()
2203             compute_utils.notify_about_instance_create(
2204                     context, instance, self.host,
2205                     phase=fields.NotificationPhase.ERROR, exception=e,
2206                     bdms=block_device_mapping, tb=tb)
2207             raise exception.RescheduledException(
2208                     instance_uuid=instance.uuid, reason=six.text_type(e))
2209 
2210         # NOTE(alaski): This is only useful during reschedules, remove it now.
2211         instance.system_metadata.pop('network_allocated', None)
2212 
2213         # If CONF.default_access_ip_network_name is set, grab the
2214         # corresponding network and set the access ip values accordingly.
2215         network_name = CONF.default_access_ip_network_name
2216         if (network_name and not instance.access_ip_v4 and
2217                 not instance.access_ip_v6):
2218             # Note that when there are multiple ips to choose from, an
2219             # arbitrary one will be chosen.
2220             for vif in network_info:
2221                 if vif['network']['label'] == network_name:
2222                     for ip in vif.fixed_ips():
2223                         if not instance.access_ip_v4 and ip['version'] == 4:
2224                             instance.access_ip_v4 = ip['address']
2225                         if not instance.access_ip_v6 and ip['version'] == 6:
2226                             instance.access_ip_v6 = ip['address']
2227                     break
2228 
2229         self._update_instance_after_spawn(context, instance)
2230 
2231         try:
2232             instance.save(expected_task_state=task_states.SPAWNING)
2233         except (exception.InstanceNotFound,
2234                 exception.UnexpectedDeletingTaskStateError) as e:
2235             with excutils.save_and_reraise_exception():
2236                 self._notify_about_instance_usage(context, instance,
2237                     'create.error', fault=e)
2238                 tb = traceback.format_exc()
2239                 compute_utils.notify_about_instance_create(
2240                     context, instance, self.host,
2241                     phase=fields.NotificationPhase.ERROR, exception=e,
2242                     bdms=block_device_mapping, tb=tb)
2243 
2244         self._update_scheduler_instance_info(context, instance)
2245         self._notify_about_instance_usage(context, instance, 'create.end',
2246                 extra_usage_info={'message': _('Success')},
2247                 network_info=network_info)
2248         compute_utils.notify_about_instance_create(context, instance,
2249                 self.host, phase=fields.NotificationPhase.END,
2250                 bdms=block_device_mapping)
2251 
2252     @contextlib.contextmanager
2253     def _build_resources(self, context, instance, requested_networks,
2254                          security_groups, image_meta, block_device_mapping):
2255         resources = {}
2256         network_info = None
2257         try:
2258             LOG.debug('Start building networks asynchronously for instance.',
2259                       instance=instance)
2260             network_info = self._build_networks_for_instance(context, instance,
2261                     requested_networks, security_groups)
2262             resources['network_info'] = network_info
2263         except (exception.InstanceNotFound,
2264                 exception.UnexpectedDeletingTaskStateError):
2265             raise
2266         except exception.UnexpectedTaskStateError as e:
2267             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2268                     reason=e.format_message())
2269         except Exception:
2270             # Because this allocation is async any failures are likely to occur
2271             # when the driver accesses network_info during spawn().
2272             LOG.exception('Failed to allocate network(s)',
2273                           instance=instance)
2274             msg = _('Failed to allocate the network(s), not rescheduling.')
2275             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2276                     reason=msg)
2277 
2278         try:
2279             # Perform any driver preparation work for the driver.
2280             self.driver.prepare_for_spawn(instance)
2281 
2282             # Depending on a virt driver, some network configuration is
2283             # necessary before preparing block devices.
2284             self.driver.prepare_networks_before_block_device_mapping(
2285                 instance, network_info)
2286 
2287             # Verify that all the BDMs have a device_name set and assign a
2288             # default to the ones missing it with the help of the driver.
2289             self._default_block_device_names(instance, image_meta,
2290                                              block_device_mapping)
2291 
2292             LOG.debug('Start building block device mappings for instance.',
2293                       instance=instance)
2294             instance.vm_state = vm_states.BUILDING
2295             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2296             instance.save()
2297 
2298             block_device_info = self._prep_block_device(context, instance,
2299                     block_device_mapping)
2300             resources['block_device_info'] = block_device_info
2301         except (exception.InstanceNotFound,
2302                 exception.UnexpectedDeletingTaskStateError):
2303             with excutils.save_and_reraise_exception():
2304                 # Make sure the async call finishes
2305                 if network_info is not None:
2306                     network_info.wait(do_raise=False)
2307                     self.driver.clean_networks_preparation(instance,
2308                                                            network_info)
2309                 self.driver.failed_spawn_cleanup(instance)
2310         except (exception.UnexpectedTaskStateError,
2311                 exception.OverQuota, exception.InvalidBDM) as e:
2312             # Make sure the async call finishes
2313             if network_info is not None:
2314                 network_info.wait(do_raise=False)
2315                 self.driver.clean_networks_preparation(instance, network_info)
2316             self.driver.failed_spawn_cleanup(instance)
2317             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2318                     reason=e.format_message())
2319         except Exception:
2320             LOG.exception('Failure prepping block device',
2321                           instance=instance)
2322             # Make sure the async call finishes
2323             if network_info is not None:
2324                 network_info.wait(do_raise=False)
2325                 self.driver.clean_networks_preparation(instance, network_info)
2326             self.driver.failed_spawn_cleanup(instance)
2327             msg = _('Failure prepping block device.')
2328             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2329                     reason=msg)
2330 
2331         try:
2332             resources['allocations'] = (
2333                 self.reportclient.get_allocations_for_consumer(context,
2334                                                                instance.uuid))
2335         except Exception:
2336             LOG.exception('Failure retrieving placement allocations',
2337                           instance=instance)
2338             # Make sure the async call finishes
2339             if network_info is not None:
2340                 network_info.wait(do_raise=False)
2341             self.driver.failed_spawn_cleanup(instance)
2342             msg = _('Failure retrieving placement allocations')
2343             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2344                                                 reason=msg)
2345 
2346         try:
2347             yield resources
2348         except Exception as exc:
2349             with excutils.save_and_reraise_exception() as ctxt:
2350                 if not isinstance(exc, (
2351                         exception.InstanceNotFound,
2352                         exception.UnexpectedDeletingTaskStateError)):
2353                     LOG.exception('Instance failed to spawn',
2354                                   instance=instance)
2355                 # Make sure the async call finishes
2356                 if network_info is not None:
2357                     network_info.wait(do_raise=False)
2358                 # if network_info is empty we're likely here because of
2359                 # network allocation failure. Since nothing can be reused on
2360                 # rescheduling it's better to deallocate network to eliminate
2361                 # the chance of orphaned ports in neutron
2362                 deallocate_networks = False if network_info else True
2363                 try:
2364                     self._shutdown_instance(context, instance,
2365                             block_device_mapping, requested_networks,
2366                             try_deallocate_networks=deallocate_networks)
2367                 except Exception as exc2:
2368                     ctxt.reraise = False
2369                     LOG.warning('Could not clean up failed build,'
2370                                 ' not rescheduling. Error: %s',
2371                                 six.text_type(exc2))
2372                     raise exception.BuildAbortException(
2373                             instance_uuid=instance.uuid,
2374                             reason=six.text_type(exc))
2375 
2376     def _cleanup_allocated_networks(self, context, instance,
2377             requested_networks):
2378         try:
2379             self._deallocate_network(context, instance, requested_networks)
2380         except Exception:
2381             LOG.exception('Failed to deallocate networks', instance=instance)
2382             return
2383 
2384         instance.system_metadata['network_allocated'] = 'False'
2385         try:
2386             instance.save()
2387         except exception.InstanceNotFound:
2388             # NOTE(alaski): It's possible that we're cleaning up the networks
2389             # because the instance was deleted.  If that's the case then this
2390             # exception will be raised by instance.save()
2391             pass
2392 
2393     def _try_deallocate_network(self, context, instance,
2394                                 requested_networks=None):
2395 
2396         # During auto-scale cleanup, we could be deleting a large number
2397         # of servers at the same time and overloading parts of the system,
2398         # so we retry a few times in case of connection failures to the
2399         # networking service.
2400         @loopingcall.RetryDecorator(
2401             max_retry_count=3, inc_sleep_time=2, max_sleep_time=12,
2402             exceptions=(keystone_exception.connection.ConnectFailure,))
2403         def _deallocate_network_with_retries():
2404             try:
2405                 self._deallocate_network(
2406                     context, instance, requested_networks)
2407             except keystone_exception.connection.ConnectFailure as e:
2408                 # Provide a warning that something is amiss.
2409                 with excutils.save_and_reraise_exception():
2410                     LOG.warning('Failed to deallocate network for instance; '
2411                                 'retrying. Error: %s', six.text_type(e),
2412                                 instance=instance)
2413 
2414         try:
2415             # tear down allocated network structure
2416             _deallocate_network_with_retries()
2417         except Exception as ex:
2418             with excutils.save_and_reraise_exception():
2419                 LOG.error('Failed to deallocate network for instance. '
2420                           'Error: %s', ex, instance=instance)
2421                 self._set_instance_obj_error_state(context, instance)
2422 
2423     def _get_power_off_values(self, context, instance, clean_shutdown):
2424         """Get the timing configuration for powering down this instance."""
2425         if clean_shutdown:
2426             timeout = compute_utils.get_value_from_system_metadata(instance,
2427                           key='image_os_shutdown_timeout', type=int,
2428                           default=CONF.shutdown_timeout)
2429             retry_interval = CONF.compute.shutdown_retry_interval
2430         else:
2431             timeout = 0
2432             retry_interval = 0
2433 
2434         return timeout, retry_interval
2435 
2436     def _power_off_instance(self, context, instance, clean_shutdown=True):
2437         """Power off an instance on this host."""
2438         timeout, retry_interval = self._get_power_off_values(context,
2439                                         instance, clean_shutdown)
2440         self.driver.power_off(instance, timeout, retry_interval)
2441 
2442     def _shutdown_instance(self, context, instance,
2443                            bdms, requested_networks=None, notify=True,
2444                            try_deallocate_networks=True):
2445         """Shutdown an instance on this host.
2446 
2447         :param:context: security context
2448         :param:instance: a nova.objects.Instance object
2449         :param:bdms: the block devices for the instance to be torn
2450                      down
2451         :param:requested_networks: the networks on which the instance
2452                                    has ports
2453         :param:notify: true if a final usage notification should be
2454                        emitted
2455         :param:try_deallocate_networks: false if we should avoid
2456                                         trying to teardown networking
2457         """
2458         context = context.elevated()
2459         LOG.info('Terminating instance', instance=instance)
2460 
2461         if notify:
2462             self._notify_about_instance_usage(context, instance,
2463                                               "shutdown.start")
2464             compute_utils.notify_about_instance_action(context, instance,
2465                     self.host, action=fields.NotificationAction.SHUTDOWN,
2466                     phase=fields.NotificationPhase.START, bdms=bdms)
2467 
2468         network_info = instance.get_network_info()
2469 
2470         # NOTE(vish) get bdms before destroying the instance
2471         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2472         block_device_info = self._get_instance_block_device_info(
2473             context, instance, bdms=bdms)
2474 
2475         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2476         #                want to keep ip allocated for certain failures
2477         try:
2478             LOG.debug('Start destroying the instance on the hypervisor.',
2479                       instance=instance)
2480             with timeutils.StopWatch() as timer:
2481                 self.driver.destroy(context, instance, network_info,
2482                                     block_device_info)
2483             LOG.info('Took %0.2f seconds to destroy the instance on the '
2484                      'hypervisor.', timer.elapsed(), instance=instance)
2485         except exception.InstancePowerOffFailure:
2486             # if the instance can't power off, don't release the ip
2487             with excutils.save_and_reraise_exception():
2488                 pass
2489         except Exception:
2490             with excutils.save_and_reraise_exception():
2491                 # deallocate ip and fail without proceeding to
2492                 # volume api calls, preserving current behavior
2493                 if try_deallocate_networks:
2494                     self._try_deallocate_network(context, instance,
2495                                                  requested_networks)
2496 
2497         if try_deallocate_networks:
2498             self._try_deallocate_network(context, instance, requested_networks)
2499 
2500         timer.restart()
2501         try:
2502             self._terminate_volume_connections(context, instance, vol_bdms)
2503         except exception.VolumeAttachmentNotFound as exc:
2504             LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2505                       instance=instance)
2506         except exception.DiskNotFound as exc:
2507             LOG.debug('Ignoring DiskNotFound: %s', exc,
2508                       instance=instance)
2509         except exception.VolumeNotFound as exc:
2510             LOG.debug('Ignoring VolumeNotFound: %s', exc,
2511                       instance=instance)
2512         except (cinder_exception.EndpointNotFound,
2513                 keystone_exception.EndpointNotFound) as exc:
2514             LOG.warning('Ignoring EndpointNotFound for '
2515                         'volume %(volume_id)s: %(exc)s',
2516                         {'exc': exc, 'volume_id': bdm.volume_id},
2517                         instance=instance)
2518         except cinder_exception.ClientException as exc:
2519             LOG.warning('Ignoring unknown cinder exception for '
2520                         'volume %(volume_id)s: %(exc)s',
2521                         {'exc': exc, 'volume_id': bdm.volume_id},
2522                         instance=instance)
2523         except Exception as exc:
2524             LOG.warning('Ignoring unknown exception for '
2525                         'volume %(volume_id)s: %(exc)s',
2526                         {'exc': exc, 'volume_id': bdm.volume_id},
2527                         instance=instance)
2528         if vol_bdms:
2529             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2530                      'for instance.',
2531                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2532                      instance=instance)
2533 
2534         if notify:
2535             self._notify_about_instance_usage(context, instance,
2536                                               "shutdown.end")
2537             compute_utils.notify_about_instance_action(context, instance,
2538                     self.host, action=fields.NotificationAction.SHUTDOWN,
2539                     phase=fields.NotificationPhase.END, bdms=bdms)
2540 
2541     def _cleanup_volumes(self, context, instance, bdms, raise_exc=True,
2542                          detach=True):
2543         exc_info = None
2544         for bdm in bdms:
2545             if detach and bdm.volume_id:
2546                 try:
2547                     LOG.debug("Detaching volume: %s", bdm.volume_id,
2548                               instance_uuid=instance.uuid)
2549                     destroy = bdm.delete_on_termination
2550                     self._detach_volume(context, bdm, instance,
2551                                         destroy_bdm=destroy)
2552                 except Exception as exc:
2553                     exc_info = sys.exc_info()
2554                     LOG.warning('Failed to detach volume: %(volume_id)s '
2555                                 'due to %(exc)s',
2556                                 {'volume_id': bdm.volume_id, 'exc': exc})
2557 
2558             if bdm.volume_id and bdm.delete_on_termination:
2559                 try:
2560                     LOG.debug("Deleting volume: %s", bdm.volume_id,
2561                               instance_uuid=instance.uuid)
2562                     self.volume_api.delete(context, bdm.volume_id)
2563                 except Exception as exc:
2564                     exc_info = sys.exc_info()
2565                     LOG.warning('Failed to delete volume: %(volume_id)s '
2566                                 'due to %(exc)s',
2567                                 {'volume_id': bdm.volume_id, 'exc': exc})
2568         if exc_info is not None and raise_exc:
2569             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2570 
2571     @hooks.add_hook("delete_instance")
2572     def _delete_instance(self, context, instance, bdms):
2573         """Delete an instance on this host.
2574 
2575         :param context: nova request context
2576         :param instance: nova.objects.instance.Instance object
2577         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2578         """
2579         events = self.instance_events.clear_events_for_instance(instance)
2580         if events:
2581             LOG.debug('Events pending at deletion: %(events)s',
2582                       {'events': ','.join(events.keys())},
2583                       instance=instance)
2584         self._notify_about_instance_usage(context, instance,
2585                                           "delete.start")
2586         compute_utils.notify_about_instance_action(context, instance,
2587                 self.host, action=fields.NotificationAction.DELETE,
2588                 phase=fields.NotificationPhase.START, bdms=bdms)
2589 
2590         self._shutdown_instance(context, instance, bdms)
2591 
2592         # NOTE(vish): We have already deleted the instance, so we have
2593         #             to ignore problems cleaning up the volumes. It
2594         #             would be nice to let the user know somehow that
2595         #             the volume deletion failed, but it is not
2596         #             acceptable to have an instance that can not be
2597         #             deleted. Perhaps this could be reworked in the
2598         #             future to set an instance fault the first time
2599         #             and to only ignore the failure if the instance
2600         #             is already in ERROR.
2601 
2602         # NOTE(ameeda): The volumes already detached during the above
2603         #               _shutdown_instance() call and this is why
2604         #               detach is not requested from _cleanup_volumes()
2605         #               in this case
2606 
2607         self._cleanup_volumes(context, instance, bdms,
2608                 raise_exc=False, detach=False)
2609         # if a delete task succeeded, always update vm state and task
2610         # state without expecting task state to be DELETING
2611         instance.vm_state = vm_states.DELETED
2612         instance.task_state = None
2613         instance.power_state = power_state.NOSTATE
2614         instance.terminated_at = timeutils.utcnow()
2615         instance.save()
2616         instance.destroy()
2617 
2618         self._complete_deletion(context,
2619                                 instance,
2620                                 bdms)
2621 
2622     @wrap_exception()
2623     @reverts_task_state
2624     @wrap_instance_event(prefix='compute')
2625     @wrap_instance_fault
2626     def terminate_instance(self, context, instance, bdms):
2627         """Terminate an instance on this host."""
2628         @utils.synchronized(instance.uuid)
2629         def do_terminate_instance(instance, bdms):
2630             # NOTE(mriedem): If we are deleting the instance while it was
2631             # booting from volume, we could be racing with a database update of
2632             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2633             # to compute here, the BDMs may be stale at this point. So check
2634             # for any volume BDMs that don't have volume_id set and if we
2635             # detect that, we need to refresh the BDM list before proceeding.
2636             # TODO(mriedem): Move this into _delete_instance and make the bdms
2637             # parameter optional.
2638             for bdm in list(bdms):
2639                 if bdm.is_volume and not bdm.volume_id:
2640                     LOG.debug('There are potentially stale BDMs during '
2641                               'delete, refreshing the BlockDeviceMappingList.',
2642                               instance=instance)
2643                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2644                         context, instance.uuid)
2645                     break
2646             try:
2647                 self._delete_instance(context, instance, bdms)
2648             except exception.InstanceNotFound:
2649                 LOG.info("Instance disappeared during terminate",
2650                          instance=instance)
2651             except Exception:
2652                 # As we're trying to delete always go to Error if something
2653                 # goes wrong that _delete_instance can't handle.
2654                 with excutils.save_and_reraise_exception():
2655                     LOG.exception('Setting instance vm_state to ERROR',
2656                                   instance=instance)
2657                     self._set_instance_obj_error_state(context, instance)
2658 
2659         do_terminate_instance(instance, bdms)
2660 
2661     # NOTE(johannes): This is probably better named power_off_instance
2662     # so it matches the driver method, but because of other issues, we
2663     # can't use that name in grizzly.
2664     @wrap_exception()
2665     @reverts_task_state
2666     @wrap_instance_event(prefix='compute')
2667     @wrap_instance_fault
2668     def stop_instance(self, context, instance, clean_shutdown):
2669         """Stopping an instance on this host."""
2670 
2671         @utils.synchronized(instance.uuid)
2672         def do_stop_instance():
2673             current_power_state = self._get_power_state(context, instance)
2674             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2675                       'current task_state: %(task_state)s, current DB '
2676                       'power_state: %(db_power_state)s, current VM '
2677                       'power_state: %(current_power_state)s',
2678                       {'vm_state': instance.vm_state,
2679                        'task_state': instance.task_state,
2680                        'db_power_state': instance.power_state,
2681                        'current_power_state': current_power_state},
2682                       instance_uuid=instance.uuid)
2683 
2684             # NOTE(mriedem): If the instance is already powered off, we are
2685             # possibly tearing down and racing with other operations, so we can
2686             # expect the task_state to be None if something else updates the
2687             # instance and we're not locking it.
2688             expected_task_state = [task_states.POWERING_OFF]
2689             # The list of power states is from _sync_instance_power_state.
2690             if current_power_state in (power_state.NOSTATE,
2691                                        power_state.SHUTDOWN,
2692                                        power_state.CRASHED):
2693                 LOG.info('Instance is already powered off in the '
2694                          'hypervisor when stop is called.',
2695                          instance=instance)
2696                 expected_task_state.append(None)
2697 
2698             self._notify_about_instance_usage(context, instance,
2699                                               "power_off.start")
2700 
2701             compute_utils.notify_about_instance_action(context, instance,
2702                         self.host, action=fields.NotificationAction.POWER_OFF,
2703                         phase=fields.NotificationPhase.START)
2704 
2705             self._power_off_instance(context, instance, clean_shutdown)
2706             instance.power_state = self._get_power_state(context, instance)
2707             instance.vm_state = vm_states.STOPPED
2708             instance.task_state = None
2709             instance.save(expected_task_state=expected_task_state)
2710             self._notify_about_instance_usage(context, instance,
2711                                               "power_off.end")
2712 
2713             compute_utils.notify_about_instance_action(context, instance,
2714                         self.host, action=fields.NotificationAction.POWER_OFF,
2715                         phase=fields.NotificationPhase.END)
2716 
2717         do_stop_instance()
2718 
2719     def _power_on(self, context, instance):
2720         network_info = self.network_api.get_instance_nw_info(context, instance)
2721         block_device_info = self._get_instance_block_device_info(context,
2722                                                                  instance)
2723         self.driver.power_on(context, instance,
2724                              network_info,
2725                              block_device_info)
2726 
2727     def _delete_snapshot_of_shelved_instance(self, context, instance,
2728                                              snapshot_id):
2729         """Delete snapshot of shelved instance."""
2730         try:
2731             self.image_api.delete(context, snapshot_id)
2732         except (exception.ImageNotFound,
2733                 exception.ImageNotAuthorized) as exc:
2734             LOG.warning("Failed to delete snapshot "
2735                         "from shelved instance (%s).",
2736                         exc.format_message(), instance=instance)
2737         except Exception:
2738             LOG.exception("Something wrong happened when trying to "
2739                           "delete snapshot from shelved instance.",
2740                           instance=instance)
2741 
2742     # NOTE(johannes): This is probably better named power_on_instance
2743     # so it matches the driver method, but because of other issues, we
2744     # can't use that name in grizzly.
2745     @wrap_exception()
2746     @reverts_task_state
2747     @wrap_instance_event(prefix='compute')
2748     @wrap_instance_fault
2749     def start_instance(self, context, instance):
2750         """Starting an instance on this host."""
2751         self._notify_about_instance_usage(context, instance, "power_on.start")
2752         compute_utils.notify_about_instance_action(context, instance,
2753             self.host, action=fields.NotificationAction.POWER_ON,
2754             phase=fields.NotificationPhase.START)
2755         self._power_on(context, instance)
2756         instance.power_state = self._get_power_state(context, instance)
2757         instance.vm_state = vm_states.ACTIVE
2758         instance.task_state = None
2759 
2760         # Delete an image(VM snapshot) for a shelved instance
2761         snapshot_id = instance.system_metadata.get('shelved_image_id')
2762         if snapshot_id:
2763             self._delete_snapshot_of_shelved_instance(context, instance,
2764                                                       snapshot_id)
2765 
2766         # Delete system_metadata for a shelved instance
2767         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2768 
2769         instance.save(expected_task_state=task_states.POWERING_ON)
2770         self._notify_about_instance_usage(context, instance, "power_on.end")
2771         compute_utils.notify_about_instance_action(context, instance,
2772             self.host, action=fields.NotificationAction.POWER_ON,
2773             phase=fields.NotificationPhase.END)
2774 
2775     @messaging.expected_exceptions(NotImplementedError,
2776                                    exception.TriggerCrashDumpNotSupported,
2777                                    exception.InstanceNotRunning)
2778     @wrap_exception()
2779     @wrap_instance_event(prefix='compute')
2780     @wrap_instance_fault
2781     def trigger_crash_dump(self, context, instance):
2782         """Trigger crash dump in an instance."""
2783 
2784         self._notify_about_instance_usage(context, instance,
2785                                           "trigger_crash_dump.start")
2786         compute_utils.notify_about_instance_action(context, instance,
2787                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2788                 phase=fields.NotificationPhase.START)
2789 
2790         # This method does not change task_state and power_state because the
2791         # effect of a trigger depends on user's configuration.
2792         self.driver.trigger_crash_dump(instance)
2793 
2794         self._notify_about_instance_usage(context, instance,
2795                                           "trigger_crash_dump.end")
2796         compute_utils.notify_about_instance_action(context, instance,
2797                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2798                 phase=fields.NotificationPhase.END)
2799 
2800     @wrap_exception()
2801     @reverts_task_state
2802     @wrap_instance_event(prefix='compute')
2803     @wrap_instance_fault
2804     def soft_delete_instance(self, context, instance):
2805         """Soft delete an instance on this host."""
2806         with compute_utils.notify_about_instance_delete(
2807                 self.notifier, context, instance, 'soft_delete'):
2808             compute_utils.notify_about_instance_action(context, instance,
2809                 self.host, action=fields.NotificationAction.SOFT_DELETE,
2810                 phase=fields.NotificationPhase.START)
2811             try:
2812                 self.driver.soft_delete(instance)
2813             except NotImplementedError:
2814                 # Fallback to just powering off the instance if the
2815                 # hypervisor doesn't implement the soft_delete method
2816                 self.driver.power_off(instance)
2817             instance.power_state = self._get_power_state(context, instance)
2818             instance.vm_state = vm_states.SOFT_DELETED
2819             instance.task_state = None
2820             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2821             compute_utils.notify_about_instance_action(
2822                 context, instance, self.host,
2823                 action=fields.NotificationAction.SOFT_DELETE,
2824                 phase=fields.NotificationPhase.END)
2825 
2826     @wrap_exception()
2827     @reverts_task_state
2828     @wrap_instance_event(prefix='compute')
2829     @wrap_instance_fault
2830     def restore_instance(self, context, instance):
2831         """Restore a soft-deleted instance on this host."""
2832         self._notify_about_instance_usage(context, instance, "restore.start")
2833         compute_utils.notify_about_instance_action(context, instance,
2834             self.host, action=fields.NotificationAction.RESTORE,
2835             phase=fields.NotificationPhase.START)
2836         try:
2837             self.driver.restore(instance)
2838         except NotImplementedError:
2839             # Fallback to just powering on the instance if the hypervisor
2840             # doesn't implement the restore method
2841             self._power_on(context, instance)
2842         instance.power_state = self._get_power_state(context, instance)
2843         instance.vm_state = vm_states.ACTIVE
2844         instance.task_state = None
2845         instance.save(expected_task_state=task_states.RESTORING)
2846         self._notify_about_instance_usage(context, instance, "restore.end")
2847         compute_utils.notify_about_instance_action(context, instance,
2848             self.host, action=fields.NotificationAction.RESTORE,
2849             phase=fields.NotificationPhase.END)
2850 
2851     @staticmethod
2852     def _set_migration_status(migration, status):
2853         """Set the status, and guard against a None being passed in.
2854 
2855         This is useful as some of the compute RPC calls will not pass
2856         a migration object in older versions. The check can be removed when
2857         we move past 4.x major version of the RPC API.
2858         """
2859         if migration:
2860             migration.status = status
2861             migration.save()
2862 
2863     def _rebuild_default_impl(self, context, instance, image_meta,
2864                               injected_files, admin_password, allocations,
2865                               bdms, detach_block_devices, attach_block_devices,
2866                               network_info=None,
2867                               evacuate=False, block_device_info=None,
2868                               preserve_ephemeral=False):
2869         if preserve_ephemeral:
2870             # The default code path does not support preserving ephemeral
2871             # partitions.
2872             raise exception.PreserveEphemeralNotSupported()
2873 
2874         if evacuate:
2875             detach_block_devices(context, bdms)
2876         else:
2877             self._power_off_instance(context, instance, clean_shutdown=True)
2878             detach_block_devices(context, bdms)
2879             self.driver.destroy(context, instance,
2880                                 network_info=network_info,
2881                                 block_device_info=block_device_info)
2882 
2883         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2884         instance.save(expected_task_state=[task_states.REBUILDING])
2885 
2886         new_block_device_info = attach_block_devices(context, instance, bdms)
2887 
2888         instance.task_state = task_states.REBUILD_SPAWNING
2889         instance.save(
2890             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2891 
2892         with instance.mutated_migration_context():
2893             self.driver.spawn(context, instance, image_meta, injected_files,
2894                               admin_password, allocations,
2895                               network_info=network_info,
2896                               block_device_info=new_block_device_info)
2897 
2898     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
2899         tb = traceback.format_exc()
2900         self._notify_about_instance_usage(context, instance,
2901                                           'rebuild.error', fault=error)
2902         compute_utils.notify_about_instance_rebuild(
2903             context, instance, self.host,
2904             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms,
2905             tb=tb)
2906 
2907     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2908     @wrap_exception()
2909     @reverts_task_state
2910     @wrap_instance_event(prefix='compute')
2911     @wrap_instance_fault
2912     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2913                          injected_files, new_pass, orig_sys_metadata,
2914                          bdms, recreate, on_shared_storage,
2915                          preserve_ephemeral, migration,
2916                          scheduled_node, limits, request_spec):
2917         """Destroy and re-make this instance.
2918 
2919         A 'rebuild' effectively purges all existing data from the system and
2920         remakes the VM with given 'metadata' and 'personalities'.
2921 
2922         :param context: `nova.RequestContext` object
2923         :param instance: Instance object
2924         :param orig_image_ref: Original image_ref before rebuild
2925         :param image_ref: New image_ref for rebuild
2926         :param injected_files: Files to inject
2927         :param new_pass: password to set on rebuilt instance
2928         :param orig_sys_metadata: instance system metadata from pre-rebuild
2929         :param bdms: block-device-mappings to use for rebuild
2930         :param recreate: True if the instance is being recreated (e.g. the
2931             hypervisor it was on failed) - cleanup of old state will be
2932             skipped.
2933         :param on_shared_storage: True if instance files on shared storage.
2934                                   If not provided then information from the
2935                                   driver will be used to decide if the instance
2936                                   files are available or not on the target host
2937         :param preserve_ephemeral: True if the default ephemeral storage
2938                                    partition must be preserved on rebuild
2939         :param migration: a Migration object if one was created for this
2940                           rebuild operation (if it's a part of evacuate)
2941         :param scheduled_node: A node of the host chosen by the scheduler. If a
2942                                host was specified by the user, this will be
2943                                None
2944         :param limits: Overcommit limits set by the scheduler. If a host was
2945                        specified by the user, this will be None
2946         :param request_spec: a RequestSpec object used to schedule the instance
2947 
2948         """
2949         # recreate=True means the instance is being evacuated from a failed
2950         # host to a new destination host (this host). The 'recreate' variable
2951         # name is confusing, so rename it to evacuate here at the top, which
2952         # is simpler than renaming a parameter in an RPC versioned method.
2953         evacuate = recreate
2954         context = context.elevated()
2955 
2956         if evacuate:
2957             LOG.info("Evacuating instance", instance=instance)
2958         else:
2959             LOG.info("Rebuilding instance", instance=instance)
2960 
2961         rt = self._get_resource_tracker()
2962         if evacuate:
2963             # This is an evacuation to a new host, so we need to perform a
2964             # resource claim.
2965             rebuild_claim = rt.rebuild_claim
2966         else:
2967             # This is a rebuild to the same host, so we don't need to make
2968             # a claim since the instance is already on this host.
2969             rebuild_claim = claims.NopClaim
2970 
2971         image_meta = {}
2972         if image_ref:
2973             image_meta = self.image_api.get(context, image_ref)
2974 
2975         # NOTE(mriedem): On an evacuate, we need to update
2976         # the instance's host and node properties to reflect it's
2977         # destination node for the evacuate.
2978         if not scheduled_node:
2979             if evacuate:
2980                 try:
2981                     compute_node = self._get_compute_info(context, self.host)
2982                     scheduled_node = compute_node.hypervisor_hostname
2983                 except exception.ComputeHostNotFound:
2984                     LOG.exception('Failed to get compute_info for %s',
2985                                   self.host)
2986             else:
2987                 scheduled_node = instance.node
2988 
2989         with self._error_out_instance_on_exception(context, instance):
2990             try:
2991                 claim_ctxt = rebuild_claim(
2992                     context, instance, scheduled_node,
2993                     limits=limits, image_meta=image_meta,
2994                     migration=migration)
2995                 self._do_rebuild_instance_with_claim(
2996                     claim_ctxt, context, instance, orig_image_ref,
2997                     image_ref, injected_files, new_pass, orig_sys_metadata,
2998                     bdms, evacuate, on_shared_storage, preserve_ephemeral,
2999                     migration, request_spec)
3000             except (exception.ComputeResourcesUnavailable,
3001                     exception.RescheduledException) as e:
3002                 if isinstance(e, exception.ComputeResourcesUnavailable):
3003                     LOG.debug("Could not rebuild instance on this host, not "
3004                               "enough resources available.", instance=instance)
3005                 else:
3006                     # RescheduledException is raised by the late server group
3007                     # policy check during evacuation if a parallel scheduling
3008                     # violated the policy.
3009                     # We catch the RescheduledException here but we don't have
3010                     # the plumbing to do an actual reschedule so we abort the
3011                     # operation.
3012                     LOG.debug("Could not rebuild instance on this host, "
3013                               "late server group check failed.",
3014                               instance=instance)
3015                 # NOTE(ndipanov): We just abort the build for now and leave a
3016                 # migration record for potential cleanup later
3017                 self._set_migration_status(migration, 'failed')
3018                 # Since the claim failed, we need to remove the allocation
3019                 # created against the destination node. Note that we can only
3020                 # get here when evacuating to a destination node. Rebuilding
3021                 # on the same host (not evacuate) uses the NopClaim which will
3022                 # not raise ComputeResourcesUnavailable.
3023                 rt.delete_allocation_for_evacuated_instance(
3024                     context, instance, scheduled_node, node_type='destination')
3025                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3026                 raise exception.BuildAbortException(
3027                     instance_uuid=instance.uuid, reason=e.format_message())
3028             except (exception.InstanceNotFound,
3029                     exception.UnexpectedDeletingTaskStateError) as e:
3030                 LOG.debug('Instance was deleted while rebuilding',
3031                           instance=instance)
3032                 self._set_migration_status(migration, 'failed')
3033                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3034             except Exception as e:
3035                 self._set_migration_status(migration, 'failed')
3036                 if evacuate or scheduled_node is not None:
3037                     rt.delete_allocation_for_evacuated_instance(
3038                         context, instance, scheduled_node,
3039                         node_type='destination')
3040                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3041                 raise
3042             else:
3043                 instance.apply_migration_context()
3044                 # NOTE (ndipanov): This save will now update the host and node
3045                 # attributes making sure that next RT pass is consistent since
3046                 # it will be based on the instance and not the migration DB
3047                 # entry.
3048                 instance.host = self.host
3049                 instance.node = scheduled_node
3050                 instance.save()
3051                 instance.drop_migration_context()
3052 
3053                 # NOTE (ndipanov): Mark the migration as done only after we
3054                 # mark the instance as belonging to this host.
3055                 self._set_migration_status(migration, 'done')
3056 
3057     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
3058         """Helper to avoid deep nesting in the top-level method."""
3059 
3060         with claim_context:
3061             self._do_rebuild_instance(*args, **kwargs)
3062 
3063     @staticmethod
3064     def _get_image_name(image_meta):
3065         if image_meta.obj_attr_is_set("name"):
3066             return image_meta.name
3067         else:
3068             return ''
3069 
3070     def _do_rebuild_instance(self, context, instance, orig_image_ref,
3071                              image_ref, injected_files, new_pass,
3072                              orig_sys_metadata, bdms, evacuate,
3073                              on_shared_storage, preserve_ephemeral,
3074                              migration, request_spec):
3075         orig_vm_state = instance.vm_state
3076 
3077         if evacuate:
3078             if request_spec:
3079                 # NOTE(gibi): Do a late check of server group policy as
3080                 # parallel scheduling could violate such policy. This will
3081                 # cause the evacuate to fail as rebuild does not implement
3082                 # reschedule.
3083                 hints = self._get_scheduler_hints({}, request_spec)
3084                 self._validate_instance_group_policy(context, instance, hints)
3085 
3086             if not self.driver.capabilities.get("supports_evacuate", False):
3087                 raise exception.InstanceEvacuateNotSupported
3088 
3089             self._check_instance_exists(context, instance)
3090 
3091             if on_shared_storage is None:
3092                 LOG.debug('on_shared_storage is not provided, using driver '
3093                           'information to decide if the instance needs to '
3094                           'be evacuated')
3095                 on_shared_storage = self.driver.instance_on_disk(instance)
3096 
3097             elif (on_shared_storage !=
3098                     self.driver.instance_on_disk(instance)):
3099                 # To cover case when admin expects that instance files are
3100                 # on shared storage, but not accessible and vice versa
3101                 raise exception.InvalidSharedStorage(
3102                         _("Invalid state of instance files on shared"
3103                             " storage"))
3104 
3105             if on_shared_storage:
3106                 LOG.info('disk on shared storage, evacuating using'
3107                          ' existing disk')
3108             else:
3109                 image_ref = orig_image_ref = instance.image_ref
3110                 LOG.info("disk not on shared storage, evacuating from:"
3111                          " '%s'", str(image_ref))
3112 
3113         if image_ref:
3114             image_meta = objects.ImageMeta.from_image_ref(
3115                 context, self.image_api, image_ref)
3116         else:
3117             image_meta = instance.image_meta
3118 
3119         # We check trusted certs capabilities for both evacuate (rebuild on
3120         # another host) and rebuild (rebuild on the same host) because for
3121         # evacuate we need to make sure an instance with trusted certs can
3122         # have the image verified with those certs during rebuild, and for
3123         # rebuild we could be rebuilding a server that started out with no
3124         # trusted certs on this host, and then was rebuilt with trusted certs
3125         # for a new image, in which case we need to validate that new image
3126         # with the trusted certs during the rebuild.
3127         self._check_trusted_certs(instance)
3128 
3129         # This instance.exists message should contain the original
3130         # image_ref, not the new one.  Since the DB has been updated
3131         # to point to the new one... we have to override it.
3132         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
3133                                                                context)
3134         extra_usage_info = {'image_ref_url': orig_image_ref_url}
3135         compute_utils.notify_usage_exists(
3136                 self.notifier, context, instance, self.host,
3137                 current_period=True, system_metadata=orig_sys_metadata,
3138                 extra_usage_info=extra_usage_info)
3139 
3140         # This message should contain the new image_ref
3141         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
3142         self._notify_about_instance_usage(context, instance,
3143                 "rebuild.start", extra_usage_info=extra_usage_info)
3144         # NOTE: image_name is not included in the versioned notification
3145         # because we already provide the image_uuid in the notification
3146         # payload and the image details can be looked up via the uuid.
3147         compute_utils.notify_about_instance_rebuild(
3148             context, instance, self.host,
3149             phase=fields.NotificationPhase.START,
3150             bdms=bdms)
3151 
3152         instance.power_state = self._get_power_state(context, instance)
3153         instance.task_state = task_states.REBUILDING
3154         instance.save(expected_task_state=[task_states.REBUILDING])
3155 
3156         if evacuate:
3157             self.network_api.setup_networks_on_host(
3158                     context, instance, self.host)
3159             # For nova-network this is needed to move floating IPs
3160             # For neutron this updates the host in the port binding
3161             # TODO(cfriesen): this network_api call and the one above
3162             # are so similar, we should really try to unify them.
3163             self.network_api.setup_instance_network_on_host(
3164                     context, instance, self.host, migration)
3165 
3166         allocations = self.reportclient.get_allocations_for_consumer(
3167             context, instance.uuid)
3168 
3169         network_info = instance.get_network_info()
3170         if bdms is None:
3171             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3172                     context, instance.uuid)
3173 
3174         block_device_info = \
3175             self._get_instance_block_device_info(
3176                     context, instance, bdms=bdms)
3177 
3178         def detach_block_devices(context, bdms):
3179             for bdm in bdms:
3180                 if bdm.is_volume:
3181                     # NOTE (ildikov): Having the attachment_id set in the BDM
3182                     # means that it's the new Cinder attach/detach flow
3183                     # (available from v3.44). In that case we explicitly
3184                     # attach and detach the volumes through attachment level
3185                     # operations. In this scenario _detach_volume will delete
3186                     # the existing attachment which would make the volume
3187                     # status change to 'available' if we don't pre-create
3188                     # another empty attachment before deleting the old one.
3189                     attachment_id = None
3190                     if bdm.attachment_id:
3191                         attachment_id = self.volume_api.attachment_create(
3192                             context, bdm['volume_id'], instance.uuid)['id']
3193                     self._detach_volume(context, bdm, instance,
3194                                         destroy_bdm=False)
3195                     if attachment_id:
3196                         bdm.attachment_id = attachment_id
3197                         bdm.save()
3198 
3199         files = self._decode_files(injected_files)
3200 
3201         kwargs = dict(
3202             context=context,
3203             instance=instance,
3204             image_meta=image_meta,
3205             injected_files=files,
3206             admin_password=new_pass,
3207             allocations=allocations,
3208             bdms=bdms,
3209             detach_block_devices=detach_block_devices,
3210             attach_block_devices=self._prep_block_device,
3211             block_device_info=block_device_info,
3212             network_info=network_info,
3213             preserve_ephemeral=preserve_ephemeral,
3214             evacuate=evacuate)
3215         try:
3216             with instance.mutated_migration_context():
3217                 self.driver.rebuild(**kwargs)
3218         except NotImplementedError:
3219             # NOTE(rpodolyaka): driver doesn't provide specialized version
3220             # of rebuild, fall back to the default implementation
3221             self._rebuild_default_impl(**kwargs)
3222         self._update_instance_after_spawn(context, instance)
3223         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3224 
3225         if orig_vm_state == vm_states.STOPPED:
3226             LOG.info("bringing vm to original state: '%s'",
3227                      orig_vm_state, instance=instance)
3228             instance.vm_state = vm_states.ACTIVE
3229             instance.task_state = task_states.POWERING_OFF
3230             instance.progress = 0
3231             instance.save()
3232             self.stop_instance(context, instance, False)
3233         # TODO(melwitt): We should clean up instance console tokens here in the
3234         # case of evacuate. The instance is on a new host and will need to
3235         # establish a new console connection.
3236         self._update_scheduler_instance_info(context, instance)
3237         self._notify_about_instance_usage(
3238                 context, instance, "rebuild.end",
3239                 network_info=network_info,
3240                 extra_usage_info=extra_usage_info)
3241         compute_utils.notify_about_instance_rebuild(
3242             context, instance, self.host,
3243             phase=fields.NotificationPhase.END,
3244             bdms=bdms)
3245 
3246     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3247                                      block_device_info):
3248         """Handle cases where the virt-layer had to detach non-working volumes
3249         in order to complete an operation.
3250         """
3251         for bdm in block_device_info['block_device_mapping']:
3252             if bdm.get('mount_device') in bad_devices:
3253                 try:
3254                     volume_id = bdm['connection_info']['data']['volume_id']
3255                 except KeyError:
3256                     continue
3257 
3258                 # NOTE(sirp): ideally we'd just call
3259                 # `compute_api.detach_volume` here but since that hits the
3260                 # DB directly, that's off limits from within the
3261                 # compute-manager.
3262                 #
3263                 # API-detach
3264                 LOG.info("Detaching from volume api: %s", volume_id)
3265                 self.volume_api.begin_detaching(context, volume_id)
3266 
3267                 # Manager-detach
3268                 self.detach_volume(context, volume_id, instance)
3269 
3270     @wrap_exception()
3271     @reverts_task_state
3272     @wrap_instance_event(prefix='compute')
3273     @wrap_instance_fault
3274     def reboot_instance(self, context, instance, block_device_info,
3275                         reboot_type):
3276         """Reboot an instance on this host."""
3277         # acknowledge the request made it to the manager
3278         if reboot_type == "SOFT":
3279             instance.task_state = task_states.REBOOT_PENDING
3280             expected_states = task_states.soft_reboot_states
3281         else:
3282             instance.task_state = task_states.REBOOT_PENDING_HARD
3283             expected_states = task_states.hard_reboot_states
3284 
3285         context = context.elevated()
3286         LOG.info("Rebooting instance", instance=instance)
3287 
3288         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3289             context, instance.uuid)
3290         block_device_info = self._get_instance_block_device_info(
3291             context, instance, bdms=bdms)
3292 
3293         network_info = self.network_api.get_instance_nw_info(context, instance)
3294 
3295         self._notify_about_instance_usage(context, instance, "reboot.start")
3296         compute_utils.notify_about_instance_action(
3297             context, instance, self.host,
3298             action=fields.NotificationAction.REBOOT,
3299             phase=fields.NotificationPhase.START,
3300             bdms=bdms
3301         )
3302 
3303         instance.power_state = self._get_power_state(context, instance)
3304         instance.save(expected_task_state=expected_states)
3305 
3306         if instance.power_state != power_state.RUNNING:
3307             state = instance.power_state
3308             running = power_state.RUNNING
3309             LOG.warning('trying to reboot a non-running instance:'
3310                         ' (state: %(state)s expected: %(running)s)',
3311                         {'state': state, 'running': running},
3312                         instance=instance)
3313 
3314         def bad_volumes_callback(bad_devices):
3315             self._handle_bad_volumes_detached(
3316                     context, instance, bad_devices, block_device_info)
3317 
3318         try:
3319             # Don't change it out of rescue mode
3320             if instance.vm_state == vm_states.RESCUED:
3321                 new_vm_state = vm_states.RESCUED
3322             else:
3323                 new_vm_state = vm_states.ACTIVE
3324             new_power_state = None
3325             if reboot_type == "SOFT":
3326                 instance.task_state = task_states.REBOOT_STARTED
3327                 expected_state = task_states.REBOOT_PENDING
3328             else:
3329                 instance.task_state = task_states.REBOOT_STARTED_HARD
3330                 expected_state = task_states.REBOOT_PENDING_HARD
3331             instance.save(expected_task_state=expected_state)
3332             self.driver.reboot(context, instance,
3333                                network_info,
3334                                reboot_type,
3335                                block_device_info=block_device_info,
3336                                bad_volumes_callback=bad_volumes_callback)
3337 
3338         except Exception as error:
3339             with excutils.save_and_reraise_exception() as ctxt:
3340                 exc_info = sys.exc_info()
3341                 # if the reboot failed but the VM is running don't
3342                 # put it into an error state
3343                 new_power_state = self._get_power_state(context, instance)
3344                 if new_power_state == power_state.RUNNING:
3345                     LOG.warning('Reboot failed but instance is running',
3346                                 instance=instance)
3347                     compute_utils.add_instance_fault_from_exc(context,
3348                             instance, error, exc_info)
3349                     self._notify_about_instance_usage(context, instance,
3350                             'reboot.error', fault=error)
3351                     tb = traceback.format_exc()
3352                     compute_utils.notify_about_instance_action(
3353                         context, instance, self.host,
3354                         action=fields.NotificationAction.REBOOT,
3355                         phase=fields.NotificationPhase.ERROR,
3356                         exception=error, bdms=bdms, tb=tb
3357                     )
3358                     ctxt.reraise = False
3359                 else:
3360                     LOG.error('Cannot reboot instance: %s', error,
3361                               instance=instance)
3362                     self._set_instance_obj_error_state(context, instance)
3363 
3364         if not new_power_state:
3365             new_power_state = self._get_power_state(context, instance)
3366         try:
3367             instance.power_state = new_power_state
3368             instance.vm_state = new_vm_state
3369             instance.task_state = None
3370             instance.save()
3371         except exception.InstanceNotFound:
3372             LOG.warning("Instance disappeared during reboot",
3373                         instance=instance)
3374 
3375         self._notify_about_instance_usage(context, instance, "reboot.end")
3376         compute_utils.notify_about_instance_action(
3377             context, instance, self.host,
3378             action=fields.NotificationAction.REBOOT,
3379             phase=fields.NotificationPhase.END,
3380             bdms=bdms
3381         )
3382 
3383     @delete_image_on_error
3384     def _do_snapshot_instance(self, context, image_id, instance):
3385         self._snapshot_instance(context, image_id, instance,
3386                                 task_states.IMAGE_BACKUP)
3387 
3388     @wrap_exception()
3389     @reverts_task_state
3390     @wrap_instance_event(prefix='compute')
3391     @wrap_instance_fault
3392     def backup_instance(self, context, image_id, instance, backup_type,
3393                         rotation):
3394         """Backup an instance on this host.
3395 
3396         :param backup_type: daily | weekly
3397         :param rotation: int representing how many backups to keep around
3398         """
3399         self._do_snapshot_instance(context, image_id, instance)
3400         self._rotate_backups(context, instance, backup_type, rotation)
3401 
3402     @wrap_exception()
3403     @reverts_task_state
3404     @wrap_instance_event(prefix='compute')
3405     @wrap_instance_fault
3406     @delete_image_on_error
3407     def snapshot_instance(self, context, image_id, instance):
3408         """Snapshot an instance on this host.
3409 
3410         :param context: security context
3411         :param image_id: glance.db.sqlalchemy.models.Image.Id
3412         :param instance: a nova.objects.instance.Instance object
3413         """
3414         # NOTE(dave-mcnally) the task state will already be set by the api
3415         # but if the compute manager has crashed/been restarted prior to the
3416         # request getting here the task state may have been cleared so we set
3417         # it again and things continue normally
3418         try:
3419             instance.task_state = task_states.IMAGE_SNAPSHOT
3420             instance.save(
3421                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3422         except exception.InstanceNotFound:
3423             # possibility instance no longer exists, no point in continuing
3424             LOG.debug("Instance not found, could not set state %s "
3425                       "for instance.",
3426                       task_states.IMAGE_SNAPSHOT, instance=instance)
3427             return
3428 
3429         except exception.UnexpectedDeletingTaskStateError:
3430             LOG.debug("Instance being deleted, snapshot cannot continue",
3431                       instance=instance)
3432             return
3433 
3434         self._snapshot_instance(context, image_id, instance,
3435                                 task_states.IMAGE_SNAPSHOT)
3436 
3437     def _snapshot_instance(self, context, image_id, instance,
3438                            expected_task_state):
3439         context = context.elevated()
3440 
3441         instance.power_state = self._get_power_state(context, instance)
3442         try:
3443             instance.save()
3444 
3445             LOG.info('instance snapshotting', instance=instance)
3446 
3447             if instance.power_state != power_state.RUNNING:
3448                 state = instance.power_state
3449                 running = power_state.RUNNING
3450                 LOG.warning('trying to snapshot a non-running instance: '
3451                             '(state: %(state)s expected: %(running)s)',
3452                             {'state': state, 'running': running},
3453                             instance=instance)
3454 
3455             self._notify_about_instance_usage(
3456                 context, instance, "snapshot.start")
3457             compute_utils.notify_about_instance_snapshot(context, instance,
3458                 self.host, phase=fields.NotificationPhase.START,
3459                 snapshot_image_id=image_id)
3460 
3461             def update_task_state(task_state,
3462                                   expected_state=expected_task_state):
3463                 instance.task_state = task_state
3464                 instance.save(expected_task_state=expected_state)
3465 
3466             with timeutils.StopWatch() as timer:
3467                 self.driver.snapshot(context, instance, image_id,
3468                                      update_task_state)
3469             LOG.info('Took %0.2f seconds to snapshot the instance on '
3470                      'the hypervisor.', timer.elapsed(), instance=instance)
3471 
3472             instance.task_state = None
3473             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3474 
3475             self._notify_about_instance_usage(context, instance,
3476                                               "snapshot.end")
3477             compute_utils.notify_about_instance_snapshot(context, instance,
3478                 self.host, phase=fields.NotificationPhase.END,
3479                 snapshot_image_id=image_id)
3480         except (exception.InstanceNotFound,
3481                 exception.UnexpectedDeletingTaskStateError):
3482             # the instance got deleted during the snapshot
3483             # Quickly bail out of here
3484             msg = 'Instance disappeared during snapshot'
3485             LOG.debug(msg, instance=instance)
3486             try:
3487                 image = self.image_api.get(context, image_id)
3488                 if image['status'] != 'active':
3489                     self.image_api.delete(context, image_id)
3490             except exception.ImageNotFound:
3491                 LOG.debug('Image not found during clean up %s', image_id)
3492             except Exception:
3493                 LOG.warning("Error while trying to clean up image %s",
3494                             image_id, instance=instance)
3495         except exception.ImageNotFound:
3496             instance.task_state = None
3497             instance.save()
3498             LOG.warning("Image not found during snapshot", instance=instance)
3499 
3500     def _post_interrupted_snapshot_cleanup(self, context, instance):
3501         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3502 
3503     @messaging.expected_exceptions(NotImplementedError)
3504     @wrap_exception()
3505     def volume_snapshot_create(self, context, instance, volume_id,
3506                                create_info):
3507         self.driver.volume_snapshot_create(context, instance, volume_id,
3508                                            create_info)
3509 
3510     @messaging.expected_exceptions(NotImplementedError)
3511     @wrap_exception()
3512     def volume_snapshot_delete(self, context, instance, volume_id,
3513                                snapshot_id, delete_info):
3514         self.driver.volume_snapshot_delete(context, instance, volume_id,
3515                                            snapshot_id, delete_info)
3516 
3517     @wrap_instance_fault
3518     def _rotate_backups(self, context, instance, backup_type, rotation):
3519         """Delete excess backups associated to an instance.
3520 
3521         Instances are allowed a fixed number of backups (the rotation number);
3522         this method deletes the oldest backups that exceed the rotation
3523         threshold.
3524 
3525         :param context: security context
3526         :param instance: Instance dict
3527         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3528         :param rotation: int representing how many backups to keep around;
3529             None if rotation shouldn't be used (as in the case of snapshots)
3530         """
3531         filters = {'property-image_type': 'backup',
3532                    'property-backup_type': backup_type,
3533                    'property-instance_uuid': instance.uuid}
3534 
3535         images = self.image_api.get_all(context, filters=filters,
3536                                         sort_key='created_at', sort_dir='desc')
3537         num_images = len(images)
3538         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3539                   {'num_images': num_images, 'rotation': rotation},
3540                   instance=instance)
3541 
3542         if num_images > rotation:
3543             # NOTE(sirp): this deletes all backups that exceed the rotation
3544             # limit
3545             excess = len(images) - rotation
3546             LOG.debug("Rotating out %d backups", excess,
3547                       instance=instance)
3548             for i in range(excess):
3549                 image = images.pop()
3550                 image_id = image['id']
3551                 LOG.debug("Deleting image %s", image_id,
3552                           instance=instance)
3553                 try:
3554                     self.image_api.delete(context, image_id)
3555                 except exception.ImageNotFound:
3556                     LOG.info("Failed to find image %(image_id)s to "
3557                              "delete", {'image_id': image_id},
3558                              instance=instance)
3559                 except (exception.ImageDeleteConflict, Exception) as exc:
3560                     LOG.info("Failed to delete image %(image_id)s during "
3561                              "deleting excess backups. "
3562                              "Continuing for next image.. %(exc)s",
3563                              {'image_id': image_id, 'exc': exc},
3564                              instance=instance)
3565 
3566     @wrap_exception()
3567     @reverts_task_state
3568     @wrap_instance_event(prefix='compute')
3569     @wrap_instance_fault
3570     def set_admin_password(self, context, instance, new_pass):
3571         """Set the root/admin password for an instance on this host.
3572 
3573         This is generally only called by API password resets after an
3574         image has been built.
3575 
3576         @param context: Nova auth context.
3577         @param instance: Nova instance object.
3578         @param new_pass: The admin password for the instance.
3579         """
3580 
3581         context = context.elevated()
3582         if new_pass is None:
3583             # Generate a random password
3584             new_pass = utils.generate_password()
3585 
3586         current_power_state = self._get_power_state(context, instance)
3587         expected_state = power_state.RUNNING
3588 
3589         if current_power_state != expected_state:
3590             instance.task_state = None
3591             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3592             _msg = _('instance %s is not running') % instance.uuid
3593             raise exception.InstancePasswordSetFailed(
3594                 instance=instance.uuid, reason=_msg)
3595 
3596         try:
3597             self.driver.set_admin_password(instance, new_pass)
3598             LOG.info("Admin password set", instance=instance)
3599             instance.task_state = None
3600             instance.save(
3601                 expected_task_state=task_states.UPDATING_PASSWORD)
3602         except exception.InstanceAgentNotEnabled:
3603             with excutils.save_and_reraise_exception():
3604                 LOG.debug('Guest agent is not enabled for the instance.',
3605                           instance=instance)
3606                 instance.task_state = None
3607                 instance.save(
3608                     expected_task_state=task_states.UPDATING_PASSWORD)
3609         except exception.SetAdminPasswdNotSupported:
3610             with excutils.save_and_reraise_exception():
3611                 LOG.info('set_admin_password is not supported '
3612                          'by this driver or guest instance.',
3613                          instance=instance)
3614                 instance.task_state = None
3615                 instance.save(
3616                     expected_task_state=task_states.UPDATING_PASSWORD)
3617         except NotImplementedError:
3618             LOG.warning('set_admin_password is not implemented '
3619                         'by this driver or guest instance.',
3620                         instance=instance)
3621             instance.task_state = None
3622             instance.save(
3623                 expected_task_state=task_states.UPDATING_PASSWORD)
3624             raise NotImplementedError(_('set_admin_password is not '
3625                                         'implemented by this driver or guest '
3626                                         'instance.'))
3627         except exception.UnexpectedTaskStateError:
3628             # interrupted by another (most likely delete) task
3629             # do not retry
3630             raise
3631         except Exception:
3632             # Catch all here because this could be anything.
3633             LOG.exception('set_admin_password failed', instance=instance)
3634             self._set_instance_obj_error_state(context, instance)
3635             # We create a new exception here so that we won't
3636             # potentially reveal password information to the
3637             # API caller.  The real exception is logged above
3638             _msg = _('error setting admin password')
3639             raise exception.InstancePasswordSetFailed(
3640                 instance=instance.uuid, reason=_msg)
3641 
3642     @wrap_exception()
3643     @reverts_task_state
3644     @wrap_instance_fault
3645     def inject_file(self, context, path, file_contents, instance):
3646         """Write a file to the specified path in an instance on this host."""
3647         # NOTE(russellb) Remove this method, as well as the underlying virt
3648         # driver methods, when the compute rpc interface is bumped to 4.x
3649         # as it is no longer used.
3650         context = context.elevated()
3651         current_power_state = self._get_power_state(context, instance)
3652         expected_state = power_state.RUNNING
3653         if current_power_state != expected_state:
3654             LOG.warning('trying to inject a file into a non-running '
3655                         '(state: %(current_state)s expected: '
3656                         '%(expected_state)s)',
3657                         {'current_state': current_power_state,
3658                          'expected_state': expected_state},
3659                         instance=instance)
3660         LOG.info('injecting file to %s', path, instance=instance)
3661         self.driver.inject_file(instance, path, file_contents)
3662 
3663     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3664         """Determine what image should be used to boot the rescue VM."""
3665         # 1. If rescue_image_ref is passed in, use that for rescue.
3666         # 2. Else, use the base image associated with instance's current image.
3667         #       The idea here is to provide the customer with a rescue
3668         #       environment which they are familiar with.
3669         #       So, if they built their instance off of a Debian image,
3670         #       their rescue VM will also be Debian.
3671         # 3. As a last resort, use instance's current image.
3672         if not rescue_image_ref:
3673             system_meta = utils.instance_sys_meta(instance)
3674             rescue_image_ref = system_meta.get('image_base_image_ref')
3675 
3676         if not rescue_image_ref:
3677             LOG.warning('Unable to find a different image to use for '
3678                         'rescue VM, using instance\'s current image',
3679                         instance=instance)
3680             rescue_image_ref = instance.image_ref
3681 
3682         return objects.ImageMeta.from_image_ref(
3683             context, self.image_api, rescue_image_ref)
3684 
3685     @wrap_exception()
3686     @reverts_task_state
3687     @wrap_instance_event(prefix='compute')
3688     @wrap_instance_fault
3689     def rescue_instance(self, context, instance, rescue_password,
3690                         rescue_image_ref, clean_shutdown):
3691         context = context.elevated()
3692         LOG.info('Rescuing', instance=instance)
3693 
3694         admin_password = (rescue_password if rescue_password else
3695                       utils.generate_password())
3696 
3697         network_info = self.network_api.get_instance_nw_info(context, instance)
3698 
3699         rescue_image_meta = self._get_rescue_image(context, instance,
3700                                                    rescue_image_ref)
3701 
3702         extra_usage_info = {'rescue_image_name':
3703                             self._get_image_name(rescue_image_meta)}
3704         self._notify_about_instance_usage(context, instance,
3705                 "rescue.start", extra_usage_info=extra_usage_info,
3706                 network_info=network_info)
3707         compute_utils.notify_about_instance_rescue_action(
3708             context, instance, self.host, rescue_image_ref,
3709             phase=fields.NotificationPhase.START)
3710 
3711         try:
3712             self._power_off_instance(context, instance, clean_shutdown)
3713 
3714             self.driver.rescue(context, instance,
3715                                network_info,
3716                                rescue_image_meta, admin_password)
3717         except Exception as e:
3718             LOG.exception("Error trying to Rescue Instance",
3719                           instance=instance)
3720             self._set_instance_obj_error_state(context, instance)
3721             raise exception.InstanceNotRescuable(
3722                 instance_id=instance.uuid,
3723                 reason=_("Driver Error: %s") % e)
3724 
3725         compute_utils.notify_usage_exists(self.notifier, context, instance,
3726                                           self.host, current_period=True)
3727 
3728         instance.vm_state = vm_states.RESCUED
3729         instance.task_state = None
3730         instance.power_state = self._get_power_state(context, instance)
3731         instance.launched_at = timeutils.utcnow()
3732         instance.save(expected_task_state=task_states.RESCUING)
3733 
3734         self._notify_about_instance_usage(context, instance,
3735                 "rescue.end", extra_usage_info=extra_usage_info,
3736                 network_info=network_info)
3737         compute_utils.notify_about_instance_rescue_action(
3738             context, instance, self.host, rescue_image_ref,
3739             phase=fields.NotificationPhase.END)
3740 
3741     @wrap_exception()
3742     @reverts_task_state
3743     @wrap_instance_event(prefix='compute')
3744     @wrap_instance_fault
3745     def unrescue_instance(self, context, instance):
3746         context = context.elevated()
3747         LOG.info('Unrescuing', instance=instance)
3748 
3749         network_info = self.network_api.get_instance_nw_info(context, instance)
3750         self._notify_about_instance_usage(context, instance,
3751                 "unrescue.start", network_info=network_info)
3752         compute_utils.notify_about_instance_action(context, instance,
3753             self.host, action=fields.NotificationAction.UNRESCUE,
3754             phase=fields.NotificationPhase.START)
3755 
3756         with self._error_out_instance_on_exception(context, instance):
3757             self.driver.unrescue(instance,
3758                                  network_info)
3759 
3760         instance.vm_state = vm_states.ACTIVE
3761         instance.task_state = None
3762         instance.power_state = self._get_power_state(context, instance)
3763         instance.save(expected_task_state=task_states.UNRESCUING)
3764 
3765         self._notify_about_instance_usage(context,
3766                                           instance,
3767                                           "unrescue.end",
3768                                           network_info=network_info)
3769         compute_utils.notify_about_instance_action(context, instance,
3770             self.host, action=fields.NotificationAction.UNRESCUE,
3771             phase=fields.NotificationPhase.END)
3772 
3773     @wrap_exception()
3774     @wrap_instance_fault
3775     def change_instance_metadata(self, context, diff, instance):
3776         """Update the metadata published to the instance."""
3777         LOG.debug("Changing instance metadata according to %r",
3778                   diff, instance=instance)
3779         self.driver.change_instance_metadata(context, instance, diff)
3780 
3781     @wrap_exception()
3782     @wrap_instance_event(prefix='compute')
3783     @wrap_instance_fault
3784     def confirm_resize(self, context, instance, migration):
3785         """Confirms a migration/resize and deletes the 'old' instance.
3786 
3787         This is called from the API and runs on the source host.
3788 
3789         Nothing needs to happen on the destination host at this point since
3790         the instance is already running there. This routine just cleans up the
3791         source host.
3792         """
3793         @utils.synchronized(instance.uuid)
3794         def do_confirm_resize(context, instance, migration_id):
3795             # NOTE(wangpan): Get the migration status from db, if it has been
3796             #                confirmed, we do nothing and return here
3797             LOG.debug("Going to confirm migration %s", migration_id,
3798                       instance=instance)
3799             try:
3800                 # TODO(russellb) Why are we sending the migration object just
3801                 # to turn around and look it up from the db again?
3802                 migration = objects.Migration.get_by_id(
3803                                     context.elevated(), migration_id)
3804             except exception.MigrationNotFound:
3805                 LOG.error("Migration %s is not found during confirmation",
3806                           migration_id, instance=instance)
3807                 return
3808 
3809             if migration.status == 'confirmed':
3810                 LOG.info("Migration %s is already confirmed",
3811                          migration_id, instance=instance)
3812                 return
3813             elif migration.status not in ('finished', 'confirming'):
3814                 LOG.warning("Unexpected confirmation status '%(status)s' "
3815                             "of migration %(id)s, exit confirmation process",
3816                             {"status": migration.status, "id": migration_id},
3817                             instance=instance)
3818                 return
3819 
3820             # NOTE(wangpan): Get the instance from db, if it has been
3821             #                deleted, we do nothing and return here
3822             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3823             try:
3824                 instance = objects.Instance.get_by_uuid(
3825                         context, instance.uuid,
3826                         expected_attrs=expected_attrs)
3827             except exception.InstanceNotFound:
3828                 LOG.info("Instance is not found during confirmation",
3829                          instance=instance)
3830                 return
3831 
3832             self._confirm_resize(context, instance, migration=migration)
3833 
3834         do_confirm_resize(context, instance, migration.id)
3835 
3836     def _confirm_resize(self, context, instance, migration=None):
3837         """Destroys the source instance."""
3838         self._notify_about_instance_usage(context, instance,
3839                                           "resize.confirm.start")
3840         compute_utils.notify_about_instance_action(context, instance,
3841             self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3842             phase=fields.NotificationPhase.START)
3843 
3844         with self._error_out_instance_on_exception(context, instance):
3845             # NOTE(danms): delete stashed migration information
3846             old_instance_type = instance.old_flavor
3847             instance.old_flavor = None
3848             instance.new_flavor = None
3849             instance.system_metadata.pop('old_vm_state', None)
3850             instance.save()
3851 
3852             # NOTE(tr3buchet): tear down networks on source host
3853             self.network_api.setup_networks_on_host(context, instance,
3854                                migration.source_compute, teardown=True)
3855 
3856             network_info = self.network_api.get_instance_nw_info(context,
3857                                                                  instance)
3858             # TODO(mriedem): Get BDMs here and pass them to the driver.
3859             self.driver.confirm_migration(context, migration, instance,
3860                                           network_info)
3861 
3862             migration.status = 'confirmed'
3863             with migration.obj_as_admin():
3864                 migration.save()
3865 
3866             rt = self._get_resource_tracker()
3867             rt.drop_move_claim(context, instance, migration.source_node,
3868                                old_instance_type, prefix='old_')
3869             self._delete_allocation_after_move(context, instance, migration,
3870                                                old_instance_type,
3871                                                migration.source_node)
3872             instance.drop_migration_context()
3873 
3874             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3875             # might have manually powered up the instance to confirm the
3876             # resize/migrate, so we need to check the current power state
3877             # on the instance and set the vm_state appropriately. We default
3878             # to ACTIVE because if the power state is not SHUTDOWN, we
3879             # assume _sync_instance_power_state will clean it up.
3880             p_state = instance.power_state
3881             vm_state = None
3882             if p_state == power_state.SHUTDOWN:
3883                 vm_state = vm_states.STOPPED
3884                 LOG.debug("Resized/migrated instance is powered off. "
3885                           "Setting vm_state to '%s'.", vm_state,
3886                           instance=instance)
3887             else:
3888                 vm_state = vm_states.ACTIVE
3889 
3890             instance.vm_state = vm_state
3891             instance.task_state = None
3892             instance.save(expected_task_state=[None, task_states.DELETING])
3893 
3894             self._notify_about_instance_usage(
3895                 context, instance, "resize.confirm.end",
3896                 network_info=network_info)
3897             compute_utils.notify_about_instance_action(context, instance,
3898                    self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3899                    phase=fields.NotificationPhase.END)
3900 
3901     def _delete_allocation_after_move(self, context, instance, migration,
3902                                       flavor, nodename):
3903         rt = self._get_resource_tracker()
3904         cn_uuid = rt.get_node_uuid(nodename)
3905 
3906         if migration.source_node == nodename:
3907             if migration.status in ('confirmed', 'completed'):
3908                 # NOTE(danms): We're finishing on the source node, so try to
3909                 # delete the allocation based on the migration uuid
3910                 deleted = self.reportclient.delete_allocation_for_instance(
3911                     context, migration.uuid)
3912                 if deleted:
3913                     LOG.info(_('Source node %(node)s confirmed migration '
3914                                '%(mig)s; deleted migration-based '
3915                                'allocation'),
3916                              {'node': nodename, 'mig': migration.uuid})
3917                     # NOTE(danms): We succeeded, which means we do not
3918                     # need to do the complex double allocation dance
3919                     return
3920             else:
3921                 # We're reverting (or failed) on the source, so we
3922                 # need to check if our migration holds a claim and if
3923                 # so, avoid doing the legacy behavior below.
3924                 mig_allocs = (
3925                     self.reportclient.get_allocations_for_consumer_by_provider(
3926                         context, cn_uuid, migration.uuid))
3927                 if mig_allocs:
3928                     LOG.info(_('Source node %(node)s reverted migration '
3929                                '%(mig)s; not deleting migration-based '
3930                                'allocation'),
3931                              {'node': nodename, 'mig': migration.uuid})
3932                     return
3933         elif migration.dest_node == nodename:
3934             # NOTE(danms): We're reverting on the destination node
3935             # (and we must not be doing a same-host migration if we
3936             # made it past the check above), so we need to check to
3937             # see if the source did migration-based allocation
3938             # accounting
3939             allocs = (
3940                 self.reportclient.get_allocations_for_consumer_by_provider(
3941                     context, cn_uuid, migration.uuid))
3942             if allocs:
3943                 # NOTE(danms): The source did migration-based allocation
3944                 # accounting, so we should let the source node rejigger
3945                 # the allocations in finish_resize_revert()
3946                 LOG.info(_('Destination node %(node)s reverted migration '
3947                            '%(mig)s; not deleting migration-based '
3948                            'allocation'),
3949                          {'node': nodename, 'mig': migration.uuid})
3950                 return
3951 
3952         # TODO(danms): Remove below this line when we remove compatibility
3953         # for double-accounting migrations (likely rocky)
3954         LOG.info(_('Doing legacy allocation math for migration %(mig)s after '
3955                    'instance move'),
3956                  {'mig': migration.uuid},
3957                  instance=instance)
3958 
3959         # NOTE(jaypipes): This sucks, but due to the fact that confirm_resize()
3960         # only runs on the source host and revert_resize() runs on the
3961         # destination host, we need to do this here. Basically, what we're
3962         # doing here is grabbing the existing allocations for this instance
3963         # from the placement API, dropping the resources in the doubled-up
3964         # allocation set that refer to the source host UUID and calling PUT
3965         # /allocations back to the placement API. The allocation that gets
3966         # PUT'd back to placement will only include the destination host and
3967         # any shared providers in the case of a confirm_resize operation and
3968         # the source host and shared providers for a revert_resize operation..
3969         if not scheduler_utils.remove_allocation_from_compute(
3970                 context, instance, cn_uuid, self.reportclient, flavor):
3971             LOG.error("Failed to save manipulated allocation",
3972                       instance=instance)
3973 
3974     @wrap_exception()
3975     @reverts_task_state
3976     @wrap_instance_event(prefix='compute')
3977     @errors_out_migration
3978     @wrap_instance_fault
3979     def revert_resize(self, context, instance, migration):
3980         """Destroys the new instance on the destination machine.
3981 
3982         Reverts the model changes, and powers on the old instance on the
3983         source machine.
3984 
3985         """
3986         # NOTE(comstud): A revert_resize is essentially a resize back to
3987         # the old size, so we need to send a usage event here.
3988         compute_utils.notify_usage_exists(self.notifier, context, instance,
3989                                           self.host, current_period=True)
3990 
3991         with self._error_out_instance_on_exception(context, instance):
3992             # NOTE(tr3buchet): tear down networks on destination host
3993             self.network_api.setup_networks_on_host(context, instance,
3994                                                     teardown=True)
3995 
3996             migration_p = obj_base.obj_to_primitive(migration)
3997             self.network_api.migrate_instance_start(context,
3998                                                     instance,
3999                                                     migration_p)
4000 
4001             network_info = self.network_api.get_instance_nw_info(context,
4002                                                                  instance)
4003             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4004                     context, instance.uuid)
4005             block_device_info = self._get_instance_block_device_info(
4006                                 context, instance, bdms=bdms)
4007 
4008             destroy_disks = not self._is_instance_storage_shared(
4009                 context, instance, host=migration.source_compute)
4010             self.driver.destroy(context, instance, network_info,
4011                                 block_device_info, destroy_disks)
4012 
4013             self._terminate_volume_connections(context, instance, bdms)
4014 
4015             migration.status = 'reverted'
4016             with migration.obj_as_admin():
4017                 migration.save()
4018 
4019             # NOTE(ndipanov): We need to do this here because dropping the
4020             # claim means we lose the migration_context data. We really should
4021             # fix this by moving the drop_move_claim call to the
4022             # finish_revert_resize method as this is racy (revert is dropped,
4023             # but instance resources will be tracked with the new flavor until
4024             # it gets rolled back in finish_revert_resize, which is
4025             # potentially wrong for a period of time).
4026             instance.revert_migration_context()
4027             instance.save()
4028 
4029             rt = self._get_resource_tracker()
4030             rt.drop_move_claim(context, instance, instance.node)
4031             self._delete_allocation_after_move(context, instance, migration,
4032                                                instance.flavor,
4033                                                instance.node)
4034 
4035             # RPC cast back to the source host to finish the revert there.
4036             self.compute_rpcapi.finish_revert_resize(context, instance,
4037                     migration, migration.source_compute)
4038 
4039     @wrap_exception()
4040     @reverts_task_state
4041     @wrap_instance_event(prefix='compute')
4042     @errors_out_migration
4043     @wrap_instance_fault
4044     def finish_revert_resize(self, context, instance, migration):
4045         """Finishes the second half of reverting a resize on the source host.
4046 
4047         Bring the original source instance state back (active/shutoff) and
4048         revert the resized attributes in the database.
4049 
4050         """
4051         with self._error_out_instance_on_exception(context, instance):
4052             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4053                 context, instance.uuid)
4054             self._notify_about_instance_usage(
4055                     context, instance, "resize.revert.start")
4056             compute_utils.notify_about_instance_action(context, instance,
4057                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4058                     phase=fields.NotificationPhase.START, bdms=bdms)
4059 
4060             # NOTE(mriedem): delete stashed old_vm_state information; we
4061             # default to ACTIVE for backwards compatibility if old_vm_state
4062             # is not set
4063             old_vm_state = instance.system_metadata.pop('old_vm_state',
4064                                                         vm_states.ACTIVE)
4065 
4066             self._set_instance_info(instance, instance.old_flavor)
4067             instance.old_flavor = None
4068             instance.new_flavor = None
4069             instance.host = migration.source_compute
4070             instance.node = migration.source_node
4071             instance.save()
4072 
4073             self._revert_allocation(context, instance, migration)
4074 
4075             self.network_api.setup_networks_on_host(context, instance,
4076                                                     migration.source_compute)
4077             migration_p = obj_base.obj_to_primitive(migration)
4078             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
4079             # source host temporarily. "network_api.migrate_instance_finish"
4080             # will setup the network for the instance on the destination host.
4081             # For revert resize, the instance will back to the source host, the
4082             # setup of the network for instance should be on the source host.
4083             # So set the migration_p['dest_compute'] to source host at here.
4084             migration_p['dest_compute'] = migration.source_compute
4085             self.network_api.migrate_instance_finish(context,
4086                                                      instance,
4087                                                      migration_p)
4088             network_info = self.network_api.get_instance_nw_info(context,
4089                                                                  instance)
4090 
4091             # revert_resize deleted any volume attachments for the instance
4092             # and created new ones to be used on this host, but we
4093             # have to update those attachments with the host connector so the
4094             # BDM.connection_info will get set in the call to
4095             # _get_instance_block_device_info below with refresh_conn_info=True
4096             # and then the volumes can be re-connected via the driver on this
4097             # host.
4098             self._update_volume_attachments(context, instance, bdms)
4099 
4100             block_device_info = self._get_instance_block_device_info(
4101                     context, instance, refresh_conn_info=True, bdms=bdms)
4102 
4103             power_on = old_vm_state != vm_states.STOPPED
4104             self.driver.finish_revert_migration(context, instance,
4105                                        network_info,
4106                                        block_device_info, power_on)
4107 
4108             instance.drop_migration_context()
4109             instance.launched_at = timeutils.utcnow()
4110             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
4111 
4112             # Complete any volume attachments so the volumes are in-use.
4113             self._complete_volume_attachments(context, bdms)
4114 
4115             # if the original vm state was STOPPED, set it back to STOPPED
4116             LOG.info("Updating instance to original state: '%s'",
4117                      old_vm_state, instance=instance)
4118             if power_on:
4119                 instance.vm_state = vm_states.ACTIVE
4120                 instance.task_state = None
4121                 instance.save()
4122             else:
4123                 instance.task_state = task_states.POWERING_OFF
4124                 instance.save()
4125                 self.stop_instance(context, instance=instance,
4126                                    clean_shutdown=True)
4127 
4128             self._notify_about_instance_usage(
4129                     context, instance, "resize.revert.end")
4130             compute_utils.notify_about_instance_action(context, instance,
4131                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4132                     phase=fields.NotificationPhase.END, bdms=bdms)
4133 
4134     def _revert_allocation(self, context, instance, migration):
4135         """Revert an allocation that is held by migration to our instance."""
4136 
4137         # Fetch the original allocation that the instance had on the source
4138         # node, which are now held by the migration
4139         orig_alloc = self.reportclient.get_allocations_for_consumer(
4140             context, migration.uuid)
4141         if not orig_alloc:
4142             # NOTE(danms): This migration did not do per-migration allocation
4143             # accounting, so nothing to do here.
4144             LOG.info('Old-style migration %(mig)s is being reverted; '
4145                      'no migration claims found on original node '
4146                      'to swap.',
4147                      {'mig': migration.uuid},
4148                      instance=instance)
4149             return False
4150 
4151         if len(orig_alloc) > 1:
4152             # NOTE(danms): This may change later if we have other allocations
4153             # against other providers that need to be held by the migration
4154             # as well. Perhaps something like shared storage resources that
4155             # will actually be duplicated during a resize type operation.
4156             LOG.error('New-style migration %(mig)s has allocations against '
4157                       'more than one provider %(rps)s. This should not be '
4158                       'possible, but reverting it anyway.',
4159                       {'mig': migration.uuid,
4160                        'rps': ','.join(orig_alloc.keys())},
4161                       instance=instance)
4162 
4163         # We only have a claim against one provider, it is the source node
4164         cn_uuid = list(orig_alloc.keys())[0]
4165 
4166         # Get just the resources part of the one allocation we need below
4167         orig_alloc = orig_alloc[cn_uuid].get('resources', {})
4168 
4169         # FIXME(danms): This method is flawed in that it asssumes allocations
4170         # against only one provider. So, this may overwite allocations against
4171         # a shared provider, if we had one.
4172         LOG.info('Swapping old allocation on %(node)s held by migration '
4173                  '%(mig)s for instance',
4174                  {'node': cn_uuid, 'mig': migration.uuid},
4175                  instance=instance)
4176         # TODO(cdent): Should we be doing anything with return values here?
4177         self.reportclient.set_and_clear_allocations(
4178             context, cn_uuid, instance.uuid, orig_alloc, instance.project_id,
4179             instance.user_id, consumer_to_clear=migration.uuid)
4180         return True
4181 
4182     def _prep_resize(self, context, image, instance, instance_type,
4183                      filter_properties, node, migration, clean_shutdown=True):
4184 
4185         if not filter_properties:
4186             filter_properties = {}
4187 
4188         if not instance.host:
4189             self._set_instance_obj_error_state(context, instance)
4190             msg = _('Instance has no source host')
4191             raise exception.MigrationError(reason=msg)
4192 
4193         same_host = instance.host == self.host
4194         # if the flavor IDs match, it's migrate; otherwise resize
4195         if same_host and instance_type.id == instance['instance_type_id']:
4196             # check driver whether support migrate to same host
4197             if not self.driver.capabilities.get(
4198                     'supports_migrate_to_same_host', False):
4199                 raise exception.UnableToMigrateToSelf(
4200                     instance_id=instance.uuid, host=self.host)
4201 
4202         # NOTE(danms): Stash the new instance_type to avoid having to
4203         # look it up in the database later
4204         instance.new_flavor = instance_type
4205         # NOTE(mriedem): Stash the old vm_state so we can set the
4206         # resized/reverted instance back to the same state later.
4207         vm_state = instance.vm_state
4208         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4209         instance.system_metadata['old_vm_state'] = vm_state
4210         instance.save()
4211 
4212         limits = filter_properties.get('limits', {})
4213         rt = self._get_resource_tracker()
4214         with rt.resize_claim(context, instance, instance_type, node,
4215                              migration, image_meta=image,
4216                              limits=limits) as claim:
4217             LOG.info('Migrating', instance=instance)
4218             # RPC cast to the source host to start the actual resize/migration.
4219             self.compute_rpcapi.resize_instance(
4220                     context, instance, claim.migration, image,
4221                     instance_type, clean_shutdown)
4222 
4223     @wrap_exception()
4224     @reverts_task_state
4225     @wrap_instance_event(prefix='compute')
4226     @wrap_instance_fault
4227     def prep_resize(self, context, image, instance, instance_type,
4228                     request_spec, filter_properties, node,
4229                     clean_shutdown, migration, host_list):
4230         """Initiates the process of moving a running instance to another host.
4231 
4232         Possibly changes the VCPU, RAM and disk size in the process.
4233 
4234         This is initiated from conductor and runs on the destination host.
4235 
4236         The main purpose of this method is performing some checks on the
4237         destination host and making a claim for resources. If the claim fails
4238         then a reschedule to another host may be attempted which involves
4239         calling back to conductor to start the process over again.
4240         """
4241         if node is None:
4242             node = self._get_nodename(instance, refresh=True)
4243 
4244         with self._error_out_instance_on_exception(context, instance), \
4245                  errors_out_migration_ctxt(migration):
4246             compute_utils.notify_usage_exists(self.notifier, context, instance,
4247                                               self.host, current_period=True)
4248             self._notify_about_instance_usage(
4249                     context, instance, "resize.prep.start")
4250             compute_utils.notify_about_resize_prep_instance(
4251                 context, instance, self.host,
4252                 fields.NotificationPhase.START, instance_type)
4253             try:
4254                 self._prep_resize(context, image, instance,
4255                                   instance_type, filter_properties,
4256                                   node, migration, clean_shutdown)
4257             except Exception:
4258                 # Since we hit a failure, we're either rescheduling or dead
4259                 # and either way we need to cleanup any allocations created
4260                 # by the scheduler for the destination node.
4261                 if migration and not self._revert_allocation(
4262                         context, instance, migration):
4263                     # We did not do a migration-based
4264                     # allocation. Note that for a resize to the
4265                     # same host, the scheduler will merge the
4266                     # flavors, so here we'd be subtracting the new
4267                     # flavor from the allocated resources on this
4268                     # node.
4269                     # FIXME(danms): Remove this in Rocky
4270                     rt = self._get_resource_tracker()
4271                     rt.delete_allocation_for_failed_resize(
4272                         context, instance, node, instance_type)
4273                 # try to re-schedule the resize elsewhere:
4274                 exc_info = sys.exc_info()
4275                 self._reschedule_resize_or_reraise(context, image, instance,
4276                         exc_info, instance_type, request_spec,
4277                         filter_properties, host_list)
4278             finally:
4279                 extra_usage_info = dict(
4280                         new_instance_type=instance_type.name,
4281                         new_instance_type_id=instance_type.id)
4282 
4283                 self._notify_about_instance_usage(
4284                     context, instance, "resize.prep.end",
4285                     extra_usage_info=extra_usage_info)
4286                 compute_utils.notify_about_resize_prep_instance(
4287                     context, instance, self.host,
4288                     fields.NotificationPhase.END, instance_type)
4289 
4290     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
4291             instance_type, request_spec, filter_properties, host_list):
4292         """Try to re-schedule the resize or re-raise the original error to
4293         error out the instance.
4294         """
4295         if not request_spec:
4296             request_spec = {}
4297         if not filter_properties:
4298             filter_properties = {}
4299 
4300         rescheduled = False
4301         instance_uuid = instance.uuid
4302 
4303         try:
4304             reschedule_method = self.compute_task_api.resize_instance
4305             scheduler_hint = dict(filter_properties=filter_properties)
4306             method_args = (instance, None, scheduler_hint, instance_type)
4307             task_state = task_states.RESIZE_PREP
4308 
4309             rescheduled = self._reschedule(context, request_spec,
4310                     filter_properties, instance, reschedule_method,
4311                     method_args, task_state, exc_info, host_list=host_list)
4312         except Exception as error:
4313             rescheduled = False
4314             LOG.exception("Error trying to reschedule",
4315                           instance_uuid=instance_uuid)
4316             compute_utils.add_instance_fault_from_exc(context,
4317                     instance, error,
4318                     exc_info=sys.exc_info())
4319             self._notify_about_instance_usage(context, instance,
4320                     'resize.error', fault=error)
4321             compute_utils.notify_about_instance_action(
4322                 context, instance, self.host,
4323                 action=fields.NotificationAction.RESIZE,
4324                 phase=fields.NotificationPhase.ERROR,
4325                 exception=error,
4326                 tb=','.join(traceback.format_exception(*exc_info)))
4327         if rescheduled:
4328             self._log_original_error(exc_info, instance_uuid)
4329             compute_utils.add_instance_fault_from_exc(context,
4330                     instance, exc_info[1], exc_info=exc_info)
4331             self._notify_about_instance_usage(context, instance,
4332                     'resize.error', fault=exc_info[1])
4333             compute_utils.notify_about_instance_action(
4334                 context, instance, self.host,
4335                 action=fields.NotificationAction.RESIZE,
4336                 phase=fields.NotificationPhase.ERROR,
4337                 exception=exc_info[1],
4338                 tb=','.join(traceback.format_exception(*exc_info)))
4339         else:
4340             # not re-scheduling
4341             six.reraise(*exc_info)
4342 
4343     @wrap_exception()
4344     @reverts_task_state
4345     @wrap_instance_event(prefix='compute')
4346     @wrap_instance_fault
4347     def resize_instance(self, context, instance, image,
4348                         migration, instance_type, clean_shutdown):
4349         """Starts the migration of a running instance to another host.
4350 
4351         This is initiated from the destination host's ``prep_resize`` routine
4352         and runs on the source host.
4353         """
4354         try:
4355             self._resize_instance(context, instance, image, migration,
4356                                   instance_type, clean_shutdown)
4357         except Exception:
4358             with excutils.save_and_reraise_exception():
4359                 self._revert_allocation(context, instance, migration)
4360 
4361     def _resize_instance(self, context, instance, image,
4362                          migration, instance_type, clean_shutdown):
4363         with self._error_out_instance_on_exception(context, instance), \
4364              errors_out_migration_ctxt(migration):
4365             network_info = self.network_api.get_instance_nw_info(context,
4366                                                                  instance)
4367 
4368             migration.status = 'migrating'
4369             with migration.obj_as_admin():
4370                 migration.save()
4371 
4372             instance.task_state = task_states.RESIZE_MIGRATING
4373             instance.save(expected_task_state=task_states.RESIZE_PREP)
4374 
4375             self._notify_about_instance_usage(
4376                 context, instance, "resize.start", network_info=network_info)
4377 
4378             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4379                     context, instance.uuid)
4380 
4381             compute_utils.notify_about_instance_action(context, instance,
4382                    self.host, action=fields.NotificationAction.RESIZE,
4383                    phase=fields.NotificationPhase.START, bdms=bdms)
4384 
4385             block_device_info = self._get_instance_block_device_info(
4386                                 context, instance, bdms=bdms)
4387 
4388             timeout, retry_interval = self._get_power_off_values(context,
4389                                             instance, clean_shutdown)
4390             disk_info = self.driver.migrate_disk_and_power_off(
4391                     context, instance, migration.dest_host,
4392                     instance_type, network_info,
4393                     block_device_info,
4394                     timeout, retry_interval)
4395 
4396             self._terminate_volume_connections(context, instance, bdms)
4397 
4398             migration_p = obj_base.obj_to_primitive(migration)
4399             self.network_api.migrate_instance_start(context,
4400                                                     instance,
4401                                                     migration_p)
4402 
4403             migration.status = 'post-migrating'
4404             with migration.obj_as_admin():
4405                 migration.save()
4406 
4407             instance.host = migration.dest_compute
4408             instance.node = migration.dest_node
4409             instance.task_state = task_states.RESIZE_MIGRATED
4410             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4411 
4412             # RPC cast to the destination host to finish the resize/migration.
4413             self.compute_rpcapi.finish_resize(context, instance,
4414                     migration, image, disk_info, migration.dest_compute)
4415 
4416         self._notify_about_instance_usage(context, instance, "resize.end",
4417                                           network_info=network_info)
4418 
4419         compute_utils.notify_about_instance_action(context, instance,
4420                self.host, action=fields.NotificationAction.RESIZE,
4421                phase=fields.NotificationPhase.END, bdms=bdms)
4422         self.instance_events.clear_events_for_instance(instance)
4423 
4424     def _terminate_volume_connections(self, context, instance, bdms):
4425         connector = None
4426         for bdm in bdms:
4427             if bdm.is_volume:
4428                 if bdm.attachment_id:
4429                     # NOTE(jdg): So here's the thing, the idea behind the new
4430                     # attach API's was to have a new code fork/path that we
4431                     # followed, we're not going to do that so we have to do
4432                     # some extra work in here to make it *behave* just like the
4433                     # old code. Cinder doesn't allow disconnect/reconnect (you
4434                     # just delete the attachment and get a new one)
4435                     # attachments in the new attach code so we have to do
4436                     # a delete and create without a connector (reserve),
4437                     # in other words, beware
4438                     attachment_id = self.volume_api.attachment_create(
4439                         context, bdm.volume_id, instance.uuid)['id']
4440                     self.volume_api.attachment_delete(context,
4441                                                       bdm.attachment_id)
4442                     bdm.attachment_id = attachment_id
4443                     bdm.save()
4444 
4445                 else:
4446                     if connector is None:
4447                         connector = self.driver.get_volume_connector(instance)
4448                     self.volume_api.terminate_connection(context,
4449                                                          bdm.volume_id,
4450                                                          connector)
4451 
4452     @staticmethod
4453     def _set_instance_info(instance, instance_type):
4454         instance.instance_type_id = instance_type.id
4455         instance.memory_mb = instance_type.memory_mb
4456         instance.vcpus = instance_type.vcpus
4457         instance.root_gb = instance_type.root_gb
4458         instance.ephemeral_gb = instance_type.ephemeral_gb
4459         instance.flavor = instance_type
4460 
4461     def _update_volume_attachments(self, context, instance, bdms):
4462         """Updates volume attachments using the virt driver host connector.
4463 
4464         :param context: nova.context.RequestContext - user request context
4465         :param instance: nova.objects.Instance
4466         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4467                      device mappings for the given instance
4468         """
4469         if bdms:
4470             connector = None
4471             for bdm in bdms:
4472                 if bdm.is_volume and bdm.attachment_id:
4473                     if connector is None:
4474                         connector = self.driver.get_volume_connector(instance)
4475                     self.volume_api.attachment_update(
4476                         context, bdm.attachment_id, connector, bdm.device_name)
4477 
4478     def _complete_volume_attachments(self, context, bdms):
4479         """Completes volume attachments for the instance
4480 
4481         :param context: nova.context.RequestContext - user request context
4482         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4483                      device mappings for the given instance
4484         """
4485         if bdms:
4486             for bdm in bdms:
4487                 if bdm.is_volume and bdm.attachment_id:
4488                     self.volume_api.attachment_complete(
4489                         context, bdm.attachment_id)
4490 
4491     def _finish_resize(self, context, instance, migration, disk_info,
4492                        image_meta, bdms):
4493         resize_instance = False
4494         old_instance_type_id = migration['old_instance_type_id']
4495         new_instance_type_id = migration['new_instance_type_id']
4496         old_instance_type = instance.get_flavor()
4497         # NOTE(mriedem): Get the old_vm_state so we know if we should
4498         # power on the instance. If old_vm_state is not set we need to default
4499         # to ACTIVE for backwards compatibility
4500         old_vm_state = instance.system_metadata.get('old_vm_state',
4501                                                     vm_states.ACTIVE)
4502         instance.old_flavor = old_instance_type
4503 
4504         if old_instance_type_id != new_instance_type_id:
4505             instance_type = instance.get_flavor('new')
4506             self._set_instance_info(instance, instance_type)
4507             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4508                 if old_instance_type[key] != instance_type[key]:
4509                     resize_instance = True
4510                     break
4511         instance.apply_migration_context()
4512 
4513         # NOTE(tr3buchet): setup networks on destination host
4514         self.network_api.setup_networks_on_host(context, instance,
4515                                                 migration['dest_compute'])
4516 
4517         migration_p = obj_base.obj_to_primitive(migration)
4518         self.network_api.migrate_instance_finish(context,
4519                                                  instance,
4520                                                  migration_p)
4521 
4522         network_info = self.network_api.get_instance_nw_info(context, instance)
4523 
4524         instance.task_state = task_states.RESIZE_FINISH
4525         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4526 
4527         self._notify_about_instance_usage(
4528             context, instance, "finish_resize.start",
4529             network_info=network_info)
4530         compute_utils.notify_about_instance_action(context, instance,
4531                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4532                phase=fields.NotificationPhase.START, bdms=bdms)
4533 
4534         # We need to update any volume attachments using the destination
4535         # host connector so that we can update the BDM.connection_info
4536         # before calling driver.finish_migration otherwise the driver
4537         # won't know how to connect the volumes to this host.
4538         # Note that _get_instance_block_device_info with
4539         # refresh_conn_info=True will update the BDM.connection_info value
4540         # in the database so we must do this before calling that method.
4541         self._update_volume_attachments(context, instance, bdms)
4542 
4543         block_device_info = self._get_instance_block_device_info(
4544             context, instance, refresh_conn_info=True, bdms=bdms)
4545 
4546         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4547         # automatically power on the instance after it's migrated
4548         power_on = old_vm_state != vm_states.STOPPED
4549 
4550         try:
4551             self.driver.finish_migration(context, migration, instance,
4552                                          disk_info,
4553                                          network_info,
4554                                          image_meta, resize_instance,
4555                                          block_device_info, power_on)
4556         except Exception:
4557             with excutils.save_and_reraise_exception():
4558                 if old_instance_type_id != new_instance_type_id:
4559                     self._set_instance_info(instance,
4560                                             old_instance_type)
4561 
4562         # Now complete any volume attachments that were previously updated.
4563         self._complete_volume_attachments(context, bdms)
4564 
4565         migration.status = 'finished'
4566         with migration.obj_as_admin():
4567             migration.save()
4568 
4569         instance.vm_state = vm_states.RESIZED
4570         instance.task_state = None
4571         instance.launched_at = timeutils.utcnow()
4572         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4573 
4574         return network_info
4575 
4576     @wrap_exception()
4577     @reverts_task_state
4578     @wrap_instance_event(prefix='compute')
4579     @wrap_instance_fault
4580     def finish_resize(self, context, disk_info, image, instance,
4581                       migration):
4582         """Completes the migration process.
4583 
4584         Sets up the newly transferred disk and turns on the instance at its
4585         new host machine.
4586 
4587         """
4588         try:
4589             self._finish_resize_helper(context, disk_info, image, instance,
4590                                        migration)
4591         except Exception:
4592             with excutils.save_and_reraise_exception():
4593                 self._revert_allocation(context, instance, migration)
4594 
4595     def _finish_resize_helper(self, context, disk_info, image, instance,
4596                               migration):
4597         """Completes the migration process.
4598 
4599         The caller must revert the instance's allocations if the migration
4600         process failed.
4601         """
4602         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4603             context, instance.uuid)
4604 
4605         with self._error_out_instance_on_exception(context, instance), \
4606              errors_out_migration_ctxt(migration):
4607             image_meta = objects.ImageMeta.from_dict(image)
4608             network_info = self._finish_resize(context, instance, migration,
4609                                                disk_info, image_meta, bdms)
4610 
4611         # TODO(melwitt): We should clean up instance console tokens here. The
4612         # instance is on a new host and will need to establish a new console
4613         # connection.
4614         self._update_scheduler_instance_info(context, instance)
4615         self._notify_about_instance_usage(
4616             context, instance, "finish_resize.end",
4617             network_info=network_info)
4618         compute_utils.notify_about_instance_action(context, instance,
4619                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4620                phase=fields.NotificationPhase.END, bdms=bdms)
4621 
4622     @wrap_exception()
4623     @wrap_instance_fault
4624     def add_fixed_ip_to_instance(self, context, network_id, instance):
4625         """Calls network_api to add new fixed_ip to instance
4626         then injects the new network info and resets instance networking.
4627 
4628         """
4629         self._notify_about_instance_usage(
4630                 context, instance, "create_ip.start")
4631 
4632         network_info = self.network_api.add_fixed_ip_to_instance(context,
4633                                                                  instance,
4634                                                                  network_id)
4635         self._inject_network_info(context, instance, network_info)
4636         self.reset_network(context, instance)
4637 
4638         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4639         instance.updated_at = timeutils.utcnow()
4640         instance.save()
4641 
4642         self._notify_about_instance_usage(
4643             context, instance, "create_ip.end", network_info=network_info)
4644 
4645     @wrap_exception()
4646     @wrap_instance_fault
4647     def remove_fixed_ip_from_instance(self, context, address, instance):
4648         """Calls network_api to remove existing fixed_ip from instance
4649         by injecting the altered network info and resetting
4650         instance networking.
4651         """
4652         self._notify_about_instance_usage(
4653                 context, instance, "delete_ip.start")
4654 
4655         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4656                                                                       instance,
4657                                                                       address)
4658         self._inject_network_info(context, instance, network_info)
4659         self.reset_network(context, instance)
4660 
4661         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4662         instance.updated_at = timeutils.utcnow()
4663         instance.save()
4664 
4665         self._notify_about_instance_usage(
4666             context, instance, "delete_ip.end", network_info=network_info)
4667 
4668     @wrap_exception()
4669     @reverts_task_state
4670     @wrap_instance_event(prefix='compute')
4671     @wrap_instance_fault
4672     def pause_instance(self, context, instance):
4673         """Pause an instance on this host."""
4674         context = context.elevated()
4675         LOG.info('Pausing', instance=instance)
4676         self._notify_about_instance_usage(context, instance, 'pause.start')
4677         compute_utils.notify_about_instance_action(context, instance,
4678                self.host, action=fields.NotificationAction.PAUSE,
4679                phase=fields.NotificationPhase.START)
4680         self.driver.pause(instance)
4681         instance.power_state = self._get_power_state(context, instance)
4682         instance.vm_state = vm_states.PAUSED
4683         instance.task_state = None
4684         instance.save(expected_task_state=task_states.PAUSING)
4685         self._notify_about_instance_usage(context, instance, 'pause.end')
4686         compute_utils.notify_about_instance_action(context, instance,
4687                self.host, action=fields.NotificationAction.PAUSE,
4688                phase=fields.NotificationPhase.END)
4689 
4690     @wrap_exception()
4691     @reverts_task_state
4692     @wrap_instance_event(prefix='compute')
4693     @wrap_instance_fault
4694     def unpause_instance(self, context, instance):
4695         """Unpause a paused instance on this host."""
4696         context = context.elevated()
4697         LOG.info('Unpausing', instance=instance)
4698         self._notify_about_instance_usage(context, instance, 'unpause.start')
4699         compute_utils.notify_about_instance_action(context, instance,
4700             self.host, action=fields.NotificationAction.UNPAUSE,
4701             phase=fields.NotificationPhase.START)
4702         self.driver.unpause(instance)
4703         instance.power_state = self._get_power_state(context, instance)
4704         instance.vm_state = vm_states.ACTIVE
4705         instance.task_state = None
4706         instance.save(expected_task_state=task_states.UNPAUSING)
4707         self._notify_about_instance_usage(context, instance, 'unpause.end')
4708         compute_utils.notify_about_instance_action(context, instance,
4709             self.host, action=fields.NotificationAction.UNPAUSE,
4710             phase=fields.NotificationPhase.END)
4711 
4712     @wrap_exception()
4713     def host_power_action(self, context, action):
4714         """Reboots, shuts down or powers up the host."""
4715         return self.driver.host_power_action(action)
4716 
4717     @wrap_exception()
4718     def host_maintenance_mode(self, context, host, mode):
4719         """Start/Stop host maintenance window. On start, it triggers
4720         guest VMs evacuation.
4721         """
4722         return self.driver.host_maintenance_mode(host, mode)
4723 
4724     @wrap_exception()
4725     def set_host_enabled(self, context, enabled):
4726         """Sets the specified host's ability to accept new instances."""
4727         return self.driver.set_host_enabled(enabled)
4728 
4729     @wrap_exception()
4730     def get_host_uptime(self, context):
4731         """Returns the result of calling "uptime" on the target host."""
4732         return self.driver.get_host_uptime()
4733 
4734     @wrap_exception()
4735     @wrap_instance_fault
4736     def get_diagnostics(self, context, instance):
4737         """Retrieve diagnostics for an instance on this host."""
4738         current_power_state = self._get_power_state(context, instance)
4739         if current_power_state == power_state.RUNNING:
4740             LOG.info("Retrieving diagnostics", instance=instance)
4741             return self.driver.get_diagnostics(instance)
4742         else:
4743             raise exception.InstanceInvalidState(
4744                 attr='power state',
4745                 instance_uuid=instance.uuid,
4746                 state=power_state.STATE_MAP[instance.power_state],
4747                 method='get_diagnostics')
4748 
4749     @wrap_exception()
4750     @wrap_instance_fault
4751     def get_instance_diagnostics(self, context, instance):
4752         """Retrieve diagnostics for an instance on this host."""
4753         current_power_state = self._get_power_state(context, instance)
4754         if current_power_state == power_state.RUNNING:
4755             LOG.info("Retrieving diagnostics", instance=instance)
4756             return self.driver.get_instance_diagnostics(instance)
4757         else:
4758             raise exception.InstanceInvalidState(
4759                 attr='power state',
4760                 instance_uuid=instance.uuid,
4761                 state=power_state.STATE_MAP[instance.power_state],
4762                 method='get_diagnostics')
4763 
4764     @wrap_exception()
4765     @reverts_task_state
4766     @wrap_instance_event(prefix='compute')
4767     @wrap_instance_fault
4768     def suspend_instance(self, context, instance):
4769         """Suspend the given instance."""
4770         context = context.elevated()
4771 
4772         # Store the old state
4773         instance.system_metadata['old_vm_state'] = instance.vm_state
4774         self._notify_about_instance_usage(context, instance, 'suspend.start')
4775         compute_utils.notify_about_instance_action(context, instance,
4776                 self.host, action=fields.NotificationAction.SUSPEND,
4777                 phase=fields.NotificationPhase.START)
4778         with self._error_out_instance_on_exception(context, instance,
4779              instance_state=instance.vm_state):
4780             self.driver.suspend(context, instance)
4781         instance.power_state = self._get_power_state(context, instance)
4782         instance.vm_state = vm_states.SUSPENDED
4783         instance.task_state = None
4784         instance.save(expected_task_state=task_states.SUSPENDING)
4785         self._notify_about_instance_usage(context, instance, 'suspend.end')
4786         compute_utils.notify_about_instance_action(context, instance,
4787                 self.host, action=fields.NotificationAction.SUSPEND,
4788                 phase=fields.NotificationPhase.END)
4789 
4790     @wrap_exception()
4791     @reverts_task_state
4792     @wrap_instance_event(prefix='compute')
4793     @wrap_instance_fault
4794     def resume_instance(self, context, instance):
4795         """Resume the given suspended instance."""
4796         context = context.elevated()
4797         LOG.info('Resuming', instance=instance)
4798 
4799         self._notify_about_instance_usage(context, instance, 'resume.start')
4800 
4801         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4802             context, instance.uuid)
4803         block_device_info = self._get_instance_block_device_info(
4804             context, instance, bdms=bdms)
4805 
4806         compute_utils.notify_about_instance_action(context, instance,
4807             self.host, action=fields.NotificationAction.RESUME,
4808             phase=fields.NotificationPhase.START, bdms=bdms)
4809 
4810         network_info = self.network_api.get_instance_nw_info(context, instance)
4811 
4812         with self._error_out_instance_on_exception(context, instance,
4813              instance_state=instance.vm_state):
4814             self.driver.resume(context, instance, network_info,
4815                                block_device_info)
4816 
4817         instance.power_state = self._get_power_state(context, instance)
4818 
4819         # We default to the ACTIVE state for backwards compatibility
4820         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4821                                                          vm_states.ACTIVE)
4822 
4823         instance.task_state = None
4824         instance.save(expected_task_state=task_states.RESUMING)
4825         self._notify_about_instance_usage(context, instance, 'resume.end')
4826         compute_utils.notify_about_instance_action(context, instance,
4827             self.host, action=fields.NotificationAction.RESUME,
4828             phase=fields.NotificationPhase.END, bdms=bdms)
4829 
4830     @wrap_exception()
4831     @reverts_task_state
4832     @wrap_instance_event(prefix='compute')
4833     @wrap_instance_fault
4834     def shelve_instance(self, context, instance, image_id,
4835                         clean_shutdown):
4836         """Shelve an instance.
4837 
4838         This should be used when you want to take a snapshot of the instance.
4839         It also adds system_metadata that can be used by a periodic task to
4840         offload the shelved instance after a period of time.
4841 
4842         :param context: request context
4843         :param instance: an Instance object
4844         :param image_id: an image id to snapshot to.
4845         :param clean_shutdown: give the GuestOS a chance to stop
4846         """
4847 
4848         @utils.synchronized(instance.uuid)
4849         def do_shelve_instance():
4850             self._shelve_instance(context, instance, image_id, clean_shutdown)
4851         do_shelve_instance()
4852 
4853     def _shelve_instance(self, context, instance, image_id,
4854                          clean_shutdown):
4855         LOG.info('Shelving', instance=instance)
4856         offload = CONF.shelved_offload_time == 0
4857         if offload:
4858             # Get the BDMs early so we can pass them into versioned
4859             # notifications since _shelve_offload_instance needs the
4860             # BDMs anyway.
4861             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4862                 context, instance.uuid)
4863         else:
4864             bdms = None
4865         compute_utils.notify_usage_exists(self.notifier, context, instance,
4866                                           self.host, current_period=True)
4867         self._notify_about_instance_usage(context, instance, 'shelve.start')
4868         compute_utils.notify_about_instance_action(context, instance,
4869                 self.host, action=fields.NotificationAction.SHELVE,
4870                 phase=fields.NotificationPhase.START, bdms=bdms)
4871 
4872         def update_task_state(task_state, expected_state=task_states.SHELVING):
4873             shelving_state_map = {
4874                     task_states.IMAGE_PENDING_UPLOAD:
4875                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4876                     task_states.IMAGE_UPLOADING:
4877                         task_states.SHELVING_IMAGE_UPLOADING,
4878                     task_states.SHELVING: task_states.SHELVING}
4879             task_state = shelving_state_map[task_state]
4880             expected_state = shelving_state_map[expected_state]
4881             instance.task_state = task_state
4882             instance.save(expected_task_state=expected_state)
4883         # Do not attempt a clean shutdown of a paused guest since some
4884         # hypervisors will fail the clean shutdown if the guest is not
4885         # running.
4886         if instance.power_state == power_state.PAUSED:
4887             clean_shutdown = False
4888         self._power_off_instance(context, instance, clean_shutdown)
4889         self.driver.snapshot(context, instance, image_id, update_task_state)
4890 
4891         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4892         instance.system_metadata['shelved_image_id'] = image_id
4893         instance.system_metadata['shelved_host'] = self.host
4894         instance.vm_state = vm_states.SHELVED
4895         instance.task_state = None
4896         if CONF.shelved_offload_time == 0:
4897             instance.task_state = task_states.SHELVING_OFFLOADING
4898         instance.power_state = self._get_power_state(context, instance)
4899         instance.save(expected_task_state=[
4900                 task_states.SHELVING,
4901                 task_states.SHELVING_IMAGE_UPLOADING])
4902 
4903         self._notify_about_instance_usage(context, instance, 'shelve.end')
4904         compute_utils.notify_about_instance_action(context, instance,
4905                 self.host, action=fields.NotificationAction.SHELVE,
4906                 phase=fields.NotificationPhase.END, bdms=bdms)
4907 
4908         if offload:
4909             self._shelve_offload_instance(context, instance,
4910                                           clean_shutdown=False, bdms=bdms)
4911 
4912     @wrap_exception()
4913     @reverts_task_state
4914     @wrap_instance_event(prefix='compute')
4915     @wrap_instance_fault
4916     def shelve_offload_instance(self, context, instance, clean_shutdown):
4917         """Remove a shelved instance from the hypervisor.
4918 
4919         This frees up those resources for use by other instances, but may lead
4920         to slower unshelve times for this instance.  This method is used by
4921         volume backed instances since restoring them doesn't involve the
4922         potentially large download of an image.
4923 
4924         :param context: request context
4925         :param instance: nova.objects.instance.Instance
4926         :param clean_shutdown: give the GuestOS a chance to stop
4927         """
4928 
4929         @utils.synchronized(instance.uuid)
4930         def do_shelve_offload_instance():
4931             self._shelve_offload_instance(context, instance, clean_shutdown)
4932         do_shelve_offload_instance()
4933 
4934     def _shelve_offload_instance(self, context, instance, clean_shutdown,
4935                                  bdms=None):
4936         LOG.info('Shelve offloading', instance=instance)
4937         if bdms is None:
4938             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4939                 context, instance.uuid)
4940         self._notify_about_instance_usage(context, instance,
4941                 'shelve_offload.start')
4942         compute_utils.notify_about_instance_action(context, instance,
4943                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4944                 phase=fields.NotificationPhase.START, bdms=bdms)
4945 
4946         self._power_off_instance(context, instance, clean_shutdown)
4947         current_power_state = self._get_power_state(context, instance)
4948 
4949         self.network_api.cleanup_instance_network_on_host(context, instance,
4950                                                           instance.host)
4951         network_info = self.network_api.get_instance_nw_info(context, instance)
4952 
4953         block_device_info = self._get_instance_block_device_info(context,
4954                                                                  instance,
4955                                                                  bdms=bdms)
4956         self.driver.destroy(context, instance, network_info,
4957                 block_device_info)
4958 
4959         # the instance is going to be removed from the host so we want to
4960         # terminate all the connections with the volume server and the host
4961         self._terminate_volume_connections(context, instance, bdms)
4962 
4963         instance.power_state = current_power_state
4964         # NOTE(mriedem): The vm_state has to be set before updating the
4965         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4966         # values cannot be nulled out until after updating the resource tracker
4967         # though.
4968         instance.vm_state = vm_states.SHELVED_OFFLOADED
4969         instance.task_state = None
4970         instance.save(expected_task_state=[task_states.SHELVING,
4971                                            task_states.SHELVING_OFFLOADING])
4972 
4973         # NOTE(ndipanov): Free resources from the resource tracker
4974         self._update_resource_tracker(context, instance)
4975 
4976         rt = self._get_resource_tracker()
4977         rt.delete_allocation_for_shelve_offloaded_instance(context, instance)
4978 
4979         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4980         # instance, so ensure any calls result in errors
4981         self._nil_out_instance_obj_host_and_node(instance)
4982         instance.save(expected_task_state=None)
4983 
4984         # TODO(melwitt): We should clean up instance console tokens here. The
4985         # instance has no host at this point and will need to establish a new
4986         # console connection in the future after it is unshelved.
4987         self._delete_scheduler_instance_info(context, instance.uuid)
4988         self._notify_about_instance_usage(context, instance,
4989                 'shelve_offload.end')
4990         compute_utils.notify_about_instance_action(context, instance,
4991                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4992                 phase=fields.NotificationPhase.END, bdms=bdms)
4993 
4994     @wrap_exception()
4995     @reverts_task_state
4996     @wrap_instance_event(prefix='compute')
4997     @wrap_instance_fault
4998     def unshelve_instance(self, context, instance, image,
4999                           filter_properties, node):
5000         """Unshelve the instance.
5001 
5002         :param context: request context
5003         :param instance: a nova.objects.instance.Instance object
5004         :param image: an image to build from.  If None we assume a
5005             volume backed instance.
5006         :param filter_properties: dict containing limits, retry info etc.
5007         :param node: target compute node
5008         """
5009         if filter_properties is None:
5010             filter_properties = {}
5011 
5012         @utils.synchronized(instance.uuid)
5013         def do_unshelve_instance():
5014             self._unshelve_instance(context, instance, image,
5015                                     filter_properties, node)
5016         do_unshelve_instance()
5017 
5018     def _unshelve_instance_key_scrub(self, instance):
5019         """Remove data from the instance that may cause side effects."""
5020         cleaned_keys = dict(
5021                 key_data=instance.key_data,
5022                 auto_disk_config=instance.auto_disk_config)
5023         instance.key_data = None
5024         instance.auto_disk_config = False
5025         return cleaned_keys
5026 
5027     def _unshelve_instance_key_restore(self, instance, keys):
5028         """Restore previously scrubbed keys before saving the instance."""
5029         instance.update(keys)
5030 
5031     def _unshelve_instance(self, context, instance, image, filter_properties,
5032                            node):
5033         LOG.info('Unshelving', instance=instance)
5034         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5035                 context, instance.uuid)
5036 
5037         self._notify_about_instance_usage(context, instance, 'unshelve.start')
5038         compute_utils.notify_about_instance_action(context, instance,
5039                 self.host, action=fields.NotificationAction.UNSHELVE,
5040                 phase=fields.NotificationPhase.START, bdms=bdms)
5041 
5042         instance.task_state = task_states.SPAWNING
5043         instance.save()
5044 
5045         block_device_info = self._prep_block_device(context, instance, bdms)
5046         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
5047 
5048         if node is None:
5049             node = self._get_nodename(instance)
5050 
5051         rt = self._get_resource_tracker()
5052         limits = filter_properties.get('limits', {})
5053 
5054         allocations = self.reportclient.get_allocations_for_consumer(
5055             context, instance.uuid)
5056 
5057         shelved_image_ref = instance.image_ref
5058         if image:
5059             instance.image_ref = image['id']
5060             image_meta = objects.ImageMeta.from_dict(image)
5061         else:
5062             image_meta = objects.ImageMeta.from_dict(
5063                 utils.get_image_from_system_metadata(
5064                     instance.system_metadata))
5065 
5066         self.network_api.setup_instance_network_on_host(context, instance,
5067                                                         self.host)
5068         network_info = self.network_api.get_instance_nw_info(context, instance)
5069         try:
5070             with rt.instance_claim(context, instance, node, limits):
5071                 self.driver.spawn(context, instance, image_meta,
5072                                   injected_files=[],
5073                                   admin_password=None,
5074                                   allocations=allocations,
5075                                   network_info=network_info,
5076                                   block_device_info=block_device_info)
5077         except Exception:
5078             with excutils.save_and_reraise_exception(logger=LOG):
5079                 LOG.exception('Instance failed to spawn',
5080                               instance=instance)
5081                 # Cleanup allocations created by the scheduler on this host
5082                 # since we failed to spawn the instance. We do this both if
5083                 # the instance claim failed with ComputeResourcesUnavailable
5084                 # or if we did claim but the spawn failed, because aborting the
5085                 # instance claim will not remove the allocations.
5086                 rt.reportclient.delete_allocation_for_instance(context,
5087                                                                instance.uuid)
5088                 # FIXME: Umm, shouldn't we be rolling back port bindings too?
5089                 self._terminate_volume_connections(context, instance, bdms)
5090                 # The reverts_task_state decorator on unshelve_instance will
5091                 # eventually save these updates.
5092                 self._nil_out_instance_obj_host_and_node(instance)
5093 
5094         if image:
5095             instance.image_ref = shelved_image_ref
5096             self._delete_snapshot_of_shelved_instance(context, instance,
5097                                                       image['id'])
5098 
5099         self._unshelve_instance_key_restore(instance, scrubbed_keys)
5100         self._update_instance_after_spawn(context, instance)
5101         # Delete system_metadata for a shelved instance
5102         compute_utils.remove_shelved_keys_from_system_metadata(instance)
5103 
5104         instance.save(expected_task_state=task_states.SPAWNING)
5105         self._update_scheduler_instance_info(context, instance)
5106         self._notify_about_instance_usage(context, instance, 'unshelve.end')
5107         compute_utils.notify_about_instance_action(context, instance,
5108                 self.host, action=fields.NotificationAction.UNSHELVE,
5109                 phase=fields.NotificationPhase.END, bdms=bdms)
5110 
5111     @messaging.expected_exceptions(NotImplementedError)
5112     @wrap_instance_fault
5113     def reset_network(self, context, instance):
5114         """Reset networking on the given instance."""
5115         LOG.debug('Reset network', instance=instance)
5116         self.driver.reset_network(instance)
5117 
5118     def _inject_network_info(self, context, instance, network_info):
5119         """Inject network info for the given instance."""
5120         LOG.debug('Inject network info', instance=instance)
5121         LOG.debug('network_info to inject: |%s|', network_info,
5122                   instance=instance)
5123 
5124         self.driver.inject_network_info(instance,
5125                                         network_info)
5126 
5127     @wrap_instance_fault
5128     def inject_network_info(self, context, instance):
5129         """Inject network info, but don't return the info."""
5130         network_info = self.network_api.get_instance_nw_info(context, instance)
5131         self._inject_network_info(context, instance, network_info)
5132 
5133     @messaging.expected_exceptions(NotImplementedError,
5134                                    exception.ConsoleNotAvailable,
5135                                    exception.InstanceNotFound)
5136     @wrap_exception()
5137     @wrap_instance_fault
5138     def get_console_output(self, context, instance, tail_length):
5139         """Send the console output for the given instance."""
5140         context = context.elevated()
5141         LOG.info("Get console output", instance=instance)
5142         output = self.driver.get_console_output(context, instance)
5143 
5144         if type(output) is six.text_type:
5145             output = six.b(output)
5146 
5147         if tail_length is not None:
5148             output = self._tail_log(output, tail_length)
5149 
5150         return output.decode('ascii', 'replace')
5151 
5152     def _tail_log(self, log, length):
5153         try:
5154             length = int(length)
5155         except ValueError:
5156             length = 0
5157 
5158         if length == 0:
5159             return b''
5160         else:
5161             return b'\n'.join(log.split(b'\n')[-int(length):])
5162 
5163     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5164                                    exception.InstanceNotReady,
5165                                    exception.InstanceNotFound,
5166                                    exception.ConsoleTypeUnavailable,
5167                                    NotImplementedError)
5168     @wrap_exception()
5169     @wrap_instance_fault
5170     def get_vnc_console(self, context, console_type, instance):
5171         """Return connection information for a vnc console."""
5172         context = context.elevated()
5173         LOG.debug("Getting vnc console", instance=instance)
5174 
5175         if not CONF.vnc.enabled:
5176             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5177 
5178         if console_type == 'novnc':
5179             # For essex, novncproxy_base_url must include the full path
5180             # including the html file (like http://myhost/vnc_auto.html)
5181             access_url_base = CONF.vnc.novncproxy_base_url
5182         elif console_type == 'xvpvnc':
5183             access_url_base = CONF.vnc.xvpvncproxy_base_url
5184         else:
5185             raise exception.ConsoleTypeInvalid(console_type=console_type)
5186 
5187         try:
5188             # Retrieve connect info from driver, and then decorate with our
5189             # access info token
5190             console = self.driver.get_vnc_console(context, instance)
5191             console_auth = objects.ConsoleAuthToken(
5192                 context=context,
5193                 console_type=console_type,
5194                 host=console.host,
5195                 port=console.port,
5196                 internal_access_path=console.internal_access_path,
5197                 instance_uuid=instance.uuid,
5198                 access_url_base=access_url_base,
5199             )
5200             console_auth.authorize(CONF.consoleauth.token_ttl)
5201             connect_info = console.get_connection_info(
5202                 console_auth.token, console_auth.access_url)
5203 
5204         except exception.InstanceNotFound:
5205             if instance.vm_state != vm_states.BUILDING:
5206                 raise
5207             raise exception.InstanceNotReady(instance_id=instance.uuid)
5208 
5209         return connect_info
5210 
5211     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5212                                    exception.InstanceNotReady,
5213                                    exception.InstanceNotFound,
5214                                    exception.ConsoleTypeUnavailable,
5215                                    NotImplementedError)
5216     @wrap_exception()
5217     @wrap_instance_fault
5218     def get_spice_console(self, context, console_type, instance):
5219         """Return connection information for a spice console."""
5220         context = context.elevated()
5221         LOG.debug("Getting spice console", instance=instance)
5222 
5223         if not CONF.spice.enabled:
5224             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5225 
5226         if console_type != 'spice-html5':
5227             raise exception.ConsoleTypeInvalid(console_type=console_type)
5228 
5229         try:
5230             # Retrieve connect info from driver, and then decorate with our
5231             # access info token
5232             console = self.driver.get_spice_console(context, instance)
5233             console_auth = objects.ConsoleAuthToken(
5234                 context=context,
5235                 console_type=console_type,
5236                 host=console.host,
5237                 port=console.port,
5238                 internal_access_path=console.internal_access_path,
5239                 instance_uuid=instance.uuid,
5240                 access_url_base=CONF.spice.html5proxy_base_url,
5241             )
5242             console_auth.authorize(CONF.consoleauth.token_ttl)
5243             connect_info = console.get_connection_info(
5244                 console_auth.token, console_auth.access_url)
5245 
5246         except exception.InstanceNotFound:
5247             if instance.vm_state != vm_states.BUILDING:
5248                 raise
5249             raise exception.InstanceNotReady(instance_id=instance.uuid)
5250 
5251         return connect_info
5252 
5253     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5254                                    exception.InstanceNotReady,
5255                                    exception.InstanceNotFound,
5256                                    exception.ConsoleTypeUnavailable,
5257                                    NotImplementedError)
5258     @wrap_exception()
5259     @wrap_instance_fault
5260     def get_rdp_console(self, context, console_type, instance):
5261         """Return connection information for a RDP console."""
5262         context = context.elevated()
5263         LOG.debug("Getting RDP console", instance=instance)
5264 
5265         if not CONF.rdp.enabled:
5266             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5267 
5268         if console_type != 'rdp-html5':
5269             raise exception.ConsoleTypeInvalid(console_type=console_type)
5270 
5271         try:
5272             # Retrieve connect info from driver, and then decorate with our
5273             # access info token
5274             console = self.driver.get_rdp_console(context, instance)
5275             console_auth = objects.ConsoleAuthToken(
5276                 context=context,
5277                 console_type=console_type,
5278                 host=console.host,
5279                 port=console.port,
5280                 internal_access_path=console.internal_access_path,
5281                 instance_uuid=instance.uuid,
5282                 access_url_base=CONF.rdp.html5_proxy_base_url,
5283             )
5284             console_auth.authorize(CONF.consoleauth.token_ttl)
5285             connect_info = console.get_connection_info(
5286                 console_auth.token, console_auth.access_url)
5287 
5288         except exception.InstanceNotFound:
5289             if instance.vm_state != vm_states.BUILDING:
5290                 raise
5291             raise exception.InstanceNotReady(instance_id=instance.uuid)
5292 
5293         return connect_info
5294 
5295     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5296                                    exception.InstanceNotReady,
5297                                    exception.InstanceNotFound,
5298                                    exception.ConsoleTypeUnavailable,
5299                                    NotImplementedError)
5300     @wrap_exception()
5301     @wrap_instance_fault
5302     def get_mks_console(self, context, console_type, instance):
5303         """Return connection information for a MKS console."""
5304         context = context.elevated()
5305         LOG.debug("Getting MKS console", instance=instance)
5306 
5307         if not CONF.mks.enabled:
5308             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5309 
5310         if console_type != 'webmks':
5311             raise exception.ConsoleTypeInvalid(console_type=console_type)
5312 
5313         try:
5314             # Retrieve connect info from driver, and then decorate with our
5315             # access info token
5316             console = self.driver.get_mks_console(context, instance)
5317             console_auth = objects.ConsoleAuthToken(
5318                 context=context,
5319                 console_type=console_type,
5320                 host=console.host,
5321                 port=console.port,
5322                 internal_access_path=console.internal_access_path,
5323                 instance_uuid=instance.uuid,
5324                 access_url_base=CONF.mks.mksproxy_base_url,
5325             )
5326             console_auth.authorize(CONF.consoleauth.token_ttl)
5327             connect_info = console.get_connection_info(
5328                 console_auth.token, console_auth.access_url)
5329 
5330         except exception.InstanceNotFound:
5331             if instance.vm_state != vm_states.BUILDING:
5332                 raise
5333             raise exception.InstanceNotReady(instance_id=instance.uuid)
5334 
5335         return connect_info
5336 
5337     @messaging.expected_exceptions(
5338         exception.ConsoleTypeInvalid,
5339         exception.InstanceNotReady,
5340         exception.InstanceNotFound,
5341         exception.ConsoleTypeUnavailable,
5342         exception.SocketPortRangeExhaustedException,
5343         exception.ImageSerialPortNumberInvalid,
5344         exception.ImageSerialPortNumberExceedFlavorValue,
5345         NotImplementedError)
5346     @wrap_exception()
5347     @wrap_instance_fault
5348     def get_serial_console(self, context, console_type, instance):
5349         """Returns connection information for a serial console."""
5350 
5351         LOG.debug("Getting serial console", instance=instance)
5352 
5353         if not CONF.serial_console.enabled:
5354             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5355 
5356         context = context.elevated()
5357 
5358         try:
5359             # Retrieve connect info from driver, and then decorate with our
5360             # access info token
5361             console = self.driver.get_serial_console(context, instance)
5362             console_auth = objects.ConsoleAuthToken(
5363                 context=context,
5364                 console_type=console_type,
5365                 host=console.host,
5366                 port=console.port,
5367                 internal_access_path=console.internal_access_path,
5368                 instance_uuid=instance.uuid,
5369                 access_url_base=CONF.serial_console.base_url,
5370             )
5371             console_auth.authorize(CONF.consoleauth.token_ttl)
5372             connect_info = console.get_connection_info(
5373                 console_auth.token, console_auth.access_url)
5374 
5375         except exception.InstanceNotFound:
5376             if instance.vm_state != vm_states.BUILDING:
5377                 raise
5378             raise exception.InstanceNotReady(instance_id=instance.uuid)
5379 
5380         return connect_info
5381 
5382     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5383                                    exception.InstanceNotReady,
5384                                    exception.InstanceNotFound)
5385     @wrap_exception()
5386     @wrap_instance_fault
5387     def validate_console_port(self, ctxt, instance, port, console_type):
5388         if console_type == "spice-html5":
5389             console_info = self.driver.get_spice_console(ctxt, instance)
5390         elif console_type == "rdp-html5":
5391             console_info = self.driver.get_rdp_console(ctxt, instance)
5392         elif console_type == "serial":
5393             console_info = self.driver.get_serial_console(ctxt, instance)
5394         elif console_type == "webmks":
5395             console_info = self.driver.get_mks_console(ctxt, instance)
5396         else:
5397             console_info = self.driver.get_vnc_console(ctxt, instance)
5398 
5399         return console_info.port == port
5400 
5401     @wrap_exception()
5402     @reverts_task_state
5403     @wrap_instance_fault
5404     def reserve_block_device_name(self, context, instance, device,
5405                                   volume_id, disk_bus, device_type, tag,
5406                                   multiattach):
5407         if (tag and not
5408                 self.driver.capabilities.get('supports_tagged_attach_volume',
5409                                              False)):
5410             raise exception.VolumeTaggedAttachNotSupported()
5411 
5412         if (multiattach and not
5413                 self.driver.capabilities.get('supports_multiattach', False)):
5414             raise exception.MultiattachNotSupportedByVirtDriver(
5415                 volume_id=volume_id)
5416 
5417         @utils.synchronized(instance.uuid)
5418         def do_reserve():
5419             bdms = (
5420                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5421                     context, instance.uuid))
5422 
5423             # NOTE(ndipanov): We need to explicitly set all the fields on the
5424             #                 object so that obj_load_attr does not fail
5425             new_bdm = objects.BlockDeviceMapping(
5426                     context=context,
5427                     source_type='volume', destination_type='volume',
5428                     instance_uuid=instance.uuid, boot_index=None,
5429                     volume_id=volume_id,
5430                     device_name=device, guest_format=None,
5431                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5432 
5433             new_bdm.device_name = self._get_device_name_for_instance(
5434                     instance, bdms, new_bdm)
5435 
5436             # NOTE(vish): create bdm here to avoid race condition
5437             new_bdm.create()
5438             return new_bdm
5439 
5440         return do_reserve()
5441 
5442     @wrap_exception()
5443     @wrap_instance_event(prefix='compute')
5444     @wrap_instance_fault
5445     def attach_volume(self, context, instance, bdm):
5446         """Attach a volume to an instance."""
5447         driver_bdm = driver_block_device.convert_volume(bdm)
5448 
5449         @utils.synchronized(instance.uuid)
5450         def do_attach_volume(context, instance, driver_bdm):
5451             try:
5452                 return self._attach_volume(context, instance, driver_bdm)
5453             except Exception:
5454                 with excutils.save_and_reraise_exception():
5455                     bdm.destroy()
5456 
5457         do_attach_volume(context, instance, driver_bdm)
5458 
5459     def _attach_volume(self, context, instance, bdm):
5460         context = context.elevated()
5461         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5462                  {'volume_id': bdm.volume_id,
5463                   'mountpoint': bdm['mount_device']},
5464                  instance=instance)
5465         compute_utils.notify_about_volume_attach_detach(
5466             context, instance, self.host,
5467             action=fields.NotificationAction.VOLUME_ATTACH,
5468             phase=fields.NotificationPhase.START,
5469             volume_id=bdm.volume_id)
5470         try:
5471             bdm.attach(context, instance, self.volume_api, self.driver,
5472                        do_driver_attach=True)
5473         except Exception as e:
5474             with excutils.save_and_reraise_exception():
5475                 LOG.exception("Failed to attach %(volume_id)s "
5476                               "at %(mountpoint)s",
5477                               {'volume_id': bdm.volume_id,
5478                                'mountpoint': bdm['mount_device']},
5479                               instance=instance)
5480                 if bdm['attachment_id']:
5481                     self.volume_api.attachment_delete(context,
5482                                                       bdm['attachment_id'])
5483                 else:
5484                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5485                 tb = traceback.format_exc()
5486                 compute_utils.notify_about_volume_attach_detach(
5487                     context, instance, self.host,
5488                     action=fields.NotificationAction.VOLUME_ATTACH,
5489                     phase=fields.NotificationPhase.ERROR,
5490                     exception=e,
5491                     volume_id=bdm.volume_id, tb=tb)
5492 
5493         info = {'volume_id': bdm.volume_id}
5494         self._notify_about_instance_usage(
5495             context, instance, "volume.attach", extra_usage_info=info)
5496         compute_utils.notify_about_volume_attach_detach(
5497             context, instance, self.host,
5498             action=fields.NotificationAction.VOLUME_ATTACH,
5499             phase=fields.NotificationPhase.END,
5500             volume_id=bdm.volume_id)
5501 
5502     def _notify_volume_usage_detach(self, context, instance, bdm):
5503         if CONF.volume_usage_poll_interval <= 0:
5504             return
5505 
5506         vol_stats = []
5507         mp = bdm.device_name
5508         # Handle bootable volumes which will not contain /dev/
5509         if '/dev/' in mp:
5510             mp = mp[5:]
5511         try:
5512             vol_stats = self.driver.block_stats(instance, mp)
5513         except NotImplementedError:
5514             return
5515 
5516         LOG.debug("Updating volume usage cache with totals", instance=instance)
5517         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5518         vol_usage = objects.VolumeUsage(context)
5519         vol_usage.volume_id = bdm.volume_id
5520         vol_usage.instance_uuid = instance.uuid
5521         vol_usage.project_id = instance.project_id
5522         vol_usage.user_id = instance.user_id
5523         vol_usage.availability_zone = instance.availability_zone
5524         vol_usage.curr_reads = rd_req
5525         vol_usage.curr_read_bytes = rd_bytes
5526         vol_usage.curr_writes = wr_req
5527         vol_usage.curr_write_bytes = wr_bytes
5528         vol_usage.save(update_totals=True)
5529         self.notifier.info(context, 'volume.usage',
5530                            compute_utils.usage_volume_info(vol_usage))
5531 
5532     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5533                        attachment_id=None):
5534         """Detach a volume from an instance.
5535 
5536         :param context: security context
5537         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5538         :param instance: the Instance object to detach the volume from
5539         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5540                             as deleted. Disabling this is useful for operations
5541                             like rebuild, when we don't want to destroy BDM
5542         :param attachment_id: The volume attachment_id for the given instance
5543                               and volume.
5544         """
5545         volume_id = bdm.volume_id
5546         compute_utils.notify_about_volume_attach_detach(
5547             context, instance, self.host,
5548             action=fields.NotificationAction.VOLUME_DETACH,
5549             phase=fields.NotificationPhase.START,
5550             volume_id=volume_id)
5551 
5552         self._notify_volume_usage_detach(context, instance, bdm)
5553 
5554         LOG.info('Detaching volume %(volume_id)s',
5555                  {'volume_id': volume_id}, instance=instance)
5556 
5557         driver_bdm = driver_block_device.convert_volume(bdm)
5558         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5559                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5560 
5561         info = dict(volume_id=volume_id)
5562         self._notify_about_instance_usage(
5563             context, instance, "volume.detach", extra_usage_info=info)
5564         compute_utils.notify_about_volume_attach_detach(
5565             context, instance, self.host,
5566             action=fields.NotificationAction.VOLUME_DETACH,
5567             phase=fields.NotificationPhase.END,
5568             volume_id=volume_id)
5569 
5570         if 'tag' in bdm and bdm.tag:
5571             self._delete_disk_metadata(instance, bdm)
5572         if destroy_bdm:
5573             bdm.destroy()
5574 
5575     def _delete_disk_metadata(self, instance, bdm):
5576         for device in instance.device_metadata.devices:
5577             if isinstance(device, objects.DiskMetadata):
5578                 if 'serial' in device:
5579                     if device.serial == bdm.volume_id:
5580                         instance.device_metadata.devices.remove(device)
5581                         instance.save()
5582                         break
5583                 else:
5584                     # NOTE(artom) We log the entire device object because all
5585                     # fields are nullable and may not be set
5586                     LOG.warning('Unable to determine whether to clean up '
5587                                 'device metadata for disk %s', device,
5588                                 instance=instance)
5589 
5590     @wrap_exception()
5591     @wrap_instance_event(prefix='compute')
5592     @wrap_instance_fault
5593     def detach_volume(self, context, volume_id, instance, attachment_id):
5594         """Detach a volume from an instance.
5595 
5596         :param context: security context
5597         :param volume_id: the volume id
5598         :param instance: the Instance object to detach the volume from
5599         :param attachment_id: The volume attachment_id for the given instance
5600                               and volume.
5601 
5602         """
5603         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5604                 context, volume_id, instance.uuid)
5605         self._detach_volume(context, bdm, instance,
5606                             attachment_id=attachment_id)
5607 
5608     def _init_volume_connection(self, context, new_volume,
5609                                 old_volume_id, connector, bdm,
5610                                 new_attachment_id, mountpoint):
5611         new_volume_id = new_volume['id']
5612         if new_attachment_id is None:
5613             # We're dealing with an old-style attachment so initialize the
5614             # connection so we can get the connection_info.
5615             new_cinfo = self.volume_api.initialize_connection(context,
5616                                                               new_volume_id,
5617                                                               connector)
5618         else:
5619             # Check for multiattach on the new volume and if True, check to
5620             # see if the virt driver supports multiattach.
5621             # TODO(mriedem): This is copied from DriverVolumeBlockDevice
5622             # and should be consolidated into some common code at some point.
5623             vol_multiattach = new_volume.get('multiattach', False)
5624             virt_multiattach = self.driver.capabilities.get(
5625                 'supports_multiattach', False)
5626             if vol_multiattach and not virt_multiattach:
5627                 raise exception.MultiattachNotSupportedByVirtDriver(
5628                     volume_id=new_volume_id)
5629 
5630             # This is a new style attachment and the API created the new
5631             # volume attachment and passed the id to the compute over RPC.
5632             # At this point we need to update the new volume attachment with
5633             # the host connector, which will give us back the new attachment
5634             # connection_info.
5635             new_cinfo = self.volume_api.attachment_update(
5636                 context, new_attachment_id, connector,
5637                 mountpoint)['connection_info']
5638 
5639             if vol_multiattach:
5640                 # This will be used by the volume driver to determine the
5641                 # proper disk configuration.
5642                 new_cinfo['multiattach'] = True
5643 
5644         old_cinfo = jsonutils.loads(bdm['connection_info'])
5645         if old_cinfo and 'serial' not in old_cinfo:
5646             old_cinfo['serial'] = old_volume_id
5647         # NOTE(lyarwood): serial is not always present in the returned
5648         # connection_info so set it if it is missing as we do in
5649         # DriverVolumeBlockDevice.attach().
5650         if 'serial' not in new_cinfo:
5651             new_cinfo['serial'] = new_volume_id
5652         return (old_cinfo, new_cinfo)
5653 
5654     def _swap_volume(self, context, instance, bdm, connector,
5655                      old_volume_id, new_volume, resize_to,
5656                      new_attachment_id, is_cinder_migration):
5657         new_volume_id = new_volume['id']
5658         mountpoint = bdm['device_name']
5659         failed = False
5660         new_cinfo = None
5661         try:
5662             old_cinfo, new_cinfo = self._init_volume_connection(
5663                 context, new_volume, old_volume_id, connector,
5664                 bdm, new_attachment_id, mountpoint)
5665             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5666             # currently implementing swap_volume, will modify the contents of
5667             # new_cinfo when connect_volume is called. This is then saved to
5668             # the BDM in swap_volume for future use outside of this flow.
5669             msg = ("swap_volume: Calling driver volume swap with "
5670                    "connection infos: new: %(new_cinfo)s; "
5671                    "old: %(old_cinfo)s" %
5672                    {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo})
5673             # Both new and old info might contain password
5674             LOG.debug(strutils.mask_password(msg), instance=instance)
5675 
5676             self.driver.swap_volume(context, old_cinfo, new_cinfo, instance,
5677                                     mountpoint, resize_to)
5678             if new_attachment_id:
5679                 self.volume_api.attachment_complete(context, new_attachment_id)
5680             msg = ("swap_volume: Driver volume swap returned, new "
5681                    "connection_info is now : %(new_cinfo)s" %
5682                    {'new_cinfo': new_cinfo})
5683             LOG.debug(strutils.mask_password(msg))
5684         except Exception as ex:
5685             failed = True
5686             with excutils.save_and_reraise_exception():
5687                 tb = traceback.format_exc()
5688                 compute_utils.notify_about_volume_swap(
5689                     context, instance, self.host,
5690                     fields.NotificationPhase.ERROR,
5691                     old_volume_id, new_volume_id, ex, tb)
5692                 if new_cinfo:
5693                     msg = ("Failed to swap volume %(old_volume_id)s "
5694                            "for %(new_volume_id)s")
5695                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5696                                         'new_volume_id': new_volume_id},
5697                                   instance=instance)
5698                 else:
5699                     msg = ("Failed to connect to volume %(volume_id)s "
5700                            "with volume at %(mountpoint)s")
5701                     LOG.exception(msg, {'volume_id': new_volume_id,
5702                                         'mountpoint': bdm['device_name']},
5703                                   instance=instance)
5704 
5705                 # The API marked the volume as 'detaching' for the old volume
5706                 # so we need to roll that back so the volume goes back to
5707                 # 'in-use' state.
5708                 self.volume_api.roll_detaching(context, old_volume_id)
5709 
5710                 if new_attachment_id is None:
5711                     # The API reserved the new volume so it would be in
5712                     # 'attaching' status, so we need to unreserve it so it
5713                     # goes back to 'available' status.
5714                     self.volume_api.unreserve_volume(context, new_volume_id)
5715                 else:
5716                     # This is a new style attachment for the new volume, which
5717                     # was created in the API. We just need to delete it here
5718                     # to put the new volume back into 'available' status.
5719                     self.volume_api.attachment_delete(
5720                         context, new_attachment_id)
5721         finally:
5722             # TODO(mriedem): This finally block is terribly confusing and is
5723             # trying to do too much. We should consider removing the finally
5724             # block and move whatever needs to happen on success and failure
5725             # into the blocks above for clarity, even if it means a bit of
5726             # redundant code.
5727             conn_volume = new_volume_id if failed else old_volume_id
5728             if new_cinfo:
5729                 LOG.debug("swap_volume: removing Cinder connection "
5730                           "for volume %(volume)s", {'volume': conn_volume},
5731                           instance=instance)
5732                 if bdm.attachment_id is None:
5733                     # This is the pre-3.44 flow for new-style volume
5734                     # attachments so just terminate the connection.
5735                     self.volume_api.terminate_connection(context,
5736                                                          conn_volume,
5737                                                          connector)
5738                 else:
5739                     # This is a new style volume attachment. If we failed, then
5740                     # the new attachment was already deleted above in the
5741                     # exception block and we have nothing more to do here. If
5742                     # swap_volume was successful in the driver, then we need to
5743                     # "detach" the original attachment by deleting it.
5744                     if not failed:
5745                         self.volume_api.attachment_delete(
5746                             context, bdm.attachment_id)
5747 
5748             # Need to make some decisions based on whether this was
5749             # a Cinder initiated migration or not. The callback to
5750             # migration completion isn't needed in the case of a
5751             # nova initiated simple swap of two volume
5752             # "volume-update" call so skip that. The new attachment
5753             # scenarios will give us a new attachment record and
5754             # that's what we want.
5755             if bdm.attachment_id and not is_cinder_migration:
5756                 # we don't callback to cinder
5757                 comp_ret = {'save_volume_id': new_volume_id}
5758             else:
5759                 # NOTE(lyarwood): The following call to
5760                 # os-migrate-volume-completion returns a dict containing
5761                 # save_volume_id, this volume id has two possible values :
5762                 # 1. old_volume_id if we are migrating (retyping) volumes
5763                 # 2. new_volume_id if we are swapping between two existing
5764                 #    volumes
5765                 # This volume id is later used to update the volume_id and
5766                 # connection_info['serial'] of the BDM.
5767                 comp_ret = self.volume_api.migrate_volume_completion(
5768                                                           context,
5769                                                           old_volume_id,
5770                                                           new_volume_id,
5771                                                           error=failed)
5772                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5773                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5774                           instance=instance)
5775 
5776         return (comp_ret, new_cinfo)
5777 
5778     @wrap_exception()
5779     @wrap_instance_event(prefix='compute')
5780     @wrap_instance_fault
5781     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
5782                     new_attachment_id):
5783         """Swap volume for an instance."""
5784         context = context.elevated()
5785 
5786         compute_utils.notify_about_volume_swap(
5787             context, instance, self.host,
5788             fields.NotificationPhase.START,
5789             old_volume_id, new_volume_id)
5790 
5791         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5792                 context, old_volume_id, instance.uuid)
5793         connector = self.driver.get_volume_connector(instance)
5794 
5795         resize_to = 0
5796         old_volume = self.volume_api.get(context, old_volume_id)
5797         # Yes this is a tightly-coupled state check of what's going on inside
5798         # cinder, but we need this while we still support old (v1/v2) and
5799         # new style attachments (v3.44). Once we drop support for old style
5800         # attachments we could think about cleaning up the cinder-initiated
5801         # swap volume API flows.
5802         is_cinder_migration = (
5803             True if old_volume['status'] in ('retyping',
5804                                              'migrating') else False)
5805         old_vol_size = old_volume['size']
5806         new_volume = self.volume_api.get(context, new_volume_id)
5807         new_vol_size = new_volume['size']
5808         if new_vol_size > old_vol_size:
5809             resize_to = new_vol_size
5810 
5811         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5812                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5813                  instance=instance)
5814         comp_ret, new_cinfo = self._swap_volume(context,
5815                                                 instance,
5816                                                 bdm,
5817                                                 connector,
5818                                                 old_volume_id,
5819                                                 new_volume,
5820                                                 resize_to,
5821                                                 new_attachment_id,
5822                                                 is_cinder_migration)
5823 
5824         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5825         # correct volume_id returned by Cinder.
5826         save_volume_id = comp_ret['save_volume_id']
5827         new_cinfo['serial'] = save_volume_id
5828         values = {
5829             'connection_info': jsonutils.dumps(new_cinfo),
5830             'source_type': 'volume',
5831             'destination_type': 'volume',
5832             'snapshot_id': None,
5833             'volume_id': save_volume_id,
5834             'no_device': None}
5835 
5836         if resize_to:
5837             values['volume_size'] = resize_to
5838 
5839         if new_attachment_id is not None:
5840             # This was a volume swap for a new-style attachment so we
5841             # need to update the BDM attachment_id for the new attachment.
5842             values['attachment_id'] = new_attachment_id
5843 
5844         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5845                   "%(updates)s", {'volume_id': bdm.volume_id,
5846                                   'updates': values},
5847                   instance=instance)
5848         bdm.update(values)
5849         bdm.save()
5850 
5851         compute_utils.notify_about_volume_swap(
5852             context, instance, self.host,
5853             fields.NotificationPhase.END,
5854             old_volume_id, new_volume_id)
5855 
5856     @wrap_exception()
5857     def remove_volume_connection(self, context, volume_id, instance):
5858         """Remove the volume connection on this host
5859 
5860         Detach the volume from this instance on this host, and if this is
5861         the cinder v2 flow, call cinder to terminate the connection.
5862         """
5863         try:
5864             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5865                     context, volume_id, instance.uuid)
5866             driver_bdm = driver_block_device.convert_volume(bdm)
5867             driver_bdm.driver_detach(context, instance,
5868                                      self.volume_api, self.driver)
5869             if bdm.attachment_id is None:
5870                 # cinder v2 api flow
5871                 connector = self.driver.get_volume_connector(instance)
5872                 self.volume_api.terminate_connection(context, volume_id,
5873                                                      connector)
5874         except exception.NotFound:
5875             pass
5876 
5877     @wrap_exception()
5878     @wrap_instance_event(prefix='compute')
5879     @wrap_instance_fault
5880     def attach_interface(self, context, instance, network_id, port_id,
5881                          requested_ip, tag):
5882         """Use hotplug to add an network adapter to an instance."""
5883         if not self.driver.capabilities.get('supports_attach_interface',
5884                                             False):
5885             raise exception.AttachInterfaceNotSupported(
5886                 instance_uuid=instance.uuid)
5887         if (tag and not
5888             self.driver.capabilities.get('supports_tagged_attach_interface',
5889                                          False)):
5890             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5891 
5892         compute_utils.notify_about_instance_action(
5893             context, instance, self.host,
5894             action=fields.NotificationAction.INTERFACE_ATTACH,
5895             phase=fields.NotificationPhase.START)
5896 
5897         bind_host_id = self.driver.network_binding_host_id(context, instance)
5898         network_info = self.network_api.allocate_port_for_instance(
5899             context, instance, port_id, network_id, requested_ip,
5900             bind_host_id=bind_host_id, tag=tag)
5901         if len(network_info) != 1:
5902             LOG.error('allocate_port_for_instance returned %(ports)s '
5903                       'ports', {'ports': len(network_info)})
5904             # TODO(elod.illes): an instance.interface_attach.error notification
5905             # should be sent here
5906             raise exception.InterfaceAttachFailed(
5907                     instance_uuid=instance.uuid)
5908         image_meta = objects.ImageMeta.from_instance(instance)
5909 
5910         try:
5911             self.driver.attach_interface(context, instance, image_meta,
5912                                          network_info[0])
5913         except exception.NovaException as ex:
5914             port_id = network_info[0].get('id')
5915             LOG.warning("attach interface failed , try to deallocate "
5916                         "port %(port_id)s, reason: %(msg)s",
5917                         {'port_id': port_id, 'msg': ex},
5918                         instance=instance)
5919             try:
5920                 self.network_api.deallocate_port_for_instance(
5921                     context, instance, port_id)
5922             except Exception:
5923                 LOG.warning("deallocate port %(port_id)s failed",
5924                             {'port_id': port_id}, instance=instance)
5925 
5926             tb = traceback.format_exc()
5927             compute_utils.notify_about_instance_action(
5928                 context, instance, self.host,
5929                 action=fields.NotificationAction.INTERFACE_ATTACH,
5930                 phase=fields.NotificationPhase.ERROR,
5931                 exception=ex, tb=tb)
5932 
5933             raise exception.InterfaceAttachFailed(
5934                 instance_uuid=instance.uuid)
5935 
5936         compute_utils.notify_about_instance_action(
5937             context, instance, self.host,
5938             action=fields.NotificationAction.INTERFACE_ATTACH,
5939             phase=fields.NotificationPhase.END)
5940 
5941         return network_info[0]
5942 
5943     @wrap_exception()
5944     @wrap_instance_event(prefix='compute')
5945     @wrap_instance_fault
5946     def detach_interface(self, context, instance, port_id):
5947         """Detach a network adapter from an instance."""
5948         network_info = instance.info_cache.network_info
5949         condemned = None
5950         for vif in network_info:
5951             if vif['id'] == port_id:
5952                 condemned = vif
5953                 break
5954         if condemned is None:
5955             raise exception.PortNotFound(_("Port %s is not "
5956                                            "attached") % port_id)
5957 
5958         compute_utils.notify_about_instance_action(
5959             context, instance, self.host,
5960             action=fields.NotificationAction.INTERFACE_DETACH,
5961             phase=fields.NotificationPhase.START)
5962 
5963         try:
5964             self.driver.detach_interface(context, instance, condemned)
5965         except exception.NovaException as ex:
5966             # If the instance was deleted before the interface was detached,
5967             # just log it at debug.
5968             log_level = (logging.DEBUG
5969                          if isinstance(ex, exception.InstanceNotFound)
5970                          else logging.WARNING)
5971             LOG.log(log_level,
5972                     "Detach interface failed, port_id=%(port_id)s, reason: "
5973                     "%(msg)s", {'port_id': port_id, 'msg': ex},
5974                     instance=instance)
5975             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5976         else:
5977             try:
5978                 self.network_api.deallocate_port_for_instance(
5979                     context, instance, port_id)
5980             except Exception as ex:
5981                 with excutils.save_and_reraise_exception():
5982                     # Since this is a cast operation, log the failure for
5983                     # triage.
5984                     LOG.warning('Failed to deallocate port %(port_id)s '
5985                                 'for instance. Error: %(error)s',
5986                                 {'port_id': port_id, 'error': ex},
5987                                 instance=instance)
5988 
5989         compute_utils.notify_about_instance_action(
5990             context, instance, self.host,
5991             action=fields.NotificationAction.INTERFACE_DETACH,
5992             phase=fields.NotificationPhase.END)
5993 
5994     def _get_compute_info(self, context, host):
5995         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5996             context, host)
5997 
5998     @wrap_exception()
5999     def check_instance_shared_storage(self, ctxt, instance, data):
6000         """Check if the instance files are shared
6001 
6002         :param ctxt: security context
6003         :param instance: dict of instance data
6004         :param data: result of driver.check_instance_shared_storage_local
6005 
6006         Returns True if instance disks located on shared storage and
6007         False otherwise.
6008         """
6009         return self.driver.check_instance_shared_storage_remote(ctxt, data)
6010 
6011     @wrap_exception()
6012     @wrap_instance_event(prefix='compute')
6013     @wrap_instance_fault
6014     def check_can_live_migrate_destination(self, ctxt, instance,
6015                                            block_migration, disk_over_commit):
6016         """Check if it is possible to execute live migration.
6017 
6018         This runs checks on the destination host, and then calls
6019         back to the source host to check the results.
6020 
6021         :param context: security context
6022         :param instance: dict of instance data
6023         :param block_migration: if true, prepare for block migration
6024                                 if None, calculate it in driver
6025         :param disk_over_commit: if true, allow disk over commit
6026                                  if None, ignore disk usage checking
6027         :returns: a dict containing migration info
6028         """
6029         src_compute_info = obj_base.obj_to_primitive(
6030             self._get_compute_info(ctxt, instance.host))
6031         dst_compute_info = obj_base.obj_to_primitive(
6032             self._get_compute_info(ctxt, CONF.host))
6033         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
6034             instance, src_compute_info, dst_compute_info,
6035             block_migration, disk_over_commit)
6036         LOG.debug('destination check data is %s', dest_check_data)
6037         try:
6038             migrate_data = self.compute_rpcapi.\
6039                                 check_can_live_migrate_source(ctxt, instance,
6040                                                               dest_check_data)
6041         finally:
6042             self.driver.cleanup_live_migration_destination_check(ctxt,
6043                     dest_check_data)
6044         return migrate_data
6045 
6046     @wrap_exception()
6047     @wrap_instance_event(prefix='compute')
6048     @wrap_instance_fault
6049     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
6050         """Check if it is possible to execute live migration.
6051 
6052         This checks if the live migration can succeed, based on the
6053         results from check_can_live_migrate_destination.
6054 
6055         :param ctxt: security context
6056         :param instance: dict of instance data
6057         :param dest_check_data: result of check_can_live_migrate_destination
6058         :returns: a dict containing migration info
6059         """
6060         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6061             ctxt, instance.uuid)
6062         is_volume_backed = compute_utils.is_volume_backed_instance(
6063             ctxt, instance, bdms)
6064         dest_check_data.is_volume_backed = is_volume_backed
6065         block_device_info = self._get_instance_block_device_info(
6066                             ctxt, instance, refresh_conn_info=False, bdms=bdms)
6067         result = self.driver.check_can_live_migrate_source(ctxt, instance,
6068                                                            dest_check_data,
6069                                                            block_device_info)
6070         LOG.debug('source check data is %s', result)
6071         return result
6072 
6073     @wrap_exception()
6074     @wrap_instance_event(prefix='compute')
6075     @wrap_instance_fault
6076     def pre_live_migration(self, context, instance, block_migration, disk,
6077                            migrate_data):
6078         """Preparations for live migration at dest host.
6079 
6080         :param context: security context
6081         :param instance: dict of instance data
6082         :param block_migration: if true, prepare for block migration
6083         :param disk: disk info of instance
6084         :param migrate_data: A dict or LiveMigrateData object holding data
6085                              required for live migration without shared
6086                              storage.
6087         :returns: migrate_data containing additional migration info
6088         """
6089         LOG.debug('pre_live_migration data is %s', migrate_data)
6090 
6091         migrate_data.old_vol_attachment_ids = {}
6092         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6093             context, instance.uuid)
6094         try:
6095             connector = self.driver.get_volume_connector(instance)
6096             for bdm in bdms:
6097                 if bdm.is_volume and bdm.attachment_id is not None:
6098                     # This bdm uses the new cinder v3.44 API.
6099                     # We will create a new attachment for this
6100                     # volume on this migration destination host. The old
6101                     # attachment will be deleted on the source host
6102                     # when the migration succeeds. The old attachment_id
6103                     # is stored in dict with the key being the bdm.volume_id
6104                     # so it can be restored on rollback.
6105                     #
6106                     # Also note that attachment_update is not needed as we
6107                     # are providing the connector in the create call.
6108                     attach_ref = self.volume_api.attachment_create(
6109                         context, bdm.volume_id, bdm.instance_uuid,
6110                         connector=connector, mountpoint=bdm.device_name)
6111 
6112                     # save current attachment so we can detach it on success,
6113                     # or restore it on a rollback.
6114                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
6115                         bdm.attachment_id
6116 
6117                     # update the bdm with the new attachment_id.
6118                     bdm.attachment_id = attach_ref['id']
6119                     bdm.save()
6120         except Exception:
6121             # If we raise, migrate_data with the updated attachment ids
6122             # will not be returned to the source host for rollback.
6123             # So we need to rollback new attachments here.
6124             with excutils.save_and_reraise_exception():
6125                 old_attachments = migrate_data.old_vol_attachment_ids
6126                 for bdm in bdms:
6127                     if (bdm.is_volume and bdm.attachment_id is not None and
6128                             bdm.volume_id in old_attachments):
6129                         self.volume_api.attachment_delete(context,
6130                                                           bdm.attachment_id)
6131                         bdm.attachment_id = old_attachments[bdm.volume_id]
6132                         bdm.save()
6133 
6134         block_device_info = self._get_instance_block_device_info(
6135                             context, instance, refresh_conn_info=True,
6136                             bdms=bdms)
6137 
6138         network_info = self.network_api.get_instance_nw_info(context, instance)
6139         self._notify_about_instance_usage(
6140                      context, instance, "live_migration.pre.start",
6141                      network_info=network_info)
6142         compute_utils.notify_about_instance_action(
6143             context, instance, self.host,
6144             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6145             phase=fields.NotificationPhase.START)
6146 
6147         # The driver pre_live_migration will plug vifs on the host.
6148         # We call plug_vifs before calling ensure_filtering_rules_for_instance,
6149         # to ensure bridge is set up.
6150         migrate_data = self.driver.pre_live_migration(context,
6151                                        instance,
6152                                        block_device_info,
6153                                        network_info,
6154                                        disk,
6155                                        migrate_data)
6156         LOG.debug('driver pre_live_migration data is %s', migrate_data)
6157         # driver.pre_live_migration is what plugs vifs on the destination host
6158         # so now we can set the wait_for_vif_plugged flag in the migrate_data
6159         # object which the source compute will use to determine if it should
6160         # wait for a 'network-vif-plugged' event from neutron before starting
6161         # the actual guest transfer in the hypervisor
6162         migrate_data.wait_for_vif_plugged = (
6163             CONF.compute.live_migration_wait_for_vif_plug)
6164 
6165         # Volume connections are complete, tell cinder that all the
6166         # attachments have completed.
6167         for bdm in bdms:
6168             if bdm.is_volume and bdm.attachment_id is not None:
6169                 self.volume_api.attachment_complete(context,
6170                                                     bdm.attachment_id)
6171 
6172         # NOTE(tr3buchet): setup networks on destination host
6173         self.network_api.setup_networks_on_host(context, instance,
6174                                                          self.host)
6175 
6176         # Creating filters to hypervisors and firewalls.
6177         # An example is that nova-instance-instance-xxx,
6178         # which is written to libvirt.xml(Check "virsh nwfilter-list")
6179         # This nwfilter is necessary on the destination host.
6180         # In addition, this method is creating filtering rule
6181         # onto destination host.
6182         self.driver.ensure_filtering_rules_for_instance(instance,
6183                                             network_info)
6184 
6185         self._notify_about_instance_usage(
6186                      context, instance, "live_migration.pre.end",
6187                      network_info=network_info)
6188         compute_utils.notify_about_instance_action(
6189             context, instance, self.host,
6190             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6191             phase=fields.NotificationPhase.END)
6192 
6193         LOG.debug('pre_live_migration result data is %s', migrate_data)
6194         return migrate_data
6195 
6196     @staticmethod
6197     def _neutron_failed_live_migration_callback(event_name, instance):
6198         msg = ('Neutron reported failure during live migration '
6199                'with %(event)s for instance %(uuid)s')
6200         msg_args = {'event': event_name, 'uuid': instance.uuid}
6201         if CONF.vif_plugging_is_fatal:
6202             raise exception.VirtualInterfacePlugException(msg % msg_args)
6203         LOG.error(msg, msg_args)
6204 
6205     @staticmethod
6206     def _get_neutron_events_for_live_migration(instance):
6207         # We don't generate events if CONF.vif_plugging_timeout=0
6208         # meaning that the operator disabled using them.
6209         if CONF.vif_plugging_timeout and utils.is_neutron():
6210             return [('network-vif-plugged', vif['id'])
6211                     for vif in instance.get_network_info()]
6212         else:
6213             return []
6214 
6215     def _cleanup_pre_live_migration(self, context, dest, instance,
6216                                     migration, migrate_data):
6217         """Helper method for when pre_live_migration fails
6218 
6219         Sets the migration status to "error" and rolls back the live migration
6220         setup on the destination host.
6221 
6222         :param context: The user request context.
6223         :type context: nova.context.RequestContext
6224         :param dest: The live migration destination hostname.
6225         :type dest: str
6226         :param instance: The instance being live migrated.
6227         :type instance: nova.objects.Instance
6228         :param migration: The migration record tracking this live migration.
6229         :type migration: nova.objects.Migration
6230         :param migrate_data: Data about the live migration, populated from
6231                              the destination host.
6232         :type migrate_data: Subclass of nova.objects.LiveMigrateData
6233         """
6234         self._set_migration_status(migration, 'error')
6235         # Make sure we set this for _rollback_live_migration()
6236         # so it can find it, as expected if it was called later
6237         migrate_data.migration = migration
6238         self._rollback_live_migration(context, instance, dest,
6239                                       migrate_data)
6240 
6241     def _do_live_migration(self, context, dest, instance, block_migration,
6242                            migration, migrate_data):
6243         # NOTE(danms): We should enhance the RT to account for migrations
6244         # and use the status field to denote when the accounting has been
6245         # done on source/destination. For now, this is just here for status
6246         # reporting
6247         self._set_migration_status(migration, 'preparing')
6248 
6249         class _BreakWaitForInstanceEvent(Exception):
6250             """Used as a signal to stop waiting for the network-vif-plugged
6251             event when we discover that
6252             [compute]/live_migration_wait_for_vif_plug is not set on the
6253             destination.
6254             """
6255             pass
6256 
6257         events = self._get_neutron_events_for_live_migration(instance)
6258         try:
6259             if ('block_migration' in migrate_data and
6260                     migrate_data.block_migration):
6261                 block_device_info = self._get_instance_block_device_info(
6262                     context, instance)
6263                 disk = self.driver.get_instance_disk_info(
6264                     instance, block_device_info=block_device_info)
6265             else:
6266                 disk = None
6267 
6268             deadline = CONF.vif_plugging_timeout
6269             error_cb = self._neutron_failed_live_migration_callback
6270             # In order to avoid a race with the vif plugging that the virt
6271             # driver does on the destination host, we register our events
6272             # to wait for before calling pre_live_migration. Then if the
6273             # dest host reports back that we shouldn't wait, we can break
6274             # out of the context manager using _BreakWaitForInstanceEvent.
6275             with self.virtapi.wait_for_instance_event(
6276                     instance, events, deadline=deadline,
6277                     error_callback=error_cb):
6278                 with timeutils.StopWatch() as timer:
6279                     migrate_data = self.compute_rpcapi.pre_live_migration(
6280                         context, instance,
6281                         block_migration, disk, dest, migrate_data)
6282                 LOG.info('Took %0.2f seconds for pre_live_migration on '
6283                          'destination host %s.',
6284                          timer.elapsed(), dest, instance=instance)
6285                 wait_for_vif_plugged = (
6286                     'wait_for_vif_plugged' in migrate_data and
6287                     migrate_data.wait_for_vif_plugged)
6288                 if events and not wait_for_vif_plugged:
6289                     raise _BreakWaitForInstanceEvent
6290         except _BreakWaitForInstanceEvent:
6291             if events:
6292                 LOG.debug('Not waiting for events after pre_live_migration: '
6293                           '%s. ', events, instance=instance)
6294             # This is a bit weird, but we need to clear sys.exc_info() so that
6295             # oslo.log formatting does not inadvertently use it later if an
6296             # error message is logged without an explicit exc_info. This is
6297             # only a problem with python 2.
6298             if six.PY2:
6299                 sys.exc_clear()
6300         except exception.VirtualInterfacePlugException:
6301             with excutils.save_and_reraise_exception():
6302                 LOG.exception('Failed waiting for network virtual interfaces '
6303                               'to be plugged on the destination host %s.',
6304                               dest, instance=instance)
6305                 self._cleanup_pre_live_migration(
6306                     context, dest, instance, migration, migrate_data)
6307         except eventlet.timeout.Timeout:
6308             msg = 'Timed out waiting for events: %s'
6309             LOG.warning(msg, events, instance=instance)
6310             if CONF.vif_plugging_is_fatal:
6311                 self._cleanup_pre_live_migration(
6312                     context, dest, instance, migration, migrate_data)
6313                 raise exception.MigrationError(reason=msg % events)
6314         except Exception:
6315             with excutils.save_and_reraise_exception():
6316                 LOG.exception('Pre live migration failed at %s',
6317                               dest, instance=instance)
6318                 self._cleanup_pre_live_migration(
6319                     context, dest, instance, migration, migrate_data)
6320 
6321         # NOTE(Kevin_Zheng): Pop the migration from the waiting queue
6322         # if it exist in the queue, then we are good to moving on, if
6323         # not, some other process must have aborted it, then we should
6324         # rollback.
6325         try:
6326             self._waiting_live_migrations.pop(instance.uuid)
6327         except KeyError:
6328             LOG.debug('Migration %s aborted by another process, rollback.',
6329                       migration.uuid, instance=instance)
6330             migrate_data.migration = migration
6331             self._rollback_live_migration(context, instance, dest,
6332                                           migrate_data, 'cancelled')
6333             self._notify_live_migrate_abort_end(context, instance)
6334             return
6335 
6336         self._set_migration_status(migration, 'running')
6337         if migrate_data:
6338             migrate_data.migration = migration
6339         LOG.debug('live_migration data is %s', migrate_data)
6340         try:
6341             self.driver.live_migration(context, instance, dest,
6342                                        self._post_live_migration,
6343                                        self._rollback_live_migration,
6344                                        block_migration, migrate_data)
6345         except Exception:
6346             LOG.exception('Live migration failed.', instance=instance)
6347             with excutils.save_and_reraise_exception():
6348                 # Put instance and migration into error state,
6349                 # as its almost certainly too late to rollback
6350                 self._set_migration_status(migration, 'error')
6351                 # first refresh instance as it may have got updated by
6352                 # post_live_migration_at_destination
6353                 instance.refresh()
6354                 self._set_instance_obj_error_state(context, instance,
6355                                                    clean_task_state=True)
6356 
6357     @wrap_exception()
6358     @wrap_instance_event(prefix='compute')
6359     @wrap_instance_fault
6360     def live_migration(self, context, dest, instance, block_migration,
6361                        migration, migrate_data):
6362         """Executing live migration.
6363 
6364         :param context: security context
6365         :param dest: destination host
6366         :param instance: a nova.objects.instance.Instance object
6367         :param block_migration: if true, prepare for block migration
6368         :param migration: an nova.objects.Migration object
6369         :param migrate_data: implementation specific params
6370 
6371         """
6372         self._set_migration_status(migration, 'queued')
6373         # NOTE(Kevin_Zheng): Submit the live_migration job to the pool and
6374         # put the returned Future object into dict mapped with migration.uuid
6375         # in order to be able to track and abort it in the future.
6376         self._waiting_live_migrations[instance.uuid] = (None, None)
6377         try:
6378             future = self._live_migration_executor.submit(
6379                 self._do_live_migration, context, dest, instance,
6380                 block_migration, migration, migrate_data)
6381             self._waiting_live_migrations[instance.uuid] = (migration, future)
6382         except RuntimeError:
6383             # ThreadPoolExecutor.submit will raise RuntimeError if the pool
6384             # is shutdown, which happens in _cleanup_live_migrations_in_pool.
6385             LOG.info('Migration %s failed to submit as the compute service '
6386                      'is shutting down.', migration.uuid, instance=instance)
6387             self._set_migration_status(migration, 'error')
6388             raise exception.LiveMigrationNotSubmitted(
6389                 migration_uuid=migration.uuid, instance_uuid=instance.uuid)
6390 
6391     @wrap_exception()
6392     @wrap_instance_event(prefix='compute')
6393     @wrap_instance_fault
6394     def live_migration_force_complete(self, context, instance):
6395         """Force live migration to complete.
6396 
6397         :param context: Security context
6398         :param instance: The instance that is being migrated
6399         """
6400 
6401         self._notify_about_instance_usage(
6402             context, instance, 'live.migration.force.complete.start')
6403         compute_utils.notify_about_instance_action(
6404             context, instance, self.host,
6405             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6406             phase=fields.NotificationPhase.START)
6407         self.driver.live_migration_force_complete(instance)
6408         self._notify_about_instance_usage(
6409             context, instance, 'live.migration.force.complete.end')
6410         compute_utils.notify_about_instance_action(
6411             context, instance, self.host,
6412             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6413             phase=fields.NotificationPhase.END)
6414 
6415     def _notify_live_migrate_abort_end(self, context, instance):
6416         self._notify_about_instance_usage(
6417             context, instance, 'live.migration.abort.end')
6418         compute_utils.notify_about_instance_action(
6419             context, instance, self.host,
6420             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6421             phase=fields.NotificationPhase.END)
6422 
6423     @wrap_exception()
6424     @wrap_instance_event(prefix='compute')
6425     @wrap_instance_fault
6426     def live_migration_abort(self, context, instance, migration_id):
6427         """Abort an in-progress live migration.
6428 
6429         :param context: Security context
6430         :param instance: The instance that is being migrated
6431         :param migration_id: ID of in-progress live migration
6432 
6433         """
6434         self._notify_about_instance_usage(
6435             context, instance, 'live.migration.abort.start')
6436         compute_utils.notify_about_instance_action(
6437             context, instance, self.host,
6438             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6439             phase=fields.NotificationPhase.START)
6440         # NOTE(Kevin_Zheng): Pop the migration out from the queue, this might
6441         # lead to 3 scenarios:
6442         # 1. The selected migration is still in queue, and the future.cancel()
6443         #    succeed, then the abort action is succeed, mark the migration
6444         #    status to 'cancelled'.
6445         # 2. The selected migration is still in queue, but the future.cancel()
6446         #    failed, then the _do_live_migration() has started executing, and
6447         #    the migration status is 'preparing', then we just pop it from the
6448         #    queue, and the migration process will handle it later. And the
6449         #    migration status couldn't be 'running' in this scenario because
6450         #    if _do_live_migration has started executing and we've already
6451         #    popped it from the queue and set the migration status to
6452         #    'running' at this point, popping it here will raise KeyError at
6453         #    which point we check if it's running and if so, we abort the old
6454         #    way.
6455         # 3. The selected migration is not in the queue, then the migration
6456         #    status is 'running', let the driver handle it.
6457         try:
6458             migration, future = (
6459                 self._waiting_live_migrations.pop(instance.uuid))
6460             if future and future.cancel():
6461                 # If we got here, we've successfully aborted the queued
6462                 # migration and _do_live_migration won't run so we need
6463                 # to set the migration status to cancelled and send the
6464                 # notification. If Future.cancel() fails, it means
6465                 # _do_live_migration is running and the migration status
6466                 # is preparing, and _do_live_migration() itself will attempt
6467                 # to pop the queued migration, hit a KeyError, and rollback,
6468                 # set the migration to cancelled and send the
6469                 # live.migration.abort.end notification.
6470                 self._set_migration_status(migration, 'cancelled')
6471         except KeyError:
6472             migration = objects.Migration.get_by_id(context, migration_id)
6473             if migration.status != 'running':
6474                 raise exception.InvalidMigrationState(
6475                     migration_id=migration_id, instance_uuid=instance.uuid,
6476                     state=migration.status, method='abort live migration')
6477             self.driver.live_migration_abort(instance)
6478         self._notify_live_migrate_abort_end(context, instance)
6479 
6480     def _live_migration_cleanup_flags(self, migrate_data):
6481         """Determine whether disks or instance path need to be cleaned up after
6482         live migration (at source on success, at destination on rollback)
6483 
6484         Block migration needs empty image at destination host before migration
6485         starts, so if any failure occurs, any empty images has to be deleted.
6486 
6487         Also Volume backed live migration w/o shared storage needs to delete
6488         newly created instance-xxx dir on the destination as a part of its
6489         rollback process
6490 
6491         :param migrate_data: implementation specific data
6492         :returns: (bool, bool) -- do_cleanup, destroy_disks
6493         """
6494         # NOTE(pkoniszewski): block migration specific params are set inside
6495         # migrate_data objects for drivers that expose block live migration
6496         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6497         # cleanup is not needed.
6498         is_shared_block_storage = True
6499         is_shared_instance_path = True
6500         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6501             is_shared_block_storage = migrate_data.is_shared_block_storage
6502             is_shared_instance_path = migrate_data.is_shared_instance_path
6503         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6504             is_shared_block_storage = not migrate_data.block_migration
6505             is_shared_instance_path = not migrate_data.block_migration
6506         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6507             is_shared_instance_path = migrate_data.is_shared_instance_path
6508             is_shared_block_storage = migrate_data.is_shared_instance_path
6509 
6510         # No instance booting at source host, but instance dir
6511         # must be deleted for preparing next block migration
6512         # must be deleted for preparing next live migration w/o shared storage
6513         do_cleanup = not is_shared_instance_path
6514         destroy_disks = not is_shared_block_storage
6515 
6516         return (do_cleanup, destroy_disks)
6517 
6518     @wrap_exception()
6519     @wrap_instance_fault
6520     def _post_live_migration(self, ctxt, instance,
6521                             dest, block_migration=False, migrate_data=None):
6522         """Post operations for live migration.
6523 
6524         This method is called from live_migration
6525         and mainly updating database record.
6526 
6527         :param ctxt: security context
6528         :param instance: instance dict
6529         :param dest: destination host
6530         :param block_migration: if true, prepare for block migration
6531         :param migrate_data: if not None, it is a dict which has data
6532         required for live migration without shared storage
6533 
6534         """
6535         LOG.info('_post_live_migration() is started..',
6536                  instance=instance)
6537 
6538         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6539                 ctxt, instance.uuid)
6540 
6541         # Cleanup source host post live-migration
6542         block_device_info = self._get_instance_block_device_info(
6543                             ctxt, instance, bdms=bdms)
6544         self.driver.post_live_migration(ctxt, instance, block_device_info,
6545                                         migrate_data)
6546 
6547         # Detaching volumes.
6548         connector = self.driver.get_volume_connector(instance)
6549         for bdm in bdms:
6550             if bdm.is_volume:
6551                 if bdm.attachment_id is None:
6552                     # Prior to cinder v3.44:
6553                     # We don't want to actually mark the volume detached, or
6554                     # delete the bdm, just remove the connection from this
6555                     # host.
6556                     #
6557                     # remove the volume connection without detaching from
6558                     # hypervisor because the instance is not running anymore
6559                     # on the current host
6560                     self.volume_api.terminate_connection(ctxt, bdm.volume_id,
6561                                                          connector)
6562                 else:
6563                     # cinder v3.44 api flow - delete the old attachment
6564                     # for the source host
6565                     old_attachment_id = \
6566                         migrate_data.old_vol_attachment_ids[bdm.volume_id]
6567                     self.volume_api.attachment_delete(ctxt, old_attachment_id)
6568 
6569         # Releasing vlan.
6570         # (not necessary in current implementation?)
6571 
6572         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
6573 
6574         self._notify_about_instance_usage(ctxt, instance,
6575                                           "live_migration._post.start",
6576                                           network_info=network_info)
6577         compute_utils.notify_about_instance_action(
6578             ctxt, instance, self.host,
6579             action=fields.NotificationAction.LIVE_MIGRATION_POST,
6580             phase=fields.NotificationPhase.START)
6581         # Releasing security group ingress rule.
6582         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
6583                   instance=instance)
6584         self.driver.unfilter_instance(instance,
6585                                       network_info)
6586 
6587         migration = {'source_compute': self.host,
6588                      'dest_compute': dest, }
6589         # For neutron, migrate_instance_start will activate the destination
6590         # host port bindings, if there are any created by conductor before live
6591         # migration started.
6592         self.network_api.migrate_instance_start(ctxt,
6593                                                 instance,
6594                                                 migration)
6595 
6596         destroy_vifs = False
6597         try:
6598             # It's possible that the vif type changed on the destination
6599             # host and is already bound and active, so we need to use the
6600             # stashed source vifs in migrate_data.vifs (if present) to unplug
6601             # on the source host.
6602             unplug_nw_info = network_info
6603             if migrate_data and 'vifs' in migrate_data:
6604                 nw_info = []
6605                 for migrate_vif in migrate_data.vifs:
6606                     nw_info.append(migrate_vif.source_vif)
6607                 unplug_nw_info = network_model.NetworkInfo.hydrate(nw_info)
6608                 LOG.debug('Calling driver.post_live_migration_at_source '
6609                           'with original source VIFs from migrate_data: %s',
6610                           unplug_nw_info, instance=instance)
6611             self.driver.post_live_migration_at_source(ctxt, instance,
6612                                                       unplug_nw_info)
6613         except NotImplementedError as ex:
6614             LOG.debug(ex, instance=instance)
6615             # For all hypervisors other than libvirt, there is a possibility
6616             # they are unplugging networks from source node in the cleanup
6617             # method
6618             destroy_vifs = True
6619 
6620         # NOTE(danms): Save source node before calling post method on
6621         # destination, which will update it
6622         source_node = instance.node
6623 
6624         # Define domain at destination host, without doing it,
6625         # pause/suspend/terminate do not work.
6626         post_at_dest_success = True
6627         try:
6628             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
6629                     instance, block_migration, dest)
6630         except Exception as error:
6631             post_at_dest_success = False
6632             # We don't want to break _post_live_migration() if
6633             # post_live_migration_at_destination() fails as it should never
6634             # affect cleaning up source node.
6635             LOG.exception("Post live migration at destination %s failed",
6636                           dest, instance=instance, error=error)
6637 
6638         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6639                 migrate_data)
6640 
6641         if do_cleanup:
6642             LOG.debug('Calling driver.cleanup from _post_live_migration',
6643                       instance=instance)
6644             self.driver.cleanup(ctxt, instance, unplug_nw_info,
6645                                 destroy_disks=destroy_disks,
6646                                 migrate_data=migrate_data,
6647                                 destroy_vifs=destroy_vifs)
6648 
6649         self.instance_events.clear_events_for_instance(instance)
6650 
6651         # NOTE(timello): make sure we update available resources on source
6652         # host even before next periodic task.
6653         self.update_available_resource(ctxt)
6654 
6655         self._update_scheduler_instance_info(ctxt, instance)
6656         self._notify_about_instance_usage(ctxt, instance,
6657                                           "live_migration._post.end",
6658                                           network_info=network_info)
6659         compute_utils.notify_about_instance_action(
6660             ctxt, instance, self.host,
6661             action=fields.NotificationAction.LIVE_MIGRATION_POST,
6662             phase=fields.NotificationPhase.END)
6663         if post_at_dest_success:
6664             LOG.info('Migrating instance to %s finished successfully.',
6665                      dest, instance=instance)
6666 
6667         self._clean_instance_console_tokens(ctxt, instance)
6668         if migrate_data and migrate_data.obj_attr_is_set('migration'):
6669             migrate_data.migration.status = 'completed'
6670             migrate_data.migration.save()
6671             migration = migrate_data.migration
6672             rc = self.scheduler_client.reportclient
6673             # Check to see if our migration has its own allocations
6674             allocs = rc.get_allocations_for_consumer(ctxt, migration.uuid)
6675         else:
6676             # We didn't have data on a migration, which means we can't
6677             # look up to see if we had new-style migration-based
6678             # allocations. This should really only happen in cases of
6679             # a buggy virt driver or some really old component in the
6680             # system. Log a warning so we know it happened.
6681             allocs = None
6682             LOG.warning('Live migration ended with no migrate_data '
6683                         'record. Unable to clean up migration-based '
6684                         'allocations which is almost certainly not '
6685                         'an expected situation.')
6686 
6687         if allocs:
6688             # We had a migration-based allocation that we need to handle
6689             self._delete_allocation_after_move(ctxt,
6690                                                instance,
6691                                                migrate_data.migration,
6692                                                instance.flavor,
6693                                                source_node)
6694         else:
6695             # No migration-based allocations, so do the old thing and
6696             # attempt to clean up any doubled per-instance allocation
6697             rt = self._get_resource_tracker()
6698             rt.delete_allocation_for_migrated_instance(
6699                 ctxt, instance, source_node)
6700 
6701     def _consoles_enabled(self):
6702         """Returns whether a console is enable."""
6703         return (CONF.vnc.enabled or CONF.spice.enabled or
6704                 CONF.rdp.enabled or CONF.serial_console.enabled or
6705                 CONF.mks.enabled)
6706 
6707     def _clean_instance_console_tokens(self, ctxt, instance):
6708         """Clean console tokens stored for an instance."""
6709         # If the database backend isn't in use, don't bother trying to clean
6710         # tokens. The database backend is not supported for cells v1.
6711         if not CONF.cells.enable and self._consoles_enabled():
6712             objects.ConsoleAuthToken.\
6713                 clean_console_auths_for_instance(ctxt, instance.uuid)
6714 
6715     @wrap_exception()
6716     @wrap_instance_event(prefix='compute')
6717     @wrap_instance_fault
6718     def post_live_migration_at_destination(self, context, instance,
6719                                            block_migration):
6720         """Post operations for live migration .
6721 
6722         :param context: security context
6723         :param instance: Instance dict
6724         :param block_migration: if true, prepare for block migration
6725 
6726         """
6727         LOG.info('Post operation of migration started',
6728                  instance=instance)
6729 
6730         # NOTE(tr3buchet): setup networks on destination host
6731         #                  this is called a second time because
6732         #                  multi_host does not create the bridge in
6733         #                  plug_vifs
6734         # NOTE(mriedem): This is a no-op for neutron.
6735         self.network_api.setup_networks_on_host(context, instance,
6736                                                          self.host)
6737         migration = {'source_compute': instance.host,
6738                      'dest_compute': self.host, }
6739         self.network_api.migrate_instance_finish(context,
6740                                                  instance,
6741                                                  migration)
6742 
6743         network_info = self.network_api.get_instance_nw_info(context, instance)
6744         self._notify_about_instance_usage(
6745                      context, instance, "live_migration.post.dest.start",
6746                      network_info=network_info)
6747         compute_utils.notify_about_instance_action(context, instance,
6748                 self.host,
6749                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6750                 phase=fields.NotificationPhase.START)
6751         block_device_info = self._get_instance_block_device_info(context,
6752                                                                  instance)
6753 
6754         try:
6755             self.driver.post_live_migration_at_destination(
6756                 context, instance, network_info, block_migration,
6757                 block_device_info)
6758         except Exception:
6759             with excutils.save_and_reraise_exception():
6760                 instance.vm_state = vm_states.ERROR
6761                 LOG.error('Unexpected error during post live migration at '
6762                           'destination host.', instance=instance)
6763         finally:
6764             # Restore instance state and update host
6765             current_power_state = self._get_power_state(context, instance)
6766             node_name = None
6767             prev_host = instance.host
6768             try:
6769                 compute_node = self._get_compute_info(context, self.host)
6770                 node_name = compute_node.hypervisor_hostname
6771             except exception.ComputeHostNotFound:
6772                 LOG.exception('Failed to get compute_info for %s', self.host)
6773             finally:
6774                 instance.host = self.host
6775                 instance.power_state = current_power_state
6776                 instance.task_state = None
6777                 instance.node = node_name
6778                 instance.progress = 0
6779                 instance.save(expected_task_state=task_states.MIGRATING)
6780 
6781         # NOTE(tr3buchet): tear down networks on source host (nova-net)
6782         # NOTE(mriedem): For neutron, this will delete any inactive source
6783         # host port bindings.
6784         try:
6785             self.network_api.setup_networks_on_host(context, instance,
6786                                                     prev_host, teardown=True)
6787         except exception.PortBindingDeletionFailed as e:
6788             # Removing the inactive port bindings from the source host is not
6789             # critical so just log an error but don't fail.
6790             LOG.error('Network cleanup failed for source host %s during post '
6791                       'live migration. You may need to manually clean up '
6792                       'resources in the network service. Error: %s',
6793                       prev_host, six.text_type(e))
6794         # NOTE(vish): this is necessary to update dhcp for nova-network
6795         # NOTE(mriedem): This is a no-op for neutron.
6796         self.network_api.setup_networks_on_host(context, instance, self.host)
6797         self._notify_about_instance_usage(
6798                      context, instance, "live_migration.post.dest.end",
6799                      network_info=network_info)
6800         compute_utils.notify_about_instance_action(context, instance,
6801                 self.host,
6802                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6803                 phase=fields.NotificationPhase.END)
6804 
6805     @wrap_exception()
6806     @wrap_instance_fault
6807     def _rollback_live_migration(self, context, instance,
6808                                  dest, migrate_data=None,
6809                                  migration_status='error'):
6810         """Recovers Instance/volume state from migrating -> running.
6811 
6812         :param context: security context
6813         :param instance: nova.objects.instance.Instance object
6814         :param dest:
6815             This method is called from live migration src host.
6816             This param specifies destination host.
6817         :param migrate_data:
6818             if not none, contains implementation specific data.
6819         :param migration_status:
6820             Contains the status we want to set for the migration object
6821 
6822         """
6823         if (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
6824               migrate_data.obj_attr_is_set('migration')):
6825             migration = migrate_data.migration
6826         else:
6827             migration = None
6828 
6829         if migration:
6830             # Remove allocations created in Placement for the dest node.
6831             # If migration is None, we must be so old we don't have placement,
6832             # so no need to do something else.
6833             self._revert_allocation(context, instance, migration)
6834         else:
6835             LOG.error('Unable to revert allocations during live migration '
6836                       'rollback; compute driver did not provide migrate_data',
6837                       instance=instance)
6838 
6839         instance.task_state = None
6840         instance.progress = 0
6841         instance.save(expected_task_state=[task_states.MIGRATING])
6842 
6843         # NOTE(tr3buchet): setup networks on source host (really it's re-setup
6844         #                  for nova-network)
6845         # NOTE(mriedem): This is a no-op for neutron.
6846         self.network_api.setup_networks_on_host(context, instance, self.host)
6847 
6848         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6849                 context, instance.uuid)
6850         for bdm in bdms:
6851             if bdm.is_volume:
6852                 # remove the connection on the destination host
6853                 self.compute_rpcapi.remove_volume_connection(
6854                         context, instance, bdm.volume_id, dest)
6855 
6856                 if bdm.attachment_id:
6857                     # 3.44 cinder api flow. Set the bdm's
6858                     # attachment_id to the old attachment of the source
6859                     # host. If old_attachments is not there, then
6860                     # there was an error before the new attachment was made.
6861                     old_attachments = migrate_data.old_vol_attachment_ids \
6862                         if 'old_vol_attachment_ids' in migrate_data else None
6863                     if old_attachments and bdm.volume_id in old_attachments:
6864                         self.volume_api.attachment_delete(context,
6865                                                           bdm.attachment_id)
6866                         bdm.attachment_id = old_attachments[bdm.volume_id]
6867                         bdm.save()
6868 
6869         self._notify_about_instance_usage(context, instance,
6870                                           "live_migration._rollback.start")
6871         compute_utils.notify_about_instance_action(context, instance,
6872                 self.host,
6873                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6874                 phase=fields.NotificationPhase.START,
6875                 bdms=bdms)
6876 
6877         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6878                 migrate_data)
6879 
6880         if do_cleanup:
6881             self.compute_rpcapi.rollback_live_migration_at_destination(
6882                     context, instance, dest, destroy_disks=destroy_disks,
6883                     migrate_data=migrate_data)
6884         elif utils.is_neutron():
6885             # The port binding profiles need to be cleaned up.
6886             with errors_out_migration_ctxt(migration):
6887                 try:
6888                     # This call will delete any inactive destination host
6889                     # port bindings.
6890                     self.network_api.setup_networks_on_host(
6891                         context, instance, host=dest, teardown=True)
6892                 except exception.PortBindingDeletionFailed as e:
6893                     # Removing the inactive port bindings from the destination
6894                     # host is not critical so just log an error but don't fail.
6895                     LOG.error(
6896                         'Network cleanup failed for destination host %s '
6897                         'during live migration rollback. You may need to '
6898                         'manually clean up resources in the network service. '
6899                         'Error: %s', dest, six.text_type(e))
6900                 except Exception:
6901                     with excutils.save_and_reraise_exception():
6902                         LOG.exception(
6903                             'An error occurred while cleaning up networking '
6904                             'during live migration rollback.',
6905                             instance=instance)
6906 
6907         self._notify_about_instance_usage(context, instance,
6908                                           "live_migration._rollback.end")
6909         compute_utils.notify_about_instance_action(context, instance,
6910                 self.host,
6911                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6912                 phase=fields.NotificationPhase.END,
6913                 bdms=bdms)
6914 
6915         self._set_migration_status(migration, migration_status)
6916 
6917     @wrap_exception()
6918     @wrap_instance_event(prefix='compute')
6919     @wrap_instance_fault
6920     def rollback_live_migration_at_destination(self, context, instance,
6921                                                destroy_disks,
6922                                                migrate_data):
6923         """Cleaning up image directory that is created pre_live_migration.
6924 
6925         :param context: security context
6926         :param instance: a nova.objects.instance.Instance object sent over rpc
6927         :param destroy_disks: whether to destroy volumes or not
6928         :param migrate_data: contains migration info
6929         """
6930         network_info = self.network_api.get_instance_nw_info(context, instance)
6931         self._notify_about_instance_usage(
6932                       context, instance, "live_migration.rollback.dest.start",
6933                       network_info=network_info)
6934         compute_utils.notify_about_instance_action(
6935             context, instance, self.host,
6936             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
6937             phase=fields.NotificationPhase.START)
6938         try:
6939             # NOTE(tr3buchet): tear down networks on dest host (nova-net)
6940             # NOTE(mriedem): For neutron, this call will delete any
6941             # destination host port bindings.
6942             # TODO(mriedem): We should eventually remove this call from
6943             # this method (rollback_live_migration_at_destination) since this
6944             # method is only called conditionally based on whether or not the
6945             # instance is running on shared storage. _rollback_live_migration
6946             # already calls this method for neutron if we are running on
6947             # shared storage.
6948             self.network_api.setup_networks_on_host(context, instance,
6949                                                     self.host, teardown=True)
6950         except exception.PortBindingDeletionFailed as e:
6951             # Removing the inactive port bindings from the destination
6952             # host is not critical so just log an error but don't fail.
6953             LOG.error(
6954                 'Network cleanup failed for destination host %s '
6955                 'during live migration rollback. You may need to '
6956                 'manually clean up resources in the network service. '
6957                 'Error: %s', self.host, six.text_type(e))
6958         except Exception:
6959             with excutils.save_and_reraise_exception():
6960                 # NOTE(tdurakov): even if teardown networks fails driver
6961                 # should try to rollback live migration on destination.
6962                 LOG.exception('An error occurred while deallocating network.',
6963                               instance=instance)
6964         finally:
6965             # always run this even if setup_networks_on_host fails
6966             # NOTE(vish): The mapping is passed in so the driver can disconnect
6967             #             from remote volumes if necessary
6968             block_device_info = self._get_instance_block_device_info(context,
6969                                                                      instance)
6970             self.driver.rollback_live_migration_at_destination(
6971                 context, instance, network_info, block_device_info,
6972                 destroy_disks=destroy_disks, migrate_data=migrate_data)
6973 
6974         self._notify_about_instance_usage(
6975                         context, instance, "live_migration.rollback.dest.end",
6976                         network_info=network_info)
6977         compute_utils.notify_about_instance_action(
6978             context, instance, self.host,
6979             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
6980             phase=fields.NotificationPhase.END)
6981 
6982     @periodic_task.periodic_task(
6983         spacing=CONF.heal_instance_info_cache_interval)
6984     def _heal_instance_info_cache(self, context):
6985         """Called periodically.  On every call, try to update the
6986         info_cache's network information for another instance by
6987         calling to the network manager.
6988 
6989         This is implemented by keeping a cache of uuids of instances
6990         that live on this host.  On each call, we pop one off of a
6991         list, pull the DB record, and try the call to the network API.
6992         If anything errors don't fail, as it's possible the instance
6993         has been deleted, etc.
6994         """
6995         heal_interval = CONF.heal_instance_info_cache_interval
6996         if not heal_interval:
6997             return
6998 
6999         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
7000         instance = None
7001 
7002         LOG.debug('Starting heal instance info cache')
7003 
7004         if not instance_uuids:
7005             # The list of instances to heal is empty so rebuild it
7006             LOG.debug('Rebuilding the list of instances to heal')
7007             db_instances = objects.InstanceList.get_by_host(
7008                 context, self.host, expected_attrs=[], use_slave=True)
7009             for inst in db_instances:
7010                 # We don't want to refresh the cache for instances
7011                 # which are building or deleting so don't put them
7012                 # in the list. If they are building they will get
7013                 # added to the list next time we build it.
7014                 if (inst.vm_state == vm_states.BUILDING):
7015                     LOG.debug('Skipping network cache update for instance '
7016                               'because it is Building.', instance=inst)
7017                     continue
7018                 if (inst.task_state == task_states.DELETING):
7019                     LOG.debug('Skipping network cache update for instance '
7020                               'because it is being deleted.', instance=inst)
7021                     continue
7022 
7023                 if not instance:
7024                     # Save the first one we find so we don't
7025                     # have to get it again
7026                     instance = inst
7027                 else:
7028                     instance_uuids.append(inst['uuid'])
7029 
7030             self._instance_uuids_to_heal = instance_uuids
7031         else:
7032             # Find the next valid instance on the list
7033             while instance_uuids:
7034                 try:
7035                     inst = objects.Instance.get_by_uuid(
7036                             context, instance_uuids.pop(0),
7037                             expected_attrs=['system_metadata', 'info_cache',
7038                                             'flavor'],
7039                             use_slave=True)
7040                 except exception.InstanceNotFound:
7041                     # Instance is gone.  Try to grab another.
7042                     continue
7043 
7044                 # Check the instance hasn't been migrated
7045                 if inst.host != self.host:
7046                     LOG.debug('Skipping network cache update for instance '
7047                               'because it has been migrated to another '
7048                               'host.', instance=inst)
7049                 # Check the instance isn't being deleting
7050                 elif inst.task_state == task_states.DELETING:
7051                     LOG.debug('Skipping network cache update for instance '
7052                               'because it is being deleted.', instance=inst)
7053                 else:
7054                     instance = inst
7055                     break
7056 
7057         if instance:
7058             # We have an instance now to refresh
7059             try:
7060                 # Call to network API to get instance info.. this will
7061                 # force an update to the instance's info_cache
7062                 self.network_api.get_instance_nw_info(context, instance)
7063                 LOG.debug('Updated the network info_cache for instance',
7064                           instance=instance)
7065             except exception.InstanceNotFound:
7066                 # Instance is gone.
7067                 LOG.debug('Instance no longer exists. Unable to refresh',
7068                           instance=instance)
7069                 return
7070             except exception.InstanceInfoCacheNotFound:
7071                 # InstanceInfoCache is gone.
7072                 LOG.debug('InstanceInfoCache no longer exists. '
7073                           'Unable to refresh', instance=instance)
7074             except Exception:
7075                 LOG.error('An error occurred while refreshing the network '
7076                           'cache.', instance=instance, exc_info=True)
7077         else:
7078             LOG.debug("Didn't find any instances for network info cache "
7079                       "update.")
7080 
7081     @periodic_task.periodic_task
7082     def _poll_rebooting_instances(self, context):
7083         if CONF.reboot_timeout > 0:
7084             filters = {'task_state':
7085                        [task_states.REBOOTING,
7086                         task_states.REBOOT_STARTED,
7087                         task_states.REBOOT_PENDING],
7088                        'host': self.host}
7089             rebooting = objects.InstanceList.get_by_filters(
7090                 context, filters, expected_attrs=[], use_slave=True)
7091 
7092             to_poll = []
7093             for instance in rebooting:
7094                 if timeutils.is_older_than(instance.updated_at,
7095                                            CONF.reboot_timeout):
7096                     to_poll.append(instance)
7097 
7098             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
7099 
7100     @periodic_task.periodic_task
7101     def _poll_rescued_instances(self, context):
7102         if CONF.rescue_timeout > 0:
7103             filters = {'vm_state': vm_states.RESCUED,
7104                        'host': self.host}
7105             rescued_instances = objects.InstanceList.get_by_filters(
7106                 context, filters, expected_attrs=["system_metadata"],
7107                 use_slave=True)
7108 
7109             to_unrescue = []
7110             for instance in rescued_instances:
7111                 if timeutils.is_older_than(instance.launched_at,
7112                                            CONF.rescue_timeout):
7113                     to_unrescue.append(instance)
7114 
7115             for instance in to_unrescue:
7116                 self.compute_api.unrescue(context, instance)
7117 
7118     @periodic_task.periodic_task
7119     def _poll_unconfirmed_resizes(self, context):
7120         if CONF.resize_confirm_window == 0:
7121             return
7122 
7123         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
7124                 context, CONF.resize_confirm_window, self.host,
7125                 use_slave=True)
7126 
7127         migrations_info = dict(migration_count=len(migrations),
7128                 confirm_window=CONF.resize_confirm_window)
7129 
7130         if migrations_info["migration_count"] > 0:
7131             LOG.info("Found %(migration_count)d unconfirmed migrations "
7132                      "older than %(confirm_window)d seconds",
7133                      migrations_info)
7134 
7135         def _set_migration_to_error(migration, reason, **kwargs):
7136             LOG.warning("Setting migration %(migration_id)s to error: "
7137                         "%(reason)s",
7138                         {'migration_id': migration['id'], 'reason': reason},
7139                         **kwargs)
7140             migration.status = 'error'
7141             with migration.obj_as_admin():
7142                 migration.save()
7143 
7144         for migration in migrations:
7145             instance_uuid = migration.instance_uuid
7146             LOG.info("Automatically confirming migration "
7147                      "%(migration_id)s for instance %(instance_uuid)s",
7148                      {'migration_id': migration.id,
7149                       'instance_uuid': instance_uuid})
7150             expected_attrs = ['metadata', 'system_metadata']
7151             try:
7152                 instance = objects.Instance.get_by_uuid(context,
7153                             instance_uuid, expected_attrs=expected_attrs,
7154                             use_slave=True)
7155             except exception.InstanceNotFound:
7156                 reason = (_("Instance %s not found") %
7157                           instance_uuid)
7158                 _set_migration_to_error(migration, reason)
7159                 continue
7160             if instance.vm_state == vm_states.ERROR:
7161                 reason = _("In ERROR state")
7162                 _set_migration_to_error(migration, reason,
7163                                         instance=instance)
7164                 continue
7165             # race condition: The instance in DELETING state should not be
7166             # set the migration state to error, otherwise the instance in
7167             # to be deleted which is in RESIZED state
7168             # will not be able to confirm resize
7169             if instance.task_state in [task_states.DELETING,
7170                                        task_states.SOFT_DELETING]:
7171                 msg = ("Instance being deleted or soft deleted during resize "
7172                        "confirmation. Skipping.")
7173                 LOG.debug(msg, instance=instance)
7174                 continue
7175 
7176             # race condition: This condition is hit when this method is
7177             # called between the save of the migration record with a status of
7178             # finished and the save of the instance object with a state of
7179             # RESIZED. The migration record should not be set to error.
7180             if instance.task_state == task_states.RESIZE_FINISH:
7181                 msg = ("Instance still resizing during resize "
7182                        "confirmation. Skipping.")
7183                 LOG.debug(msg, instance=instance)
7184                 continue
7185 
7186             vm_state = instance.vm_state
7187             task_state = instance.task_state
7188             if vm_state != vm_states.RESIZED or task_state is not None:
7189                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
7190                            "RESIZED/None") %
7191                           {'vm_state': vm_state,
7192                            'task_state': task_state})
7193                 _set_migration_to_error(migration, reason,
7194                                         instance=instance)
7195                 continue
7196             try:
7197                 self.compute_api.confirm_resize(context, instance,
7198                                                 migration=migration)
7199             except Exception as e:
7200                 LOG.info("Error auto-confirming resize: %s. "
7201                          "Will retry later.", e, instance=instance)
7202 
7203     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
7204     def _poll_shelved_instances(self, context):
7205 
7206         if CONF.shelved_offload_time <= 0:
7207             return
7208 
7209         filters = {'vm_state': vm_states.SHELVED,
7210                    'task_state': None,
7211                    'host': self.host}
7212         shelved_instances = objects.InstanceList.get_by_filters(
7213             context, filters=filters, expected_attrs=['system_metadata'],
7214             use_slave=True)
7215 
7216         to_gc = []
7217         for instance in shelved_instances:
7218             sys_meta = instance.system_metadata
7219             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
7220             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
7221                 to_gc.append(instance)
7222 
7223         for instance in to_gc:
7224             try:
7225                 instance.task_state = task_states.SHELVING_OFFLOADING
7226                 instance.save(expected_task_state=(None,))
7227                 self.shelve_offload_instance(context, instance,
7228                                              clean_shutdown=False)
7229             except Exception:
7230                 LOG.exception('Periodic task failed to offload instance.',
7231                               instance=instance)
7232 
7233     @periodic_task.periodic_task
7234     def _instance_usage_audit(self, context):
7235         if not CONF.instance_usage_audit:
7236             return
7237 
7238         begin, end = utils.last_completed_audit_period()
7239         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
7240                                self.host):
7241             return
7242 
7243         instances = objects.InstanceList.get_active_by_window_joined(
7244             context, begin, end, host=self.host,
7245             expected_attrs=['system_metadata', 'info_cache', 'metadata',
7246                             'flavor'],
7247             use_slave=True)
7248         num_instances = len(instances)
7249         errors = 0
7250         successes = 0
7251         LOG.info("Running instance usage audit for host %(host)s "
7252                  "from %(begin_time)s to %(end_time)s. "
7253                  "%(number_instances)s instances.",
7254                  {'host': self.host,
7255                   'begin_time': begin,
7256                   'end_time': end,
7257                   'number_instances': num_instances})
7258         start_time = time.time()
7259         task_log = objects.TaskLog(context)
7260         task_log.task_name = 'instance_usage_audit'
7261         task_log.period_beginning = begin
7262         task_log.period_ending = end
7263         task_log.host = self.host
7264         task_log.task_items = num_instances
7265         task_log.message = 'Instance usage audit started...'
7266         task_log.begin_task()
7267         for instance in instances:
7268             try:
7269                 compute_utils.notify_usage_exists(
7270                     self.notifier, context, instance, self.host,
7271                     ignore_missing_network_data=False)
7272                 successes += 1
7273             except Exception:
7274                 LOG.exception('Failed to generate usage '
7275                               'audit for instance '
7276                               'on host %s', self.host,
7277                               instance=instance)
7278                 errors += 1
7279         task_log.errors = errors
7280         task_log.message = (
7281             'Instance usage audit ran for host %s, %s instances in %s seconds.'
7282             % (self.host, num_instances, time.time() - start_time))
7283         task_log.end_task()
7284 
7285     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
7286     def _poll_bandwidth_usage(self, context):
7287 
7288         if not self._bw_usage_supported:
7289             return
7290 
7291         prev_time, start_time = utils.last_completed_audit_period()
7292 
7293         curr_time = time.time()
7294         if (curr_time - self._last_bw_usage_poll >
7295                 CONF.bandwidth_poll_interval):
7296             self._last_bw_usage_poll = curr_time
7297             LOG.info("Updating bandwidth usage cache")
7298             cells_update_interval = CONF.cells.bandwidth_update_interval
7299             if (cells_update_interval > 0 and
7300                    curr_time - self._last_bw_usage_cell_update >
7301                            cells_update_interval):
7302                 self._last_bw_usage_cell_update = curr_time
7303                 update_cells = True
7304             else:
7305                 update_cells = False
7306 
7307             instances = objects.InstanceList.get_by_host(context,
7308                                                               self.host,
7309                                                               use_slave=True)
7310             try:
7311                 bw_counters = self.driver.get_all_bw_counters(instances)
7312             except NotImplementedError:
7313                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
7314                 # implemented yet.  If they don't it doesn't break anything,
7315                 # they just don't get the info in the usage events.
7316                 # NOTE(PhilDay): Record that its not supported so we can
7317                 # skip fast on future calls rather than waste effort getting
7318                 # the list of instances.
7319                 LOG.info("Bandwidth usage not supported by %(driver)s.",
7320                          {'driver': CONF.compute_driver})
7321                 self._bw_usage_supported = False
7322                 return
7323 
7324             refreshed = timeutils.utcnow()
7325             for bw_ctr in bw_counters:
7326                 # Allow switching of greenthreads between queries.
7327                 greenthread.sleep(0)
7328                 bw_in = 0
7329                 bw_out = 0
7330                 last_ctr_in = None
7331                 last_ctr_out = None
7332                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
7333                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
7334                     start_period=start_time, use_slave=True)
7335                 if usage:
7336                     bw_in = usage.bw_in
7337                     bw_out = usage.bw_out
7338                     last_ctr_in = usage.last_ctr_in
7339                     last_ctr_out = usage.last_ctr_out
7340                 else:
7341                     usage = (objects.BandwidthUsage.
7342                              get_by_instance_uuid_and_mac(
7343                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
7344                         start_period=prev_time, use_slave=True))
7345                     if usage:
7346                         last_ctr_in = usage.last_ctr_in
7347                         last_ctr_out = usage.last_ctr_out
7348 
7349                 if last_ctr_in is not None:
7350                     if bw_ctr['bw_in'] < last_ctr_in:
7351                         # counter rollover
7352                         bw_in += bw_ctr['bw_in']
7353                     else:
7354                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
7355 
7356                 if last_ctr_out is not None:
7357                     if bw_ctr['bw_out'] < last_ctr_out:
7358                         # counter rollover
7359                         bw_out += bw_ctr['bw_out']
7360                     else:
7361                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
7362 
7363                 objects.BandwidthUsage(context=context).create(
7364                                               bw_ctr['uuid'],
7365                                               bw_ctr['mac_address'],
7366                                               bw_in,
7367                                               bw_out,
7368                                               bw_ctr['bw_in'],
7369                                               bw_ctr['bw_out'],
7370                                               start_period=start_time,
7371                                               last_refreshed=refreshed,
7372                                               update_cells=update_cells)
7373 
7374     def _get_host_volume_bdms(self, context, use_slave=False):
7375         """Return all block device mappings on a compute host."""
7376         compute_host_bdms = []
7377         instances = objects.InstanceList.get_by_host(context, self.host,
7378             use_slave=use_slave)
7379         for instance in instances:
7380             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7381                     context, instance.uuid, use_slave=use_slave)
7382             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
7383             compute_host_bdms.append(dict(instance=instance,
7384                                           instance_bdms=instance_bdms))
7385 
7386         return compute_host_bdms
7387 
7388     def _update_volume_usage_cache(self, context, vol_usages):
7389         """Updates the volume usage cache table with a list of stats."""
7390         for usage in vol_usages:
7391             # Allow switching of greenthreads between queries.
7392             greenthread.sleep(0)
7393             vol_usage = objects.VolumeUsage(context)
7394             vol_usage.volume_id = usage['volume']
7395             vol_usage.instance_uuid = usage['instance'].uuid
7396             vol_usage.project_id = usage['instance'].project_id
7397             vol_usage.user_id = usage['instance'].user_id
7398             vol_usage.availability_zone = usage['instance'].availability_zone
7399             vol_usage.curr_reads = usage['rd_req']
7400             vol_usage.curr_read_bytes = usage['rd_bytes']
7401             vol_usage.curr_writes = usage['wr_req']
7402             vol_usage.curr_write_bytes = usage['wr_bytes']
7403             vol_usage.save()
7404             self.notifier.info(context, 'volume.usage',
7405                                compute_utils.usage_volume_info(vol_usage))
7406 
7407     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
7408     def _poll_volume_usage(self, context):
7409         if CONF.volume_usage_poll_interval == 0:
7410             return
7411 
7412         compute_host_bdms = self._get_host_volume_bdms(context,
7413                                                        use_slave=True)
7414         if not compute_host_bdms:
7415             return
7416 
7417         LOG.debug("Updating volume usage cache")
7418         try:
7419             vol_usages = self.driver.get_all_volume_usage(context,
7420                                                           compute_host_bdms)
7421         except NotImplementedError:
7422             return
7423 
7424         self._update_volume_usage_cache(context, vol_usages)
7425 
7426     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
7427                                  run_immediately=True)
7428     def _sync_power_states(self, context):
7429         """Align power states between the database and the hypervisor.
7430 
7431         To sync power state data we make a DB call to get the number of
7432         virtual machines known by the hypervisor and if the number matches the
7433         number of virtual machines known by the database, we proceed in a lazy
7434         loop, one database record at a time, checking if the hypervisor has the
7435         same power state as is in the database.
7436         """
7437         db_instances = objects.InstanceList.get_by_host(context, self.host,
7438                                                         expected_attrs=[],
7439                                                         use_slave=True)
7440 
7441         num_vm_instances = self.driver.get_num_instances()
7442         num_db_instances = len(db_instances)
7443 
7444         if num_vm_instances != num_db_instances:
7445             LOG.warning("While synchronizing instance power states, found "
7446                         "%(num_db_instances)s instances in the database "
7447                         "and %(num_vm_instances)s instances on the "
7448                         "hypervisor.",
7449                         {'num_db_instances': num_db_instances,
7450                          'num_vm_instances': num_vm_instances})
7451 
7452         def _sync(db_instance):
7453             # NOTE(melwitt): This must be synchronized as we query state from
7454             #                two separate sources, the driver and the database.
7455             #                They are set (in stop_instance) and read, in sync.
7456             @utils.synchronized(db_instance.uuid)
7457             def query_driver_power_state_and_sync():
7458                 self._query_driver_power_state_and_sync(context, db_instance)
7459 
7460             try:
7461                 query_driver_power_state_and_sync()
7462             except Exception:
7463                 LOG.exception("Periodic sync_power_state task had an "
7464                               "error while processing an instance.",
7465                               instance=db_instance)
7466 
7467             self._syncs_in_progress.pop(db_instance.uuid)
7468 
7469         for db_instance in db_instances:
7470             # process syncs asynchronously - don't want instance locking to
7471             # block entire periodic task thread
7472             uuid = db_instance.uuid
7473             if uuid in self._syncs_in_progress:
7474                 LOG.debug('Sync already in progress for %s', uuid)
7475             else:
7476                 LOG.debug('Triggering sync for uuid %s', uuid)
7477                 self._syncs_in_progress[uuid] = True
7478                 self._sync_power_pool.spawn_n(_sync, db_instance)
7479 
7480     def _query_driver_power_state_and_sync(self, context, db_instance):
7481         if db_instance.task_state is not None:
7482             LOG.info("During sync_power_state the instance has a "
7483                      "pending task (%(task)s). Skip.",
7484                      {'task': db_instance.task_state}, instance=db_instance)
7485             return
7486         # No pending tasks. Now try to figure out the real vm_power_state.
7487         try:
7488             vm_instance = self.driver.get_info(db_instance)
7489             vm_power_state = vm_instance.state
7490         except exception.InstanceNotFound:
7491             vm_power_state = power_state.NOSTATE
7492         # Note(maoy): the above get_info call might take a long time,
7493         # for example, because of a broken libvirt driver.
7494         try:
7495             self._sync_instance_power_state(context,
7496                                             db_instance,
7497                                             vm_power_state,
7498                                             use_slave=True)
7499         except exception.InstanceNotFound:
7500             # NOTE(hanlind): If the instance gets deleted during sync,
7501             # silently ignore.
7502             pass
7503 
7504     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
7505                                    use_slave=False):
7506         """Align instance power state between the database and hypervisor.
7507 
7508         If the instance is not found on the hypervisor, but is in the database,
7509         then a stop() API will be called on the instance.
7510         """
7511 
7512         # We re-query the DB to get the latest instance info to minimize
7513         # (not eliminate) race condition.
7514         db_instance.refresh(use_slave=use_slave)
7515         db_power_state = db_instance.power_state
7516         vm_state = db_instance.vm_state
7517 
7518         if self.host != db_instance.host:
7519             # on the sending end of nova-compute _sync_power_state
7520             # may have yielded to the greenthread performing a live
7521             # migration; this in turn has changed the resident-host
7522             # for the VM; However, the instance is still active, it
7523             # is just in the process of migrating to another host.
7524             # This implies that the compute source must relinquish
7525             # control to the compute destination.
7526             LOG.info("During the sync_power process the "
7527                      "instance has moved from "
7528                      "host %(src)s to host %(dst)s",
7529                      {'src': db_instance.host,
7530                       'dst': self.host},
7531                      instance=db_instance)
7532             return
7533         elif db_instance.task_state is not None:
7534             # on the receiving end of nova-compute, it could happen
7535             # that the DB instance already report the new resident
7536             # but the actual VM has not showed up on the hypervisor
7537             # yet. In this case, let's allow the loop to continue
7538             # and run the state sync in a later round
7539             LOG.info("During sync_power_state the instance has a "
7540                      "pending task (%(task)s). Skip.",
7541                      {'task': db_instance.task_state},
7542                      instance=db_instance)
7543             return
7544 
7545         orig_db_power_state = db_power_state
7546         if vm_power_state != db_power_state:
7547             LOG.info('During _sync_instance_power_state the DB '
7548                      'power_state (%(db_power_state)s) does not match '
7549                      'the vm_power_state from the hypervisor '
7550                      '(%(vm_power_state)s). Updating power_state in the '
7551                      'DB to match the hypervisor.',
7552                      {'db_power_state': db_power_state,
7553                       'vm_power_state': vm_power_state},
7554                      instance=db_instance)
7555             # power_state is always updated from hypervisor to db
7556             db_instance.power_state = vm_power_state
7557             db_instance.save()
7558             db_power_state = vm_power_state
7559 
7560         # Note(maoy): Now resolve the discrepancy between vm_state and
7561         # vm_power_state. We go through all possible vm_states.
7562         if vm_state in (vm_states.BUILDING,
7563                         vm_states.RESCUED,
7564                         vm_states.RESIZED,
7565                         vm_states.SUSPENDED,
7566                         vm_states.ERROR):
7567             # TODO(maoy): we ignore these vm_state for now.
7568             pass
7569         elif vm_state == vm_states.ACTIVE:
7570             # The only rational power state should be RUNNING
7571             if vm_power_state in (power_state.SHUTDOWN,
7572                                   power_state.CRASHED):
7573                 LOG.warning("Instance shutdown by itself. Calling the "
7574                             "stop API. Current vm_state: %(vm_state)s, "
7575                             "current task_state: %(task_state)s, "
7576                             "original DB power_state: %(db_power_state)s, "
7577                             "current VM power_state: %(vm_power_state)s",
7578                             {'vm_state': vm_state,
7579                              'task_state': db_instance.task_state,
7580                              'db_power_state': orig_db_power_state,
7581                              'vm_power_state': vm_power_state},
7582                             instance=db_instance)
7583                 try:
7584                     # Note(maoy): here we call the API instead of
7585                     # brutally updating the vm_state in the database
7586                     # to allow all the hooks and checks to be performed.
7587                     if db_instance.shutdown_terminate:
7588                         self.compute_api.delete(context, db_instance)
7589                     else:
7590                         self.compute_api.stop(context, db_instance)
7591                 except Exception:
7592                     # Note(maoy): there is no need to propagate the error
7593                     # because the same power_state will be retrieved next
7594                     # time and retried.
7595                     # For example, there might be another task scheduled.
7596                     LOG.exception("error during stop() in sync_power_state.",
7597                                   instance=db_instance)
7598             elif vm_power_state == power_state.SUSPENDED:
7599                 LOG.warning("Instance is suspended unexpectedly. Calling "
7600                             "the stop API.", instance=db_instance)
7601                 try:
7602                     self.compute_api.stop(context, db_instance)
7603                 except Exception:
7604                     LOG.exception("error during stop() in sync_power_state.",
7605                                   instance=db_instance)
7606             elif vm_power_state == power_state.PAUSED:
7607                 # Note(maoy): a VM may get into the paused state not only
7608                 # because the user request via API calls, but also
7609                 # due to (temporary) external instrumentations.
7610                 # Before the virt layer can reliably report the reason,
7611                 # we simply ignore the state discrepancy. In many cases,
7612                 # the VM state will go back to running after the external
7613                 # instrumentation is done. See bug 1097806 for details.
7614                 LOG.warning("Instance is paused unexpectedly. Ignore.",
7615                             instance=db_instance)
7616             elif vm_power_state == power_state.NOSTATE:
7617                 # Occasionally, depending on the status of the hypervisor,
7618                 # which could be restarting for example, an instance may
7619                 # not be found.  Therefore just log the condition.
7620                 LOG.warning("Instance is unexpectedly not found. Ignore.",
7621                             instance=db_instance)
7622         elif vm_state == vm_states.STOPPED:
7623             if vm_power_state not in (power_state.NOSTATE,
7624                                       power_state.SHUTDOWN,
7625                                       power_state.CRASHED):
7626                 LOG.warning("Instance is not stopped. Calling "
7627                             "the stop API. Current vm_state: %(vm_state)s,"
7628                             " current task_state: %(task_state)s, "
7629                             "original DB power_state: %(db_power_state)s, "
7630                             "current VM power_state: %(vm_power_state)s",
7631                             {'vm_state': vm_state,
7632                              'task_state': db_instance.task_state,
7633                              'db_power_state': orig_db_power_state,
7634                              'vm_power_state': vm_power_state},
7635                             instance=db_instance)
7636                 try:
7637                     # NOTE(russellb) Force the stop, because normally the
7638                     # compute API would not allow an attempt to stop a stopped
7639                     # instance.
7640                     self.compute_api.force_stop(context, db_instance)
7641                 except Exception:
7642                     LOG.exception("error during stop() in sync_power_state.",
7643                                   instance=db_instance)
7644         elif vm_state == vm_states.PAUSED:
7645             if vm_power_state in (power_state.SHUTDOWN,
7646                                   power_state.CRASHED):
7647                 LOG.warning("Paused instance shutdown by itself. Calling "
7648                             "the stop API.", instance=db_instance)
7649                 try:
7650                     self.compute_api.force_stop(context, db_instance)
7651                 except Exception:
7652                     LOG.exception("error during stop() in sync_power_state.",
7653                                   instance=db_instance)
7654         elif vm_state in (vm_states.SOFT_DELETED,
7655                           vm_states.DELETED):
7656             if vm_power_state not in (power_state.NOSTATE,
7657                                       power_state.SHUTDOWN):
7658                 # Note(maoy): this should be taken care of periodically in
7659                 # _cleanup_running_deleted_instances().
7660                 LOG.warning("Instance is not (soft-)deleted.",
7661                             instance=db_instance)
7662 
7663     @periodic_task.periodic_task
7664     def _reclaim_queued_deletes(self, context):
7665         """Reclaim instances that are queued for deletion."""
7666         interval = CONF.reclaim_instance_interval
7667         if interval <= 0:
7668             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
7669             return
7670 
7671         filters = {'vm_state': vm_states.SOFT_DELETED,
7672                    'task_state': None,
7673                    'host': self.host}
7674         instances = objects.InstanceList.get_by_filters(
7675             context, filters,
7676             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
7677             use_slave=True)
7678         for instance in instances:
7679             if self._deleted_old_enough(instance, interval):
7680                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7681                         context, instance.uuid)
7682                 LOG.info('Reclaiming deleted instance', instance=instance)
7683                 try:
7684                     self._delete_instance(context, instance, bdms)
7685                 except Exception as e:
7686                     LOG.warning("Periodic reclaim failed to delete "
7687                                 "instance: %s",
7688                                 e, instance=instance)
7689 
7690     def _get_nodename(self, instance, refresh=False):
7691         """Helper method to get the name of the first available node
7692         on this host. This method should not be used with any operations
7693         on ironic instances since it does not handle multiple nodes.
7694         """
7695         node = self.driver.get_available_nodes(refresh=refresh)[0]
7696         LOG.debug("No node specified, defaulting to %s", node,
7697                   instance=instance)
7698         return node
7699 
7700     def _update_available_resource_for_node(self, context, nodename):
7701 
7702         rt = self._get_resource_tracker()
7703         try:
7704             rt.update_available_resource(context, nodename)
7705         except exception.ComputeHostNotFound:
7706             # NOTE(comstud): We can get to this case if a node was
7707             # marked 'deleted' in the DB and then re-added with a
7708             # different auto-increment id. The cached resource
7709             # tracker tried to update a deleted record and failed.
7710             # Don't add this resource tracker to the new dict, so
7711             # that this will resolve itself on the next run.
7712             LOG.info("Compute node '%s' not found in "
7713                      "update_available_resource.", nodename)
7714             # TODO(jaypipes): Yes, this is inefficient to throw away all of the
7715             # compute nodes to force a rebuild, but this is only temporary
7716             # until Ironic baremetal node resource providers are tracked
7717             # properly in the report client and this is a tiny edge case
7718             # anyway.
7719             self._resource_tracker = None
7720             return
7721         except Exception:
7722             LOG.exception("Error updating resources for node %(node)s.",
7723                           {'node': nodename})
7724 
7725     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
7726     def update_available_resource(self, context, startup=False):
7727         """See driver.get_available_resource()
7728 
7729         Periodic process that keeps that the compute host's understanding of
7730         resource availability and usage in sync with the underlying hypervisor.
7731 
7732         :param context: security context
7733         :param startup: True if this is being called when the nova-compute
7734             service is starting, False otherwise.
7735         """
7736 
7737         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
7738                                                             use_slave=True,
7739                                                             startup=startup)
7740         try:
7741             nodenames = set(self.driver.get_available_nodes())
7742         except exception.VirtDriverNotReady:
7743             LOG.warning("Virt driver is not ready.")
7744             return
7745 
7746         rt = self._get_resource_tracker()
7747         # Delete orphan compute node not reported by driver but still in db
7748         for cn in compute_nodes_in_db:
7749             if cn.hypervisor_hostname not in nodenames:
7750                 LOG.info("Deleting orphan compute node %(id)s "
7751                          "hypervisor host is %(hh)s, "
7752                          "nodes are %(nodes)s",
7753                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
7754                           'nodes': nodenames})
7755                 cn.destroy()
7756                 rt.remove_node(cn.hypervisor_hostname)
7757                 # Delete the corresponding resource provider in placement,
7758                 # along with any associated allocations and inventory.
7759                 # TODO(cdent): Move use of reportclient into resource tracker.
7760                 self.scheduler_client.reportclient.delete_resource_provider(
7761                     context, cn, cascade=True)
7762 
7763         for nodename in nodenames:
7764             self._update_available_resource_for_node(context, nodename)
7765 
7766     def _get_compute_nodes_in_db(self, context, use_slave=False,
7767                                  startup=False):
7768         try:
7769             return objects.ComputeNodeList.get_all_by_host(context, self.host,
7770                                                            use_slave=use_slave)
7771         except exception.NotFound:
7772             if startup:
7773                 LOG.warning(
7774                     "No compute node record found for host %s. If this is "
7775                     "the first time this service is starting on this "
7776                     "host, then you can ignore this warning.", self.host)
7777             else:
7778                 LOG.error("No compute node record for host %s", self.host)
7779             return []
7780 
7781     @periodic_task.periodic_task(
7782         spacing=CONF.running_deleted_instance_poll_interval)
7783     def _cleanup_running_deleted_instances(self, context):
7784         """Cleanup any instances which are erroneously still running after
7785         having been deleted.
7786 
7787         Valid actions to take are:
7788 
7789             1. noop - do nothing
7790             2. log - log which instances are erroneously running
7791             3. reap - shutdown and cleanup any erroneously running instances
7792             4. shutdown - power off *and disable* any erroneously running
7793                           instances
7794 
7795         The use-case for this cleanup task is: for various reasons, it may be
7796         possible for the database to show an instance as deleted but for that
7797         instance to still be running on a host machine (see bug
7798         https://bugs.launchpad.net/nova/+bug/911366).
7799 
7800         This cleanup task is a cross-hypervisor utility for finding these
7801         zombied instances and either logging the discrepancy (likely what you
7802         should do in production), or automatically reaping the instances (more
7803         appropriate for dev environments).
7804         """
7805         action = CONF.running_deleted_instance_action
7806 
7807         if action == "noop":
7808             return
7809 
7810         # NOTE(sirp): admin contexts don't ordinarily return deleted records
7811         with utils.temporary_mutation(context, read_deleted="yes"):
7812             for instance in self._running_deleted_instances(context):
7813                 if action == "log":
7814                     LOG.warning("Detected instance with name label "
7815                                 "'%s' which is marked as "
7816                                 "DELETED but still present on host.",
7817                                 instance.name, instance=instance)
7818 
7819                 elif action == 'shutdown':
7820                     LOG.info("Powering off instance with name label "
7821                              "'%s' which is marked as "
7822                              "DELETED but still present on host.",
7823                              instance.name, instance=instance)
7824                     try:
7825                         try:
7826                             # disable starting the instance
7827                             self.driver.set_bootable(instance, False)
7828                         except NotImplementedError:
7829                             LOG.debug("set_bootable is not implemented "
7830                                       "for the current driver")
7831                         # and power it off
7832                         self.driver.power_off(instance)
7833                     except Exception:
7834                         LOG.warning("Failed to power off instance",
7835                                     instance=instance, exc_info=True)
7836 
7837                 elif action == 'reap':
7838                     LOG.info("Destroying instance with name label "
7839                              "'%s' which is marked as "
7840                              "DELETED but still present on host.",
7841                              instance.name, instance=instance)
7842                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7843                         context, instance.uuid, use_slave=True)
7844                     self.instance_events.clear_events_for_instance(instance)
7845                     try:
7846                         self._shutdown_instance(context, instance, bdms,
7847                                                 notify=False)
7848                         self._cleanup_volumes(context, instance, bdms,
7849                                               detach=False)
7850                     except Exception as e:
7851                         LOG.warning("Periodic cleanup failed to delete "
7852                                     "instance: %s",
7853                                     e, instance=instance)
7854                 else:
7855                     raise Exception(_("Unrecognized value '%s'"
7856                                       " for CONF.running_deleted_"
7857                                       "instance_action") % action)
7858 
7859     def _running_deleted_instances(self, context):
7860         """Returns a list of instances nova thinks is deleted,
7861         but the hypervisor thinks is still running.
7862         """
7863         timeout = CONF.running_deleted_instance_timeout
7864         filters = {'deleted': True,
7865                    'soft_deleted': False}
7866         instances = self._get_instances_on_driver(context, filters)
7867         return [i for i in instances if self._deleted_old_enough(i, timeout)]
7868 
7869     def _deleted_old_enough(self, instance, timeout):
7870         deleted_at = instance.deleted_at
7871         if deleted_at:
7872             deleted_at = deleted_at.replace(tzinfo=None)
7873         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
7874 
7875     @contextlib.contextmanager
7876     def _error_out_instance_on_exception(self, context, instance,
7877                                          instance_state=vm_states.ACTIVE):
7878         instance_uuid = instance.uuid
7879         try:
7880             yield
7881         except NotImplementedError as error:
7882             with excutils.save_and_reraise_exception():
7883                 LOG.info("Setting instance back to %(state)s after: "
7884                          "%(error)s",
7885                          {'state': instance_state, 'error': error},
7886                          instance_uuid=instance_uuid)
7887                 self._instance_update(context, instance,
7888                                       vm_state=instance_state,
7889                                       task_state=None)
7890         except exception.InstanceFaultRollback as error:
7891             LOG.info("Setting instance back to ACTIVE after: %s",
7892                      error, instance_uuid=instance_uuid)
7893             self._instance_update(context, instance,
7894                                   vm_state=vm_states.ACTIVE,
7895                                   task_state=None)
7896             raise error.inner_exception
7897         except Exception:
7898             LOG.exception('Setting instance vm_state to ERROR',
7899                           instance_uuid=instance_uuid)
7900             with excutils.save_and_reraise_exception():
7901                 self._set_instance_obj_error_state(context, instance)
7902 
7903     @wrap_exception()
7904     def add_aggregate_host(self, context, aggregate, host, slave_info):
7905         """Notify hypervisor of change (for hypervisor pools)."""
7906         try:
7907             self.driver.add_to_aggregate(context, aggregate, host,
7908                                          slave_info=slave_info)
7909         except NotImplementedError:
7910             LOG.debug('Hypervisor driver does not support '
7911                       'add_aggregate_host')
7912         except exception.AggregateError:
7913             with excutils.save_and_reraise_exception():
7914                 self.driver.undo_aggregate_operation(
7915                                     context,
7916                                     aggregate.delete_host,
7917                                     aggregate, host)
7918 
7919     @wrap_exception()
7920     def remove_aggregate_host(self, context, host, slave_info, aggregate):
7921         """Removes a host from a physical hypervisor pool."""
7922         try:
7923             self.driver.remove_from_aggregate(context, aggregate, host,
7924                                               slave_info=slave_info)
7925         except NotImplementedError:
7926             LOG.debug('Hypervisor driver does not support '
7927                       'remove_aggregate_host')
7928         except (exception.AggregateError,
7929                 exception.InvalidAggregateAction) as e:
7930             with excutils.save_and_reraise_exception():
7931                 self.driver.undo_aggregate_operation(
7932                                     context,
7933                                     aggregate.add_host,
7934                                     aggregate, host,
7935                                     isinstance(e, exception.AggregateError))
7936 
7937     def _process_instance_event(self, instance, event):
7938         _event = self.instance_events.pop_instance_event(instance, event)
7939         if _event:
7940             LOG.debug('Processing event %(event)s',
7941                       {'event': event.key}, instance=instance)
7942             _event.send(event)
7943         else:
7944             # If it's a network-vif-unplugged event and the instance is being
7945             # deleted then we don't need to make this a warning as it's
7946             # expected. There are other things which could trigger this like
7947             # detaching an interface, but we don't have a task state for that.
7948             if (event.name == 'network-vif-unplugged' and
7949                     instance.task_state == task_states.DELETING):
7950                 LOG.debug('Received event %s for instance which is being '
7951                           'deleted.', event.key, instance=instance)
7952             else:
7953                 LOG.warning('Received unexpected event %(event)s for '
7954                             'instance with vm_state %(vm_state)s and '
7955                             'task_state %(task_state)s.',
7956                             {'event': event.key,
7957                              'vm_state': instance.vm_state,
7958                              'task_state': instance.task_state},
7959                             instance=instance)
7960 
7961     def _process_instance_vif_deleted_event(self, context, instance,
7962                                             deleted_vif_id):
7963         # If an attached port is deleted by neutron, it needs to
7964         # be detached from the instance.
7965         # And info cache needs to be updated.
7966         network_info = instance.info_cache.network_info
7967         for index, vif in enumerate(network_info):
7968             if vif['id'] == deleted_vif_id:
7969                 LOG.info('Neutron deleted interface %(intf)s; '
7970                          'detaching it from the instance and '
7971                          'deleting it from the info cache',
7972                          {'intf': vif['id']},
7973                          instance=instance)
7974                 del network_info[index]
7975                 base_net_api.update_instance_cache_with_nw_info(
7976                                  self.network_api, context,
7977                                  instance,
7978                                  nw_info=network_info)
7979                 try:
7980                     self.driver.detach_interface(context, instance, vif)
7981                 except NotImplementedError:
7982                     # Not all virt drivers support attach/detach of interfaces
7983                     # yet (like Ironic), so just ignore this.
7984                     pass
7985                 except exception.NovaException as ex:
7986                     # If the instance was deleted before the interface was
7987                     # detached, just log it at debug.
7988                     log_level = (logging.DEBUG
7989                                  if isinstance(ex, exception.InstanceNotFound)
7990                                  else logging.WARNING)
7991                     LOG.log(log_level,
7992                             "Detach interface failed, "
7993                             "port_id=%(port_id)s, reason: %(msg)s",
7994                             {'port_id': deleted_vif_id, 'msg': ex},
7995                             instance=instance)
7996                 break
7997 
7998     @wrap_instance_event(prefix='compute')
7999     @wrap_instance_fault
8000     def extend_volume(self, context, instance, extended_volume_id):
8001 
8002         # If an attached volume is extended by cinder, it needs to
8003         # be extended by virt driver so host can detect its new size.
8004         # And bdm needs to be updated.
8005         LOG.debug('Handling volume-extended event for volume %(vol)s',
8006                   {'vol': extended_volume_id}, instance=instance)
8007 
8008         try:
8009             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
8010                    context, extended_volume_id, instance.uuid)
8011         except exception.NotFound:
8012             LOG.warning('Extend volume failed, '
8013                         'volume %(vol)s is not attached to instance.',
8014                         {'vol': extended_volume_id},
8015                         instance=instance)
8016             return
8017 
8018         LOG.info('Cinder extended volume %(vol)s; '
8019                  'extending it to detect new size',
8020                  {'vol': extended_volume_id},
8021                  instance=instance)
8022         volume = self.volume_api.get(context, bdm.volume_id)
8023 
8024         if bdm.connection_info is None:
8025             LOG.warning('Extend volume failed, '
8026                         'attached volume %(vol)s has no connection_info',
8027                         {'vol': extended_volume_id},
8028                         instance=instance)
8029             return
8030 
8031         connection_info = jsonutils.loads(bdm.connection_info)
8032         bdm.volume_size = volume['size']
8033         bdm.save()
8034 
8035         if not self.driver.capabilities.get('supports_extend_volume', False):
8036             raise exception.ExtendVolumeNotSupported()
8037 
8038         try:
8039             self.driver.extend_volume(connection_info,
8040                                       instance)
8041         except Exception as ex:
8042             LOG.warning('Extend volume failed, '
8043                         'volume_id=%(volume_id)s, reason: %(msg)s',
8044                         {'volume_id': extended_volume_id, 'msg': ex},
8045                         instance=instance)
8046             raise
8047 
8048     @wrap_exception()
8049     def external_instance_event(self, context, instances, events):
8050         # NOTE(danms): Some event types are handled by the manager, such
8051         # as when we're asked to update the instance's info_cache. If it's
8052         # not one of those, look for some thread(s) waiting for the event and
8053         # unblock them if so.
8054         for event in events:
8055             instance = [inst for inst in instances
8056                         if inst.uuid == event.instance_uuid][0]
8057             LOG.debug('Received event %(event)s',
8058                       {'event': event.key},
8059                       instance=instance)
8060             if event.name == 'network-changed':
8061                 try:
8062                     LOG.debug('Refreshing instance network info cache due to '
8063                               'event %s.', event.key, instance=instance)
8064                     self.network_api.get_instance_nw_info(
8065                         context, instance, refresh_vif_id=event.tag)
8066                 except exception.NotFound as e:
8067                     LOG.info('Failed to process external instance event '
8068                              '%(event)s due to: %(error)s',
8069                              {'event': event.key, 'error': six.text_type(e)},
8070                              instance=instance)
8071             elif event.name == 'network-vif-deleted':
8072                 try:
8073                     self._process_instance_vif_deleted_event(context,
8074                                                              instance,
8075                                                              event.tag)
8076                 except exception.NotFound as e:
8077                     LOG.info('Failed to process external instance event '
8078                              '%(event)s due to: %(error)s',
8079                              {'event': event.key, 'error': six.text_type(e)},
8080                              instance=instance)
8081             elif event.name == 'volume-extended':
8082                 self.extend_volume(context, instance, event.tag)
8083             else:
8084                 self._process_instance_event(instance, event)
8085 
8086     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
8087                                  external_process_ok=True)
8088     def _run_image_cache_manager_pass(self, context):
8089         """Run a single pass of the image cache manager."""
8090 
8091         if not self.driver.capabilities.get("has_imagecache", False):
8092             return
8093 
8094         # Determine what other nodes use this storage
8095         storage_users.register_storage_use(CONF.instances_path, CONF.host)
8096         nodes = storage_users.get_storage_users(CONF.instances_path)
8097 
8098         # Filter all_instances to only include those nodes which share this
8099         # storage path.
8100         # TODO(mikal): this should be further refactored so that the cache
8101         # cleanup code doesn't know what those instances are, just a remote
8102         # count, and then this logic should be pushed up the stack.
8103         filters = {'deleted': False,
8104                    'soft_deleted': True,
8105                    'host': nodes}
8106         filtered_instances = objects.InstanceList.get_by_filters(context,
8107                                  filters, expected_attrs=[], use_slave=True)
8108 
8109         self.driver.manage_image_cache(context, filtered_instances)
8110 
8111     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8112     def _run_pending_deletes(self, context):
8113         """Retry any pending instance file deletes."""
8114         LOG.debug('Cleaning up deleted instances')
8115         filters = {'deleted': True,
8116                    'soft_deleted': False,
8117                    'host': CONF.host,
8118                    'cleaned': False}
8119         attrs = ['system_metadata']
8120         with utils.temporary_mutation(context, read_deleted='yes'):
8121             instances = objects.InstanceList.get_by_filters(
8122                 context, filters, expected_attrs=attrs, use_slave=True)
8123         LOG.debug('There are %d instances to clean', len(instances))
8124 
8125         # TODO(raj_singh): Remove this if condition when min value is
8126         # introduced to "maximum_instance_delete_attempts" cfg option.
8127         if CONF.maximum_instance_delete_attempts < 1:
8128             LOG.warning('Future versions of Nova will restrict the '
8129                         '"maximum_instance_delete_attempts" config option '
8130                         'to values >=1. Update your configuration file to '
8131                         'mitigate future upgrade issues.')
8132 
8133         for instance in instances:
8134             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
8135             LOG.debug('Instance has had %(attempts)s of %(max)s '
8136                       'cleanup attempts',
8137                       {'attempts': attempts,
8138                        'max': CONF.maximum_instance_delete_attempts},
8139                       instance=instance)
8140             if attempts < CONF.maximum_instance_delete_attempts:
8141                 success = self.driver.delete_instance_files(instance)
8142 
8143                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
8144                 if success:
8145                     instance.cleaned = True
8146                 with utils.temporary_mutation(context, read_deleted='yes'):
8147                     instance.save()
8148 
8149     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8150     def _cleanup_incomplete_migrations(self, context):
8151         """Delete instance files on failed resize/revert-resize operation
8152 
8153         During resize/revert-resize operation, if that instance gets deleted
8154         in-between then instance files might remain either on source or
8155         destination compute node because of race condition.
8156         """
8157         LOG.debug('Cleaning up deleted instances with incomplete migration ')
8158         migration_filters = {'host': CONF.host,
8159                              'status': 'error'}
8160         migrations = objects.MigrationList.get_by_filters(context,
8161                                                           migration_filters)
8162 
8163         if not migrations:
8164             return
8165 
8166         inst_uuid_from_migrations = set([migration.instance_uuid for migration
8167                                          in migrations])
8168 
8169         inst_filters = {'deleted': True, 'soft_deleted': False,
8170                         'uuid': inst_uuid_from_migrations}
8171         attrs = ['info_cache', 'security_groups', 'system_metadata']
8172         with utils.temporary_mutation(context, read_deleted='yes'):
8173             instances = objects.InstanceList.get_by_filters(
8174                 context, inst_filters, expected_attrs=attrs, use_slave=True)
8175 
8176         for instance in instances:
8177             if instance.host != CONF.host:
8178                 for migration in migrations:
8179                     if instance.uuid == migration.instance_uuid:
8180                         # Delete instance files if not cleanup properly either
8181                         # from the source or destination compute nodes when
8182                         # the instance is deleted during resizing.
8183                         self.driver.delete_instance_files(instance)
8184                         try:
8185                             migration.status = 'failed'
8186                             with migration.obj_as_admin():
8187                                 migration.save()
8188                         except exception.MigrationNotFound:
8189                             LOG.warning("Migration %s is not found.",
8190                                         migration.id,
8191                                         instance=instance)
8192                         break
8193 
8194     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8195                                    exception.QemuGuestAgentNotEnabled,
8196                                    exception.NovaException,
8197                                    NotImplementedError)
8198     @wrap_exception()
8199     def quiesce_instance(self, context, instance):
8200         """Quiesce an instance on this host."""
8201         context = context.elevated()
8202         image_meta = objects.ImageMeta.from_instance(instance)
8203         self.driver.quiesce(context, instance, image_meta)
8204 
8205     def _wait_for_snapshots_completion(self, context, mapping):
8206         for mapping_dict in mapping:
8207             if mapping_dict.get('source_type') == 'snapshot':
8208 
8209                 def _wait_snapshot():
8210                     snapshot = self.volume_api.get_snapshot(
8211                         context, mapping_dict['snapshot_id'])
8212                     if snapshot.get('status') != 'creating':
8213                         raise loopingcall.LoopingCallDone()
8214 
8215                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
8216                 timer.start(interval=0.5).wait()
8217 
8218     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8219                                    exception.QemuGuestAgentNotEnabled,
8220                                    exception.NovaException,
8221                                    NotImplementedError)
8222     @wrap_exception()
8223     def unquiesce_instance(self, context, instance, mapping=None):
8224         """Unquiesce an instance on this host.
8225 
8226         If snapshots' image mapping is provided, it waits until snapshots are
8227         completed before unqueiscing.
8228         """
8229         context = context.elevated()
8230         if mapping:
8231             try:
8232                 self._wait_for_snapshots_completion(context, mapping)
8233             except Exception as error:
8234                 LOG.exception("Exception while waiting completion of "
8235                               "volume snapshots: %s",
8236                               error, instance=instance)
8237         image_meta = objects.ImageMeta.from_instance(instance)
8238         self.driver.unquiesce(context, instance, image_meta)
8239 
8240     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8241     def _cleanup_expired_console_auth_tokens(self, context):
8242         """Remove expired console auth tokens for this host.
8243 
8244         Console authorization tokens and their connection data are stored
8245         in the database when a user asks for a console connection to an
8246         instance. After a time they expire. We periodically remove any expired
8247         tokens from the database.
8248         """
8249         # If the database backend isn't in use, don't bother looking for
8250         # expired tokens. The database backend is not supported for cells v1.
8251         if not CONF.cells.enable:
8252             objects.ConsoleAuthToken.\
8253                 clean_expired_console_auths_for_host(context, self.host)
