Please review the code below for security defects using the CWE (Common Weakness Enumeration) as a reference standard. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are detected, state: 'No security defects are detected in the code'.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import copy
32 import functools
33 import inspect
34 import sys
35 import time
36 import traceback
37 
38 from cinderclient import exceptions as cinder_exception
39 from cursive import exception as cursive_exception
40 import eventlet.event
41 from eventlet import greenthread
42 import eventlet.semaphore
43 import eventlet.timeout
44 import futurist
45 from keystoneauth1 import exceptions as keystone_exception
46 from oslo_log import log as logging
47 import oslo_messaging as messaging
48 from oslo_serialization import jsonutils
49 from oslo_service import loopingcall
50 from oslo_service import periodic_task
51 from oslo_utils import excutils
52 from oslo_utils import strutils
53 from oslo_utils import timeutils
54 from oslo_utils import units
55 import six
56 from six.moves import range
57 
58 from nova import block_device
59 from nova import compute
60 from nova.compute import build_results
61 from nova.compute import claims
62 from nova.compute import power_state
63 from nova.compute import resource_tracker
64 from nova.compute import rpcapi as compute_rpcapi
65 from nova.compute import task_states
66 from nova.compute import utils as compute_utils
67 from nova.compute.utils import wrap_instance_event
68 from nova.compute import vm_states
69 from nova import conductor
70 import nova.conf
71 from nova.console import rpcapi as console_rpcapi
72 import nova.context
73 from nova import exception
74 from nova import exception_wrapper
75 from nova import hooks
76 from nova.i18n import _
77 from nova import image
78 from nova import manager
79 from nova import network
80 from nova.network import base_api as base_net_api
81 from nova.network import model as network_model
82 from nova.network.security_group import openstack_driver
83 from nova import objects
84 from nova.objects import base as obj_base
85 from nova.objects import fields
86 from nova.objects import instance as obj_instance
87 from nova.objects import migrate_data as migrate_data_obj
88 from nova.pci import request as pci_req_module
89 from nova.pci import whitelist
90 from nova import rpc
91 from nova import safe_utils
92 from nova.scheduler.client import query
93 from nova import utils
94 from nova.virt import block_device as driver_block_device
95 from nova.virt import configdrive
96 from nova.virt import driver
97 from nova.virt import event as virtevent
98 from nova.virt import storage_users
99 from nova.virt import virtapi
100 from nova.volume import cinder
101 
102 CONF = nova.conf.CONF
103 
104 LOG = logging.getLogger(__name__)
105 
106 get_notifier = functools.partial(rpc.get_notifier, service='compute')
107 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
108                                    get_notifier=get_notifier,
109                                    binary='nova-compute')
110 
111 
112 @contextlib.contextmanager
113 def errors_out_migration_ctxt(migration):
114     """Context manager to error out migration on failure."""
115 
116     try:
117         yield
118     except Exception:
119         with excutils.save_and_reraise_exception():
120             if migration:
121                 # We may have been passed None for our migration if we're
122                 # receiving from an older client. The migration will be
123                 # errored via the legacy path.
124                 migration.status = 'error'
125                 try:
126                     migration.save()
127                 except Exception:
128                     LOG.debug(
129                         'Error setting migration status for instance %s.',
130                         migration.instance_uuid, exc_info=True)
131 
132 
133 @utils.expects_func_args('migration')
134 def errors_out_migration(function):
135     """Decorator to error out migration on failure."""
136 
137     @functools.wraps(function)
138     def decorated_function(self, context, *args, **kwargs):
139         wrapped_func = safe_utils.get_wrapped_function(function)
140         keyed_args = inspect.getcallargs(wrapped_func, self, context,
141                                          *args, **kwargs)
142         migration = keyed_args['migration']
143         with errors_out_migration_ctxt(migration):
144             return function(self, context, *args, **kwargs)
145 
146     return decorated_function
147 
148 
149 @utils.expects_func_args('instance')
150 def reverts_task_state(function):
151     """Decorator to revert task_state on failure."""
152 
153     @functools.wraps(function)
154     def decorated_function(self, context, *args, **kwargs):
155         try:
156             return function(self, context, *args, **kwargs)
157         except exception.UnexpectedTaskStateError as e:
158             # Note(maoy): unexpected task state means the current
159             # task is preempted. Do not clear task state in this
160             # case.
161             with excutils.save_and_reraise_exception():
162                 LOG.info("Task possibly preempted: %s",
163                          e.format_message())
164         except Exception:
165             with excutils.save_and_reraise_exception():
166                 wrapped_func = safe_utils.get_wrapped_function(function)
167                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
168                                                  *args, **kwargs)
169                 # NOTE(mriedem): 'instance' must be in keyed_args because we
170                 # have utils.expects_func_args('instance') decorating this
171                 # method.
172                 instance = keyed_args['instance']
173                 original_task_state = instance.task_state
174                 try:
175                     self._instance_update(context, instance, task_state=None)
176                     LOG.info("Successfully reverted task state from %s on "
177                              "failure for instance.",
178                              original_task_state, instance=instance)
179                 except exception.InstanceNotFound:
180                     # We might delete an instance that failed to build shortly
181                     # after it errored out this is an expected case and we
182                     # should not trace on it.
183                     pass
184                 except Exception as e:
185                     LOG.warning("Failed to revert task state for instance. "
186                                 "Error: %s", e, instance=instance)
187 
188     return decorated_function
189 
190 
191 @utils.expects_func_args('instance')
192 def wrap_instance_fault(function):
193     """Wraps a method to catch exceptions related to instances.
194 
195     This decorator wraps a method to catch any exceptions having to do with
196     an instance that may get thrown. It then logs an instance fault in the db.
197     """
198 
199     @functools.wraps(function)
200     def decorated_function(self, context, *args, **kwargs):
201         try:
202             return function(self, context, *args, **kwargs)
203         except exception.InstanceNotFound:
204             raise
205         except Exception as e:
206             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
207             # we will get a KeyError exception which will cover up the real
208             # exception. So, we update kwargs with the values from args first.
209             # then, we can get 'instance' from kwargs easily.
210             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
211 
212             with excutils.save_and_reraise_exception():
213                 compute_utils.add_instance_fault_from_exc(context,
214                         kwargs['instance'], e, sys.exc_info())
215 
216     return decorated_function
217 
218 
219 @utils.expects_func_args('image_id', 'instance')
220 def delete_image_on_error(function):
221     """Used for snapshot related method to ensure the image created in
222     compute.api is deleted when an error occurs.
223     """
224 
225     @functools.wraps(function)
226     def decorated_function(self, context, image_id, instance,
227                            *args, **kwargs):
228         try:
229             return function(self, context, image_id, instance,
230                             *args, **kwargs)
231         except Exception:
232             with excutils.save_and_reraise_exception():
233                 LOG.debug("Cleaning up image %s", image_id,
234                           exc_info=True, instance=instance)
235                 try:
236                     self.image_api.delete(context, image_id)
237                 except exception.ImageNotFound:
238                     # Since we're trying to cleanup an image, we don't care if
239                     # if it's already gone.
240                     pass
241                 except Exception:
242                     LOG.exception("Error while trying to clean up image %s",
243                                   image_id, instance=instance)
244 
245     return decorated_function
246 
247 
248 # TODO(danms): Remove me after Icehouse
249 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
250 # NOTE(mikal): if the method being decorated has more than one decorator, then
251 # put this one first. Otherwise the various exception handling decorators do
252 # not function correctly.
253 def object_compat(function):
254     """Wraps a method that expects a new-world instance
255 
256     This provides compatibility for callers passing old-style dict
257     instances.
258     """
259 
260     @functools.wraps(function)
261     def decorated_function(self, context, *args, **kwargs):
262         def _load_instance(instance_or_dict):
263             if isinstance(instance_or_dict, dict):
264                 # try to get metadata and system_metadata for most cases but
265                 # only attempt to load those if the db instance already has
266                 # those fields joined
267                 metas = [meta for meta in ('metadata', 'system_metadata')
268                          if meta in instance_or_dict]
269                 instance = objects.Instance._from_db_object(
270                     context, objects.Instance(), instance_or_dict,
271                     expected_attrs=metas)
272                 instance._context = context
273                 return instance
274             return instance_or_dict
275 
276         try:
277             kwargs['instance'] = _load_instance(kwargs['instance'])
278         except KeyError:
279             args = (_load_instance(args[0]),) + args[1:]
280 
281         migration = kwargs.get('migration')
282         if isinstance(migration, dict):
283             migration = objects.Migration._from_db_object(
284                     context.elevated(), objects.Migration(),
285                     migration)
286             kwargs['migration'] = migration
287 
288         return function(self, context, *args, **kwargs)
289 
290     return decorated_function
291 
292 
293 class InstanceEvents(object):
294     def __init__(self):
295         self._events = {}
296 
297     @staticmethod
298     def _lock_name(instance):
299         return '%s-%s' % (instance.uuid, 'events')
300 
301     def prepare_for_instance_event(self, instance, name, tag):
302         """Prepare to receive an event for an instance.
303 
304         This will register an event for the given instance that we will
305         wait on later. This should be called before initiating whatever
306         action will trigger the event. The resulting eventlet.event.Event
307         object should be wait()'d on to ensure completion.
308 
309         :param instance: the instance for which the event will be generated
310         :param name: the name of the event we're expecting
311         :param tag: the tag associated with the event we're expecting
312         :returns: an event object that should be wait()'d on
313         """
314         if self._events is None:
315             # NOTE(danms): We really should have a more specific error
316             # here, but this is what we use for our default error case
317             raise exception.NovaException('In shutdown, no new events '
318                                           'can be scheduled')
319 
320         @utils.synchronized(self._lock_name(instance))
321         def _create_or_get_event():
322             instance_events = self._events.setdefault(instance.uuid, {})
323             return instance_events.setdefault((name, tag),
324                                               eventlet.event.Event())
325         LOG.debug('Preparing to wait for external event %(name)s-%(tag)s',
326                   {'name': name, 'tag': tag}, instance=instance)
327         return _create_or_get_event()
328 
329     def pop_instance_event(self, instance, event):
330         """Remove a pending event from the wait list.
331 
332         This will remove a pending event from the wait list so that it
333         can be used to signal the waiters to wake up.
334 
335         :param instance: the instance for which the event was generated
336         :param event: the nova.objects.external_event.InstanceExternalEvent
337                       that describes the event
338         :returns: the eventlet.event.Event object on which the waiters
339                   are blocked
340         """
341         no_events_sentinel = object()
342         no_matching_event_sentinel = object()
343 
344         @utils.synchronized(self._lock_name(instance))
345         def _pop_event():
346             if self._events is None:
347                 LOG.debug('Unexpected attempt to pop events during shutdown',
348                           instance=instance)
349                 return no_events_sentinel
350             events = self._events.get(instance.uuid)
351             if not events:
352                 return no_events_sentinel
353             _event = events.pop((event.name, event.tag), None)
354             if not events:
355                 del self._events[instance.uuid]
356             if _event is None:
357                 return no_matching_event_sentinel
358             return _event
359 
360         result = _pop_event()
361         if result is no_events_sentinel:
362             LOG.debug('No waiting events found dispatching %(event)s',
363                       {'event': event.key},
364                       instance=instance)
365             return None
366         elif result is no_matching_event_sentinel:
367             LOG.debug('No event matching %(event)s in %(events)s',
368                       {'event': event.key,
369                        'events': self._events.get(instance.uuid, {}).keys()},
370                       instance=instance)
371             return None
372         else:
373             return result
374 
375     def clear_events_for_instance(self, instance):
376         """Remove all pending events for an instance.
377 
378         This will remove all events currently pending for an instance
379         and return them (indexed by event name).
380 
381         :param instance: the instance for which events should be purged
382         :returns: a dictionary of {event_name: eventlet.event.Event}
383         """
384         @utils.synchronized(self._lock_name(instance))
385         def _clear_events():
386             if self._events is None:
387                 LOG.debug('Unexpected attempt to clear events during shutdown',
388                           instance=instance)
389                 return dict()
390             # NOTE(danms): We have historically returned the raw internal
391             # format here, which is {event.key: [events, ...])} so just
392             # trivially convert it here.
393             return {'%s-%s' % k: e
394                     for k, e in self._events.pop(instance.uuid, {}).items()}
395         return _clear_events()
396 
397     def cancel_all_events(self):
398         if self._events is None:
399             LOG.debug('Unexpected attempt to cancel events during shutdown.')
400             return
401         our_events = self._events
402         # NOTE(danms): Block new events
403         self._events = None
404 
405         for instance_uuid, events in our_events.items():
406             for (name, tag), eventlet_event in events.items():
407                 LOG.debug('Canceling in-flight event %(name)s-%(tag)s for '
408                           'instance %(instance_uuid)s',
409                           {'name': name,
410                            'tag': tag,
411                            'instance_uuid': instance_uuid})
412                 event = objects.InstanceExternalEvent(
413                     instance_uuid=instance_uuid,
414                     name=name, status='failed',
415                     tag=tag, data={})
416                 eventlet_event.send(event)
417 
418 
419 class ComputeVirtAPI(virtapi.VirtAPI):
420     def __init__(self, compute):
421         super(ComputeVirtAPI, self).__init__()
422         self._compute = compute
423 
424     def _default_error_callback(self, event_name, instance):
425         raise exception.NovaException(_('Instance event failed'))
426 
427     @contextlib.contextmanager
428     def wait_for_instance_event(self, instance, event_names, deadline=300,
429                                 error_callback=None):
430         """Plan to wait for some events, run some code, then wait.
431 
432         This context manager will first create plans to wait for the
433         provided event_names, yield, and then wait for all the scheduled
434         events to complete.
435 
436         Note that this uses an eventlet.timeout.Timeout to bound the
437         operation, so callers should be prepared to catch that
438         failure and handle that situation appropriately.
439 
440         If the event is not received by the specified timeout deadline,
441         eventlet.timeout.Timeout is raised.
442 
443         If the event is received but did not have a 'completed'
444         status, a NovaException is raised.  If an error_callback is
445         provided, instead of raising an exception as detailed above
446         for the failure case, the callback will be called with the
447         event_name and instance, and can return True to continue
448         waiting for the rest of the events, False to stop processing,
449         or raise an exception which will bubble up to the waiter.
450 
451         :param instance: The instance for which an event is expected
452         :param event_names: A list of event names. Each element is a
453                             tuple of strings to indicate (name, tag),
454                             where name is required, but tag may be None.
455         :param deadline: Maximum number of seconds we should wait for all
456                          of the specified events to arrive.
457         :param error_callback: A function to be called if an event arrives
458 
459         """
460 
461         if error_callback is None:
462             error_callback = self._default_error_callback
463         events = {}
464         for event_name in event_names:
465             name, tag = event_name
466             event_name = objects.InstanceExternalEvent.make_key(name, tag)
467             try:
468                 events[event_name] = (
469                     self._compute.instance_events.prepare_for_instance_event(
470                         instance, name, tag))
471             except exception.NovaException:
472                 error_callback(event_name, instance)
473                 # NOTE(danms): Don't wait for any of the events. They
474                 # should all be canceled and fired immediately below,
475                 # but don't stick around if not.
476                 deadline = 0
477         yield
478         with eventlet.timeout.Timeout(deadline):
479             for event_name, event in events.items():
480                 actual_event = event.wait()
481                 if actual_event.status == 'completed':
482                     continue
483                 decision = error_callback(event_name, instance)
484                 if decision is False:
485                     break
486 
487 
488 class ComputeManager(manager.Manager):
489     """Manages the running instances from creation to destruction."""
490 
491     target = messaging.Target(version='5.2')
492 
493     def __init__(self, compute_driver=None, *args, **kwargs):
494         """Load configuration options and connect to the hypervisor."""
495         self.virtapi = ComputeVirtAPI(self)
496         self.network_api = network.API()
497         self.volume_api = cinder.API()
498         self.image_api = image.API()
499         self._last_bw_usage_poll = 0
500         self._bw_usage_supported = True
501         self._last_bw_usage_cell_update = 0
502         self.compute_api = compute.API()
503         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
504         self.compute_task_api = conductor.ComputeTaskAPI()
505         self.is_neutron_security_groups = (
506             openstack_driver.is_neutron_security_groups())
507         self.query_client = query.SchedulerQueryClient()
508         self.instance_events = InstanceEvents()
509         self._sync_power_pool = eventlet.GreenPool(
510             size=CONF.sync_power_state_pool_size)
511         self._syncs_in_progress = {}
512         self.send_instance_updates = (
513             CONF.filter_scheduler.track_instance_changes)
514         if CONF.max_concurrent_builds != 0:
515             self._build_semaphore = eventlet.semaphore.Semaphore(
516                 CONF.max_concurrent_builds)
517         else:
518             self._build_semaphore = compute_utils.UnlimitedSemaphore()
519         if CONF.max_concurrent_live_migrations > 0:
520             self._live_migration_executor = futurist.GreenThreadPoolExecutor(
521                 max_workers=CONF.max_concurrent_live_migrations)
522         else:
523             # CONF.max_concurrent_live_migrations is 0 (unlimited)
524             self._live_migration_executor = futurist.GreenThreadPoolExecutor()
525         # This is a dict, keyed by instance uuid, to a two-item tuple of
526         # migration object and Future for the queued live migration.
527         self._waiting_live_migrations = {}
528 
529         super(ComputeManager, self).__init__(service_name="compute",
530                                              *args, **kwargs)
531 
532         # NOTE(russellb) Load the driver last.  It may call back into the
533         # compute manager via the virtapi, so we want it to be fully
534         # initialized before that happens.
535         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
536         self.use_legacy_block_device_info = \
537                             self.driver.need_legacy_block_device_info
538         self.rt = resource_tracker.ResourceTracker(self.host, self.driver)
539         self.reportclient = self.rt.reportclient
540 
541     def reset(self):
542         LOG.info('Reloading compute RPC API')
543         compute_rpcapi.reset_globals()
544         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
545         self.reportclient.clear_provider_cache()
546 
547     def _update_resource_tracker(self, context, instance):
548         """Let the resource tracker know that an instance has changed state."""
549 
550         if instance.host == self.host:
551             self.rt.update_usage(context, instance, instance.node)
552 
553     def _instance_update(self, context, instance, **kwargs):
554         """Update an instance in the database using kwargs as value."""
555 
556         for k, v in kwargs.items():
557             setattr(instance, k, v)
558         instance.save()
559         self._update_resource_tracker(context, instance)
560 
561     def _nil_out_instance_obj_host_and_node(self, instance):
562         # NOTE(jwcroppe): We don't do instance.save() here for performance
563         # reasons; a call to this is expected to be immediately followed by
564         # another call that does instance.save(), thus avoiding two writes
565         # to the database layer.
566         instance.host = None
567         instance.node = None
568         # If the instance is not on a host, it's not in an aggregate and
569         # therefore is not in an availability zone.
570         instance.availability_zone = None
571 
572     def _set_instance_obj_error_state(self, context, instance,
573                                       clean_task_state=False):
574         try:
575             instance.vm_state = vm_states.ERROR
576             if clean_task_state:
577                 instance.task_state = None
578             instance.save()
579         except exception.InstanceNotFound:
580             LOG.debug('Instance has been destroyed from under us while '
581                       'trying to set it to ERROR', instance=instance)
582 
583     def _get_instances_on_driver(self, context, filters=None):
584         """Return a list of instance records for the instances found
585         on the hypervisor which satisfy the specified filters. If filters=None
586         return a list of instance records for all the instances found on the
587         hypervisor.
588         """
589         if not filters:
590             filters = {}
591         try:
592             driver_uuids = self.driver.list_instance_uuids()
593             if len(driver_uuids) == 0:
594                 # Short circuit, don't waste a DB call
595                 return objects.InstanceList()
596             filters['uuid'] = driver_uuids
597             local_instances = objects.InstanceList.get_by_filters(
598                 context, filters, use_slave=True)
599             return local_instances
600         except NotImplementedError:
601             pass
602 
603         # The driver doesn't support uuids listing, so we'll have
604         # to brute force.
605         driver_instances = self.driver.list_instances()
606         # NOTE(mjozefcz): In this case we need to apply host filter.
607         # Without this all instance data would be fetched from db.
608         filters['host'] = self.host
609         instances = objects.InstanceList.get_by_filters(context, filters,
610                                                         use_slave=True)
611         name_map = {instance.name: instance for instance in instances}
612         local_instances = []
613         for driver_instance in driver_instances:
614             instance = name_map.get(driver_instance)
615             if not instance:
616                 continue
617             local_instances.append(instance)
618         return local_instances
619 
620     def _destroy_evacuated_instances(self, context):
621         """Destroys evacuated instances.
622 
623         While nova-compute was down, the instances running on it could be
624         evacuated to another host. This method looks for evacuation migration
625         records where this is the source host and which were either started
626         (accepted), in-progress (pre-migrating) or migrated (done). From those
627         migration records, local instances reported by the hypervisor are
628         compared to the instances for the migration records and those local
629         guests are destroyed, along with instance allocation records in
630         Placement for this node.
631         Then allocations are removed from Placement for every instance that is
632         evacuated from this host regardless if the instance is reported by the
633         hypervisor or not.
634         """
635         filters = {
636             'source_compute': self.host,
637             # NOTE(mriedem): Migration records that have been accepted are
638             # included in case the source node comes back up while instances
639             # are being evacuated to another host. We don't want the same
640             # instance being reported from multiple hosts.
641             # NOTE(lyarwood): pre-migrating is also included here as the
642             # source compute can come back online shortly after the RT
643             # claims on the destination that in-turn moves the migration to
644             # pre-migrating. If the evacuate fails on the destination host,
645             # the user can rebuild the instance (in ERROR state) on the source
646             # host.
647             'status': ['accepted', 'pre-migrating', 'done'],
648             'migration_type': 'evacuation',
649         }
650         with utils.temporary_mutation(context, read_deleted='yes'):
651             evacuations = objects.MigrationList.get_by_filters(context,
652                                                                filters)
653         if not evacuations:
654             return
655         evacuations = {mig.instance_uuid: mig for mig in evacuations}
656 
657         # TODO(mriedem): We could optimize by pre-loading the joined fields
658         # we know we'll use, like info_cache and flavor.
659         local_instances = self._get_instances_on_driver(context)
660         evacuated_local_instances = {inst.uuid: inst
661                                      for inst in local_instances
662                                      if inst.uuid in evacuations}
663 
664         for instance in evacuated_local_instances.values():
665             LOG.info('Destroying instance as it has been evacuated from '
666                      'this host but still exists in the hypervisor',
667                      instance=instance)
668             try:
669                 network_info = self.network_api.get_instance_nw_info(
670                     context, instance)
671                 bdi = self._get_instance_block_device_info(context,
672                                                            instance)
673                 destroy_disks = not (self._is_instance_storage_shared(
674                     context, instance))
675             except exception.InstanceNotFound:
676                 network_info = network_model.NetworkInfo()
677                 bdi = {}
678                 LOG.info('Instance has been marked deleted already, '
679                          'removing it from the hypervisor.',
680                          instance=instance)
681                 # always destroy disks if the instance was deleted
682                 destroy_disks = True
683             self.driver.destroy(context, instance,
684                                 network_info,
685                                 bdi, destroy_disks)
686 
687         # NOTE(gibi): We are called from init_host and at this point the
688         # compute_nodes of the resource tracker has not been populated yet so
689         # we cannot rely on the resource tracker here.
690         compute_nodes = {}
691 
692         for instance_uuid, migration in evacuations.items():
693             try:
694                 if instance_uuid in evacuated_local_instances:
695                     # Avoid the db call if we already have the instance loaded
696                     # above
697                     instance = evacuated_local_instances[instance_uuid]
698                 else:
699                     instance = objects.Instance.get_by_uuid(
700                         context, instance_uuid)
701             except exception.InstanceNotFound:
702                 # The instance already deleted so we expect that every
703                 # allocation of that instance has already been cleaned up
704                 continue
705 
706             LOG.info('Cleaning up allocations of the instance as it has been '
707                      'evacuated from this host',
708                      instance=instance)
709             if migration.source_node not in compute_nodes:
710                 try:
711                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
712                         context, self.host, migration.source_node).uuid
713                     compute_nodes[migration.source_node] = cn_uuid
714                 except exception.ComputeHostNotFound:
715                     LOG.error("Failed to clean allocation of evacuated "
716                               "instance as the source node %s is not found",
717                               migration.source_node, instance=instance)
718                     continue
719             cn_uuid = compute_nodes[migration.source_node]
720 
721             # If the instance was deleted in the interim, assume its
722             # allocations were properly cleaned up (either by its hosting
723             # compute service or the API).
724             if (not instance.deleted and
725                     not self.reportclient.
726                         remove_provider_tree_from_instance_allocation(
727                             context, instance.uuid, cn_uuid)):
728                 LOG.error("Failed to clean allocation of evacuated instance "
729                           "on the source node %s",
730                           cn_uuid, instance=instance)
731 
732             migration.status = 'completed'
733             migration.save()
734         return evacuations
735 
736     def _is_instance_storage_shared(self, context, instance, host=None):
737         shared_storage = True
738         data = None
739         try:
740             data = self.driver.check_instance_shared_storage_local(context,
741                                                        instance)
742             if data:
743                 shared_storage = (self.compute_rpcapi.
744                                   check_instance_shared_storage(context,
745                                   instance, data, host=host))
746         except NotImplementedError:
747             LOG.debug('Hypervisor driver does not support '
748                       'instance shared storage check, '
749                       'assuming it\'s not on shared storage',
750                       instance=instance)
751             shared_storage = False
752         except Exception:
753             LOG.exception('Failed to check if instance shared',
754                           instance=instance)
755         finally:
756             if data:
757                 self.driver.check_instance_shared_storage_cleanup(context,
758                                                                   data)
759         return shared_storage
760 
761     def _complete_partial_deletion(self, context, instance):
762         """Complete deletion for instances in DELETED status but not marked as
763         deleted in the DB
764         """
765         instance.destroy()
766         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
767                 context, instance.uuid)
768         self._complete_deletion(context,
769                                 instance)
770         self._notify_about_instance_usage(context, instance, "delete.end")
771         compute_utils.notify_about_instance_action(context, instance,
772                 self.host, action=fields.NotificationAction.DELETE,
773                 phase=fields.NotificationPhase.END, bdms=bdms)
774 
775     def _complete_deletion(self, context, instance):
776         self._update_resource_tracker(context, instance)
777 
778         self.reportclient.delete_allocation_for_instance(context,
779                                                          instance.uuid)
780 
781         self._clean_instance_console_tokens(context, instance)
782         self._delete_scheduler_instance_info(context, instance.uuid)
783 
784     def _init_instance(self, context, instance):
785         """Initialize this instance during service init."""
786 
787         # NOTE(danms): If the instance appears to not be owned by this
788         # host, it may have been evacuated away, but skipped by the
789         # evacuation cleanup code due to configuration. Thus, if that
790         # is a possibility, don't touch the instance in any way, but
791         # log the concern. This will help avoid potential issues on
792         # startup due to misconfiguration.
793         if instance.host != self.host:
794             LOG.warning('Instance %(uuid)s appears to not be owned '
795                         'by this host, but by %(host)s. Startup '
796                         'processing is being skipped.',
797                         {'uuid': instance.uuid,
798                          'host': instance.host})
799             return
800 
801         # Instances that are shut down, or in an error state can not be
802         # initialized and are not attempted to be recovered. The exception
803         # to this are instances that are in RESIZE_MIGRATING or DELETING,
804         # which are dealt with further down.
805         if (instance.vm_state == vm_states.SOFT_DELETED or
806             (instance.vm_state == vm_states.ERROR and
807             instance.task_state not in
808             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
809             LOG.debug("Instance is in %s state.",
810                       instance.vm_state, instance=instance)
811             return
812 
813         if instance.vm_state == vm_states.DELETED:
814             try:
815                 self._complete_partial_deletion(context, instance)
816             except Exception:
817                 # we don't want that an exception blocks the init_host
818                 LOG.exception('Failed to complete a deletion',
819                               instance=instance)
820             return
821 
822         if (instance.vm_state == vm_states.BUILDING or
823             instance.task_state in [task_states.SCHEDULING,
824                                     task_states.BLOCK_DEVICE_MAPPING,
825                                     task_states.NETWORKING,
826                                     task_states.SPAWNING]):
827             # NOTE(dave-mcnally) compute stopped before instance was fully
828             # spawned so set to ERROR state. This is safe to do as the state
829             # may be set by the api but the host is not so if we get here the
830             # instance has already been scheduled to this particular host.
831             LOG.debug("Instance failed to spawn correctly, "
832                       "setting to ERROR state", instance=instance)
833             instance.task_state = None
834             instance.vm_state = vm_states.ERROR
835             instance.save()
836             return
837 
838         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
839             instance.task_state in [task_states.REBUILDING,
840                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
841                                     task_states.REBUILD_SPAWNING]):
842             # NOTE(jichenjc) compute stopped before instance was fully
843             # spawned so set to ERROR state. This is consistent to BUILD
844             LOG.debug("Instance failed to rebuild correctly, "
845                       "setting to ERROR state", instance=instance)
846             instance.task_state = None
847             instance.vm_state = vm_states.ERROR
848             instance.save()
849             return
850 
851         if (instance.vm_state != vm_states.ERROR and
852             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
853                                     task_states.IMAGE_PENDING_UPLOAD,
854                                     task_states.IMAGE_UPLOADING,
855                                     task_states.IMAGE_SNAPSHOT]):
856             LOG.debug("Instance in transitional state %s at start-up "
857                       "clearing task state",
858                       instance.task_state, instance=instance)
859             try:
860                 self._post_interrupted_snapshot_cleanup(context, instance)
861             except Exception:
862                 # we don't want that an exception blocks the init_host
863                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
864             instance.task_state = None
865             instance.save()
866 
867         if (instance.vm_state != vm_states.ERROR and
868             instance.task_state in [task_states.RESIZE_PREP]):
869             LOG.debug("Instance in transitional state %s at start-up "
870                       "clearing task state",
871                       instance['task_state'], instance=instance)
872             instance.task_state = None
873             instance.save()
874 
875         if instance.task_state == task_states.DELETING:
876             try:
877                 LOG.info('Service started deleting the instance during '
878                          'the previous run, but did not finish. Restarting'
879                          ' the deletion now.', instance=instance)
880                 instance.obj_load_attr('metadata')
881                 instance.obj_load_attr('system_metadata')
882                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
883                         context, instance.uuid)
884                 self._delete_instance(context, instance, bdms)
885             except Exception:
886                 # we don't want that an exception blocks the init_host
887                 LOG.exception('Failed to complete a deletion',
888                               instance=instance)
889                 self._set_instance_obj_error_state(context, instance)
890             return
891 
892         current_power_state = self._get_power_state(context, instance)
893         try_reboot, reboot_type = self._retry_reboot(context, instance,
894                                                      current_power_state)
895 
896         if try_reboot:
897             LOG.debug("Instance in transitional state (%(task_state)s) at "
898                       "start-up and power state is (%(power_state)s), "
899                       "triggering reboot",
900                       {'task_state': instance.task_state,
901                        'power_state': current_power_state},
902                       instance=instance)
903 
904             # NOTE(mikal): if the instance was doing a soft reboot that got as
905             # far as shutting down the instance but not as far as starting it
906             # again, then we've just become a hard reboot. That means the
907             # task state for the instance needs to change so that we're in one
908             # of the expected task states for a hard reboot.
909             if (instance.task_state in task_states.soft_reboot_states and
910                 reboot_type == 'HARD'):
911                 instance.task_state = task_states.REBOOT_PENDING_HARD
912                 instance.save()
913 
914             self.reboot_instance(context, instance, block_device_info=None,
915                                  reboot_type=reboot_type)
916             return
917 
918         elif (current_power_state == power_state.RUNNING and
919               instance.task_state in [task_states.REBOOT_STARTED,
920                                       task_states.REBOOT_STARTED_HARD,
921                                       task_states.PAUSING,
922                                       task_states.UNPAUSING]):
923             LOG.warning("Instance in transitional state "
924                         "(%(task_state)s) at start-up and power state "
925                         "is (%(power_state)s), clearing task state",
926                         {'task_state': instance.task_state,
927                          'power_state': current_power_state},
928                         instance=instance)
929             instance.task_state = None
930             instance.vm_state = vm_states.ACTIVE
931             instance.save()
932         elif (current_power_state == power_state.PAUSED and
933               instance.task_state == task_states.UNPAUSING):
934             LOG.warning("Instance in transitional state "
935                         "(%(task_state)s) at start-up and power state "
936                         "is (%(power_state)s), clearing task state "
937                         "and unpausing the instance",
938                         {'task_state': instance.task_state,
939                          'power_state': current_power_state},
940                         instance=instance)
941             try:
942                 self.unpause_instance(context, instance)
943             except NotImplementedError:
944                 # Some virt driver didn't support pause and unpause
945                 pass
946             except Exception:
947                 LOG.exception('Failed to unpause instance', instance=instance)
948             return
949 
950         if instance.task_state == task_states.POWERING_OFF:
951             try:
952                 LOG.debug("Instance in transitional state %s at start-up "
953                           "retrying stop request",
954                           instance.task_state, instance=instance)
955                 self.stop_instance(context, instance, True)
956             except Exception:
957                 # we don't want that an exception blocks the init_host
958                 LOG.exception('Failed to stop instance', instance=instance)
959             return
960 
961         if instance.task_state == task_states.POWERING_ON:
962             try:
963                 LOG.debug("Instance in transitional state %s at start-up "
964                           "retrying start request",
965                           instance.task_state, instance=instance)
966                 self.start_instance(context, instance)
967             except Exception:
968                 # we don't want that an exception blocks the init_host
969                 LOG.exception('Failed to start instance', instance=instance)
970             return
971 
972         net_info = instance.get_network_info()
973         try:
974             self.driver.plug_vifs(instance, net_info)
975         except NotImplementedError as e:
976             LOG.debug(e, instance=instance)
977         except exception.VirtualInterfacePlugException:
978             # NOTE(mriedem): If we get here, it could be because the vif_type
979             # in the cache is "binding_failed" or "unbound".
980             # The periodic task _heal_instance_info_cache checks for this
981             # condition. It should fix this by binding the ports again when
982             # it gets to this instance.
983             LOG.exception('Virtual interface plugging failed for instance. '
984                           'The port binding:host_id may need to be manually '
985                           'updated.', instance=instance)
986             self._set_instance_obj_error_state(context, instance)
987             return
988 
989         if instance.task_state == task_states.RESIZE_MIGRATING:
990             # We crashed during resize/migration, so roll back for safety
991             try:
992                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
993                 # not in system_metadata we default to True for backwards
994                 # compatibility
995                 power_on = (instance.system_metadata.get('old_vm_state') !=
996                             vm_states.STOPPED)
997 
998                 block_dev_info = self._get_instance_block_device_info(context,
999                                                                       instance)
1000 
1001                 self.driver.finish_revert_migration(context,
1002                     instance, net_info, block_dev_info, power_on)
1003 
1004             except Exception:
1005                 LOG.exception('Failed to revert crashed migration',
1006                               instance=instance)
1007             finally:
1008                 LOG.info('Instance found in migrating state during '
1009                          'startup. Resetting task_state',
1010                          instance=instance)
1011                 instance.task_state = None
1012                 instance.save()
1013         if instance.task_state == task_states.MIGRATING:
1014             # Live migration did not complete, but instance is on this
1015             # host, so reset the state.
1016             instance.task_state = None
1017             instance.save(expected_task_state=[task_states.MIGRATING])
1018 
1019         db_state = instance.power_state
1020         drv_state = self._get_power_state(context, instance)
1021         expect_running = (db_state == power_state.RUNNING and
1022                           drv_state != db_state)
1023 
1024         LOG.debug('Current state is %(drv_state)s, state in DB is '
1025                   '%(db_state)s.',
1026                   {'drv_state': drv_state, 'db_state': db_state},
1027                   instance=instance)
1028 
1029         if expect_running and CONF.resume_guests_state_on_host_boot:
1030             self._resume_guests_state(context, instance, net_info)
1031         elif drv_state == power_state.RUNNING:
1032             # VMwareAPI drivers will raise an exception
1033             try:
1034                 self.driver.ensure_filtering_rules_for_instance(
1035                                        instance, net_info)
1036             except NotImplementedError:
1037                 LOG.debug('Hypervisor driver does not support '
1038                           'firewall rules', instance=instance)
1039 
1040     def _resume_guests_state(self, context, instance, net_info):
1041         LOG.info('Rebooting instance after nova-compute restart.',
1042                  instance=instance)
1043         block_device_info = \
1044             self._get_instance_block_device_info(context, instance)
1045 
1046         try:
1047             self.driver.resume_state_on_host_boot(
1048                 context, instance, net_info, block_device_info)
1049         except NotImplementedError:
1050             LOG.warning('Hypervisor driver does not support '
1051                         'resume guests', instance=instance)
1052         except Exception:
1053             # NOTE(vish): The instance failed to resume, so we set the
1054             #             instance to error and attempt to continue.
1055             LOG.warning('Failed to resume instance',
1056                         instance=instance)
1057             self._set_instance_obj_error_state(context, instance)
1058 
1059     def _retry_reboot(self, context, instance, current_power_state):
1060         current_task_state = instance.task_state
1061         retry_reboot = False
1062         reboot_type = compute_utils.get_reboot_type(current_task_state,
1063                                                     current_power_state)
1064 
1065         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1066                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1067         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1068                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1069         started_not_running = (current_task_state in
1070                                [task_states.REBOOT_STARTED,
1071                                 task_states.REBOOT_STARTED_HARD] and
1072                                current_power_state != power_state.RUNNING)
1073 
1074         if pending_soft or pending_hard or started_not_running:
1075             retry_reboot = True
1076 
1077         return retry_reboot, reboot_type
1078 
1079     def handle_lifecycle_event(self, event):
1080         LOG.info("VM %(state)s (Lifecycle Event)",
1081                  {'state': event.get_name()},
1082                  instance_uuid=event.get_instance_uuid())
1083         context = nova.context.get_admin_context(read_deleted='yes')
1084         vm_power_state = None
1085         event_transition = event.get_transition()
1086         if event_transition == virtevent.EVENT_LIFECYCLE_STOPPED:
1087             vm_power_state = power_state.SHUTDOWN
1088         elif event_transition == virtevent.EVENT_LIFECYCLE_STARTED:
1089             vm_power_state = power_state.RUNNING
1090         elif event_transition in (
1091                 virtevent.EVENT_LIFECYCLE_PAUSED,
1092                 virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED,
1093                 virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED):
1094             vm_power_state = power_state.PAUSED
1095         elif event_transition == virtevent.EVENT_LIFECYCLE_RESUMED:
1096             vm_power_state = power_state.RUNNING
1097         elif event_transition == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1098             vm_power_state = power_state.SUSPENDED
1099         else:
1100             LOG.warning("Unexpected lifecycle event: %d", event_transition)
1101 
1102         migrate_finish_statuses = {
1103             # This happens on the source node and indicates live migration
1104             # entered post-copy mode.
1105             virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED: 'running (post-copy)',
1106             # Suspended for offline migration.
1107             virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED: 'running'
1108         }
1109 
1110         expected_attrs = []
1111         if event_transition in migrate_finish_statuses:
1112             # Join on info_cache since that's needed in migrate_instance_start.
1113             expected_attrs.append('info_cache')
1114         instance = objects.Instance.get_by_uuid(context,
1115                                                 event.get_instance_uuid(),
1116                                                 expected_attrs=expected_attrs)
1117 
1118         # Note(lpetrut): The event may be delayed, thus not reflecting
1119         # the current instance power state. In that case, ignore the event.
1120         current_power_state = self._get_power_state(context, instance)
1121         if current_power_state == vm_power_state:
1122             LOG.debug('Synchronizing instance power state after lifecycle '
1123                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1124                       'current task_state: %(task_state)s, current DB '
1125                       'power_state: %(db_power_state)s, VM power_state: '
1126                       '%(vm_power_state)s',
1127                       {'event': event.get_name(),
1128                        'vm_state': instance.vm_state,
1129                        'task_state': instance.task_state,
1130                        'db_power_state': instance.power_state,
1131                        'vm_power_state': vm_power_state},
1132                       instance_uuid=instance.uuid)
1133             self._sync_instance_power_state(context,
1134                                             instance,
1135                                             vm_power_state)
1136 
1137         # The following checks are for live migration. We want to activate
1138         # the port binding for the destination host before the live migration
1139         # is resumed on the destination host in order to reduce network
1140         # downtime. Otherwise the ports are bound to the destination host
1141         # in post_live_migration_at_destination.
1142         # TODO(danms): Explore options for using a different live migration
1143         # specific callback for this instead of piggy-backing on the
1144         # handle_lifecycle_event callback.
1145         if (instance.task_state == task_states.MIGRATING and
1146                 event_transition in migrate_finish_statuses):
1147             status = migrate_finish_statuses[event_transition]
1148             try:
1149                 migration = objects.Migration.get_by_instance_and_status(
1150                             context, instance.uuid, status)
1151                 LOG.debug('Binding ports to destination host: %s',
1152                           migration.dest_compute, instance=instance)
1153                 # For neutron, migrate_instance_start will activate the
1154                 # destination host port bindings, if there are any created by
1155                 # conductor before live migration started.
1156                 self.network_api.migrate_instance_start(
1157                     context, instance, migration)
1158             except exception.MigrationNotFoundByStatus:
1159                 LOG.warning("Unable to find migration record with status "
1160                             "'%s' for instance. Port binding will happen in "
1161                             "post live migration.", status, instance=instance)
1162 
1163     def handle_events(self, event):
1164         if isinstance(event, virtevent.LifecycleEvent):
1165             try:
1166                 self.handle_lifecycle_event(event)
1167             except exception.InstanceNotFound:
1168                 LOG.debug("Event %s arrived for non-existent instance. The "
1169                           "instance was probably deleted.", event)
1170         else:
1171             LOG.debug("Ignoring event %s", event)
1172 
1173     def init_virt_events(self):
1174         if CONF.workarounds.handle_virt_lifecycle_events:
1175             self.driver.register_event_listener(self.handle_events)
1176         else:
1177             # NOTE(mriedem): If the _sync_power_states periodic task is
1178             # disabled we should emit a warning in the logs.
1179             if CONF.sync_power_state_interval < 0:
1180                 LOG.warning('Instance lifecycle events from the compute '
1181                             'driver have been disabled. Note that lifecycle '
1182                             'changes to an instance outside of the compute '
1183                             'service will not be synchronized '
1184                             'automatically since the _sync_power_states '
1185                             'periodic task is also disabled.')
1186             else:
1187                 LOG.info('Instance lifecycle events from the compute '
1188                          'driver have been disabled. Note that lifecycle '
1189                          'changes to an instance outside of the compute '
1190                          'service will only be synchronized by the '
1191                          '_sync_power_states periodic task.')
1192 
1193     def init_host(self):
1194         """Initialization for a standalone compute service."""
1195 
1196         if CONF.pci.passthrough_whitelist:
1197             # Simply loading the PCI passthrough whitelist will do a bunch of
1198             # validation that would otherwise wait until the PciDevTracker is
1199             # constructed when updating available resources for the compute
1200             # node(s) in the resource tracker, effectively killing that task.
1201             # So load up the whitelist when starting the compute service to
1202             # flush any invalid configuration early so we can kill the service
1203             # if the configuration is wrong.
1204             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1205 
1206         nova.conf.neutron.register_dynamic_opts(CONF)
1207 
1208         # Override the number of concurrent disk operations allowed if the
1209         # user has specified a limit.
1210         if CONF.compute.max_concurrent_disk_ops != 0:
1211             compute_utils.disk_ops_semaphore = \
1212                 eventlet.semaphore.BoundedSemaphore(
1213                     CONF.compute.max_concurrent_disk_ops)
1214 
1215         self.driver.init_host(host=self.host)
1216         context = nova.context.get_admin_context()
1217         instances = objects.InstanceList.get_by_host(
1218             context, self.host, expected_attrs=['info_cache', 'metadata'])
1219 
1220         if CONF.defer_iptables_apply:
1221             self.driver.filter_defer_apply_on()
1222 
1223         self.init_virt_events()
1224 
1225         try:
1226             # checking that instance was not already evacuated to other host
1227             evacuated_instances = self._destroy_evacuated_instances(context)
1228 
1229             # Initialise instances on the host that are not evacuating
1230             for instance in instances:
1231                 if (not evacuated_instances or
1232                         instance.uuid not in evacuated_instances):
1233                     self._init_instance(context, instance)
1234 
1235         finally:
1236             if CONF.defer_iptables_apply:
1237                 self.driver.filter_defer_apply_off()
1238             if instances:
1239                 # We only send the instance info to the scheduler on startup
1240                 # if there is anything to send, otherwise this host might
1241                 # not be mapped yet in a cell and the scheduler may have
1242                 # issues dealing with the information. Later changes to
1243                 # instances on this host will update the scheduler, or the
1244                 # _sync_scheduler_instance_info periodic task will.
1245                 self._update_scheduler_instance_info(context, instances)
1246 
1247     def cleanup_host(self):
1248         self.driver.register_event_listener(None)
1249         self.instance_events.cancel_all_events()
1250         self.driver.cleanup_host(host=self.host)
1251         self._cleanup_live_migrations_in_pool()
1252 
1253     def _cleanup_live_migrations_in_pool(self):
1254         # Shutdown the pool so we don't get new requests.
1255         self._live_migration_executor.shutdown(wait=False)
1256         # For any queued migrations, cancel the migration and update
1257         # its status.
1258         for migration, future in self._waiting_live_migrations.values():
1259             # If we got here before the Future was submitted then we need
1260             # to move on since there isn't anything we can do.
1261             if future is None:
1262                 continue
1263             if future.cancel():
1264                 self._set_migration_status(migration, 'cancelled')
1265                 LOG.info('Successfully cancelled queued live migration.',
1266                          instance_uuid=migration.instance_uuid)
1267             else:
1268                 LOG.warning('Unable to cancel live migration.',
1269                             instance_uuid=migration.instance_uuid)
1270         self._waiting_live_migrations.clear()
1271 
1272     def pre_start_hook(self):
1273         """After the service is initialized, but before we fully bring
1274         the service up by listening on RPC queues, make sure to update
1275         our available resources (and indirectly our available nodes).
1276         """
1277         self.update_available_resource(nova.context.get_admin_context(),
1278                                        startup=True)
1279 
1280     def _get_power_state(self, context, instance):
1281         """Retrieve the power state for the given instance."""
1282         LOG.debug('Checking state', instance=instance)
1283         try:
1284             return self.driver.get_info(instance).state
1285         except exception.InstanceNotFound:
1286             return power_state.NOSTATE
1287 
1288     def get_console_topic(self, context):
1289         """Retrieves the console host for a project on this host.
1290 
1291         Currently this is just set in the flags for each compute host.
1292 
1293         """
1294         # TODO(mdragon): perhaps make this variable by console_type?
1295         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1296 
1297     @wrap_exception()
1298     def get_console_pool_info(self, context, console_type):
1299         return self.driver.get_console_pool_info(console_type)
1300 
1301     @wrap_exception()
1302     def refresh_instance_security_rules(self, context, instance):
1303         """Tell the virtualization driver to refresh security rules for
1304         an instance.
1305 
1306         Passes straight through to the virtualization driver.
1307 
1308         Synchronize the call because we may still be in the middle of
1309         creating the instance.
1310         """
1311         @utils.synchronized(instance.uuid)
1312         def _sync_refresh():
1313             try:
1314                 return self.driver.refresh_instance_security_rules(instance)
1315             except NotImplementedError:
1316                 LOG.debug('Hypervisor driver does not support '
1317                           'security groups.', instance=instance)
1318 
1319         return _sync_refresh()
1320 
1321     def _await_block_device_map_created(self, context, vol_id):
1322         # TODO(yamahata): creating volume simultaneously
1323         #                 reduces creation time?
1324         # TODO(yamahata): eliminate dumb polling
1325         start = time.time()
1326         retries = CONF.block_device_allocate_retries
1327         # (1) if the configured value is 0, one attempt should be made
1328         # (2) if the configured value is > 0, then the total number attempts
1329         #      is (retries + 1)
1330         attempts = 1
1331         if retries >= 1:
1332             attempts = retries + 1
1333         for attempt in range(1, attempts + 1):
1334             volume = self.volume_api.get(context, vol_id)
1335             volume_status = volume['status']
1336             if volume_status not in ['creating', 'downloading']:
1337                 if volume_status == 'available':
1338                     return attempt
1339                 LOG.warning("Volume id: %(vol_id)s finished being "
1340                             "created but its status is %(vol_status)s.",
1341                             {'vol_id': vol_id,
1342                              'vol_status': volume_status})
1343                 break
1344             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1345         raise exception.VolumeNotCreated(volume_id=vol_id,
1346                                          seconds=int(time.time() - start),
1347                                          attempts=attempt,
1348                                          volume_status=volume_status)
1349 
1350     def _decode_files(self, injected_files):
1351         """Base64 decode the list of files to inject."""
1352         if not injected_files:
1353             return []
1354 
1355         def _decode(f):
1356             path, contents = f
1357             # Py3 raises binascii.Error instead of TypeError as in Py27
1358             try:
1359                 decoded = base64.b64decode(contents)
1360                 return path, decoded
1361             except (TypeError, binascii.Error):
1362                 raise exception.Base64Exception(path=path)
1363 
1364         return [_decode(f) for f in injected_files]
1365 
1366     def _validate_instance_group_policy(self, context, instance,
1367                                         scheduler_hints, migration=None):
1368         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1369         # However, there is a race condition with the enforcement of
1370         # the policy.  Since more than one instance may be scheduled at the
1371         # same time, it's possible that more than one instance with an
1372         # anti-affinity policy may end up here.  It's also possible that
1373         # multiple instances with an affinity policy could end up on different
1374         # hosts.  This is a validation step to make sure that starting the
1375         # instance here doesn't violate the policy.
1376         group_hint = scheduler_hints.get('group')
1377         if not group_hint:
1378             return
1379 
1380         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1381         # to check the type on the value and pull the single entry out. The
1382         # API request schema validates that the 'group' hint is a single value.
1383         if isinstance(group_hint, list):
1384             group_hint = group_hint[0]
1385 
1386         @utils.synchronized(group_hint)
1387         def _do_validation(context, instance, group_hint, migration):
1388             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1389             if group.policy and 'anti-affinity' == group.policy:
1390                 instances_uuids = objects.InstanceList.get_uuids_by_host(
1391                     context, self.host)
1392                 ins_on_host = set(instances_uuids)
1393                 members = set(group.members)
1394                 # Determine the set of instance group members on this host
1395                 # which are not the instance in question. This is used to
1396                 # determine how many other members from the same anti-affinity
1397                 # group can be on this host.
1398                 # Also consider group members that are migrating to avoid
1399                 # breaking the policy of group if it is a migration action.
1400                 ins_uuids = set()
1401                 if migration:
1402                     migrations_same_host_and_node = (objects.MigrationList.
1403                         get_in_progress_by_host_and_node(
1404                             context, host=self.host,
1405                             node=migration.dest_node))
1406                     ins_uuids = set([mgs.instance_uuid
1407                                      for mgs in migrations_same_host_and_node])
1408                 members_on_host = ((ins_on_host | ins_uuids)
1409                     & members - set([instance.uuid]))
1410                 rules = group.rules
1411                 if rules and 'max_server_per_host' in rules:
1412                     max_server = rules['max_server_per_host']
1413                 else:
1414                     max_server = 1
1415                 if len(members_on_host) >= max_server:
1416                     msg = _("Anti-affinity instance group policy "
1417                             "was violated.")
1418                     raise exception.RescheduledException(
1419                             instance_uuid=instance.uuid,
1420                             reason=msg)
1421             elif group.policy and 'affinity' == group.policy:
1422                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1423                 if group_hosts and self.host not in group_hosts:
1424                     msg = _("Affinity instance group policy was violated.")
1425                     raise exception.RescheduledException(
1426                             instance_uuid=instance.uuid,
1427                             reason=msg)
1428 
1429         if not CONF.workarounds.disable_group_policy_check_upcall:
1430             _do_validation(context, instance, group_hint, migration)
1431 
1432     def _log_original_error(self, exc_info, instance_uuid):
1433         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1434                   exc_info=exc_info)
1435 
1436     @periodic_task.periodic_task
1437     def _check_instance_build_time(self, context):
1438         """Ensure that instances are not stuck in build."""
1439         timeout = CONF.instance_build_timeout
1440         if timeout == 0:
1441             return
1442 
1443         filters = {'vm_state': vm_states.BUILDING,
1444                    'host': self.host}
1445 
1446         building_insts = objects.InstanceList.get_by_filters(context,
1447                            filters, expected_attrs=[], use_slave=True)
1448 
1449         for instance in building_insts:
1450             if timeutils.is_older_than(instance.created_at, timeout):
1451                 self._set_instance_obj_error_state(context, instance)
1452                 LOG.warning("Instance build timed out. Set to error "
1453                             "state.", instance=instance)
1454 
1455     def _check_instance_exists(self, context, instance):
1456         """Ensure an instance with the same name is not already present."""
1457         if self.driver.instance_exists(instance):
1458             raise exception.InstanceExists(name=instance.name)
1459 
1460     def _allocate_network_async(self, context, instance, requested_networks,
1461                                 security_groups, is_vpn,
1462                                 resource_provider_mapping):
1463         """Method used to allocate networks in the background.
1464 
1465         Broken out for testing.
1466         """
1467         # First check to see if we're specifically not supposed to allocate
1468         # networks because if so, we can exit early.
1469         if requested_networks and requested_networks.no_allocate:
1470             LOG.debug("Not allocating networking since 'none' was specified.",
1471                       instance=instance)
1472             return network_model.NetworkInfo([])
1473 
1474         LOG.debug("Allocating IP information in the background.",
1475                   instance=instance)
1476         retries = CONF.network_allocate_retries
1477         attempts = retries + 1
1478         retry_time = 1
1479         bind_host_id = self.driver.network_binding_host_id(context, instance)
1480         for attempt in range(1, attempts + 1):
1481             try:
1482                 nwinfo = self.network_api.allocate_for_instance(
1483                         context, instance, vpn=is_vpn,
1484                         requested_networks=requested_networks,
1485                         security_groups=security_groups,
1486                         bind_host_id=bind_host_id,
1487                         resource_provider_mapping=resource_provider_mapping)
1488                 LOG.debug('Instance network_info: |%s|', nwinfo,
1489                           instance=instance)
1490                 instance.system_metadata['network_allocated'] = 'True'
1491                 # NOTE(JoshNang) do not save the instance here, as it can cause
1492                 # races. The caller shares a reference to instance and waits
1493                 # for this async greenthread to finish before calling
1494                 # instance.save().
1495                 return nwinfo
1496             except Exception:
1497                 exc_info = sys.exc_info()
1498                 log_info = {'attempt': attempt,
1499                             'attempts': attempts}
1500                 if attempt == attempts:
1501                     LOG.exception('Instance failed network setup '
1502                                   'after %(attempts)d attempt(s)',
1503                                   log_info)
1504                     six.reraise(*exc_info)
1505                 LOG.warning('Instance failed network setup '
1506                             '(attempt %(attempt)d of %(attempts)d)',
1507                             log_info, instance=instance)
1508                 time.sleep(retry_time)
1509                 retry_time *= 2
1510                 if retry_time > 30:
1511                     retry_time = 30
1512         # Not reached.
1513 
1514     def _build_networks_for_instance(self, context, instance,
1515             requested_networks, security_groups, resource_provider_mapping):
1516 
1517         # If we're here from a reschedule the network may already be allocated.
1518         if strutils.bool_from_string(
1519                 instance.system_metadata.get('network_allocated', 'False')):
1520             # NOTE(alex_xu): The network_allocated is True means the network
1521             # resource already allocated at previous scheduling, and the
1522             # network setup is cleanup at previous. After rescheduling, the
1523             # network resource need setup on the new host.
1524             self.network_api.setup_instance_network_on_host(
1525                 context, instance, instance.host)
1526             return self.network_api.get_instance_nw_info(context, instance)
1527 
1528         if not self.is_neutron_security_groups:
1529             security_groups = []
1530 
1531         network_info = self._allocate_network(context, instance,
1532                 requested_networks, security_groups,
1533                 resource_provider_mapping)
1534 
1535         return network_info
1536 
1537     def _allocate_network(self, context, instance, requested_networks,
1538                           security_groups, resource_provider_mapping):
1539         """Start network allocation asynchronously.  Return an instance
1540         of NetworkInfoAsyncWrapper that can be used to retrieve the
1541         allocated networks when the operation has finished.
1542         """
1543         # NOTE(comstud): Since we're allocating networks asynchronously,
1544         # this task state has little meaning, as we won't be in this
1545         # state for very long.
1546         instance.vm_state = vm_states.BUILDING
1547         instance.task_state = task_states.NETWORKING
1548         instance.save(expected_task_state=[None])
1549 
1550         is_vpn = False
1551         return network_model.NetworkInfoAsyncWrapper(
1552                 self._allocate_network_async, context, instance,
1553                 requested_networks, security_groups, is_vpn,
1554                 resource_provider_mapping)
1555 
1556     def _default_root_device_name(self, instance, image_meta, root_bdm):
1557         """Gets a default root device name from the driver.
1558 
1559         :param nova.objects.Instance instance:
1560             The instance for which to get the root device name.
1561         :param nova.objects.ImageMeta image_meta:
1562             The metadata of the image of the instance.
1563         :param nova.objects.BlockDeviceMapping root_bdm:
1564             The description of the root device.
1565         :returns: str -- The default root device name.
1566         :raises: InternalError, TooManyDiskDevices
1567         """
1568         try:
1569             return self.driver.default_root_device_name(instance,
1570                                                         image_meta,
1571                                                         root_bdm)
1572         except NotImplementedError:
1573             return compute_utils.get_next_device_name(instance, [])
1574 
1575     def _default_device_names_for_instance(self, instance,
1576                                            root_device_name,
1577                                            *block_device_lists):
1578         """Default the missing device names in the BDM from the driver.
1579 
1580         :param nova.objects.Instance instance:
1581             The instance for which to get default device names.
1582         :param str root_device_name: The root device name.
1583         :param list block_device_lists: List of block device mappings.
1584         :returns: None
1585         :raises: InternalError, TooManyDiskDevices
1586         """
1587         try:
1588             self.driver.default_device_names_for_instance(instance,
1589                                                           root_device_name,
1590                                                           *block_device_lists)
1591         except NotImplementedError:
1592             compute_utils.default_device_names_for_instance(
1593                 instance, root_device_name, *block_device_lists)
1594 
1595     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1596         """Get the next device name from the driver, based on the BDM.
1597 
1598         :param nova.objects.Instance instance:
1599             The instance whose volume is requesting a device name.
1600         :param nova.objects.BlockDeviceMappingList bdms:
1601             The block device mappings for the instance.
1602         :param nova.objects.BlockDeviceMapping block_device_obj:
1603             A block device mapping containing info about the requested block
1604             device.
1605         :returns: The next device name.
1606         :raises: InternalError, TooManyDiskDevices
1607         """
1608         # NOTE(ndipanov): Copy obj to avoid changing the original
1609         block_device_obj = block_device_obj.obj_clone()
1610         try:
1611             return self.driver.get_device_name_for_instance(
1612                 instance, bdms, block_device_obj)
1613         except NotImplementedError:
1614             return compute_utils.get_device_name_for_instance(
1615                 instance, bdms, block_device_obj.get("device_name"))
1616 
1617     def _default_block_device_names(self, instance, image_meta, block_devices):
1618         """Verify that all the devices have the device_name set. If not,
1619         provide a default name.
1620 
1621         It also ensures that there is a root_device_name and is set to the
1622         first block device in the boot sequence (boot_index=0).
1623         """
1624         root_bdm = block_device.get_root_bdm(block_devices)
1625         if not root_bdm:
1626             return
1627 
1628         # Get the root_device_name from the root BDM or the instance
1629         root_device_name = None
1630         update_root_bdm = False
1631 
1632         if root_bdm.device_name:
1633             root_device_name = root_bdm.device_name
1634             instance.root_device_name = root_device_name
1635         elif instance.root_device_name:
1636             root_device_name = instance.root_device_name
1637             root_bdm.device_name = root_device_name
1638             update_root_bdm = True
1639         else:
1640             root_device_name = self._default_root_device_name(instance,
1641                                                               image_meta,
1642                                                               root_bdm)
1643 
1644             instance.root_device_name = root_device_name
1645             root_bdm.device_name = root_device_name
1646             update_root_bdm = True
1647 
1648         if update_root_bdm:
1649             root_bdm.save()
1650 
1651         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1652                             block_devices))
1653         swap = list(filter(block_device.new_format_is_swap,
1654                       block_devices))
1655         block_device_mapping = list(filter(
1656               driver_block_device.is_block_device_mapping, block_devices))
1657 
1658         self._default_device_names_for_instance(instance,
1659                                                 root_device_name,
1660                                                 ephemerals,
1661                                                 swap,
1662                                                 block_device_mapping)
1663 
1664     def _block_device_info_to_legacy(self, block_device_info):
1665         """Convert BDI to the old format for drivers that need it."""
1666 
1667         if self.use_legacy_block_device_info:
1668             ephemerals = driver_block_device.legacy_block_devices(
1669                 driver.block_device_info_get_ephemerals(block_device_info))
1670             mapping = driver_block_device.legacy_block_devices(
1671                 driver.block_device_info_get_mapping(block_device_info))
1672             swap = block_device_info['swap']
1673             if swap:
1674                 swap = swap.legacy()
1675 
1676             block_device_info.update({
1677                 'ephemerals': ephemerals,
1678                 'swap': swap,
1679                 'block_device_mapping': mapping})
1680 
1681     def _add_missing_dev_names(self, bdms, instance):
1682         for bdm in bdms:
1683             if bdm.device_name is not None:
1684                 continue
1685 
1686             device_name = self._get_device_name_for_instance(instance,
1687                                                              bdms, bdm)
1688             values = {'device_name': device_name}
1689             bdm.update(values)
1690             bdm.save()
1691 
1692     def _prep_block_device(self, context, instance, bdms):
1693         """Set up the block device for an instance with error logging."""
1694         try:
1695             self._add_missing_dev_names(bdms, instance)
1696             block_device_info = driver.get_block_device_info(instance, bdms)
1697             mapping = driver.block_device_info_get_mapping(block_device_info)
1698             driver_block_device.attach_block_devices(
1699                 mapping, context, instance, self.volume_api, self.driver,
1700                 wait_func=self._await_block_device_map_created)
1701 
1702             self._block_device_info_to_legacy(block_device_info)
1703             return block_device_info
1704 
1705         except exception.OverQuota as e:
1706             LOG.warning('Failed to create block device for instance due'
1707                         ' to exceeding volume related resource quota.'
1708                         ' Error: %s', e.message, instance=instance)
1709             raise
1710 
1711         except Exception as ex:
1712             LOG.exception('Instance failed block device setup',
1713                           instance=instance)
1714             # InvalidBDM will eventually result in a BuildAbortException when
1715             # booting from volume, and will be recorded as an instance fault.
1716             # Maintain the original exception message which most likely has
1717             # useful details which the standard InvalidBDM error message lacks.
1718             raise exception.InvalidBDM(six.text_type(ex))
1719 
1720     def _update_instance_after_spawn(self, context, instance):
1721         instance.power_state = self._get_power_state(context, instance)
1722         instance.vm_state = vm_states.ACTIVE
1723         instance.task_state = None
1724         instance.launched_at = timeutils.utcnow()
1725         configdrive.update_instance(instance)
1726 
1727     def _update_scheduler_instance_info(self, context, instance):
1728         """Sends an InstanceList with created or updated Instance objects to
1729         the Scheduler client.
1730 
1731         In the case of init_host, the value passed will already be an
1732         InstanceList. Other calls will send individual Instance objects that
1733         have been created or resized. In this case, we create an InstanceList
1734         object containing that Instance.
1735         """
1736         if not self.send_instance_updates:
1737             return
1738         if isinstance(instance, obj_instance.Instance):
1739             instance = objects.InstanceList(objects=[instance])
1740         context = context.elevated()
1741         self.query_client.update_instance_info(context, self.host,
1742                                                instance)
1743 
1744     def _delete_scheduler_instance_info(self, context, instance_uuid):
1745         """Sends the uuid of the deleted Instance to the Scheduler client."""
1746         if not self.send_instance_updates:
1747             return
1748         context = context.elevated()
1749         self.query_client.delete_instance_info(context, self.host,
1750                                                instance_uuid)
1751 
1752     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1753     def _sync_scheduler_instance_info(self, context):
1754         if not self.send_instance_updates:
1755             return
1756         context = context.elevated()
1757         instances = objects.InstanceList.get_by_host(context, self.host,
1758                                                      expected_attrs=[],
1759                                                      use_slave=True)
1760         uuids = [instance.uuid for instance in instances]
1761         self.query_client.sync_instance_info(context, self.host, uuids)
1762 
1763     def _notify_about_instance_usage(self, context, instance, event_suffix,
1764                                      network_info=None, extra_usage_info=None,
1765                                      fault=None):
1766         compute_utils.notify_about_instance_usage(
1767             self.notifier, context, instance, event_suffix,
1768             network_info=network_info,
1769             extra_usage_info=extra_usage_info, fault=fault)
1770 
1771     def _deallocate_network(self, context, instance,
1772                             requested_networks=None):
1773         # If we were told not to allocate networks let's save ourselves
1774         # the trouble of calling the network API.
1775         if requested_networks and requested_networks.no_allocate:
1776             LOG.debug("Skipping network deallocation for instance since "
1777                       "networking was not requested.", instance=instance)
1778             return
1779 
1780         LOG.debug('Deallocating network for instance', instance=instance)
1781         with timeutils.StopWatch() as timer:
1782             self.network_api.deallocate_for_instance(
1783                 context, instance, requested_networks=requested_networks)
1784         # nova-network does an rpc call so we're OK tracking time spent here
1785         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1786                  timer.elapsed(), instance=instance)
1787 
1788     def _get_instance_block_device_info(self, context, instance,
1789                                         refresh_conn_info=False,
1790                                         bdms=None):
1791         """Transform block devices to the driver block_device format."""
1792 
1793         if bdms is None:
1794             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1795                     context, instance.uuid)
1796         block_device_info = driver.get_block_device_info(instance, bdms)
1797 
1798         if not refresh_conn_info:
1799             # if the block_device_mapping has no value in connection_info
1800             # (returned as None), don't include in the mapping
1801             block_device_info['block_device_mapping'] = [
1802                 bdm for bdm in driver.block_device_info_get_mapping(
1803                                     block_device_info)
1804                 if bdm.get('connection_info')]
1805         else:
1806             driver_block_device.refresh_conn_infos(
1807                 driver.block_device_info_get_mapping(block_device_info),
1808                 context, instance, self.volume_api, self.driver)
1809 
1810         self._block_device_info_to_legacy(block_device_info)
1811 
1812         return block_device_info
1813 
1814     def _build_failed(self, node):
1815         if CONF.compute.consecutive_build_service_disable_threshold:
1816             # NOTE(danms): Update our counter, but wait for the next
1817             # update_available_resource() periodic to flush it to the DB
1818             self.rt.build_failed(node)
1819 
1820     def _build_succeeded(self, node):
1821         self.rt.build_succeeded(node)
1822 
1823     @wrap_exception()
1824     @reverts_task_state
1825     @wrap_instance_fault
1826     def build_and_run_instance(self, context, instance, image, request_spec,
1827                      filter_properties, admin_password=None,
1828                      injected_files=None, requested_networks=None,
1829                      security_groups=None, block_device_mapping=None,
1830                      node=None, limits=None, host_list=None):
1831 
1832         @utils.synchronized(instance.uuid)
1833         def _locked_do_build_and_run_instance(*args, **kwargs):
1834             # NOTE(danms): We grab the semaphore with the instance uuid
1835             # locked because we could wait in line to build this instance
1836             # for a while and we want to make sure that nothing else tries
1837             # to do anything with this instance while we wait.
1838             with self._build_semaphore:
1839                 try:
1840                     result = self._do_build_and_run_instance(*args, **kwargs)
1841                 except Exception:
1842                     # NOTE(mriedem): This should really only happen if
1843                     # _decode_files in _do_build_and_run_instance fails, and
1844                     # that's before a guest is spawned so it's OK to remove
1845                     # allocations for the instance for this node from Placement
1846                     # below as there is no guest consuming resources anyway.
1847                     # The _decode_files case could be handled more specifically
1848                     # but that's left for another day.
1849                     result = build_results.FAILED
1850                     raise
1851                 finally:
1852                     if result == build_results.FAILED:
1853                         # Remove the allocation records from Placement for the
1854                         # instance if the build failed. The instance.host is
1855                         # likely set to None in _do_build_and_run_instance
1856                         # which means if the user deletes the instance, it
1857                         # will be deleted in the API, not the compute service.
1858                         # Setting the instance.host to None in
1859                         # _do_build_and_run_instance means that the
1860                         # ResourceTracker will no longer consider this instance
1861                         # to be claiming resources against it, so we want to
1862                         # reflect that same thing in Placement.  No need to
1863                         # call this for a reschedule, as the allocations will
1864                         # have already been removed in
1865                         # self._do_build_and_run_instance().
1866                         self.reportclient.delete_allocation_for_instance(
1867                             context, instance.uuid)
1868 
1869                     if result in (build_results.FAILED,
1870                                   build_results.RESCHEDULED):
1871                         self._build_failed(node)
1872                     else:
1873                         self._build_succeeded(node)
1874 
1875         # NOTE(danms): We spawn here to return the RPC worker thread back to
1876         # the pool. Since what follows could take a really long time, we don't
1877         # want to tie up RPC workers.
1878         utils.spawn_n(_locked_do_build_and_run_instance,
1879                       context, instance, image, request_spec,
1880                       filter_properties, admin_password, injected_files,
1881                       requested_networks, security_groups,
1882                       block_device_mapping, node, limits, host_list)
1883 
1884     def _check_device_tagging(self, requested_networks, block_device_mapping):
1885         tagging_requested = False
1886         if requested_networks:
1887             for net in requested_networks:
1888                 if 'tag' in net and net.tag is not None:
1889                     tagging_requested = True
1890                     break
1891         if block_device_mapping and not tagging_requested:
1892             for bdm in block_device_mapping:
1893                 if 'tag' in bdm and bdm.tag is not None:
1894                     tagging_requested = True
1895                     break
1896         if (tagging_requested and
1897                 not self.driver.capabilities.get('supports_device_tagging',
1898                                                  False)):
1899             raise exception.BuildAbortException('Attempt to boot guest with '
1900                                                 'tagged devices on host that '
1901                                                 'does not support tagging.')
1902 
1903     def _check_trusted_certs(self, instance):
1904         if (instance.trusted_certs and
1905                 not self.driver.capabilities.get('supports_trusted_certs',
1906                                                  False)):
1907             raise exception.BuildAbortException(
1908                 'Trusted image certificates provided on host that does not '
1909                 'support certificate validation.')
1910 
1911     @hooks.add_hook('build_instance')
1912     @wrap_exception()
1913     @reverts_task_state
1914     @wrap_instance_event(prefix='compute')
1915     @wrap_instance_fault
1916     def _do_build_and_run_instance(self, context, instance, image,
1917             request_spec, filter_properties, admin_password, injected_files,
1918             requested_networks, security_groups, block_device_mapping,
1919             node=None, limits=None, host_list=None):
1920 
1921         try:
1922             LOG.debug('Starting instance...', instance=instance)
1923             instance.vm_state = vm_states.BUILDING
1924             instance.task_state = None
1925             instance.save(expected_task_state=
1926                     (task_states.SCHEDULING, None))
1927         except exception.InstanceNotFound:
1928             msg = 'Instance disappeared before build.'
1929             LOG.debug(msg, instance=instance)
1930             return build_results.FAILED
1931         except exception.UnexpectedTaskStateError as e:
1932             LOG.debug(e.format_message(), instance=instance)
1933             return build_results.FAILED
1934 
1935         # b64 decode the files to inject:
1936         decoded_files = self._decode_files(injected_files)
1937 
1938         if limits is None:
1939             limits = {}
1940 
1941         if node is None:
1942             node = self._get_nodename(instance, refresh=True)
1943 
1944         try:
1945             with timeutils.StopWatch() as timer:
1946                 self._build_and_run_instance(context, instance, image,
1947                         decoded_files, admin_password, requested_networks,
1948                         security_groups, block_device_mapping, node, limits,
1949                         filter_properties, request_spec)
1950             LOG.info('Took %0.2f seconds to build instance.',
1951                      timer.elapsed(), instance=instance)
1952             return build_results.ACTIVE
1953         except exception.RescheduledException as e:
1954             retry = filter_properties.get('retry')
1955             if not retry:
1956                 # no retry information, do not reschedule.
1957                 LOG.debug("Retry info not present, will not reschedule",
1958                     instance=instance)
1959                 self._cleanup_allocated_networks(context, instance,
1960                     requested_networks)
1961                 self._cleanup_volumes(context, instance,
1962                     block_device_mapping, raise_exc=False)
1963                 compute_utils.add_instance_fault_from_exc(context,
1964                         instance, e, sys.exc_info(),
1965                         fault_message=e.kwargs['reason'])
1966                 self._nil_out_instance_obj_host_and_node(instance)
1967                 self._set_instance_obj_error_state(context, instance,
1968                                                    clean_task_state=True)
1969                 return build_results.FAILED
1970             LOG.debug(e.format_message(), instance=instance)
1971             # This will be used for logging the exception
1972             retry['exc'] = traceback.format_exception(*sys.exc_info())
1973             # This will be used for setting the instance fault message
1974             retry['exc_reason'] = e.kwargs['reason']
1975             # NOTE(comstud): Deallocate networks if the driver wants
1976             # us to do so.
1977             # NOTE(mriedem): Always deallocate networking when using Neutron.
1978             # This is to unbind any ports that the user supplied in the server
1979             # create request, or delete any ports that nova created which were
1980             # meant to be bound to this host. This check intentionally bypasses
1981             # the result of deallocate_networks_on_reschedule because the
1982             # default value in the driver is False, but that method was really
1983             # only meant for Ironic and should be removed when nova-network is
1984             # removed (since is_neutron() will then always be True).
1985             # NOTE(vladikr): SR-IOV ports should be deallocated to
1986             # allow new sriov pci devices to be allocated on a new host.
1987             # Otherwise, if devices with pci addresses are already allocated
1988             # on the destination host, the instance will fail to spawn.
1989             # info_cache.network_info should be present at this stage.
1990             if (self.driver.deallocate_networks_on_reschedule(instance) or
1991                 utils.is_neutron() or
1992                 self.deallocate_sriov_ports_on_reschedule(instance)):
1993                 self._cleanup_allocated_networks(context, instance,
1994                         requested_networks)
1995             else:
1996                 # NOTE(alex_xu): Network already allocated and we don't
1997                 # want to deallocate them before rescheduling. But we need
1998                 # to cleanup those network resources setup on this host before
1999                 # rescheduling.
2000                 self.network_api.cleanup_instance_network_on_host(
2001                     context, instance, self.host)
2002 
2003             self._nil_out_instance_obj_host_and_node(instance)
2004             instance.task_state = task_states.SCHEDULING
2005             instance.save()
2006             # The instance will have already claimed resources from this host
2007             # before this build was attempted. Now that it has failed, we need
2008             # to unclaim those resources before casting to the conductor, so
2009             # that if there are alternate hosts available for a retry, it can
2010             # claim resources on that new host for the instance.
2011             self.reportclient.delete_allocation_for_instance(context,
2012                                                              instance.uuid)
2013 
2014             self.compute_task_api.build_instances(context, [instance],
2015                     image, filter_properties, admin_password,
2016                     injected_files, requested_networks, security_groups,
2017                     block_device_mapping, request_spec=request_spec,
2018                     host_lists=[host_list])
2019             return build_results.RESCHEDULED
2020         except (exception.InstanceNotFound,
2021                 exception.UnexpectedDeletingTaskStateError):
2022             msg = 'Instance disappeared during build.'
2023             LOG.debug(msg, instance=instance)
2024             self._cleanup_allocated_networks(context, instance,
2025                     requested_networks)
2026             return build_results.FAILED
2027         except Exception as e:
2028             if isinstance(e, exception.BuildAbortException):
2029                 LOG.error(e.format_message(), instance=instance)
2030             else:
2031                 # Should not reach here.
2032                 LOG.exception('Unexpected build failure, not rescheduling '
2033                               'build.', instance=instance)
2034             self._cleanup_allocated_networks(context, instance,
2035                     requested_networks)
2036             self._cleanup_volumes(context, instance,
2037                     block_device_mapping, raise_exc=False)
2038             compute_utils.add_instance_fault_from_exc(context, instance,
2039                     e, sys.exc_info())
2040             self._nil_out_instance_obj_host_and_node(instance)
2041             self._set_instance_obj_error_state(context, instance,
2042                                                clean_task_state=True)
2043             return build_results.FAILED
2044 
2045     def deallocate_sriov_ports_on_reschedule(self, instance):
2046         """Determine if networks are needed to be deallocated before reschedule
2047 
2048         Check the cached network info for any assigned SR-IOV ports.
2049         SR-IOV ports should be deallocated prior to rescheduling
2050         in order to allow new sriov pci devices to be allocated on a new host.
2051         """
2052         info_cache = instance.info_cache
2053 
2054         def _has_sriov_port(vif):
2055             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
2056 
2057         if (info_cache and info_cache.network_info):
2058             for vif in info_cache.network_info:
2059                 if _has_sriov_port(vif):
2060                     return True
2061         return False
2062 
2063     @staticmethod
2064     def _get_scheduler_hints(filter_properties, request_spec=None):
2065         """Helper method to get scheduler hints.
2066 
2067         This method prefers to get the hints out of the request spec, but that
2068         might not be provided. Conductor will pass request_spec down to the
2069         first compute chosen for a build but older computes will not pass
2070         the request_spec to conductor's build_instances method for a
2071         a reschedule, so if we're on a host via a retry, request_spec may not
2072         be provided so we need to fallback to use the filter_properties
2073         to get scheduler hints.
2074         """
2075         hints = {}
2076         if request_spec is not None and 'scheduler_hints' in request_spec:
2077             hints = request_spec.scheduler_hints
2078         if not hints:
2079             hints = filter_properties.get('scheduler_hints') or {}
2080         return hints
2081 
2082     @staticmethod
2083     def _get_request_group_mapping(request_spec):
2084         """Return request group resource - provider mapping. This is currently
2085         used for Neutron ports that have resource request due to the port
2086         having QoS minimum bandwidth policy rule attached.
2087 
2088         :param request_spec: A RequestSpec object
2089         :returns: A dict keyed by RequestGroup requester_id, currently Neutron
2090         port_id, to resource provider UUID that provides resource for that
2091         RequestGroup.
2092         """
2093 
2094         if (request_spec
2095                 and 'requested_resources' in request_spec
2096                 and request_spec.requested_resources is not None):
2097             return {
2098                 group.requester_id: group.provider_uuids
2099                 for group in request_spec.requested_resources
2100             }
2101         else:
2102             return None
2103 
2104     def _update_pci_request_spec_with_allocated_interface_name(
2105             self, context, instance, request_group_resource_providers_mapping):
2106         if not instance.pci_requests:
2107             return
2108 
2109         def needs_update(pci_request, mapping):
2110             return (pci_request.requester_id
2111                     and pci_request.requester_id in mapping)
2112 
2113         modified = False
2114         for pci_request in instance.pci_requests.requests:
2115             if needs_update(
2116                     pci_request, request_group_resource_providers_mapping):
2117 
2118                 provider_uuids = request_group_resource_providers_mapping[
2119                     pci_request.requester_id]
2120 
2121                 if len(provider_uuids) != 1:
2122                     reason = (
2123                         'Allocating resources from more than one resource '
2124                         'providers %(providers)s for a single pci request '
2125                         '%(requester)s is not supported.' %
2126                         {'providers': provider_uuids,
2127                          'requester': pci_request.requester_id})
2128                     raise exception.BuildAbortException(
2129                         instance_uuid=instance.uuid,
2130                         reason=reason)
2131 
2132                 dev_rp_name = self.reportclient.get_resource_provider_name(
2133                     context,
2134                     provider_uuids[0])
2135 
2136                 # NOTE(gibi): the device RP name reported by neutron is
2137                 # structured like <hostname>:<agentname>:<interfacename>
2138                 rp_name_pieces = dev_rp_name.split(':')
2139                 if len(rp_name_pieces) != 3:
2140                     reason = (
2141                         'Resource provider %(provider)s used to allocate '
2142                         'resources for the pci request %(requester)s does not '
2143                         'have properly formatted name. Expected name format '
2144                         'is <hostname>:<agentname>:<interfacename>, but got '
2145                         '%(provider_name)s' %
2146                         {'provider': provider_uuids[0],
2147                          'requester': pci_request.requester_id,
2148                          'provider_name': dev_rp_name})
2149                     raise exception.BuildAbortException(
2150                         instance_uuid=instance.uuid,
2151                         reason=reason)
2152 
2153                 for spec in pci_request.spec:
2154                     spec['parent_ifname'] = rp_name_pieces[2]
2155                     modified = True
2156         if modified:
2157             instance.save()
2158 
2159     def _build_and_run_instance(self, context, instance, image, injected_files,
2160             admin_password, requested_networks, security_groups,
2161             block_device_mapping, node, limits, filter_properties,
2162             request_spec=None):
2163 
2164         image_name = image.get('name')
2165         self._notify_about_instance_usage(context, instance, 'create.start',
2166                 extra_usage_info={'image_name': image_name})
2167         compute_utils.notify_about_instance_create(
2168             context, instance, self.host,
2169             phase=fields.NotificationPhase.START,
2170             bdms=block_device_mapping)
2171 
2172         # NOTE(mikal): cache the keystone roles associated with the instance
2173         # at boot time for later reference
2174         instance.system_metadata.update(
2175             {'boot_roles': ','.join(context.roles)})
2176 
2177         self._check_device_tagging(requested_networks, block_device_mapping)
2178         self._check_trusted_certs(instance)
2179 
2180         request_group_resource_providers_mapping = \
2181             self._get_request_group_mapping(request_spec)
2182 
2183         if request_group_resource_providers_mapping:
2184             self._update_pci_request_spec_with_allocated_interface_name(
2185                 context, instance, request_group_resource_providers_mapping)
2186 
2187         try:
2188             scheduler_hints = self._get_scheduler_hints(filter_properties,
2189                                                         request_spec)
2190             with self.rt.instance_claim(context, instance, node, limits):
2191                 # NOTE(russellb) It's important that this validation be done
2192                 # *after* the resource tracker instance claim, as that is where
2193                 # the host is set on the instance.
2194                 self._validate_instance_group_policy(context, instance,
2195                                                      scheduler_hints)
2196                 image_meta = objects.ImageMeta.from_dict(image)
2197 
2198                 request_group_resource_providers_mapping = \
2199                     self._get_request_group_mapping(request_spec)
2200 
2201                 with self._build_resources(context, instance,
2202                         requested_networks, security_groups, image_meta,
2203                         block_device_mapping,
2204                         request_group_resource_providers_mapping) as resources:
2205                     instance.vm_state = vm_states.BUILDING
2206                     instance.task_state = task_states.SPAWNING
2207                     # NOTE(JoshNang) This also saves the changes to the
2208                     # instance from _allocate_network_async, as they aren't
2209                     # saved in that function to prevent races.
2210                     instance.save(expected_task_state=
2211                             task_states.BLOCK_DEVICE_MAPPING)
2212                     block_device_info = resources['block_device_info']
2213                     network_info = resources['network_info']
2214                     allocs = resources['allocations']
2215                     LOG.debug('Start spawning the instance on the hypervisor.',
2216                               instance=instance)
2217                     with timeutils.StopWatch() as timer:
2218                         self.driver.spawn(context, instance, image_meta,
2219                                           injected_files, admin_password,
2220                                           allocs, network_info=network_info,
2221                                           block_device_info=block_device_info)
2222                     LOG.info('Took %0.2f seconds to spawn the instance on '
2223                              'the hypervisor.', timer.elapsed(),
2224                              instance=instance)
2225         except (exception.InstanceNotFound,
2226                 exception.UnexpectedDeletingTaskStateError) as e:
2227             with excutils.save_and_reraise_exception():
2228                 self._notify_about_instance_usage(context, instance,
2229                     'create.error', fault=e)
2230                 tb = traceback.format_exc()
2231                 compute_utils.notify_about_instance_create(
2232                     context, instance, self.host,
2233                     phase=fields.NotificationPhase.ERROR, exception=e,
2234                     bdms=block_device_mapping, tb=tb)
2235         except exception.ComputeResourcesUnavailable as e:
2236             LOG.debug(e.format_message(), instance=instance)
2237             self._notify_about_instance_usage(context, instance,
2238                     'create.error', fault=e)
2239             tb = traceback.format_exc()
2240             compute_utils.notify_about_instance_create(
2241                     context, instance, self.host,
2242                     phase=fields.NotificationPhase.ERROR, exception=e,
2243                     bdms=block_device_mapping, tb=tb)
2244             raise exception.RescheduledException(
2245                     instance_uuid=instance.uuid, reason=e.format_message())
2246         except exception.BuildAbortException as e:
2247             with excutils.save_and_reraise_exception():
2248                 LOG.debug(e.format_message(), instance=instance)
2249                 self._notify_about_instance_usage(context, instance,
2250                     'create.error', fault=e)
2251                 tb = traceback.format_exc()
2252                 compute_utils.notify_about_instance_create(
2253                     context, instance, self.host,
2254                     phase=fields.NotificationPhase.ERROR, exception=e,
2255                     bdms=block_device_mapping, tb=tb)
2256         except (exception.FixedIpLimitExceeded,
2257                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2258             LOG.warning('No more network or fixed IP to be allocated',
2259                         instance=instance)
2260             self._notify_about_instance_usage(context, instance,
2261                     'create.error', fault=e)
2262             tb = traceback.format_exc()
2263             compute_utils.notify_about_instance_create(
2264                     context, instance, self.host,
2265                     phase=fields.NotificationPhase.ERROR, exception=e,
2266                     bdms=block_device_mapping, tb=tb)
2267             msg = _('Failed to allocate the network(s) with error %s, '
2268                     'not rescheduling.') % e.format_message()
2269             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2270                     reason=msg)
2271         except (exception.VirtualInterfaceCreateException,
2272                 exception.VirtualInterfaceMacAddressException,
2273                 exception.FixedIpInvalidOnHost,
2274                 exception.UnableToAutoAllocateNetwork,
2275                 exception.NetworksWithQoSPolicyNotSupported) as e:
2276             LOG.exception('Failed to allocate network(s)',
2277                           instance=instance)
2278             self._notify_about_instance_usage(context, instance,
2279                     'create.error', fault=e)
2280             tb = traceback.format_exc()
2281             compute_utils.notify_about_instance_create(
2282                     context, instance, self.host,
2283                     phase=fields.NotificationPhase.ERROR, exception=e,
2284                     bdms=block_device_mapping, tb=tb)
2285             msg = _('Failed to allocate the network(s), not rescheduling.')
2286             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2287                     reason=msg)
2288         except (exception.FlavorDiskTooSmall,
2289                 exception.FlavorMemoryTooSmall,
2290                 exception.ImageNotActive,
2291                 exception.ImageUnacceptable,
2292                 exception.InvalidDiskInfo,
2293                 exception.InvalidDiskFormat,
2294                 cursive_exception.SignatureVerificationError,
2295                 exception.CertificateValidationFailed,
2296                 exception.VolumeEncryptionNotSupported,
2297                 exception.InvalidInput,
2298                 # TODO(mriedem): We should be validating RequestedVRamTooHigh
2299                 # in the API during server create and rebuild.
2300                 exception.RequestedVRamTooHigh) as e:
2301             self._notify_about_instance_usage(context, instance,
2302                     'create.error', fault=e)
2303             tb = traceback.format_exc()
2304             compute_utils.notify_about_instance_create(
2305                     context, instance, self.host,
2306                     phase=fields.NotificationPhase.ERROR, exception=e,
2307                     bdms=block_device_mapping, tb=tb)
2308             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2309                     reason=e.format_message())
2310         except Exception as e:
2311             self._notify_about_instance_usage(context, instance,
2312                     'create.error', fault=e)
2313             tb = traceback.format_exc()
2314             compute_utils.notify_about_instance_create(
2315                     context, instance, self.host,
2316                     phase=fields.NotificationPhase.ERROR, exception=e,
2317                     bdms=block_device_mapping, tb=tb)
2318             raise exception.RescheduledException(
2319                     instance_uuid=instance.uuid, reason=six.text_type(e))
2320 
2321         # NOTE(alaski): This is only useful during reschedules, remove it now.
2322         instance.system_metadata.pop('network_allocated', None)
2323 
2324         # If CONF.default_access_ip_network_name is set, grab the
2325         # corresponding network and set the access ip values accordingly.
2326         network_name = CONF.default_access_ip_network_name
2327         if (network_name and not instance.access_ip_v4 and
2328                 not instance.access_ip_v6):
2329             # Note that when there are multiple ips to choose from, an
2330             # arbitrary one will be chosen.
2331             for vif in network_info:
2332                 if vif['network']['label'] == network_name:
2333                     for ip in vif.fixed_ips():
2334                         if not instance.access_ip_v4 and ip['version'] == 4:
2335                             instance.access_ip_v4 = ip['address']
2336                         if not instance.access_ip_v6 and ip['version'] == 6:
2337                             instance.access_ip_v6 = ip['address']
2338                     break
2339 
2340         self._update_instance_after_spawn(context, instance)
2341 
2342         try:
2343             instance.save(expected_task_state=task_states.SPAWNING)
2344         except (exception.InstanceNotFound,
2345                 exception.UnexpectedDeletingTaskStateError) as e:
2346             with excutils.save_and_reraise_exception():
2347                 self._notify_about_instance_usage(context, instance,
2348                     'create.error', fault=e)
2349                 tb = traceback.format_exc()
2350                 compute_utils.notify_about_instance_create(
2351                     context, instance, self.host,
2352                     phase=fields.NotificationPhase.ERROR, exception=e,
2353                     bdms=block_device_mapping, tb=tb)
2354 
2355         self._update_scheduler_instance_info(context, instance)
2356         self._notify_about_instance_usage(context, instance, 'create.end',
2357                 extra_usage_info={'message': _('Success')},
2358                 network_info=network_info)
2359         compute_utils.notify_about_instance_create(context, instance,
2360                 self.host, phase=fields.NotificationPhase.END,
2361                 bdms=block_device_mapping)
2362 
2363     @contextlib.contextmanager
2364     def _build_resources(self, context, instance, requested_networks,
2365                          security_groups, image_meta, block_device_mapping,
2366                          resource_provider_mapping):
2367         resources = {}
2368         network_info = None
2369         try:
2370             LOG.debug('Start building networks asynchronously for instance.',
2371                       instance=instance)
2372             network_info = self._build_networks_for_instance(context, instance,
2373                     requested_networks, security_groups,
2374                     resource_provider_mapping)
2375             resources['network_info'] = network_info
2376         except (exception.InstanceNotFound,
2377                 exception.UnexpectedDeletingTaskStateError):
2378             raise
2379         except exception.UnexpectedTaskStateError as e:
2380             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2381                     reason=e.format_message())
2382         except Exception:
2383             # Because this allocation is async any failures are likely to occur
2384             # when the driver accesses network_info during spawn().
2385             LOG.exception('Failed to allocate network(s)',
2386                           instance=instance)
2387             msg = _('Failed to allocate the network(s), not rescheduling.')
2388             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2389                     reason=msg)
2390 
2391         try:
2392             # Perform any driver preparation work for the driver.
2393             self.driver.prepare_for_spawn(instance)
2394 
2395             # Depending on a virt driver, some network configuration is
2396             # necessary before preparing block devices.
2397             self.driver.prepare_networks_before_block_device_mapping(
2398                 instance, network_info)
2399 
2400             # Verify that all the BDMs have a device_name set and assign a
2401             # default to the ones missing it with the help of the driver.
2402             self._default_block_device_names(instance, image_meta,
2403                                              block_device_mapping)
2404 
2405             LOG.debug('Start building block device mappings for instance.',
2406                       instance=instance)
2407             instance.vm_state = vm_states.BUILDING
2408             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2409             instance.save()
2410 
2411             block_device_info = self._prep_block_device(context, instance,
2412                     block_device_mapping)
2413             resources['block_device_info'] = block_device_info
2414         except (exception.InstanceNotFound,
2415                 exception.UnexpectedDeletingTaskStateError):
2416             with excutils.save_and_reraise_exception():
2417                 # Make sure the async call finishes
2418                 if network_info is not None:
2419                     network_info.wait(do_raise=False)
2420                     self.driver.clean_networks_preparation(instance,
2421                                                            network_info)
2422                 self.driver.failed_spawn_cleanup(instance)
2423         except (exception.UnexpectedTaskStateError,
2424                 exception.OverQuota, exception.InvalidBDM) as e:
2425             # Make sure the async call finishes
2426             if network_info is not None:
2427                 network_info.wait(do_raise=False)
2428                 self.driver.clean_networks_preparation(instance, network_info)
2429             self.driver.failed_spawn_cleanup(instance)
2430             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2431                     reason=e.format_message())
2432         except Exception:
2433             LOG.exception('Failure prepping block device',
2434                           instance=instance)
2435             # Make sure the async call finishes
2436             if network_info is not None:
2437                 network_info.wait(do_raise=False)
2438                 self.driver.clean_networks_preparation(instance, network_info)
2439             self.driver.failed_spawn_cleanup(instance)
2440             msg = _('Failure prepping block device.')
2441             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2442                     reason=msg)
2443 
2444         try:
2445             resources['allocations'] = (
2446                 self.reportclient.get_allocations_for_consumer(context,
2447                                                                instance.uuid))
2448         except Exception:
2449             LOG.exception('Failure retrieving placement allocations',
2450                           instance=instance)
2451             # Make sure the async call finishes
2452             if network_info is not None:
2453                 network_info.wait(do_raise=False)
2454             self.driver.failed_spawn_cleanup(instance)
2455             msg = _('Failure retrieving placement allocations')
2456             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2457                                                 reason=msg)
2458 
2459         try:
2460             yield resources
2461         except Exception as exc:
2462             with excutils.save_and_reraise_exception() as ctxt:
2463                 if not isinstance(exc, (
2464                         exception.InstanceNotFound,
2465                         exception.UnexpectedDeletingTaskStateError)):
2466                     LOG.exception('Instance failed to spawn',
2467                                   instance=instance)
2468                 # Make sure the async call finishes
2469                 if network_info is not None:
2470                     network_info.wait(do_raise=False)
2471                 # if network_info is empty we're likely here because of
2472                 # network allocation failure. Since nothing can be reused on
2473                 # rescheduling it's better to deallocate network to eliminate
2474                 # the chance of orphaned ports in neutron
2475                 deallocate_networks = False if network_info else True
2476                 try:
2477                     self._shutdown_instance(context, instance,
2478                             block_device_mapping, requested_networks,
2479                             try_deallocate_networks=deallocate_networks)
2480                 except Exception as exc2:
2481                     ctxt.reraise = False
2482                     LOG.warning('Could not clean up failed build,'
2483                                 ' not rescheduling. Error: %s',
2484                                 six.text_type(exc2))
2485                     raise exception.BuildAbortException(
2486                             instance_uuid=instance.uuid,
2487                             reason=six.text_type(exc))
2488 
2489     def _cleanup_allocated_networks(self, context, instance,
2490             requested_networks):
2491         try:
2492             self._deallocate_network(context, instance, requested_networks)
2493         except Exception:
2494             LOG.exception('Failed to deallocate networks', instance=instance)
2495             return
2496 
2497         instance.system_metadata['network_allocated'] = 'False'
2498         try:
2499             instance.save()
2500         except exception.InstanceNotFound:
2501             # NOTE(alaski): It's possible that we're cleaning up the networks
2502             # because the instance was deleted.  If that's the case then this
2503             # exception will be raised by instance.save()
2504             pass
2505 
2506     def _try_deallocate_network(self, context, instance,
2507                                 requested_networks=None):
2508 
2509         # During auto-scale cleanup, we could be deleting a large number
2510         # of servers at the same time and overloading parts of the system,
2511         # so we retry a few times in case of connection failures to the
2512         # networking service.
2513         @loopingcall.RetryDecorator(
2514             max_retry_count=3, inc_sleep_time=2, max_sleep_time=12,
2515             exceptions=(keystone_exception.connection.ConnectFailure,))
2516         def _deallocate_network_with_retries():
2517             try:
2518                 self._deallocate_network(
2519                     context, instance, requested_networks)
2520             except keystone_exception.connection.ConnectFailure as e:
2521                 # Provide a warning that something is amiss.
2522                 with excutils.save_and_reraise_exception():
2523                     LOG.warning('Failed to deallocate network for instance; '
2524                                 'retrying. Error: %s', six.text_type(e),
2525                                 instance=instance)
2526 
2527         try:
2528             # tear down allocated network structure
2529             _deallocate_network_with_retries()
2530         except Exception as ex:
2531             with excutils.save_and_reraise_exception():
2532                 LOG.error('Failed to deallocate network for instance. '
2533                           'Error: %s', ex, instance=instance)
2534                 self._set_instance_obj_error_state(context, instance)
2535 
2536     def _get_power_off_values(self, context, instance, clean_shutdown):
2537         """Get the timing configuration for powering down this instance."""
2538         if clean_shutdown:
2539             timeout = compute_utils.get_value_from_system_metadata(instance,
2540                           key='image_os_shutdown_timeout', type=int,
2541                           default=CONF.shutdown_timeout)
2542             retry_interval = CONF.compute.shutdown_retry_interval
2543         else:
2544             timeout = 0
2545             retry_interval = 0
2546 
2547         return timeout, retry_interval
2548 
2549     def _power_off_instance(self, context, instance, clean_shutdown=True):
2550         """Power off an instance on this host."""
2551         timeout, retry_interval = self._get_power_off_values(context,
2552                                         instance, clean_shutdown)
2553         self.driver.power_off(instance, timeout, retry_interval)
2554 
2555     def _shutdown_instance(self, context, instance,
2556                            bdms, requested_networks=None, notify=True,
2557                            try_deallocate_networks=True):
2558         """Shutdown an instance on this host.
2559 
2560         :param:context: security context
2561         :param:instance: a nova.objects.Instance object
2562         :param:bdms: the block devices for the instance to be torn
2563                      down
2564         :param:requested_networks: the networks on which the instance
2565                                    has ports
2566         :param:notify: true if a final usage notification should be
2567                        emitted
2568         :param:try_deallocate_networks: false if we should avoid
2569                                         trying to teardown networking
2570         """
2571         context = context.elevated()
2572         LOG.info('Terminating instance', instance=instance)
2573 
2574         if notify:
2575             self._notify_about_instance_usage(context, instance,
2576                                               "shutdown.start")
2577             compute_utils.notify_about_instance_action(context, instance,
2578                     self.host, action=fields.NotificationAction.SHUTDOWN,
2579                     phase=fields.NotificationPhase.START, bdms=bdms)
2580 
2581         network_info = instance.get_network_info()
2582 
2583         # NOTE(arnaudmorin) to avoid nova destroying the instance without
2584         # unplugging the interface, refresh network_info if it is empty.
2585         if not network_info:
2586             network_info = self.network_api.get_instance_nw_info(
2587                 context, instance)
2588 
2589         # NOTE(vish) get bdms before destroying the instance
2590         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2591         block_device_info = self._get_instance_block_device_info(
2592             context, instance, bdms=bdms)
2593 
2594         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2595         #                want to keep ip allocated for certain failures
2596         try:
2597             LOG.debug('Start destroying the instance on the hypervisor.',
2598                       instance=instance)
2599             with timeutils.StopWatch() as timer:
2600                 self.driver.destroy(context, instance, network_info,
2601                                     block_device_info)
2602             LOG.info('Took %0.2f seconds to destroy the instance on the '
2603                      'hypervisor.', timer.elapsed(), instance=instance)
2604         except exception.InstancePowerOffFailure:
2605             # if the instance can't power off, don't release the ip
2606             with excutils.save_and_reraise_exception():
2607                 pass
2608         except Exception:
2609             with excutils.save_and_reraise_exception():
2610                 # deallocate ip and fail without proceeding to
2611                 # volume api calls, preserving current behavior
2612                 if try_deallocate_networks:
2613                     self._try_deallocate_network(context, instance,
2614                                                  requested_networks)
2615 
2616         if try_deallocate_networks:
2617             self._try_deallocate_network(context, instance, requested_networks)
2618 
2619         timer.restart()
2620         for bdm in vol_bdms:
2621             try:
2622                 if bdm.attachment_id:
2623                     self.volume_api.attachment_delete(context,
2624                                                       bdm.attachment_id)
2625                 else:
2626                     # NOTE(vish): actual driver detach done in driver.destroy,
2627                     #             so just tell cinder that we are done with it.
2628                     connector = self.driver.get_volume_connector(instance)
2629                     self.volume_api.terminate_connection(context,
2630                                                          bdm.volume_id,
2631                                                          connector)
2632                     self.volume_api.detach(context, bdm.volume_id,
2633                                            instance.uuid)
2634 
2635             except exception.VolumeAttachmentNotFound as exc:
2636                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2637                           instance=instance)
2638             except exception.DiskNotFound as exc:
2639                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2640                           instance=instance)
2641             except exception.VolumeNotFound as exc:
2642                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2643                           instance=instance)
2644             except (cinder_exception.EndpointNotFound,
2645                     keystone_exception.EndpointNotFound) as exc:
2646                 LOG.warning('Ignoring EndpointNotFound for '
2647                             'volume %(volume_id)s: %(exc)s',
2648                             {'exc': exc, 'volume_id': bdm.volume_id},
2649                             instance=instance)
2650             except cinder_exception.ClientException as exc:
2651                 LOG.warning('Ignoring unknown cinder exception for '
2652                             'volume %(volume_id)s: %(exc)s',
2653                             {'exc': exc, 'volume_id': bdm.volume_id},
2654                             instance=instance)
2655             except Exception as exc:
2656                 LOG.warning('Ignoring unknown exception for '
2657                             'volume %(volume_id)s: %(exc)s',
2658                             {'exc': exc, 'volume_id': bdm.volume_id},
2659                             instance=instance)
2660         if vol_bdms:
2661             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2662                      'for instance.',
2663                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2664                      instance=instance)
2665 
2666         if notify:
2667             self._notify_about_instance_usage(context, instance,
2668                                               "shutdown.end")
2669             compute_utils.notify_about_instance_action(context, instance,
2670                     self.host, action=fields.NotificationAction.SHUTDOWN,
2671                     phase=fields.NotificationPhase.END, bdms=bdms)
2672 
2673     def _cleanup_volumes(self, context, instance, bdms, raise_exc=True,
2674                          detach=True):
2675         exc_info = None
2676         for bdm in bdms:
2677             if detach and bdm.volume_id:
2678                 try:
2679                     LOG.debug("Detaching volume: %s", bdm.volume_id,
2680                               instance_uuid=instance.uuid)
2681                     destroy = bdm.delete_on_termination
2682                     self._detach_volume(context, bdm, instance,
2683                                         destroy_bdm=destroy)
2684                 except Exception as exc:
2685                     exc_info = sys.exc_info()
2686                     LOG.warning('Failed to detach volume: %(volume_id)s '
2687                                 'due to %(exc)s',
2688                                 {'volume_id': bdm.volume_id, 'exc': exc})
2689 
2690             if bdm.volume_id and bdm.delete_on_termination:
2691                 try:
2692                     LOG.debug("Deleting volume: %s", bdm.volume_id,
2693                               instance_uuid=instance.uuid)
2694                     self.volume_api.delete(context, bdm.volume_id)
2695                 except Exception as exc:
2696                     exc_info = sys.exc_info()
2697                     LOG.warning('Failed to delete volume: %(volume_id)s '
2698                                 'due to %(exc)s',
2699                                 {'volume_id': bdm.volume_id, 'exc': exc})
2700         if exc_info is not None and raise_exc:
2701             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2702 
2703     @hooks.add_hook("delete_instance")
2704     def _delete_instance(self, context, instance, bdms):
2705         """Delete an instance on this host.
2706 
2707         :param context: nova request context
2708         :param instance: nova.objects.instance.Instance object
2709         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2710         """
2711         events = self.instance_events.clear_events_for_instance(instance)
2712         if events:
2713             LOG.debug('Events pending at deletion: %(events)s',
2714                       {'events': ','.join(events.keys())},
2715                       instance=instance)
2716         self._notify_about_instance_usage(context, instance,
2717                                           "delete.start")
2718         compute_utils.notify_about_instance_action(context, instance,
2719                 self.host, action=fields.NotificationAction.DELETE,
2720                 phase=fields.NotificationPhase.START, bdms=bdms)
2721 
2722         self._shutdown_instance(context, instance, bdms)
2723 
2724         # NOTE(vish): We have already deleted the instance, so we have
2725         #             to ignore problems cleaning up the volumes. It
2726         #             would be nice to let the user know somehow that
2727         #             the volume deletion failed, but it is not
2728         #             acceptable to have an instance that can not be
2729         #             deleted. Perhaps this could be reworked in the
2730         #             future to set an instance fault the first time
2731         #             and to only ignore the failure if the instance
2732         #             is already in ERROR.
2733 
2734         # NOTE(ameeda): The volumes already detached during the above
2735         #               _shutdown_instance() call and this is why
2736         #               detach is not requested from _cleanup_volumes()
2737         #               in this case
2738 
2739         self._cleanup_volumes(context, instance, bdms,
2740                 raise_exc=False, detach=False)
2741         # if a delete task succeeded, always update vm state and task
2742         # state without expecting task state to be DELETING
2743         instance.vm_state = vm_states.DELETED
2744         instance.task_state = None
2745         instance.power_state = power_state.NOSTATE
2746         instance.terminated_at = timeutils.utcnow()
2747         instance.save()
2748 
2749         self._complete_deletion(context, instance)
2750         # only destroy the instance in the db if the _complete_deletion
2751         # doesn't raise and therefore allocation is successfully
2752         # deleted in placement
2753         instance.destroy()
2754 
2755         self._notify_about_instance_usage(context, instance, "delete.end")
2756         compute_utils.notify_about_instance_action(context, instance,
2757                 self.host, action=fields.NotificationAction.DELETE,
2758                 phase=fields.NotificationPhase.END, bdms=bdms)
2759 
2760     @wrap_exception()
2761     @reverts_task_state
2762     @wrap_instance_event(prefix='compute')
2763     @wrap_instance_fault
2764     def terminate_instance(self, context, instance, bdms):
2765         """Terminate an instance on this host."""
2766         @utils.synchronized(instance.uuid)
2767         def do_terminate_instance(instance, bdms):
2768             # NOTE(mriedem): If we are deleting the instance while it was
2769             # booting from volume, we could be racing with a database update of
2770             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2771             # to compute here, the BDMs may be stale at this point. So check
2772             # for any volume BDMs that don't have volume_id set and if we
2773             # detect that, we need to refresh the BDM list before proceeding.
2774             # TODO(mriedem): Move this into _delete_instance and make the bdms
2775             # parameter optional.
2776             for bdm in list(bdms):
2777                 if bdm.is_volume and not bdm.volume_id:
2778                     LOG.debug('There are potentially stale BDMs during '
2779                               'delete, refreshing the BlockDeviceMappingList.',
2780                               instance=instance)
2781                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2782                         context, instance.uuid)
2783                     break
2784             try:
2785                 self._delete_instance(context, instance, bdms)
2786             except exception.InstanceNotFound:
2787                 LOG.info("Instance disappeared during terminate",
2788                          instance=instance)
2789             except Exception:
2790                 # As we're trying to delete always go to Error if something
2791                 # goes wrong that _delete_instance can't handle.
2792                 with excutils.save_and_reraise_exception():
2793                     LOG.exception('Setting instance vm_state to ERROR',
2794                                   instance=instance)
2795                     self._set_instance_obj_error_state(context, instance)
2796 
2797         do_terminate_instance(instance, bdms)
2798 
2799     # NOTE(johannes): This is probably better named power_off_instance
2800     # so it matches the driver method, but because of other issues, we
2801     # can't use that name in grizzly.
2802     @wrap_exception()
2803     @reverts_task_state
2804     @wrap_instance_event(prefix='compute')
2805     @wrap_instance_fault
2806     def stop_instance(self, context, instance, clean_shutdown):
2807         """Stopping an instance on this host."""
2808 
2809         @utils.synchronized(instance.uuid)
2810         def do_stop_instance():
2811             current_power_state = self._get_power_state(context, instance)
2812             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2813                       'current task_state: %(task_state)s, current DB '
2814                       'power_state: %(db_power_state)s, current VM '
2815                       'power_state: %(current_power_state)s',
2816                       {'vm_state': instance.vm_state,
2817                        'task_state': instance.task_state,
2818                        'db_power_state': instance.power_state,
2819                        'current_power_state': current_power_state},
2820                       instance_uuid=instance.uuid)
2821 
2822             # NOTE(mriedem): If the instance is already powered off, we are
2823             # possibly tearing down and racing with other operations, so we can
2824             # expect the task_state to be None if something else updates the
2825             # instance and we're not locking it.
2826             expected_task_state = [task_states.POWERING_OFF]
2827             # The list of power states is from _sync_instance_power_state.
2828             if current_power_state in (power_state.NOSTATE,
2829                                        power_state.SHUTDOWN,
2830                                        power_state.CRASHED):
2831                 LOG.info('Instance is already powered off in the '
2832                          'hypervisor when stop is called.',
2833                          instance=instance)
2834                 expected_task_state.append(None)
2835 
2836             self._notify_about_instance_usage(context, instance,
2837                                               "power_off.start")
2838 
2839             compute_utils.notify_about_instance_action(context, instance,
2840                         self.host, action=fields.NotificationAction.POWER_OFF,
2841                         phase=fields.NotificationPhase.START)
2842 
2843             self._power_off_instance(context, instance, clean_shutdown)
2844             instance.power_state = self._get_power_state(context, instance)
2845             instance.vm_state = vm_states.STOPPED
2846             instance.task_state = None
2847             instance.save(expected_task_state=expected_task_state)
2848             self._notify_about_instance_usage(context, instance,
2849                                               "power_off.end")
2850 
2851             compute_utils.notify_about_instance_action(context, instance,
2852                         self.host, action=fields.NotificationAction.POWER_OFF,
2853                         phase=fields.NotificationPhase.END)
2854 
2855         do_stop_instance()
2856 
2857     def _power_on(self, context, instance):
2858         network_info = self.network_api.get_instance_nw_info(context, instance)
2859         block_device_info = self._get_instance_block_device_info(context,
2860                                                                  instance)
2861         self.driver.power_on(context, instance,
2862                              network_info,
2863                              block_device_info)
2864 
2865     def _delete_snapshot_of_shelved_instance(self, context, instance,
2866                                              snapshot_id):
2867         """Delete snapshot of shelved instance."""
2868         try:
2869             self.image_api.delete(context, snapshot_id)
2870         except (exception.ImageNotFound,
2871                 exception.ImageNotAuthorized) as exc:
2872             LOG.warning("Failed to delete snapshot "
2873                         "from shelved instance (%s).",
2874                         exc.format_message(), instance=instance)
2875         except Exception:
2876             LOG.exception("Something wrong happened when trying to "
2877                           "delete snapshot from shelved instance.",
2878                           instance=instance)
2879 
2880     # NOTE(johannes): This is probably better named power_on_instance
2881     # so it matches the driver method, but because of other issues, we
2882     # can't use that name in grizzly.
2883     @wrap_exception()
2884     @reverts_task_state
2885     @wrap_instance_event(prefix='compute')
2886     @wrap_instance_fault
2887     def start_instance(self, context, instance):
2888         """Starting an instance on this host."""
2889         self._notify_about_instance_usage(context, instance, "power_on.start")
2890         compute_utils.notify_about_instance_action(context, instance,
2891             self.host, action=fields.NotificationAction.POWER_ON,
2892             phase=fields.NotificationPhase.START)
2893         self._power_on(context, instance)
2894         instance.power_state = self._get_power_state(context, instance)
2895         instance.vm_state = vm_states.ACTIVE
2896         instance.task_state = None
2897 
2898         # Delete an image(VM snapshot) for a shelved instance
2899         snapshot_id = instance.system_metadata.get('shelved_image_id')
2900         if snapshot_id:
2901             self._delete_snapshot_of_shelved_instance(context, instance,
2902                                                       snapshot_id)
2903 
2904         # Delete system_metadata for a shelved instance
2905         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2906 
2907         instance.save(expected_task_state=task_states.POWERING_ON)
2908         self._notify_about_instance_usage(context, instance, "power_on.end")
2909         compute_utils.notify_about_instance_action(context, instance,
2910             self.host, action=fields.NotificationAction.POWER_ON,
2911             phase=fields.NotificationPhase.END)
2912 
2913     @messaging.expected_exceptions(NotImplementedError,
2914                                    exception.TriggerCrashDumpNotSupported,
2915                                    exception.InstanceNotRunning)
2916     @wrap_exception()
2917     @wrap_instance_event(prefix='compute')
2918     @wrap_instance_fault
2919     def trigger_crash_dump(self, context, instance):
2920         """Trigger crash dump in an instance."""
2921 
2922         self._notify_about_instance_usage(context, instance,
2923                                           "trigger_crash_dump.start")
2924         compute_utils.notify_about_instance_action(context, instance,
2925                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2926                 phase=fields.NotificationPhase.START)
2927 
2928         # This method does not change task_state and power_state because the
2929         # effect of a trigger depends on user's configuration.
2930         self.driver.trigger_crash_dump(instance)
2931 
2932         self._notify_about_instance_usage(context, instance,
2933                                           "trigger_crash_dump.end")
2934         compute_utils.notify_about_instance_action(context, instance,
2935                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2936                 phase=fields.NotificationPhase.END)
2937 
2938     @wrap_exception()
2939     @reverts_task_state
2940     @wrap_instance_event(prefix='compute')
2941     @wrap_instance_fault
2942     def soft_delete_instance(self, context, instance):
2943         """Soft delete an instance on this host."""
2944         with compute_utils.notify_about_instance_delete(
2945                 self.notifier, context, instance, 'soft_delete',
2946                 source=fields.NotificationSource.COMPUTE):
2947             try:
2948                 self.driver.soft_delete(instance)
2949             except NotImplementedError:
2950                 # Fallback to just powering off the instance if the
2951                 # hypervisor doesn't implement the soft_delete method
2952                 self.driver.power_off(instance)
2953             instance.power_state = self._get_power_state(context, instance)
2954             instance.vm_state = vm_states.SOFT_DELETED
2955             instance.task_state = None
2956             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2957 
2958     @wrap_exception()
2959     @reverts_task_state
2960     @wrap_instance_event(prefix='compute')
2961     @wrap_instance_fault
2962     def restore_instance(self, context, instance):
2963         """Restore a soft-deleted instance on this host."""
2964         self._notify_about_instance_usage(context, instance, "restore.start")
2965         compute_utils.notify_about_instance_action(context, instance,
2966             self.host, action=fields.NotificationAction.RESTORE,
2967             phase=fields.NotificationPhase.START)
2968         try:
2969             self.driver.restore(instance)
2970         except NotImplementedError:
2971             # Fallback to just powering on the instance if the hypervisor
2972             # doesn't implement the restore method
2973             self._power_on(context, instance)
2974         instance.power_state = self._get_power_state(context, instance)
2975         instance.vm_state = vm_states.ACTIVE
2976         instance.task_state = None
2977         instance.save(expected_task_state=task_states.RESTORING)
2978         self._notify_about_instance_usage(context, instance, "restore.end")
2979         compute_utils.notify_about_instance_action(context, instance,
2980             self.host, action=fields.NotificationAction.RESTORE,
2981             phase=fields.NotificationPhase.END)
2982 
2983     @staticmethod
2984     def _set_migration_status(migration, status):
2985         """Set the status, and guard against a None being passed in.
2986 
2987         This is useful as some of the compute RPC calls will not pass
2988         a migration object in older versions. The check can be removed when
2989         we move past 4.x major version of the RPC API.
2990         """
2991         if migration:
2992             migration.status = status
2993             migration.save()
2994 
2995     def _rebuild_default_impl(self, context, instance, image_meta,
2996                               injected_files, admin_password, allocations,
2997                               bdms, detach_block_devices, attach_block_devices,
2998                               network_info=None,
2999                               evacuate=False, block_device_info=None,
3000                               preserve_ephemeral=False):
3001         if preserve_ephemeral:
3002             # The default code path does not support preserving ephemeral
3003             # partitions.
3004             raise exception.PreserveEphemeralNotSupported()
3005 
3006         if evacuate:
3007             detach_block_devices(context, bdms)
3008         else:
3009             self._power_off_instance(context, instance, clean_shutdown=True)
3010             detach_block_devices(context, bdms)
3011             self.driver.destroy(context, instance,
3012                                 network_info=network_info,
3013                                 block_device_info=block_device_info)
3014 
3015         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
3016         instance.save(expected_task_state=[task_states.REBUILDING])
3017 
3018         new_block_device_info = attach_block_devices(context, instance, bdms)
3019 
3020         instance.task_state = task_states.REBUILD_SPAWNING
3021         instance.save(
3022             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
3023 
3024         with instance.mutated_migration_context():
3025             self.driver.spawn(context, instance, image_meta, injected_files,
3026                               admin_password, allocations,
3027                               network_info=network_info,
3028                               block_device_info=new_block_device_info)
3029 
3030     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
3031         tb = traceback.format_exc()
3032         self._notify_about_instance_usage(context, instance,
3033                                           'rebuild.error', fault=error)
3034         compute_utils.notify_about_instance_rebuild(
3035             context, instance, self.host,
3036             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms,
3037             tb=tb)
3038 
3039     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
3040     @wrap_exception()
3041     @reverts_task_state
3042     @wrap_instance_event(prefix='compute')
3043     @wrap_instance_fault
3044     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
3045                          injected_files, new_pass, orig_sys_metadata,
3046                          bdms, recreate, on_shared_storage,
3047                          preserve_ephemeral, migration,
3048                          scheduled_node, limits, request_spec):
3049         """Destroy and re-make this instance.
3050 
3051         A 'rebuild' effectively purges all existing data from the system and
3052         remakes the VM with given 'metadata' and 'personalities'.
3053 
3054         :param context: `nova.RequestContext` object
3055         :param instance: Instance object
3056         :param orig_image_ref: Original image_ref before rebuild
3057         :param image_ref: New image_ref for rebuild
3058         :param injected_files: Files to inject
3059         :param new_pass: password to set on rebuilt instance
3060         :param orig_sys_metadata: instance system metadata from pre-rebuild
3061         :param bdms: block-device-mappings to use for rebuild
3062         :param recreate: True if the instance is being recreated (e.g. the
3063             hypervisor it was on failed) - cleanup of old state will be
3064             skipped.
3065         :param on_shared_storage: True if instance files on shared storage.
3066                                   If not provided then information from the
3067                                   driver will be used to decide if the instance
3068                                   files are available or not on the target host
3069         :param preserve_ephemeral: True if the default ephemeral storage
3070                                    partition must be preserved on rebuild
3071         :param migration: a Migration object if one was created for this
3072                           rebuild operation (if it's a part of evacuate)
3073         :param scheduled_node: A node of the host chosen by the scheduler. If a
3074                                host was specified by the user, this will be
3075                                None
3076         :param limits: Overcommit limits set by the scheduler. If a host was
3077                        specified by the user, this will be None
3078         :param request_spec: a RequestSpec object used to schedule the instance
3079 
3080         """
3081         # recreate=True means the instance is being evacuated from a failed
3082         # host to a new destination host (this host). The 'recreate' variable
3083         # name is confusing, so rename it to evacuate here at the top, which
3084         # is simpler than renaming a parameter in an RPC versioned method.
3085         evacuate = recreate
3086         context = context.elevated()
3087 
3088         if evacuate:
3089             LOG.info("Evacuating instance", instance=instance)
3090         else:
3091             LOG.info("Rebuilding instance", instance=instance)
3092 
3093         if evacuate:
3094             # This is an evacuation to a new host, so we need to perform a
3095             # resource claim.
3096             rebuild_claim = self.rt.rebuild_claim
3097         else:
3098             # This is a rebuild to the same host, so we don't need to make
3099             # a claim since the instance is already on this host.
3100             rebuild_claim = claims.NopClaim
3101 
3102         if image_ref:
3103             image_meta = objects.ImageMeta.from_image_ref(
3104                 context, self.image_api, image_ref)
3105         elif evacuate:
3106             # For evacuate the API does not send down the image_ref since the
3107             # image does not change so just get it from what was stashed in
3108             # the instance system_metadata when the instance was created (or
3109             # last rebuilt). This also works for volume-backed instances.
3110             image_meta = instance.image_meta
3111         else:
3112             image_meta = objects.ImageMeta()
3113 
3114         # NOTE(mriedem): On an evacuate, we need to update
3115         # the instance's host and node properties to reflect it's
3116         # destination node for the evacuate.
3117         if not scheduled_node:
3118             if evacuate:
3119                 try:
3120                     compute_node = self._get_compute_info(context, self.host)
3121                     scheduled_node = compute_node.hypervisor_hostname
3122                 except exception.ComputeHostNotFound:
3123                     LOG.exception('Failed to get compute_info for %s',
3124                                   self.host)
3125             else:
3126                 scheduled_node = instance.node
3127 
3128         with self._error_out_instance_on_exception(context, instance):
3129             try:
3130                 claim_ctxt = rebuild_claim(
3131                     context, instance, scheduled_node,
3132                     limits=limits, image_meta=image_meta,
3133                     migration=migration)
3134                 self._do_rebuild_instance_with_claim(
3135                     claim_ctxt, context, instance, orig_image_ref,
3136                     image_meta, injected_files, new_pass, orig_sys_metadata,
3137                     bdms, evacuate, on_shared_storage, preserve_ephemeral,
3138                     migration, request_spec)
3139             except (exception.ComputeResourcesUnavailable,
3140                     exception.RescheduledException) as e:
3141                 if isinstance(e, exception.ComputeResourcesUnavailable):
3142                     LOG.debug("Could not rebuild instance on this host, not "
3143                               "enough resources available.", instance=instance)
3144                 else:
3145                     # RescheduledException is raised by the late server group
3146                     # policy check during evacuation if a parallel scheduling
3147                     # violated the policy.
3148                     # We catch the RescheduledException here but we don't have
3149                     # the plumbing to do an actual reschedule so we abort the
3150                     # operation.
3151                     LOG.debug("Could not rebuild instance on this host, "
3152                               "late server group check failed.",
3153                               instance=instance)
3154                 # NOTE(ndipanov): We just abort the build for now and leave a
3155                 # migration record for potential cleanup later
3156                 self._set_migration_status(migration, 'failed')
3157                 # Since the claim failed, we need to remove the allocation
3158                 # created against the destination node. Note that we can only
3159                 # get here when evacuating to a destination node. Rebuilding
3160                 # on the same host (not evacuate) uses the NopClaim which will
3161                 # not raise ComputeResourcesUnavailable.
3162                 self.rt.delete_allocation_for_evacuated_instance(
3163                     context, instance, scheduled_node, node_type='destination')
3164                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3165                 raise exception.BuildAbortException(
3166                     instance_uuid=instance.uuid, reason=e.format_message())
3167             except (exception.InstanceNotFound,
3168                     exception.UnexpectedDeletingTaskStateError) as e:
3169                 LOG.debug('Instance was deleted while rebuilding',
3170                           instance=instance)
3171                 self._set_migration_status(migration, 'failed')
3172                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3173             except Exception as e:
3174                 self._set_migration_status(migration, 'failed')
3175                 if evacuate or scheduled_node is not None:
3176                     self.rt.delete_allocation_for_evacuated_instance(
3177                         context, instance, scheduled_node,
3178                         node_type='destination')
3179                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3180                 raise
3181             else:
3182                 instance.apply_migration_context()
3183                 # NOTE (ndipanov): This save will now update the host and node
3184                 # attributes making sure that next RT pass is consistent since
3185                 # it will be based on the instance and not the migration DB
3186                 # entry.
3187                 instance.host = self.host
3188                 instance.node = scheduled_node
3189                 instance.save()
3190                 instance.drop_migration_context()
3191 
3192                 # NOTE (ndipanov): Mark the migration as done only after we
3193                 # mark the instance as belonging to this host.
3194                 self._set_migration_status(migration, 'done')
3195 
3196     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
3197         """Helper to avoid deep nesting in the top-level method."""
3198 
3199         with claim_context:
3200             self._do_rebuild_instance(*args, **kwargs)
3201 
3202     @staticmethod
3203     def _get_image_name(image_meta):
3204         if image_meta.obj_attr_is_set("name"):
3205             return image_meta.name
3206         else:
3207             return ''
3208 
3209     def _do_rebuild_instance(self, context, instance, orig_image_ref,
3210                              image_meta, injected_files, new_pass,
3211                              orig_sys_metadata, bdms, evacuate,
3212                              on_shared_storage, preserve_ephemeral,
3213                              migration, request_spec):
3214         orig_vm_state = instance.vm_state
3215 
3216         if evacuate:
3217             if request_spec:
3218                 # NOTE(gibi): Do a late check of server group policy as
3219                 # parallel scheduling could violate such policy. This will
3220                 # cause the evacuate to fail as rebuild does not implement
3221                 # reschedule.
3222                 hints = self._get_scheduler_hints({}, request_spec)
3223                 self._validate_instance_group_policy(context, instance,
3224                                                      hints, migration)
3225 
3226             if not self.driver.capabilities.get("supports_evacuate", False):
3227                 raise exception.InstanceEvacuateNotSupported
3228 
3229             self._check_instance_exists(context, instance)
3230 
3231             if on_shared_storage is None:
3232                 LOG.debug('on_shared_storage is not provided, using driver '
3233                           'information to decide if the instance needs to '
3234                           'be evacuated')
3235                 on_shared_storage = self.driver.instance_on_disk(instance)
3236 
3237             elif (on_shared_storage !=
3238                     self.driver.instance_on_disk(instance)):
3239                 # To cover case when admin expects that instance files are
3240                 # on shared storage, but not accessible and vice versa
3241                 raise exception.InvalidSharedStorage(
3242                         _("Invalid state of instance files on shared"
3243                             " storage"))
3244 
3245             if on_shared_storage:
3246                 LOG.info('disk on shared storage, evacuating using'
3247                          ' existing disk')
3248             elif instance.image_ref:
3249                 orig_image_ref = instance.image_ref
3250                 LOG.info("disk not on shared storage, evacuating from "
3251                          "image: '%s'", str(orig_image_ref))
3252             else:
3253                 LOG.info('disk on volume, evacuating using existing '
3254                          'volume')
3255 
3256         # We check trusted certs capabilities for both evacuate (rebuild on
3257         # another host) and rebuild (rebuild on the same host) because for
3258         # evacuate we need to make sure an instance with trusted certs can
3259         # have the image verified with those certs during rebuild, and for
3260         # rebuild we could be rebuilding a server that started out with no
3261         # trusted certs on this host, and then was rebuilt with trusted certs
3262         # for a new image, in which case we need to validate that new image
3263         # with the trusted certs during the rebuild.
3264         self._check_trusted_certs(instance)
3265 
3266         # This instance.exists message should contain the original
3267         # image_ref, not the new one.  Since the DB has been updated
3268         # to point to the new one... we have to override it.
3269         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
3270                                                                context)
3271         extra_usage_info = {'image_ref_url': orig_image_ref_url}
3272         compute_utils.notify_usage_exists(
3273                 self.notifier, context, instance, self.host,
3274                 current_period=True, system_metadata=orig_sys_metadata,
3275                 extra_usage_info=extra_usage_info)
3276 
3277         # This message should contain the new image_ref
3278         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
3279         self._notify_about_instance_usage(context, instance,
3280                 "rebuild.start", extra_usage_info=extra_usage_info)
3281         # NOTE: image_name is not included in the versioned notification
3282         # because we already provide the image_uuid in the notification
3283         # payload and the image details can be looked up via the uuid.
3284         compute_utils.notify_about_instance_rebuild(
3285             context, instance, self.host,
3286             phase=fields.NotificationPhase.START,
3287             bdms=bdms)
3288 
3289         instance.power_state = self._get_power_state(context, instance)
3290         instance.task_state = task_states.REBUILDING
3291         instance.save(expected_task_state=[task_states.REBUILDING])
3292 
3293         if evacuate:
3294             self.network_api.setup_networks_on_host(
3295                     context, instance, self.host)
3296             # For nova-network this is needed to move floating IPs
3297             # For neutron this updates the host in the port binding
3298             # TODO(cfriesen): this network_api call and the one above
3299             # are so similar, we should really try to unify them.
3300             self.network_api.setup_instance_network_on_host(
3301                     context, instance, self.host, migration)
3302             # TODO(mriedem): Consider decorating setup_instance_network_on_host
3303             # with @base_api.refresh_cache and then we wouldn't need this
3304             # explicit call to get_instance_nw_info.
3305             network_info = self.network_api.get_instance_nw_info(context,
3306                                                                  instance)
3307         else:
3308             network_info = instance.get_network_info()
3309 
3310         allocations = self.reportclient.get_allocations_for_consumer(
3311             context, instance.uuid)
3312 
3313         if bdms is None:
3314             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3315                     context, instance.uuid)
3316 
3317         block_device_info = \
3318             self._get_instance_block_device_info(
3319                     context, instance, bdms=bdms)
3320 
3321         def detach_block_devices(context, bdms):
3322             for bdm in bdms:
3323                 if bdm.is_volume:
3324                     # NOTE (ildikov): Having the attachment_id set in the BDM
3325                     # means that it's the new Cinder attach/detach flow
3326                     # (available from v3.44). In that case we explicitly
3327                     # attach and detach the volumes through attachment level
3328                     # operations. In this scenario _detach_volume will delete
3329                     # the existing attachment which would make the volume
3330                     # status change to 'available' if we don't pre-create
3331                     # another empty attachment before deleting the old one.
3332                     attachment_id = None
3333                     if bdm.attachment_id:
3334                         attachment_id = self.volume_api.attachment_create(
3335                             context, bdm['volume_id'], instance.uuid)['id']
3336                     self._detach_volume(context, bdm, instance,
3337                                         destroy_bdm=False)
3338                     if attachment_id:
3339                         bdm.attachment_id = attachment_id
3340                         bdm.save()
3341 
3342         files = self._decode_files(injected_files)
3343 
3344         kwargs = dict(
3345             context=context,
3346             instance=instance,
3347             image_meta=image_meta,
3348             injected_files=files,
3349             admin_password=new_pass,
3350             allocations=allocations,
3351             bdms=bdms,
3352             detach_block_devices=detach_block_devices,
3353             attach_block_devices=self._prep_block_device,
3354             block_device_info=block_device_info,
3355             network_info=network_info,
3356             preserve_ephemeral=preserve_ephemeral,
3357             evacuate=evacuate)
3358         try:
3359             with instance.mutated_migration_context():
3360                 self.driver.rebuild(**kwargs)
3361         except NotImplementedError:
3362             # NOTE(rpodolyaka): driver doesn't provide specialized version
3363             # of rebuild, fall back to the default implementation
3364             self._rebuild_default_impl(**kwargs)
3365         self._update_instance_after_spawn(context, instance)
3366         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3367 
3368         if orig_vm_state == vm_states.STOPPED:
3369             LOG.info("bringing vm to original state: '%s'",
3370                      orig_vm_state, instance=instance)
3371             instance.vm_state = vm_states.ACTIVE
3372             instance.task_state = task_states.POWERING_OFF
3373             instance.progress = 0
3374             instance.save()
3375             self.stop_instance(context, instance, False)
3376         # TODO(melwitt): We should clean up instance console tokens here in the
3377         # case of evacuate. The instance is on a new host and will need to
3378         # establish a new console connection.
3379         self._update_scheduler_instance_info(context, instance)
3380         self._notify_about_instance_usage(
3381                 context, instance, "rebuild.end",
3382                 network_info=network_info,
3383                 extra_usage_info=extra_usage_info)
3384         compute_utils.notify_about_instance_rebuild(
3385             context, instance, self.host,
3386             phase=fields.NotificationPhase.END,
3387             bdms=bdms)
3388 
3389     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3390                                      block_device_info):
3391         """Handle cases where the virt-layer had to detach non-working volumes
3392         in order to complete an operation.
3393         """
3394         for bdm in block_device_info['block_device_mapping']:
3395             if bdm.get('mount_device') in bad_devices:
3396                 try:
3397                     volume_id = bdm['connection_info']['data']['volume_id']
3398                 except KeyError:
3399                     continue
3400 
3401                 # NOTE(sirp): ideally we'd just call
3402                 # `compute_api.detach_volume` here but since that hits the
3403                 # DB directly, that's off limits from within the
3404                 # compute-manager.
3405                 #
3406                 # API-detach
3407                 LOG.info("Detaching from volume api: %s", volume_id)
3408                 self.volume_api.begin_detaching(context, volume_id)
3409 
3410                 # Manager-detach
3411                 self.detach_volume(context, volume_id, instance)
3412 
3413     @wrap_exception()
3414     @reverts_task_state
3415     @wrap_instance_event(prefix='compute')
3416     @wrap_instance_fault
3417     def reboot_instance(self, context, instance, block_device_info,
3418                         reboot_type):
3419         """Reboot an instance on this host."""
3420         # acknowledge the request made it to the manager
3421         if reboot_type == "SOFT":
3422             instance.task_state = task_states.REBOOT_PENDING
3423             expected_states = task_states.soft_reboot_states
3424         else:
3425             instance.task_state = task_states.REBOOT_PENDING_HARD
3426             expected_states = task_states.hard_reboot_states
3427 
3428         context = context.elevated()
3429         LOG.info("Rebooting instance", instance=instance)
3430 
3431         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3432             context, instance.uuid)
3433         block_device_info = self._get_instance_block_device_info(
3434             context, instance, bdms=bdms)
3435 
3436         network_info = self.network_api.get_instance_nw_info(context, instance)
3437 
3438         self._notify_about_instance_usage(context, instance, "reboot.start")
3439         compute_utils.notify_about_instance_action(
3440             context, instance, self.host,
3441             action=fields.NotificationAction.REBOOT,
3442             phase=fields.NotificationPhase.START,
3443             bdms=bdms
3444         )
3445 
3446         instance.power_state = self._get_power_state(context, instance)
3447         instance.save(expected_task_state=expected_states)
3448 
3449         if instance.power_state != power_state.RUNNING:
3450             state = instance.power_state
3451             running = power_state.RUNNING
3452             LOG.warning('trying to reboot a non-running instance:'
3453                         ' (state: %(state)s expected: %(running)s)',
3454                         {'state': state, 'running': running},
3455                         instance=instance)
3456 
3457         def bad_volumes_callback(bad_devices):
3458             self._handle_bad_volumes_detached(
3459                     context, instance, bad_devices, block_device_info)
3460 
3461         try:
3462             # Don't change it out of rescue mode
3463             if instance.vm_state == vm_states.RESCUED:
3464                 new_vm_state = vm_states.RESCUED
3465             else:
3466                 new_vm_state = vm_states.ACTIVE
3467             new_power_state = None
3468             if reboot_type == "SOFT":
3469                 instance.task_state = task_states.REBOOT_STARTED
3470                 expected_state = task_states.REBOOT_PENDING
3471             else:
3472                 instance.task_state = task_states.REBOOT_STARTED_HARD
3473                 expected_state = task_states.REBOOT_PENDING_HARD
3474             instance.save(expected_task_state=expected_state)
3475             self.driver.reboot(context, instance,
3476                                network_info,
3477                                reboot_type,
3478                                block_device_info=block_device_info,
3479                                bad_volumes_callback=bad_volumes_callback)
3480 
3481         except Exception as error:
3482             with excutils.save_and_reraise_exception() as ctxt:
3483                 exc_info = sys.exc_info()
3484                 # if the reboot failed but the VM is running don't
3485                 # put it into an error state
3486                 new_power_state = self._get_power_state(context, instance)
3487                 if new_power_state == power_state.RUNNING:
3488                     LOG.warning('Reboot failed but instance is running',
3489                                 instance=instance)
3490                     compute_utils.add_instance_fault_from_exc(context,
3491                             instance, error, exc_info)
3492                     self._notify_about_instance_usage(context, instance,
3493                             'reboot.error', fault=error)
3494                     tb = traceback.format_exc()
3495                     compute_utils.notify_about_instance_action(
3496                         context, instance, self.host,
3497                         action=fields.NotificationAction.REBOOT,
3498                         phase=fields.NotificationPhase.ERROR,
3499                         exception=error, bdms=bdms, tb=tb
3500                     )
3501                     ctxt.reraise = False
3502                 else:
3503                     LOG.error('Cannot reboot instance: %s', error,
3504                               instance=instance)
3505                     self._set_instance_obj_error_state(context, instance)
3506 
3507         if not new_power_state:
3508             new_power_state = self._get_power_state(context, instance)
3509         try:
3510             instance.power_state = new_power_state
3511             instance.vm_state = new_vm_state
3512             instance.task_state = None
3513             instance.save()
3514         except exception.InstanceNotFound:
3515             LOG.warning("Instance disappeared during reboot",
3516                         instance=instance)
3517 
3518         self._notify_about_instance_usage(context, instance, "reboot.end")
3519         compute_utils.notify_about_instance_action(
3520             context, instance, self.host,
3521             action=fields.NotificationAction.REBOOT,
3522             phase=fields.NotificationPhase.END,
3523             bdms=bdms
3524         )
3525 
3526     @delete_image_on_error
3527     def _do_snapshot_instance(self, context, image_id, instance):
3528         self._snapshot_instance(context, image_id, instance,
3529                                 task_states.IMAGE_BACKUP)
3530 
3531     @wrap_exception()
3532     @reverts_task_state
3533     @wrap_instance_event(prefix='compute')
3534     @wrap_instance_fault
3535     def backup_instance(self, context, image_id, instance, backup_type,
3536                         rotation):
3537         """Backup an instance on this host.
3538 
3539         :param backup_type: daily | weekly
3540         :param rotation: int representing how many backups to keep around
3541         """
3542         self._do_snapshot_instance(context, image_id, instance)
3543         self._rotate_backups(context, instance, backup_type, rotation)
3544 
3545     @wrap_exception()
3546     @reverts_task_state
3547     @wrap_instance_event(prefix='compute')
3548     @wrap_instance_fault
3549     @delete_image_on_error
3550     def snapshot_instance(self, context, image_id, instance):
3551         """Snapshot an instance on this host.
3552 
3553         :param context: security context
3554         :param image_id: glance.db.sqlalchemy.models.Image.Id
3555         :param instance: a nova.objects.instance.Instance object
3556         """
3557         # NOTE(dave-mcnally) the task state will already be set by the api
3558         # but if the compute manager has crashed/been restarted prior to the
3559         # request getting here the task state may have been cleared so we set
3560         # it again and things continue normally
3561         try:
3562             instance.task_state = task_states.IMAGE_SNAPSHOT
3563             instance.save(
3564                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3565         except exception.InstanceNotFound:
3566             # possibility instance no longer exists, no point in continuing
3567             LOG.debug("Instance not found, could not set state %s "
3568                       "for instance.",
3569                       task_states.IMAGE_SNAPSHOT, instance=instance)
3570             return
3571 
3572         except exception.UnexpectedDeletingTaskStateError:
3573             LOG.debug("Instance being deleted, snapshot cannot continue",
3574                       instance=instance)
3575             return
3576 
3577         self._snapshot_instance(context, image_id, instance,
3578                                 task_states.IMAGE_SNAPSHOT)
3579 
3580     def _snapshot_instance(self, context, image_id, instance,
3581                            expected_task_state):
3582         context = context.elevated()
3583 
3584         instance.power_state = self._get_power_state(context, instance)
3585         try:
3586             instance.save()
3587 
3588             LOG.info('instance snapshotting', instance=instance)
3589 
3590             if instance.power_state != power_state.RUNNING:
3591                 state = instance.power_state
3592                 running = power_state.RUNNING
3593                 LOG.warning('trying to snapshot a non-running instance: '
3594                             '(state: %(state)s expected: %(running)s)',
3595                             {'state': state, 'running': running},
3596                             instance=instance)
3597 
3598             self._notify_about_instance_usage(
3599                 context, instance, "snapshot.start")
3600             compute_utils.notify_about_instance_snapshot(context, instance,
3601                 self.host, phase=fields.NotificationPhase.START,
3602                 snapshot_image_id=image_id)
3603 
3604             def update_task_state(task_state,
3605                                   expected_state=expected_task_state):
3606                 instance.task_state = task_state
3607                 instance.save(expected_task_state=expected_state)
3608 
3609             with timeutils.StopWatch() as timer:
3610                 self.driver.snapshot(context, instance, image_id,
3611                                      update_task_state)
3612             LOG.info('Took %0.2f seconds to snapshot the instance on '
3613                      'the hypervisor.', timer.elapsed(), instance=instance)
3614 
3615             instance.task_state = None
3616             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3617 
3618             self._notify_about_instance_usage(context, instance,
3619                                               "snapshot.end")
3620             compute_utils.notify_about_instance_snapshot(context, instance,
3621                 self.host, phase=fields.NotificationPhase.END,
3622                 snapshot_image_id=image_id)
3623         except (exception.InstanceNotFound,
3624                 exception.UnexpectedDeletingTaskStateError):
3625             # the instance got deleted during the snapshot
3626             # Quickly bail out of here
3627             msg = 'Instance disappeared during snapshot'
3628             LOG.debug(msg, instance=instance)
3629             try:
3630                 image = self.image_api.get(context, image_id)
3631                 if image['status'] != 'active':
3632                     self.image_api.delete(context, image_id)
3633             except exception.ImageNotFound:
3634                 LOG.debug('Image not found during clean up %s', image_id)
3635             except Exception:
3636                 LOG.warning("Error while trying to clean up image %s",
3637                             image_id, instance=instance)
3638         except exception.ImageNotFound:
3639             instance.task_state = None
3640             instance.save()
3641             LOG.warning("Image not found during snapshot", instance=instance)
3642 
3643     def _post_interrupted_snapshot_cleanup(self, context, instance):
3644         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3645 
3646     @messaging.expected_exceptions(NotImplementedError)
3647     @wrap_exception()
3648     def volume_snapshot_create(self, context, instance, volume_id,
3649                                create_info):
3650         self.driver.volume_snapshot_create(context, instance, volume_id,
3651                                            create_info)
3652 
3653     @messaging.expected_exceptions(NotImplementedError)
3654     @wrap_exception()
3655     def volume_snapshot_delete(self, context, instance, volume_id,
3656                                snapshot_id, delete_info):
3657         self.driver.volume_snapshot_delete(context, instance, volume_id,
3658                                            snapshot_id, delete_info)
3659 
3660     @wrap_instance_fault
3661     def _rotate_backups(self, context, instance, backup_type, rotation):
3662         """Delete excess backups associated to an instance.
3663 
3664         Instances are allowed a fixed number of backups (the rotation number);
3665         this method deletes the oldest backups that exceed the rotation
3666         threshold.
3667 
3668         :param context: security context
3669         :param instance: Instance dict
3670         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3671         :param rotation: int representing how many backups to keep around;
3672             None if rotation shouldn't be used (as in the case of snapshots)
3673         """
3674         filters = {'property-image_type': 'backup',
3675                    'property-backup_type': backup_type,
3676                    'property-instance_uuid': instance.uuid}
3677 
3678         images = self.image_api.get_all(context, filters=filters,
3679                                         sort_key='created_at', sort_dir='desc')
3680         num_images = len(images)
3681         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3682                   {'num_images': num_images, 'rotation': rotation},
3683                   instance=instance)
3684 
3685         if num_images > rotation:
3686             # NOTE(sirp): this deletes all backups that exceed the rotation
3687             # limit
3688             excess = len(images) - rotation
3689             LOG.debug("Rotating out %d backups", excess,
3690                       instance=instance)
3691             for i in range(excess):
3692                 image = images.pop()
3693                 image_id = image['id']
3694                 LOG.debug("Deleting image %s", image_id,
3695                           instance=instance)
3696                 try:
3697                     self.image_api.delete(context, image_id)
3698                 except exception.ImageNotFound:
3699                     LOG.info("Failed to find image %(image_id)s to "
3700                              "delete", {'image_id': image_id},
3701                              instance=instance)
3702                 except (exception.ImageDeleteConflict, Exception) as exc:
3703                     LOG.info("Failed to delete image %(image_id)s during "
3704                              "deleting excess backups. "
3705                              "Continuing for next image.. %(exc)s",
3706                              {'image_id': image_id, 'exc': exc},
3707                              instance=instance)
3708 
3709     @wrap_exception()
3710     @reverts_task_state
3711     @wrap_instance_event(prefix='compute')
3712     @wrap_instance_fault
3713     def set_admin_password(self, context, instance, new_pass):
3714         """Set the root/admin password for an instance on this host.
3715 
3716         This is generally only called by API password resets after an
3717         image has been built.
3718 
3719         @param context: Nova auth context.
3720         @param instance: Nova instance object.
3721         @param new_pass: The admin password for the instance.
3722         """
3723 
3724         context = context.elevated()
3725         if new_pass is None:
3726             # Generate a random password
3727             new_pass = utils.generate_password()
3728 
3729         current_power_state = self._get_power_state(context, instance)
3730         expected_state = power_state.RUNNING
3731 
3732         if current_power_state != expected_state:
3733             instance.task_state = None
3734             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3735             _msg = _('instance %s is not running') % instance.uuid
3736             raise exception.InstancePasswordSetFailed(
3737                 instance=instance.uuid, reason=_msg)
3738 
3739         try:
3740             self.driver.set_admin_password(instance, new_pass)
3741             LOG.info("Admin password set", instance=instance)
3742             instance.task_state = None
3743             instance.save(
3744                 expected_task_state=task_states.UPDATING_PASSWORD)
3745         except exception.InstanceAgentNotEnabled:
3746             with excutils.save_and_reraise_exception():
3747                 LOG.debug('Guest agent is not enabled for the instance.',
3748                           instance=instance)
3749                 instance.task_state = None
3750                 instance.save(
3751                     expected_task_state=task_states.UPDATING_PASSWORD)
3752         except exception.SetAdminPasswdNotSupported:
3753             with excutils.save_and_reraise_exception():
3754                 LOG.info('set_admin_password is not supported '
3755                          'by this driver or guest instance.',
3756                          instance=instance)
3757                 instance.task_state = None
3758                 instance.save(
3759                     expected_task_state=task_states.UPDATING_PASSWORD)
3760         except NotImplementedError:
3761             LOG.warning('set_admin_password is not implemented '
3762                         'by this driver or guest instance.',
3763                         instance=instance)
3764             instance.task_state = None
3765             instance.save(
3766                 expected_task_state=task_states.UPDATING_PASSWORD)
3767             raise NotImplementedError(_('set_admin_password is not '
3768                                         'implemented by this driver or guest '
3769                                         'instance.'))
3770         except exception.UnexpectedTaskStateError:
3771             # interrupted by another (most likely delete) task
3772             # do not retry
3773             raise
3774         except Exception:
3775             # Catch all here because this could be anything.
3776             LOG.exception('set_admin_password failed', instance=instance)
3777             # We create a new exception here so that we won't
3778             # potentially reveal password information to the
3779             # API caller.  The real exception is logged above
3780             _msg = _('error setting admin password')
3781             raise exception.InstancePasswordSetFailed(
3782                 instance=instance.uuid, reason=_msg)
3783 
3784     @wrap_exception()
3785     @reverts_task_state
3786     @wrap_instance_fault
3787     def inject_file(self, context, path, file_contents, instance):
3788         """Write a file to the specified path in an instance on this host."""
3789         # NOTE(russellb) Remove this method, as well as the underlying virt
3790         # driver methods, when the compute rpc interface is bumped to 4.x
3791         # as it is no longer used.
3792         context = context.elevated()
3793         current_power_state = self._get_power_state(context, instance)
3794         expected_state = power_state.RUNNING
3795         if current_power_state != expected_state:
3796             LOG.warning('trying to inject a file into a non-running '
3797                         '(state: %(current_state)s expected: '
3798                         '%(expected_state)s)',
3799                         {'current_state': current_power_state,
3800                          'expected_state': expected_state},
3801                         instance=instance)
3802         LOG.info('injecting file to %s', path, instance=instance)
3803         self.driver.inject_file(instance, path, file_contents)
3804 
3805     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3806         """Determine what image should be used to boot the rescue VM."""
3807         # 1. If rescue_image_ref is passed in, use that for rescue.
3808         # 2. Else, use the base image associated with instance's current image.
3809         #       The idea here is to provide the customer with a rescue
3810         #       environment which they are familiar with.
3811         #       So, if they built their instance off of a Debian image,
3812         #       their rescue VM will also be Debian.
3813         # 3. As a last resort, use instance's current image.
3814         if not rescue_image_ref:
3815             system_meta = utils.instance_sys_meta(instance)
3816             rescue_image_ref = system_meta.get('image_base_image_ref')
3817 
3818         if not rescue_image_ref:
3819             LOG.warning('Unable to find a different image to use for '
3820                         'rescue VM, using instance\'s current image',
3821                         instance=instance)
3822             rescue_image_ref = instance.image_ref
3823 
3824         return objects.ImageMeta.from_image_ref(
3825             context, self.image_api, rescue_image_ref)
3826 
3827     @wrap_exception()
3828     @reverts_task_state
3829     @wrap_instance_event(prefix='compute')
3830     @wrap_instance_fault
3831     def rescue_instance(self, context, instance, rescue_password,
3832                         rescue_image_ref, clean_shutdown):
3833         context = context.elevated()
3834         LOG.info('Rescuing', instance=instance)
3835 
3836         admin_password = (rescue_password if rescue_password else
3837                       utils.generate_password())
3838 
3839         network_info = self.network_api.get_instance_nw_info(context, instance)
3840 
3841         rescue_image_meta = self._get_rescue_image(context, instance,
3842                                                    rescue_image_ref)
3843 
3844         extra_usage_info = {'rescue_image_name':
3845                             self._get_image_name(rescue_image_meta)}
3846         self._notify_about_instance_usage(context, instance,
3847                 "rescue.start", extra_usage_info=extra_usage_info,
3848                 network_info=network_info)
3849         compute_utils.notify_about_instance_rescue_action(
3850             context, instance, self.host, rescue_image_ref,
3851             phase=fields.NotificationPhase.START)
3852 
3853         try:
3854             self._power_off_instance(context, instance, clean_shutdown)
3855 
3856             self.driver.rescue(context, instance,
3857                                network_info,
3858                                rescue_image_meta, admin_password)
3859         except Exception as e:
3860             LOG.exception("Error trying to Rescue Instance",
3861                           instance=instance)
3862             self._set_instance_obj_error_state(context, instance)
3863             raise exception.InstanceNotRescuable(
3864                 instance_id=instance.uuid,
3865                 reason=_("Driver Error: %s") % e)
3866 
3867         compute_utils.notify_usage_exists(self.notifier, context, instance,
3868                                           self.host, current_period=True)
3869 
3870         instance.vm_state = vm_states.RESCUED
3871         instance.task_state = None
3872         instance.power_state = self._get_power_state(context, instance)
3873         instance.launched_at = timeutils.utcnow()
3874         instance.save(expected_task_state=task_states.RESCUING)
3875 
3876         self._notify_about_instance_usage(context, instance,
3877                 "rescue.end", extra_usage_info=extra_usage_info,
3878                 network_info=network_info)
3879         compute_utils.notify_about_instance_rescue_action(
3880             context, instance, self.host, rescue_image_ref,
3881             phase=fields.NotificationPhase.END)
3882 
3883     @wrap_exception()
3884     @reverts_task_state
3885     @wrap_instance_event(prefix='compute')
3886     @wrap_instance_fault
3887     def unrescue_instance(self, context, instance):
3888         context = context.elevated()
3889         LOG.info('Unrescuing', instance=instance)
3890 
3891         network_info = self.network_api.get_instance_nw_info(context, instance)
3892         self._notify_about_instance_usage(context, instance,
3893                 "unrescue.start", network_info=network_info)
3894         compute_utils.notify_about_instance_action(context, instance,
3895             self.host, action=fields.NotificationAction.UNRESCUE,
3896             phase=fields.NotificationPhase.START)
3897 
3898         with self._error_out_instance_on_exception(context, instance):
3899             self.driver.unrescue(instance,
3900                                  network_info)
3901 
3902         instance.vm_state = vm_states.ACTIVE
3903         instance.task_state = None
3904         instance.power_state = self._get_power_state(context, instance)
3905         instance.save(expected_task_state=task_states.UNRESCUING)
3906 
3907         self._notify_about_instance_usage(context,
3908                                           instance,
3909                                           "unrescue.end",
3910                                           network_info=network_info)
3911         compute_utils.notify_about_instance_action(context, instance,
3912             self.host, action=fields.NotificationAction.UNRESCUE,
3913             phase=fields.NotificationPhase.END)
3914 
3915     @wrap_exception()
3916     @wrap_instance_fault
3917     def change_instance_metadata(self, context, diff, instance):
3918         """Update the metadata published to the instance."""
3919         LOG.debug("Changing instance metadata according to %r",
3920                   diff, instance=instance)
3921         self.driver.change_instance_metadata(context, instance, diff)
3922 
3923     @wrap_exception()
3924     @wrap_instance_event(prefix='compute')
3925     @errors_out_migration
3926     @wrap_instance_fault
3927     def confirm_resize(self, context, instance, migration):
3928         """Confirms a migration/resize and deletes the 'old' instance.
3929 
3930         This is called from the API and runs on the source host.
3931 
3932         Nothing needs to happen on the destination host at this point since
3933         the instance is already running there. This routine just cleans up the
3934         source host.
3935         """
3936         @utils.synchronized(instance.uuid)
3937         def do_confirm_resize(context, instance, migration_id):
3938             # NOTE(wangpan): Get the migration status from db, if it has been
3939             #                confirmed, we do nothing and return here
3940             LOG.debug("Going to confirm migration %s", migration_id,
3941                       instance=instance)
3942             try:
3943                 # TODO(russellb) Why are we sending the migration object just
3944                 # to turn around and look it up from the db again?
3945                 migration = objects.Migration.get_by_id(
3946                                     context.elevated(), migration_id)
3947             except exception.MigrationNotFound:
3948                 LOG.error("Migration %s is not found during confirmation",
3949                           migration_id, instance=instance)
3950                 return
3951 
3952             if migration.status == 'confirmed':
3953                 LOG.info("Migration %s is already confirmed",
3954                          migration_id, instance=instance)
3955                 return
3956             elif migration.status not in ('finished', 'confirming'):
3957                 LOG.warning("Unexpected confirmation status '%(status)s' "
3958                             "of migration %(id)s, exit confirmation process",
3959                             {"status": migration.status, "id": migration_id},
3960                             instance=instance)
3961                 return
3962 
3963             # NOTE(wangpan): Get the instance from db, if it has been
3964             #                deleted, we do nothing and return here
3965             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3966             try:
3967                 instance = objects.Instance.get_by_uuid(
3968                         context, instance.uuid,
3969                         expected_attrs=expected_attrs)
3970             except exception.InstanceNotFound:
3971                 LOG.info("Instance is not found during confirmation",
3972                          instance=instance)
3973                 return
3974 
3975             with self._error_out_instance_on_exception(context, instance):
3976                 try:
3977                     self._confirm_resize(
3978                         context, instance, migration=migration)
3979                 except Exception:
3980                     # Something failed when cleaning up the source host so
3981                     # log a traceback and leave a hint about hard rebooting
3982                     # the server to correct its state in the DB.
3983                     with excutils.save_and_reraise_exception(logger=LOG):
3984                         LOG.exception(
3985                             'Confirm resize failed on source host %s. '
3986                             'Resource allocations in the placement service '
3987                             'will be removed regardless because the instance '
3988                             'is now on the destination host %s. You can try '
3989                             'hard rebooting the instance to correct its '
3990                             'state.', self.host, migration.dest_compute,
3991                             instance=instance)
3992                 finally:
3993                     # Whether an error occurred or not, at this point the
3994                     # instance is on the dest host so to avoid leaking
3995                     # allocations in placement, delete them here.
3996                     self._delete_allocation_after_move(
3997                         context, instance, migration)
3998 
3999         do_confirm_resize(context, instance, migration.id)
4000 
4001     def _get_updated_nw_info_with_pci_mapping(self, nw_info, pci_mapping):
4002         # NOTE(adrianc): This method returns a copy of nw_info if modifications
4003         # are made else it returns the original nw_info.
4004         updated_nw_info = nw_info
4005         if nw_info and pci_mapping:
4006             updated_nw_info = copy.deepcopy(nw_info)
4007             for vif in updated_nw_info:
4008                 if vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV:
4009                     try:
4010                         vif_pci_addr = vif['profile']['pci_slot']
4011                         new_addr = pci_mapping[vif_pci_addr].address
4012                         vif['profile']['pci_slot'] = new_addr
4013                         LOG.debug("Updating VIF's PCI address for VIF %(id)s. "
4014                                   "Original value %(orig_val)s, "
4015                                   "new value %(new_val)s",
4016                                   {'id': vif['id'],
4017                                    'orig_val': vif_pci_addr,
4018                                    'new_val': new_addr})
4019                     except (KeyError, AttributeError):
4020                         with excutils.save_and_reraise_exception():
4021                             # NOTE(adrianc): This should never happen. If we
4022                             # get here it means there is some inconsistency
4023                             # with either 'nw_info' or 'pci_mapping'.
4024                             LOG.error("Unexpected error when updating network "
4025                                       "information with PCI mapping.")
4026         return updated_nw_info
4027 
4028     def _confirm_resize(self, context, instance, migration=None):
4029         """Destroys the source instance."""
4030         self._notify_about_instance_usage(context, instance,
4031                                           "resize.confirm.start")
4032         compute_utils.notify_about_instance_action(context, instance,
4033             self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
4034             phase=fields.NotificationPhase.START)
4035 
4036         # NOTE(danms): delete stashed migration information
4037         old_instance_type = instance.old_flavor
4038         instance.old_flavor = None
4039         instance.new_flavor = None
4040         instance.system_metadata.pop('old_vm_state', None)
4041         instance.save()
4042 
4043         # NOTE(tr3buchet): tear down networks on source host
4044         self.network_api.setup_networks_on_host(context, instance,
4045                            migration.source_compute, teardown=True)
4046         network_info = self.network_api.get_instance_nw_info(context,
4047                                                              instance)
4048 
4049         # NOTE(adrianc): Populate old PCI device in VIF profile
4050         # to allow virt driver to properly unplug it from Hypervisor.
4051         pci_mapping = (instance.migration_context.
4052                        get_pci_mapping_for_migration(True))
4053         network_info = self._get_updated_nw_info_with_pci_mapping(
4054             network_info, pci_mapping)
4055 
4056         # TODO(mriedem): Get BDMs here and pass them to the driver.
4057         self.driver.confirm_migration(context, migration, instance,
4058                                       network_info)
4059 
4060         migration.status = 'confirmed'
4061         migration.save()
4062 
4063         # NOTE(mriedem): drop_move_claim relies on
4064         # instance.migration_context so make sure to not call
4065         # instance.drop_migration_context() until after drop_move_claim
4066         # is called.
4067         self.rt.drop_move_claim(context, instance, migration.source_node,
4068                                 old_instance_type, prefix='old_')
4069         instance.drop_migration_context()
4070 
4071         # NOTE(mriedem): The old_vm_state could be STOPPED but the user
4072         # might have manually powered up the instance to confirm the
4073         # resize/migrate, so we need to check the current power state
4074         # on the instance and set the vm_state appropriately. We default
4075         # to ACTIVE because if the power state is not SHUTDOWN, we
4076         # assume _sync_instance_power_state will clean it up.
4077         p_state = instance.power_state
4078         vm_state = None
4079         if p_state == power_state.SHUTDOWN:
4080             vm_state = vm_states.STOPPED
4081             LOG.debug("Resized/migrated instance is powered off. "
4082                       "Setting vm_state to '%s'.", vm_state,
4083                       instance=instance)
4084         else:
4085             vm_state = vm_states.ACTIVE
4086 
4087         instance.vm_state = vm_state
4088         instance.task_state = None
4089         instance.save(expected_task_state=[None, task_states.DELETING,
4090                                            task_states.SOFT_DELETING])
4091 
4092         self._notify_about_instance_usage(
4093             context, instance, "resize.confirm.end",
4094             network_info=network_info)
4095         compute_utils.notify_about_instance_action(context, instance,
4096                self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
4097                phase=fields.NotificationPhase.END)
4098 
4099     def _delete_allocation_after_move(self, context, instance, migration):
4100         """Deletes resource allocations held by the migration record against
4101         the source compute node resource provider after a confirmed cold /
4102         successful live migration.
4103         """
4104         try:
4105             # NOTE(danms): We're finishing on the source node, so try
4106             # to delete the allocation based on the migration uuid
4107             self.reportclient.delete_allocation_for_instance(
4108                 context, migration.uuid, consumer_type='migration')
4109         except exception.AllocationDeleteFailed:
4110             LOG.error('Deleting allocation in placement for migration '
4111                       '%(migration_uuid)s failed. The instance '
4112                       '%(instance_uuid)s will be put to ERROR state '
4113                       'but the allocation held by the migration is '
4114                       'leaked.',
4115                       {'instance_uuid': instance.uuid,
4116                        'migration_uuid': migration.uuid})
4117             raise
4118 
4119     @wrap_exception()
4120     @reverts_task_state
4121     @wrap_instance_event(prefix='compute')
4122     @errors_out_migration
4123     @wrap_instance_fault
4124     def revert_resize(self, context, instance, migration):
4125         """Destroys the new instance on the destination machine.
4126 
4127         Reverts the model changes, and powers on the old instance on the
4128         source machine.
4129 
4130         """
4131         # NOTE(comstud): A revert_resize is essentially a resize back to
4132         # the old size, so we need to send a usage event here.
4133         compute_utils.notify_usage_exists(self.notifier, context, instance,
4134                                           self.host, current_period=True)
4135 
4136         with self._error_out_instance_on_exception(context, instance):
4137             # NOTE(tr3buchet): tear down networks on destination host
4138             self.network_api.setup_networks_on_host(context, instance,
4139                                                     teardown=True)
4140 
4141             migration_p = obj_base.obj_to_primitive(migration)
4142             self.network_api.migrate_instance_start(context,
4143                                                     instance,
4144                                                     migration_p)
4145 
4146             network_info = self.network_api.get_instance_nw_info(context,
4147                                                                  instance)
4148             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4149                     context, instance.uuid)
4150             block_device_info = self._get_instance_block_device_info(
4151                                 context, instance, bdms=bdms)
4152 
4153             destroy_disks = not self._is_instance_storage_shared(
4154                 context, instance, host=migration.source_compute)
4155             self.driver.destroy(context, instance, network_info,
4156                                 block_device_info, destroy_disks)
4157 
4158             self._terminate_volume_connections(context, instance, bdms)
4159 
4160             migration.status = 'reverted'
4161             migration.save()
4162 
4163             # NOTE(ndipanov): We need to do this here because dropping the
4164             # claim means we lose the migration_context data. We really should
4165             # fix this by moving the drop_move_claim call to the
4166             # finish_revert_resize method as this is racy (revert is dropped,
4167             # but instance resources will be tracked with the new flavor until
4168             # it gets rolled back in finish_revert_resize, which is
4169             # potentially wrong for a period of time).
4170             instance.revert_migration_context()
4171             instance.save()
4172 
4173             self.rt.drop_move_claim(context, instance, instance.node)
4174 
4175             # RPC cast back to the source host to finish the revert there.
4176             self.compute_rpcapi.finish_revert_resize(context, instance,
4177                     migration, migration.source_compute)
4178 
4179     @wrap_exception()
4180     @reverts_task_state
4181     @wrap_instance_event(prefix='compute')
4182     @errors_out_migration
4183     @wrap_instance_fault
4184     def finish_revert_resize(self, context, instance, migration):
4185         """Finishes the second half of reverting a resize on the source host.
4186 
4187         Bring the original source instance state back (active/shutoff) and
4188         revert the resized attributes in the database.
4189 
4190         """
4191         with self._error_out_instance_on_exception(context, instance):
4192             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4193                 context, instance.uuid)
4194             self._notify_about_instance_usage(
4195                     context, instance, "resize.revert.start")
4196             compute_utils.notify_about_instance_action(context, instance,
4197                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4198                     phase=fields.NotificationPhase.START, bdms=bdms)
4199 
4200             # NOTE(mriedem): delete stashed old_vm_state information; we
4201             # default to ACTIVE for backwards compatibility if old_vm_state
4202             # is not set
4203             old_vm_state = instance.system_metadata.pop('old_vm_state',
4204                                                         vm_states.ACTIVE)
4205 
4206             self._set_instance_info(instance, instance.old_flavor)
4207             instance.old_flavor = None
4208             instance.new_flavor = None
4209             instance.host = migration.source_compute
4210             instance.node = migration.source_node
4211             instance.save()
4212 
4213             try:
4214                 self._revert_allocation(context, instance, migration)
4215             except exception.AllocationMoveFailed:
4216                 LOG.error('Reverting allocation in placement for migration '
4217                           '%(migration_uuid)s failed. The instance '
4218                           '%(instance_uuid)s will be put into ERROR state but '
4219                           'the allocation held by the migration is leaked.',
4220                           {'instance_uuid': instance.uuid,
4221                            'migration_uuid': migration.uuid})
4222                 raise
4223 
4224             self.network_api.setup_networks_on_host(context, instance,
4225                                                     migration.source_compute)
4226             # NOTE(hanrong): we need to change migration.dest_compute to
4227             # source host temporarily. "network_api.migrate_instance_finish"
4228             # will setup the network for the instance on the destination host.
4229             # For revert resize, the instance will back to the source host, the
4230             # setup of the network for instance should be on the source host.
4231             # So set the migration.dest_compute to source host at here.
4232             with utils.temporary_mutation(
4233                     migration, dest_compute=migration.source_compute):
4234                 self.network_api.migrate_instance_finish(context,
4235                                                          instance,
4236                                                          migration)
4237             network_info = self.network_api.get_instance_nw_info(context,
4238                                                                  instance)
4239 
4240             # revert_resize deleted any volume attachments for the instance
4241             # and created new ones to be used on this host, but we
4242             # have to update those attachments with the host connector so the
4243             # BDM.connection_info will get set in the call to
4244             # _get_instance_block_device_info below with refresh_conn_info=True
4245             # and then the volumes can be re-connected via the driver on this
4246             # host.
4247             self._update_volume_attachments(context, instance, bdms)
4248 
4249             block_device_info = self._get_instance_block_device_info(
4250                     context, instance, refresh_conn_info=True, bdms=bdms)
4251 
4252             power_on = old_vm_state != vm_states.STOPPED
4253             self.driver.finish_revert_migration(context, instance,
4254                                        network_info,
4255                                        block_device_info, power_on)
4256 
4257             instance.drop_migration_context()
4258             instance.launched_at = timeutils.utcnow()
4259             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
4260 
4261             # Complete any volume attachments so the volumes are in-use.
4262             self._complete_volume_attachments(context, bdms)
4263 
4264             # if the original vm state was STOPPED, set it back to STOPPED
4265             LOG.info("Updating instance to original state: '%s'",
4266                      old_vm_state, instance=instance)
4267             if power_on:
4268                 instance.vm_state = vm_states.ACTIVE
4269                 instance.task_state = None
4270                 instance.save()
4271             else:
4272                 instance.task_state = task_states.POWERING_OFF
4273                 instance.save()
4274                 self.stop_instance(context, instance=instance,
4275                                    clean_shutdown=True)
4276 
4277             self._notify_about_instance_usage(
4278                     context, instance, "resize.revert.end")
4279             compute_utils.notify_about_instance_action(context, instance,
4280                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4281                     phase=fields.NotificationPhase.END, bdms=bdms)
4282 
4283     def _revert_allocation(self, context, instance, migration):
4284         """Revert an allocation that is held by migration to our instance."""
4285 
4286         # Fetch the original allocation that the instance had on the source
4287         # node, which are now held by the migration
4288         orig_alloc = self.reportclient.get_allocations_for_consumer(
4289             context, migration.uuid)
4290         if not orig_alloc:
4291             LOG.error('Did not find resource allocations for migration '
4292                       '%s on source node %s. Unable to revert source node '
4293                       'allocations back to the instance.',
4294                       migration.uuid, migration.source_node, instance=instance)
4295             return False
4296 
4297         if len(orig_alloc) > 1:
4298             # NOTE(danms): This may change later if we have other allocations
4299             # against other providers that need to be held by the migration
4300             # as well. Perhaps something like shared storage resources that
4301             # will actually be duplicated during a resize type operation.
4302             LOG.error('Migration %(mig)s has allocations against '
4303                       'more than one provider %(rps)s. This should not be '
4304                       'possible, but reverting it anyway.',
4305                       {'mig': migration.uuid,
4306                        'rps': ','.join(orig_alloc.keys())},
4307                       instance=instance)
4308 
4309         # We only have a claim against one provider, it is the source node
4310         cn_uuid = list(orig_alloc.keys())[0]
4311 
4312         # FIXME(danms): This method is flawed in that it asssumes allocations
4313         # against only one provider. So, this may overwite allocations against
4314         # a shared provider, if we had one.
4315         LOG.info('Swapping old allocation on %(node)s held by migration '
4316                  '%(mig)s for instance',
4317                  {'node': cn_uuid, 'mig': migration.uuid},
4318                  instance=instance)
4319         # TODO(cdent): Should we be doing anything with return values here?
4320         self.reportclient.move_allocations(context, migration.uuid,
4321                                            instance.uuid)
4322         return True
4323 
4324     def _prep_resize(self, context, image, instance, instance_type,
4325                      filter_properties, node, migration, clean_shutdown=True):
4326 
4327         if not filter_properties:
4328             filter_properties = {}
4329 
4330         if not instance.host:
4331             self._set_instance_obj_error_state(context, instance)
4332             msg = _('Instance has no source host')
4333             raise exception.MigrationError(reason=msg)
4334 
4335         same_host = instance.host == self.host
4336         # if the flavor IDs match, it's migrate; otherwise resize
4337         if same_host and instance_type.id == instance['instance_type_id']:
4338             # check driver whether support migrate to same host
4339             if not self.driver.capabilities.get(
4340                     'supports_migrate_to_same_host', False):
4341                 raise exception.UnableToMigrateToSelf(
4342                     instance_id=instance.uuid, host=self.host)
4343 
4344         # NOTE(danms): Stash the new instance_type to avoid having to
4345         # look it up in the database later
4346         instance.new_flavor = instance_type
4347         # NOTE(mriedem): Stash the old vm_state so we can set the
4348         # resized/reverted instance back to the same state later.
4349         vm_state = instance.vm_state
4350         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4351         instance.system_metadata['old_vm_state'] = vm_state
4352         instance.save()
4353 
4354         limits = filter_properties.get('limits', {})
4355         with self.rt.resize_claim(context, instance, instance_type, node,
4356                                   migration, image_meta=image,
4357                                   limits=limits) as claim:
4358             LOG.info('Migrating', instance=instance)
4359             # RPC cast to the source host to start the actual resize/migration.
4360             self.compute_rpcapi.resize_instance(
4361                     context, instance, claim.migration, image,
4362                     instance_type, clean_shutdown)
4363 
4364     def _send_prep_resize_notifications(
4365             self, context, instance, phase, flavor):
4366         """Send "resize.prep.*" notifications.
4367 
4368         :param context: nova auth request context
4369         :param instance: The instance being resized
4370         :param phase: The phase of the action (NotificationPhase enum)
4371         :param flavor: The (new) flavor for the resize (same as existing
4372             instance.flavor for a cold migration)
4373         """
4374         # Only send notify_usage_exists if it's the "start" phase.
4375         if phase == fields.NotificationPhase.START:
4376             compute_utils.notify_usage_exists(
4377                 self.notifier, context, instance, self.host,
4378                 current_period=True)
4379 
4380         # Send extra usage info about the flavor if it's the "end" phase for
4381         # the legacy unversioned notification.
4382         extra_usage_info = None
4383         if phase == fields.NotificationPhase.END:
4384             extra_usage_info = dict(
4385                 new_instance_type=flavor.name,
4386                 new_instance_type_id=flavor.id)
4387         self._notify_about_instance_usage(
4388             context, instance, "resize.prep.%s" % phase,
4389             extra_usage_info=extra_usage_info)
4390 
4391         # Send the versioned notification.
4392         compute_utils.notify_about_resize_prep_instance(
4393             context, instance, self.host, phase, flavor)
4394 
4395     @wrap_exception()
4396     @reverts_task_state
4397     @wrap_instance_event(prefix='compute')
4398     @wrap_instance_fault
4399     def prep_resize(self, context, image, instance, instance_type,
4400                     request_spec, filter_properties, node,
4401                     clean_shutdown, migration, host_list):
4402         """Initiates the process of moving a running instance to another host.
4403 
4404         Possibly changes the VCPU, RAM and disk size in the process.
4405 
4406         This is initiated from conductor and runs on the destination host.
4407 
4408         The main purpose of this method is performing some checks on the
4409         destination host and making a claim for resources. If the claim fails
4410         then a reschedule to another host may be attempted which involves
4411         calling back to conductor to start the process over again.
4412         """
4413         if node is None:
4414             node = self._get_nodename(instance, refresh=True)
4415 
4416         with self._error_out_instance_on_exception(context, instance), \
4417                  errors_out_migration_ctxt(migration):
4418             self._send_prep_resize_notifications(
4419                 context, instance, fields.NotificationPhase.START,
4420                 instance_type)
4421             try:
4422                 self._prep_resize(context, image, instance,
4423                                   instance_type, filter_properties,
4424                                   node, migration, clean_shutdown)
4425             except Exception:
4426                 # Since we hit a failure, we're either rescheduling or dead
4427                 # and either way we need to cleanup any allocations created
4428                 # by the scheduler for the destination node.
4429                 self._revert_allocation(context, instance, migration)
4430                 # try to re-schedule the resize elsewhere:
4431                 exc_info = sys.exc_info()
4432                 self._reschedule_resize_or_reraise(context, instance,
4433                         exc_info, instance_type, request_spec,
4434                         filter_properties, host_list)
4435             finally:
4436                 self._send_prep_resize_notifications(
4437                     context, instance, fields.NotificationPhase.END,
4438                     instance_type)
4439 
4440     def _reschedule_resize_or_reraise(self, context, instance, exc_info,
4441             instance_type, request_spec, filter_properties, host_list):
4442         """Try to re-schedule the resize or re-raise the original error to
4443         error out the instance.
4444         """
4445         if not filter_properties:
4446             filter_properties = {}
4447 
4448         rescheduled = False
4449         instance_uuid = instance.uuid
4450 
4451         try:
4452             retry = filter_properties.get('retry')
4453             if retry:
4454                 LOG.debug('Rescheduling, attempt %d', retry['num_attempts'],
4455                           instance_uuid=instance_uuid)
4456 
4457                 # reset the task state
4458                 task_state = task_states.RESIZE_PREP
4459                 self._instance_update(context, instance, task_state=task_state)
4460 
4461                 if exc_info:
4462                     # stringify to avoid circular ref problem in json
4463                     # serialization
4464                     retry['exc'] = traceback.format_exception_only(
4465                         exc_info[0], exc_info[1])
4466 
4467                 scheduler_hint = {'filter_properties': filter_properties}
4468 
4469                 self.compute_task_api.resize_instance(
4470                     context, instance, scheduler_hint, instance_type,
4471                     request_spec=request_spec, host_list=host_list)
4472 
4473                 rescheduled = True
4474             else:
4475                 # no retry information, do not reschedule.
4476                 LOG.debug('Retry info not present, will not reschedule',
4477                           instance_uuid=instance_uuid)
4478                 rescheduled = False
4479         except Exception as error:
4480             rescheduled = False
4481             LOG.exception("Error trying to reschedule",
4482                           instance_uuid=instance_uuid)
4483             compute_utils.add_instance_fault_from_exc(context,
4484                     instance, error,
4485                     exc_info=sys.exc_info())
4486             self._notify_about_instance_usage(context, instance,
4487                     'resize.error', fault=error)
4488             compute_utils.notify_about_instance_action(
4489                 context, instance, self.host,
4490                 action=fields.NotificationAction.RESIZE,
4491                 phase=fields.NotificationPhase.ERROR,
4492                 exception=error,
4493                 tb=','.join(traceback.format_exception(*exc_info)))
4494 
4495         if rescheduled:
4496             self._log_original_error(exc_info, instance_uuid)
4497             compute_utils.add_instance_fault_from_exc(context,
4498                     instance, exc_info[1], exc_info=exc_info)
4499             self._notify_about_instance_usage(context, instance,
4500                     'resize.error', fault=exc_info[1])
4501             compute_utils.notify_about_instance_action(
4502                 context, instance, self.host,
4503                 action=fields.NotificationAction.RESIZE,
4504                 phase=fields.NotificationPhase.ERROR,
4505                 exception=exc_info[1],
4506                 tb=','.join(traceback.format_exception(*exc_info)))
4507         else:
4508             # not re-scheduling
4509             six.reraise(*exc_info)
4510 
4511     @wrap_exception()
4512     @reverts_task_state
4513     @wrap_instance_event(prefix='compute')
4514     @wrap_instance_fault
4515     def resize_instance(self, context, instance, image,
4516                         migration, instance_type, clean_shutdown):
4517         """Starts the migration of a running instance to another host.
4518 
4519         This is initiated from the destination host's ``prep_resize`` routine
4520         and runs on the source host.
4521         """
4522         try:
4523             self._resize_instance(context, instance, image, migration,
4524                                   instance_type, clean_shutdown)
4525         except Exception:
4526             with excutils.save_and_reraise_exception():
4527                 self._revert_allocation(context, instance, migration)
4528 
4529     def _resize_instance(self, context, instance, image,
4530                          migration, instance_type, clean_shutdown):
4531         with self._error_out_instance_on_exception(context, instance), \
4532              errors_out_migration_ctxt(migration):
4533             network_info = self.network_api.get_instance_nw_info(context,
4534                                                                  instance)
4535 
4536             migration.status = 'migrating'
4537             migration.save()
4538 
4539             instance.task_state = task_states.RESIZE_MIGRATING
4540             instance.save(expected_task_state=task_states.RESIZE_PREP)
4541 
4542             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4543                     context, instance.uuid)
4544             self._send_resize_instance_notifications(
4545                 context, instance, bdms, network_info,
4546                 fields.NotificationPhase.START)
4547 
4548             block_device_info = self._get_instance_block_device_info(
4549                                 context, instance, bdms=bdms)
4550 
4551             timeout, retry_interval = self._get_power_off_values(context,
4552                                             instance, clean_shutdown)
4553             disk_info = self.driver.migrate_disk_and_power_off(
4554                     context, instance, migration.dest_host,
4555                     instance_type, network_info,
4556                     block_device_info,
4557                     timeout, retry_interval)
4558 
4559             self._terminate_volume_connections(context, instance, bdms)
4560 
4561             migration_p = obj_base.obj_to_primitive(migration)
4562             self.network_api.migrate_instance_start(context,
4563                                                     instance,
4564                                                     migration_p)
4565 
4566             migration.status = 'post-migrating'
4567             migration.save()
4568 
4569             instance.host = migration.dest_compute
4570             instance.node = migration.dest_node
4571             instance.task_state = task_states.RESIZE_MIGRATED
4572             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4573 
4574             # RPC cast to the destination host to finish the resize/migration.
4575             self.compute_rpcapi.finish_resize(context, instance,
4576                     migration, image, disk_info, migration.dest_compute)
4577 
4578         self._send_resize_instance_notifications(
4579             context, instance, bdms, network_info,
4580             fields.NotificationPhase.END)
4581         self.instance_events.clear_events_for_instance(instance)
4582 
4583     def _send_resize_instance_notifications(
4584             self, context, instance, bdms, network_info, phase):
4585         """Send "resize.(start|end)" notifications.
4586 
4587         :param context: nova auth request context
4588         :param instance: The instance being resized
4589         :param bdms: BlockDeviceMappingList for the BDMs associated with the
4590             instance
4591         :param network_info: NetworkInfo for the instance info cache of ports
4592         :param phase: The phase of the action (NotificationPhase enum, either
4593             ``start`` or ``end``)
4594         """
4595         action = fields.NotificationAction.RESIZE
4596         # Send the legacy unversioned notification.
4597         self._notify_about_instance_usage(
4598             context, instance, "%s.%s" % (action, phase),
4599             network_info=network_info)
4600         # Send the versioned notification.
4601         compute_utils.notify_about_instance_action(
4602             context, instance, self.host, action=action, phase=phase,
4603             bdms=bdms)
4604 
4605     def _terminate_volume_connections(self, context, instance, bdms):
4606         connector = None
4607         for bdm in bdms:
4608             if bdm.is_volume:
4609                 if bdm.attachment_id:
4610                     # NOTE(jdg): So here's the thing, the idea behind the new
4611                     # attach API's was to have a new code fork/path that we
4612                     # followed, we're not going to do that so we have to do
4613                     # some extra work in here to make it *behave* just like the
4614                     # old code. Cinder doesn't allow disconnect/reconnect (you
4615                     # just delete the attachment and get a new one)
4616                     # attachments in the new attach code so we have to do
4617                     # a delete and create without a connector (reserve),
4618                     # in other words, beware
4619                     attachment_id = self.volume_api.attachment_create(
4620                         context, bdm.volume_id, instance.uuid)['id']
4621                     self.volume_api.attachment_delete(context,
4622                                                       bdm.attachment_id)
4623                     bdm.attachment_id = attachment_id
4624                     bdm.save()
4625 
4626                 else:
4627                     if connector is None:
4628                         connector = self.driver.get_volume_connector(instance)
4629                     self.volume_api.terminate_connection(context,
4630                                                          bdm.volume_id,
4631                                                          connector)
4632 
4633     @staticmethod
4634     def _set_instance_info(instance, instance_type):
4635         instance.instance_type_id = instance_type.id
4636         instance.memory_mb = instance_type.memory_mb
4637         instance.vcpus = instance_type.vcpus
4638         instance.root_gb = instance_type.root_gb
4639         instance.ephemeral_gb = instance_type.ephemeral_gb
4640         instance.flavor = instance_type
4641 
4642     def _update_volume_attachments(self, context, instance, bdms):
4643         """Updates volume attachments using the virt driver host connector.
4644 
4645         :param context: nova.context.RequestContext - user request context
4646         :param instance: nova.objects.Instance
4647         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4648                      device mappings for the given instance
4649         """
4650         if bdms:
4651             connector = None
4652             for bdm in bdms:
4653                 if bdm.is_volume and bdm.attachment_id:
4654                     if connector is None:
4655                         connector = self.driver.get_volume_connector(instance)
4656                     self.volume_api.attachment_update(
4657                         context, bdm.attachment_id, connector, bdm.device_name)
4658 
4659     def _complete_volume_attachments(self, context, bdms):
4660         """Completes volume attachments for the instance
4661 
4662         :param context: nova.context.RequestContext - user request context
4663         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4664                      device mappings for the given instance
4665         """
4666         if bdms:
4667             for bdm in bdms:
4668                 if bdm.is_volume and bdm.attachment_id:
4669                     self.volume_api.attachment_complete(
4670                         context, bdm.attachment_id)
4671 
4672     def _finish_resize(self, context, instance, migration, disk_info,
4673                        image_meta, bdms):
4674         resize_instance = False  # indicates disks have been resized
4675         old_instance_type_id = migration['old_instance_type_id']
4676         new_instance_type_id = migration['new_instance_type_id']
4677         old_flavor = instance.flavor  # the current flavor is now old
4678         # NOTE(mriedem): Get the old_vm_state so we know if we should
4679         # power on the instance. If old_vm_state is not set we need to default
4680         # to ACTIVE for backwards compatibility
4681         old_vm_state = instance.system_metadata.get('old_vm_state',
4682                                                     vm_states.ACTIVE)
4683         instance.old_flavor = old_flavor
4684 
4685         if old_instance_type_id != new_instance_type_id:
4686             new_flavor = instance.new_flavor  # this is set in _prep_resize
4687             # Set the flavor-related fields on the instance object including
4688             # making instance.flavor = new_flavor.
4689             self._set_instance_info(instance, new_flavor)
4690             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4691                 if old_flavor[key] != new_flavor[key]:
4692                     resize_instance = True
4693                     break
4694         instance.apply_migration_context()
4695 
4696         # NOTE(tr3buchet): setup networks on destination host
4697         self.network_api.setup_networks_on_host(context, instance,
4698                                                 migration.dest_compute)
4699         # For neutron, migrate_instance_finish updates port bindings for this
4700         # host including any PCI devices claimed for SR-IOV ports.
4701         self.network_api.migrate_instance_finish(context,
4702                                                  instance,
4703                                                  migration)
4704 
4705         network_info = self.network_api.get_instance_nw_info(context, instance)
4706 
4707         instance.task_state = task_states.RESIZE_FINISH
4708         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4709 
4710         self._send_finish_resize_notifications(
4711             context, instance, bdms, network_info,
4712             fields.NotificationPhase.START)
4713 
4714         # We need to update any volume attachments using the destination
4715         # host connector so that we can update the BDM.connection_info
4716         # before calling driver.finish_migration otherwise the driver
4717         # won't know how to connect the volumes to this host.
4718         # Note that _get_instance_block_device_info with
4719         # refresh_conn_info=True will update the BDM.connection_info value
4720         # in the database so we must do this before calling that method.
4721         self._update_volume_attachments(context, instance, bdms)
4722 
4723         block_device_info = self._get_instance_block_device_info(
4724             context, instance, refresh_conn_info=True, bdms=bdms)
4725 
4726         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4727         # automatically power on the instance after it's migrated
4728         power_on = old_vm_state != vm_states.STOPPED
4729 
4730         try:
4731             self.driver.finish_migration(context, migration, instance,
4732                                          disk_info,
4733                                          network_info,
4734                                          image_meta, resize_instance,
4735                                          block_device_info, power_on)
4736         except Exception:
4737             # Note that we do not rollback port bindings to the source host
4738             # because resize_instance (on the source host) updated the
4739             # instance.host to point to *this* host (the destination host)
4740             # so the port bindings pointing at this host are correct even
4741             # though we failed to create the guest.
4742             with excutils.save_and_reraise_exception():
4743                 # If we failed to create the guest on this host, reset the
4744                 # instance flavor-related fields to the old flavor. An
4745                 # error handler like reverts_task_state will save the changes.
4746                 if old_instance_type_id != new_instance_type_id:
4747                     self._set_instance_info(instance, old_flavor)
4748 
4749         # Now complete any volume attachments that were previously updated.
4750         self._complete_volume_attachments(context, bdms)
4751 
4752         migration.status = 'finished'
4753         migration.save()
4754 
4755         instance.vm_state = vm_states.RESIZED
4756         instance.task_state = None
4757         instance.launched_at = timeutils.utcnow()
4758         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4759 
4760         return network_info
4761 
4762     @wrap_exception()
4763     @reverts_task_state
4764     @wrap_instance_event(prefix='compute')
4765     @errors_out_migration
4766     @wrap_instance_fault
4767     def finish_resize(self, context, disk_info, image, instance,
4768                       migration):
4769         """Completes the migration process.
4770 
4771         Sets up the newly transferred disk and turns on the instance at its
4772         new host machine.
4773 
4774         """
4775         try:
4776             self._finish_resize_helper(context, disk_info, image, instance,
4777                                        migration)
4778         except Exception:
4779             with excutils.save_and_reraise_exception():
4780                 self._revert_allocation(context, instance, migration)
4781 
4782     def _finish_resize_helper(self, context, disk_info, image, instance,
4783                               migration):
4784         """Completes the migration process.
4785 
4786         The caller must revert the instance's allocations if the migration
4787         process failed.
4788         """
4789         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4790             context, instance.uuid)
4791 
4792         with self._error_out_instance_on_exception(context, instance):
4793             image_meta = objects.ImageMeta.from_dict(image)
4794             network_info = self._finish_resize(context, instance, migration,
4795                                                disk_info, image_meta, bdms)
4796 
4797         # TODO(melwitt): We should clean up instance console tokens here. The
4798         # instance is on a new host and will need to establish a new console
4799         # connection.
4800         self._update_scheduler_instance_info(context, instance)
4801         self._send_finish_resize_notifications(
4802             context, instance, bdms, network_info,
4803             fields.NotificationPhase.END)
4804 
4805     def _send_finish_resize_notifications(
4806             self, context, instance, bdms, network_info, phase):
4807         """Send notifications for the finish_resize flow.
4808 
4809         :param context: nova auth request context
4810         :param instance: The instance being resized
4811         :param bdms: BlockDeviceMappingList for the BDMs associated with the
4812             instance
4813         :param network_info: NetworkInfo for the instance info cache of ports
4814         :param phase: The phase of the action (NotificationPhase enum, either
4815             ``start`` or ``end``)
4816         """
4817         # Send the legacy unversioned notification.
4818         self._notify_about_instance_usage(
4819             context, instance, "finish_resize.%s" % phase,
4820             network_info=network_info)
4821         # Send the versioned notification.
4822         compute_utils.notify_about_instance_action(
4823             context, instance, self.host,
4824             action=fields.NotificationAction.RESIZE_FINISH, phase=phase,
4825             bdms=bdms)
4826 
4827     @wrap_exception()
4828     @wrap_instance_fault
4829     def add_fixed_ip_to_instance(self, context, network_id, instance):
4830         """Calls network_api to add new fixed_ip to instance
4831         then injects the new network info and resets instance networking.
4832 
4833         """
4834         self._notify_about_instance_usage(
4835                 context, instance, "create_ip.start")
4836 
4837         network_info = self.network_api.add_fixed_ip_to_instance(context,
4838                                                                  instance,
4839                                                                  network_id)
4840         self._inject_network_info(context, instance, network_info)
4841         self.reset_network(context, instance)
4842 
4843         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4844         instance.updated_at = timeutils.utcnow()
4845         instance.save()
4846 
4847         self._notify_about_instance_usage(
4848             context, instance, "create_ip.end", network_info=network_info)
4849 
4850     @wrap_exception()
4851     @wrap_instance_fault
4852     def remove_fixed_ip_from_instance(self, context, address, instance):
4853         """Calls network_api to remove existing fixed_ip from instance
4854         by injecting the altered network info and resetting
4855         instance networking.
4856         """
4857         self._notify_about_instance_usage(
4858                 context, instance, "delete_ip.start")
4859 
4860         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4861                                                                       instance,
4862                                                                       address)
4863         self._inject_network_info(context, instance, network_info)
4864         self.reset_network(context, instance)
4865 
4866         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4867         instance.updated_at = timeutils.utcnow()
4868         instance.save()
4869 
4870         self._notify_about_instance_usage(
4871             context, instance, "delete_ip.end", network_info=network_info)
4872 
4873     @wrap_exception()
4874     @reverts_task_state
4875     @wrap_instance_event(prefix='compute')
4876     @wrap_instance_fault
4877     def pause_instance(self, context, instance):
4878         """Pause an instance on this host."""
4879         context = context.elevated()
4880         LOG.info('Pausing', instance=instance)
4881         self._notify_about_instance_usage(context, instance, 'pause.start')
4882         compute_utils.notify_about_instance_action(context, instance,
4883                self.host, action=fields.NotificationAction.PAUSE,
4884                phase=fields.NotificationPhase.START)
4885         self.driver.pause(instance)
4886         instance.power_state = self._get_power_state(context, instance)
4887         instance.vm_state = vm_states.PAUSED
4888         instance.task_state = None
4889         instance.save(expected_task_state=task_states.PAUSING)
4890         self._notify_about_instance_usage(context, instance, 'pause.end')
4891         compute_utils.notify_about_instance_action(context, instance,
4892                self.host, action=fields.NotificationAction.PAUSE,
4893                phase=fields.NotificationPhase.END)
4894 
4895     @wrap_exception()
4896     @reverts_task_state
4897     @wrap_instance_event(prefix='compute')
4898     @wrap_instance_fault
4899     def unpause_instance(self, context, instance):
4900         """Unpause a paused instance on this host."""
4901         context = context.elevated()
4902         LOG.info('Unpausing', instance=instance)
4903         self._notify_about_instance_usage(context, instance, 'unpause.start')
4904         compute_utils.notify_about_instance_action(context, instance,
4905             self.host, action=fields.NotificationAction.UNPAUSE,
4906             phase=fields.NotificationPhase.START)
4907         self.driver.unpause(instance)
4908         instance.power_state = self._get_power_state(context, instance)
4909         instance.vm_state = vm_states.ACTIVE
4910         instance.task_state = None
4911         instance.save(expected_task_state=task_states.UNPAUSING)
4912         self._notify_about_instance_usage(context, instance, 'unpause.end')
4913         compute_utils.notify_about_instance_action(context, instance,
4914             self.host, action=fields.NotificationAction.UNPAUSE,
4915             phase=fields.NotificationPhase.END)
4916 
4917     @wrap_exception()
4918     def host_power_action(self, context, action):
4919         """Reboots, shuts down or powers up the host."""
4920         return self.driver.host_power_action(action)
4921 
4922     @wrap_exception()
4923     def host_maintenance_mode(self, context, host, mode):
4924         """Start/Stop host maintenance window. On start, it triggers
4925         guest VMs evacuation.
4926         """
4927         return self.driver.host_maintenance_mode(host, mode)
4928 
4929     @wrap_exception()
4930     def set_host_enabled(self, context, enabled):
4931         """Sets the specified host's ability to accept new instances."""
4932         return self.driver.set_host_enabled(enabled)
4933 
4934     @wrap_exception()
4935     def get_host_uptime(self, context):
4936         """Returns the result of calling "uptime" on the target host."""
4937         return self.driver.get_host_uptime()
4938 
4939     @wrap_exception()
4940     @wrap_instance_fault
4941     def get_diagnostics(self, context, instance):
4942         """Retrieve diagnostics for an instance on this host."""
4943         current_power_state = self._get_power_state(context, instance)
4944         if current_power_state == power_state.RUNNING:
4945             LOG.info("Retrieving diagnostics", instance=instance)
4946             return self.driver.get_diagnostics(instance)
4947         else:
4948             raise exception.InstanceInvalidState(
4949                 attr='power state',
4950                 instance_uuid=instance.uuid,
4951                 state=power_state.STATE_MAP[instance.power_state],
4952                 method='get_diagnostics')
4953 
4954     @wrap_exception()
4955     @wrap_instance_fault
4956     def get_instance_diagnostics(self, context, instance):
4957         """Retrieve diagnostics for an instance on this host."""
4958         current_power_state = self._get_power_state(context, instance)
4959         if current_power_state == power_state.RUNNING:
4960             LOG.info("Retrieving diagnostics", instance=instance)
4961             return self.driver.get_instance_diagnostics(instance)
4962         else:
4963             raise exception.InstanceInvalidState(
4964                 attr='power state',
4965                 instance_uuid=instance.uuid,
4966                 state=power_state.STATE_MAP[instance.power_state],
4967                 method='get_diagnostics')
4968 
4969     @wrap_exception()
4970     @reverts_task_state
4971     @wrap_instance_event(prefix='compute')
4972     @wrap_instance_fault
4973     def suspend_instance(self, context, instance):
4974         """Suspend the given instance."""
4975         context = context.elevated()
4976 
4977         # Store the old state
4978         instance.system_metadata['old_vm_state'] = instance.vm_state
4979         self._notify_about_instance_usage(context, instance, 'suspend.start')
4980         compute_utils.notify_about_instance_action(context, instance,
4981                 self.host, action=fields.NotificationAction.SUSPEND,
4982                 phase=fields.NotificationPhase.START)
4983         with self._error_out_instance_on_exception(context, instance,
4984              instance_state=instance.vm_state):
4985             self.driver.suspend(context, instance)
4986         instance.power_state = self._get_power_state(context, instance)
4987         instance.vm_state = vm_states.SUSPENDED
4988         instance.task_state = None
4989         instance.save(expected_task_state=task_states.SUSPENDING)
4990         self._notify_about_instance_usage(context, instance, 'suspend.end')
4991         compute_utils.notify_about_instance_action(context, instance,
4992                 self.host, action=fields.NotificationAction.SUSPEND,
4993                 phase=fields.NotificationPhase.END)
4994 
4995     @wrap_exception()
4996     @reverts_task_state
4997     @wrap_instance_event(prefix='compute')
4998     @wrap_instance_fault
4999     def resume_instance(self, context, instance):
5000         """Resume the given suspended instance."""
5001         context = context.elevated()
5002         LOG.info('Resuming', instance=instance)
5003 
5004         self._notify_about_instance_usage(context, instance, 'resume.start')
5005 
5006         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5007             context, instance.uuid)
5008         block_device_info = self._get_instance_block_device_info(
5009             context, instance, bdms=bdms)
5010 
5011         compute_utils.notify_about_instance_action(context, instance,
5012             self.host, action=fields.NotificationAction.RESUME,
5013             phase=fields.NotificationPhase.START, bdms=bdms)
5014 
5015         network_info = self.network_api.get_instance_nw_info(context, instance)
5016 
5017         with self._error_out_instance_on_exception(context, instance,
5018              instance_state=instance.vm_state):
5019             self.driver.resume(context, instance, network_info,
5020                                block_device_info)
5021 
5022         instance.power_state = self._get_power_state(context, instance)
5023 
5024         # We default to the ACTIVE state for backwards compatibility
5025         instance.vm_state = instance.system_metadata.pop('old_vm_state',
5026                                                          vm_states.ACTIVE)
5027 
5028         instance.task_state = None
5029         instance.save(expected_task_state=task_states.RESUMING)
5030         self._notify_about_instance_usage(context, instance, 'resume.end')
5031         compute_utils.notify_about_instance_action(context, instance,
5032             self.host, action=fields.NotificationAction.RESUME,
5033             phase=fields.NotificationPhase.END, bdms=bdms)
5034 
5035     @wrap_exception()
5036     @reverts_task_state
5037     @wrap_instance_event(prefix='compute')
5038     @wrap_instance_fault
5039     def shelve_instance(self, context, instance, image_id,
5040                         clean_shutdown):
5041         """Shelve an instance.
5042 
5043         This should be used when you want to take a snapshot of the instance.
5044         It also adds system_metadata that can be used by a periodic task to
5045         offload the shelved instance after a period of time.
5046 
5047         :param context: request context
5048         :param instance: an Instance object
5049         :param image_id: an image id to snapshot to.
5050         :param clean_shutdown: give the GuestOS a chance to stop
5051         """
5052 
5053         @utils.synchronized(instance.uuid)
5054         def do_shelve_instance():
5055             self._shelve_instance(context, instance, image_id, clean_shutdown)
5056         do_shelve_instance()
5057 
5058     def _shelve_instance(self, context, instance, image_id,
5059                          clean_shutdown):
5060         LOG.info('Shelving', instance=instance)
5061         offload = CONF.shelved_offload_time == 0
5062         if offload:
5063             # Get the BDMs early so we can pass them into versioned
5064             # notifications since _shelve_offload_instance needs the
5065             # BDMs anyway.
5066             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5067                 context, instance.uuid)
5068         else:
5069             bdms = None
5070         compute_utils.notify_usage_exists(self.notifier, context, instance,
5071                                           self.host, current_period=True)
5072         self._notify_about_instance_usage(context, instance, 'shelve.start')
5073         compute_utils.notify_about_instance_action(context, instance,
5074                 self.host, action=fields.NotificationAction.SHELVE,
5075                 phase=fields.NotificationPhase.START, bdms=bdms)
5076 
5077         def update_task_state(task_state, expected_state=task_states.SHELVING):
5078             shelving_state_map = {
5079                     task_states.IMAGE_PENDING_UPLOAD:
5080                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
5081                     task_states.IMAGE_UPLOADING:
5082                         task_states.SHELVING_IMAGE_UPLOADING,
5083                     task_states.SHELVING: task_states.SHELVING}
5084             task_state = shelving_state_map[task_state]
5085             expected_state = shelving_state_map[expected_state]
5086             instance.task_state = task_state
5087             instance.save(expected_task_state=expected_state)
5088         # Do not attempt a clean shutdown of a paused guest since some
5089         # hypervisors will fail the clean shutdown if the guest is not
5090         # running.
5091         if instance.power_state == power_state.PAUSED:
5092             clean_shutdown = False
5093         self._power_off_instance(context, instance, clean_shutdown)
5094         self.driver.snapshot(context, instance, image_id, update_task_state)
5095 
5096         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
5097         instance.system_metadata['shelved_image_id'] = image_id
5098         instance.system_metadata['shelved_host'] = self.host
5099         instance.vm_state = vm_states.SHELVED
5100         instance.task_state = None
5101         if CONF.shelved_offload_time == 0:
5102             instance.task_state = task_states.SHELVING_OFFLOADING
5103         instance.power_state = self._get_power_state(context, instance)
5104         instance.save(expected_task_state=[
5105                 task_states.SHELVING,
5106                 task_states.SHELVING_IMAGE_UPLOADING])
5107 
5108         self._notify_about_instance_usage(context, instance, 'shelve.end')
5109         compute_utils.notify_about_instance_action(context, instance,
5110                 self.host, action=fields.NotificationAction.SHELVE,
5111                 phase=fields.NotificationPhase.END, bdms=bdms)
5112 
5113         if offload:
5114             self._shelve_offload_instance(context, instance,
5115                                           clean_shutdown=False, bdms=bdms)
5116 
5117     @wrap_exception()
5118     @reverts_task_state
5119     @wrap_instance_event(prefix='compute')
5120     @wrap_instance_fault
5121     def shelve_offload_instance(self, context, instance, clean_shutdown):
5122         """Remove a shelved instance from the hypervisor.
5123 
5124         This frees up those resources for use by other instances, but may lead
5125         to slower unshelve times for this instance.  This method is used by
5126         volume backed instances since restoring them doesn't involve the
5127         potentially large download of an image.
5128 
5129         :param context: request context
5130         :param instance: nova.objects.instance.Instance
5131         :param clean_shutdown: give the GuestOS a chance to stop
5132         """
5133 
5134         @utils.synchronized(instance.uuid)
5135         def do_shelve_offload_instance():
5136             self._shelve_offload_instance(context, instance, clean_shutdown)
5137         do_shelve_offload_instance()
5138 
5139     def _shelve_offload_instance(self, context, instance, clean_shutdown,
5140                                  bdms=None):
5141         LOG.info('Shelve offloading', instance=instance)
5142         if bdms is None:
5143             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5144                 context, instance.uuid)
5145         self._notify_about_instance_usage(context, instance,
5146                 'shelve_offload.start')
5147         compute_utils.notify_about_instance_action(context, instance,
5148                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
5149                 phase=fields.NotificationPhase.START, bdms=bdms)
5150 
5151         self._power_off_instance(context, instance, clean_shutdown)
5152         current_power_state = self._get_power_state(context, instance)
5153 
5154         self.network_api.cleanup_instance_network_on_host(context, instance,
5155                                                           instance.host)
5156         network_info = self.network_api.get_instance_nw_info(context, instance)
5157 
5158         block_device_info = self._get_instance_block_device_info(context,
5159                                                                  instance,
5160                                                                  bdms=bdms)
5161         self.driver.destroy(context, instance, network_info,
5162                 block_device_info)
5163 
5164         # the instance is going to be removed from the host so we want to
5165         # terminate all the connections with the volume server and the host
5166         self._terminate_volume_connections(context, instance, bdms)
5167 
5168         # Free up the resource allocations in the placement service.
5169         # This should happen *before* the vm_state is changed to
5170         # SHELVED_OFFLOADED in case client-side code is polling the API to
5171         # schedule more instances (or unshelve) once this server is offloaded.
5172         self.rt.delete_allocation_for_shelve_offloaded_instance(context,
5173                                                                 instance)
5174 
5175         instance.power_state = current_power_state
5176         # NOTE(mriedem): The vm_state has to be set before updating the
5177         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
5178         # values cannot be nulled out until after updating the resource tracker
5179         # though.
5180         instance.vm_state = vm_states.SHELVED_OFFLOADED
5181         instance.task_state = None
5182         instance.save(expected_task_state=[task_states.SHELVING,
5183                                            task_states.SHELVING_OFFLOADING])
5184 
5185         # NOTE(ndipanov): Free resources from the resource tracker
5186         self._update_resource_tracker(context, instance)
5187 
5188         # NOTE(sfinucan): RPC calls should no longer be attempted against this
5189         # instance, so ensure any calls result in errors
5190         self._nil_out_instance_obj_host_and_node(instance)
5191         instance.save(expected_task_state=None)
5192 
5193         # TODO(melwitt): We should clean up instance console tokens here. The
5194         # instance has no host at this point and will need to establish a new
5195         # console connection in the future after it is unshelved.
5196         self._delete_scheduler_instance_info(context, instance.uuid)
5197         self._notify_about_instance_usage(context, instance,
5198                 'shelve_offload.end')
5199         compute_utils.notify_about_instance_action(context, instance,
5200                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
5201                 phase=fields.NotificationPhase.END, bdms=bdms)
5202 
5203     @wrap_exception()
5204     @reverts_task_state
5205     @wrap_instance_event(prefix='compute')
5206     @wrap_instance_fault
5207     def unshelve_instance(self, context, instance, image,
5208                           filter_properties, node):
5209         """Unshelve the instance.
5210 
5211         :param context: request context
5212         :param instance: a nova.objects.instance.Instance object
5213         :param image: an image to build from.  If None we assume a
5214             volume backed instance.
5215         :param filter_properties: dict containing limits, retry info etc.
5216         :param node: target compute node
5217         """
5218         if filter_properties is None:
5219             filter_properties = {}
5220 
5221         @utils.synchronized(instance.uuid)
5222         def do_unshelve_instance():
5223             self._unshelve_instance(context, instance, image,
5224                                     filter_properties, node)
5225         do_unshelve_instance()
5226 
5227     def _unshelve_instance_key_scrub(self, instance):
5228         """Remove data from the instance that may cause side effects."""
5229         cleaned_keys = dict(
5230                 key_data=instance.key_data,
5231                 auto_disk_config=instance.auto_disk_config)
5232         instance.key_data = None
5233         instance.auto_disk_config = False
5234         return cleaned_keys
5235 
5236     def _unshelve_instance_key_restore(self, instance, keys):
5237         """Restore previously scrubbed keys before saving the instance."""
5238         instance.update(keys)
5239 
5240     def _unshelve_instance(self, context, instance, image, filter_properties,
5241                            node):
5242         LOG.info('Unshelving', instance=instance)
5243         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5244                 context, instance.uuid)
5245 
5246         self._notify_about_instance_usage(context, instance, 'unshelve.start')
5247         compute_utils.notify_about_instance_action(context, instance,
5248                 self.host, action=fields.NotificationAction.UNSHELVE,
5249                 phase=fields.NotificationPhase.START, bdms=bdms)
5250 
5251         instance.task_state = task_states.SPAWNING
5252         instance.save()
5253 
5254         block_device_info = self._prep_block_device(context, instance, bdms)
5255         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
5256 
5257         if node is None:
5258             node = self._get_nodename(instance)
5259 
5260         limits = filter_properties.get('limits', {})
5261 
5262         allocations = self.reportclient.get_allocations_for_consumer(
5263             context, instance.uuid)
5264 
5265         shelved_image_ref = instance.image_ref
5266         if image:
5267             instance.image_ref = image['id']
5268             image_meta = objects.ImageMeta.from_dict(image)
5269         else:
5270             image_meta = objects.ImageMeta.from_dict(
5271                 utils.get_image_from_system_metadata(
5272                     instance.system_metadata))
5273 
5274         self.network_api.setup_instance_network_on_host(context, instance,
5275                                                         self.host)
5276         network_info = self.network_api.get_instance_nw_info(context, instance)
5277         try:
5278             with self.rt.instance_claim(context, instance, node, limits):
5279                 self.driver.spawn(context, instance, image_meta,
5280                                   injected_files=[],
5281                                   admin_password=None,
5282                                   allocations=allocations,
5283                                   network_info=network_info,
5284                                   block_device_info=block_device_info)
5285         except Exception:
5286             with excutils.save_and_reraise_exception(logger=LOG):
5287                 LOG.exception('Instance failed to spawn',
5288                               instance=instance)
5289                 # Cleanup allocations created by the scheduler on this host
5290                 # since we failed to spawn the instance. We do this both if
5291                 # the instance claim failed with ComputeResourcesUnavailable
5292                 # or if we did claim but the spawn failed, because aborting the
5293                 # instance claim will not remove the allocations.
5294                 self.reportclient.delete_allocation_for_instance(context,
5295                                                                  instance.uuid)
5296                 # FIXME: Umm, shouldn't we be rolling back port bindings too?
5297                 self._terminate_volume_connections(context, instance, bdms)
5298                 # The reverts_task_state decorator on unshelve_instance will
5299                 # eventually save these updates.
5300                 self._nil_out_instance_obj_host_and_node(instance)
5301 
5302         if image:
5303             instance.image_ref = shelved_image_ref
5304             self._delete_snapshot_of_shelved_instance(context, instance,
5305                                                       image['id'])
5306 
5307         self._unshelve_instance_key_restore(instance, scrubbed_keys)
5308         self._update_instance_after_spawn(context, instance)
5309         # Delete system_metadata for a shelved instance
5310         compute_utils.remove_shelved_keys_from_system_metadata(instance)
5311 
5312         instance.save(expected_task_state=task_states.SPAWNING)
5313         self._update_scheduler_instance_info(context, instance)
5314         self._notify_about_instance_usage(context, instance, 'unshelve.end')
5315         compute_utils.notify_about_instance_action(context, instance,
5316                 self.host, action=fields.NotificationAction.UNSHELVE,
5317                 phase=fields.NotificationPhase.END, bdms=bdms)
5318 
5319     @messaging.expected_exceptions(NotImplementedError)
5320     @wrap_instance_fault
5321     def reset_network(self, context, instance):
5322         """Reset networking on the given instance."""
5323         LOG.debug('Reset network', instance=instance)
5324         self.driver.reset_network(instance)
5325 
5326     def _inject_network_info(self, context, instance, network_info):
5327         """Inject network info for the given instance."""
5328         LOG.debug('Inject network info', instance=instance)
5329         LOG.debug('network_info to inject: |%s|', network_info,
5330                   instance=instance)
5331 
5332         self.driver.inject_network_info(instance,
5333                                         network_info)
5334 
5335     @wrap_instance_fault
5336     def inject_network_info(self, context, instance):
5337         """Inject network info, but don't return the info."""
5338         network_info = self.network_api.get_instance_nw_info(context, instance)
5339         self._inject_network_info(context, instance, network_info)
5340 
5341     @messaging.expected_exceptions(NotImplementedError,
5342                                    exception.ConsoleNotAvailable,
5343                                    exception.InstanceNotFound)
5344     @wrap_exception()
5345     @wrap_instance_fault
5346     def get_console_output(self, context, instance, tail_length):
5347         """Send the console output for the given instance."""
5348         context = context.elevated()
5349         LOG.info("Get console output", instance=instance)
5350         output = self.driver.get_console_output(context, instance)
5351 
5352         if type(output) is six.text_type:
5353             output = six.b(output)
5354 
5355         if tail_length is not None:
5356             output = self._tail_log(output, tail_length)
5357 
5358         return output.decode('ascii', 'replace')
5359 
5360     def _tail_log(self, log, length):
5361         try:
5362             length = int(length)
5363         except ValueError:
5364             length = 0
5365 
5366         if length == 0:
5367             return b''
5368         else:
5369             return b'\n'.join(log.split(b'\n')[-int(length):])
5370 
5371     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5372                                    exception.InstanceNotReady,
5373                                    exception.InstanceNotFound,
5374                                    exception.ConsoleTypeUnavailable,
5375                                    NotImplementedError)
5376     @wrap_exception()
5377     @wrap_instance_fault
5378     def get_vnc_console(self, context, console_type, instance):
5379         """Return connection information for a vnc console."""
5380         context = context.elevated()
5381         LOG.debug("Getting vnc console", instance=instance)
5382 
5383         if not CONF.vnc.enabled:
5384             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5385 
5386         if console_type == 'novnc':
5387             # For essex, novncproxy_base_url must include the full path
5388             # including the html file (like http://myhost/vnc_auto.html)
5389             access_url_base = CONF.vnc.novncproxy_base_url
5390         elif console_type == 'xvpvnc':
5391             access_url_base = CONF.vnc.xvpvncproxy_base_url
5392         else:
5393             raise exception.ConsoleTypeInvalid(console_type=console_type)
5394 
5395         try:
5396             # Retrieve connect info from driver, and then decorate with our
5397             # access info token
5398             console = self.driver.get_vnc_console(context, instance)
5399             console_auth = objects.ConsoleAuthToken(
5400                 context=context,
5401                 console_type=console_type,
5402                 host=console.host,
5403                 port=console.port,
5404                 internal_access_path=console.internal_access_path,
5405                 instance_uuid=instance.uuid,
5406                 access_url_base=access_url_base,
5407             )
5408             console_auth.authorize(CONF.consoleauth.token_ttl)
5409             connect_info = console.get_connection_info(
5410                 console_auth.token, console_auth.access_url)
5411 
5412         except exception.InstanceNotFound:
5413             if instance.vm_state != vm_states.BUILDING:
5414                 raise
5415             raise exception.InstanceNotReady(instance_id=instance.uuid)
5416 
5417         return connect_info
5418 
5419     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5420                                    exception.InstanceNotReady,
5421                                    exception.InstanceNotFound,
5422                                    exception.ConsoleTypeUnavailable,
5423                                    NotImplementedError)
5424     @wrap_exception()
5425     @wrap_instance_fault
5426     def get_spice_console(self, context, console_type, instance):
5427         """Return connection information for a spice console."""
5428         context = context.elevated()
5429         LOG.debug("Getting spice console", instance=instance)
5430 
5431         if not CONF.spice.enabled:
5432             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5433 
5434         if console_type != 'spice-html5':
5435             raise exception.ConsoleTypeInvalid(console_type=console_type)
5436 
5437         try:
5438             # Retrieve connect info from driver, and then decorate with our
5439             # access info token
5440             console = self.driver.get_spice_console(context, instance)
5441             console_auth = objects.ConsoleAuthToken(
5442                 context=context,
5443                 console_type=console_type,
5444                 host=console.host,
5445                 port=console.port,
5446                 internal_access_path=console.internal_access_path,
5447                 instance_uuid=instance.uuid,
5448                 access_url_base=CONF.spice.html5proxy_base_url,
5449             )
5450             console_auth.authorize(CONF.consoleauth.token_ttl)
5451             connect_info = console.get_connection_info(
5452                 console_auth.token, console_auth.access_url)
5453 
5454         except exception.InstanceNotFound:
5455             if instance.vm_state != vm_states.BUILDING:
5456                 raise
5457             raise exception.InstanceNotReady(instance_id=instance.uuid)
5458 
5459         return connect_info
5460 
5461     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5462                                    exception.InstanceNotReady,
5463                                    exception.InstanceNotFound,
5464                                    exception.ConsoleTypeUnavailable,
5465                                    NotImplementedError)
5466     @wrap_exception()
5467     @wrap_instance_fault
5468     def get_rdp_console(self, context, console_type, instance):
5469         """Return connection information for a RDP console."""
5470         context = context.elevated()
5471         LOG.debug("Getting RDP console", instance=instance)
5472 
5473         if not CONF.rdp.enabled:
5474             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5475 
5476         if console_type != 'rdp-html5':
5477             raise exception.ConsoleTypeInvalid(console_type=console_type)
5478 
5479         try:
5480             # Retrieve connect info from driver, and then decorate with our
5481             # access info token
5482             console = self.driver.get_rdp_console(context, instance)
5483             console_auth = objects.ConsoleAuthToken(
5484                 context=context,
5485                 console_type=console_type,
5486                 host=console.host,
5487                 port=console.port,
5488                 internal_access_path=console.internal_access_path,
5489                 instance_uuid=instance.uuid,
5490                 access_url_base=CONF.rdp.html5_proxy_base_url,
5491             )
5492             console_auth.authorize(CONF.consoleauth.token_ttl)
5493             connect_info = console.get_connection_info(
5494                 console_auth.token, console_auth.access_url)
5495 
5496         except exception.InstanceNotFound:
5497             if instance.vm_state != vm_states.BUILDING:
5498                 raise
5499             raise exception.InstanceNotReady(instance_id=instance.uuid)
5500 
5501         return connect_info
5502 
5503     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5504                                    exception.InstanceNotReady,
5505                                    exception.InstanceNotFound,
5506                                    exception.ConsoleTypeUnavailable,
5507                                    NotImplementedError)
5508     @wrap_exception()
5509     @wrap_instance_fault
5510     def get_mks_console(self, context, console_type, instance):
5511         """Return connection information for a MKS console."""
5512         context = context.elevated()
5513         LOG.debug("Getting MKS console", instance=instance)
5514 
5515         if not CONF.mks.enabled:
5516             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5517 
5518         if console_type != 'webmks':
5519             raise exception.ConsoleTypeInvalid(console_type=console_type)
5520 
5521         try:
5522             # Retrieve connect info from driver, and then decorate with our
5523             # access info token
5524             console = self.driver.get_mks_console(context, instance)
5525             console_auth = objects.ConsoleAuthToken(
5526                 context=context,
5527                 console_type=console_type,
5528                 host=console.host,
5529                 port=console.port,
5530                 internal_access_path=console.internal_access_path,
5531                 instance_uuid=instance.uuid,
5532                 access_url_base=CONF.mks.mksproxy_base_url,
5533             )
5534             console_auth.authorize(CONF.consoleauth.token_ttl)
5535             connect_info = console.get_connection_info(
5536                 console_auth.token, console_auth.access_url)
5537 
5538         except exception.InstanceNotFound:
5539             if instance.vm_state != vm_states.BUILDING:
5540                 raise
5541             raise exception.InstanceNotReady(instance_id=instance.uuid)
5542 
5543         return connect_info
5544 
5545     @messaging.expected_exceptions(
5546         exception.ConsoleTypeInvalid,
5547         exception.InstanceNotReady,
5548         exception.InstanceNotFound,
5549         exception.ConsoleTypeUnavailable,
5550         exception.SocketPortRangeExhaustedException,
5551         exception.ImageSerialPortNumberInvalid,
5552         exception.ImageSerialPortNumberExceedFlavorValue,
5553         NotImplementedError)
5554     @wrap_exception()
5555     @wrap_instance_fault
5556     def get_serial_console(self, context, console_type, instance):
5557         """Returns connection information for a serial console."""
5558 
5559         LOG.debug("Getting serial console", instance=instance)
5560 
5561         if not CONF.serial_console.enabled:
5562             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5563 
5564         context = context.elevated()
5565 
5566         try:
5567             # Retrieve connect info from driver, and then decorate with our
5568             # access info token
5569             console = self.driver.get_serial_console(context, instance)
5570             console_auth = objects.ConsoleAuthToken(
5571                 context=context,
5572                 console_type=console_type,
5573                 host=console.host,
5574                 port=console.port,
5575                 internal_access_path=console.internal_access_path,
5576                 instance_uuid=instance.uuid,
5577                 access_url_base=CONF.serial_console.base_url,
5578             )
5579             console_auth.authorize(CONF.consoleauth.token_ttl)
5580             connect_info = console.get_connection_info(
5581                 console_auth.token, console_auth.access_url)
5582 
5583         except exception.InstanceNotFound:
5584             if instance.vm_state != vm_states.BUILDING:
5585                 raise
5586             raise exception.InstanceNotReady(instance_id=instance.uuid)
5587 
5588         return connect_info
5589 
5590     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5591                                    exception.InstanceNotReady,
5592                                    exception.InstanceNotFound)
5593     @wrap_exception()
5594     @wrap_instance_fault
5595     def validate_console_port(self, ctxt, instance, port, console_type):
5596         if console_type == "spice-html5":
5597             console_info = self.driver.get_spice_console(ctxt, instance)
5598         elif console_type == "rdp-html5":
5599             console_info = self.driver.get_rdp_console(ctxt, instance)
5600         elif console_type == "serial":
5601             console_info = self.driver.get_serial_console(ctxt, instance)
5602         elif console_type == "webmks":
5603             console_info = self.driver.get_mks_console(ctxt, instance)
5604         else:
5605             console_info = self.driver.get_vnc_console(ctxt, instance)
5606 
5607         # Some drivers may return an int on console_info.port but the port
5608         # variable in this method is a string, so cast to be sure we are
5609         # comparing the correct types.
5610         return str(console_info.port) == port
5611 
5612     @wrap_exception()
5613     @reverts_task_state
5614     @wrap_instance_fault
5615     def reserve_block_device_name(self, context, instance, device,
5616                                   volume_id, disk_bus, device_type, tag,
5617                                   multiattach):
5618         if (tag and not
5619                 self.driver.capabilities.get('supports_tagged_attach_volume',
5620                                              False)):
5621             raise exception.VolumeTaggedAttachNotSupported()
5622 
5623         if (multiattach and not
5624                 self.driver.capabilities.get('supports_multiattach', False)):
5625             raise exception.MultiattachNotSupportedByVirtDriver(
5626                 volume_id=volume_id)
5627 
5628         @utils.synchronized(instance.uuid)
5629         def do_reserve():
5630             bdms = (
5631                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5632                     context, instance.uuid))
5633 
5634             # NOTE(ndipanov): We need to explicitly set all the fields on the
5635             #                 object so that obj_load_attr does not fail
5636             new_bdm = objects.BlockDeviceMapping(
5637                     context=context,
5638                     source_type='volume', destination_type='volume',
5639                     instance_uuid=instance.uuid, boot_index=None,
5640                     volume_id=volume_id,
5641                     device_name=device, guest_format=None,
5642                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5643 
5644             new_bdm.device_name = self._get_device_name_for_instance(
5645                     instance, bdms, new_bdm)
5646 
5647             # NOTE(vish): create bdm here to avoid race condition
5648             new_bdm.create()
5649             return new_bdm
5650 
5651         return do_reserve()
5652 
5653     @wrap_exception()
5654     @wrap_instance_event(prefix='compute')
5655     @wrap_instance_fault
5656     def attach_volume(self, context, instance, bdm):
5657         """Attach a volume to an instance."""
5658         driver_bdm = driver_block_device.convert_volume(bdm)
5659 
5660         @utils.synchronized(instance.uuid)
5661         def do_attach_volume(context, instance, driver_bdm):
5662             try:
5663                 return self._attach_volume(context, instance, driver_bdm)
5664             except Exception:
5665                 with excutils.save_and_reraise_exception():
5666                     bdm.destroy()
5667 
5668         do_attach_volume(context, instance, driver_bdm)
5669 
5670     def _attach_volume(self, context, instance, bdm):
5671         context = context.elevated()
5672         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5673                  {'volume_id': bdm.volume_id,
5674                   'mountpoint': bdm['mount_device']},
5675                  instance=instance)
5676         compute_utils.notify_about_volume_attach_detach(
5677             context, instance, self.host,
5678             action=fields.NotificationAction.VOLUME_ATTACH,
5679             phase=fields.NotificationPhase.START,
5680             volume_id=bdm.volume_id)
5681         try:
5682             bdm.attach(context, instance, self.volume_api, self.driver,
5683                        do_driver_attach=True)
5684         except Exception as e:
5685             with excutils.save_and_reraise_exception():
5686                 LOG.exception("Failed to attach %(volume_id)s "
5687                               "at %(mountpoint)s",
5688                               {'volume_id': bdm.volume_id,
5689                                'mountpoint': bdm['mount_device']},
5690                               instance=instance)
5691                 if bdm['attachment_id']:
5692                     # Try to delete the attachment to make the volume
5693                     # available again. Note that DriverVolumeBlockDevice
5694                     # may have already deleted the attachment so ignore
5695                     # VolumeAttachmentNotFound.
5696                     try:
5697                         self.volume_api.attachment_delete(
5698                             context, bdm['attachment_id'])
5699                     except exception.VolumeAttachmentNotFound as exc:
5700                         LOG.debug('Ignoring VolumeAttachmentNotFound: %s',
5701                                   exc, instance=instance)
5702                 else:
5703                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5704                 tb = traceback.format_exc()
5705                 compute_utils.notify_about_volume_attach_detach(
5706                     context, instance, self.host,
5707                     action=fields.NotificationAction.VOLUME_ATTACH,
5708                     phase=fields.NotificationPhase.ERROR,
5709                     exception=e,
5710                     volume_id=bdm.volume_id, tb=tb)
5711 
5712         info = {'volume_id': bdm.volume_id}
5713         self._notify_about_instance_usage(
5714             context, instance, "volume.attach", extra_usage_info=info)
5715         compute_utils.notify_about_volume_attach_detach(
5716             context, instance, self.host,
5717             action=fields.NotificationAction.VOLUME_ATTACH,
5718             phase=fields.NotificationPhase.END,
5719             volume_id=bdm.volume_id)
5720 
5721     def _notify_volume_usage_detach(self, context, instance, bdm):
5722         if CONF.volume_usage_poll_interval <= 0:
5723             return
5724 
5725         mp = bdm.device_name
5726         # Handle bootable volumes which will not contain /dev/
5727         if '/dev/' in mp:
5728             mp = mp[5:]
5729         try:
5730             vol_stats = self.driver.block_stats(instance, mp)
5731             if vol_stats is None:
5732                 return
5733         except NotImplementedError:
5734             return
5735 
5736         LOG.debug("Updating volume usage cache with totals", instance=instance)
5737         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5738         vol_usage = objects.VolumeUsage(context)
5739         vol_usage.volume_id = bdm.volume_id
5740         vol_usage.instance_uuid = instance.uuid
5741         vol_usage.project_id = instance.project_id
5742         vol_usage.user_id = instance.user_id
5743         vol_usage.availability_zone = instance.availability_zone
5744         vol_usage.curr_reads = rd_req
5745         vol_usage.curr_read_bytes = rd_bytes
5746         vol_usage.curr_writes = wr_req
5747         vol_usage.curr_write_bytes = wr_bytes
5748         vol_usage.save(update_totals=True)
5749         self.notifier.info(context, 'volume.usage', vol_usage.to_dict())
5750         compute_utils.notify_about_volume_usage(context, vol_usage, self.host)
5751 
5752     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5753                        attachment_id=None):
5754         """Detach a volume from an instance.
5755 
5756         :param context: security context
5757         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5758         :param instance: the Instance object to detach the volume from
5759         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5760                             as deleted. Disabling this is useful for operations
5761                             like rebuild, when we don't want to destroy BDM
5762         :param attachment_id: The volume attachment_id for the given instance
5763                               and volume.
5764         """
5765         volume_id = bdm.volume_id
5766         compute_utils.notify_about_volume_attach_detach(
5767             context, instance, self.host,
5768             action=fields.NotificationAction.VOLUME_DETACH,
5769             phase=fields.NotificationPhase.START,
5770             volume_id=volume_id)
5771 
5772         self._notify_volume_usage_detach(context, instance, bdm)
5773 
5774         LOG.info('Detaching volume %(volume_id)s',
5775                  {'volume_id': volume_id}, instance=instance)
5776 
5777         driver_bdm = driver_block_device.convert_volume(bdm)
5778         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5779                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5780 
5781         info = dict(volume_id=volume_id)
5782         self._notify_about_instance_usage(
5783             context, instance, "volume.detach", extra_usage_info=info)
5784         compute_utils.notify_about_volume_attach_detach(
5785             context, instance, self.host,
5786             action=fields.NotificationAction.VOLUME_DETACH,
5787             phase=fields.NotificationPhase.END,
5788             volume_id=volume_id)
5789 
5790         if 'tag' in bdm and bdm.tag:
5791             self._delete_disk_metadata(instance, bdm)
5792         if destroy_bdm:
5793             bdm.destroy()
5794 
5795     def _delete_disk_metadata(self, instance, bdm):
5796         for device in instance.device_metadata.devices:
5797             if isinstance(device, objects.DiskMetadata):
5798                 if 'serial' in device:
5799                     if device.serial == bdm.volume_id:
5800                         instance.device_metadata.devices.remove(device)
5801                         instance.save()
5802                         break
5803                 else:
5804                     # NOTE(artom) We log the entire device object because all
5805                     # fields are nullable and may not be set
5806                     LOG.warning('Unable to determine whether to clean up '
5807                                 'device metadata for disk %s', device,
5808                                 instance=instance)
5809 
5810     @wrap_exception()
5811     @wrap_instance_event(prefix='compute')
5812     @wrap_instance_fault
5813     def detach_volume(self, context, volume_id, instance, attachment_id):
5814         """Detach a volume from an instance.
5815 
5816         :param context: security context
5817         :param volume_id: the volume id
5818         :param instance: the Instance object to detach the volume from
5819         :param attachment_id: The volume attachment_id for the given instance
5820                               and volume.
5821 
5822         """
5823         @utils.synchronized(instance.uuid)
5824         def do_detach_volume(context, volume_id, instance, attachment_id):
5825             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5826                     context, volume_id, instance.uuid)
5827             self._detach_volume(context, bdm, instance,
5828                                 attachment_id=attachment_id)
5829 
5830         do_detach_volume(context, volume_id, instance, attachment_id)
5831 
5832     def _init_volume_connection(self, context, new_volume,
5833                                 old_volume_id, connector, bdm,
5834                                 new_attachment_id, mountpoint):
5835         new_volume_id = new_volume['id']
5836         if new_attachment_id is None:
5837             # We're dealing with an old-style attachment so initialize the
5838             # connection so we can get the connection_info.
5839             new_cinfo = self.volume_api.initialize_connection(context,
5840                                                               new_volume_id,
5841                                                               connector)
5842         else:
5843             # Check for multiattach on the new volume and if True, check to
5844             # see if the virt driver supports multiattach.
5845             # TODO(mriedem): This is copied from DriverVolumeBlockDevice
5846             # and should be consolidated into some common code at some point.
5847             vol_multiattach = new_volume.get('multiattach', False)
5848             virt_multiattach = self.driver.capabilities.get(
5849                 'supports_multiattach', False)
5850             if vol_multiattach and not virt_multiattach:
5851                 raise exception.MultiattachNotSupportedByVirtDriver(
5852                     volume_id=new_volume_id)
5853 
5854             # This is a new style attachment and the API created the new
5855             # volume attachment and passed the id to the compute over RPC.
5856             # At this point we need to update the new volume attachment with
5857             # the host connector, which will give us back the new attachment
5858             # connection_info.
5859             new_cinfo = self.volume_api.attachment_update(
5860                 context, new_attachment_id, connector,
5861                 mountpoint)['connection_info']
5862 
5863             if vol_multiattach:
5864                 # This will be used by the volume driver to determine the
5865                 # proper disk configuration.
5866                 new_cinfo['multiattach'] = True
5867 
5868         old_cinfo = jsonutils.loads(bdm['connection_info'])
5869         if old_cinfo and 'serial' not in old_cinfo:
5870             old_cinfo['serial'] = old_volume_id
5871         # NOTE(lyarwood): serial is not always present in the returned
5872         # connection_info so set it if it is missing as we do in
5873         # DriverVolumeBlockDevice.attach().
5874         if 'serial' not in new_cinfo:
5875             new_cinfo['serial'] = new_volume_id
5876         return (old_cinfo, new_cinfo)
5877 
5878     def _swap_volume(self, context, instance, bdm, connector,
5879                      old_volume_id, new_volume, resize_to,
5880                      new_attachment_id, is_cinder_migration):
5881         new_volume_id = new_volume['id']
5882         mountpoint = bdm['device_name']
5883         failed = False
5884         new_cinfo = None
5885         try:
5886             old_cinfo, new_cinfo = self._init_volume_connection(
5887                 context, new_volume, old_volume_id, connector,
5888                 bdm, new_attachment_id, mountpoint)
5889             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5890             # currently implementing swap_volume, will modify the contents of
5891             # new_cinfo when connect_volume is called. This is then saved to
5892             # the BDM in swap_volume for future use outside of this flow.
5893             msg = ("swap_volume: Calling driver volume swap with "
5894                    "connection infos: new: %(new_cinfo)s; "
5895                    "old: %(old_cinfo)s" %
5896                    {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo})
5897             # Both new and old info might contain password
5898             LOG.debug(strutils.mask_password(msg), instance=instance)
5899 
5900             self.driver.swap_volume(context, old_cinfo, new_cinfo, instance,
5901                                     mountpoint, resize_to)
5902             if new_attachment_id:
5903                 self.volume_api.attachment_complete(context, new_attachment_id)
5904             msg = ("swap_volume: Driver volume swap returned, new "
5905                    "connection_info is now : %(new_cinfo)s" %
5906                    {'new_cinfo': new_cinfo})
5907             LOG.debug(strutils.mask_password(msg))
5908         except Exception as ex:
5909             failed = True
5910             with excutils.save_and_reraise_exception():
5911                 tb = traceback.format_exc()
5912                 compute_utils.notify_about_volume_swap(
5913                     context, instance, self.host,
5914                     fields.NotificationPhase.ERROR,
5915                     old_volume_id, new_volume_id, ex, tb)
5916                 if new_cinfo:
5917                     msg = ("Failed to swap volume %(old_volume_id)s "
5918                            "for %(new_volume_id)s")
5919                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5920                                         'new_volume_id': new_volume_id},
5921                                   instance=instance)
5922                 else:
5923                     msg = ("Failed to connect to volume %(volume_id)s "
5924                            "with volume at %(mountpoint)s")
5925                     LOG.exception(msg, {'volume_id': new_volume_id,
5926                                         'mountpoint': bdm['device_name']},
5927                                   instance=instance)
5928 
5929                 # The API marked the volume as 'detaching' for the old volume
5930                 # so we need to roll that back so the volume goes back to
5931                 # 'in-use' state.
5932                 self.volume_api.roll_detaching(context, old_volume_id)
5933 
5934                 if new_attachment_id is None:
5935                     # The API reserved the new volume so it would be in
5936                     # 'attaching' status, so we need to unreserve it so it
5937                     # goes back to 'available' status.
5938                     self.volume_api.unreserve_volume(context, new_volume_id)
5939                 else:
5940                     # This is a new style attachment for the new volume, which
5941                     # was created in the API. We just need to delete it here
5942                     # to put the new volume back into 'available' status.
5943                     self.volume_api.attachment_delete(
5944                         context, new_attachment_id)
5945         finally:
5946             # TODO(mriedem): This finally block is terribly confusing and is
5947             # trying to do too much. We should consider removing the finally
5948             # block and move whatever needs to happen on success and failure
5949             # into the blocks above for clarity, even if it means a bit of
5950             # redundant code.
5951             conn_volume = new_volume_id if failed else old_volume_id
5952             if new_cinfo:
5953                 LOG.debug("swap_volume: removing Cinder connection "
5954                           "for volume %(volume)s", {'volume': conn_volume},
5955                           instance=instance)
5956                 if bdm.attachment_id is None:
5957                     # This is the pre-3.44 flow for new-style volume
5958                     # attachments so just terminate the connection.
5959                     self.volume_api.terminate_connection(context,
5960                                                          conn_volume,
5961                                                          connector)
5962                 else:
5963                     # This is a new style volume attachment. If we failed, then
5964                     # the new attachment was already deleted above in the
5965                     # exception block and we have nothing more to do here. If
5966                     # swap_volume was successful in the driver, then we need to
5967                     # "detach" the original attachment by deleting it.
5968                     if not failed:
5969                         self.volume_api.attachment_delete(
5970                             context, bdm.attachment_id)
5971 
5972             # Need to make some decisions based on whether this was
5973             # a Cinder initiated migration or not. The callback to
5974             # migration completion isn't needed in the case of a
5975             # nova initiated simple swap of two volume
5976             # "volume-update" call so skip that. The new attachment
5977             # scenarios will give us a new attachment record and
5978             # that's what we want.
5979             if bdm.attachment_id and not is_cinder_migration:
5980                 # we don't callback to cinder
5981                 comp_ret = {'save_volume_id': new_volume_id}
5982             else:
5983                 # NOTE(lyarwood): The following call to
5984                 # os-migrate-volume-completion returns a dict containing
5985                 # save_volume_id, this volume id has two possible values :
5986                 # 1. old_volume_id if we are migrating (retyping) volumes
5987                 # 2. new_volume_id if we are swapping between two existing
5988                 #    volumes
5989                 # This volume id is later used to update the volume_id and
5990                 # connection_info['serial'] of the BDM.
5991                 comp_ret = self.volume_api.migrate_volume_completion(
5992                                                           context,
5993                                                           old_volume_id,
5994                                                           new_volume_id,
5995                                                           error=failed)
5996                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5997                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5998                           instance=instance)
5999 
6000         return (comp_ret, new_cinfo)
6001 
6002     @wrap_exception()
6003     @wrap_instance_event(prefix='compute')
6004     @wrap_instance_fault
6005     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
6006                     new_attachment_id):
6007         """Swap volume for an instance."""
6008         context = context.elevated()
6009 
6010         compute_utils.notify_about_volume_swap(
6011             context, instance, self.host,
6012             fields.NotificationPhase.START,
6013             old_volume_id, new_volume_id)
6014 
6015         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
6016                 context, old_volume_id, instance.uuid)
6017         connector = self.driver.get_volume_connector(instance)
6018 
6019         resize_to = 0
6020         old_volume = self.volume_api.get(context, old_volume_id)
6021         # Yes this is a tightly-coupled state check of what's going on inside
6022         # cinder, but we need this while we still support old (v1/v2) and
6023         # new style attachments (v3.44). Once we drop support for old style
6024         # attachments we could think about cleaning up the cinder-initiated
6025         # swap volume API flows.
6026         is_cinder_migration = False
6027         if 'migration_status' in old_volume:
6028             is_cinder_migration = old_volume['migration_status'] == 'migrating'
6029         old_vol_size = old_volume['size']
6030         new_volume = self.volume_api.get(context, new_volume_id)
6031         new_vol_size = new_volume['size']
6032         if new_vol_size > old_vol_size:
6033             resize_to = new_vol_size
6034 
6035         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
6036                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
6037                  instance=instance)
6038         comp_ret, new_cinfo = self._swap_volume(context,
6039                                                 instance,
6040                                                 bdm,
6041                                                 connector,
6042                                                 old_volume_id,
6043                                                 new_volume,
6044                                                 resize_to,
6045                                                 new_attachment_id,
6046                                                 is_cinder_migration)
6047 
6048         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
6049         # correct volume_id returned by Cinder.
6050         save_volume_id = comp_ret['save_volume_id']
6051         new_cinfo['serial'] = save_volume_id
6052         values = {
6053             'connection_info': jsonutils.dumps(new_cinfo),
6054             'source_type': 'volume',
6055             'destination_type': 'volume',
6056             'snapshot_id': None,
6057             'volume_id': save_volume_id,
6058             'no_device': None}
6059 
6060         if resize_to:
6061             values['volume_size'] = resize_to
6062 
6063         if new_attachment_id is not None:
6064             # This was a volume swap for a new-style attachment so we
6065             # need to update the BDM attachment_id for the new attachment.
6066             values['attachment_id'] = new_attachment_id
6067 
6068         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
6069                   "%(updates)s", {'volume_id': bdm.volume_id,
6070                                   'updates': values},
6071                   instance=instance)
6072         bdm.update(values)
6073         bdm.save()
6074 
6075         compute_utils.notify_about_volume_swap(
6076             context, instance, self.host,
6077             fields.NotificationPhase.END,
6078             old_volume_id, new_volume_id)
6079 
6080     @wrap_exception()
6081     def remove_volume_connection(self, context, volume_id, instance):
6082         """Remove the volume connection on this host
6083 
6084         Detach the volume from this instance on this host, and if this is
6085         the cinder v2 flow, call cinder to terminate the connection.
6086         """
6087         try:
6088             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
6089                     context, volume_id, instance.uuid)
6090             driver_bdm = driver_block_device.convert_volume(bdm)
6091             driver_bdm.driver_detach(context, instance,
6092                                      self.volume_api, self.driver)
6093             if bdm.attachment_id is None:
6094                 # cinder v2 api flow
6095                 connector = self.driver.get_volume_connector(instance)
6096                 self.volume_api.terminate_connection(context, volume_id,
6097                                                      connector)
6098         except exception.NotFound:
6099             pass
6100 
6101     def _deallocate_port_for_instance(self, context, instance, port_id,
6102                                       raise_on_failure=False):
6103         try:
6104             result = self.network_api.deallocate_port_for_instance(
6105                 context, instance, port_id)
6106             __, port_allocation = result
6107         except Exception as ex:
6108             with excutils.save_and_reraise_exception(
6109                     reraise=raise_on_failure):
6110                 LOG.warning('Failed to deallocate port %(port_id)s '
6111                             'for instance. Error: %(error)s',
6112                             {'port_id': port_id, 'error': ex},
6113                             instance=instance)
6114         else:
6115             if port_allocation:
6116                 # Deallocate the resources in placement that were used by the
6117                 # detached port.
6118                 try:
6119                     client = self.reportclient
6120                     client.remove_resources_from_instance_allocation(
6121                         context, instance.uuid, port_allocation)
6122                 except Exception as ex:
6123                     # We always raise here as it is not a race condition where
6124                     # somebody has already deleted the port we want to cleanup.
6125                     # Here we see that the port exists, the allocation exists,
6126                     # but we cannot clean it up so we will actually leak
6127                     # allocations.
6128                     with excutils.save_and_reraise_exception():
6129                         LOG.warning('Failed to remove resource allocation '
6130                                     'of port %(port_id)s for instance. Error: '
6131                                     '%(error)s',
6132                                     {'port_id': port_id, 'error': ex},
6133                                     instance=instance)
6134 
6135     @wrap_exception()
6136     @wrap_instance_event(prefix='compute')
6137     @wrap_instance_fault
6138     def attach_interface(self, context, instance, network_id, port_id,
6139                          requested_ip, tag):
6140         """Use hotplug to add an network adapter to an instance."""
6141         if not self.driver.capabilities.get('supports_attach_interface',
6142                                             False):
6143             raise exception.AttachInterfaceNotSupported(
6144                 instance_uuid=instance.uuid)
6145         if (tag and not
6146             self.driver.capabilities.get('supports_tagged_attach_interface',
6147                                          False)):
6148             raise exception.NetworkInterfaceTaggedAttachNotSupported()
6149 
6150         compute_utils.notify_about_instance_action(
6151             context, instance, self.host,
6152             action=fields.NotificationAction.INTERFACE_ATTACH,
6153             phase=fields.NotificationPhase.START)
6154 
6155         bind_host_id = self.driver.network_binding_host_id(context, instance)
6156         network_info = self.network_api.allocate_port_for_instance(
6157             context, instance, port_id, network_id, requested_ip,
6158             bind_host_id=bind_host_id, tag=tag)
6159         if len(network_info) != 1:
6160             LOG.error('allocate_port_for_instance returned %(ports)s '
6161                       'ports', {'ports': len(network_info)})
6162             # TODO(elod.illes): an instance.interface_attach.error notification
6163             # should be sent here
6164             raise exception.InterfaceAttachFailed(
6165                     instance_uuid=instance.uuid)
6166         image_meta = objects.ImageMeta.from_instance(instance)
6167 
6168         try:
6169             self.driver.attach_interface(context, instance, image_meta,
6170                                          network_info[0])
6171         except exception.NovaException as ex:
6172             port_id = network_info[0].get('id')
6173             LOG.warning("attach interface failed , try to deallocate "
6174                         "port %(port_id)s, reason: %(msg)s",
6175                         {'port_id': port_id, 'msg': ex},
6176                         instance=instance)
6177             self._deallocate_port_for_instance(context, instance, port_id)
6178 
6179             tb = traceback.format_exc()
6180             compute_utils.notify_about_instance_action(
6181                 context, instance, self.host,
6182                 action=fields.NotificationAction.INTERFACE_ATTACH,
6183                 phase=fields.NotificationPhase.ERROR,
6184                 exception=ex, tb=tb)
6185 
6186             raise exception.InterfaceAttachFailed(
6187                 instance_uuid=instance.uuid)
6188 
6189         compute_utils.notify_about_instance_action(
6190             context, instance, self.host,
6191             action=fields.NotificationAction.INTERFACE_ATTACH,
6192             phase=fields.NotificationPhase.END)
6193 
6194         return network_info[0]
6195 
6196     @wrap_exception()
6197     @wrap_instance_event(prefix='compute')
6198     @wrap_instance_fault
6199     def detach_interface(self, context, instance, port_id):
6200         """Detach a network adapter from an instance."""
6201         network_info = instance.info_cache.network_info
6202         condemned = None
6203         for vif in network_info:
6204             if vif['id'] == port_id:
6205                 condemned = vif
6206                 break
6207         if condemned is None:
6208             raise exception.PortNotFound(_("Port %s is not "
6209                                            "attached") % port_id)
6210 
6211         compute_utils.notify_about_instance_action(
6212             context, instance, self.host,
6213             action=fields.NotificationAction.INTERFACE_DETACH,
6214             phase=fields.NotificationPhase.START)
6215 
6216         try:
6217             self.driver.detach_interface(context, instance, condemned)
6218         except exception.NovaException as ex:
6219             # If the instance was deleted before the interface was detached,
6220             # just log it at debug.
6221             log_level = (logging.DEBUG
6222                          if isinstance(ex, exception.InstanceNotFound)
6223                          else logging.WARNING)
6224             LOG.log(log_level,
6225                     "Detach interface failed, port_id=%(port_id)s, reason: "
6226                     "%(msg)s", {'port_id': port_id, 'msg': ex},
6227                     instance=instance)
6228             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
6229         else:
6230             self._deallocate_port_for_instance(
6231                 context, instance, port_id, raise_on_failure=True)
6232 
6233         compute_utils.notify_about_instance_action(
6234             context, instance, self.host,
6235             action=fields.NotificationAction.INTERFACE_DETACH,
6236             phase=fields.NotificationPhase.END)
6237 
6238     def _get_compute_info(self, context, host):
6239         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
6240             context, host)
6241 
6242     @wrap_exception()
6243     def check_instance_shared_storage(self, ctxt, instance, data):
6244         """Check if the instance files are shared
6245 
6246         :param ctxt: security context
6247         :param instance: dict of instance data
6248         :param data: result of driver.check_instance_shared_storage_local
6249 
6250         Returns True if instance disks located on shared storage and
6251         False otherwise.
6252         """
6253         return self.driver.check_instance_shared_storage_remote(ctxt, data)
6254 
6255     @wrap_exception()
6256     @wrap_instance_event(prefix='compute')
6257     @wrap_instance_fault
6258     def check_can_live_migrate_destination(self, ctxt, instance,
6259                                            block_migration, disk_over_commit):
6260         """Check if it is possible to execute live migration.
6261 
6262         This runs checks on the destination host, and then calls
6263         back to the source host to check the results.
6264 
6265         :param context: security context
6266         :param instance: dict of instance data
6267         :param block_migration: if true, prepare for block migration
6268                                 if None, calculate it in driver
6269         :param disk_over_commit: if true, allow disk over commit
6270                                  if None, ignore disk usage checking
6271         :returns: a LiveMigrateData object (hypervisor-dependent)
6272         """
6273         src_compute_info = obj_base.obj_to_primitive(
6274             self._get_compute_info(ctxt, instance.host))
6275         dst_compute_info = obj_base.obj_to_primitive(
6276             self._get_compute_info(ctxt, CONF.host))
6277         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
6278             instance, src_compute_info, dst_compute_info,
6279             block_migration, disk_over_commit)
6280         LOG.debug('destination check data is %s', dest_check_data)
6281         try:
6282             migrate_data = self.compute_rpcapi.\
6283                                 check_can_live_migrate_source(ctxt, instance,
6284                                                               dest_check_data)
6285             # Create migrate_data vifs
6286             migrate_data.vifs = \
6287                 migrate_data_obj.LiveMigrateData.create_skeleton_migrate_vifs(
6288                     instance.get_network_info())
6289             # Claim PCI devices for VIFs on destination (if needed)
6290             port_id_to_pci = self._claim_pci_for_instance_vifs(ctxt, instance)
6291             # Update migrate VIFs with the newly claimed PCI devices
6292             self._update_migrate_vifs_profile_with_pci(migrate_data.vifs,
6293                                                        port_id_to_pci)
6294         finally:
6295             self.driver.cleanup_live_migration_destination_check(ctxt,
6296                     dest_check_data)
6297         return migrate_data
6298 
6299     @wrap_exception()
6300     @wrap_instance_event(prefix='compute')
6301     @wrap_instance_fault
6302     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
6303         """Check if it is possible to execute live migration.
6304 
6305         This checks if the live migration can succeed, based on the
6306         results from check_can_live_migrate_destination.
6307 
6308         :param ctxt: security context
6309         :param instance: dict of instance data
6310         :param dest_check_data: result of check_can_live_migrate_destination
6311         :returns: a LiveMigrateData object
6312         """
6313         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6314             ctxt, instance.uuid)
6315         is_volume_backed = compute_utils.is_volume_backed_instance(
6316             ctxt, instance, bdms)
6317         dest_check_data.is_volume_backed = is_volume_backed
6318         block_device_info = self._get_instance_block_device_info(
6319                             ctxt, instance, refresh_conn_info=False, bdms=bdms)
6320         result = self.driver.check_can_live_migrate_source(ctxt, instance,
6321                                                            dest_check_data,
6322                                                            block_device_info)
6323         LOG.debug('source check data is %s', result)
6324         return result
6325 
6326     @wrap_exception()
6327     @wrap_instance_event(prefix='compute')
6328     @wrap_instance_fault
6329     def pre_live_migration(self, context, instance, block_migration, disk,
6330                            migrate_data, migration=None):
6331         """Preparations for live migration at dest host.
6332 
6333         :param context: security context
6334         :param instance: dict of instance data
6335         :param block_migration: if true, prepare for block migration
6336         :param disk: disk info of instance
6337         :param migrate_data: A dict or LiveMigrateData object holding data
6338                              required for live migration without shared
6339                              storage.
6340         :param migration: a Migration object if one was created for this
6341                           live migration operation
6342         :returns: migrate_data containing additional migration info
6343         """
6344         LOG.debug('pre_live_migration data is %s', migrate_data)
6345 
6346         if migration:
6347             # NOTE(boxiang): Do a late check of server group policy as
6348             # parallel scheduling could violate such policy. This will
6349             # cause the live-migration to fail.
6350             request_spec = objects.RequestSpec.get_by_instance_uuid(
6351                 context, instance_uuid=instance.uuid)
6352             hints = self._get_scheduler_hints({}, request_spec)
6353             self._validate_instance_group_policy(context, instance,
6354                                                  hints, migration)
6355 
6356         migrate_data.old_vol_attachment_ids = {}
6357         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6358             context, instance.uuid)
6359         network_info = self.network_api.get_instance_nw_info(context, instance)
6360         self._notify_about_instance_usage(
6361             context, instance, "live_migration.pre.start",
6362             network_info=network_info)
6363         compute_utils.notify_about_instance_action(
6364             context, instance, self.host,
6365             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6366             phase=fields.NotificationPhase.START, bdms=bdms)
6367 
6368         connector = self.driver.get_volume_connector(instance)
6369         try:
6370             for bdm in bdms:
6371                 if bdm.is_volume and bdm.attachment_id is not None:
6372                     # This bdm uses the new cinder v3.44 API.
6373                     # We will create a new attachment for this
6374                     # volume on this migration destination host. The old
6375                     # attachment will be deleted on the source host
6376                     # when the migration succeeds. The old attachment_id
6377                     # is stored in dict with the key being the bdm.volume_id
6378                     # so it can be restored on rollback.
6379                     #
6380                     # Also note that attachment_update is not needed as we
6381                     # are providing the connector in the create call.
6382                     attach_ref = self.volume_api.attachment_create(
6383                         context, bdm.volume_id, bdm.instance_uuid,
6384                         connector=connector, mountpoint=bdm.device_name)
6385 
6386                     # save current attachment so we can detach it on success,
6387                     # or restore it on a rollback.
6388                     # NOTE(mdbooth): This data is no longer used by the source
6389                     # host since change I0390c9ff. We can't remove it until we
6390                     # are sure the source host has been upgraded.
6391                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
6392                         bdm.attachment_id
6393 
6394                     # update the bdm with the new attachment_id.
6395                     bdm.attachment_id = attach_ref['id']
6396                     bdm.save()
6397 
6398             block_device_info = self._get_instance_block_device_info(
6399                                 context, instance, refresh_conn_info=True,
6400                                 bdms=bdms)
6401 
6402             # The driver pre_live_migration will plug vifs on the host. We call
6403             # plug_vifs before calling ensure_filtering_rules_for_instance, to
6404             # ensure bridge is set up.
6405             migrate_data = self.driver.pre_live_migration(context,
6406                                            instance,
6407                                            block_device_info,
6408                                            network_info,
6409                                            disk,
6410                                            migrate_data)
6411             LOG.debug('driver pre_live_migration data is %s', migrate_data)
6412             # driver.pre_live_migration is what plugs vifs on the destination
6413             # host so now we can set the wait_for_vif_plugged flag in the
6414             # migrate_data object which the source compute will use to
6415             # determine if it should wait for a 'network-vif-plugged' event
6416             # from neutron before starting the actual guest transfer in the
6417             # hypervisor
6418             migrate_data.wait_for_vif_plugged = (
6419                 CONF.compute.live_migration_wait_for_vif_plug)
6420 
6421             # NOTE(tr3buchet): setup networks on destination host
6422             self.network_api.setup_networks_on_host(context, instance,
6423                                                              self.host)
6424 
6425             # Creating filters to hypervisors and firewalls.
6426             # An example is that nova-instance-instance-xxx,
6427             # which is written to libvirt.xml(Check "virsh nwfilter-list")
6428             # This nwfilter is necessary on the destination host.
6429             # In addition, this method is creating filtering rule
6430             # onto destination host.
6431             self.driver.ensure_filtering_rules_for_instance(instance,
6432                                                 network_info)
6433         except Exception:
6434             # If we raise, migrate_data with the updated attachment ids
6435             # will not be returned to the source host for rollback.
6436             # So we need to rollback new attachments here.
6437             with excutils.save_and_reraise_exception():
6438                 old_attachments = migrate_data.old_vol_attachment_ids
6439                 for bdm in bdms:
6440                     if (bdm.is_volume and bdm.attachment_id is not None and
6441                             bdm.volume_id in old_attachments):
6442                         self.volume_api.attachment_delete(context,
6443                                                           bdm.attachment_id)
6444                         bdm.attachment_id = old_attachments[bdm.volume_id]
6445                         bdm.save()
6446 
6447         # Volume connections are complete, tell cinder that all the
6448         # attachments have completed.
6449         for bdm in bdms:
6450             if bdm.is_volume and bdm.attachment_id is not None:
6451                 self.volume_api.attachment_complete(context,
6452                                                     bdm.attachment_id)
6453 
6454         self._notify_about_instance_usage(
6455                      context, instance, "live_migration.pre.end",
6456                      network_info=network_info)
6457         compute_utils.notify_about_instance_action(
6458             context, instance, self.host,
6459             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6460             phase=fields.NotificationPhase.END, bdms=bdms)
6461 
6462         LOG.debug('pre_live_migration result data is %s', migrate_data)
6463         return migrate_data
6464 
6465     @staticmethod
6466     def _neutron_failed_live_migration_callback(event_name, instance):
6467         msg = ('Neutron reported failure during live migration '
6468                'with %(event)s for instance %(uuid)s')
6469         msg_args = {'event': event_name, 'uuid': instance.uuid}
6470         if CONF.vif_plugging_is_fatal:
6471             raise exception.VirtualInterfacePlugException(msg % msg_args)
6472         LOG.error(msg, msg_args)
6473 
6474     @staticmethod
6475     def _get_neutron_events_for_live_migration(instance):
6476         # We don't generate events if CONF.vif_plugging_timeout=0
6477         # meaning that the operator disabled using them.
6478         if CONF.vif_plugging_timeout and utils.is_neutron():
6479             return [('network-vif-plugged', vif['id'])
6480                     for vif in instance.get_network_info()]
6481         else:
6482             return []
6483 
6484     def _cleanup_pre_live_migration(self, context, dest, instance,
6485                                     migration, migrate_data, source_bdms):
6486         """Helper method for when pre_live_migration fails
6487 
6488         Sets the migration status to "error" and rolls back the live migration
6489         setup on the destination host.
6490 
6491         :param context: The user request context.
6492         :type context: nova.context.RequestContext
6493         :param dest: The live migration destination hostname.
6494         :type dest: str
6495         :param instance: The instance being live migrated.
6496         :type instance: nova.objects.Instance
6497         :param migration: The migration record tracking this live migration.
6498         :type migration: nova.objects.Migration
6499         :param migrate_data: Data about the live migration, populated from
6500                              the destination host.
6501         :type migrate_data: Subclass of nova.objects.LiveMigrateData
6502         :param source_bdms: BDMs prior to modification by the destination
6503                             compute host. Set by _do_live_migration and not
6504                             part of the callback interface, so this is never
6505                             None
6506         """
6507         self._set_migration_status(migration, 'error')
6508         # Make sure we set this for _rollback_live_migration()
6509         # so it can find it, as expected if it was called later
6510         migrate_data.migration = migration
6511         self._rollback_live_migration(context, instance, dest,
6512                                       migrate_data=migrate_data,
6513                                       source_bdms=source_bdms)
6514 
6515     def _do_live_migration(self, context, dest, instance, block_migration,
6516                            migration, migrate_data):
6517         # NOTE(danms): We should enhance the RT to account for migrations
6518         # and use the status field to denote when the accounting has been
6519         # done on source/destination. For now, this is just here for status
6520         # reporting
6521         self._set_migration_status(migration, 'preparing')
6522         source_bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6523                 context, instance.uuid)
6524 
6525         class _BreakWaitForInstanceEvent(Exception):
6526             """Used as a signal to stop waiting for the network-vif-plugged
6527             event when we discover that
6528             [compute]/live_migration_wait_for_vif_plug is not set on the
6529             destination.
6530             """
6531             pass
6532 
6533         events = self._get_neutron_events_for_live_migration(instance)
6534         try:
6535             if ('block_migration' in migrate_data and
6536                     migrate_data.block_migration):
6537                 block_device_info = self._get_instance_block_device_info(
6538                     context, instance, bdms=source_bdms)
6539                 disk = self.driver.get_instance_disk_info(
6540                     instance, block_device_info=block_device_info)
6541             else:
6542                 disk = None
6543 
6544             deadline = CONF.vif_plugging_timeout
6545             error_cb = self._neutron_failed_live_migration_callback
6546             # In order to avoid a race with the vif plugging that the virt
6547             # driver does on the destination host, we register our events
6548             # to wait for before calling pre_live_migration. Then if the
6549             # dest host reports back that we shouldn't wait, we can break
6550             # out of the context manager using _BreakWaitForInstanceEvent.
6551             with self.virtapi.wait_for_instance_event(
6552                     instance, events, deadline=deadline,
6553                     error_callback=error_cb):
6554                 with timeutils.StopWatch() as timer:
6555                     migrate_data = self.compute_rpcapi.pre_live_migration(
6556                         context, instance,
6557                         block_migration, disk, dest, migrate_data, migration)
6558                 LOG.info('Took %0.2f seconds for pre_live_migration on '
6559                          'destination host %s.',
6560                          timer.elapsed(), dest, instance=instance)
6561                 wait_for_vif_plugged = (
6562                     'wait_for_vif_plugged' in migrate_data and
6563                     migrate_data.wait_for_vif_plugged)
6564                 if events and not wait_for_vif_plugged:
6565                     raise _BreakWaitForInstanceEvent
6566         except _BreakWaitForInstanceEvent:
6567             if events:
6568                 LOG.debug('Not waiting for events after pre_live_migration: '
6569                           '%s. ', events, instance=instance)
6570             # This is a bit weird, but we need to clear sys.exc_info() so that
6571             # oslo.log formatting does not inadvertently use it later if an
6572             # error message is logged without an explicit exc_info. This is
6573             # only a problem with python 2.
6574             if six.PY2:
6575                 sys.exc_clear()
6576         except exception.VirtualInterfacePlugException:
6577             with excutils.save_and_reraise_exception():
6578                 LOG.exception('Failed waiting for network virtual interfaces '
6579                               'to be plugged on the destination host %s.',
6580                               dest, instance=instance)
6581                 self._cleanup_pre_live_migration(
6582                     context, dest, instance, migration, migrate_data,
6583                     source_bdms)
6584         except eventlet.timeout.Timeout:
6585             # We only get here if wait_for_vif_plugged is True which means
6586             # live_migration_wait_for_vif_plug=True on the destination host.
6587             msg = (
6588                 'Timed out waiting for events: %(events)s. If these timeouts '
6589                 'are a persistent issue it could mean the networking backend '
6590                 'on host %(dest)s does not support sending these events '
6591                 'unless there are port binding host changes which does not '
6592                 'happen at this point in the live migration process. You may '
6593                 'need to disable the live_migration_wait_for_vif_plug option '
6594                 'on host %(dest)s.')
6595             subs = {'events': events, 'dest': dest}
6596             LOG.warning(msg, subs, instance=instance)
6597             if CONF.vif_plugging_is_fatal:
6598                 self._cleanup_pre_live_migration(
6599                     context, dest, instance, migration, migrate_data,
6600                     source_bdms)
6601                 raise exception.MigrationError(reason=msg % subs)
6602         except Exception:
6603             with excutils.save_and_reraise_exception():
6604                 LOG.exception('Pre live migration failed at %s',
6605                               dest, instance=instance)
6606                 self._cleanup_pre_live_migration(
6607                     context, dest, instance, migration, migrate_data,
6608                     source_bdms)
6609 
6610         # Set migrate_data.migration because that is how _post_live_migration
6611         # and _rollback_live_migration get the migration object for cleanup.
6612         # Yes this is gross but changing the _post_live_migration and
6613         # _rollback_live_migration interfaces would also mean changing how the
6614         # virt drivers call them from the driver.live_migration method, i.e.
6615         # we would have to pass the migration object through the driver (or
6616         # consider using a partial but some do not like that pattern).
6617         migrate_data.migration = migration
6618 
6619         # NOTE(Kevin_Zheng): Pop the migration from the waiting queue
6620         # if it exist in the queue, then we are good to moving on, if
6621         # not, some other process must have aborted it, then we should
6622         # rollback.
6623         try:
6624             self._waiting_live_migrations.pop(instance.uuid)
6625         except KeyError:
6626             LOG.debug('Migration %s aborted by another process, rollback.',
6627                       migration.uuid, instance=instance)
6628             self._rollback_live_migration(context, instance, dest,
6629                                           migrate_data, 'cancelled',
6630                                           source_bdms=source_bdms)
6631             self._notify_live_migrate_abort_end(context, instance)
6632             return
6633 
6634         self._set_migration_status(migration, 'running')
6635 
6636         # NOTE(mdbooth): pre_live_migration will update connection_info and
6637         # attachment_id on all volume BDMS to reflect the new destination
6638         # host attachment. We fetch BDMs before that to retain connection_info
6639         # and attachment_id relating to the source host for post migration
6640         # cleanup.
6641         post_live_migration = functools.partial(self._post_live_migration,
6642                                                 source_bdms=source_bdms)
6643         rollback_live_migration = functools.partial(
6644             self._rollback_live_migration, source_bdms=source_bdms)
6645 
6646         LOG.debug('live_migration data is %s', migrate_data)
6647         try:
6648             self.driver.live_migration(context, instance, dest,
6649                                        post_live_migration,
6650                                        rollback_live_migration,
6651                                        block_migration, migrate_data)
6652         except Exception:
6653             LOG.exception('Live migration failed.', instance=instance)
6654             with excutils.save_and_reraise_exception():
6655                 # Put instance and migration into error state,
6656                 # as its almost certainly too late to rollback
6657                 self._set_migration_status(migration, 'error')
6658                 # first refresh instance as it may have got updated by
6659                 # post_live_migration_at_destination
6660                 instance.refresh()
6661                 self._set_instance_obj_error_state(context, instance,
6662                                                    clean_task_state=True)
6663 
6664     @wrap_exception()
6665     @wrap_instance_event(prefix='compute')
6666     @errors_out_migration
6667     @wrap_instance_fault
6668     def live_migration(self, context, dest, instance, block_migration,
6669                        migration, migrate_data):
6670         """Executing live migration.
6671 
6672         :param context: security context
6673         :param dest: destination host
6674         :param instance: a nova.objects.instance.Instance object
6675         :param block_migration: if true, prepare for block migration
6676         :param migration: an nova.objects.Migration object
6677         :param migrate_data: implementation specific params
6678 
6679         """
6680         self._set_migration_status(migration, 'queued')
6681         # NOTE(Kevin_Zheng): Submit the live_migration job to the pool and
6682         # put the returned Future object into dict mapped with migration.uuid
6683         # in order to be able to track and abort it in the future.
6684         self._waiting_live_migrations[instance.uuid] = (None, None)
6685         try:
6686             future = self._live_migration_executor.submit(
6687                 self._do_live_migration, context, dest, instance,
6688                 block_migration, migration, migrate_data)
6689             self._waiting_live_migrations[instance.uuid] = (migration, future)
6690         except RuntimeError:
6691             # GreenThreadPoolExecutor.submit will raise RuntimeError if the
6692             # pool is shutdown, which happens in
6693             # _cleanup_live_migrations_in_pool.
6694             LOG.info('Migration %s failed to submit as the compute service '
6695                      'is shutting down.', migration.uuid, instance=instance)
6696             raise exception.LiveMigrationNotSubmitted(
6697                 migration_uuid=migration.uuid, instance_uuid=instance.uuid)
6698 
6699     @wrap_exception()
6700     @wrap_instance_event(prefix='compute')
6701     @wrap_instance_fault
6702     def live_migration_force_complete(self, context, instance):
6703         """Force live migration to complete.
6704 
6705         :param context: Security context
6706         :param instance: The instance that is being migrated
6707         """
6708 
6709         self._notify_about_instance_usage(
6710             context, instance, 'live.migration.force.complete.start')
6711         compute_utils.notify_about_instance_action(
6712             context, instance, self.host,
6713             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6714             phase=fields.NotificationPhase.START)
6715         self.driver.live_migration_force_complete(instance)
6716         self._notify_about_instance_usage(
6717             context, instance, 'live.migration.force.complete.end')
6718         compute_utils.notify_about_instance_action(
6719             context, instance, self.host,
6720             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6721             phase=fields.NotificationPhase.END)
6722 
6723     def _notify_live_migrate_abort_end(self, context, instance):
6724         self._notify_about_instance_usage(
6725             context, instance, 'live.migration.abort.end')
6726         compute_utils.notify_about_instance_action(
6727             context, instance, self.host,
6728             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6729             phase=fields.NotificationPhase.END)
6730 
6731     @wrap_exception()
6732     @wrap_instance_event(prefix='compute')
6733     @wrap_instance_fault
6734     def live_migration_abort(self, context, instance, migration_id):
6735         """Abort an in-progress live migration.
6736 
6737         :param context: Security context
6738         :param instance: The instance that is being migrated
6739         :param migration_id: ID of in-progress live migration
6740 
6741         """
6742         self._notify_about_instance_usage(
6743             context, instance, 'live.migration.abort.start')
6744         compute_utils.notify_about_instance_action(
6745             context, instance, self.host,
6746             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6747             phase=fields.NotificationPhase.START)
6748         # NOTE(Kevin_Zheng): Pop the migration out from the queue, this might
6749         # lead to 3 scenarios:
6750         # 1. The selected migration is still in queue, and the future.cancel()
6751         #    succeed, then the abort action is succeed, mark the migration
6752         #    status to 'cancelled'.
6753         # 2. The selected migration is still in queue, but the future.cancel()
6754         #    failed, then the _do_live_migration() has started executing, and
6755         #    the migration status is 'preparing', then we just pop it from the
6756         #    queue, and the migration process will handle it later. And the
6757         #    migration status couldn't be 'running' in this scenario because
6758         #    if _do_live_migration has started executing and we've already
6759         #    popped it from the queue and set the migration status to
6760         #    'running' at this point, popping it here will raise KeyError at
6761         #    which point we check if it's running and if so, we abort the old
6762         #    way.
6763         # 3. The selected migration is not in the queue, then the migration
6764         #    status is 'running', let the driver handle it.
6765         try:
6766             migration, future = (
6767                 self._waiting_live_migrations.pop(instance.uuid))
6768             if future and future.cancel():
6769                 # If we got here, we've successfully aborted the queued
6770                 # migration and _do_live_migration won't run so we need
6771                 # to set the migration status to cancelled and send the
6772                 # notification. If Future.cancel() fails, it means
6773                 # _do_live_migration is running and the migration status
6774                 # is preparing, and _do_live_migration() itself will attempt
6775                 # to pop the queued migration, hit a KeyError, and rollback,
6776                 # set the migration to cancelled and send the
6777                 # live.migration.abort.end notification.
6778                 self._set_migration_status(migration, 'cancelled')
6779         except KeyError:
6780             migration = objects.Migration.get_by_id(context, migration_id)
6781             if migration.status != 'running':
6782                 raise exception.InvalidMigrationState(
6783                     migration_id=migration_id, instance_uuid=instance.uuid,
6784                     state=migration.status, method='abort live migration')
6785             self.driver.live_migration_abort(instance)
6786         self._notify_live_migrate_abort_end(context, instance)
6787 
6788     def _live_migration_cleanup_flags(self, migrate_data):
6789         """Determine whether disks or instance path need to be cleaned up after
6790         live migration (at source on success, at destination on rollback)
6791 
6792         Block migration needs empty image at destination host before migration
6793         starts, so if any failure occurs, any empty images has to be deleted.
6794 
6795         Also Volume backed live migration w/o shared storage needs to delete
6796         newly created instance-xxx dir on the destination as a part of its
6797         rollback process
6798 
6799         :param migrate_data: implementation specific data
6800         :returns: (bool, bool) -- do_cleanup, destroy_disks
6801         """
6802         # NOTE(pkoniszewski): block migration specific params are set inside
6803         # migrate_data objects for drivers that expose block live migration
6804         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6805         # cleanup is not needed.
6806         do_cleanup = False
6807         destroy_disks = False
6808         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6809             # No instance booting at source host, but instance dir
6810             # must be deleted for preparing next block migration
6811             # must be deleted for preparing next live migration w/o shared
6812             # storage
6813             do_cleanup = not migrate_data.is_shared_instance_path
6814             destroy_disks = not migrate_data.is_shared_block_storage
6815         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6816             do_cleanup = migrate_data.block_migration
6817             destroy_disks = migrate_data.block_migration
6818         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6819             # NOTE(claudiub): We need to cleanup any zombie Planned VM.
6820             do_cleanup = True
6821             destroy_disks = not migrate_data.is_shared_instance_path
6822 
6823         return (do_cleanup, destroy_disks)
6824 
6825     @wrap_exception()
6826     @wrap_instance_fault
6827     def _post_live_migration(self, ctxt, instance, dest,
6828                              block_migration=False, migrate_data=None,
6829                              source_bdms=None):
6830         """Post operations for live migration.
6831 
6832         This method is called from live_migration
6833         and mainly updating database record.
6834 
6835         :param ctxt: security context
6836         :param instance: instance dict
6837         :param dest: destination host
6838         :param block_migration: if true, prepare for block migration
6839         :param migrate_data: if not None, it is a dict which has data
6840         :param source_bdms: BDMs prior to modification by the destination
6841                             compute host. Set by _do_live_migration and not
6842                             part of the callback interface, so this is never
6843                             None
6844         required for live migration without shared storage
6845 
6846         """
6847         LOG.info('_post_live_migration() is started..',
6848                  instance=instance)
6849 
6850         # Cleanup source host post live-migration
6851         block_device_info = self._get_instance_block_device_info(
6852                             ctxt, instance, bdms=source_bdms)
6853         self.driver.post_live_migration(ctxt, instance, block_device_info,
6854                                         migrate_data)
6855 
6856         # Detaching volumes.
6857         connector = self.driver.get_volume_connector(instance)
6858         for bdm in source_bdms:
6859             if bdm.is_volume:
6860                 # Detaching volumes is a call to an external API that can fail.
6861                 # If it does, we need to handle it gracefully so that the call
6862                 # to post_live_migration_at_destination - where we set instance
6863                 # host and task state - still happens. We need to rethink the
6864                 # current approach of setting instance host and task state
6865                 # AFTER a whole bunch of things that could fail in unhandled
6866                 # ways, but that is left as a TODO(artom).
6867                 try:
6868                     if bdm.attachment_id is None:
6869                         # Prior to cinder v3.44:
6870                         # We don't want to actually mark the volume detached,
6871                         # or delete the bdm, just remove the connection from
6872                         # this host.
6873                         #
6874                         # remove the volume connection without detaching from
6875                         # hypervisor because the instance is not running
6876                         # anymore on the current host
6877                         self.volume_api.terminate_connection(ctxt,
6878                                                              bdm.volume_id,
6879                                                              connector)
6880                     else:
6881                         # cinder v3.44 api flow - delete the old attachment
6882                         # for the source host
6883                         self.volume_api.attachment_delete(ctxt,
6884                                                           bdm.attachment_id)
6885 
6886                 except Exception as e:
6887                     if bdm.attachment_id is None:
6888                         LOG.error('Connection for volume %s not terminated on '
6889                                   'source host %s during post_live_migration: '
6890                                    '%s', bdm.volume_id, self.host,
6891                                    six.text_type(e), instance=instance)
6892                     else:
6893                         LOG.error('Volume attachment %s not deleted on source '
6894                                   'host %s during post_live_migration: %s',
6895                                   bdm.attachment_id, self.host,
6896                                   six.text_type(e), instance=instance)
6897 
6898         # Releasing vlan.
6899         # (not necessary in current implementation?)
6900 
6901         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
6902 
6903         self._notify_about_instance_usage(ctxt, instance,
6904                                           "live_migration._post.start",
6905                                           network_info=network_info)
6906         compute_utils.notify_about_instance_action(
6907             ctxt, instance, self.host,
6908             action=fields.NotificationAction.LIVE_MIGRATION_POST,
6909             phase=fields.NotificationPhase.START)
6910         # Releasing security group ingress rule.
6911         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
6912                   instance=instance)
6913         self.driver.unfilter_instance(instance,
6914                                       network_info)
6915 
6916         migration = {'source_compute': self.host,
6917                      'dest_compute': dest, }
6918         # For neutron, migrate_instance_start will activate the destination
6919         # host port bindings, if there are any created by conductor before live
6920         # migration started.
6921         self.network_api.migrate_instance_start(ctxt,
6922                                                 instance,
6923                                                 migration)
6924 
6925         destroy_vifs = False
6926         try:
6927             # It's possible that the vif type changed on the destination
6928             # host and is already bound and active, so we need to use the
6929             # stashed source vifs in migrate_data.vifs (if present) to unplug
6930             # on the source host.
6931             unplug_nw_info = network_info
6932             if migrate_data and 'vifs' in migrate_data:
6933                 nw_info = []
6934                 for migrate_vif in migrate_data.vifs:
6935                     nw_info.append(migrate_vif.source_vif)
6936                 unplug_nw_info = network_model.NetworkInfo.hydrate(nw_info)
6937                 LOG.debug('Calling driver.post_live_migration_at_source '
6938                           'with original source VIFs from migrate_data: %s',
6939                           unplug_nw_info, instance=instance)
6940             self.driver.post_live_migration_at_source(ctxt, instance,
6941                                                       unplug_nw_info)
6942         except NotImplementedError as ex:
6943             LOG.debug(ex, instance=instance)
6944             # For all hypervisors other than libvirt, there is a possibility
6945             # they are unplugging networks from source node in the cleanup
6946             # method
6947             destroy_vifs = True
6948 
6949         # Free instance allocations on source before claims are allocated on
6950         # destination node
6951         self.rt.free_pci_device_allocations_for_instance(ctxt, instance)
6952         # NOTE(danms): Save source node before calling post method on
6953         # destination, which will update it
6954         source_node = instance.node
6955 
6956         # Define domain at destination host, without doing it,
6957         # pause/suspend/terminate do not work.
6958         post_at_dest_success = True
6959         try:
6960             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
6961                     instance, block_migration, dest)
6962         except Exception as error:
6963             post_at_dest_success = False
6964             # We don't want to break _post_live_migration() if
6965             # post_live_migration_at_destination() fails as it should never
6966             # affect cleaning up source node.
6967             LOG.exception("Post live migration at destination %s failed",
6968                           dest, instance=instance, error=error)
6969 
6970         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6971                 migrate_data)
6972 
6973         if do_cleanup:
6974             LOG.debug('Calling driver.cleanup from _post_live_migration',
6975                       instance=instance)
6976             self.driver.cleanup(ctxt, instance, unplug_nw_info,
6977                                 destroy_disks=destroy_disks,
6978                                 migrate_data=migrate_data,
6979                                 destroy_vifs=destroy_vifs)
6980 
6981         self.instance_events.clear_events_for_instance(instance)
6982 
6983         # NOTE(timello): make sure we update available resources on source
6984         # host even before next periodic task.
6985         self.update_available_resource(ctxt)
6986 
6987         self._update_scheduler_instance_info(ctxt, instance)
6988         self._notify_about_instance_usage(ctxt, instance,
6989                                           "live_migration._post.end",
6990                                           network_info=network_info)
6991         compute_utils.notify_about_instance_action(
6992             ctxt, instance, self.host,
6993             action=fields.NotificationAction.LIVE_MIGRATION_POST,
6994             phase=fields.NotificationPhase.END)
6995         if post_at_dest_success:
6996             LOG.info('Migrating instance to %s finished successfully.',
6997                      dest, instance=instance)
6998 
6999         self._clean_instance_console_tokens(ctxt, instance)
7000         if migrate_data and migrate_data.obj_attr_is_set('migration'):
7001             migrate_data.migration.status = 'completed'
7002             migrate_data.migration.save()
7003             self._delete_allocation_after_move(ctxt,
7004                                                instance,
7005                                                migrate_data.migration)
7006         else:
7007             # We didn't have data on a migration, which means we can't
7008             # look up to see if we had new-style migration-based
7009             # allocations. This should really only happen in cases of
7010             # a buggy virt driver. Log a warning so we know it happened.
7011             LOG.warning('Live migration ended with no migrate_data '
7012                         'record. Unable to clean up migration-based '
7013                         'allocations for node %s which is almost certainly '
7014                         'not an expected situation.', source_node,
7015                         instance=instance)
7016 
7017     def _consoles_enabled(self):
7018         """Returns whether a console is enable."""
7019         return (CONF.vnc.enabled or CONF.spice.enabled or
7020                 CONF.rdp.enabled or CONF.serial_console.enabled or
7021                 CONF.mks.enabled)
7022 
7023     def _clean_instance_console_tokens(self, ctxt, instance):
7024         """Clean console tokens stored for an instance."""
7025         # If the database backend isn't in use, don't bother trying to clean
7026         # tokens.
7027         if self._consoles_enabled():
7028             objects.ConsoleAuthToken.\
7029                 clean_console_auths_for_instance(ctxt, instance.uuid)
7030 
7031     @wrap_exception()
7032     @wrap_instance_event(prefix='compute')
7033     @wrap_instance_fault
7034     def post_live_migration_at_destination(self, context, instance,
7035                                            block_migration):
7036         """Post operations for live migration .
7037 
7038         :param context: security context
7039         :param instance: Instance dict
7040         :param block_migration: if true, prepare for block migration
7041 
7042         """
7043         LOG.info('Post operation of migration started',
7044                  instance=instance)
7045 
7046         # NOTE(tr3buchet): setup networks on destination host
7047         #                  this is called a second time because
7048         #                  multi_host does not create the bridge in
7049         #                  plug_vifs
7050         # NOTE(mriedem): This is a no-op for neutron.
7051         self.network_api.setup_networks_on_host(context, instance,
7052                                                          self.host)
7053         migration = {'source_compute': instance.host,
7054                      'dest_compute': self.host,
7055                      'migration_type': 'live-migration'}
7056         self.network_api.migrate_instance_finish(context,
7057                                                  instance,
7058                                                  migration)
7059 
7060         network_info = self.network_api.get_instance_nw_info(context, instance)
7061         self._notify_about_instance_usage(
7062                      context, instance, "live_migration.post.dest.start",
7063                      network_info=network_info)
7064         compute_utils.notify_about_instance_action(context, instance,
7065                 self.host,
7066                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
7067                 phase=fields.NotificationPhase.START)
7068         block_device_info = self._get_instance_block_device_info(context,
7069                                                                  instance)
7070         # Allocate the claimed PCI resources at destination.
7071         self.rt.allocate_pci_devices_for_instance(context, instance)
7072 
7073         try:
7074             self.driver.post_live_migration_at_destination(
7075                 context, instance, network_info, block_migration,
7076                 block_device_info)
7077         except Exception:
7078             with excutils.save_and_reraise_exception():
7079                 instance.vm_state = vm_states.ERROR
7080                 LOG.error('Unexpected error during post live migration at '
7081                           'destination host.', instance=instance)
7082         finally:
7083             # Restore instance state and update host
7084             current_power_state = self._get_power_state(context, instance)
7085             node_name = None
7086             prev_host = instance.host
7087             try:
7088                 compute_node = self._get_compute_info(context, self.host)
7089                 node_name = compute_node.hypervisor_hostname
7090             except exception.ComputeHostNotFound:
7091                 LOG.exception('Failed to get compute_info for %s', self.host)
7092             finally:
7093                 instance.host = self.host
7094                 instance.power_state = current_power_state
7095                 instance.task_state = None
7096                 instance.node = node_name
7097                 instance.progress = 0
7098                 instance.save(expected_task_state=task_states.MIGRATING)
7099 
7100         # NOTE(tr3buchet): tear down networks on source host (nova-net)
7101         # NOTE(mriedem): For neutron, this will delete any inactive source
7102         # host port bindings.
7103         try:
7104             self.network_api.setup_networks_on_host(context, instance,
7105                                                     prev_host, teardown=True)
7106         except exception.PortBindingDeletionFailed as e:
7107             # Removing the inactive port bindings from the source host is not
7108             # critical so just log an error but don't fail.
7109             LOG.error('Network cleanup failed for source host %s during post '
7110                       'live migration. You may need to manually clean up '
7111                       'resources in the network service. Error: %s',
7112                       prev_host, six.text_type(e))
7113         # NOTE(vish): this is necessary to update dhcp for nova-network
7114         # NOTE(mriedem): This is a no-op for neutron.
7115         self.network_api.setup_networks_on_host(context, instance, self.host)
7116         self._notify_about_instance_usage(
7117                      context, instance, "live_migration.post.dest.end",
7118                      network_info=network_info)
7119         compute_utils.notify_about_instance_action(context, instance,
7120                 self.host,
7121                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
7122                 phase=fields.NotificationPhase.END)
7123 
7124     @wrap_exception()
7125     @wrap_instance_fault
7126     def _rollback_live_migration(self, context, instance,
7127                                  dest, migrate_data=None,
7128                                  migration_status='error',
7129                                  source_bdms=None):
7130         """Recovers Instance/volume state from migrating -> running.
7131 
7132         :param context: security context
7133         :param instance: nova.objects.instance.Instance object
7134         :param dest:
7135             This method is called from live migration src host.
7136             This param specifies destination host.
7137         :param migrate_data:
7138             if not none, contains implementation specific data.
7139         :param migration_status:
7140             Contains the status we want to set for the migration object
7141         :param source_bdms: BDMs prior to modification by the destination
7142                             compute host. Set by _do_live_migration and not
7143                             part of the callback interface, so this is never
7144                             None
7145 
7146         """
7147         if (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
7148               migrate_data.obj_attr_is_set('migration')):
7149             migration = migrate_data.migration
7150         else:
7151             migration = None
7152 
7153         if migration:
7154             # Remove allocations created in Placement for the dest node.
7155             # If migration is None, the virt driver didn't pass it which is
7156             # a bug.
7157             self._revert_allocation(context, instance, migration)
7158         else:
7159             LOG.error('Unable to revert allocations during live migration '
7160                       'rollback; compute driver did not provide migrate_data',
7161                       instance=instance)
7162 
7163         instance.task_state = None
7164         instance.progress = 0
7165         instance.save(expected_task_state=[task_states.MIGRATING])
7166 
7167         # NOTE(tr3buchet): setup networks on source host (really it's re-setup
7168         #                  for nova-network)
7169         # NOTE(mriedem): This is a no-op for neutron.
7170         self.network_api.setup_networks_on_host(context, instance, self.host)
7171         self.driver.rollback_live_migration_at_source(context, instance,
7172                                                       migrate_data)
7173 
7174         source_bdms_by_volid = {bdm.volume_id: bdm for bdm in source_bdms
7175                                 if bdm.is_volume}
7176 
7177         # NOTE(lyarwood): Fetch the current list of BDMs and delete any volume
7178         # attachments used by the destination host before rolling back to the
7179         # original and still valid source host volume attachments.
7180         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7181                 context, instance.uuid)
7182         for bdm in bdms:
7183             if bdm.is_volume:
7184                 # remove the connection on the destination host
7185                 # NOTE(lyarwood): This actually calls the cinderv2
7186                 # os-terminate_connection API if required.
7187                 self.compute_rpcapi.remove_volume_connection(
7188                         context, instance, bdm.volume_id, dest)
7189 
7190                 if bdm.attachment_id:
7191                     # 3.44 cinder api flow. Set the bdm's
7192                     # attachment_id to the old attachment of the source
7193                     # host. If old_attachments is not there, then
7194                     # there was an error before the new attachment was made.
7195                     # TODO(lyarwood): migrate_data.old_vol_attachment_ids can
7196                     # be removed now as we can lookup the original
7197                     # attachment_ids from the source_bdms list here.
7198                     old_attachments = migrate_data.old_vol_attachment_ids \
7199                         if 'old_vol_attachment_ids' in migrate_data else None
7200                     if old_attachments and bdm.volume_id in old_attachments:
7201                         self.volume_api.attachment_delete(context,
7202                                                           bdm.attachment_id)
7203                         bdm.attachment_id = old_attachments[bdm.volume_id]
7204 
7205                 # NOTE(lyarwood): Rollback the connection_info stored within
7206                 # the BDM to that used by the source and not the destination.
7207                 source_bdm = source_bdms_by_volid[bdm.volume_id]
7208                 bdm.connection_info = source_bdm.connection_info
7209                 bdm.save()
7210 
7211         self._notify_about_instance_usage(context, instance,
7212                                           "live_migration._rollback.start")
7213         compute_utils.notify_about_instance_action(context, instance,
7214                 self.host,
7215                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
7216                 phase=fields.NotificationPhase.START,
7217                 bdms=bdms)
7218 
7219         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
7220                 migrate_data)
7221 
7222         if do_cleanup:
7223             self.compute_rpcapi.rollback_live_migration_at_destination(
7224                     context, instance, dest, destroy_disks=destroy_disks,
7225                     migrate_data=migrate_data)
7226         elif utils.is_neutron():
7227             # The port binding profiles need to be cleaned up.
7228             with errors_out_migration_ctxt(migration):
7229                 try:
7230                     # This call will delete any inactive destination host
7231                     # port bindings.
7232                     self.network_api.setup_networks_on_host(
7233                         context, instance, host=dest, teardown=True)
7234                 except exception.PortBindingDeletionFailed as e:
7235                     # Removing the inactive port bindings from the destination
7236                     # host is not critical so just log an error but don't fail.
7237                     LOG.error(
7238                         'Network cleanup failed for destination host %s '
7239                         'during live migration rollback. You may need to '
7240                         'manually clean up resources in the network service. '
7241                         'Error: %s', dest, six.text_type(e))
7242                 except Exception:
7243                     with excutils.save_and_reraise_exception():
7244                         LOG.exception(
7245                             'An error occurred while cleaning up networking '
7246                             'during live migration rollback.',
7247                             instance=instance)
7248 
7249         self._notify_about_instance_usage(context, instance,
7250                                           "live_migration._rollback.end")
7251         compute_utils.notify_about_instance_action(context, instance,
7252                 self.host,
7253                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
7254                 phase=fields.NotificationPhase.END,
7255                 bdms=bdms)
7256 
7257         self._set_migration_status(migration, migration_status)
7258 
7259     @wrap_exception()
7260     @wrap_instance_event(prefix='compute')
7261     @wrap_instance_fault
7262     def rollback_live_migration_at_destination(self, context, instance,
7263                                                destroy_disks,
7264                                                migrate_data):
7265         """Cleaning up image directory that is created pre_live_migration.
7266 
7267         :param context: security context
7268         :param instance: a nova.objects.instance.Instance object sent over rpc
7269         :param destroy_disks: whether to destroy volumes or not
7270         :param migrate_data: contains migration info
7271         """
7272         network_info = self.network_api.get_instance_nw_info(context, instance)
7273         self._notify_about_instance_usage(
7274                       context, instance, "live_migration.rollback.dest.start",
7275                       network_info=network_info)
7276         compute_utils.notify_about_instance_action(
7277             context, instance, self.host,
7278             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
7279             phase=fields.NotificationPhase.START)
7280         try:
7281             # NOTE(tr3buchet): tear down networks on dest host (nova-net)
7282             # NOTE(mriedem): For neutron, this call will delete any
7283             # destination host port bindings.
7284             # TODO(mriedem): We should eventually remove this call from
7285             # this method (rollback_live_migration_at_destination) since this
7286             # method is only called conditionally based on whether or not the
7287             # instance is running on shared storage. _rollback_live_migration
7288             # already calls this method for neutron if we are running on
7289             # shared storage.
7290             self.network_api.setup_networks_on_host(context, instance,
7291                                                     self.host, teardown=True)
7292         except exception.PortBindingDeletionFailed as e:
7293             # Removing the inactive port bindings from the destination
7294             # host is not critical so just log an error but don't fail.
7295             LOG.error(
7296                 'Network cleanup failed for destination host %s '
7297                 'during live migration rollback. You may need to '
7298                 'manually clean up resources in the network service. '
7299                 'Error: %s', self.host, six.text_type(e))
7300         except Exception:
7301             with excutils.save_and_reraise_exception():
7302                 # NOTE(tdurakov): even if teardown networks fails driver
7303                 # should try to rollback live migration on destination.
7304                 LOG.exception('An error occurred while deallocating network.',
7305                               instance=instance)
7306         finally:
7307             # always run this even if setup_networks_on_host fails
7308             # NOTE(vish): The mapping is passed in so the driver can disconnect
7309             #             from remote volumes if necessary
7310             block_device_info = self._get_instance_block_device_info(context,
7311                                                                      instance)
7312             # free any instance PCI claims done on destination during
7313             # check_can_live_migrate_destination()
7314             self.rt.free_pci_device_claims_for_instance(context, instance)
7315 
7316             self.driver.rollback_live_migration_at_destination(
7317                 context, instance, network_info, block_device_info,
7318                 destroy_disks=destroy_disks, migrate_data=migrate_data)
7319 
7320         self._notify_about_instance_usage(
7321                         context, instance, "live_migration.rollback.dest.end",
7322                         network_info=network_info)
7323         compute_utils.notify_about_instance_action(
7324             context, instance, self.host,
7325             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
7326             phase=fields.NotificationPhase.END)
7327 
7328     def _require_nw_info_update(self, context, instance):
7329         """Detect whether there is a mismatch in binding:host_id, or
7330         binding_failed or unbound binding:vif_type for any of the instances
7331         ports.
7332         """
7333         # Only update port bindings if compute manager does manage port
7334         # bindings instead of the compute driver. For example IronicDriver
7335         # manages the port binding for baremetal instance ports, hence,
7336         # external intervention with the binding is not desired.
7337         if (not utils.is_neutron() or
7338                 self.driver.manages_network_binding_host_id()):
7339             return False
7340 
7341         search_opts = {'device_id': instance.uuid,
7342                        'fields': ['binding:host_id', 'binding:vif_type']}
7343         ports = self.network_api.list_ports(context, **search_opts)
7344         for p in ports['ports']:
7345             if p.get('binding:host_id') != self.host:
7346                 return True
7347             vif_type = p.get('binding:vif_type')
7348             if (vif_type == network_model.VIF_TYPE_UNBOUND or
7349                     vif_type == network_model.VIF_TYPE_BINDING_FAILED):
7350                 return True
7351         return False
7352 
7353     @periodic_task.periodic_task(
7354         spacing=CONF.heal_instance_info_cache_interval)
7355     def _heal_instance_info_cache(self, context):
7356         """Called periodically.  On every call, try to update the
7357         info_cache's network information for another instance by
7358         calling to the network manager.
7359 
7360         This is implemented by keeping a cache of uuids of instances
7361         that live on this host.  On each call, we pop one off of a
7362         list, pull the DB record, and try the call to the network API.
7363         If anything errors don't fail, as it's possible the instance
7364         has been deleted, etc.
7365         """
7366         heal_interval = CONF.heal_instance_info_cache_interval
7367         if not heal_interval:
7368             return
7369 
7370         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
7371         instance = None
7372 
7373         LOG.debug('Starting heal instance info cache')
7374 
7375         if not instance_uuids:
7376             # The list of instances to heal is empty so rebuild it
7377             LOG.debug('Rebuilding the list of instances to heal')
7378             db_instances = objects.InstanceList.get_by_host(
7379                 context, self.host, expected_attrs=[], use_slave=True)
7380             for inst in db_instances:
7381                 # We don't want to refresh the cache for instances
7382                 # which are building or deleting so don't put them
7383                 # in the list. If they are building they will get
7384                 # added to the list next time we build it.
7385                 if (inst.vm_state == vm_states.BUILDING):
7386                     LOG.debug('Skipping network cache update for instance '
7387                               'because it is Building.', instance=inst)
7388                     continue
7389                 if (inst.task_state == task_states.DELETING):
7390                     LOG.debug('Skipping network cache update for instance '
7391                               'because it is being deleted.', instance=inst)
7392                     continue
7393 
7394                 if not instance:
7395                     # Save the first one we find so we don't
7396                     # have to get it again
7397                     instance = inst
7398                 else:
7399                     instance_uuids.append(inst['uuid'])
7400 
7401             self._instance_uuids_to_heal = instance_uuids
7402         else:
7403             # Find the next valid instance on the list
7404             while instance_uuids:
7405                 try:
7406                     inst = objects.Instance.get_by_uuid(
7407                             context, instance_uuids.pop(0),
7408                             expected_attrs=['system_metadata', 'info_cache',
7409                                             'flavor'],
7410                             use_slave=True)
7411                 except exception.InstanceNotFound:
7412                     # Instance is gone.  Try to grab another.
7413                     continue
7414 
7415                 # Check the instance hasn't been migrated
7416                 if inst.host != self.host:
7417                     LOG.debug('Skipping network cache update for instance '
7418                               'because it has been migrated to another '
7419                               'host.', instance=inst)
7420                 # Check the instance isn't being deleting
7421                 elif inst.task_state == task_states.DELETING:
7422                     LOG.debug('Skipping network cache update for instance '
7423                               'because it is being deleted.', instance=inst)
7424                 else:
7425                     instance = inst
7426                     break
7427 
7428         if instance:
7429             # We have an instance now to refresh
7430             try:
7431                 # Fix potential mismatch in port binding if evacuation failed
7432                 # after reassigning the port binding to the dest host but
7433                 # before the instance host is changed.
7434                 # Do this only when instance has no pending task.
7435                 if instance.task_state is None and \
7436                         self._require_nw_info_update(context, instance):
7437                     LOG.info("Updating ports in neutron", instance=instance)
7438                     self.network_api.setup_instance_network_on_host(
7439                         context, instance, self.host)
7440                 # Call to network API to get instance info.. this will
7441                 # force an update to the instance's info_cache
7442                 self.network_api.get_instance_nw_info(
7443                     context, instance, force_refresh=True)
7444                 LOG.debug('Updated the network info_cache for instance',
7445                           instance=instance)
7446             except exception.InstanceNotFound:
7447                 # Instance is gone.
7448                 LOG.debug('Instance no longer exists. Unable to refresh',
7449                           instance=instance)
7450                 return
7451             except exception.InstanceInfoCacheNotFound:
7452                 # InstanceInfoCache is gone.
7453                 LOG.debug('InstanceInfoCache no longer exists. '
7454                           'Unable to refresh', instance=instance)
7455             except Exception:
7456                 LOG.error('An error occurred while refreshing the network '
7457                           'cache.', instance=instance, exc_info=True)
7458         else:
7459             LOG.debug("Didn't find any instances for network info cache "
7460                       "update.")
7461 
7462     @periodic_task.periodic_task
7463     def _poll_rebooting_instances(self, context):
7464         if CONF.reboot_timeout > 0:
7465             filters = {'task_state':
7466                        [task_states.REBOOTING,
7467                         task_states.REBOOT_STARTED,
7468                         task_states.REBOOT_PENDING],
7469                        'host': self.host}
7470             rebooting = objects.InstanceList.get_by_filters(
7471                 context, filters, expected_attrs=[], use_slave=True)
7472 
7473             to_poll = []
7474             for instance in rebooting:
7475                 if timeutils.is_older_than(instance.updated_at,
7476                                            CONF.reboot_timeout):
7477                     to_poll.append(instance)
7478 
7479             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
7480 
7481     @periodic_task.periodic_task
7482     def _poll_rescued_instances(self, context):
7483         if CONF.rescue_timeout > 0:
7484             filters = {'vm_state': vm_states.RESCUED,
7485                        'host': self.host}
7486             rescued_instances = objects.InstanceList.get_by_filters(
7487                 context, filters, expected_attrs=["system_metadata"],
7488                 use_slave=True)
7489 
7490             to_unrescue = []
7491             for instance in rescued_instances:
7492                 if timeutils.is_older_than(instance.launched_at,
7493                                            CONF.rescue_timeout):
7494                     to_unrescue.append(instance)
7495 
7496             for instance in to_unrescue:
7497                 self.compute_api.unrescue(context, instance)
7498 
7499     @periodic_task.periodic_task
7500     def _poll_unconfirmed_resizes(self, context):
7501         if CONF.resize_confirm_window == 0:
7502             return
7503 
7504         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
7505                 context, CONF.resize_confirm_window, self.host,
7506                 use_slave=True)
7507 
7508         migrations_info = dict(migration_count=len(migrations),
7509                 confirm_window=CONF.resize_confirm_window)
7510 
7511         if migrations_info["migration_count"] > 0:
7512             LOG.info("Found %(migration_count)d unconfirmed migrations "
7513                      "older than %(confirm_window)d seconds",
7514                      migrations_info)
7515 
7516         def _set_migration_to_error(migration, reason, **kwargs):
7517             LOG.warning("Setting migration %(migration_id)s to error: "
7518                         "%(reason)s",
7519                         {'migration_id': migration['id'], 'reason': reason},
7520                         **kwargs)
7521             migration.status = 'error'
7522             migration.save()
7523 
7524         for migration in migrations:
7525             instance_uuid = migration.instance_uuid
7526             LOG.info("Automatically confirming migration "
7527                      "%(migration_id)s for instance %(instance_uuid)s",
7528                      {'migration_id': migration.id,
7529                       'instance_uuid': instance_uuid})
7530             expected_attrs = ['metadata', 'system_metadata']
7531             try:
7532                 instance = objects.Instance.get_by_uuid(context,
7533                             instance_uuid, expected_attrs=expected_attrs,
7534                             use_slave=True)
7535             except exception.InstanceNotFound:
7536                 reason = (_("Instance %s not found") %
7537                           instance_uuid)
7538                 _set_migration_to_error(migration, reason)
7539                 continue
7540             if instance.vm_state == vm_states.ERROR:
7541                 reason = _("In ERROR state")
7542                 _set_migration_to_error(migration, reason,
7543                                         instance=instance)
7544                 continue
7545             # race condition: The instance in DELETING state should not be
7546             # set the migration state to error, otherwise the instance in
7547             # to be deleted which is in RESIZED state
7548             # will not be able to confirm resize
7549             if instance.task_state in [task_states.DELETING,
7550                                        task_states.SOFT_DELETING]:
7551                 msg = ("Instance being deleted or soft deleted during resize "
7552                        "confirmation. Skipping.")
7553                 LOG.debug(msg, instance=instance)
7554                 continue
7555 
7556             # race condition: This condition is hit when this method is
7557             # called between the save of the migration record with a status of
7558             # finished and the save of the instance object with a state of
7559             # RESIZED. The migration record should not be set to error.
7560             if instance.task_state == task_states.RESIZE_FINISH:
7561                 msg = ("Instance still resizing during resize "
7562                        "confirmation. Skipping.")
7563                 LOG.debug(msg, instance=instance)
7564                 continue
7565 
7566             vm_state = instance.vm_state
7567             task_state = instance.task_state
7568             if vm_state != vm_states.RESIZED or task_state is not None:
7569                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
7570                            "RESIZED/None") %
7571                           {'vm_state': vm_state,
7572                            'task_state': task_state})
7573                 _set_migration_to_error(migration, reason,
7574                                         instance=instance)
7575                 continue
7576             try:
7577                 self.compute_api.confirm_resize(context, instance,
7578                                                 migration=migration)
7579             except Exception as e:
7580                 LOG.info("Error auto-confirming resize: %s. "
7581                          "Will retry later.", e, instance=instance)
7582 
7583     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
7584     def _poll_shelved_instances(self, context):
7585 
7586         if CONF.shelved_offload_time <= 0:
7587             return
7588 
7589         filters = {'vm_state': vm_states.SHELVED,
7590                    'task_state': None,
7591                    'host': self.host}
7592         shelved_instances = objects.InstanceList.get_by_filters(
7593             context, filters=filters, expected_attrs=['system_metadata'],
7594             use_slave=True)
7595 
7596         to_gc = []
7597         for instance in shelved_instances:
7598             sys_meta = instance.system_metadata
7599             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
7600             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
7601                 to_gc.append(instance)
7602 
7603         for instance in to_gc:
7604             try:
7605                 instance.task_state = task_states.SHELVING_OFFLOADING
7606                 instance.save(expected_task_state=(None,))
7607                 self.shelve_offload_instance(context, instance,
7608                                              clean_shutdown=False)
7609             except Exception:
7610                 LOG.exception('Periodic task failed to offload instance.',
7611                               instance=instance)
7612 
7613     @periodic_task.periodic_task
7614     def _instance_usage_audit(self, context):
7615         if not CONF.instance_usage_audit:
7616             return
7617 
7618         begin, end = utils.last_completed_audit_period()
7619         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
7620                                self.host):
7621             return
7622 
7623         instances = objects.InstanceList.get_active_by_window_joined(
7624             context, begin, end, host=self.host,
7625             expected_attrs=['system_metadata', 'info_cache', 'metadata',
7626                             'flavor'],
7627             use_slave=True)
7628         num_instances = len(instances)
7629         errors = 0
7630         successes = 0
7631         LOG.info("Running instance usage audit for host %(host)s "
7632                  "from %(begin_time)s to %(end_time)s. "
7633                  "%(number_instances)s instances.",
7634                  {'host': self.host,
7635                   'begin_time': begin,
7636                   'end_time': end,
7637                   'number_instances': num_instances})
7638         start_time = time.time()
7639         task_log = objects.TaskLog(context)
7640         task_log.task_name = 'instance_usage_audit'
7641         task_log.period_beginning = begin
7642         task_log.period_ending = end
7643         task_log.host = self.host
7644         task_log.task_items = num_instances
7645         task_log.message = 'Instance usage audit started...'
7646         task_log.begin_task()
7647         for instance in instances:
7648             try:
7649                 compute_utils.notify_usage_exists(
7650                     self.notifier, context, instance, self.host,
7651                     ignore_missing_network_data=False)
7652                 successes += 1
7653             except Exception:
7654                 LOG.exception('Failed to generate usage '
7655                               'audit for instance '
7656                               'on host %s', self.host,
7657                               instance=instance)
7658                 errors += 1
7659         task_log.errors = errors
7660         task_log.message = (
7661             'Instance usage audit ran for host %s, %s instances in %s seconds.'
7662             % (self.host, num_instances, time.time() - start_time))
7663         task_log.end_task()
7664 
7665     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
7666     def _poll_bandwidth_usage(self, context):
7667 
7668         if not self._bw_usage_supported:
7669             return
7670 
7671         prev_time, start_time = utils.last_completed_audit_period()
7672 
7673         curr_time = time.time()
7674         if (curr_time - self._last_bw_usage_poll >
7675                 CONF.bandwidth_poll_interval):
7676             self._last_bw_usage_poll = curr_time
7677             LOG.info("Updating bandwidth usage cache")
7678 
7679             instances = objects.InstanceList.get_by_host(context,
7680                                                               self.host,
7681                                                               use_slave=True)
7682             try:
7683                 bw_counters = self.driver.get_all_bw_counters(instances)
7684             except NotImplementedError:
7685                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
7686                 # implemented yet.  If they don't it doesn't break anything,
7687                 # they just don't get the info in the usage events.
7688                 # NOTE(PhilDay): Record that its not supported so we can
7689                 # skip fast on future calls rather than waste effort getting
7690                 # the list of instances.
7691                 LOG.info("Bandwidth usage not supported by %(driver)s.",
7692                          {'driver': CONF.compute_driver})
7693                 self._bw_usage_supported = False
7694                 return
7695 
7696             refreshed = timeutils.utcnow()
7697             for bw_ctr in bw_counters:
7698                 # Allow switching of greenthreads between queries.
7699                 greenthread.sleep(0)
7700                 bw_in = 0
7701                 bw_out = 0
7702                 last_ctr_in = None
7703                 last_ctr_out = None
7704                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
7705                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
7706                     start_period=start_time, use_slave=True)
7707                 if usage:
7708                     bw_in = usage.bw_in
7709                     bw_out = usage.bw_out
7710                     last_ctr_in = usage.last_ctr_in
7711                     last_ctr_out = usage.last_ctr_out
7712                 else:
7713                     usage = (objects.BandwidthUsage.
7714                              get_by_instance_uuid_and_mac(
7715                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
7716                         start_period=prev_time, use_slave=True))
7717                     if usage:
7718                         last_ctr_in = usage.last_ctr_in
7719                         last_ctr_out = usage.last_ctr_out
7720 
7721                 if last_ctr_in is not None:
7722                     if bw_ctr['bw_in'] < last_ctr_in:
7723                         # counter rollover
7724                         bw_in += bw_ctr['bw_in']
7725                     else:
7726                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
7727 
7728                 if last_ctr_out is not None:
7729                     if bw_ctr['bw_out'] < last_ctr_out:
7730                         # counter rollover
7731                         bw_out += bw_ctr['bw_out']
7732                     else:
7733                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
7734 
7735                 objects.BandwidthUsage(context=context).create(
7736                                               bw_ctr['uuid'],
7737                                               bw_ctr['mac_address'],
7738                                               bw_in,
7739                                               bw_out,
7740                                               bw_ctr['bw_in'],
7741                                               bw_ctr['bw_out'],
7742                                               start_period=start_time,
7743                                               last_refreshed=refreshed)
7744 
7745     def _get_host_volume_bdms(self, context, use_slave=False):
7746         """Return all block device mappings on a compute host."""
7747         compute_host_bdms = []
7748         instances = objects.InstanceList.get_by_host(context, self.host,
7749             use_slave=use_slave)
7750         for instance in instances:
7751             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7752                     context, instance.uuid, use_slave=use_slave)
7753             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
7754             compute_host_bdms.append(dict(instance=instance,
7755                                           instance_bdms=instance_bdms))
7756 
7757         return compute_host_bdms
7758 
7759     def _update_volume_usage_cache(self, context, vol_usages):
7760         """Updates the volume usage cache table with a list of stats."""
7761         for usage in vol_usages:
7762             # Allow switching of greenthreads between queries.
7763             greenthread.sleep(0)
7764             vol_usage = objects.VolumeUsage(context)
7765             vol_usage.volume_id = usage['volume']
7766             vol_usage.instance_uuid = usage['instance'].uuid
7767             vol_usage.project_id = usage['instance'].project_id
7768             vol_usage.user_id = usage['instance'].user_id
7769             vol_usage.availability_zone = usage['instance'].availability_zone
7770             vol_usage.curr_reads = usage['rd_req']
7771             vol_usage.curr_read_bytes = usage['rd_bytes']
7772             vol_usage.curr_writes = usage['wr_req']
7773             vol_usage.curr_write_bytes = usage['wr_bytes']
7774             vol_usage.save()
7775             self.notifier.info(context, 'volume.usage', vol_usage.to_dict())
7776             compute_utils.notify_about_volume_usage(context, vol_usage,
7777                                                     self.host)
7778 
7779     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
7780     def _poll_volume_usage(self, context):
7781         if CONF.volume_usage_poll_interval == 0:
7782             return
7783 
7784         compute_host_bdms = self._get_host_volume_bdms(context,
7785                                                        use_slave=True)
7786         if not compute_host_bdms:
7787             return
7788 
7789         LOG.debug("Updating volume usage cache")
7790         try:
7791             vol_usages = self.driver.get_all_volume_usage(context,
7792                                                           compute_host_bdms)
7793         except NotImplementedError:
7794             return
7795 
7796         self._update_volume_usage_cache(context, vol_usages)
7797 
7798     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
7799                                  run_immediately=True)
7800     def _sync_power_states(self, context):
7801         """Align power states between the database and the hypervisor.
7802 
7803         To sync power state data we make a DB call to get the number of
7804         virtual machines known by the hypervisor and if the number matches the
7805         number of virtual machines known by the database, we proceed in a lazy
7806         loop, one database record at a time, checking if the hypervisor has the
7807         same power state as is in the database.
7808         """
7809         db_instances = objects.InstanceList.get_by_host(context, self.host,
7810                                                         expected_attrs=[],
7811                                                         use_slave=True)
7812 
7813         try:
7814             num_vm_instances = self.driver.get_num_instances()
7815         except exception.VirtDriverNotReady as e:
7816             # If the virt driver is not ready, like ironic-api not being up
7817             # yet in the case of ironic, just log it and exit.
7818             LOG.info('Skipping _sync_power_states periodic task due to: %s', e)
7819             return
7820 
7821         num_db_instances = len(db_instances)
7822 
7823         if num_vm_instances != num_db_instances:
7824             LOG.warning("While synchronizing instance power states, found "
7825                         "%(num_db_instances)s instances in the database "
7826                         "and %(num_vm_instances)s instances on the "
7827                         "hypervisor.",
7828                         {'num_db_instances': num_db_instances,
7829                          'num_vm_instances': num_vm_instances})
7830 
7831         def _sync(db_instance):
7832             # NOTE(melwitt): This must be synchronized as we query state from
7833             #                two separate sources, the driver and the database.
7834             #                They are set (in stop_instance) and read, in sync.
7835             @utils.synchronized(db_instance.uuid)
7836             def query_driver_power_state_and_sync():
7837                 self._query_driver_power_state_and_sync(context, db_instance)
7838 
7839             try:
7840                 query_driver_power_state_and_sync()
7841             except Exception:
7842                 LOG.exception("Periodic sync_power_state task had an "
7843                               "error while processing an instance.",
7844                               instance=db_instance)
7845 
7846             self._syncs_in_progress.pop(db_instance.uuid)
7847 
7848         for db_instance in db_instances:
7849             # process syncs asynchronously - don't want instance locking to
7850             # block entire periodic task thread
7851             uuid = db_instance.uuid
7852             if uuid in self._syncs_in_progress:
7853                 LOG.debug('Sync already in progress for %s', uuid)
7854             else:
7855                 LOG.debug('Triggering sync for uuid %s', uuid)
7856                 self._syncs_in_progress[uuid] = True
7857                 self._sync_power_pool.spawn_n(_sync, db_instance)
7858 
7859     def _query_driver_power_state_and_sync(self, context, db_instance):
7860         if db_instance.task_state is not None:
7861             LOG.info("During sync_power_state the instance has a "
7862                      "pending task (%(task)s). Skip.",
7863                      {'task': db_instance.task_state}, instance=db_instance)
7864             return
7865         # No pending tasks. Now try to figure out the real vm_power_state.
7866         try:
7867             vm_instance = self.driver.get_info(db_instance)
7868             vm_power_state = vm_instance.state
7869         except exception.InstanceNotFound:
7870             vm_power_state = power_state.NOSTATE
7871         # Note(maoy): the above get_info call might take a long time,
7872         # for example, because of a broken libvirt driver.
7873         try:
7874             self._sync_instance_power_state(context,
7875                                             db_instance,
7876                                             vm_power_state,
7877                                             use_slave=True)
7878         except exception.InstanceNotFound:
7879             # NOTE(hanlind): If the instance gets deleted during sync,
7880             # silently ignore.
7881             pass
7882 
7883     def _stop_unexpected_shutdown_instance(self, context, vm_state,
7884                                            db_instance, orig_db_power_state):
7885         # this is an exceptional case; make sure our data is up
7886         # to date before slamming through a power off
7887         vm_instance = self.driver.get_info(db_instance,
7888                                            use_cache=False)
7889         vm_power_state = vm_instance.state
7890 
7891         # if it still looks off, go ahead and call stop()
7892         if vm_power_state in (power_state.SHUTDOWN,
7893                               power_state.CRASHED):
7894 
7895             LOG.warning("Instance shutdown by itself. Calling the "
7896                         "stop API. Current vm_state: %(vm_state)s, "
7897                         "current task_state: %(task_state)s, "
7898                         "original DB power_state: %(db_power_state)s, "
7899                         "current VM power_state: %(vm_power_state)s",
7900                         {'vm_state': vm_state,
7901                          'task_state': db_instance.task_state,
7902                          'db_power_state': orig_db_power_state,
7903                          'vm_power_state': vm_power_state},
7904                         instance=db_instance)
7905             try:
7906                 # Note(maoy): here we call the API instead of
7907                 # brutally updating the vm_state in the database
7908                 # to allow all the hooks and checks to be performed.
7909                 if db_instance.shutdown_terminate:
7910                     self.compute_api.delete(context, db_instance)
7911                 else:
7912                     self.compute_api.stop(context, db_instance)
7913             except Exception:
7914                 # Note(maoy): there is no need to propagate the error
7915                 # because the same power_state will be retrieved next
7916                 # time and retried.
7917                 # For example, there might be another task scheduled.
7918                 LOG.exception("error during stop() in sync_power_state.",
7919                               instance=db_instance)
7920 
7921     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
7922                                    use_slave=False):
7923         """Align instance power state between the database and hypervisor.
7924 
7925         If the instance is not found on the hypervisor, but is in the database,
7926         then a stop() API will be called on the instance.
7927         """
7928 
7929         # We re-query the DB to get the latest instance info to minimize
7930         # (not eliminate) race condition.
7931         db_instance.refresh(use_slave=use_slave)
7932         db_power_state = db_instance.power_state
7933         vm_state = db_instance.vm_state
7934 
7935         if self.host != db_instance.host:
7936             # on the sending end of nova-compute _sync_power_state
7937             # may have yielded to the greenthread performing a live
7938             # migration; this in turn has changed the resident-host
7939             # for the VM; However, the instance is still active, it
7940             # is just in the process of migrating to another host.
7941             # This implies that the compute source must relinquish
7942             # control to the compute destination.
7943             LOG.info("During the sync_power process the "
7944                      "instance has moved from "
7945                      "host %(src)s to host %(dst)s",
7946                      {'src': db_instance.host,
7947                       'dst': self.host},
7948                      instance=db_instance)
7949             return
7950         elif db_instance.task_state is not None:
7951             # on the receiving end of nova-compute, it could happen
7952             # that the DB instance already report the new resident
7953             # but the actual VM has not showed up on the hypervisor
7954             # yet. In this case, let's allow the loop to continue
7955             # and run the state sync in a later round
7956             LOG.info("During sync_power_state the instance has a "
7957                      "pending task (%(task)s). Skip.",
7958                      {'task': db_instance.task_state},
7959                      instance=db_instance)
7960             return
7961 
7962         orig_db_power_state = db_power_state
7963         if vm_power_state != db_power_state:
7964             LOG.info('During _sync_instance_power_state the DB '
7965                      'power_state (%(db_power_state)s) does not match '
7966                      'the vm_power_state from the hypervisor '
7967                      '(%(vm_power_state)s). Updating power_state in the '
7968                      'DB to match the hypervisor.',
7969                      {'db_power_state': db_power_state,
7970                       'vm_power_state': vm_power_state},
7971                      instance=db_instance)
7972             # power_state is always updated from hypervisor to db
7973             db_instance.power_state = vm_power_state
7974             db_instance.save()
7975             db_power_state = vm_power_state
7976 
7977         # Note(maoy): Now resolve the discrepancy between vm_state and
7978         # vm_power_state. We go through all possible vm_states.
7979         if vm_state in (vm_states.BUILDING,
7980                         vm_states.RESCUED,
7981                         vm_states.RESIZED,
7982                         vm_states.SUSPENDED,
7983                         vm_states.ERROR):
7984             # TODO(maoy): we ignore these vm_state for now.
7985             pass
7986         elif vm_state == vm_states.ACTIVE:
7987             # The only rational power state should be RUNNING
7988             if vm_power_state in (power_state.SHUTDOWN,
7989                                   power_state.CRASHED):
7990                 self._stop_unexpected_shutdown_instance(
7991                     context, vm_state, db_instance, orig_db_power_state)
7992             elif vm_power_state == power_state.SUSPENDED:
7993                 LOG.warning("Instance is suspended unexpectedly. Calling "
7994                             "the stop API.", instance=db_instance)
7995                 try:
7996                     self.compute_api.stop(context, db_instance)
7997                 except Exception:
7998                     LOG.exception("error during stop() in sync_power_state.",
7999                                   instance=db_instance)
8000             elif vm_power_state == power_state.PAUSED:
8001                 # Note(maoy): a VM may get into the paused state not only
8002                 # because the user request via API calls, but also
8003                 # due to (temporary) external instrumentations.
8004                 # Before the virt layer can reliably report the reason,
8005                 # we simply ignore the state discrepancy. In many cases,
8006                 # the VM state will go back to running after the external
8007                 # instrumentation is done. See bug 1097806 for details.
8008                 LOG.warning("Instance is paused unexpectedly. Ignore.",
8009                             instance=db_instance)
8010             elif vm_power_state == power_state.NOSTATE:
8011                 # Occasionally, depending on the status of the hypervisor,
8012                 # which could be restarting for example, an instance may
8013                 # not be found.  Therefore just log the condition.
8014                 LOG.warning("Instance is unexpectedly not found. Ignore.",
8015                             instance=db_instance)
8016         elif vm_state == vm_states.STOPPED:
8017             if vm_power_state not in (power_state.NOSTATE,
8018                                       power_state.SHUTDOWN,
8019                                       power_state.CRASHED):
8020                 LOG.warning("Instance is not stopped. Calling "
8021                             "the stop API. Current vm_state: %(vm_state)s,"
8022                             " current task_state: %(task_state)s, "
8023                             "original DB power_state: %(db_power_state)s, "
8024                             "current VM power_state: %(vm_power_state)s",
8025                             {'vm_state': vm_state,
8026                              'task_state': db_instance.task_state,
8027                              'db_power_state': orig_db_power_state,
8028                              'vm_power_state': vm_power_state},
8029                             instance=db_instance)
8030                 try:
8031                     # NOTE(russellb) Force the stop, because normally the
8032                     # compute API would not allow an attempt to stop a stopped
8033                     # instance.
8034                     self.compute_api.force_stop(context, db_instance)
8035                 except Exception:
8036                     LOG.exception("error during stop() in sync_power_state.",
8037                                   instance=db_instance)
8038         elif vm_state == vm_states.PAUSED:
8039             if vm_power_state in (power_state.SHUTDOWN,
8040                                   power_state.CRASHED):
8041                 LOG.warning("Paused instance shutdown by itself. Calling "
8042                             "the stop API.", instance=db_instance)
8043                 try:
8044                     self.compute_api.force_stop(context, db_instance)
8045                 except Exception:
8046                     LOG.exception("error during stop() in sync_power_state.",
8047                                   instance=db_instance)
8048         elif vm_state in (vm_states.SOFT_DELETED,
8049                           vm_states.DELETED):
8050             if vm_power_state not in (power_state.NOSTATE,
8051                                       power_state.SHUTDOWN):
8052                 # Note(maoy): this should be taken care of periodically in
8053                 # _cleanup_running_deleted_instances().
8054                 LOG.warning("Instance is not (soft-)deleted.",
8055                             instance=db_instance)
8056 
8057     @periodic_task.periodic_task
8058     def _reclaim_queued_deletes(self, context):
8059         """Reclaim instances that are queued for deletion."""
8060         interval = CONF.reclaim_instance_interval
8061         if interval <= 0:
8062             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
8063             return
8064 
8065         filters = {'vm_state': vm_states.SOFT_DELETED,
8066                    'task_state': None,
8067                    'host': self.host}
8068         instances = objects.InstanceList.get_by_filters(
8069             context, filters,
8070             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
8071             use_slave=True)
8072         for instance in instances:
8073             if self._deleted_old_enough(instance, interval):
8074                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
8075                         context, instance.uuid)
8076                 LOG.info('Reclaiming deleted instance', instance=instance)
8077                 try:
8078                     self._delete_instance(context, instance, bdms)
8079                 except Exception as e:
8080                     LOG.warning("Periodic reclaim failed to delete "
8081                                 "instance: %s",
8082                                 e, instance=instance)
8083 
8084     def _get_nodename(self, instance, refresh=False):
8085         """Helper method to get the name of the first available node
8086         on this host. This method should not be used with any operations
8087         on ironic instances since it does not handle multiple nodes.
8088         """
8089         node = self.driver.get_available_nodes(refresh=refresh)[0]
8090         LOG.debug("No node specified, defaulting to %s", node,
8091                   instance=instance)
8092         return node
8093 
8094     def _update_available_resource_for_node(self, context, nodename,
8095                                             startup=False):
8096 
8097         try:
8098             self.rt.update_available_resource(context, nodename,
8099                                               startup=startup)
8100         except exception.ComputeHostNotFound:
8101             LOG.warning("Compute node '%s' not found in "
8102                         "update_available_resource.", nodename)
8103         except exception.ReshapeFailed:
8104             # We're only supposed to get here on startup, if a reshape was
8105             # needed, was attempted, and failed. We want to kill the service.
8106             with excutils.save_and_reraise_exception():
8107                 LOG.critical("Resource provider data migration failed "
8108                              "fatally during startup for node %s.", nodename)
8109         except exception.ReshapeNeeded:
8110             # This exception should only find its way here if the virt driver's
8111             # update_provider_tree raised it incorrectly: either
8112             # a) After the resource tracker already caught it once and
8113             # reinvoked update_provider_tree with allocations. At this point
8114             # the driver is just supposed to *do* the reshape, so if it raises
8115             # ReshapeNeeded, it's a bug, and we want to kill the compute
8116             # service.
8117             # b) On periodic rather than startup (we only allow reshapes to
8118             # happen on startup). In this case we'll just make the logs red and
8119             # go again at the next periodic interval, where the same thing may
8120             # or may not happen again. Depending on the previous and intended
8121             # shape of the providers/inventories, this may not actually cause
8122             # any immediately visible symptoms (in terms of scheduling, etc.)
8123             # If this becomes a problem, we may wish to make it pop immediately
8124             # (e.g. disable the service).
8125             with excutils.save_and_reraise_exception():
8126                 LOG.exception("ReshapeNeeded exception is unexpected here!")
8127         except Exception:
8128             LOG.exception("Error updating resources for node %(node)s.",
8129                           {'node': nodename})
8130 
8131     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
8132     def update_available_resource(self, context, startup=False):
8133         """See driver.get_available_resource()
8134 
8135         Periodic process that keeps that the compute host's understanding of
8136         resource availability and usage in sync with the underlying hypervisor.
8137 
8138         :param context: security context
8139         :param startup: True if this is being called when the nova-compute
8140             service is starting, False otherwise.
8141         """
8142 
8143         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
8144                                                             use_slave=True,
8145                                                             startup=startup)
8146         try:
8147             nodenames = set(self.driver.get_available_nodes())
8148         except exception.VirtDriverNotReady:
8149             LOG.warning("Virt driver is not ready.")
8150             return
8151 
8152         # Delete orphan compute node not reported by driver but still in db
8153         for cn in compute_nodes_in_db:
8154             if cn.hypervisor_hostname not in nodenames:
8155                 LOG.info("Deleting orphan compute node %(id)s "
8156                          "hypervisor host is %(hh)s, "
8157                          "nodes are %(nodes)s",
8158                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
8159                           'nodes': nodenames})
8160                 cn.destroy()
8161                 self.rt.remove_node(cn.hypervisor_hostname)
8162                 # Delete the corresponding resource provider in placement,
8163                 # along with any associated allocations and inventory.
8164                 self.reportclient.delete_resource_provider(context, cn,
8165                                                            cascade=True)
8166 
8167         for nodename in nodenames:
8168             self._update_available_resource_for_node(context, nodename,
8169                                                      startup=startup)
8170 
8171     def _get_compute_nodes_in_db(self, context, use_slave=False,
8172                                  startup=False):
8173         try:
8174             return objects.ComputeNodeList.get_all_by_host(context, self.host,
8175                                                            use_slave=use_slave)
8176         except exception.NotFound:
8177             if startup:
8178                 LOG.warning(
8179                     "No compute node record found for host %s. If this is "
8180                     "the first time this service is starting on this "
8181                     "host, then you can ignore this warning.", self.host)
8182             else:
8183                 LOG.error("No compute node record for host %s", self.host)
8184             return []
8185 
8186     @periodic_task.periodic_task(
8187         spacing=CONF.running_deleted_instance_poll_interval,
8188         run_immediately=True)
8189     def _cleanup_running_deleted_instances(self, context):
8190         """Cleanup any instances which are erroneously still running after
8191         having been deleted.
8192 
8193         Valid actions to take are:
8194 
8195             1. noop - do nothing
8196             2. log - log which instances are erroneously running
8197             3. reap - shutdown and cleanup any erroneously running instances
8198             4. shutdown - power off *and disable* any erroneously running
8199                           instances
8200 
8201         The use-case for this cleanup task is: for various reasons, it may be
8202         possible for the database to show an instance as deleted but for that
8203         instance to still be running on a host machine (see bug
8204         https://bugs.launchpad.net/nova/+bug/911366).
8205 
8206         This cleanup task is a cross-hypervisor utility for finding these
8207         zombied instances and either logging the discrepancy (likely what you
8208         should do in production), or automatically reaping the instances (more
8209         appropriate for dev environments).
8210         """
8211         action = CONF.running_deleted_instance_action
8212 
8213         if action == "noop":
8214             return
8215 
8216         # NOTE(sirp): admin contexts don't ordinarily return deleted records
8217         with utils.temporary_mutation(context, read_deleted="yes"):
8218             for instance in self._running_deleted_instances(context):
8219                 if action == "log":
8220                     LOG.warning("Detected instance with name label "
8221                                 "'%s' which is marked as "
8222                                 "DELETED but still present on host.",
8223                                 instance.name, instance=instance)
8224 
8225                 elif action == 'shutdown':
8226                     LOG.info("Powering off instance with name label "
8227                              "'%s' which is marked as "
8228                              "DELETED but still present on host.",
8229                              instance.name, instance=instance)
8230                     try:
8231                         try:
8232                             # disable starting the instance
8233                             self.driver.set_bootable(instance, False)
8234                         except NotImplementedError:
8235                             LOG.debug("set_bootable is not implemented "
8236                                       "for the current driver")
8237                         # and power it off
8238                         self.driver.power_off(instance)
8239                     except Exception:
8240                         LOG.warning("Failed to power off instance",
8241                                     instance=instance, exc_info=True)
8242 
8243                 elif action == 'reap':
8244                     LOG.info("Destroying instance with name label "
8245                              "'%s' which is marked as "
8246                              "DELETED but still present on host.",
8247                              instance.name, instance=instance)
8248                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
8249                         context, instance.uuid, use_slave=True)
8250                     self.instance_events.clear_events_for_instance(instance)
8251                     try:
8252                         self._shutdown_instance(context, instance, bdms,
8253                                                 notify=False)
8254                         self._cleanup_volumes(context, instance, bdms,
8255                                               detach=False)
8256                     except Exception as e:
8257                         LOG.warning("Periodic cleanup failed to delete "
8258                                     "instance: %s",
8259                                     e, instance=instance)
8260                 else:
8261                     raise Exception(_("Unrecognized value '%s'"
8262                                       " for CONF.running_deleted_"
8263                                       "instance_action") % action)
8264 
8265     def _running_deleted_instances(self, context):
8266         """Returns a list of instances nova thinks is deleted,
8267         but the hypervisor thinks is still running.
8268         """
8269         timeout = CONF.running_deleted_instance_timeout
8270         filters = {'deleted': True,
8271                    'soft_deleted': False}
8272         instances = self._get_instances_on_driver(context, filters)
8273         return [i for i in instances if self._deleted_old_enough(i, timeout)]
8274 
8275     def _deleted_old_enough(self, instance, timeout):
8276         deleted_at = instance.deleted_at
8277         if deleted_at:
8278             deleted_at = deleted_at.replace(tzinfo=None)
8279         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
8280 
8281     @contextlib.contextmanager
8282     def _error_out_instance_on_exception(self, context, instance,
8283                                          instance_state=vm_states.ACTIVE):
8284         instance_uuid = instance.uuid
8285         try:
8286             yield
8287         except NotImplementedError as error:
8288             with excutils.save_and_reraise_exception():
8289                 LOG.info("Setting instance back to %(state)s after: "
8290                          "%(error)s",
8291                          {'state': instance_state, 'error': error},
8292                          instance_uuid=instance_uuid)
8293                 self._instance_update(context, instance,
8294                                       vm_state=instance_state,
8295                                       task_state=None)
8296         except exception.InstanceFaultRollback as error:
8297             LOG.info("Setting instance back to ACTIVE after: %s",
8298                      error, instance_uuid=instance_uuid)
8299             self._instance_update(context, instance,
8300                                   vm_state=vm_states.ACTIVE,
8301                                   task_state=None)
8302             raise error.inner_exception
8303         except Exception:
8304             LOG.exception('Setting instance vm_state to ERROR',
8305                           instance_uuid=instance_uuid)
8306             with excutils.save_and_reraise_exception():
8307                 self._set_instance_obj_error_state(context, instance)
8308 
8309     @wrap_exception()
8310     def add_aggregate_host(self, context, aggregate, host, slave_info):
8311         """Notify hypervisor of change (for hypervisor pools)."""
8312         try:
8313             self.driver.add_to_aggregate(context, aggregate, host,
8314                                          slave_info=slave_info)
8315         except NotImplementedError:
8316             LOG.debug('Hypervisor driver does not support '
8317                       'add_aggregate_host')
8318         except exception.AggregateError:
8319             with excutils.save_and_reraise_exception():
8320                 self.driver.undo_aggregate_operation(
8321                                     context,
8322                                     aggregate.delete_host,
8323                                     aggregate, host)
8324 
8325     @wrap_exception()
8326     def remove_aggregate_host(self, context, host, slave_info, aggregate):
8327         """Removes a host from a physical hypervisor pool."""
8328         try:
8329             self.driver.remove_from_aggregate(context, aggregate, host,
8330                                               slave_info=slave_info)
8331         except NotImplementedError:
8332             LOG.debug('Hypervisor driver does not support '
8333                       'remove_aggregate_host')
8334         except (exception.AggregateError,
8335                 exception.InvalidAggregateAction) as e:
8336             with excutils.save_and_reraise_exception():
8337                 self.driver.undo_aggregate_operation(
8338                                     context,
8339                                     aggregate.add_host,
8340                                     aggregate, host,
8341                                     isinstance(e, exception.AggregateError))
8342 
8343     def _process_instance_event(self, instance, event):
8344         _event = self.instance_events.pop_instance_event(instance, event)
8345         if _event:
8346             LOG.debug('Processing event %(event)s',
8347                       {'event': event.key}, instance=instance)
8348             _event.send(event)
8349         else:
8350             # If it's a network-vif-unplugged event and the instance is being
8351             # deleted or live migrated then we don't need to make this a
8352             # warning as it's expected. There are other expected things which
8353             # could trigger this event like detaching an interface, but we
8354             # don't have a task state for that.
8355             # TODO(mriedem): We have other move operations and things like
8356             # hard reboot (probably rebuild as well) which trigger this event
8357             # but nothing listens for network-vif-unplugged. We should either
8358             # handle those other known cases or consider just not logging a
8359             # warning if we get this event and the instance is undergoing some
8360             # task state transition.
8361             if (event.name == 'network-vif-unplugged' and
8362                     instance.task_state in (
8363                         task_states.DELETING, task_states.MIGRATING)):
8364                 LOG.debug('Received event %s for instance with task_state %s.',
8365                           event.key, instance.task_state, instance=instance)
8366             else:
8367                 LOG.warning('Received unexpected event %(event)s for '
8368                             'instance with vm_state %(vm_state)s and '
8369                             'task_state %(task_state)s.',
8370                             {'event': event.key,
8371                              'vm_state': instance.vm_state,
8372                              'task_state': instance.task_state},
8373                             instance=instance)
8374 
8375     def _process_instance_vif_deleted_event(self, context, instance,
8376                                             deleted_vif_id):
8377         # If an attached port is deleted by neutron, it needs to
8378         # be detached from the instance.
8379         # And info cache needs to be updated.
8380         network_info = instance.info_cache.network_info
8381         for index, vif in enumerate(network_info):
8382             if vif['id'] == deleted_vif_id:
8383                 LOG.info('Neutron deleted interface %(intf)s; '
8384                          'detaching it from the instance and '
8385                          'deleting it from the info cache',
8386                          {'intf': vif['id']},
8387                          instance=instance)
8388                 profile = vif.get('profile', {}) or {}  # profile can be None
8389                 if profile.get('allocation'):
8390                     LOG.error(
8391                         'The bound port %(port_id)s is deleted in Neutron but '
8392                         'the resource allocation on the resource provider '
8393                         '%(rp_uuid)s is leaked until the server '
8394                         '%(server_uuid)s is deleted.',
8395                         {'port_id': vif['id'],
8396                          'rp_uuid': vif['profile']['allocation'],
8397                          'server_uuid': instance.uuid})
8398 
8399                 del network_info[index]
8400                 base_net_api.update_instance_cache_with_nw_info(
8401                                  self.network_api, context,
8402                                  instance,
8403                                  nw_info=network_info)
8404                 try:
8405                     self.driver.detach_interface(context, instance, vif)
8406                 except NotImplementedError:
8407                     # Not all virt drivers support attach/detach of interfaces
8408                     # yet (like Ironic), so just ignore this.
8409                     pass
8410                 except exception.NovaException as ex:
8411                     # If the instance was deleted before the interface was
8412                     # detached, just log it at debug.
8413                     log_level = (logging.DEBUG
8414                                  if isinstance(ex, exception.InstanceNotFound)
8415                                  else logging.WARNING)
8416                     LOG.log(log_level,
8417                             "Detach interface failed, "
8418                             "port_id=%(port_id)s, reason: %(msg)s",
8419                             {'port_id': deleted_vif_id, 'msg': ex},
8420                             instance=instance)
8421                 break
8422 
8423     @wrap_instance_event(prefix='compute')
8424     @wrap_instance_fault
8425     def extend_volume(self, context, instance, extended_volume_id):
8426 
8427         # If an attached volume is extended by cinder, it needs to
8428         # be extended by virt driver so host can detect its new size.
8429         # And bdm needs to be updated.
8430         LOG.debug('Handling volume-extended event for volume %(vol)s',
8431                   {'vol': extended_volume_id}, instance=instance)
8432 
8433         try:
8434             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
8435                    context, extended_volume_id, instance.uuid)
8436         except exception.NotFound:
8437             LOG.warning('Extend volume failed, '
8438                         'volume %(vol)s is not attached to instance.',
8439                         {'vol': extended_volume_id},
8440                         instance=instance)
8441             return
8442 
8443         LOG.info('Cinder extended volume %(vol)s; '
8444                  'extending it to detect new size',
8445                  {'vol': extended_volume_id},
8446                  instance=instance)
8447         volume = self.volume_api.get(context, bdm.volume_id)
8448 
8449         if bdm.connection_info is None:
8450             LOG.warning('Extend volume failed, '
8451                         'attached volume %(vol)s has no connection_info',
8452                         {'vol': extended_volume_id},
8453                         instance=instance)
8454             return
8455 
8456         connection_info = jsonutils.loads(bdm.connection_info)
8457         bdm.volume_size = volume['size']
8458         bdm.save()
8459 
8460         if not self.driver.capabilities.get('supports_extend_volume', False):
8461             raise exception.ExtendVolumeNotSupported()
8462 
8463         try:
8464             self.driver.extend_volume(connection_info,
8465                                       instance,
8466                                       bdm.volume_size * units.Gi)
8467         except Exception as ex:
8468             LOG.warning('Extend volume failed, '
8469                         'volume_id=%(volume_id)s, reason: %(msg)s',
8470                         {'volume_id': extended_volume_id, 'msg': ex},
8471                         instance=instance)
8472             raise
8473 
8474     @wrap_exception()
8475     def external_instance_event(self, context, instances, events):
8476         # NOTE(danms): Some event types are handled by the manager, such
8477         # as when we're asked to update the instance's info_cache. If it's
8478         # not one of those, look for some thread(s) waiting for the event and
8479         # unblock them if so.
8480         for event in events:
8481             instance = [inst for inst in instances
8482                         if inst.uuid == event.instance_uuid][0]
8483             LOG.debug('Received event %(event)s',
8484                       {'event': event.key},
8485                       instance=instance)
8486             if event.name == 'network-changed':
8487                 try:
8488                     LOG.debug('Refreshing instance network info cache due to '
8489                               'event %s.', event.key, instance=instance)
8490                     self.network_api.get_instance_nw_info(
8491                         context, instance, refresh_vif_id=event.tag)
8492                 except exception.NotFound as e:
8493                     LOG.info('Failed to process external instance event '
8494                              '%(event)s due to: %(error)s',
8495                              {'event': event.key, 'error': six.text_type(e)},
8496                              instance=instance)
8497             elif event.name == 'network-vif-deleted':
8498                 try:
8499                     self._process_instance_vif_deleted_event(context,
8500                                                              instance,
8501                                                              event.tag)
8502                 except exception.NotFound as e:
8503                     LOG.info('Failed to process external instance event '
8504                              '%(event)s due to: %(error)s',
8505                              {'event': event.key, 'error': six.text_type(e)},
8506                              instance=instance)
8507             elif event.name == 'volume-extended':
8508                 self.extend_volume(context, instance, event.tag)
8509             else:
8510                 self._process_instance_event(instance, event)
8511 
8512     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
8513                                  external_process_ok=True)
8514     def _run_image_cache_manager_pass(self, context):
8515         """Run a single pass of the image cache manager."""
8516 
8517         if not self.driver.capabilities.get("has_imagecache", False):
8518             return
8519 
8520         # Determine what other nodes use this storage
8521         storage_users.register_storage_use(CONF.instances_path, CONF.host)
8522         nodes = storage_users.get_storage_users(CONF.instances_path)
8523 
8524         # Filter all_instances to only include those nodes which share this
8525         # storage path.
8526         # TODO(mikal): this should be further refactored so that the cache
8527         # cleanup code doesn't know what those instances are, just a remote
8528         # count, and then this logic should be pushed up the stack.
8529         filters = {'deleted': False,
8530                    'soft_deleted': True,
8531                    'host': nodes}
8532         filtered_instances = objects.InstanceList.get_by_filters(context,
8533                                  filters, expected_attrs=[], use_slave=True)
8534 
8535         self.driver.manage_image_cache(context, filtered_instances)
8536 
8537     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8538     def _run_pending_deletes(self, context):
8539         """Retry any pending instance file deletes."""
8540         LOG.debug('Cleaning up deleted instances')
8541         filters = {'deleted': True,
8542                    'soft_deleted': False,
8543                    'host': CONF.host,
8544                    'cleaned': False}
8545         attrs = ['system_metadata']
8546         with utils.temporary_mutation(context, read_deleted='yes'):
8547             instances = objects.InstanceList.get_by_filters(
8548                 context, filters, expected_attrs=attrs, use_slave=True)
8549         LOG.debug('There are %d instances to clean', len(instances))
8550 
8551         for instance in instances:
8552             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
8553             LOG.debug('Instance has had %(attempts)s of %(max)s '
8554                       'cleanup attempts',
8555                       {'attempts': attempts,
8556                        'max': CONF.maximum_instance_delete_attempts},
8557                       instance=instance)
8558             if attempts < CONF.maximum_instance_delete_attempts:
8559                 success = self.driver.delete_instance_files(instance)
8560 
8561                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
8562                 if success:
8563                     instance.cleaned = True
8564                 with utils.temporary_mutation(context, read_deleted='yes'):
8565                     instance.save()
8566 
8567     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8568     def _cleanup_incomplete_migrations(self, context):
8569         """Delete instance files on failed resize/revert-resize operation
8570 
8571         During resize/revert-resize operation, if that instance gets deleted
8572         in-between then instance files might remain either on source or
8573         destination compute node because of race condition.
8574         """
8575         LOG.debug('Cleaning up deleted instances with incomplete migration ')
8576         migration_filters = {'host': CONF.host,
8577                              'status': 'error'}
8578         migrations = objects.MigrationList.get_by_filters(context,
8579                                                           migration_filters)
8580 
8581         if not migrations:
8582             return
8583 
8584         inst_uuid_from_migrations = set([migration.instance_uuid for migration
8585                                          in migrations])
8586 
8587         inst_filters = {'deleted': True, 'soft_deleted': False,
8588                         'uuid': inst_uuid_from_migrations}
8589         attrs = ['info_cache', 'security_groups', 'system_metadata']
8590         with utils.temporary_mutation(context, read_deleted='yes'):
8591             instances = objects.InstanceList.get_by_filters(
8592                 context, inst_filters, expected_attrs=attrs, use_slave=True)
8593 
8594         for instance in instances:
8595             if instance.host != CONF.host:
8596                 for migration in migrations:
8597                     if instance.uuid == migration.instance_uuid:
8598                         # Delete instance files if not cleanup properly either
8599                         # from the source or destination compute nodes when
8600                         # the instance is deleted during resizing.
8601                         self.driver.delete_instance_files(instance)
8602                         try:
8603                             migration.status = 'failed'
8604                             migration.save()
8605                         except exception.MigrationNotFound:
8606                             LOG.warning("Migration %s is not found.",
8607                                         migration.id,
8608                                         instance=instance)
8609                         break
8610 
8611     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8612                                    exception.QemuGuestAgentNotEnabled,
8613                                    exception.NovaException,
8614                                    NotImplementedError)
8615     @wrap_exception()
8616     def quiesce_instance(self, context, instance):
8617         """Quiesce an instance on this host."""
8618         context = context.elevated()
8619         image_meta = objects.ImageMeta.from_instance(instance)
8620         self.driver.quiesce(context, instance, image_meta)
8621 
8622     def _wait_for_snapshots_completion(self, context, mapping):
8623         for mapping_dict in mapping:
8624             if mapping_dict.get('source_type') == 'snapshot':
8625 
8626                 def _wait_snapshot():
8627                     snapshot = self.volume_api.get_snapshot(
8628                         context, mapping_dict['snapshot_id'])
8629                     if snapshot.get('status') != 'creating':
8630                         raise loopingcall.LoopingCallDone()
8631 
8632                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
8633                 timer.start(interval=0.5).wait()
8634 
8635     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8636                                    exception.QemuGuestAgentNotEnabled,
8637                                    exception.NovaException,
8638                                    NotImplementedError)
8639     @wrap_exception()
8640     def unquiesce_instance(self, context, instance, mapping=None):
8641         """Unquiesce an instance on this host.
8642 
8643         If snapshots' image mapping is provided, it waits until snapshots are
8644         completed before unqueiscing.
8645         """
8646         context = context.elevated()
8647         if mapping:
8648             try:
8649                 self._wait_for_snapshots_completion(context, mapping)
8650             except Exception as error:
8651                 LOG.exception("Exception while waiting completion of "
8652                               "volume snapshots: %s",
8653                               error, instance=instance)
8654         image_meta = objects.ImageMeta.from_instance(instance)
8655         self.driver.unquiesce(context, instance, image_meta)
8656 
8657     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8658     def _cleanup_expired_console_auth_tokens(self, context):
8659         """Remove expired console auth tokens for this host.
8660 
8661         Console authorization tokens and their connection data are stored
8662         in the database when a user asks for a console connection to an
8663         instance. After a time they expire. We periodically remove any expired
8664         tokens from the database.
8665         """
8666         objects.ConsoleAuthToken.clean_expired_console_auths_for_host(
8667             context, self.host)
8668 
8669     def _claim_pci_for_instance_vifs(self, ctxt, instance):
8670         """Claim PCI devices for the instance's VIFs on the compute node
8671 
8672         :param ctxt: Context
8673         :param instance: Instance object
8674         :return: <port ID: PciDevice> mapping for the VIFs that yielded a
8675                 PCI claim on the compute node
8676         """
8677         pci_req_id_to_port_id = {}
8678         pci_reqs = []
8679         port_id_to_pci_dev = {}
8680 
8681         for vif in instance.get_network_info():
8682             pci_req = pci_req_module.get_instance_pci_request_from_vif(
8683                 ctxt,
8684                 instance,
8685                 vif)
8686             if pci_req:
8687                 pci_req_id_to_port_id[pci_req.request_id] = vif['id']
8688                 pci_reqs.append(pci_req)
8689 
8690         if pci_reqs:
8691             # Create PCI requests and claim against PCI resource tracker
8692             # NOTE(adrianc): We claim against the same requests as on the
8693             # source node.
8694             vif_pci_requests = objects.InstancePCIRequests(
8695                 requests=pci_reqs,
8696                 instance_uuid=instance.uuid)
8697 
8698             claimed_pci_devices_objs = self.rt.claim_pci_devices(
8699                 ctxt,
8700                 vif_pci_requests)
8701 
8702             # Update VIFMigrateData profile with the newly claimed PCI
8703             # device
8704             for pci_dev in claimed_pci_devices_objs:
8705                 LOG.debug("PCI device: %s Claimed on destination node",
8706                           pci_dev.address)
8707                 port_id = pci_req_id_to_port_id[pci_dev.request_id]
8708                 port_id_to_pci_dev[port_id] = pci_dev
8709 
8710         return port_id_to_pci_dev
8711 
8712     def _update_migrate_vifs_profile_with_pci(self,
8713                                               migrate_vifs,
8714                                               port_id_to_pci_dev):
8715         """Update migrate vifs profile with the claimed PCI devices
8716 
8717         :param migrate_vifs: list of VIFMigrateData objects
8718         :param port_id_to_pci_dev: a <port_id: PciDevice> mapping
8719         :return: None.
8720         """
8721         for mig_vif in migrate_vifs:
8722             port_id = mig_vif.port_id
8723             if port_id not in port_id_to_pci_dev:
8724                 continue
8725 
8726             pci_dev = port_id_to_pci_dev[port_id]
8727             profile = copy.deepcopy(mig_vif.source_vif['profile'])
8728             profile['pci_slot'] = pci_dev.address
8729             profile['pci_vendor_info'] = ':'.join([pci_dev.vendor_id,
8730                                                    pci_dev.product_id])
8731             mig_vif.profile = profile
8732             LOG.debug("Updating migrate VIF profile for port %(port_id)s:"
8733                       "%(profile)s", {'port_id': port_id,
8734                                       'profile': profile})
