Please review the code below for security defects using the CWE (Common Weakness Enumeration) as a reference standard. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are detected, state: 'No security defects are detected in the code'.

1 #
2 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
3 #    not use this file except in compliance with the License. You may obtain
4 #    a copy of the License at
5 #
6 #         http://www.apache.org/licenses/LICENSE-2.0
7 #
8 #    Unless required by applicable law or agreed to in writing, software
9 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
10 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
11 #    License for the specific language governing permissions and limitations
12 #    under the License.
13 
14 import fixtures
15 import re
16 
17 import mock
18 import os_resource_classes as orc
19 from oslo_config import cfg
20 from oslo_log import log as logging
21 from oslo_utils import uuidutils
22 
23 import nova.conf
24 from nova import context
25 from nova import objects
26 from nova.tests.functional.libvirt import base
27 from nova.tests.unit.virt.libvirt import fakelibvirt
28 from nova.virt.libvirt import driver as libvirt_driver
29 from nova.virt.libvirt import utils as libvirt_utils
30 
31 CONF = cfg.CONF
32 LOG = logging.getLogger(__name__)
33 
34 
35 class VGPUTestBase(base.ServersTestBase):
36 
37     FAKE_LIBVIRT_VERSION = 5000000
38     FAKE_QEMU_VERSION = 3001000
39 
40     current_host = 'host1'
41 
42     def setUp(self):
43         super(VGPUTestBase, self).setUp()
44         self.useFixture(fixtures.MockPatch(
45             'nova.virt.libvirt.LibvirtDriver._get_local_gb_info',
46             return_value={'total': 128,
47                           'used': 44,
48                           'free': 84}))
49         self.useFixture(fixtures.MockPatch(
50             'nova.privsep.libvirt.create_mdev',
51             side_effect=self._create_mdev))
52 
53         # NOTE(sbauza): Since the fake create_mdev doesn't know which compute
54         # was called, we need to look at a value that can be provided just
55         # before the driver calls create_mdev. That's why we fake the below
56         # method for having the LibvirtDriver instance so we could modify
57         # the self.current_host value.
58         orig_get_vgpu_type_per_pgpu = (
59             libvirt_driver.LibvirtDriver._get_vgpu_type_per_pgpu)
60 
61         def fake_get_vgpu_type_per_pgpu(_self, *args):
62             # See, here we look at the hostname from the virt driver...
63             self.current_host = _self._host.get_hostname()
64             # ... and then we call the original method
65             return orig_get_vgpu_type_per_pgpu(_self, *args)
66 
67         self.useFixture(fixtures.MockPatch(
68             'nova.virt.libvirt.LibvirtDriver._get_vgpu_type_per_pgpu',
69              new=fake_get_vgpu_type_per_pgpu))
70 
71         # for the sake of resizing, we need to patch the two methods below
72         self.useFixture(fixtures.MockPatch(
73             'nova.virt.libvirt.LibvirtDriver._get_instance_disk_info',
74              return_value=[]))
75         self.useFixture(fixtures.MockPatch('os.rename'))
76 
77         self.context = context.get_admin_context()
78 
79     def pci2libvirt_address(self, address):
80         return "pci_{}_{}_{}_{}".format(*re.split("[.:]", address))
81 
82     def libvirt2pci_address(self, dev_name):
83         return "{}:{}:{}.{}".format(*dev_name[4:].split('_'))
84 
85     def _create_mdev(self, physical_device, mdev_type, uuid=None):
86         # We need to fake the newly created sysfs object by adding a new
87         # FakeMdevDevice in the existing persisted Connection object so
88         # when asking to get the existing mdevs, we would see it.
89         if not uuid:
90             uuid = uuidutils.generate_uuid()
91         mdev_name = libvirt_utils.mdev_uuid2name(uuid)
92         libvirt_parent = self.pci2libvirt_address(physical_device)
93         # Here, we get the right compute thanks by the self.current_host that
94         # was modified just before
95         connection = self.computes[
96             self.current_host].driver._host.get_connection()
97         connection.mdev_info.devices.update(
98             {mdev_name: fakelibvirt.FakeMdevDevice(dev_name=mdev_name,
99                                                    type_id=mdev_type,
100                                                    parent=libvirt_parent)})
101         return uuid
102 
103     def _start_compute_service(self, hostname):
104         fake_connection = self._get_connection(
105             host_info=fakelibvirt.HostInfo(cpu_nodes=2, kB_mem=8192),
106             # We want to create two pGPUs but no other PCI devices
107             pci_info=fakelibvirt.HostPCIDevicesInfo(num_pci=0,
108                                                     num_pfs=0,
109                                                     num_vfs=0,
110                                                     num_mdevcap=2),
111             hostname=hostname)
112         with mock.patch('nova.virt.libvirt.host.Host.get_connection',
113                         return_value=fake_connection):
114             # this method will update a self.computes dict keyed by hostname
115             compute = self._start_compute(hostname)
116             compute.driver._host.get_connection = lambda: fake_connection
117         rp_uuid = self._get_provider_uuid_by_name(hostname)
118         rp_uuids = self._get_all_rp_uuids_in_a_tree(rp_uuid)
119         for rp in rp_uuids:
120             inventory = self._get_provider_inventory(rp)
121             if orc.VGPU in inventory:
122                 usage = self._get_provider_usages(rp)
123                 self.assertEqual(16, inventory[orc.VGPU]['total'])
124                 self.assertEqual(0, usage[orc.VGPU])
125         # Since we haven't created any mdevs yet, we shouldn't find them
126         self.assertEqual([], compute.driver._get_mediated_devices())
127         return compute
128 
129 
130 class VGPUTests(VGPUTestBase):
131 
132     # We want to target some hosts for some created instances
133     api_major_version = 'v2.1'
134     ADMIN_API = True
135     microversion = '2.74'
136 
137     def setUp(self):
138         super(VGPUTests, self).setUp()
139         extra_spec = {"resources:VGPU": "1"}
140         self.flavor = self._create_flavor(extra_spec=extra_spec)
141 
142         # Start compute1 supporting only nvidia-11
143         self.flags(
144             enabled_vgpu_types=fakelibvirt.NVIDIA_11_VGPU_TYPE,
145             group='devices')
146         self.compute1 = self._start_compute_service('host1')
147 
148     def assert_vgpu_usage_for_compute(self, compute, expected):
149         total_usage = 0
150         # We only want to get mdevs that are assigned to instances
151         mdevs = compute.driver._get_all_assigned_mediated_devices()
152         for mdev in mdevs:
153             mdev_name = libvirt_utils.mdev_uuid2name(mdev)
154             mdev_info = compute.driver._get_mediated_device_information(
155                 mdev_name)
156             parent_name = mdev_info['parent']
157             parent_rp_name = compute.host + '_' + parent_name
158             parent_rp_uuid = self._get_provider_uuid_by_name(parent_rp_name)
159             parent_usage = self._get_provider_usages(parent_rp_uuid)
160             if orc.VGPU in parent_usage:
161                 total_usage += parent_usage[orc.VGPU]
162         self.assertEqual(expected, len(mdevs))
163         self.assertEqual(expected, total_usage)
164 
165     def test_create_servers_with_vgpu(self):
166         self._create_server(
167             image_uuid='155d900f-4e14-4e4c-a73d-069cbf4541e6',
168             flavor_id=self.flavor, host=self.compute1.host,
169             networks='auto', expected_state='ACTIVE')
170         self.assert_vgpu_usage_for_compute(self.compute1, expected=1)
171 
172     def _resize_server(self, server, flavor):
173         resize_req = {
174             'resize': {
175                 'flavorRef': flavor
176             }
177         }
178         self.api.api_post('/servers/%s/action' % server['id'],
179                           resize_req)
180         self._wait_for_state_change(server, 'VERIFY_RESIZE')
181 
182     def _confirm_resize(self, server, host='host1'):
183         confirm_resize_req = {'confirmResize': None}
184         # NOTE(sbauza): Unfortunately, _cleanup_resize() in libvirt checks the
185         # host option to know the source hostname but given we have a global
186         # CONF, the value will be the hostname of the last compute service that
187         # was created, so we need to change it here.
188         # TODO(sbauza): Remove the below once we stop using CONF.host in
189         # libvirt and rather looking at the compute host value.
190         orig_host = CONF.host
191         self.flags(host=host)
192         self.api.api_post('/servers/%s/action' % server['id'],
193                           confirm_resize_req)
194         self.flags(host=orig_host)
195         self._wait_for_state_change(server, 'ACTIVE')
196 
197     def _revert_resize(self, server):
198         revert_resize_req = {'revertResize': None}
199         self.api.api_post('/servers/%s/action' % server['id'],
200                           revert_resize_req)
201         self._wait_for_state_change(server, 'ACTIVE')
202 
203     def test_resize_servers_with_vgpu(self):
204         # Add another compute for the sake of resizing
205         self.compute2 = self._start_compute_service('host2')
206         server = self._create_server(
207             image_uuid='155d900f-4e14-4e4c-a73d-069cbf4541e6',
208             flavor_id=self.flavor, host=self.compute1.host,
209             networks='auto', expected_state='ACTIVE')
210         # Make sure we only have 1 vGPU for compute1
211         self.assert_vgpu_usage_for_compute(self.compute1, expected=1)
212         self.assert_vgpu_usage_for_compute(self.compute2, expected=0)
213 
214         extra_spec = {"resources:VGPU": "1"}
215         new_flavor = self._create_flavor(memory_mb=4096,
216                                             extra_spec=extra_spec)
217         # First, resize and then revert.
218         self._resize_server(server, new_flavor)
219         # After resizing, we then have two vGPUs, both for each compute
220         self.assert_vgpu_usage_for_compute(self.compute1, expected=1)
221         self.assert_vgpu_usage_for_compute(self.compute2, expected=1)
222 
223         self._revert_resize(server)
224         # We're back to the original resources usage
225         self.assert_vgpu_usage_for_compute(self.compute1, expected=1)
226         self.assert_vgpu_usage_for_compute(self.compute2, expected=0)
227 
228         # Now resize and then confirm it.
229         self._resize_server(server, new_flavor)
230         self.assert_vgpu_usage_for_compute(self.compute1, expected=1)
231         self.assert_vgpu_usage_for_compute(self.compute2, expected=1)
232 
233         self._confirm_resize(server)
234         # In the last case, the source guest disappeared so we only have 1 vGPU
235         self.assert_vgpu_usage_for_compute(self.compute1, expected=0)
236         self.assert_vgpu_usage_for_compute(self.compute2, expected=1)
237 
238 
239 class VGPUMultipleTypesTests(VGPUTestBase):
240 
241     def setUp(self):
242         super(VGPUMultipleTypesTests, self).setUp()
243         extra_spec = {"resources:VGPU": "1"}
244         self.flavor = self._create_flavor(extra_spec=extra_spec)
245 
246         self.flags(
247             enabled_vgpu_types=[fakelibvirt.NVIDIA_11_VGPU_TYPE,
248                                 fakelibvirt.NVIDIA_12_VGPU_TYPE],
249             group='devices')
250         # we need to call the below again to ensure the updated
251         # 'device_addresses' value is read and the new groups created
252         nova.conf.devices.register_dynamic_opts(CONF)
253         # host1 will have 2 physical GPUs :
254         #  - 0000:81:00.0 will only support nvidia-11
255         #  - 0000:81:01.0 will only support nvidia-12
256         pgpu1_pci_addr = self.libvirt2pci_address(fakelibvirt.PGPU1_PCI_ADDR)
257         pgpu2_pci_addr = self.libvirt2pci_address(fakelibvirt.PGPU2_PCI_ADDR)
258         self.flags(device_addresses=[pgpu1_pci_addr], group='vgpu_nvidia-11')
259         self.flags(device_addresses=[pgpu2_pci_addr], group='vgpu_nvidia-12')
260 
261         # Prepare traits for later on
262         self._create_trait('CUSTOM_NVIDIA_11')
263         self._create_trait('CUSTOM_NVIDIA_12')
264         self.compute1 = self._start_compute_service('host1')
265 
266     def test_create_servers_with_vgpu(self):
267         self._create_server(
268             image_uuid='155d900f-4e14-4e4c-a73d-069cbf4541e6',
269             flavor_id=self.flavor, host=self.compute1.host,
270             expected_state='ACTIVE')
271         mdevs = self.compute1.driver._get_mediated_devices()
272         self.assertEqual(1, len(mdevs))
273 
274         # We can be deterministic : since 0000:81:01.0 is asked to only support
275         # nvidia-12 *BUT* doesn't actually have this type as a PCI capability,
276         # we are sure that only 0000:81:00.0 is used.
277         parent_name = mdevs[0]['parent']
278         self.assertEqual(fakelibvirt.PGPU1_PCI_ADDR, parent_name)
279 
280         # We are also sure that there is no RP for 0000:81:01.0 since there
281         # is no inventory for nvidia-12
282         root_rp_uuid = self._get_provider_uuid_by_name(self.compute1.host)
283         rp_uuids = self._get_all_rp_uuids_in_a_tree(root_rp_uuid)
284         # We only have 2 RPs : the root RP and only the pGPU1 RP...
285         self.assertEqual(2, len(rp_uuids))
286         # ... but we double-check by asking the RP by its expected name
287         expected_pgpu2_rp_name = (self.compute1.host + '_' +
288                                   fakelibvirt.PGPU2_PCI_ADDR)
289         pgpu2_rp = self.placement_api.get(
290             '/resource_providers?name=' + expected_pgpu2_rp_name).body[
291             'resource_providers']
292         # See, Placement API returned no RP for this name as it doesn't exist.
293         self.assertEqual([], pgpu2_rp)
294 
295     def test_create_servers_with_specific_type(self):
296         # Regenerate the PCI addresses so both pGPUs now support nvidia-12
297         connection = self.computes[
298             self.compute1.host].driver._host.get_connection()
299         connection.pci_info = fakelibvirt.HostPCIDevicesInfo(
300             num_pci=0, num_pfs=0, num_vfs=0, num_mdevcap=2,
301             multiple_gpu_types=True)
302         # Make a restart to update the Resource Providers
303         self.compute1 = self.restart_compute_service(self.compute1)
304         pgpu1_rp_uuid = self._get_provider_uuid_by_name(
305             self.compute1.host + '_' + fakelibvirt.PGPU1_PCI_ADDR)
306         pgpu2_rp_uuid = self._get_provider_uuid_by_name(
307             self.compute1.host + '_' + fakelibvirt.PGPU2_PCI_ADDR)
308 
309         pgpu1_inventory = self._get_provider_inventory(pgpu1_rp_uuid)
310         self.assertEqual(16, pgpu1_inventory[orc.VGPU]['total'])
311         pgpu2_inventory = self._get_provider_inventory(pgpu2_rp_uuid)
312         self.assertEqual(8, pgpu2_inventory[orc.VGPU]['total'])
313 
314         # Attach traits to the pGPU RPs
315         self._set_provider_traits(pgpu1_rp_uuid, ['CUSTOM_NVIDIA_11'])
316         self._set_provider_traits(pgpu2_rp_uuid, ['CUSTOM_NVIDIA_12'])
317 
318         expected = {'CUSTOM_NVIDIA_11': fakelibvirt.PGPU1_PCI_ADDR,
319                     'CUSTOM_NVIDIA_12': fakelibvirt.PGPU2_PCI_ADDR}
320 
321         for trait in expected.keys():
322             # Add a trait to the flavor
323             extra_spec = {"resources:VGPU": "1",
324                           "trait:%s" % trait: "required"}
325             flavor = self._create_flavor(extra_spec=extra_spec)
326 
327             # Use the new flavor for booting
328             server = self._create_server(
329                 image_uuid='155d900f-4e14-4e4c-a73d-069cbf4541e6',
330                 flavor_id=flavor, host=self.compute1.host,
331                 expected_state='ACTIVE')
332 
333             # Get the instance we just created
334             inst = objects.Instance.get_by_uuid(self.context, server['id'])
335             # Get the mdevs that were allocated for this instance, we should
336             # only have one
337             mdevs = self.compute1.driver._get_all_assigned_mediated_devices(
338                 inst)
339             self.assertEqual(1, len(mdevs))
340 
341             # It's a dict of mdev_uuid/instance_uuid pairs, we only care about
342             # the keys
343             mdevs = list(mdevs.keys())
344             # Now get the detailed information about this single mdev
345             mdev_info = self.compute1.driver._get_mediated_device_information(
346                 libvirt_utils.mdev_uuid2name(mdevs[0]))
347 
348             # We can be deterministic : since we asked for a specific type,
349             # we know which pGPU we landed.
350             self.assertEqual(expected[trait], mdev_info['parent'])
