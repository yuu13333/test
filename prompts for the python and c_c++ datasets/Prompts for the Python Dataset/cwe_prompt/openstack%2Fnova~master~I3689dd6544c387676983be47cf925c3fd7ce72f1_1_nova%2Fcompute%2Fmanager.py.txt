Please review the code below for security defects using the CWE (Common Weakness Enumeration) as a reference standard. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are detected, state: 'No security defects are detected in the code'.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 # If py2, concurrent.futures comes from the futures library otherwise it
31 # comes from the py3 standard library.
32 from concurrent import futures
33 import contextlib
34 import functools
35 import inspect
36 import sys
37 import time
38 import traceback
39 
40 from cinderclient import exceptions as cinder_exception
41 from cursive import exception as cursive_exception
42 import eventlet.event
43 from eventlet import greenthread
44 import eventlet.semaphore
45 import eventlet.timeout
46 from keystoneauth1 import exceptions as keystone_exception
47 from oslo_log import log as logging
48 import oslo_messaging as messaging
49 from oslo_serialization import jsonutils
50 from oslo_service import loopingcall
51 from oslo_service import periodic_task
52 from oslo_utils import excutils
53 from oslo_utils import strutils
54 from oslo_utils import timeutils
55 import six
56 from six.moves import range
57 
58 from nova import block_device
59 from nova.cells import rpcapi as cells_rpcapi
60 from nova import compute
61 from nova.compute import build_results
62 from nova.compute import claims
63 from nova.compute import power_state
64 from nova.compute import resource_tracker
65 from nova.compute import rpcapi as compute_rpcapi
66 from nova.compute import task_states
67 from nova.compute import utils as compute_utils
68 from nova.compute.utils import wrap_instance_event
69 from nova.compute import vm_states
70 from nova import conductor
71 import nova.conf
72 from nova.console import rpcapi as console_rpcapi
73 import nova.context
74 from nova import exception
75 from nova import exception_wrapper
76 from nova import hooks
77 from nova.i18n import _
78 from nova import image
79 from nova import manager
80 from nova import network
81 from nova.network import base_api as base_net_api
82 from nova.network import model as network_model
83 from nova.network.security_group import openstack_driver
84 from nova import objects
85 from nova.objects import base as obj_base
86 from nova.objects import fields
87 from nova.objects import instance as obj_instance
88 from nova.objects import migrate_data as migrate_data_obj
89 from nova.pci import whitelist
90 from nova import rpc
91 from nova import safe_utils
92 from nova.scheduler import client as scheduler_client
93 from nova.scheduler import utils as scheduler_utils
94 from nova import utils
95 from nova.virt import block_device as driver_block_device
96 from nova.virt import configdrive
97 from nova.virt import driver
98 from nova.virt import event as virtevent
99 from nova.virt import storage_users
100 from nova.virt import virtapi
101 from nova.volume import cinder
102 
103 CONF = nova.conf.CONF
104 
105 LOG = logging.getLogger(__name__)
106 
107 get_notifier = functools.partial(rpc.get_notifier, service='compute')
108 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
109                                    get_notifier=get_notifier,
110                                    binary='nova-compute')
111 
112 
113 @contextlib.contextmanager
114 def errors_out_migration_ctxt(migration):
115     """Context manager to error out migration on failure."""
116 
117     try:
118         yield
119     except Exception:
120         with excutils.save_and_reraise_exception():
121             if migration:
122                 # We may have been passed None for our migration if we're
123                 # receiving from an older client. The migration will be
124                 # errored via the legacy path.
125                 migration.status = 'error'
126                 try:
127                     with migration.obj_as_admin():
128                         migration.save()
129                 except Exception:
130                     LOG.debug(
131                         'Error setting migration status for instance %s.',
132                         migration.instance_uuid, exc_info=True)
133 
134 
135 @utils.expects_func_args('migration')
136 def errors_out_migration(function):
137     """Decorator to error out migration on failure."""
138 
139     @functools.wraps(function)
140     def decorated_function(self, context, *args, **kwargs):
141         wrapped_func = safe_utils.get_wrapped_function(function)
142         keyed_args = inspect.getcallargs(wrapped_func, self, context,
143                                          *args, **kwargs)
144         migration = keyed_args['migration']
145         with errors_out_migration_ctxt(migration):
146             return function(self, context, *args, **kwargs)
147 
148     return decorated_function
149 
150 
151 @utils.expects_func_args('instance')
152 def reverts_task_state(function):
153     """Decorator to revert task_state on failure."""
154 
155     @functools.wraps(function)
156     def decorated_function(self, context, *args, **kwargs):
157         try:
158             return function(self, context, *args, **kwargs)
159         except exception.UnexpectedTaskStateError as e:
160             # Note(maoy): unexpected task state means the current
161             # task is preempted. Do not clear task state in this
162             # case.
163             with excutils.save_and_reraise_exception():
164                 LOG.info("Task possibly preempted: %s",
165                          e.format_message())
166         except Exception:
167             with excutils.save_and_reraise_exception():
168                 wrapped_func = safe_utils.get_wrapped_function(function)
169                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
170                                                  *args, **kwargs)
171                 # NOTE(mriedem): 'instance' must be in keyed_args because we
172                 # have utils.expects_func_args('instance') decorating this
173                 # method.
174                 instance = keyed_args['instance']
175                 original_task_state = instance.task_state
176                 try:
177                     self._instance_update(context, instance, task_state=None)
178                     LOG.info("Successfully reverted task state from %s on "
179                              "failure for instance.",
180                              original_task_state, instance=instance)
181                 except exception.InstanceNotFound:
182                     # We might delete an instance that failed to build shortly
183                     # after it errored out this is an expected case and we
184                     # should not trace on it.
185                     pass
186                 except Exception as e:
187                     LOG.warning("Failed to revert task state for instance. "
188                                 "Error: %s", e, instance=instance)
189 
190     return decorated_function
191 
192 
193 @utils.expects_func_args('instance')
194 def wrap_instance_fault(function):
195     """Wraps a method to catch exceptions related to instances.
196 
197     This decorator wraps a method to catch any exceptions having to do with
198     an instance that may get thrown. It then logs an instance fault in the db.
199     """
200 
201     @functools.wraps(function)
202     def decorated_function(self, context, *args, **kwargs):
203         try:
204             return function(self, context, *args, **kwargs)
205         except exception.InstanceNotFound:
206             raise
207         except Exception as e:
208             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
209             # we will get a KeyError exception which will cover up the real
210             # exception. So, we update kwargs with the values from args first.
211             # then, we can get 'instance' from kwargs easily.
212             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
213 
214             with excutils.save_and_reraise_exception():
215                 compute_utils.add_instance_fault_from_exc(context,
216                         kwargs['instance'], e, sys.exc_info())
217 
218     return decorated_function
219 
220 
221 @utils.expects_func_args('image_id', 'instance')
222 def delete_image_on_error(function):
223     """Used for snapshot related method to ensure the image created in
224     compute.api is deleted when an error occurs.
225     """
226 
227     @functools.wraps(function)
228     def decorated_function(self, context, image_id, instance,
229                            *args, **kwargs):
230         try:
231             return function(self, context, image_id, instance,
232                             *args, **kwargs)
233         except Exception:
234             with excutils.save_and_reraise_exception():
235                 LOG.debug("Cleaning up image %s", image_id,
236                           exc_info=True, instance=instance)
237                 try:
238                     self.image_api.delete(context, image_id)
239                 except exception.ImageNotFound:
240                     # Since we're trying to cleanup an image, we don't care if
241                     # if it's already gone.
242                     pass
243                 except Exception:
244                     LOG.exception("Error while trying to clean up image %s",
245                                   image_id, instance=instance)
246 
247     return decorated_function
248 
249 
250 # TODO(danms): Remove me after Icehouse
251 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
252 # NOTE(mikal): if the method being decorated has more than one decorator, then
253 # put this one first. Otherwise the various exception handling decorators do
254 # not function correctly.
255 def object_compat(function):
256     """Wraps a method that expects a new-world instance
257 
258     This provides compatibility for callers passing old-style dict
259     instances.
260     """
261 
262     @functools.wraps(function)
263     def decorated_function(self, context, *args, **kwargs):
264         def _load_instance(instance_or_dict):
265             if isinstance(instance_or_dict, dict):
266                 # try to get metadata and system_metadata for most cases but
267                 # only attempt to load those if the db instance already has
268                 # those fields joined
269                 metas = [meta for meta in ('metadata', 'system_metadata')
270                          if meta in instance_or_dict]
271                 instance = objects.Instance._from_db_object(
272                     context, objects.Instance(), instance_or_dict,
273                     expected_attrs=metas)
274                 instance._context = context
275                 return instance
276             return instance_or_dict
277 
278         try:
279             kwargs['instance'] = _load_instance(kwargs['instance'])
280         except KeyError:
281             args = (_load_instance(args[0]),) + args[1:]
282 
283         migration = kwargs.get('migration')
284         if isinstance(migration, dict):
285             migration = objects.Migration._from_db_object(
286                     context.elevated(), objects.Migration(),
287                     migration)
288             kwargs['migration'] = migration
289 
290         return function(self, context, *args, **kwargs)
291 
292     return decorated_function
293 
294 
295 class InstanceEvents(object):
296     def __init__(self):
297         self._events = {}
298 
299     @staticmethod
300     def _lock_name(instance):
301         return '%s-%s' % (instance.uuid, 'events')
302 
303     def prepare_for_instance_event(self, instance, name, tag):
304         """Prepare to receive an event for an instance.
305 
306         This will register an event for the given instance that we will
307         wait on later. This should be called before initiating whatever
308         action will trigger the event. The resulting eventlet.event.Event
309         object should be wait()'d on to ensure completion.
310 
311         :param instance: the instance for which the event will be generated
312         :param name: the name of the event we're expecting
313         :param tag: the tag associated with the event we're expecting
314         :returns: an event object that should be wait()'d on
315         """
316         if self._events is None:
317             # NOTE(danms): We really should have a more specific error
318             # here, but this is what we use for our default error case
319             raise exception.NovaException('In shutdown, no new events '
320                                           'can be scheduled')
321 
322         @utils.synchronized(self._lock_name(instance))
323         def _create_or_get_event():
324             instance_events = self._events.setdefault(instance.uuid, {})
325             return instance_events.setdefault((name, tag),
326                                               eventlet.event.Event())
327         LOG.debug('Preparing to wait for external event %(name)s-%(tag)s',
328                   {'name': name, 'tag': tag}, instance=instance)
329         return _create_or_get_event()
330 
331     def pop_instance_event(self, instance, event):
332         """Remove a pending event from the wait list.
333 
334         This will remove a pending event from the wait list so that it
335         can be used to signal the waiters to wake up.
336 
337         :param instance: the instance for which the event was generated
338         :param event: the nova.objects.external_event.InstanceExternalEvent
339                       that describes the event
340         :returns: the eventlet.event.Event object on which the waiters
341                   are blocked
342         """
343         no_events_sentinel = object()
344         no_matching_event_sentinel = object()
345 
346         @utils.synchronized(self._lock_name(instance))
347         def _pop_event():
348             if self._events is None:
349                 LOG.debug('Unexpected attempt to pop events during shutdown',
350                           instance=instance)
351                 return no_events_sentinel
352             events = self._events.get(instance.uuid)
353             if not events:
354                 return no_events_sentinel
355             _event = events.pop((event.name, event.tag), None)
356             if not events:
357                 del self._events[instance.uuid]
358             if _event is None:
359                 return no_matching_event_sentinel
360             return _event
361 
362         result = _pop_event()
363         if result is no_events_sentinel:
364             LOG.debug('No waiting events found dispatching %(event)s',
365                       {'event': event.key},
366                       instance=instance)
367             return None
368         elif result is no_matching_event_sentinel:
369             LOG.debug('No event matching %(event)s in %(events)s',
370                       {'event': event.key,
371                        'events': self._events.get(instance.uuid, {}).keys()},
372                       instance=instance)
373             return None
374         else:
375             return result
376 
377     def clear_events_for_instance(self, instance):
378         """Remove all pending events for an instance.
379 
380         This will remove all events currently pending for an instance
381         and return them (indexed by event name).
382 
383         :param instance: the instance for which events should be purged
384         :returns: a dictionary of {event_name: eventlet.event.Event}
385         """
386         @utils.synchronized(self._lock_name(instance))
387         def _clear_events():
388             if self._events is None:
389                 LOG.debug('Unexpected attempt to clear events during shutdown',
390                           instance=instance)
391                 return dict()
392             # NOTE(danms): We have historically returned the raw internal
393             # format here, which is {event.key: [events, ...])} so just
394             # trivially convert it here.
395             return {'%s-%s' % k: e
396                     for k, e in self._events.pop(instance.uuid, {}).items()}
397         return _clear_events()
398 
399     def cancel_all_events(self):
400         if self._events is None:
401             LOG.debug('Unexpected attempt to cancel events during shutdown.')
402             return
403         our_events = self._events
404         # NOTE(danms): Block new events
405         self._events = None
406 
407         for instance_uuid, events in our_events.items():
408             for (name, tag), eventlet_event in events.items():
409                 LOG.debug('Canceling in-flight event %(name)s-%(tag)s for '
410                           'instance %(instance_uuid)s',
411                           {'name': name,
412                            'tag': tag,
413                            'instance_uuid': instance_uuid})
414                 event = objects.InstanceExternalEvent(
415                     instance_uuid=instance_uuid,
416                     name=name, status='failed',
417                     tag=tag, data={})
418                 eventlet_event.send(event)
419 
420 
421 class ComputeVirtAPI(virtapi.VirtAPI):
422     def __init__(self, compute):
423         super(ComputeVirtAPI, self).__init__()
424         self._compute = compute
425 
426     def _default_error_callback(self, event_name, instance):
427         raise exception.NovaException(_('Instance event failed'))
428 
429     @contextlib.contextmanager
430     def wait_for_instance_event(self, instance, event_names, deadline=300,
431                                 error_callback=None):
432         """Plan to wait for some events, run some code, then wait.
433 
434         This context manager will first create plans to wait for the
435         provided event_names, yield, and then wait for all the scheduled
436         events to complete.
437 
438         Note that this uses an eventlet.timeout.Timeout to bound the
439         operation, so callers should be prepared to catch that
440         failure and handle that situation appropriately.
441 
442         If the event is not received by the specified timeout deadline,
443         eventlet.timeout.Timeout is raised.
444 
445         If the event is received but did not have a 'completed'
446         status, a NovaException is raised.  If an error_callback is
447         provided, instead of raising an exception as detailed above
448         for the failure case, the callback will be called with the
449         event_name and instance, and can return True to continue
450         waiting for the rest of the events, False to stop processing,
451         or raise an exception which will bubble up to the waiter.
452 
453         :param instance: The instance for which an event is expected
454         :param event_names: A list of event names. Each element is a
455                             tuple of strings to indicate (name, tag),
456                             where name is required, but tag may be None.
457         :param deadline: Maximum number of seconds we should wait for all
458                          of the specified events to arrive.
459         :param error_callback: A function to be called if an event arrives
460 
461         """
462 
463         if error_callback is None:
464             error_callback = self._default_error_callback
465         events = {}
466         for event_name in event_names:
467             name, tag = event_name
468             event_name = objects.InstanceExternalEvent.make_key(name, tag)
469             try:
470                 events[event_name] = (
471                     self._compute.instance_events.prepare_for_instance_event(
472                         instance, name, tag))
473             except exception.NovaException:
474                 error_callback(event_name, instance)
475                 # NOTE(danms): Don't wait for any of the events. They
476                 # should all be canceled and fired immediately below,
477                 # but don't stick around if not.
478                 deadline = 0
479         yield
480         with eventlet.timeout.Timeout(deadline):
481             for event_name, event in events.items():
482                 actual_event = event.wait()
483                 if actual_event.status == 'completed':
484                     continue
485                 decision = error_callback(event_name, instance)
486                 if decision is False:
487                     break
488 
489 
490 class ComputeManager(manager.Manager):
491     """Manages the running instances from creation to destruction."""
492 
493     target = messaging.Target(version='5.0')
494 
495     def __init__(self, compute_driver=None, *args, **kwargs):
496         """Load configuration options and connect to the hypervisor."""
497         self.virtapi = ComputeVirtAPI(self)
498         self.network_api = network.API()
499         self.volume_api = cinder.API()
500         self.image_api = image.API()
501         self._last_host_check = 0
502         self._last_bw_usage_poll = 0
503         self._bw_usage_supported = True
504         self._last_bw_usage_cell_update = 0
505         self.compute_api = compute.API()
506         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
507         self.conductor_api = conductor.API()
508         self.compute_task_api = conductor.ComputeTaskAPI()
509         self.is_neutron_security_groups = (
510             openstack_driver.is_neutron_security_groups())
511         self.cells_rpcapi = cells_rpcapi.CellsAPI()
512         self.scheduler_client = scheduler_client.SchedulerClient()
513         self.reportclient = self.scheduler_client.reportclient
514         self._resource_tracker = None
515         self.instance_events = InstanceEvents()
516         self._sync_power_pool = eventlet.GreenPool(
517             size=CONF.sync_power_state_pool_size)
518         self._syncs_in_progress = {}
519         self.send_instance_updates = (
520             CONF.filter_scheduler.track_instance_changes)
521         if CONF.max_concurrent_builds != 0:
522             self._build_semaphore = eventlet.semaphore.Semaphore(
523                 CONF.max_concurrent_builds)
524         else:
525             self._build_semaphore = compute_utils.UnlimitedSemaphore()
526         if max(CONF.max_concurrent_live_migrations, 0) != 0:
527             self._live_migration_executor = futures.ThreadPoolExecutor(
528                 max_workers=CONF.max_concurrent_live_migrations)
529         else:
530             # Starting in python 3.5, this is technically bounded, but it's
531             # ncpu * 5 which is probably much higher than anyone would sanely
532             # use for concurrently running live migrations.
533             self._live_migration_executor = futures.ThreadPoolExecutor()
534         # This is a dict, keyed by migration uuid, to a two-item tuple of
535         # migration object and Future for the queued live migration.
536         self._waiting_live_migrations = {}
537         self._failed_builds = 0
538 
539         super(ComputeManager, self).__init__(service_name="compute",
540                                              *args, **kwargs)
541 
542         # NOTE(russellb) Load the driver last.  It may call back into the
543         # compute manager via the virtapi, so we want it to be fully
544         # initialized before that happens.
545         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
546         self.use_legacy_block_device_info = \
547                             self.driver.need_legacy_block_device_info
548 
549     def reset(self):
550         LOG.info('Reloading compute RPC API')
551         compute_rpcapi.LAST_VERSION = None
552         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
553 
554     def _get_resource_tracker(self):
555         if not self._resource_tracker:
556             rt = resource_tracker.ResourceTracker(self.host, self.driver)
557             self._resource_tracker = rt
558         return self._resource_tracker
559 
560     def _update_resource_tracker(self, context, instance):
561         """Let the resource tracker know that an instance has changed state."""
562 
563         if instance.host == self.host:
564             rt = self._get_resource_tracker()
565             rt.update_usage(context, instance, instance.node)
566 
567     def _instance_update(self, context, instance, **kwargs):
568         """Update an instance in the database using kwargs as value."""
569 
570         for k, v in kwargs.items():
571             setattr(instance, k, v)
572         instance.save()
573         self._update_resource_tracker(context, instance)
574 
575     def _nil_out_instance_obj_host_and_node(self, instance):
576         # NOTE(jwcroppe): We don't do instance.save() here for performance
577         # reasons; a call to this is expected to be immediately followed by
578         # another call that does instance.save(), thus avoiding two writes
579         # to the database layer.
580         instance.host = None
581         instance.node = None
582 
583     def _set_instance_obj_error_state(self, context, instance,
584                                       clean_task_state=False):
585         try:
586             instance.vm_state = vm_states.ERROR
587             if clean_task_state:
588                 instance.task_state = None
589             instance.save()
590         except exception.InstanceNotFound:
591             LOG.debug('Instance has been destroyed from under us while '
592                       'trying to set it to ERROR', instance=instance)
593 
594     def _get_instances_on_driver(self, context, filters=None):
595         """Return a list of instance records for the instances found
596         on the hypervisor which satisfy the specified filters. If filters=None
597         return a list of instance records for all the instances found on the
598         hypervisor.
599         """
600         if not filters:
601             filters = {}
602         try:
603             driver_uuids = self.driver.list_instance_uuids()
604             if len(driver_uuids) == 0:
605                 # Short circuit, don't waste a DB call
606                 return objects.InstanceList()
607             filters['uuid'] = driver_uuids
608             local_instances = objects.InstanceList.get_by_filters(
609                 context, filters, use_slave=True)
610             return local_instances
611         except NotImplementedError:
612             pass
613 
614         # The driver doesn't support uuids listing, so we'll have
615         # to brute force.
616         driver_instances = self.driver.list_instances()
617         # NOTE(mjozefcz): In this case we need to apply host filter.
618         # Without this all instance data would be fetched from db.
619         filters['host'] = self.host
620         instances = objects.InstanceList.get_by_filters(context, filters,
621                                                         use_slave=True)
622         name_map = {instance.name: instance for instance in instances}
623         local_instances = []
624         for driver_instance in driver_instances:
625             instance = name_map.get(driver_instance)
626             if not instance:
627                 continue
628             local_instances.append(instance)
629         return local_instances
630 
631     def _destroy_evacuated_instances(self, context):
632         """Destroys evacuated instances.
633 
634         While nova-compute was down, the instances running on it could be
635         evacuated to another host. This method looks for evacuation migration
636         records where this is the source host and which were either started
637         (accepted) or complete (done). From those migration records, local
638         instances reported by the hypervisor are compared to the instances
639         for the migration records and those local guests are destroyed, along
640         with instance allocation records in Placement for this node.
641         """
642         filters = {
643             'source_compute': self.host,
644             # NOTE(mriedem): Migration records that have been accepted are
645             # included in case the source node comes back up while instances
646             # are being evacuated to another host. We don't want the same
647             # instance being reported from multiple hosts.
648             'status': ['accepted', 'done'],
649             'migration_type': 'evacuation',
650         }
651         with utils.temporary_mutation(context, read_deleted='yes'):
652             evacuations = objects.MigrationList.get_by_filters(context,
653                                                                filters)
654         if not evacuations:
655             return
656         evacuations = {mig.instance_uuid: mig for mig in evacuations}
657 
658         local_instances = self._get_instances_on_driver(context)
659         evacuated = [inst for inst in local_instances
660                      if inst.uuid in evacuations]
661 
662         # NOTE(gibi): We are called from init_host and at this point the
663         # compute_nodes of the resource tracker has not been populated yet so
664         # we cannot rely on the resource tracker here.
665         compute_nodes = {}
666 
667         for instance in evacuated:
668             migration = evacuations[instance.uuid]
669             LOG.info('Deleting instance as it has been evacuated from '
670                      'this host', instance=instance)
671             try:
672                 network_info = self.network_api.get_instance_nw_info(
673                     context, instance)
674                 bdi = self._get_instance_block_device_info(context,
675                                                            instance)
676                 destroy_disks = not (self._is_instance_storage_shared(
677                     context, instance))
678             except exception.InstanceNotFound:
679                 network_info = network_model.NetworkInfo()
680                 bdi = {}
681                 LOG.info('Instance has been marked deleted already, '
682                          'removing it from the hypervisor.',
683                          instance=instance)
684                 # always destroy disks if the instance was deleted
685                 destroy_disks = True
686             self.driver.destroy(context, instance,
687                                 network_info,
688                                 bdi, destroy_disks)
689 
690             # delete the allocation of the evacuated instance from this host
691             if migration.source_node not in compute_nodes:
692                 try:
693                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
694                         context, self.host, migration.source_node).uuid
695                     compute_nodes[migration.source_node] = cn_uuid
696                 except exception.ComputeHostNotFound:
697                     LOG.error("Failed to clean allocation of evacuated "
698                               "instance as the source node %s is not found",
699                               migration.source_node, instance=instance)
700                     continue
701             cn_uuid = compute_nodes[migration.source_node]
702 
703             if not scheduler_utils.remove_allocation_from_compute(
704                     context, instance, cn_uuid, self.reportclient):
705                 LOG.error("Failed to clean allocation of evacuated instance "
706                           "on the source node %s",
707                           cn_uuid, instance=instance)
708 
709             migration.status = 'completed'
710             migration.save()
711 
712     def _is_instance_storage_shared(self, context, instance, host=None):
713         shared_storage = True
714         data = None
715         try:
716             data = self.driver.check_instance_shared_storage_local(context,
717                                                        instance)
718             if data:
719                 shared_storage = (self.compute_rpcapi.
720                                   check_instance_shared_storage(context,
721                                   instance, data, host=host))
722         except NotImplementedError:
723             LOG.debug('Hypervisor driver does not support '
724                       'instance shared storage check, '
725                       'assuming it\'s not on shared storage',
726                       instance=instance)
727             shared_storage = False
728         except Exception:
729             LOG.exception('Failed to check if instance shared',
730                           instance=instance)
731         finally:
732             if data:
733                 self.driver.check_instance_shared_storage_cleanup(context,
734                                                                   data)
735         return shared_storage
736 
737     def _complete_partial_deletion(self, context, instance):
738         """Complete deletion for instances in DELETED status but not marked as
739         deleted in the DB
740         """
741         instance.destroy()
742         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
743                 context, instance.uuid)
744         self._complete_deletion(context,
745                                 instance,
746                                 bdms)
747 
748     def _complete_deletion(self, context, instance, bdms):
749         self._update_resource_tracker(context, instance)
750 
751         rt = self._get_resource_tracker()
752         rt.reportclient.delete_allocation_for_instance(context, instance.uuid)
753 
754         self._notify_about_instance_usage(context, instance, "delete.end")
755         compute_utils.notify_about_instance_action(context, instance,
756                 self.host, action=fields.NotificationAction.DELETE,
757                 phase=fields.NotificationPhase.END, bdms=bdms)
758         self._clean_instance_console_tokens(context, instance)
759         self._delete_scheduler_instance_info(context, instance.uuid)
760 
761     def _init_instance(self, context, instance):
762         """Initialize this instance during service init."""
763 
764         # NOTE(danms): If the instance appears to not be owned by this
765         # host, it may have been evacuated away, but skipped by the
766         # evacuation cleanup code due to configuration. Thus, if that
767         # is a possibility, don't touch the instance in any way, but
768         # log the concern. This will help avoid potential issues on
769         # startup due to misconfiguration.
770         if instance.host != self.host:
771             LOG.warning('Instance %(uuid)s appears to not be owned '
772                         'by this host, but by %(host)s. Startup '
773                         'processing is being skipped.',
774                         {'uuid': instance.uuid,
775                          'host': instance.host})
776             return
777 
778         # Instances that are shut down, or in an error state can not be
779         # initialized and are not attempted to be recovered. The exception
780         # to this are instances that are in RESIZE_MIGRATING or DELETING,
781         # which are dealt with further down.
782         if (instance.vm_state == vm_states.SOFT_DELETED or
783             (instance.vm_state == vm_states.ERROR and
784             instance.task_state not in
785             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
786             LOG.debug("Instance is in %s state.",
787                       instance.vm_state, instance=instance)
788             return
789 
790         if instance.vm_state == vm_states.DELETED:
791             try:
792                 self._complete_partial_deletion(context, instance)
793             except Exception:
794                 # we don't want that an exception blocks the init_host
795                 LOG.exception('Failed to complete a deletion',
796                               instance=instance)
797             return
798 
799         if (instance.vm_state == vm_states.BUILDING or
800             instance.task_state in [task_states.SCHEDULING,
801                                     task_states.BLOCK_DEVICE_MAPPING,
802                                     task_states.NETWORKING,
803                                     task_states.SPAWNING]):
804             # NOTE(dave-mcnally) compute stopped before instance was fully
805             # spawned so set to ERROR state. This is safe to do as the state
806             # may be set by the api but the host is not so if we get here the
807             # instance has already been scheduled to this particular host.
808             LOG.debug("Instance failed to spawn correctly, "
809                       "setting to ERROR state", instance=instance)
810             instance.task_state = None
811             instance.vm_state = vm_states.ERROR
812             instance.save()
813             return
814 
815         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
816             instance.task_state in [task_states.REBUILDING,
817                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
818                                     task_states.REBUILD_SPAWNING]):
819             # NOTE(jichenjc) compute stopped before instance was fully
820             # spawned so set to ERROR state. This is consistent to BUILD
821             LOG.debug("Instance failed to rebuild correctly, "
822                       "setting to ERROR state", instance=instance)
823             instance.task_state = None
824             instance.vm_state = vm_states.ERROR
825             instance.save()
826             return
827 
828         if (instance.vm_state != vm_states.ERROR and
829             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
830                                     task_states.IMAGE_PENDING_UPLOAD,
831                                     task_states.IMAGE_UPLOADING,
832                                     task_states.IMAGE_SNAPSHOT]):
833             LOG.debug("Instance in transitional state %s at start-up "
834                       "clearing task state",
835                       instance.task_state, instance=instance)
836             try:
837                 self._post_interrupted_snapshot_cleanup(context, instance)
838             except Exception:
839                 # we don't want that an exception blocks the init_host
840                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
841             instance.task_state = None
842             instance.save()
843 
844         if (instance.vm_state != vm_states.ERROR and
845             instance.task_state in [task_states.RESIZE_PREP]):
846             LOG.debug("Instance in transitional state %s at start-up "
847                       "clearing task state",
848                       instance['task_state'], instance=instance)
849             instance.task_state = None
850             instance.save()
851 
852         if instance.task_state == task_states.DELETING:
853             try:
854                 LOG.info('Service started deleting the instance during '
855                          'the previous run, but did not finish. Restarting'
856                          ' the deletion now.', instance=instance)
857                 instance.obj_load_attr('metadata')
858                 instance.obj_load_attr('system_metadata')
859                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
860                         context, instance.uuid)
861                 self._delete_instance(context, instance, bdms)
862             except Exception:
863                 # we don't want that an exception blocks the init_host
864                 LOG.exception('Failed to complete a deletion',
865                               instance=instance)
866                 self._set_instance_obj_error_state(context, instance)
867             return
868 
869         current_power_state = self._get_power_state(context, instance)
870         try_reboot, reboot_type = self._retry_reboot(context, instance,
871                                                      current_power_state)
872 
873         if try_reboot:
874             LOG.debug("Instance in transitional state (%(task_state)s) at "
875                       "start-up and power state is (%(power_state)s), "
876                       "triggering reboot",
877                       {'task_state': instance.task_state,
878                        'power_state': current_power_state},
879                       instance=instance)
880 
881             # NOTE(mikal): if the instance was doing a soft reboot that got as
882             # far as shutting down the instance but not as far as starting it
883             # again, then we've just become a hard reboot. That means the
884             # task state for the instance needs to change so that we're in one
885             # of the expected task states for a hard reboot.
886             if (instance.task_state in task_states.soft_reboot_states and
887                 reboot_type == 'HARD'):
888                 instance.task_state = task_states.REBOOT_PENDING_HARD
889                 instance.save()
890 
891             self.reboot_instance(context, instance, block_device_info=None,
892                                  reboot_type=reboot_type)
893             return
894 
895         elif (current_power_state == power_state.RUNNING and
896               instance.task_state in [task_states.REBOOT_STARTED,
897                                       task_states.REBOOT_STARTED_HARD,
898                                       task_states.PAUSING,
899                                       task_states.UNPAUSING]):
900             LOG.warning("Instance in transitional state "
901                         "(%(task_state)s) at start-up and power state "
902                         "is (%(power_state)s), clearing task state",
903                         {'task_state': instance.task_state,
904                          'power_state': current_power_state},
905                         instance=instance)
906             instance.task_state = None
907             instance.vm_state = vm_states.ACTIVE
908             instance.save()
909         elif (current_power_state == power_state.PAUSED and
910               instance.task_state == task_states.UNPAUSING):
911             LOG.warning("Instance in transitional state "
912                         "(%(task_state)s) at start-up and power state "
913                         "is (%(power_state)s), clearing task state "
914                         "and unpausing the instance",
915                         {'task_state': instance.task_state,
916                          'power_state': current_power_state},
917                         instance=instance)
918             try:
919                 self.unpause_instance(context, instance)
920             except NotImplementedError:
921                 # Some virt driver didn't support pause and unpause
922                 pass
923             except Exception:
924                 LOG.exception('Failed to unpause instance', instance=instance)
925             return
926 
927         if instance.task_state == task_states.POWERING_OFF:
928             try:
929                 LOG.debug("Instance in transitional state %s at start-up "
930                           "retrying stop request",
931                           instance.task_state, instance=instance)
932                 self.stop_instance(context, instance, True)
933             except Exception:
934                 # we don't want that an exception blocks the init_host
935                 LOG.exception('Failed to stop instance', instance=instance)
936             return
937 
938         if instance.task_state == task_states.POWERING_ON:
939             try:
940                 LOG.debug("Instance in transitional state %s at start-up "
941                           "retrying start request",
942                           instance.task_state, instance=instance)
943                 self.start_instance(context, instance)
944             except Exception:
945                 # we don't want that an exception blocks the init_host
946                 LOG.exception('Failed to start instance', instance=instance)
947             return
948 
949         net_info = instance.get_network_info()
950         try:
951             self.driver.plug_vifs(instance, net_info)
952         except NotImplementedError as e:
953             LOG.debug(e, instance=instance)
954         except exception.VirtualInterfacePlugException:
955             # we don't want an exception to block the init_host
956             LOG.exception("Vifs plug failed", instance=instance)
957             self._set_instance_obj_error_state(context, instance)
958             return
959 
960         if instance.task_state == task_states.RESIZE_MIGRATING:
961             # We crashed during resize/migration, so roll back for safety
962             try:
963                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
964                 # not in system_metadata we default to True for backwards
965                 # compatibility
966                 power_on = (instance.system_metadata.get('old_vm_state') !=
967                             vm_states.STOPPED)
968 
969                 block_dev_info = self._get_instance_block_device_info(context,
970                                                                       instance)
971 
972                 self.driver.finish_revert_migration(context,
973                     instance, net_info, block_dev_info, power_on)
974 
975             except Exception:
976                 LOG.exception('Failed to revert crashed migration',
977                               instance=instance)
978             finally:
979                 LOG.info('Instance found in migrating state during '
980                          'startup. Resetting task_state',
981                          instance=instance)
982                 instance.task_state = None
983                 instance.save()
984         if instance.task_state == task_states.MIGRATING:
985             # Live migration did not complete, but instance is on this
986             # host, so reset the state.
987             instance.task_state = None
988             instance.save(expected_task_state=[task_states.MIGRATING])
989 
990         db_state = instance.power_state
991         drv_state = self._get_power_state(context, instance)
992         expect_running = (db_state == power_state.RUNNING and
993                           drv_state != db_state)
994 
995         LOG.debug('Current state is %(drv_state)s, state in DB is '
996                   '%(db_state)s.',
997                   {'drv_state': drv_state, 'db_state': db_state},
998                   instance=instance)
999 
1000         if expect_running and CONF.resume_guests_state_on_host_boot:
1001             self._resume_guests_state(context, instance, net_info)
1002         elif drv_state == power_state.RUNNING:
1003             # VMwareAPI drivers will raise an exception
1004             try:
1005                 self.driver.ensure_filtering_rules_for_instance(
1006                                        instance, net_info)
1007             except NotImplementedError:
1008                 LOG.debug('Hypervisor driver does not support '
1009                           'firewall rules', instance=instance)
1010 
1011     def _resume_guests_state(self, context, instance, net_info):
1012         LOG.info('Rebooting instance after nova-compute restart.',
1013                  instance=instance)
1014         block_device_info = \
1015             self._get_instance_block_device_info(context, instance)
1016 
1017         try:
1018             self.driver.resume_state_on_host_boot(
1019                 context, instance, net_info, block_device_info)
1020         except NotImplementedError:
1021             LOG.warning('Hypervisor driver does not support '
1022                         'resume guests', instance=instance)
1023         except Exception:
1024             # NOTE(vish): The instance failed to resume, so we set the
1025             #             instance to error and attempt to continue.
1026             LOG.warning('Failed to resume instance',
1027                         instance=instance)
1028             self._set_instance_obj_error_state(context, instance)
1029 
1030     def _retry_reboot(self, context, instance, current_power_state):
1031         current_task_state = instance.task_state
1032         retry_reboot = False
1033         reboot_type = compute_utils.get_reboot_type(current_task_state,
1034                                                     current_power_state)
1035 
1036         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1037                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1038         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1039                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1040         started_not_running = (current_task_state in
1041                                [task_states.REBOOT_STARTED,
1042                                 task_states.REBOOT_STARTED_HARD] and
1043                                current_power_state != power_state.RUNNING)
1044 
1045         if pending_soft or pending_hard or started_not_running:
1046             retry_reboot = True
1047 
1048         return retry_reboot, reboot_type
1049 
1050     def handle_lifecycle_event(self, event):
1051         LOG.info("VM %(state)s (Lifecycle Event)",
1052                  {'state': event.get_name()},
1053                  instance_uuid=event.get_instance_uuid())
1054         context = nova.context.get_admin_context(read_deleted='yes')
1055         instance = objects.Instance.get_by_uuid(context,
1056                                                 event.get_instance_uuid(),
1057                                                 expected_attrs=[])
1058         vm_power_state = None
1059         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1060             vm_power_state = power_state.SHUTDOWN
1061         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1062             vm_power_state = power_state.RUNNING
1063         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1064             vm_power_state = power_state.PAUSED
1065         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1066             vm_power_state = power_state.RUNNING
1067         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1068             vm_power_state = power_state.SUSPENDED
1069         else:
1070             LOG.warning("Unexpected power state %d", event.get_transition())
1071 
1072         # Note(lpetrut): The event may be delayed, thus not reflecting
1073         # the current instance power state. In that case, ignore the event.
1074         current_power_state = self._get_power_state(context, instance)
1075         if current_power_state == vm_power_state:
1076             LOG.debug('Synchronizing instance power state after lifecycle '
1077                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1078                       'current task_state: %(task_state)s, current DB '
1079                       'power_state: %(db_power_state)s, VM power_state: '
1080                       '%(vm_power_state)s',
1081                       {'event': event.get_name(),
1082                        'vm_state': instance.vm_state,
1083                        'task_state': instance.task_state,
1084                        'db_power_state': instance.power_state,
1085                        'vm_power_state': vm_power_state},
1086                       instance_uuid=instance.uuid)
1087             self._sync_instance_power_state(context,
1088                                             instance,
1089                                             vm_power_state)
1090 
1091     def handle_events(self, event):
1092         if isinstance(event, virtevent.LifecycleEvent):
1093             try:
1094                 self.handle_lifecycle_event(event)
1095             except exception.InstanceNotFound:
1096                 LOG.debug("Event %s arrived for non-existent instance. The "
1097                           "instance was probably deleted.", event)
1098         else:
1099             LOG.debug("Ignoring event %s", event)
1100 
1101     def init_virt_events(self):
1102         if CONF.workarounds.handle_virt_lifecycle_events:
1103             self.driver.register_event_listener(self.handle_events)
1104         else:
1105             # NOTE(mriedem): If the _sync_power_states periodic task is
1106             # disabled we should emit a warning in the logs.
1107             if CONF.sync_power_state_interval < 0:
1108                 LOG.warning('Instance lifecycle events from the compute '
1109                             'driver have been disabled. Note that lifecycle '
1110                             'changes to an instance outside of the compute '
1111                             'service will not be synchronized '
1112                             'automatically since the _sync_power_states '
1113                             'periodic task is also disabled.')
1114             else:
1115                 LOG.info('Instance lifecycle events from the compute '
1116                          'driver have been disabled. Note that lifecycle '
1117                          'changes to an instance outside of the compute '
1118                          'service will only be synchronized by the '
1119                          '_sync_power_states periodic task.')
1120 
1121     def init_host(self):
1122         """Initialization for a standalone compute service."""
1123 
1124         if CONF.pci.passthrough_whitelist:
1125             # Simply loading the PCI passthrough whitelist will do a bunch of
1126             # validation that would otherwise wait until the PciDevTracker is
1127             # constructed when updating available resources for the compute
1128             # node(s) in the resource tracker, effectively killing that task.
1129             # So load up the whitelist when starting the compute service to
1130             # flush any invalid configuration early so we can kill the service
1131             # if the configuration is wrong.
1132             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1133 
1134         self.driver.init_host(host=self.host)
1135         context = nova.context.get_admin_context()
1136         instances = objects.InstanceList.get_by_host(
1137             context, self.host, expected_attrs=['info_cache', 'metadata'])
1138 
1139         if CONF.defer_iptables_apply:
1140             self.driver.filter_defer_apply_on()
1141 
1142         self.init_virt_events()
1143 
1144         try:
1145             # checking that instance was not already evacuated to other host
1146             self._destroy_evacuated_instances(context)
1147             for instance in instances:
1148                 self._init_instance(context, instance)
1149         finally:
1150             if CONF.defer_iptables_apply:
1151                 self.driver.filter_defer_apply_off()
1152             if instances:
1153                 # We only send the instance info to the scheduler on startup
1154                 # if there is anything to send, otherwise this host might
1155                 # not be mapped yet in a cell and the scheduler may have
1156                 # issues dealing with the information. Later changes to
1157                 # instances on this host will update the scheduler, or the
1158                 # _sync_scheduler_instance_info periodic task will.
1159                 self._update_scheduler_instance_info(context, instances)
1160 
1161     def cleanup_host(self):
1162         self.driver.register_event_listener(None)
1163         self.instance_events.cancel_all_events()
1164         self.driver.cleanup_host(host=self.host)
1165         self._cleanup_live_migrations_in_pool()
1166 
1167     def _cleanup_live_migrations_in_pool(self):
1168         # Shutdown the pool so we don't get new requests.
1169         self._live_migration_executor.shutdown(wait=False)
1170         # For any queued migrations, cancel the migration and update
1171         # its status.
1172         for migration, future in self._waiting_live_migrations.values():
1173             # If we got here before the Future was submitted then we need
1174             # to move on since there isn't anything we can do.
1175             if future is None:
1176                 continue
1177             if future.cancel():
1178                 self._set_migration_status(migration, 'cancelled')
1179                 LOG.info('Successfully cancelled queued live migration.',
1180                          instance_uuid=migration.instance_uuid)
1181             else:
1182                 LOG.warning('Unable to cancel live migration.',
1183                             instance_uuid=migration.instance_uuid)
1184         self._waiting_live_migrations.clear()
1185 
1186     def pre_start_hook(self):
1187         """After the service is initialized, but before we fully bring
1188         the service up by listening on RPC queues, make sure to update
1189         our available resources (and indirectly our available nodes).
1190         """
1191         self.update_available_resource(nova.context.get_admin_context(),
1192                                        startup=True)
1193 
1194     def _get_power_state(self, context, instance):
1195         """Retrieve the power state for the given instance."""
1196         LOG.debug('Checking state', instance=instance)
1197         try:
1198             return self.driver.get_info(instance).state
1199         except exception.InstanceNotFound:
1200             return power_state.NOSTATE
1201 
1202     def get_console_topic(self, context):
1203         """Retrieves the console host for a project on this host.
1204 
1205         Currently this is just set in the flags for each compute host.
1206 
1207         """
1208         # TODO(mdragon): perhaps make this variable by console_type?
1209         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1210 
1211     @wrap_exception()
1212     def get_console_pool_info(self, context, console_type):
1213         return self.driver.get_console_pool_info(console_type)
1214 
1215     @wrap_exception()
1216     def refresh_instance_security_rules(self, context, instance):
1217         """Tell the virtualization driver to refresh security rules for
1218         an instance.
1219 
1220         Passes straight through to the virtualization driver.
1221 
1222         Synchronize the call because we may still be in the middle of
1223         creating the instance.
1224         """
1225         @utils.synchronized(instance.uuid)
1226         def _sync_refresh():
1227             try:
1228                 return self.driver.refresh_instance_security_rules(instance)
1229             except NotImplementedError:
1230                 LOG.debug('Hypervisor driver does not support '
1231                           'security groups.', instance=instance)
1232 
1233         return _sync_refresh()
1234 
1235     def _await_block_device_map_created(self, context, vol_id):
1236         # TODO(yamahata): creating volume simultaneously
1237         #                 reduces creation time?
1238         # TODO(yamahata): eliminate dumb polling
1239         start = time.time()
1240         retries = CONF.block_device_allocate_retries
1241         if retries < 0:
1242             LOG.warning("Treating negative config value (%(retries)s) for "
1243                         "'block_device_retries' as 0.",
1244                         {'retries': retries})
1245         # (1) treat  negative config value as 0
1246         # (2) the configured value is 0, one attempt should be made
1247         # (3) the configured value is > 0, then the total number attempts
1248         #      is (retries + 1)
1249         attempts = 1
1250         if retries >= 1:
1251             attempts = retries + 1
1252         for attempt in range(1, attempts + 1):
1253             volume = self.volume_api.get(context, vol_id)
1254             volume_status = volume['status']
1255             if volume_status not in ['creating', 'downloading']:
1256                 if volume_status == 'available':
1257                     return attempt
1258                 LOG.warning("Volume id: %(vol_id)s finished being "
1259                             "created but its status is %(vol_status)s.",
1260                             {'vol_id': vol_id,
1261                              'vol_status': volume_status})
1262                 break
1263             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1264         raise exception.VolumeNotCreated(volume_id=vol_id,
1265                                          seconds=int(time.time() - start),
1266                                          attempts=attempt,
1267                                          volume_status=volume_status)
1268 
1269     def _decode_files(self, injected_files):
1270         """Base64 decode the list of files to inject."""
1271         if not injected_files:
1272             return []
1273 
1274         def _decode(f):
1275             path, contents = f
1276             # Py3 raises binascii.Error instead of TypeError as in Py27
1277             try:
1278                 decoded = base64.b64decode(contents)
1279                 return path, decoded
1280             except (TypeError, binascii.Error):
1281                 raise exception.Base64Exception(path=path)
1282 
1283         return [_decode(f) for f in injected_files]
1284 
1285     def _validate_instance_group_policy(self, context, instance,
1286                                         scheduler_hints):
1287         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1288         # However, there is a race condition with the enforcement of
1289         # the policy.  Since more than one instance may be scheduled at the
1290         # same time, it's possible that more than one instance with an
1291         # anti-affinity policy may end up here.  It's also possible that
1292         # multiple instances with an affinity policy could end up on different
1293         # hosts.  This is a validation step to make sure that starting the
1294         # instance here doesn't violate the policy.
1295         group_hint = scheduler_hints.get('group')
1296         if not group_hint:
1297             return
1298 
1299         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1300         # to check the type on the value and pull the single entry out. The
1301         # API request schema validates that the 'group' hint is a single value.
1302         if isinstance(group_hint, list):
1303             group_hint = group_hint[0]
1304 
1305         @utils.synchronized(group_hint)
1306         def _do_validation(context, instance, group_hint):
1307             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1308             if 'anti-affinity' in group.policies:
1309                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1310                 if self.host in group_hosts:
1311                     msg = _("Anti-affinity instance group policy "
1312                             "was violated.")
1313                     raise exception.RescheduledException(
1314                             instance_uuid=instance.uuid,
1315                             reason=msg)
1316             elif 'affinity' in group.policies:
1317                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1318                 if group_hosts and self.host not in group_hosts:
1319                     msg = _("Affinity instance group policy was violated.")
1320                     raise exception.RescheduledException(
1321                             instance_uuid=instance.uuid,
1322                             reason=msg)
1323 
1324         if not CONF.workarounds.disable_group_policy_check_upcall:
1325             _do_validation(context, instance, group_hint)
1326 
1327     def _log_original_error(self, exc_info, instance_uuid):
1328         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1329                   exc_info=exc_info)
1330 
1331     def _reschedule(self, context, request_spec, filter_properties,
1332             instance, reschedule_method, method_args, task_state,
1333             exc_info=None, host_list=None):
1334         """Attempt to re-schedule a compute operation."""
1335 
1336         instance_uuid = instance.uuid
1337         retry = filter_properties.get('retry')
1338         if not retry:
1339             # no retry information, do not reschedule.
1340             LOG.debug("Retry info not present, will not reschedule",
1341                       instance_uuid=instance_uuid)
1342             return
1343 
1344         if not request_spec:
1345             LOG.debug("No request spec, will not reschedule",
1346                       instance_uuid=instance_uuid)
1347             return
1348 
1349         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1350                   {'method': reschedule_method.__name__,
1351                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1352 
1353         # reset the task state:
1354         self._instance_update(context, instance, task_state=task_state)
1355 
1356         if exc_info:
1357             # stringify to avoid circular ref problem in json serialization:
1358             retry['exc'] = traceback.format_exception_only(exc_info[0],
1359                                     exc_info[1])
1360 
1361         reschedule_method(context, *method_args, host_list=host_list)
1362         return True
1363 
1364     @periodic_task.periodic_task
1365     def _check_instance_build_time(self, context):
1366         """Ensure that instances are not stuck in build."""
1367         timeout = CONF.instance_build_timeout
1368         if timeout == 0:
1369             return
1370 
1371         filters = {'vm_state': vm_states.BUILDING,
1372                    'host': self.host}
1373 
1374         building_insts = objects.InstanceList.get_by_filters(context,
1375                            filters, expected_attrs=[], use_slave=True)
1376 
1377         for instance in building_insts:
1378             if timeutils.is_older_than(instance.created_at, timeout):
1379                 self._set_instance_obj_error_state(context, instance)
1380                 LOG.warning("Instance build timed out. Set to error "
1381                             "state.", instance=instance)
1382 
1383     def _check_instance_exists(self, context, instance):
1384         """Ensure an instance with the same name is not already present."""
1385         if self.driver.instance_exists(instance):
1386             raise exception.InstanceExists(name=instance.name)
1387 
1388     def _allocate_network_async(self, context, instance, requested_networks,
1389                                 macs, security_groups, is_vpn):
1390         """Method used to allocate networks in the background.
1391 
1392         Broken out for testing.
1393         """
1394         # First check to see if we're specifically not supposed to allocate
1395         # networks because if so, we can exit early.
1396         if requested_networks and requested_networks.no_allocate:
1397             LOG.debug("Not allocating networking since 'none' was specified.",
1398                       instance=instance)
1399             return network_model.NetworkInfo([])
1400 
1401         LOG.debug("Allocating IP information in the background.",
1402                   instance=instance)
1403         retries = CONF.network_allocate_retries
1404         attempts = retries + 1
1405         retry_time = 1
1406         bind_host_id = self.driver.network_binding_host_id(context, instance)
1407         for attempt in range(1, attempts + 1):
1408             try:
1409                 nwinfo = self.network_api.allocate_for_instance(
1410                         context, instance, vpn=is_vpn,
1411                         requested_networks=requested_networks,
1412                         macs=macs,
1413                         security_groups=security_groups,
1414                         bind_host_id=bind_host_id)
1415                 LOG.debug('Instance network_info: |%s|', nwinfo,
1416                           instance=instance)
1417                 instance.system_metadata['network_allocated'] = 'True'
1418                 # NOTE(JoshNang) do not save the instance here, as it can cause
1419                 # races. The caller shares a reference to instance and waits
1420                 # for this async greenthread to finish before calling
1421                 # instance.save().
1422                 return nwinfo
1423             except Exception:
1424                 exc_info = sys.exc_info()
1425                 log_info = {'attempt': attempt,
1426                             'attempts': attempts}
1427                 if attempt == attempts:
1428                     LOG.exception('Instance failed network setup '
1429                                   'after %(attempts)d attempt(s)',
1430                                   log_info)
1431                     six.reraise(*exc_info)
1432                 LOG.warning('Instance failed network setup '
1433                             '(attempt %(attempt)d of %(attempts)d)',
1434                             log_info, instance=instance)
1435                 time.sleep(retry_time)
1436                 retry_time *= 2
1437                 if retry_time > 30:
1438                     retry_time = 30
1439         # Not reached.
1440 
1441     def _build_networks_for_instance(self, context, instance,
1442             requested_networks, security_groups):
1443 
1444         # If we're here from a reschedule the network may already be allocated.
1445         if strutils.bool_from_string(
1446                 instance.system_metadata.get('network_allocated', 'False')):
1447             # NOTE(alex_xu): The network_allocated is True means the network
1448             # resource already allocated at previous scheduling, and the
1449             # network setup is cleanup at previous. After rescheduling, the
1450             # network resource need setup on the new host.
1451             self.network_api.setup_instance_network_on_host(
1452                 context, instance, instance.host)
1453             return self.network_api.get_instance_nw_info(context, instance)
1454 
1455         if not self.is_neutron_security_groups:
1456             security_groups = []
1457 
1458         macs = self.driver.macs_for_instance(instance)
1459         network_info = self._allocate_network(context, instance,
1460                 requested_networks, macs, security_groups)
1461 
1462         return network_info
1463 
1464     def _allocate_network(self, context, instance, requested_networks, macs,
1465                           security_groups):
1466         """Start network allocation asynchronously.  Return an instance
1467         of NetworkInfoAsyncWrapper that can be used to retrieve the
1468         allocated networks when the operation has finished.
1469         """
1470         # NOTE(comstud): Since we're allocating networks asynchronously,
1471         # this task state has little meaning, as we won't be in this
1472         # state for very long.
1473         instance.vm_state = vm_states.BUILDING
1474         instance.task_state = task_states.NETWORKING
1475         instance.save(expected_task_state=[None])
1476 
1477         is_vpn = False
1478         return network_model.NetworkInfoAsyncWrapper(
1479                 self._allocate_network_async, context, instance,
1480                 requested_networks, macs, security_groups, is_vpn)
1481 
1482     def _default_root_device_name(self, instance, image_meta, root_bdm):
1483         try:
1484             return self.driver.default_root_device_name(instance,
1485                                                         image_meta,
1486                                                         root_bdm)
1487         except NotImplementedError:
1488             return compute_utils.get_next_device_name(instance, [])
1489 
1490     def _default_device_names_for_instance(self, instance,
1491                                            root_device_name,
1492                                            *block_device_lists):
1493         try:
1494             self.driver.default_device_names_for_instance(instance,
1495                                                           root_device_name,
1496                                                           *block_device_lists)
1497         except NotImplementedError:
1498             compute_utils.default_device_names_for_instance(
1499                 instance, root_device_name, *block_device_lists)
1500 
1501     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1502         # NOTE(ndipanov): Copy obj to avoid changing the original
1503         block_device_obj = block_device_obj.obj_clone()
1504         try:
1505             return self.driver.get_device_name_for_instance(
1506                 instance, bdms, block_device_obj)
1507         except NotImplementedError:
1508             return compute_utils.get_device_name_for_instance(
1509                 instance, bdms, block_device_obj.get("device_name"))
1510 
1511     def _default_block_device_names(self, instance, image_meta, block_devices):
1512         """Verify that all the devices have the device_name set. If not,
1513         provide a default name.
1514 
1515         It also ensures that there is a root_device_name and is set to the
1516         first block device in the boot sequence (boot_index=0).
1517         """
1518         root_bdm = block_device.get_root_bdm(block_devices)
1519         if not root_bdm:
1520             return
1521 
1522         # Get the root_device_name from the root BDM or the instance
1523         root_device_name = None
1524         update_root_bdm = False
1525 
1526         if root_bdm.device_name:
1527             root_device_name = root_bdm.device_name
1528             instance.root_device_name = root_device_name
1529         elif instance.root_device_name:
1530             root_device_name = instance.root_device_name
1531             root_bdm.device_name = root_device_name
1532             update_root_bdm = True
1533         else:
1534             root_device_name = self._default_root_device_name(instance,
1535                                                               image_meta,
1536                                                               root_bdm)
1537 
1538             instance.root_device_name = root_device_name
1539             root_bdm.device_name = root_device_name
1540             update_root_bdm = True
1541 
1542         if update_root_bdm:
1543             root_bdm.save()
1544 
1545         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1546                             block_devices))
1547         swap = list(filter(block_device.new_format_is_swap,
1548                       block_devices))
1549         block_device_mapping = list(filter(
1550               driver_block_device.is_block_device_mapping, block_devices))
1551 
1552         self._default_device_names_for_instance(instance,
1553                                                 root_device_name,
1554                                                 ephemerals,
1555                                                 swap,
1556                                                 block_device_mapping)
1557 
1558     def _block_device_info_to_legacy(self, block_device_info):
1559         """Convert BDI to the old format for drivers that need it."""
1560 
1561         if self.use_legacy_block_device_info:
1562             ephemerals = driver_block_device.legacy_block_devices(
1563                 driver.block_device_info_get_ephemerals(block_device_info))
1564             mapping = driver_block_device.legacy_block_devices(
1565                 driver.block_device_info_get_mapping(block_device_info))
1566             swap = block_device_info['swap']
1567             if swap:
1568                 swap = swap.legacy()
1569 
1570             block_device_info.update({
1571                 'ephemerals': ephemerals,
1572                 'swap': swap,
1573                 'block_device_mapping': mapping})
1574 
1575     def _add_missing_dev_names(self, bdms, instance):
1576         for bdm in bdms:
1577             if bdm.device_name is not None:
1578                 continue
1579 
1580             device_name = self._get_device_name_for_instance(instance,
1581                                                              bdms, bdm)
1582             values = {'device_name': device_name}
1583             bdm.update(values)
1584             bdm.save()
1585 
1586     def _prep_block_device(self, context, instance, bdms):
1587         """Set up the block device for an instance with error logging."""
1588         try:
1589             self._add_missing_dev_names(bdms, instance)
1590             block_device_info = driver.get_block_device_info(instance, bdms)
1591             mapping = driver.block_device_info_get_mapping(block_device_info)
1592             driver_block_device.attach_block_devices(
1593                 mapping, context, instance, self.volume_api, self.driver,
1594                 wait_func=self._await_block_device_map_created)
1595 
1596             self._block_device_info_to_legacy(block_device_info)
1597             return block_device_info
1598 
1599         except exception.OverQuota as e:
1600             LOG.warning('Failed to create block device for instance due'
1601                         ' to exceeding volume related resource quota.'
1602                         ' Error: %s', e.message, instance=instance)
1603             raise
1604 
1605         except Exception as ex:
1606             LOG.exception('Instance failed block device setup',
1607                           instance=instance)
1608             # InvalidBDM will eventually result in a BuildAbortException when
1609             # booting from volume, and will be recorded as an instance fault.
1610             # Maintain the original exception message which most likely has
1611             # useful details which the standard InvalidBDM error message lacks.
1612             raise exception.InvalidBDM(six.text_type(ex))
1613 
1614     def _update_instance_after_spawn(self, context, instance):
1615         instance.power_state = self._get_power_state(context, instance)
1616         instance.vm_state = vm_states.ACTIVE
1617         instance.task_state = None
1618         instance.launched_at = timeutils.utcnow()
1619         configdrive.update_instance(instance)
1620 
1621     def _update_scheduler_instance_info(self, context, instance):
1622         """Sends an InstanceList with created or updated Instance objects to
1623         the Scheduler client.
1624 
1625         In the case of init_host, the value passed will already be an
1626         InstanceList. Other calls will send individual Instance objects that
1627         have been created or resized. In this case, we create an InstanceList
1628         object containing that Instance.
1629         """
1630         if not self.send_instance_updates:
1631             return
1632         if isinstance(instance, obj_instance.Instance):
1633             instance = objects.InstanceList(objects=[instance])
1634         context = context.elevated()
1635         self.scheduler_client.update_instance_info(context, self.host,
1636                                                    instance)
1637 
1638     def _delete_scheduler_instance_info(self, context, instance_uuid):
1639         """Sends the uuid of the deleted Instance to the Scheduler client."""
1640         if not self.send_instance_updates:
1641             return
1642         context = context.elevated()
1643         self.scheduler_client.delete_instance_info(context, self.host,
1644                                                    instance_uuid)
1645 
1646     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1647     def _sync_scheduler_instance_info(self, context):
1648         if not self.send_instance_updates:
1649             return
1650         context = context.elevated()
1651         instances = objects.InstanceList.get_by_host(context, self.host,
1652                                                      expected_attrs=[],
1653                                                      use_slave=True)
1654         uuids = [instance.uuid for instance in instances]
1655         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1656 
1657     def _notify_about_instance_usage(self, context, instance, event_suffix,
1658                                      network_info=None, extra_usage_info=None,
1659                                      fault=None):
1660         compute_utils.notify_about_instance_usage(
1661             self.notifier, context, instance, event_suffix,
1662             network_info=network_info,
1663             extra_usage_info=extra_usage_info, fault=fault)
1664 
1665     def _deallocate_network(self, context, instance,
1666                             requested_networks=None):
1667         # If we were told not to allocate networks let's save ourselves
1668         # the trouble of calling the network API.
1669         if requested_networks and requested_networks.no_allocate:
1670             LOG.debug("Skipping network deallocation for instance since "
1671                       "networking was not requested.", instance=instance)
1672             return
1673 
1674         LOG.debug('Deallocating network for instance', instance=instance)
1675         with timeutils.StopWatch() as timer:
1676             self.network_api.deallocate_for_instance(
1677                 context, instance, requested_networks=requested_networks)
1678         # nova-network does an rpc call so we're OK tracking time spent here
1679         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1680                  timer.elapsed(), instance=instance)
1681 
1682     def _get_instance_block_device_info(self, context, instance,
1683                                         refresh_conn_info=False,
1684                                         bdms=None):
1685         """Transform block devices to the driver block_device format."""
1686 
1687         if not bdms:
1688             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1689                     context, instance.uuid)
1690         block_device_info = driver.get_block_device_info(instance, bdms)
1691 
1692         if not refresh_conn_info:
1693             # if the block_device_mapping has no value in connection_info
1694             # (returned as None), don't include in the mapping
1695             block_device_info['block_device_mapping'] = [
1696                 bdm for bdm in driver.block_device_info_get_mapping(
1697                                     block_device_info)
1698                 if bdm.get('connection_info')]
1699         else:
1700             driver_block_device.refresh_conn_infos(
1701                 driver.block_device_info_get_mapping(block_device_info),
1702                 context, instance, self.volume_api, self.driver)
1703 
1704         self._block_device_info_to_legacy(block_device_info)
1705 
1706         return block_device_info
1707 
1708     def _build_failed(self):
1709         self._failed_builds += 1
1710         limit = CONF.compute.consecutive_build_service_disable_threshold
1711         if limit and self._failed_builds >= limit:
1712             # NOTE(danms): If we're doing a bunch of parallel builds,
1713             # it is possible (although not likely) that we have already
1714             # failed N-1 builds before this and we race with a successful
1715             # build and disable ourselves here when we might've otherwise
1716             # not.
1717             LOG.error('Disabling service due to %(fails)i '
1718                       'consecutive build failures',
1719                       {'fails': self._failed_builds})
1720             ctx = nova.context.get_admin_context()
1721             service = objects.Service.get_by_compute_host(ctx, CONF.host)
1722             service.disabled = True
1723             service.disabled_reason = (
1724                 'Auto-disabled due to %i build failures' % self._failed_builds)
1725             service.save()
1726             # NOTE(danms): Reset our counter now so that when the admin
1727             # re-enables us we can start fresh
1728             self._failed_builds = 0
1729         elif self._failed_builds > 1:
1730             LOG.warning('%(fails)i consecutive build failures',
1731                         {'fails': self._failed_builds})
1732 
1733     @wrap_exception()
1734     @reverts_task_state
1735     @wrap_instance_fault
1736     def build_and_run_instance(self, context, instance, image, request_spec,
1737                      filter_properties, admin_password=None,
1738                      injected_files=None, requested_networks=None,
1739                      security_groups=None, block_device_mapping=None,
1740                      node=None, limits=None, host_list=None):
1741 
1742         @utils.synchronized(instance.uuid)
1743         def _locked_do_build_and_run_instance(*args, **kwargs):
1744             # NOTE(danms): We grab the semaphore with the instance uuid
1745             # locked because we could wait in line to build this instance
1746             # for a while and we want to make sure that nothing else tries
1747             # to do anything with this instance while we wait.
1748             with self._build_semaphore:
1749                 try:
1750                     result = self._do_build_and_run_instance(*args, **kwargs)
1751                 except Exception:
1752                     # NOTE(mriedem): This should really only happen if
1753                     # _decode_files in _do_build_and_run_instance fails, and
1754                     # that's before a guest is spawned so it's OK to remove
1755                     # allocations for the instance for this node from Placement
1756                     # below as there is no guest consuming resources anyway.
1757                     # The _decode_files case could be handled more specifically
1758                     # but that's left for another day.
1759                     result = build_results.FAILED
1760                     raise
1761                 finally:
1762                     if result == build_results.FAILED:
1763                         # Remove the allocation records from Placement for the
1764                         # instance if the build failed. The instance.host is
1765                         # likely set to None in _do_build_and_run_instance
1766                         # which means if the user deletes the instance, it
1767                         # will be deleted in the API, not the compute service.
1768                         # Setting the instance.host to None in
1769                         # _do_build_and_run_instance means that the
1770                         # ResourceTracker will no longer consider this instance
1771                         # to be claiming resources against it, so we want to
1772                         # reflect that same thing in Placement.  No need to
1773                         # call this for a reschedule, as the allocations will
1774                         # have already been removed in
1775                         # self._do_build_and_run_instance().
1776                         self._delete_allocation_for_instance(context,
1777                                                              instance.uuid)
1778 
1779                     if result in (build_results.FAILED,
1780                                   build_results.RESCHEDULED):
1781                         self._build_failed()
1782                     else:
1783                         self._failed_builds = 0
1784 
1785         # NOTE(danms): We spawn here to return the RPC worker thread back to
1786         # the pool. Since what follows could take a really long time, we don't
1787         # want to tie up RPC workers.
1788         utils.spawn_n(_locked_do_build_and_run_instance,
1789                       context, instance, image, request_spec,
1790                       filter_properties, admin_password, injected_files,
1791                       requested_networks, security_groups,
1792                       block_device_mapping, node, limits, host_list)
1793 
1794     def _delete_allocation_for_instance(self, context, instance_uuid):
1795         rt = self._get_resource_tracker()
1796         rt.reportclient.delete_allocation_for_instance(context, instance_uuid)
1797 
1798     def _check_device_tagging(self, requested_networks, block_device_mapping):
1799         tagging_requested = False
1800         if requested_networks:
1801             for net in requested_networks:
1802                 if 'tag' in net and net.tag is not None:
1803                     tagging_requested = True
1804                     break
1805         if block_device_mapping and not tagging_requested:
1806             for bdm in block_device_mapping:
1807                 if 'tag' in bdm and bdm.tag is not None:
1808                     tagging_requested = True
1809                     break
1810         if (tagging_requested and
1811                 not self.driver.capabilities.get('supports_device_tagging',
1812                                                  False)):
1813             raise exception.BuildAbortException('Attempt to boot guest with '
1814                                                 'tagged devices on host that '
1815                                                 'does not support tagging.')
1816 
1817     @hooks.add_hook('build_instance')
1818     @wrap_exception()
1819     @reverts_task_state
1820     @wrap_instance_event(prefix='compute')
1821     @wrap_instance_fault
1822     def _do_build_and_run_instance(self, context, instance, image,
1823             request_spec, filter_properties, admin_password, injected_files,
1824             requested_networks, security_groups, block_device_mapping,
1825             node=None, limits=None, host_list=None):
1826 
1827         try:
1828             LOG.debug('Starting instance...', instance=instance)
1829             instance.vm_state = vm_states.BUILDING
1830             instance.task_state = None
1831             instance.save(expected_task_state=
1832                     (task_states.SCHEDULING, None))
1833         except exception.InstanceNotFound:
1834             msg = 'Instance disappeared before build.'
1835             LOG.debug(msg, instance=instance)
1836             return build_results.FAILED
1837         except exception.UnexpectedTaskStateError as e:
1838             LOG.debug(e.format_message(), instance=instance)
1839             return build_results.FAILED
1840 
1841         # b64 decode the files to inject:
1842         decoded_files = self._decode_files(injected_files)
1843 
1844         if limits is None:
1845             limits = {}
1846 
1847         if node is None:
1848             node = self._get_nodename(instance, refresh=True)
1849 
1850         try:
1851             with timeutils.StopWatch() as timer:
1852                 self._build_and_run_instance(context, instance, image,
1853                         decoded_files, admin_password, requested_networks,
1854                         security_groups, block_device_mapping, node, limits,
1855                         filter_properties, request_spec)
1856             LOG.info('Took %0.2f seconds to build instance.',
1857                      timer.elapsed(), instance=instance)
1858             return build_results.ACTIVE
1859         except exception.RescheduledException as e:
1860             retry = filter_properties.get('retry')
1861             if not retry:
1862                 # no retry information, do not reschedule.
1863                 LOG.debug("Retry info not present, will not reschedule",
1864                     instance=instance)
1865                 self._cleanup_allocated_networks(context, instance,
1866                     requested_networks)
1867                 self._cleanup_volumes(context, instance,
1868                     block_device_mapping, raise_exc=False)
1869                 compute_utils.add_instance_fault_from_exc(context,
1870                         instance, e, sys.exc_info(),
1871                         fault_message=e.kwargs['reason'])
1872                 self._nil_out_instance_obj_host_and_node(instance)
1873                 self._set_instance_obj_error_state(context, instance,
1874                                                    clean_task_state=True)
1875                 return build_results.FAILED
1876             LOG.debug(e.format_message(), instance=instance)
1877             # This will be used for logging the exception
1878             retry['exc'] = traceback.format_exception(*sys.exc_info())
1879             # This will be used for setting the instance fault message
1880             retry['exc_reason'] = e.kwargs['reason']
1881             # NOTE(comstud): Deallocate networks if the driver wants
1882             # us to do so.
1883             # NOTE(mriedem): Always deallocate networking when using Neutron.
1884             # This is to unbind any ports that the user supplied in the server
1885             # create request, or delete any ports that nova created which were
1886             # meant to be bound to this host. This check intentionally bypasses
1887             # the result of deallocate_networks_on_reschedule because the
1888             # default value in the driver is False, but that method was really
1889             # only meant for Ironic and should be removed when nova-network is
1890             # removed (since is_neutron() will then always be True).
1891             # NOTE(vladikr): SR-IOV ports should be deallocated to
1892             # allow new sriov pci devices to be allocated on a new host.
1893             # Otherwise, if devices with pci addresses are already allocated
1894             # on the destination host, the instance will fail to spawn.
1895             # info_cache.network_info should be present at this stage.
1896             if (self.driver.deallocate_networks_on_reschedule(instance) or
1897                 utils.is_neutron() or
1898                 self.deallocate_sriov_ports_on_reschedule(instance)):
1899                 self._cleanup_allocated_networks(context, instance,
1900                         requested_networks)
1901             else:
1902                 # NOTE(alex_xu): Network already allocated and we don't
1903                 # want to deallocate them before rescheduling. But we need
1904                 # to cleanup those network resources setup on this host before
1905                 # rescheduling.
1906                 self.network_api.cleanup_instance_network_on_host(
1907                     context, instance, self.host)
1908 
1909             self._nil_out_instance_obj_host_and_node(instance)
1910             instance.task_state = task_states.SCHEDULING
1911             instance.save()
1912             # The instance will have already claimed resources from this host
1913             # before this build was attempted. Now that it has failed, we need
1914             # to unclaim those resources before casting to the conductor, so
1915             # that if there are alternate hosts available for a retry, it can
1916             # claim resources on that new host for the instance.
1917             self._delete_allocation_for_instance(context, instance.uuid)
1918 
1919             self.compute_task_api.build_instances(context, [instance],
1920                     image, filter_properties, admin_password,
1921                     injected_files, requested_networks, security_groups,
1922                     block_device_mapping, request_spec=request_spec,
1923                     host_lists=[host_list])
1924             return build_results.RESCHEDULED
1925         except (exception.InstanceNotFound,
1926                 exception.UnexpectedDeletingTaskStateError):
1927             msg = 'Instance disappeared during build.'
1928             LOG.debug(msg, instance=instance)
1929             self._cleanup_allocated_networks(context, instance,
1930                     requested_networks)
1931             return build_results.FAILED
1932         except exception.BuildAbortException as e:
1933             LOG.error(e.format_message(), instance=instance)
1934             self._cleanup_allocated_networks(context, instance,
1935                     requested_networks)
1936             self._cleanup_volumes(context, instance,
1937                     block_device_mapping, raise_exc=False)
1938             compute_utils.add_instance_fault_from_exc(context, instance,
1939                     e, sys.exc_info())
1940             self._nil_out_instance_obj_host_and_node(instance)
1941             self._set_instance_obj_error_state(context, instance,
1942                                                clean_task_state=True)
1943             return build_results.FAILED
1944         except Exception as e:
1945             # Should not reach here.
1946             LOG.exception('Unexpected build failure, not rescheduling build.',
1947                           instance=instance)
1948             self._cleanup_allocated_networks(context, instance,
1949                     requested_networks)
1950             self._cleanup_volumes(context, instance,
1951                     block_device_mapping, raise_exc=False)
1952             compute_utils.add_instance_fault_from_exc(context, instance,
1953                     e, sys.exc_info())
1954             self._nil_out_instance_obj_host_and_node(instance)
1955             self._set_instance_obj_error_state(context, instance,
1956                                                clean_task_state=True)
1957             return build_results.FAILED
1958 
1959     def deallocate_sriov_ports_on_reschedule(self, instance):
1960         """Determine if networks are needed to be deallocated before reschedule
1961 
1962         Check the cached network info for any assigned SR-IOV ports.
1963         SR-IOV ports should be deallocated prior to rescheduling
1964         in order to allow new sriov pci devices to be allocated on a new host.
1965         """
1966         info_cache = instance.info_cache
1967 
1968         def _has_sriov_port(vif):
1969             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1970 
1971         if (info_cache and info_cache.network_info):
1972             for vif in info_cache.network_info:
1973                 if _has_sriov_port(vif):
1974                     return True
1975         return False
1976 
1977     @staticmethod
1978     def _get_scheduler_hints(filter_properties, request_spec=None):
1979         """Helper method to get scheduler hints.
1980 
1981         This method prefers to get the hints out of the request spec, but that
1982         might not be provided. Conductor will pass request_spec down to the
1983         first compute chosen for a build but older computes will not pass
1984         the request_spec to conductor's build_instances method for a
1985         a reschedule, so if we're on a host via a retry, request_spec may not
1986         be provided so we need to fallback to use the filter_properties
1987         to get scheduler hints.
1988         """
1989         hints = {}
1990         if request_spec is not None and 'scheduler_hints' in request_spec:
1991             hints = request_spec.scheduler_hints
1992         if not hints:
1993             hints = filter_properties.get('scheduler_hints') or {}
1994         return hints
1995 
1996     def _build_and_run_instance(self, context, instance, image, injected_files,
1997             admin_password, requested_networks, security_groups,
1998             block_device_mapping, node, limits, filter_properties,
1999             request_spec=None):
2000 
2001         image_name = image.get('name')
2002         self._notify_about_instance_usage(context, instance, 'create.start',
2003                 extra_usage_info={'image_name': image_name})
2004         compute_utils.notify_about_instance_create(
2005             context, instance, self.host,
2006             phase=fields.NotificationPhase.START,
2007             bdms=block_device_mapping)
2008 
2009         # NOTE(mikal): cache the keystone roles associated with the instance
2010         # at boot time for later reference
2011         instance.system_metadata.update(
2012             {'boot_roles': ','.join(context.roles)})
2013 
2014         self._check_device_tagging(requested_networks, block_device_mapping)
2015 
2016         try:
2017             scheduler_hints = self._get_scheduler_hints(filter_properties,
2018                                                         request_spec)
2019             rt = self._get_resource_tracker()
2020             with rt.instance_claim(context, instance, node, limits):
2021                 # NOTE(russellb) It's important that this validation be done
2022                 # *after* the resource tracker instance claim, as that is where
2023                 # the host is set on the instance.
2024                 self._validate_instance_group_policy(context, instance,
2025                                                      scheduler_hints)
2026                 image_meta = objects.ImageMeta.from_dict(image)
2027                 with self._build_resources(context, instance,
2028                         requested_networks, security_groups, image_meta,
2029                         block_device_mapping) as resources:
2030                     instance.vm_state = vm_states.BUILDING
2031                     instance.task_state = task_states.SPAWNING
2032                     # NOTE(JoshNang) This also saves the changes to the
2033                     # instance from _allocate_network_async, as they aren't
2034                     # saved in that function to prevent races.
2035                     instance.save(expected_task_state=
2036                             task_states.BLOCK_DEVICE_MAPPING)
2037                     block_device_info = resources['block_device_info']
2038                     network_info = resources['network_info']
2039                     allocs = resources['allocations']
2040                     LOG.debug('Start spawning the instance on the hypervisor.',
2041                               instance=instance)
2042                     with timeutils.StopWatch() as timer:
2043                         self.driver.spawn(context, instance, image_meta,
2044                                           injected_files, admin_password,
2045                                           allocs, network_info=network_info,
2046                                           block_device_info=block_device_info)
2047                     LOG.info('Took %0.2f seconds to spawn the instance on '
2048                              'the hypervisor.', timer.elapsed(),
2049                              instance=instance)
2050         except (exception.InstanceNotFound,
2051                 exception.UnexpectedDeletingTaskStateError) as e:
2052             with excutils.save_and_reraise_exception():
2053                 self._notify_about_instance_usage(context, instance,
2054                     'create.error', fault=e)
2055                 compute_utils.notify_about_instance_create(
2056                     context, instance, self.host,
2057                     phase=fields.NotificationPhase.ERROR, exception=e,
2058                     bdms=block_device_mapping)
2059         except exception.ComputeResourcesUnavailable as e:
2060             LOG.debug(e.format_message(), instance=instance)
2061             self._notify_about_instance_usage(context, instance,
2062                     'create.error', fault=e)
2063             compute_utils.notify_about_instance_create(
2064                     context, instance, self.host,
2065                     phase=fields.NotificationPhase.ERROR, exception=e,
2066                     bdms=block_device_mapping)
2067             raise exception.RescheduledException(
2068                     instance_uuid=instance.uuid, reason=e.format_message())
2069         except exception.BuildAbortException as e:
2070             with excutils.save_and_reraise_exception():
2071                 LOG.debug(e.format_message(), instance=instance)
2072                 self._notify_about_instance_usage(context, instance,
2073                     'create.error', fault=e)
2074                 compute_utils.notify_about_instance_create(
2075                     context, instance, self.host,
2076                     phase=fields.NotificationPhase.ERROR, exception=e,
2077                     bdms=block_device_mapping)
2078         except (exception.FixedIpLimitExceeded,
2079                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2080             LOG.warning('No more network or fixed IP to be allocated',
2081                         instance=instance)
2082             self._notify_about_instance_usage(context, instance,
2083                     'create.error', fault=e)
2084             compute_utils.notify_about_instance_create(
2085                     context, instance, self.host,
2086                     phase=fields.NotificationPhase.ERROR, exception=e,
2087                     bdms=block_device_mapping)
2088             msg = _('Failed to allocate the network(s) with error %s, '
2089                     'not rescheduling.') % e.format_message()
2090             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2091                     reason=msg)
2092         except (exception.VirtualInterfaceCreateException,
2093                 exception.VirtualInterfaceMacAddressException,
2094                 exception.FixedIpInvalidOnHost,
2095                 exception.UnableToAutoAllocateNetwork) as e:
2096             LOG.exception('Failed to allocate network(s)',
2097                           instance=instance)
2098             self._notify_about_instance_usage(context, instance,
2099                     'create.error', fault=e)
2100             compute_utils.notify_about_instance_create(
2101                     context, instance, self.host,
2102                     phase=fields.NotificationPhase.ERROR, exception=e,
2103                     bdms=block_device_mapping)
2104             msg = _('Failed to allocate the network(s), not rescheduling.')
2105             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2106                     reason=msg)
2107         except (exception.FlavorDiskTooSmall,
2108                 exception.FlavorMemoryTooSmall,
2109                 exception.ImageNotActive,
2110                 exception.ImageUnacceptable,
2111                 exception.InvalidDiskInfo,
2112                 exception.InvalidDiskFormat,
2113                 cursive_exception.SignatureVerificationError,
2114                 exception.VolumeEncryptionNotSupported,
2115                 exception.InvalidInput,
2116                 # TODO(mriedem): We should be validating RequestedVRamTooHigh
2117                 # in the API during server create and rebuild.
2118                 exception.RequestedVRamTooHigh) as e:
2119             self._notify_about_instance_usage(context, instance,
2120                     'create.error', fault=e)
2121             compute_utils.notify_about_instance_create(
2122                     context, instance, self.host,
2123                     phase=fields.NotificationPhase.ERROR, exception=e,
2124                     bdms=block_device_mapping)
2125             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2126                     reason=e.format_message())
2127         except Exception as e:
2128             self._notify_about_instance_usage(context, instance,
2129                     'create.error', fault=e)
2130             compute_utils.notify_about_instance_create(
2131                     context, instance, self.host,
2132                     phase=fields.NotificationPhase.ERROR, exception=e,
2133                     bdms=block_device_mapping)
2134             raise exception.RescheduledException(
2135                     instance_uuid=instance.uuid, reason=six.text_type(e))
2136 
2137         # NOTE(alaski): This is only useful during reschedules, remove it now.
2138         instance.system_metadata.pop('network_allocated', None)
2139 
2140         # If CONF.default_access_ip_network_name is set, grab the
2141         # corresponding network and set the access ip values accordingly.
2142         network_name = CONF.default_access_ip_network_name
2143         if (network_name and not instance.access_ip_v4 and
2144                 not instance.access_ip_v6):
2145             # Note that when there are multiple ips to choose from, an
2146             # arbitrary one will be chosen.
2147             for vif in network_info:
2148                 if vif['network']['label'] == network_name:
2149                     for ip in vif.fixed_ips():
2150                         if not instance.access_ip_v4 and ip['version'] == 4:
2151                             instance.access_ip_v4 = ip['address']
2152                         if not instance.access_ip_v6 and ip['version'] == 6:
2153                             instance.access_ip_v6 = ip['address']
2154                     break
2155 
2156         self._update_instance_after_spawn(context, instance)
2157 
2158         try:
2159             instance.save(expected_task_state=task_states.SPAWNING)
2160         except (exception.InstanceNotFound,
2161                 exception.UnexpectedDeletingTaskStateError) as e:
2162             with excutils.save_and_reraise_exception():
2163                 self._notify_about_instance_usage(context, instance,
2164                     'create.error', fault=e)
2165                 compute_utils.notify_about_instance_create(
2166                     context, instance, self.host,
2167                     phase=fields.NotificationPhase.ERROR, exception=e,
2168                     bdms=block_device_mapping)
2169 
2170         self._update_scheduler_instance_info(context, instance)
2171         self._notify_about_instance_usage(context, instance, 'create.end',
2172                 extra_usage_info={'message': _('Success')},
2173                 network_info=network_info)
2174         compute_utils.notify_about_instance_create(context, instance,
2175                 self.host, phase=fields.NotificationPhase.END,
2176                 bdms=block_device_mapping)
2177 
2178     @contextlib.contextmanager
2179     def _build_resources(self, context, instance, requested_networks,
2180                          security_groups, image_meta, block_device_mapping):
2181         resources = {}
2182         network_info = None
2183         try:
2184             LOG.debug('Start building networks asynchronously for instance.',
2185                       instance=instance)
2186             network_info = self._build_networks_for_instance(context, instance,
2187                     requested_networks, security_groups)
2188             resources['network_info'] = network_info
2189         except (exception.InstanceNotFound,
2190                 exception.UnexpectedDeletingTaskStateError):
2191             raise
2192         except exception.UnexpectedTaskStateError as e:
2193             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2194                     reason=e.format_message())
2195         except Exception:
2196             # Because this allocation is async any failures are likely to occur
2197             # when the driver accesses network_info during spawn().
2198             LOG.exception('Failed to allocate network(s)',
2199                           instance=instance)
2200             msg = _('Failed to allocate the network(s), not rescheduling.')
2201             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2202                     reason=msg)
2203 
2204         try:
2205             # Depending on a virt driver, some network configuration is
2206             # necessary before preparing block devices.
2207             self.driver.prepare_networks_before_block_device_mapping(
2208                 instance, network_info)
2209 
2210             # Verify that all the BDMs have a device_name set and assign a
2211             # default to the ones missing it with the help of the driver.
2212             self._default_block_device_names(instance, image_meta,
2213                                              block_device_mapping)
2214 
2215             LOG.debug('Start building block device mappings for instance.',
2216                       instance=instance)
2217             instance.vm_state = vm_states.BUILDING
2218             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2219             instance.save()
2220 
2221             block_device_info = self._prep_block_device(context, instance,
2222                     block_device_mapping)
2223             resources['block_device_info'] = block_device_info
2224         except (exception.InstanceNotFound,
2225                 exception.UnexpectedDeletingTaskStateError):
2226             with excutils.save_and_reraise_exception():
2227                 # Make sure the async call finishes
2228                 if network_info is not None:
2229                     network_info.wait(do_raise=False)
2230                     self.driver.clean_networks_preparation(instance,
2231                                                            network_info)
2232         except (exception.UnexpectedTaskStateError,
2233                 exception.OverQuota, exception.InvalidBDM) as e:
2234             # Make sure the async call finishes
2235             if network_info is not None:
2236                 network_info.wait(do_raise=False)
2237                 self.driver.clean_networks_preparation(instance, network_info)
2238             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2239                     reason=e.format_message())
2240         except Exception:
2241             LOG.exception('Failure prepping block device',
2242                           instance=instance)
2243             # Make sure the async call finishes
2244             if network_info is not None:
2245                 network_info.wait(do_raise=False)
2246                 self.driver.clean_networks_preparation(instance, network_info)
2247             msg = _('Failure prepping block device.')
2248             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2249                     reason=msg)
2250 
2251         try:
2252             resources['allocations'] = (
2253                 self.reportclient.get_allocations_for_consumer(context,
2254                                                                instance.uuid))
2255         except Exception:
2256             LOG.exception('Failure retrieving placement allocations',
2257                           instance=instance)
2258             # Make sure the async call finishes
2259             if network_info is not None:
2260                 network_info.wait(do_raise=False)
2261             msg = _('Failure retrieving placement allocations')
2262             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2263                                                 reason=msg)
2264 
2265         try:
2266             yield resources
2267         except Exception as exc:
2268             with excutils.save_and_reraise_exception() as ctxt:
2269                 if not isinstance(exc, (
2270                         exception.InstanceNotFound,
2271                         exception.UnexpectedDeletingTaskStateError)):
2272                     LOG.exception('Instance failed to spawn',
2273                                   instance=instance)
2274                 # Make sure the async call finishes
2275                 if network_info is not None:
2276                     network_info.wait(do_raise=False)
2277                 # if network_info is empty we're likely here because of
2278                 # network allocation failure. Since nothing can be reused on
2279                 # rescheduling it's better to deallocate network to eliminate
2280                 # the chance of orphaned ports in neutron
2281                 deallocate_networks = False if network_info else True
2282                 try:
2283                     self._shutdown_instance(context, instance,
2284                             block_device_mapping, requested_networks,
2285                             try_deallocate_networks=deallocate_networks)
2286                 except Exception as exc2:
2287                     ctxt.reraise = False
2288                     LOG.warning('Could not clean up failed build,'
2289                                 ' not rescheduling. Error: %s',
2290                                 six.text_type(exc2))
2291                     raise exception.BuildAbortException(
2292                             instance_uuid=instance.uuid,
2293                             reason=six.text_type(exc))
2294 
2295     def _cleanup_allocated_networks(self, context, instance,
2296             requested_networks):
2297         try:
2298             self._deallocate_network(context, instance, requested_networks)
2299         except Exception:
2300             LOG.exception('Failed to deallocate networks', instance=instance)
2301             return
2302 
2303         instance.system_metadata['network_allocated'] = 'False'
2304         try:
2305             instance.save()
2306         except exception.InstanceNotFound:
2307             # NOTE(alaski): It's possible that we're cleaning up the networks
2308             # because the instance was deleted.  If that's the case then this
2309             # exception will be raised by instance.save()
2310             pass
2311 
2312     def _try_deallocate_network(self, context, instance,
2313                                 requested_networks=None):
2314         try:
2315             # tear down allocated network structure
2316             self._deallocate_network(context, instance, requested_networks)
2317         except Exception as ex:
2318             with excutils.save_and_reraise_exception():
2319                 LOG.error('Failed to deallocate network for instance. '
2320                           'Error: %s', ex, instance=instance)
2321                 self._set_instance_obj_error_state(context, instance)
2322 
2323     def _get_power_off_values(self, context, instance, clean_shutdown):
2324         """Get the timing configuration for powering down this instance."""
2325         if clean_shutdown:
2326             timeout = compute_utils.get_value_from_system_metadata(instance,
2327                           key='image_os_shutdown_timeout', type=int,
2328                           default=CONF.shutdown_timeout)
2329             retry_interval = CONF.compute.shutdown_retry_interval
2330         else:
2331             timeout = 0
2332             retry_interval = 0
2333 
2334         return timeout, retry_interval
2335 
2336     def _power_off_instance(self, context, instance, clean_shutdown=True):
2337         """Power off an instance on this host."""
2338         timeout, retry_interval = self._get_power_off_values(context,
2339                                         instance, clean_shutdown)
2340         self.driver.power_off(instance, timeout, retry_interval)
2341 
2342     def _shutdown_instance(self, context, instance,
2343                            bdms, requested_networks=None, notify=True,
2344                            try_deallocate_networks=True):
2345         """Shutdown an instance on this host.
2346 
2347         :param:context: security context
2348         :param:instance: a nova.objects.Instance object
2349         :param:bdms: the block devices for the instance to be torn
2350                      down
2351         :param:requested_networks: the networks on which the instance
2352                                    has ports
2353         :param:notify: true if a final usage notification should be
2354                        emitted
2355         :param:try_deallocate_networks: false if we should avoid
2356                                         trying to teardown networking
2357         """
2358         context = context.elevated()
2359         LOG.info('Terminating instance', instance=instance)
2360 
2361         if notify:
2362             self._notify_about_instance_usage(context, instance,
2363                                               "shutdown.start")
2364             compute_utils.notify_about_instance_action(context, instance,
2365                     self.host, action=fields.NotificationAction.SHUTDOWN,
2366                     phase=fields.NotificationPhase.START, bdms=bdms)
2367 
2368         network_info = instance.get_network_info()
2369 
2370         # NOTE(vish) get bdms before destroying the instance
2371         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2372         block_device_info = self._get_instance_block_device_info(
2373             context, instance, bdms=bdms)
2374 
2375         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2376         #                want to keep ip allocated for certain failures
2377         try:
2378             LOG.debug('Start destroying the instance on the hypervisor.',
2379                       instance=instance)
2380             with timeutils.StopWatch() as timer:
2381                 self.driver.destroy(context, instance, network_info,
2382                                     block_device_info)
2383             LOG.info('Took %0.2f seconds to destroy the instance on the '
2384                      'hypervisor.', timer.elapsed(), instance=instance)
2385         except exception.InstancePowerOffFailure:
2386             # if the instance can't power off, don't release the ip
2387             with excutils.save_and_reraise_exception():
2388                 pass
2389         except Exception:
2390             with excutils.save_and_reraise_exception():
2391                 # deallocate ip and fail without proceeding to
2392                 # volume api calls, preserving current behavior
2393                 if try_deallocate_networks:
2394                     self._try_deallocate_network(context, instance,
2395                                                  requested_networks)
2396 
2397         if try_deallocate_networks:
2398             self._try_deallocate_network(context, instance, requested_networks)
2399 
2400         timer.restart()
2401         for bdm in vol_bdms:
2402             try:
2403                 if bdm.attachment_id:
2404                     self.volume_api.attachment_delete(context,
2405                                                       bdm.attachment_id)
2406                 else:
2407                     # NOTE(vish): actual driver detach done in driver.destroy,
2408                     #             so just tell cinder that we are done with it.
2409                     connector = self.driver.get_volume_connector(instance)
2410                     self.volume_api.terminate_connection(context,
2411                                                          bdm.volume_id,
2412                                                          connector)
2413                     self.volume_api.detach(context, bdm.volume_id,
2414                                            instance.uuid)
2415 
2416             except exception.VolumeAttachmentNotFound as exc:
2417                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2418                           instance=instance)
2419             except exception.DiskNotFound as exc:
2420                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2421                           instance=instance)
2422             except exception.VolumeNotFound as exc:
2423                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2424                           instance=instance)
2425             except (cinder_exception.EndpointNotFound,
2426                     keystone_exception.EndpointNotFound) as exc:
2427                 LOG.warning('Ignoring EndpointNotFound for '
2428                             'volume %(volume_id)s: %(exc)s',
2429                             {'exc': exc, 'volume_id': bdm.volume_id},
2430                             instance=instance)
2431             except cinder_exception.ClientException as exc:
2432                 LOG.warning('Ignoring unknown cinder exception for '
2433                             'volume %(volume_id)s: %(exc)s',
2434                             {'exc': exc, 'volume_id': bdm.volume_id},
2435                             instance=instance)
2436             except Exception as exc:
2437                 LOG.warning('Ignoring unknown exception for '
2438                             'volume %(volume_id)s: %(exc)s',
2439                             {'exc': exc, 'volume_id': bdm.volume_id},
2440                             instance=instance)
2441         if vol_bdms:
2442             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2443                      'for instance.',
2444                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2445                      instance=instance)
2446 
2447         if notify:
2448             self._notify_about_instance_usage(context, instance,
2449                                               "shutdown.end")
2450             compute_utils.notify_about_instance_action(context, instance,
2451                     self.host, action=fields.NotificationAction.SHUTDOWN,
2452                     phase=fields.NotificationPhase.END, bdms=bdms)
2453 
2454     def _cleanup_volumes(self, context, instance, bdms, raise_exc=True,
2455                          detach=True):
2456         exc_info = None
2457         for bdm in bdms:
2458             if detach and bdm.volume_id:
2459                 try:
2460                     LOG.debug("Detaching volume: %s", bdm.volume_id,
2461                               instance_uuid=instance.uuid)
2462                     destroy = bdm.delete_on_termination
2463                     self._detach_volume(context, bdm, instance,
2464                                         destroy_bdm=destroy)
2465                 except Exception as exc:
2466                     exc_info = sys.exc_info()
2467                     LOG.warning('Failed to detach volume: %(volume_id)s '
2468                                 'due to %(exc)s',
2469                                 {'volume_id': bdm.volume_id, 'exc': exc})
2470 
2471             if bdm.volume_id and bdm.delete_on_termination:
2472                 try:
2473                     LOG.debug("Deleting volume: %s", bdm.volume_id,
2474                               instance_uuid=instance.uuid)
2475                     self.volume_api.delete(context, bdm.volume_id)
2476                 except Exception as exc:
2477                     exc_info = sys.exc_info()
2478                     LOG.warning('Failed to delete volume: %(volume_id)s '
2479                                 'due to %(exc)s',
2480                                 {'volume_id': bdm.volume_id, 'exc': exc})
2481         if exc_info is not None and raise_exc:
2482             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2483 
2484     @hooks.add_hook("delete_instance")
2485     def _delete_instance(self, context, instance, bdms):
2486         """Delete an instance on this host.
2487 
2488         :param context: nova request context
2489         :param instance: nova.objects.instance.Instance object
2490         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2491         """
2492         events = self.instance_events.clear_events_for_instance(instance)
2493         if events:
2494             LOG.debug('Events pending at deletion: %(events)s',
2495                       {'events': ','.join(events.keys())},
2496                       instance=instance)
2497         self._notify_about_instance_usage(context, instance,
2498                                           "delete.start")
2499         compute_utils.notify_about_instance_action(context, instance,
2500                 self.host, action=fields.NotificationAction.DELETE,
2501                 phase=fields.NotificationPhase.START, bdms=bdms)
2502 
2503         self._shutdown_instance(context, instance, bdms)
2504 
2505         # NOTE(vish): We have already deleted the instance, so we have
2506         #             to ignore problems cleaning up the volumes. It
2507         #             would be nice to let the user know somehow that
2508         #             the volume deletion failed, but it is not
2509         #             acceptable to have an instance that can not be
2510         #             deleted. Perhaps this could be reworked in the
2511         #             future to set an instance fault the first time
2512         #             and to only ignore the failure if the instance
2513         #             is already in ERROR.
2514 
2515         # NOTE(ameeda): The volumes already detached during the above
2516         #               _shutdown_instance() call and this is why
2517         #               detach is not requested from _cleanup_volumes()
2518         #               in this case
2519 
2520         self._cleanup_volumes(context, instance, bdms,
2521                 raise_exc=False, detach=False)
2522         # if a delete task succeeded, always update vm state and task
2523         # state without expecting task state to be DELETING
2524         instance.vm_state = vm_states.DELETED
2525         instance.task_state = None
2526         instance.power_state = power_state.NOSTATE
2527         instance.terminated_at = timeutils.utcnow()
2528         instance.save()
2529         instance.destroy()
2530 
2531         self._complete_deletion(context,
2532                                 instance,
2533                                 bdms)
2534 
2535     @wrap_exception()
2536     @reverts_task_state
2537     @wrap_instance_event(prefix='compute')
2538     @wrap_instance_fault
2539     def terminate_instance(self, context, instance, bdms):
2540         """Terminate an instance on this host."""
2541         @utils.synchronized(instance.uuid)
2542         def do_terminate_instance(instance, bdms):
2543             # NOTE(mriedem): If we are deleting the instance while it was
2544             # booting from volume, we could be racing with a database update of
2545             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2546             # to compute here, the BDMs may be stale at this point. So check
2547             # for any volume BDMs that don't have volume_id set and if we
2548             # detect that, we need to refresh the BDM list before proceeding.
2549             # TODO(mriedem): Move this into _delete_instance and make the bdms
2550             # parameter optional.
2551             for bdm in list(bdms):
2552                 if bdm.is_volume and not bdm.volume_id:
2553                     LOG.debug('There are potentially stale BDMs during '
2554                               'delete, refreshing the BlockDeviceMappingList.',
2555                               instance=instance)
2556                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2557                         context, instance.uuid)
2558                     break
2559             try:
2560                 self._delete_instance(context, instance, bdms)
2561             except exception.InstanceNotFound:
2562                 LOG.info("Instance disappeared during terminate",
2563                          instance=instance)
2564             except Exception:
2565                 # As we're trying to delete always go to Error if something
2566                 # goes wrong that _delete_instance can't handle.
2567                 with excutils.save_and_reraise_exception():
2568                     LOG.exception('Setting instance vm_state to ERROR',
2569                                   instance=instance)
2570                     self._set_instance_obj_error_state(context, instance)
2571 
2572         do_terminate_instance(instance, bdms)
2573 
2574     # NOTE(johannes): This is probably better named power_off_instance
2575     # so it matches the driver method, but because of other issues, we
2576     # can't use that name in grizzly.
2577     @wrap_exception()
2578     @reverts_task_state
2579     @wrap_instance_event(prefix='compute')
2580     @wrap_instance_fault
2581     def stop_instance(self, context, instance, clean_shutdown):
2582         """Stopping an instance on this host."""
2583 
2584         @utils.synchronized(instance.uuid)
2585         def do_stop_instance():
2586             current_power_state = self._get_power_state(context, instance)
2587             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2588                       'current task_state: %(task_state)s, current DB '
2589                       'power_state: %(db_power_state)s, current VM '
2590                       'power_state: %(current_power_state)s',
2591                       {'vm_state': instance.vm_state,
2592                        'task_state': instance.task_state,
2593                        'db_power_state': instance.power_state,
2594                        'current_power_state': current_power_state},
2595                       instance_uuid=instance.uuid)
2596 
2597             # NOTE(mriedem): If the instance is already powered off, we are
2598             # possibly tearing down and racing with other operations, so we can
2599             # expect the task_state to be None if something else updates the
2600             # instance and we're not locking it.
2601             expected_task_state = [task_states.POWERING_OFF]
2602             # The list of power states is from _sync_instance_power_state.
2603             if current_power_state in (power_state.NOSTATE,
2604                                        power_state.SHUTDOWN,
2605                                        power_state.CRASHED):
2606                 LOG.info('Instance is already powered off in the '
2607                          'hypervisor when stop is called.',
2608                          instance=instance)
2609                 expected_task_state.append(None)
2610 
2611             self._notify_about_instance_usage(context, instance,
2612                                               "power_off.start")
2613 
2614             compute_utils.notify_about_instance_action(context, instance,
2615                         self.host, action=fields.NotificationAction.POWER_OFF,
2616                         phase=fields.NotificationPhase.START)
2617 
2618             self._power_off_instance(context, instance, clean_shutdown)
2619             instance.power_state = self._get_power_state(context, instance)
2620             instance.vm_state = vm_states.STOPPED
2621             instance.task_state = None
2622             instance.save(expected_task_state=expected_task_state)
2623             self._notify_about_instance_usage(context, instance,
2624                                               "power_off.end")
2625 
2626             compute_utils.notify_about_instance_action(context, instance,
2627                         self.host, action=fields.NotificationAction.POWER_OFF,
2628                         phase=fields.NotificationPhase.END)
2629 
2630         do_stop_instance()
2631 
2632     def _power_on(self, context, instance):
2633         network_info = self.network_api.get_instance_nw_info(context, instance)
2634         block_device_info = self._get_instance_block_device_info(context,
2635                                                                  instance)
2636         self.driver.power_on(context, instance,
2637                              network_info,
2638                              block_device_info)
2639 
2640     def _delete_snapshot_of_shelved_instance(self, context, instance,
2641                                              snapshot_id):
2642         """Delete snapshot of shelved instance."""
2643         try:
2644             self.image_api.delete(context, snapshot_id)
2645         except (exception.ImageNotFound,
2646                 exception.ImageNotAuthorized) as exc:
2647             LOG.warning("Failed to delete snapshot "
2648                         "from shelved instance (%s).",
2649                         exc.format_message(), instance=instance)
2650         except Exception:
2651             LOG.exception("Something wrong happened when trying to "
2652                           "delete snapshot from shelved instance.",
2653                           instance=instance)
2654 
2655     # NOTE(johannes): This is probably better named power_on_instance
2656     # so it matches the driver method, but because of other issues, we
2657     # can't use that name in grizzly.
2658     @wrap_exception()
2659     @reverts_task_state
2660     @wrap_instance_event(prefix='compute')
2661     @wrap_instance_fault
2662     def start_instance(self, context, instance):
2663         """Starting an instance on this host."""
2664         self._notify_about_instance_usage(context, instance, "power_on.start")
2665         compute_utils.notify_about_instance_action(context, instance,
2666             self.host, action=fields.NotificationAction.POWER_ON,
2667             phase=fields.NotificationPhase.START)
2668         self._power_on(context, instance)
2669         instance.power_state = self._get_power_state(context, instance)
2670         instance.vm_state = vm_states.ACTIVE
2671         instance.task_state = None
2672 
2673         # Delete an image(VM snapshot) for a shelved instance
2674         snapshot_id = instance.system_metadata.get('shelved_image_id')
2675         if snapshot_id:
2676             self._delete_snapshot_of_shelved_instance(context, instance,
2677                                                       snapshot_id)
2678 
2679         # Delete system_metadata for a shelved instance
2680         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2681 
2682         instance.save(expected_task_state=task_states.POWERING_ON)
2683         self._notify_about_instance_usage(context, instance, "power_on.end")
2684         compute_utils.notify_about_instance_action(context, instance,
2685             self.host, action=fields.NotificationAction.POWER_ON,
2686             phase=fields.NotificationPhase.END)
2687 
2688     @messaging.expected_exceptions(NotImplementedError,
2689                                    exception.TriggerCrashDumpNotSupported,
2690                                    exception.InstanceNotRunning)
2691     @wrap_exception()
2692     @wrap_instance_event(prefix='compute')
2693     @wrap_instance_fault
2694     def trigger_crash_dump(self, context, instance):
2695         """Trigger crash dump in an instance."""
2696 
2697         self._notify_about_instance_usage(context, instance,
2698                                           "trigger_crash_dump.start")
2699         compute_utils.notify_about_instance_action(context, instance,
2700                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2701                 phase=fields.NotificationPhase.START)
2702 
2703         # This method does not change task_state and power_state because the
2704         # effect of a trigger depends on user's configuration.
2705         self.driver.trigger_crash_dump(instance)
2706 
2707         self._notify_about_instance_usage(context, instance,
2708                                           "trigger_crash_dump.end")
2709         compute_utils.notify_about_instance_action(context, instance,
2710                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2711                 phase=fields.NotificationPhase.END)
2712 
2713     @wrap_exception()
2714     @reverts_task_state
2715     @wrap_instance_event(prefix='compute')
2716     @wrap_instance_fault
2717     def soft_delete_instance(self, context, instance):
2718         """Soft delete an instance on this host."""
2719         with compute_utils.notify_about_instance_delete(
2720                 self.notifier, context, instance, 'soft_delete'):
2721             compute_utils.notify_about_instance_action(context, instance,
2722                 self.host, action=fields.NotificationAction.SOFT_DELETE,
2723                 phase=fields.NotificationPhase.START)
2724             try:
2725                 self.driver.soft_delete(instance)
2726             except NotImplementedError:
2727                 # Fallback to just powering off the instance if the
2728                 # hypervisor doesn't implement the soft_delete method
2729                 self.driver.power_off(instance)
2730             instance.power_state = self._get_power_state(context, instance)
2731             instance.vm_state = vm_states.SOFT_DELETED
2732             instance.task_state = None
2733             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2734             compute_utils.notify_about_instance_action(
2735                 context, instance, self.host,
2736                 action=fields.NotificationAction.SOFT_DELETE,
2737                 phase=fields.NotificationPhase.END)
2738 
2739     @wrap_exception()
2740     @reverts_task_state
2741     @wrap_instance_event(prefix='compute')
2742     @wrap_instance_fault
2743     def restore_instance(self, context, instance):
2744         """Restore a soft-deleted instance on this host."""
2745         self._notify_about_instance_usage(context, instance, "restore.start")
2746         compute_utils.notify_about_instance_action(context, instance,
2747             self.host, action=fields.NotificationAction.RESTORE,
2748             phase=fields.NotificationPhase.START)
2749         try:
2750             self.driver.restore(instance)
2751         except NotImplementedError:
2752             # Fallback to just powering on the instance if the hypervisor
2753             # doesn't implement the restore method
2754             self._power_on(context, instance)
2755         instance.power_state = self._get_power_state(context, instance)
2756         instance.vm_state = vm_states.ACTIVE
2757         instance.task_state = None
2758         instance.save(expected_task_state=task_states.RESTORING)
2759         self._notify_about_instance_usage(context, instance, "restore.end")
2760         compute_utils.notify_about_instance_action(context, instance,
2761             self.host, action=fields.NotificationAction.RESTORE,
2762             phase=fields.NotificationPhase.END)
2763 
2764     @staticmethod
2765     def _set_migration_status(migration, status):
2766         """Set the status, and guard against a None being passed in.
2767 
2768         This is useful as some of the compute RPC calls will not pass
2769         a migration object in older versions. The check can be removed when
2770         we move past 4.x major version of the RPC API.
2771         """
2772         if migration:
2773             migration.status = status
2774             migration.save()
2775 
2776     def _rebuild_default_impl(self, context, instance, image_meta,
2777                               injected_files, admin_password, allocations,
2778                               bdms, detach_block_devices, attach_block_devices,
2779                               network_info=None,
2780                               recreate=False, block_device_info=None,
2781                               preserve_ephemeral=False):
2782         if preserve_ephemeral:
2783             # The default code path does not support preserving ephemeral
2784             # partitions.
2785             raise exception.PreserveEphemeralNotSupported()
2786 
2787         if recreate:
2788             detach_block_devices(context, bdms)
2789         else:
2790             self._power_off_instance(context, instance, clean_shutdown=True)
2791             detach_block_devices(context, bdms)
2792             self.driver.destroy(context, instance,
2793                                 network_info=network_info,
2794                                 block_device_info=block_device_info)
2795 
2796         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2797         instance.save(expected_task_state=[task_states.REBUILDING])
2798 
2799         new_block_device_info = attach_block_devices(context, instance, bdms)
2800 
2801         instance.task_state = task_states.REBUILD_SPAWNING
2802         instance.save(
2803             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2804 
2805         with instance.mutated_migration_context():
2806             self.driver.spawn(context, instance, image_meta, injected_files,
2807                               admin_password, allocations,
2808                               network_info=network_info,
2809                               block_device_info=new_block_device_info)
2810 
2811     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
2812         self._notify_about_instance_usage(context, instance,
2813                                           'rebuild.error', fault=error)
2814         compute_utils.notify_about_instance_action(
2815             context, instance, self.host,
2816             action=fields.NotificationAction.REBUILD,
2817             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms)
2818 
2819     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2820     @wrap_exception()
2821     @reverts_task_state
2822     @wrap_instance_event(prefix='compute')
2823     @wrap_instance_fault
2824     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2825                          injected_files, new_pass, orig_sys_metadata,
2826                          bdms, recreate, on_shared_storage,
2827                          preserve_ephemeral, migration,
2828                          scheduled_node, limits, request_spec):
2829         """Destroy and re-make this instance.
2830 
2831         A 'rebuild' effectively purges all existing data from the system and
2832         remakes the VM with given 'metadata' and 'personalities'.
2833 
2834         :param context: `nova.RequestContext` object
2835         :param instance: Instance object
2836         :param orig_image_ref: Original image_ref before rebuild
2837         :param image_ref: New image_ref for rebuild
2838         :param injected_files: Files to inject
2839         :param new_pass: password to set on rebuilt instance
2840         :param orig_sys_metadata: instance system metadata from pre-rebuild
2841         :param bdms: block-device-mappings to use for rebuild
2842         :param recreate: True if the instance is being recreated (e.g. the
2843             hypervisor it was on failed) - cleanup of old state will be
2844             skipped.
2845         :param on_shared_storage: True if instance files on shared storage.
2846                                   If not provided then information from the
2847                                   driver will be used to decide if the instance
2848                                   files are available or not on the target host
2849         :param preserve_ephemeral: True if the default ephemeral storage
2850                                    partition must be preserved on rebuild
2851         :param migration: a Migration object if one was created for this
2852                           rebuild operation (if it's a part of evacuate)
2853         :param scheduled_node: A node of the host chosen by the scheduler. If a
2854                                host was specified by the user, this will be
2855                                None
2856         :param limits: Overcommit limits set by the scheduler. If a host was
2857                        specified by the user, this will be None
2858         :param request_spec: a RequestSpec object used to schedule the instance
2859 
2860         """
2861         # recreate=True means the instance is being evacuated from a failed
2862         # host to a new destination host (this host). The 'recreate' variable
2863         # name is confusing, so rename it to evacuate here at the top, which
2864         # is simpler than renaming a parameter in an RPC versioned method.
2865         evacuate = recreate
2866         context = context.elevated()
2867 
2868         if evacuate:
2869             LOG.info("Evacuating instance", instance=instance)
2870         else:
2871             LOG.info("Rebuilding instance", instance=instance)
2872 
2873         rt = self._get_resource_tracker()
2874         if evacuate:
2875             # This is an evacuation to a new host, so we need to perform a
2876             # resource claim.
2877             rebuild_claim = rt.rebuild_claim
2878         else:
2879             # This is a rebuild to the same host, so we don't need to make
2880             # a claim since the instance is already on this host.
2881             rebuild_claim = claims.NopClaim
2882 
2883         image_meta = {}
2884         if image_ref:
2885             image_meta = self.image_api.get(context, image_ref)
2886 
2887         # NOTE(mriedem): On an evacuate, we need to update
2888         # the instance's host and node properties to reflect it's
2889         # destination node for the evacuate.
2890         if not scheduled_node:
2891             if evacuate:
2892                 try:
2893                     compute_node = self._get_compute_info(context, self.host)
2894                     scheduled_node = compute_node.hypervisor_hostname
2895                 except exception.ComputeHostNotFound:
2896                     LOG.exception('Failed to get compute_info for %s',
2897                                   self.host)
2898             else:
2899                 scheduled_node = instance.node
2900 
2901         with self._error_out_instance_on_exception(context, instance):
2902             try:
2903                 claim_ctxt = rebuild_claim(
2904                     context, instance, scheduled_node,
2905                     limits=limits, image_meta=image_meta,
2906                     migration=migration)
2907                 self._do_rebuild_instance_with_claim(
2908                     claim_ctxt, context, instance, orig_image_ref,
2909                     image_ref, injected_files, new_pass, orig_sys_metadata,
2910                     bdms, evacuate, on_shared_storage, preserve_ephemeral,
2911                     migration, request_spec)
2912             except (exception.ComputeResourcesUnavailable,
2913                     exception.RescheduledException) as e:
2914                 if isinstance(e, exception.ComputeResourcesUnavailable):
2915                     LOG.debug("Could not rebuild instance on this host, not "
2916                               "enough resources available.", instance=instance)
2917                 else:
2918                     # RescheduledException is raised by the late server group
2919                     # policy check during evacuation if a parallel scheduling
2920                     # violated the policy.
2921                     # We catch the RescheduledException here but we don't have
2922                     # the plumbing to do an actual reschedule so we abort the
2923                     # operation.
2924                     LOG.debug("Could not rebuild instance on this host, "
2925                               "late server group check failed.",
2926                               instance=instance)
2927                 # NOTE(ndipanov): We just abort the build for now and leave a
2928                 # migration record for potential cleanup later
2929                 self._set_migration_status(migration, 'failed')
2930                 # Since the claim failed, we need to remove the allocation
2931                 # created against the destination node. Note that we can only
2932                 # get here when evacuating to a destination node. Rebuilding
2933                 # on the same host (not evacuate) uses the NopClaim which will
2934                 # not raise ComputeResourcesUnavailable.
2935                 rt.delete_allocation_for_evacuated_instance(
2936                     context, instance, scheduled_node, node_type='destination')
2937                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2938                 raise exception.BuildAbortException(
2939                     instance_uuid=instance.uuid, reason=e.format_message())
2940             except (exception.InstanceNotFound,
2941                     exception.UnexpectedDeletingTaskStateError) as e:
2942                 LOG.debug('Instance was deleted while rebuilding',
2943                           instance=instance)
2944                 self._set_migration_status(migration, 'failed')
2945                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2946             except Exception as e:
2947                 self._set_migration_status(migration, 'failed')
2948                 if evacuate or scheduled_node is not None:
2949                     rt.delete_allocation_for_evacuated_instance(
2950                         context, instance, scheduled_node,
2951                         node_type='destination')
2952                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2953                 raise
2954             else:
2955                 instance.apply_migration_context()
2956                 # NOTE (ndipanov): This save will now update the host and node
2957                 # attributes making sure that next RT pass is consistent since
2958                 # it will be based on the instance and not the migration DB
2959                 # entry.
2960                 instance.host = self.host
2961                 instance.node = scheduled_node
2962                 instance.save()
2963                 instance.drop_migration_context()
2964 
2965                 # NOTE (ndipanov): Mark the migration as done only after we
2966                 # mark the instance as belonging to this host.
2967                 self._set_migration_status(migration, 'done')
2968 
2969     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2970         """Helper to avoid deep nesting in the top-level method."""
2971 
2972         with claim_context:
2973             self._do_rebuild_instance(*args, **kwargs)
2974 
2975     @staticmethod
2976     def _get_image_name(image_meta):
2977         if image_meta.obj_attr_is_set("name"):
2978             return image_meta.name
2979         else:
2980             return ''
2981 
2982     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2983                              image_ref, injected_files, new_pass,
2984                              orig_sys_metadata, bdms, evacuate,
2985                              on_shared_storage, preserve_ephemeral,
2986                              migration, request_spec):
2987         orig_vm_state = instance.vm_state
2988 
2989         if evacuate:
2990             if request_spec:
2991                 # NOTE(gibi): Do a late check of server group policy as
2992                 # parallel scheduling could violate such policy. This will
2993                 # cause the evacuate to fail as rebuild does not implement
2994                 # reschedule.
2995                 hints = self._get_scheduler_hints({}, request_spec)
2996                 self._validate_instance_group_policy(context, instance, hints)
2997 
2998             # TODO(mriedem): Rename the supports_recreate driver capability
2999             # to supports_evacuate.
3000             if not self.driver.capabilities.get("supports_recreate", False):
3001                 raise exception.InstanceRecreateNotSupported
3002 
3003             self._check_instance_exists(context, instance)
3004 
3005             if on_shared_storage is None:
3006                 LOG.debug('on_shared_storage is not provided, using driver '
3007                           'information to decide if the instance needs to '
3008                           'be evacuated')
3009                 on_shared_storage = self.driver.instance_on_disk(instance)
3010 
3011             elif (on_shared_storage !=
3012                     self.driver.instance_on_disk(instance)):
3013                 # To cover case when admin expects that instance files are
3014                 # on shared storage, but not accessible and vice versa
3015                 raise exception.InvalidSharedStorage(
3016                         _("Invalid state of instance files on shared"
3017                             " storage"))
3018 
3019             if on_shared_storage:
3020                 LOG.info('disk on shared storage, evacuating using'
3021                          ' existing disk')
3022             else:
3023                 image_ref = orig_image_ref = instance.image_ref
3024                 LOG.info("disk not on shared storage, evacuating from:"
3025                          " '%s'", str(image_ref))
3026 
3027         if image_ref:
3028             image_meta = objects.ImageMeta.from_image_ref(
3029                 context, self.image_api, image_ref)
3030         else:
3031             image_meta = instance.image_meta
3032 
3033         # This instance.exists message should contain the original
3034         # image_ref, not the new one.  Since the DB has been updated
3035         # to point to the new one... we have to override it.
3036         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
3037                                                                context)
3038         extra_usage_info = {'image_ref_url': orig_image_ref_url}
3039         compute_utils.notify_usage_exists(
3040                 self.notifier, context, instance,
3041                 current_period=True, system_metadata=orig_sys_metadata,
3042                 extra_usage_info=extra_usage_info)
3043 
3044         # This message should contain the new image_ref
3045         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
3046         self._notify_about_instance_usage(context, instance,
3047                 "rebuild.start", extra_usage_info=extra_usage_info)
3048         # NOTE: image_name is not included in the versioned notification
3049         # because we already provide the image_uuid in the notification
3050         # payload and the image details can be looked up via the uuid.
3051         compute_utils.notify_about_instance_action(
3052             context, instance, self.host,
3053             action=fields.NotificationAction.REBUILD,
3054             phase=fields.NotificationPhase.START,
3055             bdms=bdms)
3056 
3057         instance.power_state = self._get_power_state(context, instance)
3058         instance.task_state = task_states.REBUILDING
3059         instance.save(expected_task_state=[task_states.REBUILDING])
3060 
3061         if evacuate:
3062             self.network_api.setup_networks_on_host(
3063                     context, instance, self.host)
3064             # For nova-network this is needed to move floating IPs
3065             # For neutron this updates the host in the port binding
3066             # TODO(cfriesen): this network_api call and the one above
3067             # are so similar, we should really try to unify them.
3068             self.network_api.setup_instance_network_on_host(
3069                     context, instance, self.host, migration)
3070 
3071         allocations = self.reportclient.get_allocations_for_consumer(
3072             context, instance.uuid)
3073 
3074         network_info = instance.get_network_info()
3075         if bdms is None:
3076             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3077                     context, instance.uuid)
3078 
3079         block_device_info = \
3080             self._get_instance_block_device_info(
3081                     context, instance, bdms=bdms)
3082 
3083         def detach_block_devices(context, bdms):
3084             for bdm in bdms:
3085                 if bdm.is_volume:
3086                     # NOTE (ildikov): Having the attachment_id set in the BDM
3087                     # means that it's the new Cinder attach/detach flow
3088                     # (available from v3.44). In that case we explicitly
3089                     # attach and detach the volumes through attachment level
3090                     # operations. In this scenario _detach_volume will delete
3091                     # the existing attachment which would make the volume
3092                     # status change to 'available' if we don't pre-create
3093                     # another empty attachment before deleting the old one.
3094                     attachment_id = None
3095                     if bdm.attachment_id:
3096                         attachment_id = self.volume_api.attachment_create(
3097                             context, bdm['volume_id'], instance.uuid)['id']
3098                     self._detach_volume(context, bdm, instance,
3099                                         destroy_bdm=False)
3100                     if attachment_id:
3101                         bdm.attachment_id = attachment_id
3102                         bdm.save()
3103 
3104         files = self._decode_files(injected_files)
3105 
3106         # TODO(mriedem): Rename recreate->evacuate in the driver rebuild
3107         # method signature.
3108         kwargs = dict(
3109             context=context,
3110             instance=instance,
3111             image_meta=image_meta,
3112             injected_files=files,
3113             admin_password=new_pass,
3114             allocations=allocations,
3115             bdms=bdms,
3116             detach_block_devices=detach_block_devices,
3117             attach_block_devices=self._prep_block_device,
3118             block_device_info=block_device_info,
3119             network_info=network_info,
3120             preserve_ephemeral=preserve_ephemeral,
3121             recreate=evacuate)
3122         try:
3123             with instance.mutated_migration_context():
3124                 self.driver.rebuild(**kwargs)
3125         except NotImplementedError:
3126             # NOTE(rpodolyaka): driver doesn't provide specialized version
3127             # of rebuild, fall back to the default implementation
3128             self._rebuild_default_impl(**kwargs)
3129         self._update_instance_after_spawn(context, instance)
3130         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3131 
3132         if orig_vm_state == vm_states.STOPPED:
3133             LOG.info("bringing vm to original state: '%s'",
3134                      orig_vm_state, instance=instance)
3135             instance.vm_state = vm_states.ACTIVE
3136             instance.task_state = task_states.POWERING_OFF
3137             instance.progress = 0
3138             instance.save()
3139             self.stop_instance(context, instance, False)
3140         # TODO(melwitt): We should clean up instance console tokens here in the
3141         # case of evacuate. The instance is on a new host and will need to
3142         # establish a new console connection.
3143         self._update_scheduler_instance_info(context, instance)
3144         self._notify_about_instance_usage(
3145                 context, instance, "rebuild.end",
3146                 network_info=network_info,
3147                 extra_usage_info=extra_usage_info)
3148         compute_utils.notify_about_instance_action(
3149             context, instance, self.host,
3150             action=fields.NotificationAction.REBUILD,
3151             phase=fields.NotificationPhase.END,
3152             bdms=bdms)
3153 
3154     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3155                                      block_device_info):
3156         """Handle cases where the virt-layer had to detach non-working volumes
3157         in order to complete an operation.
3158         """
3159         for bdm in block_device_info['block_device_mapping']:
3160             if bdm.get('mount_device') in bad_devices:
3161                 try:
3162                     volume_id = bdm['connection_info']['data']['volume_id']
3163                 except KeyError:
3164                     continue
3165 
3166                 # NOTE(sirp): ideally we'd just call
3167                 # `compute_api.detach_volume` here but since that hits the
3168                 # DB directly, that's off limits from within the
3169                 # compute-manager.
3170                 #
3171                 # API-detach
3172                 LOG.info("Detaching from volume api: %s", volume_id)
3173                 self.volume_api.begin_detaching(context, volume_id)
3174 
3175                 # Manager-detach
3176                 self.detach_volume(context, volume_id, instance)
3177 
3178     @wrap_exception()
3179     @reverts_task_state
3180     @wrap_instance_event(prefix='compute')
3181     @wrap_instance_fault
3182     def reboot_instance(self, context, instance, block_device_info,
3183                         reboot_type):
3184         """Reboot an instance on this host."""
3185         # acknowledge the request made it to the manager
3186         if reboot_type == "SOFT":
3187             instance.task_state = task_states.REBOOT_PENDING
3188             expected_states = task_states.soft_reboot_states
3189         else:
3190             instance.task_state = task_states.REBOOT_PENDING_HARD
3191             expected_states = task_states.hard_reboot_states
3192 
3193         context = context.elevated()
3194         LOG.info("Rebooting instance", instance=instance)
3195 
3196         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3197             context, instance.uuid)
3198         block_device_info = self._get_instance_block_device_info(
3199             context, instance, bdms=bdms)
3200 
3201         network_info = self.network_api.get_instance_nw_info(context, instance)
3202 
3203         self._notify_about_instance_usage(context, instance, "reboot.start")
3204         compute_utils.notify_about_instance_action(
3205             context, instance, self.host,
3206             action=fields.NotificationAction.REBOOT,
3207             phase=fields.NotificationPhase.START,
3208             bdms=bdms
3209         )
3210 
3211         instance.power_state = self._get_power_state(context, instance)
3212         instance.save(expected_task_state=expected_states)
3213 
3214         if instance.power_state != power_state.RUNNING:
3215             state = instance.power_state
3216             running = power_state.RUNNING
3217             LOG.warning('trying to reboot a non-running instance:'
3218                         ' (state: %(state)s expected: %(running)s)',
3219                         {'state': state, 'running': running},
3220                         instance=instance)
3221 
3222         def bad_volumes_callback(bad_devices):
3223             self._handle_bad_volumes_detached(
3224                     context, instance, bad_devices, block_device_info)
3225 
3226         try:
3227             # Don't change it out of rescue mode
3228             if instance.vm_state == vm_states.RESCUED:
3229                 new_vm_state = vm_states.RESCUED
3230             else:
3231                 new_vm_state = vm_states.ACTIVE
3232             new_power_state = None
3233             if reboot_type == "SOFT":
3234                 instance.task_state = task_states.REBOOT_STARTED
3235                 expected_state = task_states.REBOOT_PENDING
3236             else:
3237                 instance.task_state = task_states.REBOOT_STARTED_HARD
3238                 expected_state = task_states.REBOOT_PENDING_HARD
3239             instance.save(expected_task_state=expected_state)
3240             self.driver.reboot(context, instance,
3241                                network_info,
3242                                reboot_type,
3243                                block_device_info=block_device_info,
3244                                bad_volumes_callback=bad_volumes_callback)
3245 
3246         except Exception as error:
3247             with excutils.save_and_reraise_exception() as ctxt:
3248                 exc_info = sys.exc_info()
3249                 # if the reboot failed but the VM is running don't
3250                 # put it into an error state
3251                 new_power_state = self._get_power_state(context, instance)
3252                 if new_power_state == power_state.RUNNING:
3253                     LOG.warning('Reboot failed but instance is running',
3254                                 instance=instance)
3255                     compute_utils.add_instance_fault_from_exc(context,
3256                             instance, error, exc_info)
3257                     self._notify_about_instance_usage(context, instance,
3258                             'reboot.error', fault=error)
3259                     compute_utils.notify_about_instance_action(
3260                         context, instance, self.host,
3261                         action=fields.NotificationAction.REBOOT,
3262                         phase=fields.NotificationPhase.ERROR,
3263                         exception=error, bdms=bdms
3264                     )
3265                     ctxt.reraise = False
3266                 else:
3267                     LOG.error('Cannot reboot instance: %s', error,
3268                               instance=instance)
3269                     self._set_instance_obj_error_state(context, instance)
3270 
3271         if not new_power_state:
3272             new_power_state = self._get_power_state(context, instance)
3273         try:
3274             instance.power_state = new_power_state
3275             instance.vm_state = new_vm_state
3276             instance.task_state = None
3277             instance.save()
3278         except exception.InstanceNotFound:
3279             LOG.warning("Instance disappeared during reboot",
3280                         instance=instance)
3281 
3282         self._notify_about_instance_usage(context, instance, "reboot.end")
3283         compute_utils.notify_about_instance_action(
3284             context, instance, self.host,
3285             action=fields.NotificationAction.REBOOT,
3286             phase=fields.NotificationPhase.END,
3287             bdms=bdms
3288         )
3289 
3290     @delete_image_on_error
3291     def _do_snapshot_instance(self, context, image_id, instance):
3292         self._snapshot_instance(context, image_id, instance,
3293                                 task_states.IMAGE_BACKUP)
3294 
3295     @wrap_exception()
3296     @reverts_task_state
3297     @wrap_instance_event(prefix='compute')
3298     @wrap_instance_fault
3299     def backup_instance(self, context, image_id, instance, backup_type,
3300                         rotation):
3301         """Backup an instance on this host.
3302 
3303         :param backup_type: daily | weekly
3304         :param rotation: int representing how many backups to keep around
3305         """
3306         self._do_snapshot_instance(context, image_id, instance)
3307         self._rotate_backups(context, instance, backup_type, rotation)
3308 
3309     @wrap_exception()
3310     @reverts_task_state
3311     @wrap_instance_event(prefix='compute')
3312     @wrap_instance_fault
3313     @delete_image_on_error
3314     def snapshot_instance(self, context, image_id, instance):
3315         """Snapshot an instance on this host.
3316 
3317         :param context: security context
3318         :param image_id: glance.db.sqlalchemy.models.Image.Id
3319         :param instance: a nova.objects.instance.Instance object
3320         """
3321         # NOTE(dave-mcnally) the task state will already be set by the api
3322         # but if the compute manager has crashed/been restarted prior to the
3323         # request getting here the task state may have been cleared so we set
3324         # it again and things continue normally
3325         try:
3326             instance.task_state = task_states.IMAGE_SNAPSHOT
3327             instance.save(
3328                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3329         except exception.InstanceNotFound:
3330             # possibility instance no longer exists, no point in continuing
3331             LOG.debug("Instance not found, could not set state %s "
3332                       "for instance.",
3333                       task_states.IMAGE_SNAPSHOT, instance=instance)
3334             return
3335 
3336         except exception.UnexpectedDeletingTaskStateError:
3337             LOG.debug("Instance being deleted, snapshot cannot continue",
3338                       instance=instance)
3339             return
3340 
3341         self._snapshot_instance(context, image_id, instance,
3342                                 task_states.IMAGE_SNAPSHOT)
3343 
3344     def _snapshot_instance(self, context, image_id, instance,
3345                            expected_task_state):
3346         context = context.elevated()
3347 
3348         instance.power_state = self._get_power_state(context, instance)
3349         try:
3350             instance.save()
3351 
3352             LOG.info('instance snapshotting', instance=instance)
3353 
3354             if instance.power_state != power_state.RUNNING:
3355                 state = instance.power_state
3356                 running = power_state.RUNNING
3357                 LOG.warning('trying to snapshot a non-running instance: '
3358                             '(state: %(state)s expected: %(running)s)',
3359                             {'state': state, 'running': running},
3360                             instance=instance)
3361 
3362             self._notify_about_instance_usage(
3363                 context, instance, "snapshot.start")
3364             compute_utils.notify_about_instance_snapshot(context, instance,
3365                 self.host, phase=fields.NotificationPhase.START,
3366                 snapshot_image_id=image_id)
3367 
3368             def update_task_state(task_state,
3369                                   expected_state=expected_task_state):
3370                 instance.task_state = task_state
3371                 instance.save(expected_task_state=expected_state)
3372 
3373             with timeutils.StopWatch() as timer:
3374                 self.driver.snapshot(context, instance, image_id,
3375                                      update_task_state)
3376             LOG.info('Took %0.2f seconds to snapshot the instance on '
3377                      'the hypervisor.', timer.elapsed(), instance=instance)
3378 
3379             instance.task_state = None
3380             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3381 
3382             self._notify_about_instance_usage(context, instance,
3383                                               "snapshot.end")
3384             compute_utils.notify_about_instance_snapshot(context, instance,
3385                 self.host, phase=fields.NotificationPhase.END,
3386                 snapshot_image_id=image_id)
3387         except (exception.InstanceNotFound,
3388                 exception.UnexpectedDeletingTaskStateError):
3389             # the instance got deleted during the snapshot
3390             # Quickly bail out of here
3391             msg = 'Instance disappeared during snapshot'
3392             LOG.debug(msg, instance=instance)
3393             try:
3394                 image = self.image_api.get(context, image_id)
3395                 if image['status'] != 'active':
3396                     self.image_api.delete(context, image_id)
3397             except exception.ImageNotFound:
3398                 LOG.debug('Image not found during clean up %s', image_id)
3399             except Exception:
3400                 LOG.warning("Error while trying to clean up image %s",
3401                             image_id, instance=instance)
3402         except exception.ImageNotFound:
3403             instance.task_state = None
3404             instance.save()
3405             LOG.warning("Image not found during snapshot", instance=instance)
3406 
3407     def _post_interrupted_snapshot_cleanup(self, context, instance):
3408         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3409 
3410     @messaging.expected_exceptions(NotImplementedError)
3411     @wrap_exception()
3412     def volume_snapshot_create(self, context, instance, volume_id,
3413                                create_info):
3414         self.driver.volume_snapshot_create(context, instance, volume_id,
3415                                            create_info)
3416 
3417     @messaging.expected_exceptions(NotImplementedError)
3418     @wrap_exception()
3419     def volume_snapshot_delete(self, context, instance, volume_id,
3420                                snapshot_id, delete_info):
3421         self.driver.volume_snapshot_delete(context, instance, volume_id,
3422                                            snapshot_id, delete_info)
3423 
3424     @wrap_instance_fault
3425     def _rotate_backups(self, context, instance, backup_type, rotation):
3426         """Delete excess backups associated to an instance.
3427 
3428         Instances are allowed a fixed number of backups (the rotation number);
3429         this method deletes the oldest backups that exceed the rotation
3430         threshold.
3431 
3432         :param context: security context
3433         :param instance: Instance dict
3434         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3435         :param rotation: int representing how many backups to keep around;
3436             None if rotation shouldn't be used (as in the case of snapshots)
3437         """
3438         filters = {'property-image_type': 'backup',
3439                    'property-backup_type': backup_type,
3440                    'property-instance_uuid': instance.uuid}
3441 
3442         images = self.image_api.get_all(context, filters=filters,
3443                                         sort_key='created_at', sort_dir='desc')
3444         num_images = len(images)
3445         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3446                   {'num_images': num_images, 'rotation': rotation},
3447                   instance=instance)
3448 
3449         if num_images > rotation:
3450             # NOTE(sirp): this deletes all backups that exceed the rotation
3451             # limit
3452             excess = len(images) - rotation
3453             LOG.debug("Rotating out %d backups", excess,
3454                       instance=instance)
3455             for i in range(excess):
3456                 image = images.pop()
3457                 image_id = image['id']
3458                 LOG.debug("Deleting image %s", image_id,
3459                           instance=instance)
3460                 try:
3461                     self.image_api.delete(context, image_id)
3462                 except exception.ImageNotFound:
3463                     LOG.info("Failed to find image %(image_id)s to "
3464                              "delete", {'image_id': image_id},
3465                              instance=instance)
3466                 except (exception.ImageDeleteConflict, Exception) as exc:
3467                     LOG.info("Failed to delete image %(image_id)s during "
3468                              "deleting excess backups. "
3469                              "Continuing for next image.. %(exc)s",
3470                              {'image_id': image_id, 'exc': exc},
3471                              instance=instance)
3472 
3473     @wrap_exception()
3474     @reverts_task_state
3475     @wrap_instance_event(prefix='compute')
3476     @wrap_instance_fault
3477     def set_admin_password(self, context, instance, new_pass):
3478         """Set the root/admin password for an instance on this host.
3479 
3480         This is generally only called by API password resets after an
3481         image has been built.
3482 
3483         @param context: Nova auth context.
3484         @param instance: Nova instance object.
3485         @param new_pass: The admin password for the instance.
3486         """
3487 
3488         context = context.elevated()
3489         if new_pass is None:
3490             # Generate a random password
3491             new_pass = utils.generate_password()
3492 
3493         current_power_state = self._get_power_state(context, instance)
3494         expected_state = power_state.RUNNING
3495 
3496         if current_power_state != expected_state:
3497             instance.task_state = None
3498             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3499             _msg = _('instance %s is not running') % instance.uuid
3500             raise exception.InstancePasswordSetFailed(
3501                 instance=instance.uuid, reason=_msg)
3502 
3503         try:
3504             self.driver.set_admin_password(instance, new_pass)
3505             LOG.info("Admin password set", instance=instance)
3506             instance.task_state = None
3507             instance.save(
3508                 expected_task_state=task_states.UPDATING_PASSWORD)
3509         except exception.InstanceAgentNotEnabled:
3510             with excutils.save_and_reraise_exception():
3511                 LOG.debug('Guest agent is not enabled for the instance.',
3512                           instance=instance)
3513                 instance.task_state = None
3514                 instance.save(
3515                     expected_task_state=task_states.UPDATING_PASSWORD)
3516         except exception.SetAdminPasswdNotSupported:
3517             with excutils.save_and_reraise_exception():
3518                 LOG.info('set_admin_password is not supported '
3519                          'by this driver or guest instance.',
3520                          instance=instance)
3521                 instance.task_state = None
3522                 instance.save(
3523                     expected_task_state=task_states.UPDATING_PASSWORD)
3524         except NotImplementedError:
3525             LOG.warning('set_admin_password is not implemented '
3526                         'by this driver or guest instance.',
3527                         instance=instance)
3528             instance.task_state = None
3529             instance.save(
3530                 expected_task_state=task_states.UPDATING_PASSWORD)
3531             raise NotImplementedError(_('set_admin_password is not '
3532                                         'implemented by this driver or guest '
3533                                         'instance.'))
3534         except exception.UnexpectedTaskStateError:
3535             # interrupted by another (most likely delete) task
3536             # do not retry
3537             raise
3538         except Exception:
3539             # Catch all here because this could be anything.
3540             LOG.exception('set_admin_password failed', instance=instance)
3541             self._set_instance_obj_error_state(context, instance)
3542             # We create a new exception here so that we won't
3543             # potentially reveal password information to the
3544             # API caller.  The real exception is logged above
3545             _msg = _('error setting admin password')
3546             raise exception.InstancePasswordSetFailed(
3547                 instance=instance.uuid, reason=_msg)
3548 
3549     @wrap_exception()
3550     @reverts_task_state
3551     @wrap_instance_fault
3552     def inject_file(self, context, path, file_contents, instance):
3553         """Write a file to the specified path in an instance on this host."""
3554         # NOTE(russellb) Remove this method, as well as the underlying virt
3555         # driver methods, when the compute rpc interface is bumped to 4.x
3556         # as it is no longer used.
3557         context = context.elevated()
3558         current_power_state = self._get_power_state(context, instance)
3559         expected_state = power_state.RUNNING
3560         if current_power_state != expected_state:
3561             LOG.warning('trying to inject a file into a non-running '
3562                         '(state: %(current_state)s expected: '
3563                         '%(expected_state)s)',
3564                         {'current_state': current_power_state,
3565                          'expected_state': expected_state},
3566                         instance=instance)
3567         LOG.info('injecting file to %s', path, instance=instance)
3568         self.driver.inject_file(instance, path, file_contents)
3569 
3570     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3571         """Determine what image should be used to boot the rescue VM."""
3572         # 1. If rescue_image_ref is passed in, use that for rescue.
3573         # 2. Else, use the base image associated with instance's current image.
3574         #       The idea here is to provide the customer with a rescue
3575         #       environment which they are familiar with.
3576         #       So, if they built their instance off of a Debian image,
3577         #       their rescue VM will also be Debian.
3578         # 3. As a last resort, use instance's current image.
3579         if not rescue_image_ref:
3580             system_meta = utils.instance_sys_meta(instance)
3581             rescue_image_ref = system_meta.get('image_base_image_ref')
3582 
3583         if not rescue_image_ref:
3584             LOG.warning('Unable to find a different image to use for '
3585                         'rescue VM, using instance\'s current image',
3586                         instance=instance)
3587             rescue_image_ref = instance.image_ref
3588 
3589         return objects.ImageMeta.from_image_ref(
3590             context, self.image_api, rescue_image_ref)
3591 
3592     @wrap_exception()
3593     @reverts_task_state
3594     @wrap_instance_event(prefix='compute')
3595     @wrap_instance_fault
3596     def rescue_instance(self, context, instance, rescue_password,
3597                         rescue_image_ref, clean_shutdown):
3598         context = context.elevated()
3599         LOG.info('Rescuing', instance=instance)
3600 
3601         admin_password = (rescue_password if rescue_password else
3602                       utils.generate_password())
3603 
3604         network_info = self.network_api.get_instance_nw_info(context, instance)
3605 
3606         rescue_image_meta = self._get_rescue_image(context, instance,
3607                                                    rescue_image_ref)
3608 
3609         extra_usage_info = {'rescue_image_name':
3610                             self._get_image_name(rescue_image_meta)}
3611         self._notify_about_instance_usage(context, instance,
3612                 "rescue.start", extra_usage_info=extra_usage_info,
3613                 network_info=network_info)
3614         compute_utils.notify_about_instance_rescue_action(
3615             context, instance, self.host, rescue_image_ref,
3616             phase=fields.NotificationPhase.START)
3617 
3618         try:
3619             self._power_off_instance(context, instance, clean_shutdown)
3620 
3621             self.driver.rescue(context, instance,
3622                                network_info,
3623                                rescue_image_meta, admin_password)
3624         except Exception as e:
3625             LOG.exception("Error trying to Rescue Instance",
3626                           instance=instance)
3627             self._set_instance_obj_error_state(context, instance)
3628             raise exception.InstanceNotRescuable(
3629                 instance_id=instance.uuid,
3630                 reason=_("Driver Error: %s") % e)
3631 
3632         compute_utils.notify_usage_exists(self.notifier, context, instance,
3633                                           current_period=True)
3634 
3635         instance.vm_state = vm_states.RESCUED
3636         instance.task_state = None
3637         instance.power_state = self._get_power_state(context, instance)
3638         instance.launched_at = timeutils.utcnow()
3639         instance.save(expected_task_state=task_states.RESCUING)
3640 
3641         self._notify_about_instance_usage(context, instance,
3642                 "rescue.end", extra_usage_info=extra_usage_info,
3643                 network_info=network_info)
3644         compute_utils.notify_about_instance_rescue_action(
3645             context, instance, self.host, rescue_image_ref,
3646             phase=fields.NotificationPhase.END)
3647 
3648     @wrap_exception()
3649     @reverts_task_state
3650     @wrap_instance_event(prefix='compute')
3651     @wrap_instance_fault
3652     def unrescue_instance(self, context, instance):
3653         context = context.elevated()
3654         LOG.info('Unrescuing', instance=instance)
3655 
3656         network_info = self.network_api.get_instance_nw_info(context, instance)
3657         self._notify_about_instance_usage(context, instance,
3658                 "unrescue.start", network_info=network_info)
3659         compute_utils.notify_about_instance_action(context, instance,
3660             self.host, action=fields.NotificationAction.UNRESCUE,
3661             phase=fields.NotificationPhase.START)
3662 
3663         with self._error_out_instance_on_exception(context, instance):
3664             self.driver.unrescue(instance,
3665                                  network_info)
3666 
3667         instance.vm_state = vm_states.ACTIVE
3668         instance.task_state = None
3669         instance.power_state = self._get_power_state(context, instance)
3670         instance.save(expected_task_state=task_states.UNRESCUING)
3671 
3672         self._notify_about_instance_usage(context,
3673                                           instance,
3674                                           "unrescue.end",
3675                                           network_info=network_info)
3676         compute_utils.notify_about_instance_action(context, instance,
3677             self.host, action=fields.NotificationAction.UNRESCUE,
3678             phase=fields.NotificationPhase.END)
3679 
3680     @wrap_exception()
3681     @wrap_instance_fault
3682     def change_instance_metadata(self, context, diff, instance):
3683         """Update the metadata published to the instance."""
3684         LOG.debug("Changing instance metadata according to %r",
3685                   diff, instance=instance)
3686         self.driver.change_instance_metadata(context, instance, diff)
3687 
3688     @wrap_exception()
3689     @wrap_instance_event(prefix='compute')
3690     @wrap_instance_fault
3691     def confirm_resize(self, context, instance, migration):
3692         """Confirms a migration/resize and deletes the 'old' instance.
3693 
3694         This is called from the API and runs on the source host.
3695 
3696         Nothing needs to happen on the destination host at this point since
3697         the instance is already running there. This routine just cleans up the
3698         source host.
3699         """
3700         @utils.synchronized(instance.uuid)
3701         def do_confirm_resize(context, instance, migration_id):
3702             # NOTE(wangpan): Get the migration status from db, if it has been
3703             #                confirmed, we do nothing and return here
3704             LOG.debug("Going to confirm migration %s", migration_id,
3705                       instance=instance)
3706             try:
3707                 # TODO(russellb) Why are we sending the migration object just
3708                 # to turn around and look it up from the db again?
3709                 migration = objects.Migration.get_by_id(
3710                                     context.elevated(), migration_id)
3711             except exception.MigrationNotFound:
3712                 LOG.error("Migration %s is not found during confirmation",
3713                           migration_id, instance=instance)
3714                 return
3715 
3716             if migration.status == 'confirmed':
3717                 LOG.info("Migration %s is already confirmed",
3718                          migration_id, instance=instance)
3719                 return
3720             elif migration.status not in ('finished', 'confirming'):
3721                 LOG.warning("Unexpected confirmation status '%(status)s' "
3722                             "of migration %(id)s, exit confirmation process",
3723                             {"status": migration.status, "id": migration_id},
3724                             instance=instance)
3725                 return
3726 
3727             # NOTE(wangpan): Get the instance from db, if it has been
3728             #                deleted, we do nothing and return here
3729             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3730             try:
3731                 instance = objects.Instance.get_by_uuid(
3732                         context, instance.uuid,
3733                         expected_attrs=expected_attrs)
3734             except exception.InstanceNotFound:
3735                 LOG.info("Instance is not found during confirmation",
3736                          instance=instance)
3737                 return
3738 
3739             self._confirm_resize(context, instance, migration=migration)
3740 
3741         do_confirm_resize(context, instance, migration.id)
3742 
3743     def _confirm_resize(self, context, instance, migration=None):
3744         """Destroys the source instance."""
3745         self._notify_about_instance_usage(context, instance,
3746                                           "resize.confirm.start")
3747         compute_utils.notify_about_instance_action(context, instance,
3748             self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3749             phase=fields.NotificationPhase.START)
3750 
3751         with self._error_out_instance_on_exception(context, instance):
3752             # NOTE(danms): delete stashed migration information
3753             old_instance_type = instance.old_flavor
3754             instance.old_flavor = None
3755             instance.new_flavor = None
3756             instance.system_metadata.pop('old_vm_state', None)
3757             instance.save()
3758 
3759             # NOTE(tr3buchet): tear down networks on source host
3760             self.network_api.setup_networks_on_host(context, instance,
3761                                migration.source_compute, teardown=True)
3762 
3763             network_info = self.network_api.get_instance_nw_info(context,
3764                                                                  instance)
3765             # TODO(mriedem): Get BDMs here and pass them to the driver.
3766             self.driver.confirm_migration(context, migration, instance,
3767                                           network_info)
3768 
3769             migration.status = 'confirmed'
3770             with migration.obj_as_admin():
3771                 migration.save()
3772 
3773             rt = self._get_resource_tracker()
3774             rt.drop_move_claim(context, instance, migration.source_node,
3775                                old_instance_type, prefix='old_')
3776             self._delete_allocation_after_move(context, instance, migration,
3777                                                old_instance_type,
3778                                                migration.source_node)
3779             instance.drop_migration_context()
3780 
3781             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3782             # might have manually powered up the instance to confirm the
3783             # resize/migrate, so we need to check the current power state
3784             # on the instance and set the vm_state appropriately. We default
3785             # to ACTIVE because if the power state is not SHUTDOWN, we
3786             # assume _sync_instance_power_state will clean it up.
3787             p_state = instance.power_state
3788             vm_state = None
3789             if p_state == power_state.SHUTDOWN:
3790                 vm_state = vm_states.STOPPED
3791                 LOG.debug("Resized/migrated instance is powered off. "
3792                           "Setting vm_state to '%s'.", vm_state,
3793                           instance=instance)
3794             else:
3795                 vm_state = vm_states.ACTIVE
3796 
3797             instance.vm_state = vm_state
3798             instance.task_state = None
3799             instance.save(expected_task_state=[None, task_states.DELETING])
3800 
3801             self._notify_about_instance_usage(
3802                 context, instance, "resize.confirm.end",
3803                 network_info=network_info)
3804             compute_utils.notify_about_instance_action(context, instance,
3805                    self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3806                    phase=fields.NotificationPhase.END)
3807 
3808     def _delete_allocation_after_move(self, context, instance, migration,
3809                                       flavor, nodename):
3810         rt = self._get_resource_tracker()
3811         cn_uuid = rt.get_node_uuid(nodename)
3812 
3813         if migration.source_node == nodename:
3814             if migration.status in ('confirmed', 'completed'):
3815                 # NOTE(danms): We're finishing on the source node, so try to
3816                 # delete the allocation based on the migration uuid
3817                 deleted = self.reportclient.delete_allocation_for_instance(
3818                     context, migration.uuid)
3819                 if deleted:
3820                     LOG.info(_('Source node %(node)s confirmed migration '
3821                                '%(mig)s; deleted migration-based '
3822                                'allocation'),
3823                              {'node': nodename, 'mig': migration.uuid})
3824                     # NOTE(danms): We succeeded, which means we do not
3825                     # need to do the complex double allocation dance
3826                     return
3827             else:
3828                 # We're reverting (or failed) on the source, so we
3829                 # need to check if our migration holds a claim and if
3830                 # so, avoid doing the legacy behavior below.
3831                 mig_allocs = (
3832                     self.reportclient.get_allocations_for_consumer_by_provider(
3833                         context, cn_uuid, migration.uuid))
3834                 if mig_allocs:
3835                     LOG.info(_('Source node %(node)s reverted migration '
3836                                '%(mig)s; not deleting migration-based '
3837                                'allocation'),
3838                              {'node': nodename, 'mig': migration.uuid})
3839                     return
3840         elif migration.dest_node == nodename:
3841             # NOTE(danms): We're reverting on the destination node
3842             # (and we must not be doing a same-host migration if we
3843             # made it past the check above), so we need to check to
3844             # see if the source did migration-based allocation
3845             # accounting
3846             allocs = (
3847                 self.reportclient.get_allocations_for_consumer_by_provider(
3848                     context, cn_uuid, migration.uuid))
3849             if allocs:
3850                 # NOTE(danms): The source did migration-based allocation
3851                 # accounting, so we should let the source node rejigger
3852                 # the allocations in finish_resize_revert()
3853                 LOG.info(_('Destination node %(node)s reverted migration '
3854                            '%(mig)s; not deleting migration-based '
3855                            'allocation'),
3856                          {'node': nodename, 'mig': migration.uuid})
3857                 return
3858 
3859         # TODO(danms): Remove below this line when we remove compatibility
3860         # for double-accounting migrations (likely rocky)
3861         LOG.info(_('Doing legacy allocation math for migration %(mig)s after '
3862                    'instance move'),
3863                  {'mig': migration.uuid},
3864                  instance=instance)
3865 
3866         # NOTE(jaypipes): This sucks, but due to the fact that confirm_resize()
3867         # only runs on the source host and revert_resize() runs on the
3868         # destination host, we need to do this here. Basically, what we're
3869         # doing here is grabbing the existing allocations for this instance
3870         # from the placement API, dropping the resources in the doubled-up
3871         # allocation set that refer to the source host UUID and calling PUT
3872         # /allocations back to the placement API. The allocation that gets
3873         # PUT'd back to placement will only include the destination host and
3874         # any shared providers in the case of a confirm_resize operation and
3875         # the source host and shared providers for a revert_resize operation..
3876         if not scheduler_utils.remove_allocation_from_compute(
3877                 context, instance, cn_uuid, self.reportclient, flavor):
3878             LOG.error("Failed to save manipulated allocation",
3879                       instance=instance)
3880 
3881     @wrap_exception()
3882     @reverts_task_state
3883     @wrap_instance_event(prefix='compute')
3884     @errors_out_migration
3885     @wrap_instance_fault
3886     def revert_resize(self, context, instance, migration):
3887         """Destroys the new instance on the destination machine.
3888 
3889         Reverts the model changes, and powers on the old instance on the
3890         source machine.
3891 
3892         """
3893         # NOTE(comstud): A revert_resize is essentially a resize back to
3894         # the old size, so we need to send a usage event here.
3895         compute_utils.notify_usage_exists(self.notifier, context, instance,
3896                                           current_period=True)
3897 
3898         with self._error_out_instance_on_exception(context, instance):
3899             # NOTE(tr3buchet): tear down networks on destination host
3900             self.network_api.setup_networks_on_host(context, instance,
3901                                                     teardown=True)
3902 
3903             migration_p = obj_base.obj_to_primitive(migration)
3904             self.network_api.migrate_instance_start(context,
3905                                                     instance,
3906                                                     migration_p)
3907 
3908             network_info = self.network_api.get_instance_nw_info(context,
3909                                                                  instance)
3910             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3911                     context, instance.uuid)
3912             block_device_info = self._get_instance_block_device_info(
3913                                 context, instance, bdms=bdms)
3914 
3915             destroy_disks = not self._is_instance_storage_shared(
3916                 context, instance, host=migration.source_compute)
3917             self.driver.destroy(context, instance, network_info,
3918                                 block_device_info, destroy_disks)
3919 
3920             self._terminate_volume_connections(context, instance, bdms)
3921 
3922             migration.status = 'reverted'
3923             with migration.obj_as_admin():
3924                 migration.save()
3925 
3926             # NOTE(ndipanov): We need to do this here because dropping the
3927             # claim means we lose the migration_context data. We really should
3928             # fix this by moving the drop_move_claim call to the
3929             # finish_revert_resize method as this is racy (revert is dropped,
3930             # but instance resources will be tracked with the new flavor until
3931             # it gets rolled back in finish_revert_resize, which is
3932             # potentially wrong for a period of time).
3933             instance.revert_migration_context()
3934             instance.save()
3935 
3936             rt = self._get_resource_tracker()
3937             rt.drop_move_claim(context, instance, instance.node)
3938             self._delete_allocation_after_move(context, instance, migration,
3939                                                instance.flavor,
3940                                                instance.node)
3941 
3942             # RPC cast back to the source host to finish the revert there.
3943             self.compute_rpcapi.finish_revert_resize(context, instance,
3944                     migration, migration.source_compute)
3945 
3946     @wrap_exception()
3947     @reverts_task_state
3948     @wrap_instance_event(prefix='compute')
3949     @errors_out_migration
3950     @wrap_instance_fault
3951     def finish_revert_resize(self, context, instance, migration):
3952         """Finishes the second half of reverting a resize on the source host.
3953 
3954         Bring the original source instance state back (active/shutoff) and
3955         revert the resized attributes in the database.
3956 
3957         """
3958         with self._error_out_instance_on_exception(context, instance):
3959             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3960                 context, instance.uuid)
3961             self._notify_about_instance_usage(
3962                     context, instance, "resize.revert.start")
3963             compute_utils.notify_about_instance_action(context, instance,
3964                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
3965                     phase=fields.NotificationPhase.START, bdms=bdms)
3966 
3967             # NOTE(mriedem): delete stashed old_vm_state information; we
3968             # default to ACTIVE for backwards compatibility if old_vm_state
3969             # is not set
3970             old_vm_state = instance.system_metadata.pop('old_vm_state',
3971                                                         vm_states.ACTIVE)
3972 
3973             self._set_instance_info(instance, instance.old_flavor)
3974             instance.old_flavor = None
3975             instance.new_flavor = None
3976             instance.host = migration.source_compute
3977             instance.node = migration.source_node
3978             instance.save()
3979 
3980             self._revert_allocation(context, instance, migration)
3981 
3982             self.network_api.setup_networks_on_host(context, instance,
3983                                                     migration.source_compute)
3984             migration_p = obj_base.obj_to_primitive(migration)
3985             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
3986             # source host temporarily. "network_api.migrate_instance_finish"
3987             # will setup the network for the instance on the destination host.
3988             # For revert resize, the instance will back to the source host, the
3989             # setup of the network for instance should be on the source host.
3990             # So set the migration_p['dest_compute'] to source host at here.
3991             migration_p['dest_compute'] = migration.source_compute
3992             self.network_api.migrate_instance_finish(context,
3993                                                      instance,
3994                                                      migration_p)
3995             network_info = self.network_api.get_instance_nw_info(context,
3996                                                                  instance)
3997 
3998             # revert_resize deleted any volume attachments for the instance
3999             # and created new ones to be used on this host, but we
4000             # have to update those attachments with the host connector so the
4001             # BDM.connection_info will get set in the call to
4002             # _get_instance_block_device_info below with refresh_conn_info=True
4003             # and then the volumes can be re-connected via the driver on this
4004             # host.
4005             self._update_volume_attachments(context, instance, bdms)
4006 
4007             block_device_info = self._get_instance_block_device_info(
4008                     context, instance, refresh_conn_info=True, bdms=bdms)
4009 
4010             power_on = old_vm_state != vm_states.STOPPED
4011             self.driver.finish_revert_migration(context, instance,
4012                                        network_info,
4013                                        block_device_info, power_on)
4014 
4015             instance.drop_migration_context()
4016             instance.launched_at = timeutils.utcnow()
4017             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
4018 
4019             # Complete any volume attachments so the volumes are in-use.
4020             self._complete_volume_attachments(context, bdms)
4021 
4022             # if the original vm state was STOPPED, set it back to STOPPED
4023             LOG.info("Updating instance to original state: '%s'",
4024                      old_vm_state, instance=instance)
4025             if power_on:
4026                 instance.vm_state = vm_states.ACTIVE
4027                 instance.task_state = None
4028                 instance.save()
4029             else:
4030                 instance.task_state = task_states.POWERING_OFF
4031                 instance.save()
4032                 self.stop_instance(context, instance=instance,
4033                                    clean_shutdown=True)
4034 
4035             self._notify_about_instance_usage(
4036                     context, instance, "resize.revert.end")
4037             compute_utils.notify_about_instance_action(context, instance,
4038                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4039                     phase=fields.NotificationPhase.END, bdms=bdms)
4040 
4041     def _revert_allocation(self, context, instance, migration):
4042         """Revert an allocation that is held by migration to our instance."""
4043 
4044         # Fetch the original allocation that the instance had on the source
4045         # node, which are now held by the migration
4046         orig_alloc = self.reportclient.get_allocations_for_consumer(
4047             context, migration.uuid)
4048         if not orig_alloc:
4049             # NOTE(danms): This migration did not do per-migration allocation
4050             # accounting, so nothing to do here.
4051             LOG.info('Old-style migration %(mig)s is being reverted; '
4052                      'no migration claims found on original node '
4053                      'to swap.',
4054                      {'mig': migration.uuid},
4055                      instance=instance)
4056             return False
4057 
4058         if len(orig_alloc) > 1:
4059             # NOTE(danms): This may change later if we have other allocations
4060             # against other providers that need to be held by the migration
4061             # as well. Perhaps something like shared storage resources that
4062             # will actually be duplicated during a resize type operation.
4063             LOG.error('New-style migration %(mig)s has allocations against '
4064                       'more than one provider %(rps)s. This should not be '
4065                       'possible, but reverting it anyway.',
4066                       {'mig': migration.uuid,
4067                        'rps': ','.join(orig_alloc.keys())},
4068                       instance=instance)
4069 
4070         # We only have a claim against one provider, it is the source node
4071         cn_uuid = list(orig_alloc.keys())[0]
4072 
4073         # Get just the resources part of the one allocation we need below
4074         orig_alloc = orig_alloc[cn_uuid].get('resources', {})
4075 
4076         # FIXME(danms): This method is flawed in that it asssumes allocations
4077         # against only one provider. So, this may overwite allocations against
4078         # a shared provider, if we had one.
4079         LOG.info('Swapping old allocation on %(node)s held by migration '
4080                  '%(mig)s for instance',
4081                  {'node': cn_uuid, 'mig': migration.uuid},
4082                  instance=instance)
4083         # TODO(cdent): Should we be doing anything with return values here?
4084         self.reportclient.set_and_clear_allocations(
4085             context, cn_uuid, instance.uuid, orig_alloc, instance.project_id,
4086             instance.user_id, consumer_to_clear=migration.uuid)
4087         return True
4088 
4089     def _prep_resize(self, context, image, instance, instance_type,
4090                      filter_properties, node, migration, clean_shutdown=True):
4091 
4092         if not filter_properties:
4093             filter_properties = {}
4094 
4095         if not instance.host:
4096             self._set_instance_obj_error_state(context, instance)
4097             msg = _('Instance has no source host')
4098             raise exception.MigrationError(reason=msg)
4099 
4100         same_host = instance.host == self.host
4101         # if the flavor IDs match, it's migrate; otherwise resize
4102         if same_host and instance_type.id == instance['instance_type_id']:
4103             # check driver whether support migrate to same host
4104             if not self.driver.capabilities.get(
4105                     'supports_migrate_to_same_host', False):
4106                 raise exception.UnableToMigrateToSelf(
4107                     instance_id=instance.uuid, host=self.host)
4108 
4109         # NOTE(danms): Stash the new instance_type to avoid having to
4110         # look it up in the database later
4111         instance.new_flavor = instance_type
4112         # NOTE(mriedem): Stash the old vm_state so we can set the
4113         # resized/reverted instance back to the same state later.
4114         vm_state = instance.vm_state
4115         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4116         instance.system_metadata['old_vm_state'] = vm_state
4117         instance.save()
4118 
4119         limits = filter_properties.get('limits', {})
4120         rt = self._get_resource_tracker()
4121         with rt.resize_claim(context, instance, instance_type, node,
4122                              migration, image_meta=image,
4123                              limits=limits) as claim:
4124             LOG.info('Migrating', instance=instance)
4125             # RPC cast to the source host to start the actual resize/migration.
4126             self.compute_rpcapi.resize_instance(
4127                     context, instance, claim.migration, image,
4128                     instance_type, clean_shutdown)
4129 
4130     @wrap_exception()
4131     @reverts_task_state
4132     @wrap_instance_event(prefix='compute')
4133     @wrap_instance_fault
4134     def prep_resize(self, context, image, instance, instance_type,
4135                     request_spec, filter_properties, node,
4136                     clean_shutdown, migration, host_list):
4137         """Initiates the process of moving a running instance to another host.
4138 
4139         Possibly changes the VCPU, RAM and disk size in the process.
4140 
4141         This is initiated from conductor and runs on the destination host.
4142 
4143         The main purpose of this method is performing some checks on the
4144         destination host and making a claim for resources. If the claim fails
4145         then a reschedule to another host may be attempted which involves
4146         calling back to conductor to start the process over again.
4147         """
4148         if node is None:
4149             node = self._get_nodename(instance, refresh=True)
4150 
4151         with self._error_out_instance_on_exception(context, instance), \
4152                  errors_out_migration_ctxt(migration):
4153             compute_utils.notify_usage_exists(self.notifier, context, instance,
4154                                               current_period=True)
4155             self._notify_about_instance_usage(
4156                     context, instance, "resize.prep.start")
4157             compute_utils.notify_about_resize_prep_instance(
4158                 context, instance, self.host,
4159                 fields.NotificationPhase.START, instance_type)
4160             try:
4161                 self._prep_resize(context, image, instance,
4162                                   instance_type, filter_properties,
4163                                   node, migration, clean_shutdown)
4164             except Exception:
4165                 # Since we hit a failure, we're either rescheduling or dead
4166                 # and either way we need to cleanup any allocations created
4167                 # by the scheduler for the destination node.
4168                 if migration and not self._revert_allocation(
4169                         context, instance, migration):
4170                     # We did not do a migration-based
4171                     # allocation. Note that for a resize to the
4172                     # same host, the scheduler will merge the
4173                     # flavors, so here we'd be subtracting the new
4174                     # flavor from the allocated resources on this
4175                     # node.
4176                     # FIXME(danms): Remove this in Rocky
4177                     rt = self._get_resource_tracker()
4178                     rt.delete_allocation_for_failed_resize(
4179                         instance, node, instance_type)
4180                 # try to re-schedule the resize elsewhere:
4181                 exc_info = sys.exc_info()
4182                 self._reschedule_resize_or_reraise(context, image, instance,
4183                         exc_info, instance_type, request_spec,
4184                         filter_properties, host_list)
4185             finally:
4186                 extra_usage_info = dict(
4187                         new_instance_type=instance_type.name,
4188                         new_instance_type_id=instance_type.id)
4189 
4190                 self._notify_about_instance_usage(
4191                     context, instance, "resize.prep.end",
4192                     extra_usage_info=extra_usage_info)
4193                 compute_utils.notify_about_resize_prep_instance(
4194                     context, instance, self.host,
4195                     fields.NotificationPhase.END, instance_type)
4196 
4197     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
4198             instance_type, request_spec, filter_properties, host_list):
4199         """Try to re-schedule the resize or re-raise the original error to
4200         error out the instance.
4201         """
4202         if not request_spec:
4203             request_spec = {}
4204         if not filter_properties:
4205             filter_properties = {}
4206 
4207         rescheduled = False
4208         instance_uuid = instance.uuid
4209 
4210         try:
4211             reschedule_method = self.compute_task_api.resize_instance
4212             scheduler_hint = dict(filter_properties=filter_properties)
4213             method_args = (instance, None, scheduler_hint, instance_type)
4214             task_state = task_states.RESIZE_PREP
4215 
4216             rescheduled = self._reschedule(context, request_spec,
4217                     filter_properties, instance, reschedule_method,
4218                     method_args, task_state, exc_info, host_list=host_list)
4219         except Exception as error:
4220             rescheduled = False
4221             LOG.exception("Error trying to reschedule",
4222                           instance_uuid=instance_uuid)
4223             compute_utils.add_instance_fault_from_exc(context,
4224                     instance, error,
4225                     exc_info=sys.exc_info())
4226             self._notify_about_instance_usage(context, instance,
4227                     'resize.error', fault=error)
4228             compute_utils.notify_about_instance_action(
4229                 context, instance, self.host,
4230                 action=fields.NotificationAction.RESIZE,
4231                 phase=fields.NotificationPhase.ERROR,
4232                 exception=error)
4233         if rescheduled:
4234             self._log_original_error(exc_info, instance_uuid)
4235             compute_utils.add_instance_fault_from_exc(context,
4236                     instance, exc_info[1], exc_info=exc_info)
4237             self._notify_about_instance_usage(context, instance,
4238                     'resize.error', fault=exc_info[1])
4239             compute_utils.notify_about_instance_action(
4240                 context, instance, self.host,
4241                 action=fields.NotificationAction.RESIZE,
4242                 phase=fields.NotificationPhase.ERROR,
4243                 exception=exc_info[1])
4244         else:
4245             # not re-scheduling
4246             six.reraise(*exc_info)
4247 
4248     @wrap_exception()
4249     @reverts_task_state
4250     @wrap_instance_event(prefix='compute')
4251     @wrap_instance_fault
4252     def resize_instance(self, context, instance, image,
4253                         migration, instance_type, clean_shutdown):
4254         """Starts the migration of a running instance to another host.
4255 
4256         This is initiated from the destination host's ``prep_resize`` routine
4257         and runs on the source host.
4258         """
4259         try:
4260             self._resize_instance(context, instance, image, migration,
4261                                   instance_type, clean_shutdown)
4262         except Exception:
4263             with excutils.save_and_reraise_exception():
4264                 self._revert_allocation(context, instance, migration)
4265 
4266     def _resize_instance(self, context, instance, image,
4267                          migration, instance_type, clean_shutdown):
4268         with self._error_out_instance_on_exception(context, instance), \
4269              errors_out_migration_ctxt(migration):
4270             network_info = self.network_api.get_instance_nw_info(context,
4271                                                                  instance)
4272 
4273             migration.status = 'migrating'
4274             with migration.obj_as_admin():
4275                 migration.save()
4276 
4277             instance.task_state = task_states.RESIZE_MIGRATING
4278             instance.save(expected_task_state=task_states.RESIZE_PREP)
4279 
4280             self._notify_about_instance_usage(
4281                 context, instance, "resize.start", network_info=network_info)
4282 
4283             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4284                     context, instance.uuid)
4285 
4286             compute_utils.notify_about_instance_action(context, instance,
4287                    self.host, action=fields.NotificationAction.RESIZE,
4288                    phase=fields.NotificationPhase.START, bdms=bdms)
4289 
4290             block_device_info = self._get_instance_block_device_info(
4291                                 context, instance, bdms=bdms)
4292 
4293             timeout, retry_interval = self._get_power_off_values(context,
4294                                             instance, clean_shutdown)
4295             disk_info = self.driver.migrate_disk_and_power_off(
4296                     context, instance, migration.dest_host,
4297                     instance_type, network_info,
4298                     block_device_info,
4299                     timeout, retry_interval)
4300 
4301             self._terminate_volume_connections(context, instance, bdms)
4302 
4303             migration_p = obj_base.obj_to_primitive(migration)
4304             self.network_api.migrate_instance_start(context,
4305                                                     instance,
4306                                                     migration_p)
4307 
4308             migration.status = 'post-migrating'
4309             with migration.obj_as_admin():
4310                 migration.save()
4311 
4312             instance.host = migration.dest_compute
4313             instance.node = migration.dest_node
4314             instance.task_state = task_states.RESIZE_MIGRATED
4315             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4316 
4317             # RPC cast to the destination host to finish the resize/migration.
4318             self.compute_rpcapi.finish_resize(context, instance,
4319                     migration, image, disk_info, migration.dest_compute)
4320 
4321         self._notify_about_instance_usage(context, instance, "resize.end",
4322                                           network_info=network_info)
4323 
4324         compute_utils.notify_about_instance_action(context, instance,
4325                self.host, action=fields.NotificationAction.RESIZE,
4326                phase=fields.NotificationPhase.END, bdms=bdms)
4327         self.instance_events.clear_events_for_instance(instance)
4328 
4329     def _terminate_volume_connections(self, context, instance, bdms):
4330         connector = None
4331         for bdm in bdms:
4332             if bdm.is_volume:
4333                 if bdm.attachment_id:
4334                     # NOTE(jdg): So here's the thing, the idea behind the new
4335                     # attach API's was to have a new code fork/path that we
4336                     # followed, we're not going to do that so we have to do
4337                     # some extra work in here to make it *behave* just like the
4338                     # old code. Cinder doesn't allow disconnect/reconnect (you
4339                     # just delete the attachment and get a new one)
4340                     # attachments in the new attach code so we have to do
4341                     # a delete and create without a connector (reserve),
4342                     # in other words, beware
4343                     attachment_id = self.volume_api.attachment_create(
4344                         context, bdm.volume_id, instance.uuid)['id']
4345                     self.volume_api.attachment_delete(context,
4346                                                       bdm.attachment_id)
4347                     bdm.attachment_id = attachment_id
4348                     bdm.save()
4349 
4350                 else:
4351                     if connector is None:
4352                         connector = self.driver.get_volume_connector(instance)
4353                     self.volume_api.terminate_connection(context,
4354                                                          bdm.volume_id,
4355                                                          connector)
4356 
4357     @staticmethod
4358     def _set_instance_info(instance, instance_type):
4359         instance.instance_type_id = instance_type.id
4360         instance.memory_mb = instance_type.memory_mb
4361         instance.vcpus = instance_type.vcpus
4362         instance.root_gb = instance_type.root_gb
4363         instance.ephemeral_gb = instance_type.ephemeral_gb
4364         instance.flavor = instance_type
4365 
4366     def _update_volume_attachments(self, context, instance, bdms):
4367         """Updates volume attachments using the virt driver host connector.
4368 
4369         :param context: nova.context.RequestContext - user request context
4370         :param instance: nova.objects.Instance
4371         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4372                      device mappings for the given instance
4373         """
4374         if bdms:
4375             connector = None
4376             for bdm in bdms:
4377                 if bdm.is_volume and bdm.attachment_id:
4378                     if connector is None:
4379                         connector = self.driver.get_volume_connector(instance)
4380                     self.volume_api.attachment_update(
4381                         context, bdm.attachment_id, connector, bdm.device_name)
4382 
4383     def _complete_volume_attachments(self, context, bdms):
4384         """Completes volume attachments for the instance
4385 
4386         :param context: nova.context.RequestContext - user request context
4387         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4388                      device mappings for the given instance
4389         """
4390         if bdms:
4391             for bdm in bdms:
4392                 if bdm.is_volume and bdm.attachment_id:
4393                     self.volume_api.attachment_complete(
4394                         context, bdm.attachment_id)
4395 
4396     def _finish_resize(self, context, instance, migration, disk_info,
4397                        image_meta, bdms):
4398         resize_instance = False
4399         old_instance_type_id = migration['old_instance_type_id']
4400         new_instance_type_id = migration['new_instance_type_id']
4401         old_instance_type = instance.get_flavor()
4402         # NOTE(mriedem): Get the old_vm_state so we know if we should
4403         # power on the instance. If old_vm_state is not set we need to default
4404         # to ACTIVE for backwards compatibility
4405         old_vm_state = instance.system_metadata.get('old_vm_state',
4406                                                     vm_states.ACTIVE)
4407         instance.old_flavor = old_instance_type
4408 
4409         if old_instance_type_id != new_instance_type_id:
4410             instance_type = instance.get_flavor('new')
4411             self._set_instance_info(instance, instance_type)
4412             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4413                 if old_instance_type[key] != instance_type[key]:
4414                     resize_instance = True
4415                     break
4416         instance.apply_migration_context()
4417 
4418         # NOTE(tr3buchet): setup networks on destination host
4419         self.network_api.setup_networks_on_host(context, instance,
4420                                                 migration['dest_compute'])
4421 
4422         migration_p = obj_base.obj_to_primitive(migration)
4423         self.network_api.migrate_instance_finish(context,
4424                                                  instance,
4425                                                  migration_p)
4426 
4427         network_info = self.network_api.get_instance_nw_info(context, instance)
4428 
4429         instance.task_state = task_states.RESIZE_FINISH
4430         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4431 
4432         self._notify_about_instance_usage(
4433             context, instance, "finish_resize.start",
4434             network_info=network_info)
4435         compute_utils.notify_about_instance_action(context, instance,
4436                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4437                phase=fields.NotificationPhase.START, bdms=bdms)
4438 
4439         # We need to update any volume attachments using the destination
4440         # host connector so that we can update the BDM.connection_info
4441         # before calling driver.finish_migration otherwise the driver
4442         # won't know how to connect the volumes to this host.
4443         # Note that _get_instance_block_device_info with
4444         # refresh_conn_info=True will update the BDM.connection_info value
4445         # in the database so we must do this before calling that method.
4446         self._update_volume_attachments(context, instance, bdms)
4447 
4448         block_device_info = self._get_instance_block_device_info(
4449             context, instance, refresh_conn_info=True, bdms=bdms)
4450 
4451         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4452         # automatically power on the instance after it's migrated
4453         power_on = old_vm_state != vm_states.STOPPED
4454 
4455         try:
4456             self.driver.finish_migration(context, migration, instance,
4457                                          disk_info,
4458                                          network_info,
4459                                          image_meta, resize_instance,
4460                                          block_device_info, power_on)
4461         except Exception:
4462             with excutils.save_and_reraise_exception():
4463                 if old_instance_type_id != new_instance_type_id:
4464                     self._set_instance_info(instance,
4465                                             old_instance_type)
4466 
4467         # Now complete any volume attachments that were previously updated.
4468         self._complete_volume_attachments(context, bdms)
4469 
4470         migration.status = 'finished'
4471         with migration.obj_as_admin():
4472             migration.save()
4473 
4474         instance.vm_state = vm_states.RESIZED
4475         instance.task_state = None
4476         instance.launched_at = timeutils.utcnow()
4477         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4478 
4479         return network_info
4480 
4481     @wrap_exception()
4482     @reverts_task_state
4483     @wrap_instance_event(prefix='compute')
4484     @wrap_instance_fault
4485     def finish_resize(self, context, disk_info, image, instance,
4486                       migration):
4487         """Completes the migration process.
4488 
4489         Sets up the newly transferred disk and turns on the instance at its
4490         new host machine.
4491 
4492         """
4493         try:
4494             self._finish_resize_helper(context, disk_info, image, instance,
4495                                        migration)
4496         except Exception:
4497             with excutils.save_and_reraise_exception():
4498                 self._revert_allocation(context, instance, migration)
4499 
4500     def _finish_resize_helper(self, context, disk_info, image, instance,
4501                               migration):
4502         """Completes the migration process.
4503 
4504         The caller must revert the instance's allocations if the migration
4505         process failed.
4506         """
4507         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4508             context, instance.uuid)
4509 
4510         with self._error_out_instance_on_exception(context, instance), \
4511              errors_out_migration_ctxt(migration):
4512             image_meta = objects.ImageMeta.from_dict(image)
4513             network_info = self._finish_resize(context, instance, migration,
4514                                                disk_info, image_meta, bdms)
4515 
4516         # TODO(melwitt): We should clean up instance console tokens here. The
4517         # instance is on a new host and will need to establish a new console
4518         # connection.
4519         self._update_scheduler_instance_info(context, instance)
4520         self._notify_about_instance_usage(
4521             context, instance, "finish_resize.end",
4522             network_info=network_info)
4523         compute_utils.notify_about_instance_action(context, instance,
4524                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4525                phase=fields.NotificationPhase.END, bdms=bdms)
4526 
4527     @wrap_exception()
4528     @wrap_instance_fault
4529     def add_fixed_ip_to_instance(self, context, network_id, instance):
4530         """Calls network_api to add new fixed_ip to instance
4531         then injects the new network info and resets instance networking.
4532 
4533         """
4534         self._notify_about_instance_usage(
4535                 context, instance, "create_ip.start")
4536 
4537         network_info = self.network_api.add_fixed_ip_to_instance(context,
4538                                                                  instance,
4539                                                                  network_id)
4540         self._inject_network_info(context, instance, network_info)
4541         self.reset_network(context, instance)
4542 
4543         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4544         instance.updated_at = timeutils.utcnow()
4545         instance.save()
4546 
4547         self._notify_about_instance_usage(
4548             context, instance, "create_ip.end", network_info=network_info)
4549 
4550     @wrap_exception()
4551     @wrap_instance_fault
4552     def remove_fixed_ip_from_instance(self, context, address, instance):
4553         """Calls network_api to remove existing fixed_ip from instance
4554         by injecting the altered network info and resetting
4555         instance networking.
4556         """
4557         self._notify_about_instance_usage(
4558                 context, instance, "delete_ip.start")
4559 
4560         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4561                                                                       instance,
4562                                                                       address)
4563         self._inject_network_info(context, instance, network_info)
4564         self.reset_network(context, instance)
4565 
4566         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4567         instance.updated_at = timeutils.utcnow()
4568         instance.save()
4569 
4570         self._notify_about_instance_usage(
4571             context, instance, "delete_ip.end", network_info=network_info)
4572 
4573     @wrap_exception()
4574     @reverts_task_state
4575     @wrap_instance_event(prefix='compute')
4576     @wrap_instance_fault
4577     def pause_instance(self, context, instance):
4578         """Pause an instance on this host."""
4579         context = context.elevated()
4580         LOG.info('Pausing', instance=instance)
4581         self._notify_about_instance_usage(context, instance, 'pause.start')
4582         compute_utils.notify_about_instance_action(context, instance,
4583                self.host, action=fields.NotificationAction.PAUSE,
4584                phase=fields.NotificationPhase.START)
4585         self.driver.pause(instance)
4586         instance.power_state = self._get_power_state(context, instance)
4587         instance.vm_state = vm_states.PAUSED
4588         instance.task_state = None
4589         instance.save(expected_task_state=task_states.PAUSING)
4590         self._notify_about_instance_usage(context, instance, 'pause.end')
4591         compute_utils.notify_about_instance_action(context, instance,
4592                self.host, action=fields.NotificationAction.PAUSE,
4593                phase=fields.NotificationPhase.END)
4594 
4595     @wrap_exception()
4596     @reverts_task_state
4597     @wrap_instance_event(prefix='compute')
4598     @wrap_instance_fault
4599     def unpause_instance(self, context, instance):
4600         """Unpause a paused instance on this host."""
4601         context = context.elevated()
4602         LOG.info('Unpausing', instance=instance)
4603         self._notify_about_instance_usage(context, instance, 'unpause.start')
4604         compute_utils.notify_about_instance_action(context, instance,
4605             self.host, action=fields.NotificationAction.UNPAUSE,
4606             phase=fields.NotificationPhase.START)
4607         self.driver.unpause(instance)
4608         instance.power_state = self._get_power_state(context, instance)
4609         instance.vm_state = vm_states.ACTIVE
4610         instance.task_state = None
4611         instance.save(expected_task_state=task_states.UNPAUSING)
4612         self._notify_about_instance_usage(context, instance, 'unpause.end')
4613         compute_utils.notify_about_instance_action(context, instance,
4614             self.host, action=fields.NotificationAction.UNPAUSE,
4615             phase=fields.NotificationPhase.END)
4616 
4617     @wrap_exception()
4618     def host_power_action(self, context, action):
4619         """Reboots, shuts down or powers up the host."""
4620         return self.driver.host_power_action(action)
4621 
4622     @wrap_exception()
4623     def host_maintenance_mode(self, context, host, mode):
4624         """Start/Stop host maintenance window. On start, it triggers
4625         guest VMs evacuation.
4626         """
4627         return self.driver.host_maintenance_mode(host, mode)
4628 
4629     @wrap_exception()
4630     def set_host_enabled(self, context, enabled):
4631         """Sets the specified host's ability to accept new instances."""
4632         return self.driver.set_host_enabled(enabled)
4633 
4634     @wrap_exception()
4635     def get_host_uptime(self, context):
4636         """Returns the result of calling "uptime" on the target host."""
4637         return self.driver.get_host_uptime()
4638 
4639     @wrap_exception()
4640     @wrap_instance_fault
4641     def get_diagnostics(self, context, instance):
4642         """Retrieve diagnostics for an instance on this host."""
4643         current_power_state = self._get_power_state(context, instance)
4644         if current_power_state == power_state.RUNNING:
4645             LOG.info("Retrieving diagnostics", instance=instance)
4646             return self.driver.get_diagnostics(instance)
4647         else:
4648             raise exception.InstanceInvalidState(
4649                 attr='power state',
4650                 instance_uuid=instance.uuid,
4651                 state=power_state.STATE_MAP[instance.power_state],
4652                 method='get_diagnostics')
4653 
4654     @wrap_exception()
4655     @wrap_instance_fault
4656     def get_instance_diagnostics(self, context, instance):
4657         """Retrieve diagnostics for an instance on this host."""
4658         current_power_state = self._get_power_state(context, instance)
4659         if current_power_state == power_state.RUNNING:
4660             LOG.info("Retrieving diagnostics", instance=instance)
4661             return self.driver.get_instance_diagnostics(instance)
4662         else:
4663             raise exception.InstanceInvalidState(
4664                 attr='power state',
4665                 instance_uuid=instance.uuid,
4666                 state=power_state.STATE_MAP[instance.power_state],
4667                 method='get_diagnostics')
4668 
4669     @wrap_exception()
4670     @reverts_task_state
4671     @wrap_instance_event(prefix='compute')
4672     @wrap_instance_fault
4673     def suspend_instance(self, context, instance):
4674         """Suspend the given instance."""
4675         context = context.elevated()
4676 
4677         # Store the old state
4678         instance.system_metadata['old_vm_state'] = instance.vm_state
4679         self._notify_about_instance_usage(context, instance, 'suspend.start')
4680         compute_utils.notify_about_instance_action(context, instance,
4681                 self.host, action=fields.NotificationAction.SUSPEND,
4682                 phase=fields.NotificationPhase.START)
4683         with self._error_out_instance_on_exception(context, instance,
4684              instance_state=instance.vm_state):
4685             self.driver.suspend(context, instance)
4686         instance.power_state = self._get_power_state(context, instance)
4687         instance.vm_state = vm_states.SUSPENDED
4688         instance.task_state = None
4689         instance.save(expected_task_state=task_states.SUSPENDING)
4690         self._notify_about_instance_usage(context, instance, 'suspend.end')
4691         compute_utils.notify_about_instance_action(context, instance,
4692                 self.host, action=fields.NotificationAction.SUSPEND,
4693                 phase=fields.NotificationPhase.END)
4694 
4695     @wrap_exception()
4696     @reverts_task_state
4697     @wrap_instance_event(prefix='compute')
4698     @wrap_instance_fault
4699     def resume_instance(self, context, instance):
4700         """Resume the given suspended instance."""
4701         context = context.elevated()
4702         LOG.info('Resuming', instance=instance)
4703 
4704         self._notify_about_instance_usage(context, instance, 'resume.start')
4705 
4706         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4707             context, instance.uuid)
4708         block_device_info = self._get_instance_block_device_info(
4709             context, instance, bdms=bdms)
4710 
4711         compute_utils.notify_about_instance_action(context, instance,
4712             self.host, action=fields.NotificationAction.RESUME,
4713             phase=fields.NotificationPhase.START, bdms=bdms)
4714 
4715         network_info = self.network_api.get_instance_nw_info(context, instance)
4716 
4717         with self._error_out_instance_on_exception(context, instance,
4718              instance_state=instance.vm_state):
4719             self.driver.resume(context, instance, network_info,
4720                                block_device_info)
4721 
4722         instance.power_state = self._get_power_state(context, instance)
4723 
4724         # We default to the ACTIVE state for backwards compatibility
4725         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4726                                                          vm_states.ACTIVE)
4727 
4728         instance.task_state = None
4729         instance.save(expected_task_state=task_states.RESUMING)
4730         self._notify_about_instance_usage(context, instance, 'resume.end')
4731         compute_utils.notify_about_instance_action(context, instance,
4732             self.host, action=fields.NotificationAction.RESUME,
4733             phase=fields.NotificationPhase.END, bdms=bdms)
4734 
4735     @wrap_exception()
4736     @reverts_task_state
4737     @wrap_instance_event(prefix='compute')
4738     @wrap_instance_fault
4739     def shelve_instance(self, context, instance, image_id,
4740                         clean_shutdown):
4741         """Shelve an instance.
4742 
4743         This should be used when you want to take a snapshot of the instance.
4744         It also adds system_metadata that can be used by a periodic task to
4745         offload the shelved instance after a period of time.
4746 
4747         :param context: request context
4748         :param instance: an Instance object
4749         :param image_id: an image id to snapshot to.
4750         :param clean_shutdown: give the GuestOS a chance to stop
4751         """
4752 
4753         @utils.synchronized(instance.uuid)
4754         def do_shelve_instance():
4755             self._shelve_instance(context, instance, image_id, clean_shutdown)
4756         do_shelve_instance()
4757 
4758     def _shelve_instance(self, context, instance, image_id,
4759                          clean_shutdown):
4760         LOG.info('Shelving', instance=instance)
4761         offload = CONF.shelved_offload_time == 0
4762         if offload:
4763             # Get the BDMs early so we can pass them into versioned
4764             # notifications since _shelve_offload_instance needs the
4765             # BDMs anyway.
4766             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4767                 context, instance.uuid)
4768         else:
4769             bdms = None
4770         compute_utils.notify_usage_exists(self.notifier, context, instance,
4771                                           current_period=True)
4772         self._notify_about_instance_usage(context, instance, 'shelve.start')
4773         compute_utils.notify_about_instance_action(context, instance,
4774                 self.host, action=fields.NotificationAction.SHELVE,
4775                 phase=fields.NotificationPhase.START, bdms=bdms)
4776 
4777         def update_task_state(task_state, expected_state=task_states.SHELVING):
4778             shelving_state_map = {
4779                     task_states.IMAGE_PENDING_UPLOAD:
4780                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4781                     task_states.IMAGE_UPLOADING:
4782                         task_states.SHELVING_IMAGE_UPLOADING,
4783                     task_states.SHELVING: task_states.SHELVING}
4784             task_state = shelving_state_map[task_state]
4785             expected_state = shelving_state_map[expected_state]
4786             instance.task_state = task_state
4787             instance.save(expected_task_state=expected_state)
4788         # Do not attempt a clean shutdown of a paused guest since some
4789         # hypervisors will fail the clean shutdown if the guest is not
4790         # running.
4791         if instance.power_state == power_state.PAUSED:
4792             clean_shutdown = False
4793         self._power_off_instance(context, instance, clean_shutdown)
4794         self.driver.snapshot(context, instance, image_id, update_task_state)
4795 
4796         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4797         instance.system_metadata['shelved_image_id'] = image_id
4798         instance.system_metadata['shelved_host'] = self.host
4799         instance.vm_state = vm_states.SHELVED
4800         instance.task_state = None
4801         if CONF.shelved_offload_time == 0:
4802             instance.task_state = task_states.SHELVING_OFFLOADING
4803         instance.power_state = self._get_power_state(context, instance)
4804         instance.save(expected_task_state=[
4805                 task_states.SHELVING,
4806                 task_states.SHELVING_IMAGE_UPLOADING])
4807 
4808         self._notify_about_instance_usage(context, instance, 'shelve.end')
4809         compute_utils.notify_about_instance_action(context, instance,
4810                 self.host, action=fields.NotificationAction.SHELVE,
4811                 phase=fields.NotificationPhase.END, bdms=bdms)
4812 
4813         if offload:
4814             self._shelve_offload_instance(context, instance,
4815                                           clean_shutdown=False, bdms=bdms)
4816 
4817     @wrap_exception()
4818     @reverts_task_state
4819     @wrap_instance_event(prefix='compute')
4820     @wrap_instance_fault
4821     def shelve_offload_instance(self, context, instance, clean_shutdown):
4822         """Remove a shelved instance from the hypervisor.
4823 
4824         This frees up those resources for use by other instances, but may lead
4825         to slower unshelve times for this instance.  This method is used by
4826         volume backed instances since restoring them doesn't involve the
4827         potentially large download of an image.
4828 
4829         :param context: request context
4830         :param instance: nova.objects.instance.Instance
4831         :param clean_shutdown: give the GuestOS a chance to stop
4832         """
4833 
4834         @utils.synchronized(instance.uuid)
4835         def do_shelve_offload_instance():
4836             self._shelve_offload_instance(context, instance, clean_shutdown)
4837         do_shelve_offload_instance()
4838 
4839     def _shelve_offload_instance(self, context, instance, clean_shutdown,
4840                                  bdms=None):
4841         LOG.info('Shelve offloading', instance=instance)
4842         if bdms is None:
4843             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4844                 context, instance.uuid)
4845         self._notify_about_instance_usage(context, instance,
4846                 'shelve_offload.start')
4847         compute_utils.notify_about_instance_action(context, instance,
4848                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4849                 phase=fields.NotificationPhase.START, bdms=bdms)
4850 
4851         self._power_off_instance(context, instance, clean_shutdown)
4852         current_power_state = self._get_power_state(context, instance)
4853 
4854         self.network_api.cleanup_instance_network_on_host(context, instance,
4855                                                           instance.host)
4856         network_info = self.network_api.get_instance_nw_info(context, instance)
4857 
4858         block_device_info = self._get_instance_block_device_info(context,
4859                                                                  instance,
4860                                                                  bdms=bdms)
4861         self.driver.destroy(context, instance, network_info,
4862                 block_device_info)
4863 
4864         # the instance is going to be removed from the host so we want to
4865         # terminate all the connections with the volume server and the host
4866         self._terminate_volume_connections(context, instance, bdms)
4867 
4868         instance.power_state = current_power_state
4869         # NOTE(mriedem): The vm_state has to be set before updating the
4870         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4871         # values cannot be nulled out until after updating the resource tracker
4872         # though.
4873         instance.vm_state = vm_states.SHELVED_OFFLOADED
4874         instance.task_state = None
4875         instance.save(expected_task_state=[task_states.SHELVING,
4876                                            task_states.SHELVING_OFFLOADING])
4877 
4878         # NOTE(ndipanov): Free resources from the resource tracker
4879         self._update_resource_tracker(context, instance)
4880 
4881         rt = self._get_resource_tracker()
4882         rt.delete_allocation_for_shelve_offloaded_instance(context, instance)
4883 
4884         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4885         # instance, so ensure any calls result in errors
4886         self._nil_out_instance_obj_host_and_node(instance)
4887         instance.save(expected_task_state=None)
4888 
4889         # TODO(melwitt): We should clean up instance console tokens here. The
4890         # instance has no host at this point and will need to establish a new
4891         # console connection in the future after it is unshelved.
4892         self._delete_scheduler_instance_info(context, instance.uuid)
4893         self._notify_about_instance_usage(context, instance,
4894                 'shelve_offload.end')
4895         compute_utils.notify_about_instance_action(context, instance,
4896                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4897                 phase=fields.NotificationPhase.END, bdms=bdms)
4898 
4899     @wrap_exception()
4900     @reverts_task_state
4901     @wrap_instance_event(prefix='compute')
4902     @wrap_instance_fault
4903     def unshelve_instance(self, context, instance, image,
4904                           filter_properties, node):
4905         """Unshelve the instance.
4906 
4907         :param context: request context
4908         :param instance: a nova.objects.instance.Instance object
4909         :param image: an image to build from.  If None we assume a
4910             volume backed instance.
4911         :param filter_properties: dict containing limits, retry info etc.
4912         :param node: target compute node
4913         """
4914         if filter_properties is None:
4915             filter_properties = {}
4916 
4917         @utils.synchronized(instance.uuid)
4918         def do_unshelve_instance():
4919             self._unshelve_instance(context, instance, image,
4920                                     filter_properties, node)
4921         do_unshelve_instance()
4922 
4923     def _unshelve_instance_key_scrub(self, instance):
4924         """Remove data from the instance that may cause side effects."""
4925         cleaned_keys = dict(
4926                 key_data=instance.key_data,
4927                 auto_disk_config=instance.auto_disk_config)
4928         instance.key_data = None
4929         instance.auto_disk_config = False
4930         return cleaned_keys
4931 
4932     def _unshelve_instance_key_restore(self, instance, keys):
4933         """Restore previously scrubbed keys before saving the instance."""
4934         instance.update(keys)
4935 
4936     def _unshelve_instance(self, context, instance, image, filter_properties,
4937                            node):
4938         LOG.info('Unshelving', instance=instance)
4939         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4940                 context, instance.uuid)
4941 
4942         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4943         compute_utils.notify_about_instance_action(context, instance,
4944                 self.host, action=fields.NotificationAction.UNSHELVE,
4945                 phase=fields.NotificationPhase.START, bdms=bdms)
4946 
4947         instance.task_state = task_states.SPAWNING
4948         instance.save()
4949 
4950         block_device_info = self._prep_block_device(context, instance, bdms)
4951         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4952 
4953         if node is None:
4954             node = self._get_nodename(instance)
4955 
4956         rt = self._get_resource_tracker()
4957         limits = filter_properties.get('limits', {})
4958 
4959         allocations = self.reportclient.get_allocations_for_consumer(
4960             context, instance.uuid)
4961 
4962         shelved_image_ref = instance.image_ref
4963         if image:
4964             instance.image_ref = image['id']
4965             image_meta = objects.ImageMeta.from_dict(image)
4966         else:
4967             image_meta = objects.ImageMeta.from_dict(
4968                 utils.get_image_from_system_metadata(
4969                     instance.system_metadata))
4970 
4971         self.network_api.setup_instance_network_on_host(context, instance,
4972                                                         self.host)
4973         network_info = self.network_api.get_instance_nw_info(context, instance)
4974         try:
4975             with rt.instance_claim(context, instance, node, limits):
4976                 self.driver.spawn(context, instance, image_meta,
4977                                   injected_files=[],
4978                                   admin_password=None,
4979                                   allocations=allocations,
4980                                   network_info=network_info,
4981                                   block_device_info=block_device_info)
4982         except Exception:
4983             with excutils.save_and_reraise_exception(logger=LOG):
4984                 LOG.exception('Instance failed to spawn',
4985                               instance=instance)
4986                 # Cleanup allocations created by the scheduler on this host
4987                 # since we failed to spawn the instance. We do this both if
4988                 # the instance claim failed with ComputeResourcesUnavailable
4989                 # or if we did claim but the spawn failed, because aborting the
4990                 # instance claim will not remove the allocations.
4991                 rt.reportclient.delete_allocation_for_instance(context,
4992                                                                instance.uuid)
4993                 # FIXME: Umm, shouldn't we be rolling back port bindings too?
4994                 self._terminate_volume_connections(context, instance, bdms)
4995                 # The reverts_task_state decorator on unshelve_instance will
4996                 # eventually save these updates.
4997                 self._nil_out_instance_obj_host_and_node(instance)
4998 
4999         if image:
5000             instance.image_ref = shelved_image_ref
5001             self._delete_snapshot_of_shelved_instance(context, instance,
5002                                                       image['id'])
5003 
5004         self._unshelve_instance_key_restore(instance, scrubbed_keys)
5005         self._update_instance_after_spawn(context, instance)
5006         # Delete system_metadata for a shelved instance
5007         compute_utils.remove_shelved_keys_from_system_metadata(instance)
5008 
5009         instance.save(expected_task_state=task_states.SPAWNING)
5010         self._update_scheduler_instance_info(context, instance)
5011         self._notify_about_instance_usage(context, instance, 'unshelve.end')
5012         compute_utils.notify_about_instance_action(context, instance,
5013                 self.host, action=fields.NotificationAction.UNSHELVE,
5014                 phase=fields.NotificationPhase.END, bdms=bdms)
5015 
5016     @messaging.expected_exceptions(NotImplementedError)
5017     @wrap_instance_fault
5018     def reset_network(self, context, instance):
5019         """Reset networking on the given instance."""
5020         LOG.debug('Reset network', instance=instance)
5021         self.driver.reset_network(instance)
5022 
5023     def _inject_network_info(self, context, instance, network_info):
5024         """Inject network info for the given instance."""
5025         LOG.debug('Inject network info', instance=instance)
5026         LOG.debug('network_info to inject: |%s|', network_info,
5027                   instance=instance)
5028 
5029         self.driver.inject_network_info(instance,
5030                                         network_info)
5031 
5032     @wrap_instance_fault
5033     def inject_network_info(self, context, instance):
5034         """Inject network info, but don't return the info."""
5035         network_info = self.network_api.get_instance_nw_info(context, instance)
5036         self._inject_network_info(context, instance, network_info)
5037 
5038     @messaging.expected_exceptions(NotImplementedError,
5039                                    exception.ConsoleNotAvailable,
5040                                    exception.InstanceNotFound)
5041     @wrap_exception()
5042     @wrap_instance_fault
5043     def get_console_output(self, context, instance, tail_length):
5044         """Send the console output for the given instance."""
5045         context = context.elevated()
5046         LOG.info("Get console output", instance=instance)
5047         output = self.driver.get_console_output(context, instance)
5048 
5049         if type(output) is six.text_type:
5050             output = six.b(output)
5051 
5052         if tail_length is not None:
5053             output = self._tail_log(output, tail_length)
5054 
5055         return output.decode('ascii', 'replace')
5056 
5057     def _tail_log(self, log, length):
5058         try:
5059             length = int(length)
5060         except ValueError:
5061             length = 0
5062 
5063         if length == 0:
5064             return b''
5065         else:
5066             return b'\n'.join(log.split(b'\n')[-int(length):])
5067 
5068     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5069                                    exception.InstanceNotReady,
5070                                    exception.InstanceNotFound,
5071                                    exception.ConsoleTypeUnavailable,
5072                                    NotImplementedError)
5073     @wrap_exception()
5074     @wrap_instance_fault
5075     def get_vnc_console(self, context, console_type, instance):
5076         """Return connection information for a vnc console."""
5077         context = context.elevated()
5078         LOG.debug("Getting vnc console", instance=instance)
5079 
5080         if not CONF.vnc.enabled:
5081             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5082 
5083         if console_type == 'novnc':
5084             # For essex, novncproxy_base_url must include the full path
5085             # including the html file (like http://myhost/vnc_auto.html)
5086             access_url_base = CONF.vnc.novncproxy_base_url
5087         elif console_type == 'xvpvnc':
5088             access_url_base = CONF.vnc.xvpvncproxy_base_url
5089         else:
5090             raise exception.ConsoleTypeInvalid(console_type=console_type)
5091 
5092         try:
5093             # Retrieve connect info from driver, and then decorate with our
5094             # access info token
5095             console = self.driver.get_vnc_console(context, instance)
5096             console_auth = objects.ConsoleAuthToken(
5097                 context=context,
5098                 console_type=console_type,
5099                 host=console.host,
5100                 port=console.port,
5101                 internal_access_path=console.internal_access_path,
5102                 instance_uuid=instance.uuid,
5103                 access_url_base=access_url_base,
5104             )
5105             console_auth.authorize(CONF.consoleauth.token_ttl)
5106             connect_info = console.get_connection_info(
5107                 console_auth.token, console_auth.access_url)
5108 
5109         except exception.InstanceNotFound:
5110             if instance.vm_state != vm_states.BUILDING:
5111                 raise
5112             raise exception.InstanceNotReady(instance_id=instance.uuid)
5113 
5114         return connect_info
5115 
5116     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5117                                    exception.InstanceNotReady,
5118                                    exception.InstanceNotFound,
5119                                    exception.ConsoleTypeUnavailable,
5120                                    NotImplementedError)
5121     @wrap_exception()
5122     @wrap_instance_fault
5123     def get_spice_console(self, context, console_type, instance):
5124         """Return connection information for a spice console."""
5125         context = context.elevated()
5126         LOG.debug("Getting spice console", instance=instance)
5127 
5128         if not CONF.spice.enabled:
5129             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5130 
5131         if console_type != 'spice-html5':
5132             raise exception.ConsoleTypeInvalid(console_type=console_type)
5133 
5134         try:
5135             # Retrieve connect info from driver, and then decorate with our
5136             # access info token
5137             console = self.driver.get_spice_console(context, instance)
5138             console_auth = objects.ConsoleAuthToken(
5139                 context=context,
5140                 console_type=console_type,
5141                 host=console.host,
5142                 port=console.port,
5143                 internal_access_path=console.internal_access_path,
5144                 instance_uuid=instance.uuid,
5145                 access_url_base=CONF.spice.html5proxy_base_url,
5146             )
5147             console_auth.authorize(CONF.consoleauth.token_ttl)
5148             connect_info = console.get_connection_info(
5149                 console_auth.token, console_auth.access_url)
5150 
5151         except exception.InstanceNotFound:
5152             if instance.vm_state != vm_states.BUILDING:
5153                 raise
5154             raise exception.InstanceNotReady(instance_id=instance.uuid)
5155 
5156         return connect_info
5157 
5158     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5159                                    exception.InstanceNotReady,
5160                                    exception.InstanceNotFound,
5161                                    exception.ConsoleTypeUnavailable,
5162                                    NotImplementedError)
5163     @wrap_exception()
5164     @wrap_instance_fault
5165     def get_rdp_console(self, context, console_type, instance):
5166         """Return connection information for a RDP console."""
5167         context = context.elevated()
5168         LOG.debug("Getting RDP console", instance=instance)
5169 
5170         if not CONF.rdp.enabled:
5171             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5172 
5173         if console_type != 'rdp-html5':
5174             raise exception.ConsoleTypeInvalid(console_type=console_type)
5175 
5176         try:
5177             # Retrieve connect info from driver, and then decorate with our
5178             # access info token
5179             console = self.driver.get_rdp_console(context, instance)
5180             console_auth = objects.ConsoleAuthToken(
5181                 context=context,
5182                 console_type=console_type,
5183                 host=console.host,
5184                 port=console.port,
5185                 internal_access_path=console.internal_access_path,
5186                 instance_uuid=instance.uuid,
5187                 access_url_base=CONF.rdp.html5_proxy_base_url,
5188             )
5189             console_auth.authorize(CONF.consoleauth.token_ttl)
5190             connect_info = console.get_connection_info(
5191                 console_auth.token, console_auth.access_url)
5192 
5193         except exception.InstanceNotFound:
5194             if instance.vm_state != vm_states.BUILDING:
5195                 raise
5196             raise exception.InstanceNotReady(instance_id=instance.uuid)
5197 
5198         return connect_info
5199 
5200     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5201                                    exception.InstanceNotReady,
5202                                    exception.InstanceNotFound,
5203                                    exception.ConsoleTypeUnavailable,
5204                                    NotImplementedError)
5205     @wrap_exception()
5206     @wrap_instance_fault
5207     def get_mks_console(self, context, console_type, instance):
5208         """Return connection information for a MKS console."""
5209         context = context.elevated()
5210         LOG.debug("Getting MKS console", instance=instance)
5211 
5212         if not CONF.mks.enabled:
5213             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5214 
5215         if console_type != 'webmks':
5216             raise exception.ConsoleTypeInvalid(console_type=console_type)
5217 
5218         try:
5219             # Retrieve connect info from driver, and then decorate with our
5220             # access info token
5221             console = self.driver.get_mks_console(context, instance)
5222             console_auth = objects.ConsoleAuthToken(
5223                 context=context,
5224                 console_type=console_type,
5225                 host=console.host,
5226                 port=console.port,
5227                 internal_access_path=console.internal_access_path,
5228                 instance_uuid=instance.uuid,
5229                 access_url_base=CONF.mks.mksproxy_base_url,
5230             )
5231             console_auth.authorize(CONF.consoleauth.token_ttl)
5232             connect_info = console.get_connection_info(
5233                 console_auth.token, console_auth.access_url)
5234 
5235         except exception.InstanceNotFound:
5236             if instance.vm_state != vm_states.BUILDING:
5237                 raise
5238             raise exception.InstanceNotReady(instance_id=instance.uuid)
5239 
5240         return connect_info
5241 
5242     @messaging.expected_exceptions(
5243         exception.ConsoleTypeInvalid,
5244         exception.InstanceNotReady,
5245         exception.InstanceNotFound,
5246         exception.ConsoleTypeUnavailable,
5247         exception.SocketPortRangeExhaustedException,
5248         exception.ImageSerialPortNumberInvalid,
5249         exception.ImageSerialPortNumberExceedFlavorValue,
5250         NotImplementedError)
5251     @wrap_exception()
5252     @wrap_instance_fault
5253     def get_serial_console(self, context, console_type, instance):
5254         """Returns connection information for a serial console."""
5255 
5256         LOG.debug("Getting serial console", instance=instance)
5257 
5258         if not CONF.serial_console.enabled:
5259             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5260 
5261         context = context.elevated()
5262 
5263         try:
5264             # Retrieve connect info from driver, and then decorate with our
5265             # access info token
5266             console = self.driver.get_serial_console(context, instance)
5267             console_auth = objects.ConsoleAuthToken(
5268                 context=context,
5269                 console_type=console_type,
5270                 host=console.host,
5271                 port=console.port,
5272                 internal_access_path=console.internal_access_path,
5273                 instance_uuid=instance.uuid,
5274                 access_url_base=CONF.serial_console.base_url,
5275             )
5276             console_auth.authorize(CONF.consoleauth.token_ttl)
5277             connect_info = console.get_connection_info(
5278                 console_auth.token, console_auth.access_url)
5279 
5280         except exception.InstanceNotFound:
5281             if instance.vm_state != vm_states.BUILDING:
5282                 raise
5283             raise exception.InstanceNotReady(instance_id=instance.uuid)
5284 
5285         return connect_info
5286 
5287     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5288                                    exception.InstanceNotReady,
5289                                    exception.InstanceNotFound)
5290     @wrap_exception()
5291     @wrap_instance_fault
5292     def validate_console_port(self, ctxt, instance, port, console_type):
5293         if console_type == "spice-html5":
5294             console_info = self.driver.get_spice_console(ctxt, instance)
5295         elif console_type == "rdp-html5":
5296             console_info = self.driver.get_rdp_console(ctxt, instance)
5297         elif console_type == "serial":
5298             console_info = self.driver.get_serial_console(ctxt, instance)
5299         elif console_type == "webmks":
5300             console_info = self.driver.get_mks_console(ctxt, instance)
5301         else:
5302             console_info = self.driver.get_vnc_console(ctxt, instance)
5303 
5304         return console_info.port == port
5305 
5306     @wrap_exception()
5307     @reverts_task_state
5308     @wrap_instance_fault
5309     def reserve_block_device_name(self, context, instance, device,
5310                                   volume_id, disk_bus, device_type, tag,
5311                                   multiattach):
5312         if (tag and not
5313                 self.driver.capabilities.get('supports_tagged_attach_volume',
5314                                              False)):
5315             raise exception.VolumeTaggedAttachNotSupported()
5316 
5317         if (multiattach and not
5318                 self.driver.capabilities.get('supports_multiattach', False)):
5319             raise exception.MultiattachNotSupportedByVirtDriver(
5320                 volume_id=volume_id)
5321 
5322         @utils.synchronized(instance.uuid)
5323         def do_reserve():
5324             bdms = (
5325                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5326                     context, instance.uuid))
5327 
5328             # NOTE(ndipanov): We need to explicitly set all the fields on the
5329             #                 object so that obj_load_attr does not fail
5330             new_bdm = objects.BlockDeviceMapping(
5331                     context=context,
5332                     source_type='volume', destination_type='volume',
5333                     instance_uuid=instance.uuid, boot_index=None,
5334                     volume_id=volume_id,
5335                     device_name=device, guest_format=None,
5336                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5337 
5338             new_bdm.device_name = self._get_device_name_for_instance(
5339                     instance, bdms, new_bdm)
5340 
5341             # NOTE(vish): create bdm here to avoid race condition
5342             new_bdm.create()
5343             return new_bdm
5344 
5345         return do_reserve()
5346 
5347     @wrap_exception()
5348     @wrap_instance_event(prefix='compute')
5349     @wrap_instance_fault
5350     def attach_volume(self, context, instance, bdm):
5351         """Attach a volume to an instance."""
5352         driver_bdm = driver_block_device.convert_volume(bdm)
5353 
5354         @utils.synchronized(instance.uuid)
5355         def do_attach_volume(context, instance, driver_bdm):
5356             try:
5357                 return self._attach_volume(context, instance, driver_bdm)
5358             except Exception:
5359                 with excutils.save_and_reraise_exception():
5360                     bdm.destroy()
5361 
5362         do_attach_volume(context, instance, driver_bdm)
5363 
5364     def _attach_volume(self, context, instance, bdm):
5365         context = context.elevated()
5366         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5367                  {'volume_id': bdm.volume_id,
5368                   'mountpoint': bdm['mount_device']},
5369                  instance=instance)
5370         compute_utils.notify_about_volume_attach_detach(
5371             context, instance, self.host,
5372             action=fields.NotificationAction.VOLUME_ATTACH,
5373             phase=fields.NotificationPhase.START,
5374             volume_id=bdm.volume_id)
5375         try:
5376             bdm.attach(context, instance, self.volume_api, self.driver,
5377                        do_driver_attach=True)
5378         except Exception as e:
5379             with excutils.save_and_reraise_exception():
5380                 LOG.exception("Failed to attach %(volume_id)s "
5381                               "at %(mountpoint)s",
5382                               {'volume_id': bdm.volume_id,
5383                                'mountpoint': bdm['mount_device']},
5384                               instance=instance)
5385                 if bdm['attachment_id']:
5386                     self.volume_api.attachment_delete(context,
5387                                                       bdm['attachment_id'])
5388                 else:
5389                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5390                 compute_utils.notify_about_volume_attach_detach(
5391                     context, instance, self.host,
5392                     action=fields.NotificationAction.VOLUME_ATTACH,
5393                     phase=fields.NotificationPhase.ERROR,
5394                     exception=e,
5395                     volume_id=bdm.volume_id)
5396 
5397         info = {'volume_id': bdm.volume_id}
5398         self._notify_about_instance_usage(
5399             context, instance, "volume.attach", extra_usage_info=info)
5400         compute_utils.notify_about_volume_attach_detach(
5401             context, instance, self.host,
5402             action=fields.NotificationAction.VOLUME_ATTACH,
5403             phase=fields.NotificationPhase.END,
5404             volume_id=bdm.volume_id)
5405 
5406     def _notify_volume_usage_detach(self, context, instance, bdm):
5407         if CONF.volume_usage_poll_interval <= 0:
5408             return
5409 
5410         vol_stats = []
5411         mp = bdm.device_name
5412         # Handle bootable volumes which will not contain /dev/
5413         if '/dev/' in mp:
5414             mp = mp[5:]
5415         try:
5416             vol_stats = self.driver.block_stats(instance, mp)
5417         except NotImplementedError:
5418             return
5419 
5420         LOG.debug("Updating volume usage cache with totals", instance=instance)
5421         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5422         vol_usage = objects.VolumeUsage(context)
5423         vol_usage.volume_id = bdm.volume_id
5424         vol_usage.instance_uuid = instance.uuid
5425         vol_usage.project_id = instance.project_id
5426         vol_usage.user_id = instance.user_id
5427         vol_usage.availability_zone = instance.availability_zone
5428         vol_usage.curr_reads = rd_req
5429         vol_usage.curr_read_bytes = rd_bytes
5430         vol_usage.curr_writes = wr_req
5431         vol_usage.curr_write_bytes = wr_bytes
5432         vol_usage.save(update_totals=True)
5433         self.notifier.info(context, 'volume.usage',
5434                            compute_utils.usage_volume_info(vol_usage))
5435 
5436     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5437                        attachment_id=None):
5438         """Detach a volume from an instance.
5439 
5440         :param context: security context
5441         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5442         :param instance: the Instance object to detach the volume from
5443         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5444                             as deleted. Disabling this is useful for operations
5445                             like rebuild, when we don't want to destroy BDM
5446         :param attachment_id: The volume attachment_id for the given instance
5447                               and volume.
5448         """
5449         volume_id = bdm.volume_id
5450         compute_utils.notify_about_volume_attach_detach(
5451             context, instance, self.host,
5452             action=fields.NotificationAction.VOLUME_DETACH,
5453             phase=fields.NotificationPhase.START,
5454             volume_id=volume_id)
5455 
5456         self._notify_volume_usage_detach(context, instance, bdm)
5457 
5458         LOG.info('Detaching volume %(volume_id)s',
5459                  {'volume_id': volume_id}, instance=instance)
5460 
5461         driver_bdm = driver_block_device.convert_volume(bdm)
5462         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5463                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5464 
5465         info = dict(volume_id=volume_id)
5466         self._notify_about_instance_usage(
5467             context, instance, "volume.detach", extra_usage_info=info)
5468         compute_utils.notify_about_volume_attach_detach(
5469             context, instance, self.host,
5470             action=fields.NotificationAction.VOLUME_DETACH,
5471             phase=fields.NotificationPhase.END,
5472             volume_id=volume_id)
5473 
5474         if 'tag' in bdm and bdm.tag:
5475             self._delete_disk_metadata(instance, bdm)
5476         if destroy_bdm:
5477             bdm.destroy()
5478 
5479     def _delete_disk_metadata(self, instance, bdm):
5480         for device in instance.device_metadata.devices:
5481             if isinstance(device, objects.DiskMetadata):
5482                 if 'serial' in device:
5483                     if device.serial == bdm.volume_id:
5484                         instance.device_metadata.devices.remove(device)
5485                         instance.save()
5486                         break
5487                 else:
5488                     # NOTE(artom) We log the entire device object because all
5489                     # fields are nullable and may not be set
5490                     LOG.warning('Unable to determine whether to clean up '
5491                                 'device metadata for disk %s', device,
5492                                 instance=instance)
5493 
5494     @wrap_exception()
5495     @wrap_instance_event(prefix='compute')
5496     @wrap_instance_fault
5497     def detach_volume(self, context, volume_id, instance, attachment_id):
5498         """Detach a volume from an instance.
5499 
5500         :param context: security context
5501         :param volume_id: the volume id
5502         :param instance: the Instance object to detach the volume from
5503         :param attachment_id: The volume attachment_id for the given instance
5504                               and volume.
5505 
5506         """
5507         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5508                 context, volume_id, instance.uuid)
5509         self._detach_volume(context, bdm, instance,
5510                             attachment_id=attachment_id)
5511 
5512     def _init_volume_connection(self, context, new_volume,
5513                                 old_volume_id, connector, bdm,
5514                                 new_attachment_id, mountpoint):
5515         new_volume_id = new_volume['id']
5516         if new_attachment_id is None:
5517             # We're dealing with an old-style attachment so initialize the
5518             # connection so we can get the connection_info.
5519             new_cinfo = self.volume_api.initialize_connection(context,
5520                                                               new_volume_id,
5521                                                               connector)
5522         else:
5523             # Check for multiattach on the new volume and if True, check to
5524             # see if the virt driver supports multiattach.
5525             # TODO(mriedem): This is copied from DriverVolumeBlockDevice
5526             # and should be consolidated into some common code at some point.
5527             vol_multiattach = new_volume.get('multiattach', False)
5528             virt_multiattach = self.driver.capabilities.get(
5529                 'supports_multiattach', False)
5530             if vol_multiattach and not virt_multiattach:
5531                 raise exception.MultiattachNotSupportedByVirtDriver(
5532                     volume_id=new_volume_id)
5533 
5534             # This is a new style attachment and the API created the new
5535             # volume attachment and passed the id to the compute over RPC.
5536             # At this point we need to update the new volume attachment with
5537             # the host connector, which will give us back the new attachment
5538             # connection_info.
5539             new_cinfo = self.volume_api.attachment_update(
5540                 context, new_attachment_id, connector,
5541                 mountpoint)['connection_info']
5542 
5543             if vol_multiattach:
5544                 # This will be used by the volume driver to determine the
5545                 # proper disk configuration.
5546                 new_cinfo['multiattach'] = True
5547 
5548         old_cinfo = jsonutils.loads(bdm['connection_info'])
5549         if old_cinfo and 'serial' not in old_cinfo:
5550             old_cinfo['serial'] = old_volume_id
5551         # NOTE(lyarwood): serial is not always present in the returned
5552         # connection_info so set it if it is missing as we do in
5553         # DriverVolumeBlockDevice.attach().
5554         if 'serial' not in new_cinfo:
5555             new_cinfo['serial'] = new_volume_id
5556         return (old_cinfo, new_cinfo)
5557 
5558     def _swap_volume(self, context, instance, bdm, connector,
5559                      old_volume_id, new_volume, resize_to,
5560                      new_attachment_id, is_cinder_migration):
5561         new_volume_id = new_volume['id']
5562         mountpoint = bdm['device_name']
5563         failed = False
5564         new_cinfo = None
5565         try:
5566             old_cinfo, new_cinfo = self._init_volume_connection(
5567                 context, new_volume, old_volume_id, connector,
5568                 bdm, new_attachment_id, mountpoint)
5569             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5570             # currently implementing swap_volume, will modify the contents of
5571             # new_cinfo when connect_volume is called. This is then saved to
5572             # the BDM in swap_volume for future use outside of this flow.
5573             msg = ("swap_volume: Calling driver volume swap with "
5574                    "connection infos: new: %(new_cinfo)s; "
5575                    "old: %(old_cinfo)s" %
5576                    {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo})
5577             # Both new and old info might contain password
5578             LOG.debug(strutils.mask_password(msg), instance=instance)
5579 
5580             self.driver.swap_volume(context, old_cinfo, new_cinfo, instance,
5581                                     mountpoint, resize_to)
5582             if new_attachment_id:
5583                 self.volume_api.attachment_complete(context, new_attachment_id)
5584             msg = ("swap_volume: Driver volume swap returned, new "
5585                    "connection_info is now : %(new_cinfo)s" %
5586                    {'new_cinfo': new_cinfo})
5587             LOG.debug(strutils.mask_password(msg))
5588         except Exception as ex:
5589             failed = True
5590             with excutils.save_and_reraise_exception():
5591                 compute_utils.notify_about_volume_swap(
5592                     context, instance, self.host,
5593                     fields.NotificationPhase.ERROR,
5594                     old_volume_id, new_volume_id, ex)
5595                 if new_cinfo:
5596                     msg = ("Failed to swap volume %(old_volume_id)s "
5597                            "for %(new_volume_id)s")
5598                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5599                                         'new_volume_id': new_volume_id},
5600                                   instance=instance)
5601                 else:
5602                     msg = ("Failed to connect to volume %(volume_id)s "
5603                            "with volume at %(mountpoint)s")
5604                     LOG.exception(msg, {'volume_id': new_volume_id,
5605                                         'mountpoint': bdm['device_name']},
5606                                   instance=instance)
5607 
5608                 # The API marked the volume as 'detaching' for the old volume
5609                 # so we need to roll that back so the volume goes back to
5610                 # 'in-use' state.
5611                 self.volume_api.roll_detaching(context, old_volume_id)
5612 
5613                 if new_attachment_id is None:
5614                     # The API reserved the new volume so it would be in
5615                     # 'attaching' status, so we need to unreserve it so it
5616                     # goes back to 'available' status.
5617                     self.volume_api.unreserve_volume(context, new_volume_id)
5618                 else:
5619                     # This is a new style attachment for the new volume, which
5620                     # was created in the API. We just need to delete it here
5621                     # to put the new volume back into 'available' status.
5622                     self.volume_api.attachment_delete(
5623                         context, new_attachment_id)
5624         finally:
5625             # TODO(mriedem): This finally block is terribly confusing and is
5626             # trying to do too much. We should consider removing the finally
5627             # block and move whatever needs to happen on success and failure
5628             # into the blocks above for clarity, even if it means a bit of
5629             # redundant code.
5630             conn_volume = new_volume_id if failed else old_volume_id
5631             if new_cinfo:
5632                 LOG.debug("swap_volume: removing Cinder connection "
5633                           "for volume %(volume)s", {'volume': conn_volume},
5634                           instance=instance)
5635                 if bdm.attachment_id is None:
5636                     # This is the pre-3.44 flow for new-style volume
5637                     # attachments so just terminate the connection.
5638                     self.volume_api.terminate_connection(context,
5639                                                          conn_volume,
5640                                                          connector)
5641                 else:
5642                     # This is a new style volume attachment. If we failed, then
5643                     # the new attachment was already deleted above in the
5644                     # exception block and we have nothing more to do here. If
5645                     # swap_volume was successful in the driver, then we need to
5646                     # "detach" the original attachment by deleting it.
5647                     if not failed:
5648                         self.volume_api.attachment_delete(
5649                             context, bdm.attachment_id)
5650 
5651             # Need to make some decisions based on whether this was
5652             # a Cinder initiated migration or not. The callback to
5653             # migration completion isn't needed in the case of a
5654             # nova initiated simple swap of two volume
5655             # "volume-update" call so skip that. The new attachment
5656             # scenarios will give us a new attachment record and
5657             # that's what we want.
5658             if bdm.attachment_id and not is_cinder_migration:
5659                 # we don't callback to cinder
5660                 comp_ret = {'save_volume_id': new_volume_id}
5661             else:
5662                 # NOTE(lyarwood): The following call to
5663                 # os-migrate-volume-completion returns a dict containing
5664                 # save_volume_id, this volume id has two possible values :
5665                 # 1. old_volume_id if we are migrating (retyping) volumes
5666                 # 2. new_volume_id if we are swapping between two existing
5667                 #    volumes
5668                 # This volume id is later used to update the volume_id and
5669                 # connection_info['serial'] of the BDM.
5670                 comp_ret = self.volume_api.migrate_volume_completion(
5671                                                           context,
5672                                                           old_volume_id,
5673                                                           new_volume_id,
5674                                                           error=failed)
5675                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5676                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5677                           instance=instance)
5678 
5679         return (comp_ret, new_cinfo)
5680 
5681     @wrap_exception()
5682     @wrap_instance_event(prefix='compute')
5683     @wrap_instance_fault
5684     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
5685                     new_attachment_id):
5686         """Swap volume for an instance."""
5687         context = context.elevated()
5688 
5689         compute_utils.notify_about_volume_swap(
5690             context, instance, self.host,
5691             fields.NotificationPhase.START,
5692             old_volume_id, new_volume_id)
5693 
5694         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5695                 context, old_volume_id, instance.uuid)
5696         connector = self.driver.get_volume_connector(instance)
5697 
5698         resize_to = 0
5699         old_volume = self.volume_api.get(context, old_volume_id)
5700         # Yes this is a tightly-coupled state check of what's going on inside
5701         # cinder, but we need this while we still support old (v1/v2) and
5702         # new style attachments (v3.44). Once we drop support for old style
5703         # attachments we could think about cleaning up the cinder-initiated
5704         # swap volume API flows.
5705         is_cinder_migration = (
5706             True if old_volume['status'] in ('retyping',
5707                                              'migrating') else False)
5708         old_vol_size = old_volume['size']
5709         new_volume = self.volume_api.get(context, new_volume_id)
5710         new_vol_size = new_volume['size']
5711         if new_vol_size > old_vol_size:
5712             resize_to = new_vol_size
5713 
5714         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5715                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5716                  instance=instance)
5717         comp_ret, new_cinfo = self._swap_volume(context,
5718                                                 instance,
5719                                                 bdm,
5720                                                 connector,
5721                                                 old_volume_id,
5722                                                 new_volume,
5723                                                 resize_to,
5724                                                 new_attachment_id,
5725                                                 is_cinder_migration)
5726 
5727         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5728         # correct volume_id returned by Cinder.
5729         save_volume_id = comp_ret['save_volume_id']
5730         new_cinfo['serial'] = save_volume_id
5731         values = {
5732             'connection_info': jsonutils.dumps(new_cinfo),
5733             'source_type': 'volume',
5734             'destination_type': 'volume',
5735             'snapshot_id': None,
5736             'volume_id': save_volume_id,
5737             'no_device': None}
5738 
5739         if resize_to:
5740             values['volume_size'] = resize_to
5741 
5742         if new_attachment_id is not None:
5743             # This was a volume swap for a new-style attachment so we
5744             # need to update the BDM attachment_id for the new attachment.
5745             values['attachment_id'] = new_attachment_id
5746 
5747         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5748                   "%(updates)s", {'volume_id': bdm.volume_id,
5749                                   'updates': values},
5750                   instance=instance)
5751         bdm.update(values)
5752         bdm.save()
5753 
5754         compute_utils.notify_about_volume_swap(
5755             context, instance, self.host,
5756             fields.NotificationPhase.END,
5757             old_volume_id, new_volume_id)
5758 
5759     @wrap_exception()
5760     def remove_volume_connection(self, context, volume_id, instance):
5761         """Remove the volume connection on this host
5762 
5763         Detach the volume from this instance on this host, and if this is
5764         the cinder v2 flow, call cinder to terminate the connection.
5765         """
5766         try:
5767             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5768                     context, volume_id, instance.uuid)
5769             driver_bdm = driver_block_device.convert_volume(bdm)
5770             driver_bdm.driver_detach(context, instance,
5771                                      self.volume_api, self.driver)
5772             if bdm.attachment_id is None:
5773                 # cinder v2 api flow
5774                 connector = self.driver.get_volume_connector(instance)
5775                 self.volume_api.terminate_connection(context, volume_id,
5776                                                      connector)
5777         except exception.NotFound:
5778             pass
5779 
5780     @wrap_exception()
5781     @wrap_instance_event(prefix='compute')
5782     @wrap_instance_fault
5783     def attach_interface(self, context, instance, network_id, port_id,
5784                          requested_ip, tag):
5785         """Use hotplug to add an network adapter to an instance."""
5786         if not self.driver.capabilities.get('supports_attach_interface',
5787                                             False):
5788             raise exception.AttachInterfaceNotSupported(
5789                 instance_uuid=instance.uuid)
5790         if (tag and not
5791             self.driver.capabilities.get('supports_tagged_attach_interface',
5792                                          False)):
5793             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5794 
5795         compute_utils.notify_about_instance_action(
5796             context, instance, self.host,
5797             action=fields.NotificationAction.INTERFACE_ATTACH,
5798             phase=fields.NotificationPhase.START)
5799 
5800         bind_host_id = self.driver.network_binding_host_id(context, instance)
5801         network_info = self.network_api.allocate_port_for_instance(
5802             context, instance, port_id, network_id, requested_ip,
5803             bind_host_id=bind_host_id, tag=tag)
5804         if len(network_info) != 1:
5805             LOG.error('allocate_port_for_instance returned %(ports)s '
5806                       'ports', {'ports': len(network_info)})
5807             # TODO(elod.illes): an instance.interface_attach.error notification
5808             # should be sent here
5809             raise exception.InterfaceAttachFailed(
5810                     instance_uuid=instance.uuid)
5811         image_meta = objects.ImageMeta.from_instance(instance)
5812 
5813         try:
5814             self.driver.attach_interface(context, instance, image_meta,
5815                                          network_info[0])
5816         except exception.NovaException as ex:
5817             port_id = network_info[0].get('id')
5818             LOG.warning("attach interface failed , try to deallocate "
5819                         "port %(port_id)s, reason: %(msg)s",
5820                         {'port_id': port_id, 'msg': ex},
5821                         instance=instance)
5822             try:
5823                 self.network_api.deallocate_port_for_instance(
5824                     context, instance, port_id)
5825             except Exception:
5826                 LOG.warning("deallocate port %(port_id)s failed",
5827                             {'port_id': port_id}, instance=instance)
5828 
5829             compute_utils.notify_about_instance_action(
5830                 context, instance, self.host,
5831                 action=fields.NotificationAction.INTERFACE_ATTACH,
5832                 phase=fields.NotificationPhase.ERROR,
5833                 exception=ex)
5834 
5835             raise exception.InterfaceAttachFailed(
5836                 instance_uuid=instance.uuid)
5837 
5838         compute_utils.notify_about_instance_action(
5839             context, instance, self.host,
5840             action=fields.NotificationAction.INTERFACE_ATTACH,
5841             phase=fields.NotificationPhase.END)
5842 
5843         return network_info[0]
5844 
5845     @wrap_exception()
5846     @wrap_instance_event(prefix='compute')
5847     @wrap_instance_fault
5848     def detach_interface(self, context, instance, port_id):
5849         """Detach a network adapter from an instance."""
5850         network_info = instance.info_cache.network_info
5851         condemned = None
5852         for vif in network_info:
5853             if vif['id'] == port_id:
5854                 condemned = vif
5855                 break
5856         if condemned is None:
5857             raise exception.PortNotFound(_("Port %s is not "
5858                                            "attached") % port_id)
5859 
5860         compute_utils.notify_about_instance_action(
5861             context, instance, self.host,
5862             action=fields.NotificationAction.INTERFACE_DETACH,
5863             phase=fields.NotificationPhase.START)
5864 
5865         try:
5866             self.driver.detach_interface(context, instance, condemned)
5867         except exception.NovaException as ex:
5868             # If the instance was deleted before the interface was detached,
5869             # just log it at debug.
5870             log_level = (logging.DEBUG
5871                          if isinstance(ex, exception.InstanceNotFound)
5872                          else logging.WARNING)
5873             LOG.log(log_level,
5874                     "Detach interface failed, port_id=%(port_id)s, reason: "
5875                     "%(msg)s", {'port_id': port_id, 'msg': ex},
5876                     instance=instance)
5877             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5878         else:
5879             try:
5880                 self.network_api.deallocate_port_for_instance(
5881                     context, instance, port_id)
5882             except Exception as ex:
5883                 with excutils.save_and_reraise_exception():
5884                     # Since this is a cast operation, log the failure for
5885                     # triage.
5886                     LOG.warning('Failed to deallocate port %(port_id)s '
5887                                 'for instance. Error: %(error)s',
5888                                 {'port_id': port_id, 'error': ex},
5889                                 instance=instance)
5890 
5891         compute_utils.notify_about_instance_action(
5892             context, instance, self.host,
5893             action=fields.NotificationAction.INTERFACE_DETACH,
5894             phase=fields.NotificationPhase.END)
5895 
5896     def _get_compute_info(self, context, host):
5897         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5898             context, host)
5899 
5900     @wrap_exception()
5901     def check_instance_shared_storage(self, ctxt, instance, data):
5902         """Check if the instance files are shared
5903 
5904         :param ctxt: security context
5905         :param instance: dict of instance data
5906         :param data: result of driver.check_instance_shared_storage_local
5907 
5908         Returns True if instance disks located on shared storage and
5909         False otherwise.
5910         """
5911         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5912 
5913     @wrap_exception()
5914     @wrap_instance_event(prefix='compute')
5915     @wrap_instance_fault
5916     def check_can_live_migrate_destination(self, ctxt, instance,
5917                                            block_migration, disk_over_commit):
5918         """Check if it is possible to execute live migration.
5919 
5920         This runs checks on the destination host, and then calls
5921         back to the source host to check the results.
5922 
5923         :param context: security context
5924         :param instance: dict of instance data
5925         :param block_migration: if true, prepare for block migration
5926                                 if None, calculate it in driver
5927         :param disk_over_commit: if true, allow disk over commit
5928                                  if None, ignore disk usage checking
5929         :returns: a dict containing migration info
5930         """
5931         src_compute_info = obj_base.obj_to_primitive(
5932             self._get_compute_info(ctxt, instance.host))
5933         dst_compute_info = obj_base.obj_to_primitive(
5934             self._get_compute_info(ctxt, CONF.host))
5935         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5936             instance, src_compute_info, dst_compute_info,
5937             block_migration, disk_over_commit)
5938         LOG.debug('destination check data is %s', dest_check_data)
5939         try:
5940             migrate_data = self.compute_rpcapi.\
5941                                 check_can_live_migrate_source(ctxt, instance,
5942                                                               dest_check_data)
5943         finally:
5944             self.driver.cleanup_live_migration_destination_check(ctxt,
5945                     dest_check_data)
5946         return migrate_data
5947 
5948     @wrap_exception()
5949     @wrap_instance_event(prefix='compute')
5950     @wrap_instance_fault
5951     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5952         """Check if it is possible to execute live migration.
5953 
5954         This checks if the live migration can succeed, based on the
5955         results from check_can_live_migrate_destination.
5956 
5957         :param ctxt: security context
5958         :param instance: dict of instance data
5959         :param dest_check_data: result of check_can_live_migrate_destination
5960         :returns: a dict containing migration info
5961         """
5962         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5963             ctxt, instance.uuid)
5964         is_volume_backed = compute_utils.is_volume_backed_instance(
5965             ctxt, instance, bdms)
5966         dest_check_data.is_volume_backed = is_volume_backed
5967         block_device_info = self._get_instance_block_device_info(
5968                             ctxt, instance, refresh_conn_info=False, bdms=bdms)
5969         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5970                                                            dest_check_data,
5971                                                            block_device_info)
5972         LOG.debug('source check data is %s', result)
5973         return result
5974 
5975     @wrap_exception()
5976     @wrap_instance_event(prefix='compute')
5977     @wrap_instance_fault
5978     def pre_live_migration(self, context, instance, block_migration, disk,
5979                            migrate_data):
5980         """Preparations for live migration at dest host.
5981 
5982         :param context: security context
5983         :param instance: dict of instance data
5984         :param block_migration: if true, prepare for block migration
5985         :param disk: disk info of instance
5986         :param migrate_data: A dict or LiveMigrateData object holding data
5987                              required for live migration without shared
5988                              storage.
5989         :returns: migrate_data containing additional migration info
5990         """
5991         LOG.debug('pre_live_migration data is %s', migrate_data)
5992 
5993         migrate_data.old_vol_attachment_ids = {}
5994         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5995             context, instance.uuid)
5996         try:
5997             connector = self.driver.get_volume_connector(instance)
5998             for bdm in bdms:
5999                 if bdm.is_volume and bdm.attachment_id is not None:
6000                     # This bdm uses the new cinder v3.44 API.
6001                     # We will create a new attachment for this
6002                     # volume on this migration destination host. The old
6003                     # attachment will be deleted on the source host
6004                     # when the migration succeeds. The old attachment_id
6005                     # is stored in dict with the key being the bdm.volume_id
6006                     # so it can be restored on rollback.
6007                     #
6008                     # Also note that attachment_update is not needed as we
6009                     # are providing the connector in the create call.
6010                     attach_ref = self.volume_api.attachment_create(
6011                         context, bdm.volume_id, bdm.instance_uuid,
6012                         connector=connector, mountpoint=bdm.device_name)
6013 
6014                     # save current attachment so we can detach it on success,
6015                     # or restore it on a rollback.
6016                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
6017                         bdm.attachment_id
6018 
6019                     # update the bdm with the new attachment_id.
6020                     bdm.attachment_id = attach_ref['id']
6021                     bdm.save()
6022         except Exception:
6023             # If we raise, migrate_data with the updated attachment ids
6024             # will not be returned to the source host for rollback.
6025             # So we need to rollback new attachments here.
6026             with excutils.save_and_reraise_exception():
6027                 old_attachments = migrate_data.old_vol_attachment_ids
6028                 for bdm in bdms:
6029                     if (bdm.is_volume and bdm.attachment_id is not None and
6030                             bdm.volume_id in old_attachments):
6031                         self.volume_api.attachment_delete(context,
6032                                                           bdm.attachment_id)
6033                         bdm.attachment_id = old_attachments[bdm.volume_id]
6034                         bdm.save()
6035 
6036         block_device_info = self._get_instance_block_device_info(
6037                             context, instance, refresh_conn_info=True,
6038                             bdms=bdms)
6039 
6040         network_info = self.network_api.get_instance_nw_info(context, instance)
6041         self._notify_about_instance_usage(
6042                      context, instance, "live_migration.pre.start",
6043                      network_info=network_info)
6044         compute_utils.notify_about_instance_action(
6045             context, instance, self.host,
6046             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6047             phase=fields.NotificationPhase.START)
6048 
6049         migrate_data = self.driver.pre_live_migration(context,
6050                                        instance,
6051                                        block_device_info,
6052                                        network_info,
6053                                        disk,
6054                                        migrate_data)
6055         LOG.debug('driver pre_live_migration data is %s', migrate_data)
6056 
6057         # Volume connections are complete, tell cinder that all the
6058         # attachments have completed.
6059         for bdm in bdms:
6060             if bdm.is_volume and bdm.attachment_id is not None:
6061                 self.volume_api.attachment_complete(context,
6062                                                     bdm.attachment_id)
6063 
6064         # NOTE(tr3buchet): setup networks on destination host
6065         self.network_api.setup_networks_on_host(context, instance,
6066                                                          self.host)
6067 
6068         # Creating filters to hypervisors and firewalls.
6069         # An example is that nova-instance-instance-xxx,
6070         # which is written to libvirt.xml(Check "virsh nwfilter-list")
6071         # This nwfilter is necessary on the destination host.
6072         # In addition, this method is creating filtering rule
6073         # onto destination host.
6074         self.driver.ensure_filtering_rules_for_instance(instance,
6075                                             network_info)
6076 
6077         self._notify_about_instance_usage(
6078                      context, instance, "live_migration.pre.end",
6079                      network_info=network_info)
6080         compute_utils.notify_about_instance_action(
6081             context, instance, self.host,
6082             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6083             phase=fields.NotificationPhase.END)
6084 
6085         LOG.debug('pre_live_migration result data is %s', migrate_data)
6086         return migrate_data
6087 
6088     def _do_live_migration(self, context, dest, instance, block_migration,
6089                            migration, migrate_data):
6090         # NOTE(danms): We should enhance the RT to account for migrations
6091         # and use the status field to denote when the accounting has been
6092         # done on source/destination. For now, this is just here for status
6093         # reporting
6094         self._set_migration_status(migration, 'preparing')
6095         # NOTE(Kevin_Zheng): The migration is no longer in the `queued` status
6096         # so lets remove it from the mapping.
6097         self._waiting_live_migrations.pop(instance.uuid)
6098 
6099         try:
6100             if ('block_migration' in migrate_data and
6101                     migrate_data.block_migration):
6102                 block_device_info = self._get_instance_block_device_info(
6103                     context, instance)
6104                 disk = self.driver.get_instance_disk_info(
6105                     instance, block_device_info=block_device_info)
6106             else:
6107                 disk = None
6108 
6109             migrate_data = self.compute_rpcapi.pre_live_migration(
6110                 context, instance,
6111                 block_migration, disk, dest, migrate_data)
6112         except Exception:
6113             with excutils.save_and_reraise_exception():
6114                 LOG.exception('Pre live migration failed at %s',
6115                               dest, instance=instance)
6116                 self._set_migration_status(migration, 'error')
6117                 # Make sure we set this for _rollback_live_migration()
6118                 # so it can find it, as expected if it was called later
6119                 migrate_data.migration = migration
6120                 self._rollback_live_migration(context, instance, dest,
6121                                               migrate_data)
6122 
6123         self._set_migration_status(migration, 'running')
6124 
6125         if migrate_data:
6126             migrate_data.migration = migration
6127         LOG.debug('live_migration data is %s', migrate_data)
6128         try:
6129             self.driver.live_migration(context, instance, dest,
6130                                        self._post_live_migration,
6131                                        self._rollback_live_migration,
6132                                        block_migration, migrate_data)
6133         except Exception:
6134             LOG.exception('Live migration failed.', instance=instance)
6135             with excutils.save_and_reraise_exception():
6136                 # Put instance and migration into error state,
6137                 # as its almost certainly too late to rollback
6138                 self._set_migration_status(migration, 'error')
6139                 # first refresh instance as it may have got updated by
6140                 # post_live_migration_at_destination
6141                 instance.refresh()
6142                 self._set_instance_obj_error_state(context, instance,
6143                                                    clean_task_state=True)
6144 
6145     @wrap_exception()
6146     @wrap_instance_event(prefix='compute')
6147     @wrap_instance_fault
6148     def live_migration(self, context, dest, instance, block_migration,
6149                        migration, migrate_data):
6150         """Executing live migration.
6151 
6152         :param context: security context
6153         :param dest: destination host
6154         :param instance: a nova.objects.instance.Instance object
6155         :param block_migration: if true, prepare for block migration
6156         :param migration: an nova.objects.Migration object
6157         :param migrate_data: implementation specific params
6158 
6159         """
6160         self._set_migration_status(migration, 'queued')
6161         # NOTE(Kevin_Zheng): Submit the live_migration job to the pool and
6162         # put the returned Future object into dict mapped with migration.uuid
6163         # in order to be able to track and abort it in the future.
6164         self._waiting_live_migrations[instance.uuid] = (None, None)
6165         try:
6166             future = self._live_migration_executor.submit(
6167                 self._do_live_migration, context, dest, instance,
6168                 block_migration, migration, migrate_data)
6169             self._waiting_live_migrations[instance.uuid] = (migration, future)
6170         except RuntimeError:
6171             # ThreadPoolExecutor.submit will raise RuntimeError if the pool
6172             # is shutdown, which happens in _cleanup_live_migrations_in_pool.
6173             LOG.info('Migration %s failed to submit as the compute service '
6174                      'is shutting down.', migration.uuid, instance=instance)
6175             self._set_migration_status(migration, 'error')
6176             raise exception.LiveMigrationNotSubmitted(
6177                 migration_uuid=migration.uuid, instance_uuid=instance.uuid)
6178 
6179     @wrap_exception()
6180     @wrap_instance_event(prefix='compute')
6181     @wrap_instance_fault
6182     def live_migration_force_complete(self, context, instance):
6183         """Force live migration to complete.
6184 
6185         :param context: Security context
6186         :param instance: The instance that is being migrated
6187         """
6188 
6189         self._notify_about_instance_usage(
6190             context, instance, 'live.migration.force.complete.start')
6191         self.driver.live_migration_force_complete(instance)
6192         self._notify_about_instance_usage(
6193             context, instance, 'live.migration.force.complete.end')
6194 
6195     @wrap_exception()
6196     @wrap_instance_event(prefix='compute')
6197     @wrap_instance_fault
6198     def live_migration_abort(self, context, instance, migration_id):
6199         """Abort an in-progress live migration.
6200 
6201         :param context: Security context
6202         :param instance: The instance that is being migrated
6203         :param migration_id: ID of in-progress live migration
6204 
6205         """
6206         self._notify_about_instance_usage(
6207             context, instance, 'live.migration.abort.start')
6208         compute_utils.notify_about_instance_action(
6209             context, instance, self.host,
6210             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6211             phase=fields.NotificationPhase.START)
6212         if instance.uuid in self._waiting_live_migrations:
6213             if self._waiting_live_migrations[instance.uuid][1]:
6214                 self._waiting_live_migrations[instance.uuid][1].cancel()
6215             migration = objects.Migration.get_by_id(context, migration_id)
6216             if migration.status in ('queued', 'preparing'):
6217                 self._set_migration_status(
6218                     self._waiting_live_migrations[instance.uuid][0],
6219                     'canceled')
6220         else:
6221             migration = objects.Migration.get_by_id(context, migration_id)
6222             while migration.status not in ('error', 'running'):
6223                 migration = objects.Migration.get_by_id(context, migration_id)
6224 
6225             if migration.status == 'running':
6226                 self.driver.live_migration_abort(instance)
6227             else:
6228                 LOG.info('Migration %s turned into error status before abort',
6229                          migration.uuid, instance=instance)
6230         self._notify_about_instance_usage(
6231             context, instance, 'live.migration.abort.end')
6232         compute_utils.notify_about_instance_action(
6233             context, instance, self.host,
6234             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6235             phase=fields.NotificationPhase.END)
6236 
6237     def _live_migration_cleanup_flags(self, migrate_data):
6238         """Determine whether disks or instance path need to be cleaned up after
6239         live migration (at source on success, at destination on rollback)
6240 
6241         Block migration needs empty image at destination host before migration
6242         starts, so if any failure occurs, any empty images has to be deleted.
6243 
6244         Also Volume backed live migration w/o shared storage needs to delete
6245         newly created instance-xxx dir on the destination as a part of its
6246         rollback process
6247 
6248         :param migrate_data: implementation specific data
6249         :returns: (bool, bool) -- do_cleanup, destroy_disks
6250         """
6251         # NOTE(pkoniszewski): block migration specific params are set inside
6252         # migrate_data objects for drivers that expose block live migration
6253         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6254         # cleanup is not needed.
6255         is_shared_block_storage = True
6256         is_shared_instance_path = True
6257         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6258             is_shared_block_storage = migrate_data.is_shared_block_storage
6259             is_shared_instance_path = migrate_data.is_shared_instance_path
6260         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6261             is_shared_block_storage = not migrate_data.block_migration
6262             is_shared_instance_path = not migrate_data.block_migration
6263         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6264             is_shared_instance_path = migrate_data.is_shared_instance_path
6265             is_shared_block_storage = migrate_data.is_shared_instance_path
6266 
6267         # No instance booting at source host, but instance dir
6268         # must be deleted for preparing next block migration
6269         # must be deleted for preparing next live migration w/o shared storage
6270         do_cleanup = not is_shared_instance_path
6271         destroy_disks = not is_shared_block_storage
6272 
6273         return (do_cleanup, destroy_disks)
6274 
6275     @wrap_exception()
6276     @wrap_instance_fault
6277     def _post_live_migration(self, ctxt, instance,
6278                             dest, block_migration=False, migrate_data=None):
6279         """Post operations for live migration.
6280 
6281         This method is called from live_migration
6282         and mainly updating database record.
6283 
6284         :param ctxt: security context
6285         :param instance: instance dict
6286         :param dest: destination host
6287         :param block_migration: if true, prepare for block migration
6288         :param migrate_data: if not None, it is a dict which has data
6289         required for live migration without shared storage
6290 
6291         """
6292         LOG.info('_post_live_migration() is started..',
6293                  instance=instance)
6294 
6295         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6296                 ctxt, instance.uuid)
6297 
6298         # Cleanup source host post live-migration
6299         block_device_info = self._get_instance_block_device_info(
6300                             ctxt, instance, bdms=bdms)
6301         self.driver.post_live_migration(ctxt, instance, block_device_info,
6302                                         migrate_data)
6303 
6304         # Detaching volumes.
6305         connector = self.driver.get_volume_connector(instance)
6306         for bdm in bdms:
6307             if bdm.is_volume:
6308                 if bdm.attachment_id is None:
6309                     # Prior to cinder v3.44:
6310                     # We don't want to actually mark the volume detached, or
6311                     # delete the bdm, just remove the connection from this
6312                     # host.
6313                     #
6314                     # remove the volume connection without detaching from
6315                     # hypervisor because the instance is not running anymore
6316                     # on the current host
6317                     self.volume_api.terminate_connection(ctxt, bdm.volume_id,
6318                                                          connector)
6319                 else:
6320                     # cinder v3.44 api flow - delete the old attachment
6321                     # for the source host
6322                     old_attachment_id = \
6323                         migrate_data.old_vol_attachment_ids[bdm.volume_id]
6324                     self.volume_api.attachment_delete(ctxt, old_attachment_id)
6325 
6326         # Releasing vlan.
6327         # (not necessary in current implementation?)
6328 
6329         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
6330 
6331         self._notify_about_instance_usage(ctxt, instance,
6332                                           "live_migration._post.start",
6333                                           network_info=network_info)
6334         # Releasing security group ingress rule.
6335         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
6336                   instance=instance)
6337         self.driver.unfilter_instance(instance,
6338                                       network_info)
6339 
6340         migration = {'source_compute': self.host,
6341                      'dest_compute': dest, }
6342         self.network_api.migrate_instance_start(ctxt,
6343                                                 instance,
6344                                                 migration)
6345 
6346         destroy_vifs = False
6347         try:
6348             self.driver.post_live_migration_at_source(ctxt, instance,
6349                                                       network_info)
6350         except NotImplementedError as ex:
6351             LOG.debug(ex, instance=instance)
6352             # For all hypervisors other than libvirt, there is a possibility
6353             # they are unplugging networks from source node in the cleanup
6354             # method
6355             destroy_vifs = True
6356 
6357         # NOTE(danms): Save source node before calling post method on
6358         # destination, which will update it
6359         source_node = instance.node
6360 
6361         # Define domain at destination host, without doing it,
6362         # pause/suspend/terminate do not work.
6363         post_at_dest_success = True
6364         try:
6365             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
6366                     instance, block_migration, dest)
6367         except Exception as error:
6368             post_at_dest_success = False
6369             # We don't want to break _post_live_migration() if
6370             # post_live_migration_at_destination() fails as it should never
6371             # affect cleaning up source node.
6372             LOG.exception("Post live migration at destination %s failed",
6373                           dest, instance=instance, error=error)
6374 
6375         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6376                 migrate_data)
6377 
6378         if do_cleanup:
6379             LOG.debug('Calling driver.cleanup from _post_live_migration',
6380                       instance=instance)
6381             self.driver.cleanup(ctxt, instance, network_info,
6382                                 destroy_disks=destroy_disks,
6383                                 migrate_data=migrate_data,
6384                                 destroy_vifs=destroy_vifs)
6385 
6386         self.instance_events.clear_events_for_instance(instance)
6387 
6388         # NOTE(timello): make sure we update available resources on source
6389         # host even before next periodic task.
6390         self.update_available_resource(ctxt)
6391 
6392         self._update_scheduler_instance_info(ctxt, instance)
6393         self._notify_about_instance_usage(ctxt, instance,
6394                                           "live_migration._post.end",
6395                                           network_info=network_info)
6396         if post_at_dest_success:
6397             LOG.info('Migrating instance to %s finished successfully.',
6398                      dest, instance=instance)
6399 
6400         self._clean_instance_console_tokens(ctxt, instance)
6401         if migrate_data and migrate_data.obj_attr_is_set('migration'):
6402             migrate_data.migration.status = 'completed'
6403             migrate_data.migration.save()
6404             migration = migrate_data.migration
6405             rc = self.scheduler_client.reportclient
6406             # Check to see if our migration has its own allocations
6407             allocs = rc.get_allocations_for_consumer(ctxt, migration.uuid)
6408         else:
6409             # We didn't have data on a migration, which means we can't
6410             # look up to see if we had new-style migration-based
6411             # allocations. This should really only happen in cases of
6412             # a buggy virt driver or some really old component in the
6413             # system. Log a warning so we know it happened.
6414             allocs = None
6415             LOG.warning('Live migration ended with no migrate_data '
6416                         'record. Unable to clean up migration-based '
6417                         'allocations which is almost certainly not '
6418                         'an expected situation.')
6419 
6420         if allocs:
6421             # We had a migration-based allocation that we need to handle
6422             self._delete_allocation_after_move(ctxt,
6423                                                instance,
6424                                                migrate_data.migration,
6425                                                instance.flavor,
6426                                                source_node)
6427         else:
6428             # No migration-based allocations, so do the old thing and
6429             # attempt to clean up any doubled per-instance allocation
6430             rt = self._get_resource_tracker()
6431             rt.delete_allocation_for_migrated_instance(
6432                 ctxt, instance, source_node)
6433 
6434     def _consoles_enabled(self):
6435         """Returns whether a console is enable."""
6436         return (CONF.vnc.enabled or CONF.spice.enabled or
6437                 CONF.rdp.enabled or CONF.serial_console.enabled or
6438                 CONF.mks.enabled)
6439 
6440     def _clean_instance_console_tokens(self, ctxt, instance):
6441         """Clean console tokens stored for an instance."""
6442         # If the database backend isn't in use, don't bother trying to clean
6443         # tokens. The database backend is not supported for cells v1.
6444         if not CONF.cells.enable and self._consoles_enabled():
6445             objects.ConsoleAuthToken.\
6446                 clean_console_auths_for_instance(ctxt, instance.uuid)
6447 
6448     @wrap_exception()
6449     @wrap_instance_event(prefix='compute')
6450     @wrap_instance_fault
6451     def post_live_migration_at_destination(self, context, instance,
6452                                            block_migration):
6453         """Post operations for live migration .
6454 
6455         :param context: security context
6456         :param instance: Instance dict
6457         :param block_migration: if true, prepare for block migration
6458 
6459         """
6460         LOG.info('Post operation of migration started',
6461                  instance=instance)
6462 
6463         # NOTE(tr3buchet): setup networks on destination host
6464         #                  this is called a second time because
6465         #                  multi_host does not create the bridge in
6466         #                  plug_vifs
6467         self.network_api.setup_networks_on_host(context, instance,
6468                                                          self.host)
6469         migration = {'source_compute': instance.host,
6470                      'dest_compute': self.host, }
6471         self.network_api.migrate_instance_finish(context,
6472                                                  instance,
6473                                                  migration)
6474 
6475         network_info = self.network_api.get_instance_nw_info(context, instance)
6476         self._notify_about_instance_usage(
6477                      context, instance, "live_migration.post.dest.start",
6478                      network_info=network_info)
6479         compute_utils.notify_about_instance_action(context, instance,
6480                 self.host,
6481                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6482                 phase=fields.NotificationPhase.START)
6483         block_device_info = self._get_instance_block_device_info(context,
6484                                                                  instance)
6485 
6486         try:
6487             self.driver.post_live_migration_at_destination(
6488                 context, instance, network_info, block_migration,
6489                 block_device_info)
6490         except Exception:
6491             with excutils.save_and_reraise_exception():
6492                 instance.vm_state = vm_states.ERROR
6493                 LOG.error('Unexpected error during post live migration at '
6494                           'destination host.', instance=instance)
6495         finally:
6496             # Restore instance state and update host
6497             current_power_state = self._get_power_state(context, instance)
6498             node_name = None
6499             prev_host = instance.host
6500             try:
6501                 compute_node = self._get_compute_info(context, self.host)
6502                 node_name = compute_node.hypervisor_hostname
6503             except exception.ComputeHostNotFound:
6504                 LOG.exception('Failed to get compute_info for %s', self.host)
6505             finally:
6506                 instance.host = self.host
6507                 instance.power_state = current_power_state
6508                 instance.task_state = None
6509                 instance.node = node_name
6510                 instance.progress = 0
6511                 instance.save(expected_task_state=task_states.MIGRATING)
6512 
6513         # NOTE(tr3buchet): tear down networks on source host
6514         self.network_api.setup_networks_on_host(context, instance,
6515                                                 prev_host, teardown=True)
6516         # NOTE(vish): this is necessary to update dhcp
6517         self.network_api.setup_networks_on_host(context, instance, self.host)
6518         self._notify_about_instance_usage(
6519                      context, instance, "live_migration.post.dest.end",
6520                      network_info=network_info)
6521         compute_utils.notify_about_instance_action(context, instance,
6522                 self.host,
6523                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6524                 phase=fields.NotificationPhase.END)
6525 
6526     @wrap_exception()
6527     @wrap_instance_fault
6528     def _rollback_live_migration(self, context, instance,
6529                                  dest, migrate_data=None,
6530                                  migration_status='error'):
6531         """Recovers Instance/volume state from migrating -> running.
6532 
6533         :param context: security context
6534         :param instance: nova.objects.instance.Instance object
6535         :param dest:
6536             This method is called from live migration src host.
6537             This param specifies destination host.
6538         :param migrate_data:
6539             if not none, contains implementation specific data.
6540         :param migration_status:
6541             Contains the status we want to set for the migration object
6542 
6543         """
6544         if (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
6545               migrate_data.obj_attr_is_set('migration')):
6546             migration = migrate_data.migration
6547         else:
6548             migration = None
6549 
6550         if migration:
6551             # Remove allocations created in Placement for the dest node.
6552             # If migration is None, we must be so old we don't have placement,
6553             # so no need to do something else.
6554             self._revert_allocation(context, instance, migration)
6555         else:
6556             LOG.error('Unable to revert allocations during live migration '
6557                       'rollback; compute driver did not provide migrate_data',
6558                       instance=instance)
6559 
6560         instance.task_state = None
6561         instance.progress = 0
6562         instance.save(expected_task_state=[task_states.MIGRATING])
6563 
6564         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
6565         self.network_api.setup_networks_on_host(context, instance, self.host)
6566 
6567         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6568                 context, instance.uuid)
6569         for bdm in bdms:
6570             if bdm.is_volume:
6571                 # remove the connection on the destination host
6572                 self.compute_rpcapi.remove_volume_connection(
6573                         context, instance, bdm.volume_id, dest)
6574 
6575                 if bdm.attachment_id:
6576                     # 3.44 cinder api flow. Set the bdm's
6577                     # attachment_id to the old attachment of the source
6578                     # host. If old_attachments is not there, then
6579                     # there was an error before the new attachment was made.
6580                     old_attachments = migrate_data.old_vol_attachment_ids \
6581                         if 'old_vol_attachment_ids' in migrate_data else None
6582                     if old_attachments and bdm.volume_id in old_attachments:
6583                         self.volume_api.attachment_delete(context,
6584                                                           bdm.attachment_id)
6585                         bdm.attachment_id = old_attachments[bdm.volume_id]
6586                         bdm.save()
6587 
6588         self._notify_about_instance_usage(context, instance,
6589                                           "live_migration._rollback.start")
6590         compute_utils.notify_about_instance_action(context, instance,
6591                 self.host,
6592                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6593                 phase=fields.NotificationPhase.START,
6594                 bdms=bdms)
6595 
6596         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6597                 migrate_data)
6598 
6599         if do_cleanup:
6600             self.compute_rpcapi.rollback_live_migration_at_destination(
6601                     context, instance, dest, destroy_disks=destroy_disks,
6602                     migrate_data=migrate_data)
6603         elif utils.is_neutron():
6604             # The port binding profiles need to be cleaned up.
6605             with errors_out_migration_ctxt(migration):
6606                 try:
6607                     self.network_api.setup_networks_on_host(
6608                         context, instance, teardown=True)
6609                 except Exception:
6610                     with excutils.save_and_reraise_exception():
6611                         LOG.exception(
6612                             'An error occurred while cleaning up networking '
6613                             'during live migration rollback.',
6614                             instance=instance)
6615 
6616         self._notify_about_instance_usage(context, instance,
6617                                           "live_migration._rollback.end")
6618         compute_utils.notify_about_instance_action(context, instance,
6619 
6620                 self.host,
6621                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6622                 phase=fields.NotificationPhase.END,
6623                 bdms=bdms)
6624 
6625         self._set_migration_status(migration, migration_status)
6626 
6627     @wrap_exception()
6628     @wrap_instance_event(prefix='compute')
6629     @wrap_instance_fault
6630     def rollback_live_migration_at_destination(self, context, instance,
6631                                                destroy_disks,
6632                                                migrate_data):
6633         """Cleaning up image directory that is created pre_live_migration.
6634 
6635         :param context: security context
6636         :param instance: a nova.objects.instance.Instance object sent over rpc
6637         :param destroy_disks: whether to destroy volumes or not
6638         :param migrate_data: contains migration info
6639         """
6640         network_info = self.network_api.get_instance_nw_info(context, instance)
6641         self._notify_about_instance_usage(
6642                       context, instance, "live_migration.rollback.dest.start",
6643                       network_info=network_info)
6644         try:
6645             # NOTE(tr3buchet): tear down networks on destination host
6646             self.network_api.setup_networks_on_host(context, instance,
6647                                                     self.host, teardown=True)
6648         except Exception:
6649             with excutils.save_and_reraise_exception():
6650                 # NOTE(tdurakov): even if teardown networks fails driver
6651                 # should try to rollback live migration on destination.
6652                 LOG.exception('An error occurred while deallocating network.',
6653                               instance=instance)
6654         finally:
6655             # always run this even if setup_networks_on_host fails
6656             # NOTE(vish): The mapping is passed in so the driver can disconnect
6657             #             from remote volumes if necessary
6658             block_device_info = self._get_instance_block_device_info(context,
6659                                                                      instance)
6660             self.driver.rollback_live_migration_at_destination(
6661                 context, instance, network_info, block_device_info,
6662                 destroy_disks=destroy_disks, migrate_data=migrate_data)
6663 
6664         self._notify_about_instance_usage(
6665                         context, instance, "live_migration.rollback.dest.end",
6666                         network_info=network_info)
6667 
6668     @periodic_task.periodic_task(
6669         spacing=CONF.heal_instance_info_cache_interval)
6670     def _heal_instance_info_cache(self, context):
6671         """Called periodically.  On every call, try to update the
6672         info_cache's network information for another instance by
6673         calling to the network manager.
6674 
6675         This is implemented by keeping a cache of uuids of instances
6676         that live on this host.  On each call, we pop one off of a
6677         list, pull the DB record, and try the call to the network API.
6678         If anything errors don't fail, as it's possible the instance
6679         has been deleted, etc.
6680         """
6681         heal_interval = CONF.heal_instance_info_cache_interval
6682         if not heal_interval:
6683             return
6684 
6685         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
6686         instance = None
6687 
6688         LOG.debug('Starting heal instance info cache')
6689 
6690         if not instance_uuids:
6691             # The list of instances to heal is empty so rebuild it
6692             LOG.debug('Rebuilding the list of instances to heal')
6693             db_instances = objects.InstanceList.get_by_host(
6694                 context, self.host, expected_attrs=[], use_slave=True)
6695             for inst in db_instances:
6696                 # We don't want to refresh the cache for instances
6697                 # which are building or deleting so don't put them
6698                 # in the list. If they are building they will get
6699                 # added to the list next time we build it.
6700                 if (inst.vm_state == vm_states.BUILDING):
6701                     LOG.debug('Skipping network cache update for instance '
6702                               'because it is Building.', instance=inst)
6703                     continue
6704                 if (inst.task_state == task_states.DELETING):
6705                     LOG.debug('Skipping network cache update for instance '
6706                               'because it is being deleted.', instance=inst)
6707                     continue
6708 
6709                 if not instance:
6710                     # Save the first one we find so we don't
6711                     # have to get it again
6712                     instance = inst
6713                 else:
6714                     instance_uuids.append(inst['uuid'])
6715 
6716             self._instance_uuids_to_heal = instance_uuids
6717         else:
6718             # Find the next valid instance on the list
6719             while instance_uuids:
6720                 try:
6721                     inst = objects.Instance.get_by_uuid(
6722                             context, instance_uuids.pop(0),
6723                             expected_attrs=['system_metadata', 'info_cache',
6724                                             'flavor'],
6725                             use_slave=True)
6726                 except exception.InstanceNotFound:
6727                     # Instance is gone.  Try to grab another.
6728                     continue
6729 
6730                 # Check the instance hasn't been migrated
6731                 if inst.host != self.host:
6732                     LOG.debug('Skipping network cache update for instance '
6733                               'because it has been migrated to another '
6734                               'host.', instance=inst)
6735                 # Check the instance isn't being deleting
6736                 elif inst.task_state == task_states.DELETING:
6737                     LOG.debug('Skipping network cache update for instance '
6738                               'because it is being deleted.', instance=inst)
6739                 else:
6740                     instance = inst
6741                     break
6742 
6743         if instance:
6744             # We have an instance now to refresh
6745             try:
6746                 # Call to network API to get instance info.. this will
6747                 # force an update to the instance's info_cache
6748                 self.network_api.get_instance_nw_info(context, instance)
6749                 LOG.debug('Updated the network info_cache for instance',
6750                           instance=instance)
6751             except exception.InstanceNotFound:
6752                 # Instance is gone.
6753                 LOG.debug('Instance no longer exists. Unable to refresh',
6754                           instance=instance)
6755                 return
6756             except exception.InstanceInfoCacheNotFound:
6757                 # InstanceInfoCache is gone.
6758                 LOG.debug('InstanceInfoCache no longer exists. '
6759                           'Unable to refresh', instance=instance)
6760             except Exception:
6761                 LOG.error('An error occurred while refreshing the network '
6762                           'cache.', instance=instance, exc_info=True)
6763         else:
6764             LOG.debug("Didn't find any instances for network info cache "
6765                       "update.")
6766 
6767     @periodic_task.periodic_task
6768     def _poll_rebooting_instances(self, context):
6769         if CONF.reboot_timeout > 0:
6770             filters = {'task_state':
6771                        [task_states.REBOOTING,
6772                         task_states.REBOOT_STARTED,
6773                         task_states.REBOOT_PENDING],
6774                        'host': self.host}
6775             rebooting = objects.InstanceList.get_by_filters(
6776                 context, filters, expected_attrs=[], use_slave=True)
6777 
6778             to_poll = []
6779             for instance in rebooting:
6780                 if timeutils.is_older_than(instance.updated_at,
6781                                            CONF.reboot_timeout):
6782                     to_poll.append(instance)
6783 
6784             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
6785 
6786     @periodic_task.periodic_task
6787     def _poll_rescued_instances(self, context):
6788         if CONF.rescue_timeout > 0:
6789             filters = {'vm_state': vm_states.RESCUED,
6790                        'host': self.host}
6791             rescued_instances = objects.InstanceList.get_by_filters(
6792                 context, filters, expected_attrs=["system_metadata"],
6793                 use_slave=True)
6794 
6795             to_unrescue = []
6796             for instance in rescued_instances:
6797                 if timeutils.is_older_than(instance.launched_at,
6798                                            CONF.rescue_timeout):
6799                     to_unrescue.append(instance)
6800 
6801             for instance in to_unrescue:
6802                 self.compute_api.unrescue(context, instance)
6803 
6804     @periodic_task.periodic_task
6805     def _poll_unconfirmed_resizes(self, context):
6806         if CONF.resize_confirm_window == 0:
6807             return
6808 
6809         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
6810                 context, CONF.resize_confirm_window, self.host,
6811                 use_slave=True)
6812 
6813         migrations_info = dict(migration_count=len(migrations),
6814                 confirm_window=CONF.resize_confirm_window)
6815 
6816         if migrations_info["migration_count"] > 0:
6817             LOG.info("Found %(migration_count)d unconfirmed migrations "
6818                      "older than %(confirm_window)d seconds",
6819                      migrations_info)
6820 
6821         def _set_migration_to_error(migration, reason, **kwargs):
6822             LOG.warning("Setting migration %(migration_id)s to error: "
6823                         "%(reason)s",
6824                         {'migration_id': migration['id'], 'reason': reason},
6825                         **kwargs)
6826             migration.status = 'error'
6827             with migration.obj_as_admin():
6828                 migration.save()
6829 
6830         for migration in migrations:
6831             instance_uuid = migration.instance_uuid
6832             LOG.info("Automatically confirming migration "
6833                      "%(migration_id)s for instance %(instance_uuid)s",
6834                      {'migration_id': migration.id,
6835                       'instance_uuid': instance_uuid})
6836             expected_attrs = ['metadata', 'system_metadata']
6837             try:
6838                 instance = objects.Instance.get_by_uuid(context,
6839                             instance_uuid, expected_attrs=expected_attrs,
6840                             use_slave=True)
6841             except exception.InstanceNotFound:
6842                 reason = (_("Instance %s not found") %
6843                           instance_uuid)
6844                 _set_migration_to_error(migration, reason)
6845                 continue
6846             if instance.vm_state == vm_states.ERROR:
6847                 reason = _("In ERROR state")
6848                 _set_migration_to_error(migration, reason,
6849                                         instance=instance)
6850                 continue
6851             # race condition: The instance in DELETING state should not be
6852             # set the migration state to error, otherwise the instance in
6853             # to be deleted which is in RESIZED state
6854             # will not be able to confirm resize
6855             if instance.task_state in [task_states.DELETING,
6856                                        task_states.SOFT_DELETING]:
6857                 msg = ("Instance being deleted or soft deleted during resize "
6858                        "confirmation. Skipping.")
6859                 LOG.debug(msg, instance=instance)
6860                 continue
6861 
6862             # race condition: This condition is hit when this method is
6863             # called between the save of the migration record with a status of
6864             # finished and the save of the instance object with a state of
6865             # RESIZED. The migration record should not be set to error.
6866             if instance.task_state == task_states.RESIZE_FINISH:
6867                 msg = ("Instance still resizing during resize "
6868                        "confirmation. Skipping.")
6869                 LOG.debug(msg, instance=instance)
6870                 continue
6871 
6872             vm_state = instance.vm_state
6873             task_state = instance.task_state
6874             if vm_state != vm_states.RESIZED or task_state is not None:
6875                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
6876                            "RESIZED/None") %
6877                           {'vm_state': vm_state,
6878                            'task_state': task_state})
6879                 _set_migration_to_error(migration, reason,
6880                                         instance=instance)
6881                 continue
6882             try:
6883                 self.compute_api.confirm_resize(context, instance,
6884                                                 migration=migration)
6885             except Exception as e:
6886                 LOG.info("Error auto-confirming resize: %s. "
6887                          "Will retry later.", e, instance=instance)
6888 
6889     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
6890     def _poll_shelved_instances(self, context):
6891 
6892         if CONF.shelved_offload_time <= 0:
6893             return
6894 
6895         filters = {'vm_state': vm_states.SHELVED,
6896                    'task_state': None,
6897                    'host': self.host}
6898         shelved_instances = objects.InstanceList.get_by_filters(
6899             context, filters=filters, expected_attrs=['system_metadata'],
6900             use_slave=True)
6901 
6902         to_gc = []
6903         for instance in shelved_instances:
6904             sys_meta = instance.system_metadata
6905             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
6906             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
6907                 to_gc.append(instance)
6908 
6909         for instance in to_gc:
6910             try:
6911                 instance.task_state = task_states.SHELVING_OFFLOADING
6912                 instance.save(expected_task_state=(None,))
6913                 self.shelve_offload_instance(context, instance,
6914                                              clean_shutdown=False)
6915             except Exception:
6916                 LOG.exception('Periodic task failed to offload instance.',
6917                               instance=instance)
6918 
6919     @periodic_task.periodic_task
6920     def _instance_usage_audit(self, context):
6921         if not CONF.instance_usage_audit:
6922             return
6923 
6924         begin, end = utils.last_completed_audit_period()
6925         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
6926                                self.host):
6927             return
6928 
6929         instances = objects.InstanceList.get_active_by_window_joined(
6930             context, begin, end, host=self.host,
6931             expected_attrs=['system_metadata', 'info_cache', 'metadata',
6932                             'flavor'],
6933             use_slave=True)
6934         num_instances = len(instances)
6935         errors = 0
6936         successes = 0
6937         LOG.info("Running instance usage audit for host %(host)s "
6938                  "from %(begin_time)s to %(end_time)s. "
6939                  "%(number_instances)s instances.",
6940                  {'host': self.host,
6941                   'begin_time': begin,
6942                   'end_time': end,
6943                   'number_instances': num_instances})
6944         start_time = time.time()
6945         task_log = objects.TaskLog(context)
6946         task_log.task_name = 'instance_usage_audit'
6947         task_log.period_beginning = begin
6948         task_log.period_ending = end
6949         task_log.host = self.host
6950         task_log.task_items = num_instances
6951         task_log.message = 'Instance usage audit started...'
6952         task_log.begin_task()
6953         for instance in instances:
6954             try:
6955                 compute_utils.notify_usage_exists(
6956                     self.notifier, context, instance,
6957                     ignore_missing_network_data=False)
6958                 successes += 1
6959             except Exception:
6960                 LOG.exception('Failed to generate usage '
6961                               'audit for instance '
6962                               'on host %s', self.host,
6963                               instance=instance)
6964                 errors += 1
6965         task_log.errors = errors
6966         task_log.message = (
6967             'Instance usage audit ran for host %s, %s instances in %s seconds.'
6968             % (self.host, num_instances, time.time() - start_time))
6969         task_log.end_task()
6970 
6971     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
6972     def _poll_bandwidth_usage(self, context):
6973 
6974         if not self._bw_usage_supported:
6975             return
6976 
6977         prev_time, start_time = utils.last_completed_audit_period()
6978 
6979         curr_time = time.time()
6980         if (curr_time - self._last_bw_usage_poll >
6981                 CONF.bandwidth_poll_interval):
6982             self._last_bw_usage_poll = curr_time
6983             LOG.info("Updating bandwidth usage cache")
6984             cells_update_interval = CONF.cells.bandwidth_update_interval
6985             if (cells_update_interval > 0 and
6986                    curr_time - self._last_bw_usage_cell_update >
6987                            cells_update_interval):
6988                 self._last_bw_usage_cell_update = curr_time
6989                 update_cells = True
6990             else:
6991                 update_cells = False
6992 
6993             instances = objects.InstanceList.get_by_host(context,
6994                                                               self.host,
6995                                                               use_slave=True)
6996             try:
6997                 bw_counters = self.driver.get_all_bw_counters(instances)
6998             except NotImplementedError:
6999                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
7000                 # implemented yet.  If they don't it doesn't break anything,
7001                 # they just don't get the info in the usage events.
7002                 # NOTE(PhilDay): Record that its not supported so we can
7003                 # skip fast on future calls rather than waste effort getting
7004                 # the list of instances.
7005                 LOG.info("Bandwidth usage not supported by %(driver)s.",
7006                          {'driver': CONF.compute_driver})
7007                 self._bw_usage_supported = False
7008                 return
7009 
7010             refreshed = timeutils.utcnow()
7011             for bw_ctr in bw_counters:
7012                 # Allow switching of greenthreads between queries.
7013                 greenthread.sleep(0)
7014                 bw_in = 0
7015                 bw_out = 0
7016                 last_ctr_in = None
7017                 last_ctr_out = None
7018                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
7019                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
7020                     start_period=start_time, use_slave=True)
7021                 if usage:
7022                     bw_in = usage.bw_in
7023                     bw_out = usage.bw_out
7024                     last_ctr_in = usage.last_ctr_in
7025                     last_ctr_out = usage.last_ctr_out
7026                 else:
7027                     usage = (objects.BandwidthUsage.
7028                              get_by_instance_uuid_and_mac(
7029                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
7030                         start_period=prev_time, use_slave=True))
7031                     if usage:
7032                         last_ctr_in = usage.last_ctr_in
7033                         last_ctr_out = usage.last_ctr_out
7034 
7035                 if last_ctr_in is not None:
7036                     if bw_ctr['bw_in'] < last_ctr_in:
7037                         # counter rollover
7038                         bw_in += bw_ctr['bw_in']
7039                     else:
7040                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
7041 
7042                 if last_ctr_out is not None:
7043                     if bw_ctr['bw_out'] < last_ctr_out:
7044                         # counter rollover
7045                         bw_out += bw_ctr['bw_out']
7046                     else:
7047                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
7048 
7049                 objects.BandwidthUsage(context=context).create(
7050                                               bw_ctr['uuid'],
7051                                               bw_ctr['mac_address'],
7052                                               bw_in,
7053                                               bw_out,
7054                                               bw_ctr['bw_in'],
7055                                               bw_ctr['bw_out'],
7056                                               start_period=start_time,
7057                                               last_refreshed=refreshed,
7058                                               update_cells=update_cells)
7059 
7060     def _get_host_volume_bdms(self, context, use_slave=False):
7061         """Return all block device mappings on a compute host."""
7062         compute_host_bdms = []
7063         instances = objects.InstanceList.get_by_host(context, self.host,
7064             use_slave=use_slave)
7065         for instance in instances:
7066             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7067                     context, instance.uuid, use_slave=use_slave)
7068             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
7069             compute_host_bdms.append(dict(instance=instance,
7070                                           instance_bdms=instance_bdms))
7071 
7072         return compute_host_bdms
7073 
7074     def _update_volume_usage_cache(self, context, vol_usages):
7075         """Updates the volume usage cache table with a list of stats."""
7076         for usage in vol_usages:
7077             # Allow switching of greenthreads between queries.
7078             greenthread.sleep(0)
7079             vol_usage = objects.VolumeUsage(context)
7080             vol_usage.volume_id = usage['volume']
7081             vol_usage.instance_uuid = usage['instance'].uuid
7082             vol_usage.project_id = usage['instance'].project_id
7083             vol_usage.user_id = usage['instance'].user_id
7084             vol_usage.availability_zone = usage['instance'].availability_zone
7085             vol_usage.curr_reads = usage['rd_req']
7086             vol_usage.curr_read_bytes = usage['rd_bytes']
7087             vol_usage.curr_writes = usage['wr_req']
7088             vol_usage.curr_write_bytes = usage['wr_bytes']
7089             vol_usage.save()
7090             self.notifier.info(context, 'volume.usage',
7091                                compute_utils.usage_volume_info(vol_usage))
7092 
7093     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
7094     def _poll_volume_usage(self, context):
7095         if CONF.volume_usage_poll_interval == 0:
7096             return
7097 
7098         compute_host_bdms = self._get_host_volume_bdms(context,
7099                                                        use_slave=True)
7100         if not compute_host_bdms:
7101             return
7102 
7103         LOG.debug("Updating volume usage cache")
7104         try:
7105             vol_usages = self.driver.get_all_volume_usage(context,
7106                                                           compute_host_bdms)
7107         except NotImplementedError:
7108             return
7109 
7110         self._update_volume_usage_cache(context, vol_usages)
7111 
7112     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
7113                                  run_immediately=True)
7114     def _sync_power_states(self, context):
7115         """Align power states between the database and the hypervisor.
7116 
7117         To sync power state data we make a DB call to get the number of
7118         virtual machines known by the hypervisor and if the number matches the
7119         number of virtual machines known by the database, we proceed in a lazy
7120         loop, one database record at a time, checking if the hypervisor has the
7121         same power state as is in the database.
7122         """
7123         db_instances = objects.InstanceList.get_by_host(context, self.host,
7124                                                         expected_attrs=[],
7125                                                         use_slave=True)
7126 
7127         num_vm_instances = self.driver.get_num_instances()
7128         num_db_instances = len(db_instances)
7129 
7130         if num_vm_instances != num_db_instances:
7131             LOG.warning("While synchronizing instance power states, found "
7132                         "%(num_db_instances)s instances in the database "
7133                         "and %(num_vm_instances)s instances on the "
7134                         "hypervisor.",
7135                         {'num_db_instances': num_db_instances,
7136                          'num_vm_instances': num_vm_instances})
7137 
7138         def _sync(db_instance):
7139             # NOTE(melwitt): This must be synchronized as we query state from
7140             #                two separate sources, the driver and the database.
7141             #                They are set (in stop_instance) and read, in sync.
7142             @utils.synchronized(db_instance.uuid)
7143             def query_driver_power_state_and_sync():
7144                 self._query_driver_power_state_and_sync(context, db_instance)
7145 
7146             try:
7147                 query_driver_power_state_and_sync()
7148             except Exception:
7149                 LOG.exception("Periodic sync_power_state task had an "
7150                               "error while processing an instance.",
7151                               instance=db_instance)
7152 
7153             self._syncs_in_progress.pop(db_instance.uuid)
7154 
7155         for db_instance in db_instances:
7156             # process syncs asynchronously - don't want instance locking to
7157             # block entire periodic task thread
7158             uuid = db_instance.uuid
7159             if uuid in self._syncs_in_progress:
7160                 LOG.debug('Sync already in progress for %s', uuid)
7161             else:
7162                 LOG.debug('Triggering sync for uuid %s', uuid)
7163                 self._syncs_in_progress[uuid] = True
7164                 self._sync_power_pool.spawn_n(_sync, db_instance)
7165 
7166     def _query_driver_power_state_and_sync(self, context, db_instance):
7167         if db_instance.task_state is not None:
7168             LOG.info("During sync_power_state the instance has a "
7169                      "pending task (%(task)s). Skip.",
7170                      {'task': db_instance.task_state}, instance=db_instance)
7171             return
7172         # No pending tasks. Now try to figure out the real vm_power_state.
7173         try:
7174             vm_instance = self.driver.get_info(db_instance)
7175             vm_power_state = vm_instance.state
7176         except exception.InstanceNotFound:
7177             vm_power_state = power_state.NOSTATE
7178         # Note(maoy): the above get_info call might take a long time,
7179         # for example, because of a broken libvirt driver.
7180         try:
7181             self._sync_instance_power_state(context,
7182                                             db_instance,
7183                                             vm_power_state,
7184                                             use_slave=True)
7185         except exception.InstanceNotFound:
7186             # NOTE(hanlind): If the instance gets deleted during sync,
7187             # silently ignore.
7188             pass
7189 
7190     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
7191                                    use_slave=False):
7192         """Align instance power state between the database and hypervisor.
7193 
7194         If the instance is not found on the hypervisor, but is in the database,
7195         then a stop() API will be called on the instance.
7196         """
7197 
7198         # We re-query the DB to get the latest instance info to minimize
7199         # (not eliminate) race condition.
7200         db_instance.refresh(use_slave=use_slave)
7201         db_power_state = db_instance.power_state
7202         vm_state = db_instance.vm_state
7203 
7204         if self.host != db_instance.host:
7205             # on the sending end of nova-compute _sync_power_state
7206             # may have yielded to the greenthread performing a live
7207             # migration; this in turn has changed the resident-host
7208             # for the VM; However, the instance is still active, it
7209             # is just in the process of migrating to another host.
7210             # This implies that the compute source must relinquish
7211             # control to the compute destination.
7212             LOG.info("During the sync_power process the "
7213                      "instance has moved from "
7214                      "host %(src)s to host %(dst)s",
7215                      {'src': db_instance.host,
7216                       'dst': self.host},
7217                      instance=db_instance)
7218             return
7219         elif db_instance.task_state is not None:
7220             # on the receiving end of nova-compute, it could happen
7221             # that the DB instance already report the new resident
7222             # but the actual VM has not showed up on the hypervisor
7223             # yet. In this case, let's allow the loop to continue
7224             # and run the state sync in a later round
7225             LOG.info("During sync_power_state the instance has a "
7226                      "pending task (%(task)s). Skip.",
7227                      {'task': db_instance.task_state},
7228                      instance=db_instance)
7229             return
7230 
7231         orig_db_power_state = db_power_state
7232         if vm_power_state != db_power_state:
7233             LOG.info('During _sync_instance_power_state the DB '
7234                      'power_state (%(db_power_state)s) does not match '
7235                      'the vm_power_state from the hypervisor '
7236                      '(%(vm_power_state)s). Updating power_state in the '
7237                      'DB to match the hypervisor.',
7238                      {'db_power_state': db_power_state,
7239                       'vm_power_state': vm_power_state},
7240                      instance=db_instance)
7241             # power_state is always updated from hypervisor to db
7242             db_instance.power_state = vm_power_state
7243             db_instance.save()
7244             db_power_state = vm_power_state
7245 
7246         # Note(maoy): Now resolve the discrepancy between vm_state and
7247         # vm_power_state. We go through all possible vm_states.
7248         if vm_state in (vm_states.BUILDING,
7249                         vm_states.RESCUED,
7250                         vm_states.RESIZED,
7251                         vm_states.SUSPENDED,
7252                         vm_states.ERROR):
7253             # TODO(maoy): we ignore these vm_state for now.
7254             pass
7255         elif vm_state == vm_states.ACTIVE:
7256             # The only rational power state should be RUNNING
7257             if vm_power_state in (power_state.SHUTDOWN,
7258                                   power_state.CRASHED):
7259                 LOG.warning("Instance shutdown by itself. Calling the "
7260                             "stop API. Current vm_state: %(vm_state)s, "
7261                             "current task_state: %(task_state)s, "
7262                             "original DB power_state: %(db_power_state)s, "
7263                             "current VM power_state: %(vm_power_state)s",
7264                             {'vm_state': vm_state,
7265                              'task_state': db_instance.task_state,
7266                              'db_power_state': orig_db_power_state,
7267                              'vm_power_state': vm_power_state},
7268                             instance=db_instance)
7269                 try:
7270                     # Note(maoy): here we call the API instead of
7271                     # brutally updating the vm_state in the database
7272                     # to allow all the hooks and checks to be performed.
7273                     if db_instance.shutdown_terminate:
7274                         self.compute_api.delete(context, db_instance)
7275                     else:
7276                         self.compute_api.stop(context, db_instance)
7277                 except Exception:
7278                     # Note(maoy): there is no need to propagate the error
7279                     # because the same power_state will be retrieved next
7280                     # time and retried.
7281                     # For example, there might be another task scheduled.
7282                     LOG.exception("error during stop() in sync_power_state.",
7283                                   instance=db_instance)
7284             elif vm_power_state == power_state.SUSPENDED:
7285                 LOG.warning("Instance is suspended unexpectedly. Calling "
7286                             "the stop API.", instance=db_instance)
7287                 try:
7288                     self.compute_api.stop(context, db_instance)
7289                 except Exception:
7290                     LOG.exception("error during stop() in sync_power_state.",
7291                                   instance=db_instance)
7292             elif vm_power_state == power_state.PAUSED:
7293                 # Note(maoy): a VM may get into the paused state not only
7294                 # because the user request via API calls, but also
7295                 # due to (temporary) external instrumentations.
7296                 # Before the virt layer can reliably report the reason,
7297                 # we simply ignore the state discrepancy. In many cases,
7298                 # the VM state will go back to running after the external
7299                 # instrumentation is done. See bug 1097806 for details.
7300                 LOG.warning("Instance is paused unexpectedly. Ignore.",
7301                             instance=db_instance)
7302             elif vm_power_state == power_state.NOSTATE:
7303                 # Occasionally, depending on the status of the hypervisor,
7304                 # which could be restarting for example, an instance may
7305                 # not be found.  Therefore just log the condition.
7306                 LOG.warning("Instance is unexpectedly not found. Ignore.",
7307                             instance=db_instance)
7308         elif vm_state == vm_states.STOPPED:
7309             if vm_power_state not in (power_state.NOSTATE,
7310                                       power_state.SHUTDOWN,
7311                                       power_state.CRASHED):
7312                 LOG.warning("Instance is not stopped. Calling "
7313                             "the stop API. Current vm_state: %(vm_state)s,"
7314                             " current task_state: %(task_state)s, "
7315                             "original DB power_state: %(db_power_state)s, "
7316                             "current VM power_state: %(vm_power_state)s",
7317                             {'vm_state': vm_state,
7318                              'task_state': db_instance.task_state,
7319                              'db_power_state': orig_db_power_state,
7320                              'vm_power_state': vm_power_state},
7321                             instance=db_instance)
7322                 try:
7323                     # NOTE(russellb) Force the stop, because normally the
7324                     # compute API would not allow an attempt to stop a stopped
7325                     # instance.
7326                     self.compute_api.force_stop(context, db_instance)
7327                 except Exception:
7328                     LOG.exception("error during stop() in sync_power_state.",
7329                                   instance=db_instance)
7330         elif vm_state == vm_states.PAUSED:
7331             if vm_power_state in (power_state.SHUTDOWN,
7332                                   power_state.CRASHED):
7333                 LOG.warning("Paused instance shutdown by itself. Calling "
7334                             "the stop API.", instance=db_instance)
7335                 try:
7336                     self.compute_api.force_stop(context, db_instance)
7337                 except Exception:
7338                     LOG.exception("error during stop() in sync_power_state.",
7339                                   instance=db_instance)
7340         elif vm_state in (vm_states.SOFT_DELETED,
7341                           vm_states.DELETED):
7342             if vm_power_state not in (power_state.NOSTATE,
7343                                       power_state.SHUTDOWN):
7344                 # Note(maoy): this should be taken care of periodically in
7345                 # _cleanup_running_deleted_instances().
7346                 LOG.warning("Instance is not (soft-)deleted.",
7347                             instance=db_instance)
7348 
7349     @periodic_task.periodic_task
7350     def _reclaim_queued_deletes(self, context):
7351         """Reclaim instances that are queued for deletion."""
7352         interval = CONF.reclaim_instance_interval
7353         if interval <= 0:
7354             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
7355             return
7356 
7357         filters = {'vm_state': vm_states.SOFT_DELETED,
7358                    'task_state': None,
7359                    'host': self.host}
7360         instances = objects.InstanceList.get_by_filters(
7361             context, filters,
7362             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
7363             use_slave=True)
7364         for instance in instances:
7365             if self._deleted_old_enough(instance, interval):
7366                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7367                         context, instance.uuid)
7368                 LOG.info('Reclaiming deleted instance', instance=instance)
7369                 try:
7370                     self._delete_instance(context, instance, bdms)
7371                 except Exception as e:
7372                     LOG.warning("Periodic reclaim failed to delete "
7373                                 "instance: %s",
7374                                 e, instance=instance)
7375 
7376     def _get_nodename(self, instance, refresh=False):
7377         """Helper method to get the name of the first available node
7378         on this host. This method should not be used with any operations
7379         on ironic instances since it does not handle multiple nodes.
7380         """
7381         node = self.driver.get_available_nodes(refresh=refresh)[0]
7382         LOG.debug("No node specified, defaulting to %s", node,
7383                   instance=instance)
7384         return node
7385 
7386     def update_available_resource_for_node(self, context, nodename):
7387 
7388         rt = self._get_resource_tracker()
7389         try:
7390             rt.update_available_resource(context, nodename)
7391         except exception.ComputeHostNotFound:
7392             # NOTE(comstud): We can get to this case if a node was
7393             # marked 'deleted' in the DB and then re-added with a
7394             # different auto-increment id. The cached resource
7395             # tracker tried to update a deleted record and failed.
7396             # Don't add this resource tracker to the new dict, so
7397             # that this will resolve itself on the next run.
7398             LOG.info("Compute node '%s' not found in "
7399                      "update_available_resource.", nodename)
7400             # TODO(jaypipes): Yes, this is inefficient to throw away all of the
7401             # compute nodes to force a rebuild, but this is only temporary
7402             # until Ironic baremetal node resource providers are tracked
7403             # properly in the report client and this is a tiny edge case
7404             # anyway.
7405             self._resource_tracker = None
7406             return
7407         except Exception:
7408             LOG.exception("Error updating resources for node %(node)s.",
7409                           {'node': nodename})
7410 
7411     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
7412     def update_available_resource(self, context, startup=False):
7413         """See driver.get_available_resource()
7414 
7415         Periodic process that keeps that the compute host's understanding of
7416         resource availability and usage in sync with the underlying hypervisor.
7417 
7418         :param context: security context
7419         :param startup: True if this is being called when the nova-compute
7420             service is starting, False otherwise.
7421         """
7422 
7423         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
7424                                                             use_slave=True,
7425                                                             startup=startup)
7426         try:
7427             nodenames = set(self.driver.get_available_nodes())
7428         except exception.VirtDriverNotReady:
7429             LOG.warning("Virt driver is not ready.")
7430             return
7431 
7432         for nodename in nodenames:
7433             self.update_available_resource_for_node(context, nodename)
7434 
7435         # Delete orphan compute node not reported by driver but still in db
7436         for cn in compute_nodes_in_db:
7437             if cn.hypervisor_hostname not in nodenames:
7438                 LOG.info("Deleting orphan compute node %(id)s "
7439                          "hypervisor host is %(hh)s, "
7440                          "nodes are %(nodes)s",
7441                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
7442                           'nodes': nodenames})
7443                 cn.destroy()
7444                 # Delete the corresponding resource provider in placement,
7445                 # along with any associated allocations and inventory.
7446                 # TODO(cdent): Move use of reportclient into resource tracker.
7447                 self.scheduler_client.reportclient.delete_resource_provider(
7448                     context, cn, cascade=True)
7449 
7450     def _get_compute_nodes_in_db(self, context, use_slave=False,
7451                                  startup=False):
7452         try:
7453             return objects.ComputeNodeList.get_all_by_host(context, self.host,
7454                                                            use_slave=use_slave)
7455         except exception.NotFound:
7456             if startup:
7457                 LOG.warning(
7458                     "No compute node record found for host %s. If this is "
7459                     "the first time this service is starting on this "
7460                     "host, then you can ignore this warning.", self.host)
7461             else:
7462                 LOG.error("No compute node record for host %s", self.host)
7463             return []
7464 
7465     @periodic_task.periodic_task(
7466         spacing=CONF.running_deleted_instance_poll_interval)
7467     def _cleanup_running_deleted_instances(self, context):
7468         """Cleanup any instances which are erroneously still running after
7469         having been deleted.
7470 
7471         Valid actions to take are:
7472 
7473             1. noop - do nothing
7474             2. log - log which instances are erroneously running
7475             3. reap - shutdown and cleanup any erroneously running instances
7476             4. shutdown - power off *and disable* any erroneously running
7477                           instances
7478 
7479         The use-case for this cleanup task is: for various reasons, it may be
7480         possible for the database to show an instance as deleted but for that
7481         instance to still be running on a host machine (see bug
7482         https://bugs.launchpad.net/nova/+bug/911366).
7483 
7484         This cleanup task is a cross-hypervisor utility for finding these
7485         zombied instances and either logging the discrepancy (likely what you
7486         should do in production), or automatically reaping the instances (more
7487         appropriate for dev environments).
7488         """
7489         action = CONF.running_deleted_instance_action
7490 
7491         if action == "noop":
7492             return
7493 
7494         # NOTE(sirp): admin contexts don't ordinarily return deleted records
7495         with utils.temporary_mutation(context, read_deleted="yes"):
7496             for instance in self._running_deleted_instances(context):
7497                 if action == "log":
7498                     LOG.warning("Detected instance with name label "
7499                                 "'%s' which is marked as "
7500                                 "DELETED but still present on host.",
7501                                 instance.name, instance=instance)
7502 
7503                 elif action == 'shutdown':
7504                     LOG.info("Powering off instance with name label "
7505                              "'%s' which is marked as "
7506                              "DELETED but still present on host.",
7507                              instance.name, instance=instance)
7508                     try:
7509                         try:
7510                             # disable starting the instance
7511                             self.driver.set_bootable(instance, False)
7512                         except NotImplementedError:
7513                             LOG.debug("set_bootable is not implemented "
7514                                       "for the current driver")
7515                         # and power it off
7516                         self.driver.power_off(instance)
7517                     except Exception:
7518                         LOG.warning("Failed to power off instance",
7519                                     instance=instance, exc_info=True)
7520 
7521                 elif action == 'reap':
7522                     LOG.info("Destroying instance with name label "
7523                              "'%s' which is marked as "
7524                              "DELETED but still present on host.",
7525                              instance.name, instance=instance)
7526                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7527                         context, instance.uuid, use_slave=True)
7528                     self.instance_events.clear_events_for_instance(instance)
7529                     try:
7530                         self._shutdown_instance(context, instance, bdms,
7531                                                 notify=False)
7532                         self._cleanup_volumes(context, instance, bdms,
7533                                               detach=False)
7534                     except Exception as e:
7535                         LOG.warning("Periodic cleanup failed to delete "
7536                                     "instance: %s",
7537                                     e, instance=instance)
7538                 else:
7539                     raise Exception(_("Unrecognized value '%s'"
7540                                       " for CONF.running_deleted_"
7541                                       "instance_action") % action)
7542 
7543     def _running_deleted_instances(self, context):
7544         """Returns a list of instances nova thinks is deleted,
7545         but the hypervisor thinks is still running.
7546         """
7547         timeout = CONF.running_deleted_instance_timeout
7548         filters = {'deleted': True,
7549                    'soft_deleted': False}
7550         instances = self._get_instances_on_driver(context, filters)
7551         return [i for i in instances if self._deleted_old_enough(i, timeout)]
7552 
7553     def _deleted_old_enough(self, instance, timeout):
7554         deleted_at = instance.deleted_at
7555         if deleted_at:
7556             deleted_at = deleted_at.replace(tzinfo=None)
7557         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
7558 
7559     @contextlib.contextmanager
7560     def _error_out_instance_on_exception(self, context, instance,
7561                                          instance_state=vm_states.ACTIVE):
7562         instance_uuid = instance.uuid
7563         try:
7564             yield
7565         except NotImplementedError as error:
7566             with excutils.save_and_reraise_exception():
7567                 LOG.info("Setting instance back to %(state)s after: "
7568                          "%(error)s",
7569                          {'state': instance_state, 'error': error},
7570                          instance_uuid=instance_uuid)
7571                 self._instance_update(context, instance,
7572                                       vm_state=instance_state,
7573                                       task_state=None)
7574         except exception.InstanceFaultRollback as error:
7575             LOG.info("Setting instance back to ACTIVE after: %s",
7576                      error, instance_uuid=instance_uuid)
7577             self._instance_update(context, instance,
7578                                   vm_state=vm_states.ACTIVE,
7579                                   task_state=None)
7580             raise error.inner_exception
7581         except Exception:
7582             LOG.exception('Setting instance vm_state to ERROR',
7583                           instance_uuid=instance_uuid)
7584             with excutils.save_and_reraise_exception():
7585                 self._set_instance_obj_error_state(context, instance)
7586 
7587     @wrap_exception()
7588     def add_aggregate_host(self, context, aggregate, host, slave_info):
7589         """Notify hypervisor of change (for hypervisor pools)."""
7590         try:
7591             self.driver.add_to_aggregate(context, aggregate, host,
7592                                          slave_info=slave_info)
7593         except NotImplementedError:
7594             LOG.debug('Hypervisor driver does not support '
7595                       'add_aggregate_host')
7596         except exception.AggregateError:
7597             with excutils.save_and_reraise_exception():
7598                 self.driver.undo_aggregate_operation(
7599                                     context,
7600                                     aggregate.delete_host,
7601                                     aggregate, host)
7602 
7603     @wrap_exception()
7604     def remove_aggregate_host(self, context, host, slave_info, aggregate):
7605         """Removes a host from a physical hypervisor pool."""
7606         try:
7607             self.driver.remove_from_aggregate(context, aggregate, host,
7608                                               slave_info=slave_info)
7609         except NotImplementedError:
7610             LOG.debug('Hypervisor driver does not support '
7611                       'remove_aggregate_host')
7612         except (exception.AggregateError,
7613                 exception.InvalidAggregateAction) as e:
7614             with excutils.save_and_reraise_exception():
7615                 self.driver.undo_aggregate_operation(
7616                                     context,
7617                                     aggregate.add_host,
7618                                     aggregate, host,
7619                                     isinstance(e, exception.AggregateError))
7620 
7621     def _process_instance_event(self, instance, event):
7622         _event = self.instance_events.pop_instance_event(instance, event)
7623         if _event:
7624             LOG.debug('Processing event %(event)s',
7625                       {'event': event.key}, instance=instance)
7626             _event.send(event)
7627         else:
7628             # If it's a network-vif-unplugged event and the instance is being
7629             # deleted then we don't need to make this a warning as it's
7630             # expected. There are other things which could trigger this like
7631             # detaching an interface, but we don't have a task state for that.
7632             if (event.name == 'network-vif-unplugged' and
7633                     instance.task_state == task_states.DELETING):
7634                 LOG.debug('Received event %s for instance which is being '
7635                           'deleted.', event.key, instance=instance)
7636             else:
7637                 LOG.warning('Received unexpected event %(event)s for '
7638                             'instance with vm_state %(vm_state)s and '
7639                             'task_state %(task_state)s.',
7640                             {'event': event.key,
7641                              'vm_state': instance.vm_state,
7642                              'task_state': instance.task_state},
7643                             instance=instance)
7644 
7645     def _process_instance_vif_deleted_event(self, context, instance,
7646                                             deleted_vif_id):
7647         # If an attached port is deleted by neutron, it needs to
7648         # be detached from the instance.
7649         # And info cache needs to be updated.
7650         network_info = instance.info_cache.network_info
7651         for index, vif in enumerate(network_info):
7652             if vif['id'] == deleted_vif_id:
7653                 LOG.info('Neutron deleted interface %(intf)s; '
7654                          'detaching it from the instance and '
7655                          'deleting it from the info cache',
7656                          {'intf': vif['id']},
7657                          instance=instance)
7658                 del network_info[index]
7659                 base_net_api.update_instance_cache_with_nw_info(
7660                                  self.network_api, context,
7661                                  instance,
7662                                  nw_info=network_info)
7663                 try:
7664                     self.driver.detach_interface(context, instance, vif)
7665                 except NotImplementedError:
7666                     # Not all virt drivers support attach/detach of interfaces
7667                     # yet (like Ironic), so just ignore this.
7668                     pass
7669                 except exception.NovaException as ex:
7670                     # If the instance was deleted before the interface was
7671                     # detached, just log it at debug.
7672                     log_level = (logging.DEBUG
7673                                  if isinstance(ex, exception.InstanceNotFound)
7674                                  else logging.WARNING)
7675                     LOG.log(log_level,
7676                             "Detach interface failed, "
7677                             "port_id=%(port_id)s, reason: %(msg)s",
7678                             {'port_id': deleted_vif_id, 'msg': ex},
7679                             instance=instance)
7680                 break
7681 
7682     @wrap_instance_event(prefix='compute')
7683     @wrap_instance_fault
7684     def extend_volume(self, context, instance, extended_volume_id):
7685 
7686         # If an attached volume is extended by cinder, it needs to
7687         # be extended by virt driver so host can detect its new size.
7688         # And bdm needs to be updated.
7689         LOG.debug('Handling volume-extended event for volume %(vol)s',
7690                   {'vol': extended_volume_id}, instance=instance)
7691 
7692         try:
7693             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
7694                    context, extended_volume_id, instance.uuid)
7695         except exception.NotFound:
7696             LOG.warning('Extend volume failed, '
7697                         'volume %(vol)s is not attached to instance.',
7698                         {'vol': extended_volume_id},
7699                         instance=instance)
7700             return
7701 
7702         LOG.info('Cinder extended volume %(vol)s; '
7703                  'extending it to detect new size',
7704                  {'vol': extended_volume_id},
7705                  instance=instance)
7706         volume = self.volume_api.get(context, bdm.volume_id)
7707 
7708         if bdm.connection_info is None:
7709             LOG.warning('Extend volume failed, '
7710                         'attached volume %(vol)s has no connection_info',
7711                         {'vol': extended_volume_id},
7712                         instance=instance)
7713             return
7714 
7715         connection_info = jsonutils.loads(bdm.connection_info)
7716         bdm.volume_size = volume['size']
7717         bdm.save()
7718 
7719         if not self.driver.capabilities.get('supports_extend_volume', False):
7720             raise exception.ExtendVolumeNotSupported()
7721 
7722         try:
7723             self.driver.extend_volume(connection_info,
7724                                       instance)
7725         except Exception as ex:
7726             LOG.warning('Extend volume failed, '
7727                         'volume_id=%(volume_id)s, reason: %(msg)s',
7728                         {'volume_id': extended_volume_id, 'msg': ex},
7729                         instance=instance)
7730             raise
7731 
7732     @wrap_exception()
7733     def external_instance_event(self, context, instances, events):
7734         # NOTE(danms): Some event types are handled by the manager, such
7735         # as when we're asked to update the instance's info_cache. If it's
7736         # not one of those, look for some thread(s) waiting for the event and
7737         # unblock them if so.
7738         for event in events:
7739             instance = [inst for inst in instances
7740                         if inst.uuid == event.instance_uuid][0]
7741             LOG.debug('Received event %(event)s',
7742                       {'event': event.key},
7743                       instance=instance)
7744             if event.name == 'network-changed':
7745                 try:
7746                     self.network_api.get_instance_nw_info(context, instance)
7747                 except exception.NotFound as e:
7748                     LOG.info('Failed to process external instance event '
7749                              '%(event)s due to: %(error)s',
7750                              {'event': event.key, 'error': six.text_type(e)},
7751                              instance=instance)
7752             elif event.name == 'network-vif-deleted':
7753                 try:
7754                     self._process_instance_vif_deleted_event(context,
7755                                                              instance,
7756                                                              event.tag)
7757                 except exception.NotFound as e:
7758                     LOG.info('Failed to process external instance event '
7759                              '%(event)s due to: %(error)s',
7760                              {'event': event.key, 'error': six.text_type(e)},
7761                              instance=instance)
7762             elif event.name == 'volume-extended':
7763                 self.extend_volume(context, instance, event.tag)
7764             else:
7765                 self._process_instance_event(instance, event)
7766 
7767     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
7768                                  external_process_ok=True)
7769     def _run_image_cache_manager_pass(self, context):
7770         """Run a single pass of the image cache manager."""
7771 
7772         if not self.driver.capabilities.get("has_imagecache", False):
7773             return
7774 
7775         # Determine what other nodes use this storage
7776         storage_users.register_storage_use(CONF.instances_path, CONF.host)
7777         nodes = storage_users.get_storage_users(CONF.instances_path)
7778 
7779         # Filter all_instances to only include those nodes which share this
7780         # storage path.
7781         # TODO(mikal): this should be further refactored so that the cache
7782         # cleanup code doesn't know what those instances are, just a remote
7783         # count, and then this logic should be pushed up the stack.
7784         filters = {'deleted': False,
7785                    'soft_deleted': True,
7786                    'host': nodes}
7787         filtered_instances = objects.InstanceList.get_by_filters(context,
7788                                  filters, expected_attrs=[], use_slave=True)
7789 
7790         self.driver.manage_image_cache(context, filtered_instances)
7791 
7792     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7793     def _run_pending_deletes(self, context):
7794         """Retry any pending instance file deletes."""
7795         LOG.debug('Cleaning up deleted instances')
7796         filters = {'deleted': True,
7797                    'soft_deleted': False,
7798                    'host': CONF.host,
7799                    'cleaned': False}
7800         attrs = ['system_metadata']
7801         with utils.temporary_mutation(context, read_deleted='yes'):
7802             instances = objects.InstanceList.get_by_filters(
7803                 context, filters, expected_attrs=attrs, use_slave=True)
7804         LOG.debug('There are %d instances to clean', len(instances))
7805 
7806         # TODO(raj_singh): Remove this if condition when min value is
7807         # introduced to "maximum_instance_delete_attempts" cfg option.
7808         if CONF.maximum_instance_delete_attempts < 1:
7809             LOG.warning('Future versions of Nova will restrict the '
7810                         '"maximum_instance_delete_attempts" config option '
7811                         'to values >=1. Update your configuration file to '
7812                         'mitigate future upgrade issues.')
7813 
7814         for instance in instances:
7815             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
7816             LOG.debug('Instance has had %(attempts)s of %(max)s '
7817                       'cleanup attempts',
7818                       {'attempts': attempts,
7819                        'max': CONF.maximum_instance_delete_attempts},
7820                       instance=instance)
7821             if attempts < CONF.maximum_instance_delete_attempts:
7822                 success = self.driver.delete_instance_files(instance)
7823 
7824                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
7825                 if success:
7826                     instance.cleaned = True
7827                 with utils.temporary_mutation(context, read_deleted='yes'):
7828                     instance.save()
7829 
7830     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7831     def _cleanup_incomplete_migrations(self, context):
7832         """Delete instance files on failed resize/revert-resize operation
7833 
7834         During resize/revert-resize operation, if that instance gets deleted
7835         in-between then instance files might remain either on source or
7836         destination compute node because of race condition.
7837         """
7838         LOG.debug('Cleaning up deleted instances with incomplete migration ')
7839         migration_filters = {'host': CONF.host,
7840                              'status': 'error'}
7841         migrations = objects.MigrationList.get_by_filters(context,
7842                                                           migration_filters)
7843 
7844         if not migrations:
7845             return
7846 
7847         inst_uuid_from_migrations = set([migration.instance_uuid for migration
7848                                          in migrations])
7849 
7850         inst_filters = {'deleted': True, 'soft_deleted': False,
7851                         'uuid': inst_uuid_from_migrations}
7852         attrs = ['info_cache', 'security_groups', 'system_metadata']
7853         with utils.temporary_mutation(context, read_deleted='yes'):
7854             instances = objects.InstanceList.get_by_filters(
7855                 context, inst_filters, expected_attrs=attrs, use_slave=True)
7856 
7857         for instance in instances:
7858             if instance.host != CONF.host:
7859                 for migration in migrations:
7860                     if instance.uuid == migration.instance_uuid:
7861                         # Delete instance files if not cleanup properly either
7862                         # from the source or destination compute nodes when
7863                         # the instance is deleted during resizing.
7864                         self.driver.delete_instance_files(instance)
7865                         try:
7866                             migration.status = 'failed'
7867                             with migration.obj_as_admin():
7868                                 migration.save()
7869                         except exception.MigrationNotFound:
7870                             LOG.warning("Migration %s is not found.",
7871                                         migration.id,
7872                                         instance=instance)
7873                         break
7874 
7875     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7876                                    exception.QemuGuestAgentNotEnabled,
7877                                    exception.NovaException,
7878                                    NotImplementedError)
7879     @wrap_exception()
7880     def quiesce_instance(self, context, instance):
7881         """Quiesce an instance on this host."""
7882         context = context.elevated()
7883         image_meta = objects.ImageMeta.from_instance(instance)
7884         self.driver.quiesce(context, instance, image_meta)
7885 
7886     def _wait_for_snapshots_completion(self, context, mapping):
7887         for mapping_dict in mapping:
7888             if mapping_dict.get('source_type') == 'snapshot':
7889 
7890                 def _wait_snapshot():
7891                     snapshot = self.volume_api.get_snapshot(
7892                         context, mapping_dict['snapshot_id'])
7893                     if snapshot.get('status') != 'creating':
7894                         raise loopingcall.LoopingCallDone()
7895 
7896                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
7897                 timer.start(interval=0.5).wait()
7898 
7899     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7900                                    exception.QemuGuestAgentNotEnabled,
7901                                    exception.NovaException,
7902                                    NotImplementedError)
7903     @wrap_exception()
7904     def unquiesce_instance(self, context, instance, mapping=None):
7905         """Unquiesce an instance on this host.
7906 
7907         If snapshots' image mapping is provided, it waits until snapshots are
7908         completed before unqueiscing.
7909         """
7910         context = context.elevated()
7911         if mapping:
7912             try:
7913                 self._wait_for_snapshots_completion(context, mapping)
7914             except Exception as error:
7915                 LOG.exception("Exception while waiting completion of "
7916                               "volume snapshots: %s",
7917                               error, instance=instance)
7918         image_meta = objects.ImageMeta.from_instance(instance)
7919         self.driver.unquiesce(context, instance, image_meta)
7920 
7921     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7922     def _cleanup_expired_console_auth_tokens(self, context):
7923         """Remove expired console auth tokens for this host.
7924 
7925         Console authorization tokens and their connection data are stored
7926         in the database when a user asks for a console connection to an
7927         instance. After a time they expire. We periodically remove any expired
7928         tokens from the database.
7929         """
7930         # If the database backend isn't in use, don't bother looking for
7931         # expired tokens. The database backend is not supported for cells v1.
7932         if not CONF.cells.enable:
7933             objects.ConsoleAuthToken.\
7934                 clean_expired_console_auths_for_host(context, self.host)
