Based on the given code from a commit, please generate supplementary code files according to the commit message.
####commit message
Lock detach_volume

A detach_volume operation may take place during a attach_volume or
delete_instance opertaion. This may lead to a race condition which
would result in an instance going into an error state as the volume
operation is not atomic.

Commit 4c4dc3a6d added the lock around the attach_volume. This
follows that same pattern.

Co-Authored-By: Matthew Booth <mbooth@redhat.com>

Change-Id: I7261135a44f0c2eca4732c8360b9c74b729991a8
Closes-bug: #1662483

####code 
1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 from cursive import exception as cursive_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 import futurist
44 from keystoneauth1 import exceptions as keystone_exception
45 from oslo_log import log as logging
46 import oslo_messaging as messaging
47 from oslo_serialization import jsonutils
48 from oslo_service import loopingcall
49 from oslo_service import periodic_task
50 from oslo_utils import excutils
51 from oslo_utils import strutils
52 from oslo_utils import timeutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova.console import rpcapi as console_rpcapi
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova import image
77 from nova import manager
78 from nova import network
79 from nova.network import base_api as base_net_api
80 from nova.network import model as network_model
81 from nova.network.security_group import openstack_driver
82 from nova import objects
83 from nova.objects import base as obj_base
84 from nova.objects import fields
85 from nova.objects import instance as obj_instance
86 from nova.objects import migrate_data as migrate_data_obj
87 from nova.pci import whitelist
88 from nova import rpc
89 from nova import safe_utils
90 from nova.scheduler.client import query
91 from nova import utils
92 from nova.virt import block_device as driver_block_device
93 from nova.virt import configdrive
94 from nova.virt import driver
95 from nova.virt import event as virtevent
96 from nova.virt import storage_users
97 from nova.virt import virtapi
98 from nova.volume import cinder
99 
100 CONF = nova.conf.CONF
101 
102 LOG = logging.getLogger(__name__)
103 
104 get_notifier = functools.partial(rpc.get_notifier, service='compute')
105 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
106                                    get_notifier=get_notifier,
107                                    binary='nova-compute')
108 
109 
110 @contextlib.contextmanager
111 def errors_out_migration_ctxt(migration):
112     """Context manager to error out migration on failure."""
113 
114     try:
115         yield
116     except Exception:
117         with excutils.save_and_reraise_exception():
118             if migration:
119                 # We may have been passed None for our migration if we're
120                 # receiving from an older client. The migration will be
121                 # errored via the legacy path.
122                 migration.status = 'error'
123                 try:
124                     with migration.obj_as_admin():
125                         migration.save()
126                 except Exception:
127                     LOG.debug(
128                         'Error setting migration status for instance %s.',
129                         migration.instance_uuid, exc_info=True)
130 
131 
132 @utils.expects_func_args('migration')
133 def errors_out_migration(function):
134     """Decorator to error out migration on failure."""
135 
136     @functools.wraps(function)
137     def decorated_function(self, context, *args, **kwargs):
138         wrapped_func = safe_utils.get_wrapped_function(function)
139         keyed_args = inspect.getcallargs(wrapped_func, self, context,
140                                          *args, **kwargs)
141         migration = keyed_args['migration']
142         with errors_out_migration_ctxt(migration):
143             return function(self, context, *args, **kwargs)
144 
145     return decorated_function
146 
147 
148 @utils.expects_func_args('instance')
149 def reverts_task_state(function):
150     """Decorator to revert task_state on failure."""
151 
152     @functools.wraps(function)
153     def decorated_function(self, context, *args, **kwargs):
154         try:
155             return function(self, context, *args, **kwargs)
156         except exception.UnexpectedTaskStateError as e:
157             # Note(maoy): unexpected task state means the current
158             # task is preempted. Do not clear task state in this
159             # case.
160             with excutils.save_and_reraise_exception():
161                 LOG.info("Task possibly preempted: %s",
162                          e.format_message())
163         except Exception:
164             with excutils.save_and_reraise_exception():
165                 wrapped_func = safe_utils.get_wrapped_function(function)
166                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
167                                                  *args, **kwargs)
168                 # NOTE(mriedem): 'instance' must be in keyed_args because we
169                 # have utils.expects_func_args('instance') decorating this
170                 # method.
171                 instance = keyed_args['instance']
172                 original_task_state = instance.task_state
173                 try:
174                     self._instance_update(context, instance, task_state=None)
175                     LOG.info("Successfully reverted task state from %s on "
176                              "failure for instance.",
177                              original_task_state, instance=instance)
178                 except exception.InstanceNotFound:
179                     # We might delete an instance that failed to build shortly
180                     # after it errored out this is an expected case and we
181                     # should not trace on it.
182                     pass
183                 except Exception as e:
184                     LOG.warning("Failed to revert task state for instance. "
185                                 "Error: %s", e, instance=instance)
186 
187     return decorated_function
188 
189 
190 @utils.expects_func_args('instance')
191 def wrap_instance_fault(function):
192     """Wraps a method to catch exceptions related to instances.
193 
194     This decorator wraps a method to catch any exceptions having to do with
195     an instance that may get thrown. It then logs an instance fault in the db.
196     """
197 
198     @functools.wraps(function)
199     def decorated_function(self, context, *args, **kwargs):
200         try:
201             return function(self, context, *args, **kwargs)
202         except exception.InstanceNotFound:
203             raise
204         except Exception as e:
205             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
206             # we will get a KeyError exception which will cover up the real
207             # exception. So, we update kwargs with the values from args first.
208             # then, we can get 'instance' from kwargs easily.
209             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
210 
211             with excutils.save_and_reraise_exception():
212                 compute_utils.add_instance_fault_from_exc(context,
213                         kwargs['instance'], e, sys.exc_info())
214 
215     return decorated_function
216 
217 
218 @utils.expects_func_args('image_id', 'instance')
219 def delete_image_on_error(function):
220     """Used for snapshot related method to ensure the image created in
221     compute.api is deleted when an error occurs.
222     """
223 
224     @functools.wraps(function)
225     def decorated_function(self, context, image_id, instance,
226                            *args, **kwargs):
227         try:
228             return function(self, context, image_id, instance,
229                             *args, **kwargs)
230         except Exception:
231             with excutils.save_and_reraise_exception():
232                 LOG.debug("Cleaning up image %s", image_id,
233                           exc_info=True, instance=instance)
234                 try:
235                     self.image_api.delete(context, image_id)
236                 except exception.ImageNotFound:
237                     # Since we're trying to cleanup an image, we don't care if
238                     # if it's already gone.
239                     pass
240                 except Exception:
241                     LOG.exception("Error while trying to clean up image %s",
242                                   image_id, instance=instance)
243 
244     return decorated_function
245 
246 
247 # TODO(danms): Remove me after Icehouse
248 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
249 # NOTE(mikal): if the method being decorated has more than one decorator, then
250 # put this one first. Otherwise the various exception handling decorators do
251 # not function correctly.
252 def object_compat(function):
253     """Wraps a method that expects a new-world instance
254 
255     This provides compatibility for callers passing old-style dict
256     instances.
257     """
258 
259     @functools.wraps(function)
260     def decorated_function(self, context, *args, **kwargs):
261         def _load_instance(instance_or_dict):
262             if isinstance(instance_or_dict, dict):
263                 # try to get metadata and system_metadata for most cases but
264                 # only attempt to load those if the db instance already has
265                 # those fields joined
266                 metas = [meta for meta in ('metadata', 'system_metadata')
267                          if meta in instance_or_dict]
268                 instance = objects.Instance._from_db_object(
269                     context, objects.Instance(), instance_or_dict,
270                     expected_attrs=metas)
271                 instance._context = context
272                 return instance
273             return instance_or_dict
274 
275         try:
276             kwargs['instance'] = _load_instance(kwargs['instance'])
277         except KeyError:
278             args = (_load_instance(args[0]),) + args[1:]
279 
280         migration = kwargs.get('migration')
281         if isinstance(migration, dict):
282             migration = objects.Migration._from_db_object(
283                     context.elevated(), objects.Migration(),
284                     migration)
285             kwargs['migration'] = migration
286 
287         return function(self, context, *args, **kwargs)
288 
289     return decorated_function
290 
291 
292 class InstanceEvents(object):
293     def __init__(self):
294         self._events = {}
295 
296     @staticmethod
297     def _lock_name(instance):
298         return '%s-%s' % (instance.uuid, 'events')
299 
300     def prepare_for_instance_event(self, instance, name, tag):
301         """Prepare to receive an event for an instance.
302 
303         This will register an event for the given instance that we will
304         wait on later. This should be called before initiating whatever
305         action will trigger the event. The resulting eventlet.event.Event
306         object should be wait()'d on to ensure completion.
307 
308         :param instance: the instance for which the event will be generated
309         :param name: the name of the event we're expecting
310         :param tag: the tag associated with the event we're expecting
311         :returns: an event object that should be wait()'d on
312         """
313         if self._events is None:
314             # NOTE(danms): We really should have a more specific error
315             # here, but this is what we use for our default error case
316             raise exception.NovaException('In shutdown, no new events '
317                                           'can be scheduled')
318 
319         @utils.synchronized(self._lock_name(instance))
320         def _create_or_get_event():
321             instance_events = self._events.setdefault(instance.uuid, {})
322             return instance_events.setdefault((name, tag),
323                                               eventlet.event.Event())
324         LOG.debug('Preparing to wait for external event %(name)s-%(tag)s',
325                   {'name': name, 'tag': tag}, instance=instance)
326         return _create_or_get_event()
327 
328     def pop_instance_event(self, instance, event):
329         """Remove a pending event from the wait list.
330 
331         This will remove a pending event from the wait list so that it
332         can be used to signal the waiters to wake up.
333 
334         :param instance: the instance for which the event was generated
335         :param event: the nova.objects.external_event.InstanceExternalEvent
336                       that describes the event
337         :returns: the eventlet.event.Event object on which the waiters
338                   are blocked
339         """
340         no_events_sentinel = object()
341         no_matching_event_sentinel = object()
342 
343         @utils.synchronized(self._lock_name(instance))
344         def _pop_event():
345             if self._events is None:
346                 LOG.debug('Unexpected attempt to pop events during shutdown',
347                           instance=instance)
348                 return no_events_sentinel
349             events = self._events.get(instance.uuid)
350             if not events:
351                 return no_events_sentinel
352             _event = events.pop((event.name, event.tag), None)
353             if not events:
354                 del self._events[instance.uuid]
355             if _event is None:
356                 return no_matching_event_sentinel
357             return _event
358 
359         result = _pop_event()
360         if result is no_events_sentinel:
361             LOG.debug('No waiting events found dispatching %(event)s',
362                       {'event': event.key},
363                       instance=instance)
364             return None
365         elif result is no_matching_event_sentinel:
366             LOG.debug('No event matching %(event)s in %(events)s',
367                       {'event': event.key,
368                        'events': self._events.get(instance.uuid, {}).keys()},
369                       instance=instance)
370             return None
371         else:
372             return result
373 
374     def clear_events_for_instance(self, instance):
375         """Remove all pending events for an instance.
376 
377         This will remove all events currently pending for an instance
378         and return them (indexed by event name).
379 
380         :param instance: the instance for which events should be purged
381         :returns: a dictionary of {event_name: eventlet.event.Event}
382         """
383         @utils.synchronized(self._lock_name(instance))
384         def _clear_events():
385             if self._events is None:
386                 LOG.debug('Unexpected attempt to clear events during shutdown',
387                           instance=instance)
388                 return dict()
389             # NOTE(danms): We have historically returned the raw internal
390             # format here, which is {event.key: [events, ...])} so just
391             # trivially convert it here.
392             return {'%s-%s' % k: e
393                     for k, e in self._events.pop(instance.uuid, {}).items()}
394         return _clear_events()
395 
396     def cancel_all_events(self):
397         if self._events is None:
398             LOG.debug('Unexpected attempt to cancel events during shutdown.')
399             return
400         our_events = self._events
401         # NOTE(danms): Block new events
402         self._events = None
403 
404         for instance_uuid, events in our_events.items():
405             for (name, tag), eventlet_event in events.items():
406                 LOG.debug('Canceling in-flight event %(name)s-%(tag)s for '
407                           'instance %(instance_uuid)s',
408                           {'name': name,
409                            'tag': tag,
410                            'instance_uuid': instance_uuid})
411                 event = objects.InstanceExternalEvent(
412                     instance_uuid=instance_uuid,
413                     name=name, status='failed',
414                     tag=tag, data={})
415                 eventlet_event.send(event)
416 
417 
418 class ComputeVirtAPI(virtapi.VirtAPI):
419     def __init__(self, compute):
420         super(ComputeVirtAPI, self).__init__()
421         self._compute = compute
422 
423     def _default_error_callback(self, event_name, instance):
424         raise exception.NovaException(_('Instance event failed'))
425 
426     @contextlib.contextmanager
427     def wait_for_instance_event(self, instance, event_names, deadline=300,
428                                 error_callback=None):
429         """Plan to wait for some events, run some code, then wait.
430 
431         This context manager will first create plans to wait for the
432         provided event_names, yield, and then wait for all the scheduled
433         events to complete.
434 
435         Note that this uses an eventlet.timeout.Timeout to bound the
436         operation, so callers should be prepared to catch that
437         failure and handle that situation appropriately.
438 
439         If the event is not received by the specified timeout deadline,
440         eventlet.timeout.Timeout is raised.
441 
442         If the event is received but did not have a 'completed'
443         status, a NovaException is raised.  If an error_callback is
444         provided, instead of raising an exception as detailed above
445         for the failure case, the callback will be called with the
446         event_name and instance, and can return True to continue
447         waiting for the rest of the events, False to stop processing,
448         or raise an exception which will bubble up to the waiter.
449 
450         :param instance: The instance for which an event is expected
451         :param event_names: A list of event names. Each element is a
452                             tuple of strings to indicate (name, tag),
453                             where name is required, but tag may be None.
454         :param deadline: Maximum number of seconds we should wait for all
455                          of the specified events to arrive.
456         :param error_callback: A function to be called if an event arrives
457 
458         """
459 
460         if error_callback is None:
461             error_callback = self._default_error_callback
462         events = {}
463         for event_name in event_names:
464             name, tag = event_name
465             event_name = objects.InstanceExternalEvent.make_key(name, tag)
466             try:
467                 events[event_name] = (
468                     self._compute.instance_events.prepare_for_instance_event(
469                         instance, name, tag))
470             except exception.NovaException:
471                 error_callback(event_name, instance)
472                 # NOTE(danms): Don't wait for any of the events. They
473                 # should all be canceled and fired immediately below,
474                 # but don't stick around if not.
475                 deadline = 0
476         yield
477         with eventlet.timeout.Timeout(deadline):
478             for event_name, event in events.items():
479                 actual_event = event.wait()
480                 if actual_event.status == 'completed':
481                     continue
482                 decision = error_callback(event_name, instance)
483                 if decision is False:
484                     break
485 
486 
487 class ComputeManager(manager.Manager):
488     """Manages the running instances from creation to destruction."""
489 
490     target = messaging.Target(version='5.1')
491 
492     def __init__(self, compute_driver=None, *args, **kwargs):
493         """Load configuration options and connect to the hypervisor."""
494         self.virtapi = ComputeVirtAPI(self)
495         self.network_api = network.API()
496         self.volume_api = cinder.API()
497         self.image_api = image.API()
498         self._last_host_check = 0
499         self._last_bw_usage_poll = 0
500         self._bw_usage_supported = True
501         self._last_bw_usage_cell_update = 0
502         self.compute_api = compute.API()
503         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
504         self.conductor_api = conductor.API()
505         self.compute_task_api = conductor.ComputeTaskAPI()
506         self.is_neutron_security_groups = (
507             openstack_driver.is_neutron_security_groups())
508         self.cells_rpcapi = cells_rpcapi.CellsAPI()
509         self.query_client = query.SchedulerQueryClient()
510         self.instance_events = InstanceEvents()
511         self._sync_power_pool = eventlet.GreenPool(
512             size=CONF.sync_power_state_pool_size)
513         self._syncs_in_progress = {}
514         self.send_instance_updates = (
515             CONF.filter_scheduler.track_instance_changes)
516         if CONF.max_concurrent_builds != 0:
517             self._build_semaphore = eventlet.semaphore.Semaphore(
518                 CONF.max_concurrent_builds)
519         else:
520             self._build_semaphore = compute_utils.UnlimitedSemaphore()
521         if max(CONF.max_concurrent_live_migrations, 0) != 0:
522             self._live_migration_executor = futurist.GreenThreadPoolExecutor(
523                 max_workers=CONF.max_concurrent_live_migrations)
524         else:
525             if CONF.max_concurrent_live_migrations < 0:
526                 LOG.warning('The value of the max_concurrent_live_migrations '
527                             'config option is less than 0. '
528                             'It is treated as 0 and will raise ValueError '
529                             'in a future release.')
530             self._live_migration_executor = futurist.GreenThreadPoolExecutor()
531         # This is a dict, keyed by instance uuid, to a two-item tuple of
532         # migration object and Future for the queued live migration.
533         self._waiting_live_migrations = {}
534 
535         super(ComputeManager, self).__init__(service_name="compute",
536                                              *args, **kwargs)
537 
538         # NOTE(russellb) Load the driver last.  It may call back into the
539         # compute manager via the virtapi, so we want it to be fully
540         # initialized before that happens.
541         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
542         self.use_legacy_block_device_info = \
543                             self.driver.need_legacy_block_device_info
544         self.rt = resource_tracker.ResourceTracker(self.host, self.driver)
545         self.reportclient = self.rt.reportclient
546 
547     def reset(self):
548         LOG.info('Reloading compute RPC API')
549         compute_rpcapi.LAST_VERSION = None
550         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
551         self.reportclient.clear_provider_cache()
552 
553     def _update_resource_tracker(self, context, instance):
554         """Let the resource tracker know that an instance has changed state."""
555 
556         if instance.host == self.host:
557             self.rt.update_usage(context, instance, instance.node)
558 
559     def _instance_update(self, context, instance, **kwargs):
560         """Update an instance in the database using kwargs as value."""
561 
562         for k, v in kwargs.items():
563             setattr(instance, k, v)
564         instance.save()
565         self._update_resource_tracker(context, instance)
566 
567     def _nil_out_instance_obj_host_and_node(self, instance):
568         # NOTE(jwcroppe): We don't do instance.save() here for performance
569         # reasons; a call to this is expected to be immediately followed by
570         # another call that does instance.save(), thus avoiding two writes
571         # to the database layer.
572         instance.host = None
573         instance.node = None
574         # If the instance is not on a host, it's not in an aggregate and
575         # therefore is not in an availability zone.
576         instance.availability_zone = None
577 
578     def _set_instance_obj_error_state(self, context, instance,
579                                       clean_task_state=False):
580         try:
581             instance.vm_state = vm_states.ERROR
582             if clean_task_state:
583                 instance.task_state = None
584             instance.save()
585         except exception.InstanceNotFound:
586             LOG.debug('Instance has been destroyed from under us while '
587                       'trying to set it to ERROR', instance=instance)
588 
589     def _get_instances_on_driver(self, context, filters=None):
590         """Return a list of instance records for the instances found
591         on the hypervisor which satisfy the specified filters. If filters=None
592         return a list of instance records for all the instances found on the
593         hypervisor.
594         """
595         if not filters:
596             filters = {}
597         try:
598             driver_uuids = self.driver.list_instance_uuids()
599             if len(driver_uuids) == 0:
600                 # Short circuit, don't waste a DB call
601                 return objects.InstanceList()
602             filters['uuid'] = driver_uuids
603             local_instances = objects.InstanceList.get_by_filters(
604                 context, filters, use_slave=True)
605             return local_instances
606         except NotImplementedError:
607             pass
608 
609         # The driver doesn't support uuids listing, so we'll have
610         # to brute force.
611         driver_instances = self.driver.list_instances()
612         # NOTE(mjozefcz): In this case we need to apply host filter.
613         # Without this all instance data would be fetched from db.
614         filters['host'] = self.host
615         instances = objects.InstanceList.get_by_filters(context, filters,
616                                                         use_slave=True)
617         name_map = {instance.name: instance for instance in instances}
618         local_instances = []
619         for driver_instance in driver_instances:
620             instance = name_map.get(driver_instance)
621             if not instance:
622                 continue
623             local_instances.append(instance)
624         return local_instances
625 
626     def _destroy_evacuated_instances(self, context):
627         """Destroys evacuated instances.
628 
629         While nova-compute was down, the instances running on it could be
630         evacuated to another host. This method looks for evacuation migration
631         records where this is the source host and which were either started
632         (accepted), in-progress (pre-migrating) or migrated (done). From those
633         migration records, local instances reported by the hypervisor are
634         compared to the instances for the migration records and those local
635         guests are destroyed, along with instance allocation records in
636         Placement for this node.
637         """
638         filters = {
639             'source_compute': self.host,
640             # NOTE(mriedem): Migration records that have been accepted are
641             # included in case the source node comes back up while instances
642             # are being evacuated to another host. We don't want the same
643             # instance being reported from multiple hosts.
644             # NOTE(lyarwood): pre-migrating is also included here as the
645             # source compute can come back online shortly after the RT
646             # claims on the destination that in-turn moves the migration to
647             # pre-migrating. If the evacuate fails on the destination host,
648             # the user can rebuild the instance (in ERROR state) on the source
649             # host.
650             'status': ['accepted', 'pre-migrating', 'done'],
651             'migration_type': 'evacuation',
652         }
653         with utils.temporary_mutation(context, read_deleted='yes'):
654             evacuations = objects.MigrationList.get_by_filters(context,
655                                                                filters)
656         if not evacuations:
657             return
658         evacuations = {mig.instance_uuid: mig for mig in evacuations}
659 
660         # TODO(mriedem): We could optimize by pre-loading the joined fields
661         # we know we'll use, like info_cache and flavor.
662         local_instances = self._get_instances_on_driver(context)
663         evacuated = [inst for inst in local_instances
664                      if inst.uuid in evacuations]
665 
666         # NOTE(gibi): We are called from init_host and at this point the
667         # compute_nodes of the resource tracker has not been populated yet so
668         # we cannot rely on the resource tracker here.
669         compute_nodes = {}
670 
671         for instance in evacuated:
672             migration = evacuations[instance.uuid]
673             LOG.info('Deleting instance as it has been evacuated from '
674                      'this host', instance=instance)
675             try:
676                 network_info = self.network_api.get_instance_nw_info(
677                     context, instance)
678                 bdi = self._get_instance_block_device_info(context,
679                                                            instance)
680                 destroy_disks = not (self._is_instance_storage_shared(
681                     context, instance))
682             except exception.InstanceNotFound:
683                 network_info = network_model.NetworkInfo()
684                 bdi = {}
685                 LOG.info('Instance has been marked deleted already, '
686                          'removing it from the hypervisor.',
687                          instance=instance)
688                 # always destroy disks if the instance was deleted
689                 destroy_disks = True
690             self.driver.destroy(context, instance,
691                                 network_info,
692                                 bdi, destroy_disks)
693 
694             # delete the allocation of the evacuated instance from this host
695             if migration.source_node not in compute_nodes:
696                 try:
697                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
698                         context, self.host, migration.source_node).uuid
699                     compute_nodes[migration.source_node] = cn_uuid
700                 except exception.ComputeHostNotFound:
701                     LOG.error("Failed to clean allocation of evacuated "
702                               "instance as the source node %s is not found",
703                               migration.source_node, instance=instance)
704                     continue
705             cn_uuid = compute_nodes[migration.source_node]
706 
707             # If the instance was deleted in the interim, assume its
708             # allocations were properly cleaned up (either by its hosting
709             # compute service or the API).
710             if (not instance.deleted and
711                     not self.reportclient.
712                         remove_provider_tree_from_instance_allocation(
713                             context, instance.uuid, cn_uuid)):
714                 LOG.error("Failed to clean allocation of evacuated instance "
715                           "on the source node %s",
716                           cn_uuid, instance=instance)
717 
718             migration.status = 'completed'
719             migration.save()
720         return evacuations
721 
722     def _is_instance_storage_shared(self, context, instance, host=None):
723         shared_storage = True
724         data = None
725         try:
726             data = self.driver.check_instance_shared_storage_local(context,
727                                                        instance)
728             if data:
729                 shared_storage = (self.compute_rpcapi.
730                                   check_instance_shared_storage(context,
731                                   instance, data, host=host))
732         except NotImplementedError:
733             LOG.debug('Hypervisor driver does not support '
734                       'instance shared storage check, '
735                       'assuming it\'s not on shared storage',
736                       instance=instance)
737             shared_storage = False
738         except Exception:
739             LOG.exception('Failed to check if instance shared',
740                           instance=instance)
741         finally:
742             if data:
743                 self.driver.check_instance_shared_storage_cleanup(context,
744                                                                   data)
745         return shared_storage
746 
747     def _complete_partial_deletion(self, context, instance):
748         """Complete deletion for instances in DELETED status but not marked as
749         deleted in the DB
750         """
751         instance.destroy()
752         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
753                 context, instance.uuid)
754         self._complete_deletion(context,
755                                 instance)
756         self._notify_about_instance_usage(context, instance, "delete.end")
757         compute_utils.notify_about_instance_action(context, instance,
758                 self.host, action=fields.NotificationAction.DELETE,
759                 phase=fields.NotificationPhase.END, bdms=bdms)
760 
761     def _complete_deletion(self, context, instance):
762         self._update_resource_tracker(context, instance)
763 
764         self.reportclient.delete_allocation_for_instance(context,
765                                                          instance.uuid)
766 
767         self._clean_instance_console_tokens(context, instance)
768         self._delete_scheduler_instance_info(context, instance.uuid)
769 
770     def _init_instance(self, context, instance):
771         """Initialize this instance during service init."""
772 
773         # NOTE(danms): If the instance appears to not be owned by this
774         # host, it may have been evacuated away, but skipped by the
775         # evacuation cleanup code due to configuration. Thus, if that
776         # is a possibility, don't touch the instance in any way, but
777         # log the concern. This will help avoid potential issues on
778         # startup due to misconfiguration.
779         if instance.host != self.host:
780             LOG.warning('Instance %(uuid)s appears to not be owned '
781                         'by this host, but by %(host)s. Startup '
782                         'processing is being skipped.',
783                         {'uuid': instance.uuid,
784                          'host': instance.host})
785             return
786 
787         # Instances that are shut down, or in an error state can not be
788         # initialized and are not attempted to be recovered. The exception
789         # to this are instances that are in RESIZE_MIGRATING or DELETING,
790         # which are dealt with further down.
791         if (instance.vm_state == vm_states.SOFT_DELETED or
792             (instance.vm_state == vm_states.ERROR and
793             instance.task_state not in
794             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
795             LOG.debug("Instance is in %s state.",
796                       instance.vm_state, instance=instance)
797             return
798 
799         if instance.vm_state == vm_states.DELETED:
800             try:
801                 self._complete_partial_deletion(context, instance)
802             except Exception:
803                 # we don't want that an exception blocks the init_host
804                 LOG.exception('Failed to complete a deletion',
805                               instance=instance)
806             return
807 
808         if (instance.vm_state == vm_states.BUILDING or
809             instance.task_state in [task_states.SCHEDULING,
810                                     task_states.BLOCK_DEVICE_MAPPING,
811                                     task_states.NETWORKING,
812                                     task_states.SPAWNING]):
813             # NOTE(dave-mcnally) compute stopped before instance was fully
814             # spawned so set to ERROR state. This is safe to do as the state
815             # may be set by the api but the host is not so if we get here the
816             # instance has already been scheduled to this particular host.
817             LOG.debug("Instance failed to spawn correctly, "
818                       "setting to ERROR state", instance=instance)
819             instance.task_state = None
820             instance.vm_state = vm_states.ERROR
821             instance.save()
822             return
823 
824         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
825             instance.task_state in [task_states.REBUILDING,
826                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
827                                     task_states.REBUILD_SPAWNING]):
828             # NOTE(jichenjc) compute stopped before instance was fully
829             # spawned so set to ERROR state. This is consistent to BUILD
830             LOG.debug("Instance failed to rebuild correctly, "
831                       "setting to ERROR state", instance=instance)
832             instance.task_state = None
833             instance.vm_state = vm_states.ERROR
834             instance.save()
835             return
836 
837         if (instance.vm_state != vm_states.ERROR and
838             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
839                                     task_states.IMAGE_PENDING_UPLOAD,
840                                     task_states.IMAGE_UPLOADING,
841                                     task_states.IMAGE_SNAPSHOT]):
842             LOG.debug("Instance in transitional state %s at start-up "
843                       "clearing task state",
844                       instance.task_state, instance=instance)
845             try:
846                 self._post_interrupted_snapshot_cleanup(context, instance)
847             except Exception:
848                 # we don't want that an exception blocks the init_host
849                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
850             instance.task_state = None
851             instance.save()
852 
853         if (instance.vm_state != vm_states.ERROR and
854             instance.task_state in [task_states.RESIZE_PREP]):
855             LOG.debug("Instance in transitional state %s at start-up "
856                       "clearing task state",
857                       instance['task_state'], instance=instance)
858             instance.task_state = None
859             instance.save()
860 
861         if instance.task_state == task_states.DELETING:
862             try:
863                 LOG.info('Service started deleting the instance during '
864                          'the previous run, but did not finish. Restarting'
865                          ' the deletion now.', instance=instance)
866                 instance.obj_load_attr('metadata')
867                 instance.obj_load_attr('system_metadata')
868                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
869                         context, instance.uuid)
870                 self._delete_instance(context, instance, bdms)
871             except Exception:
872                 # we don't want that an exception blocks the init_host
873                 LOG.exception('Failed to complete a deletion',
874                               instance=instance)
875                 self._set_instance_obj_error_state(context, instance)
876             return
877 
878         current_power_state = self._get_power_state(context, instance)
879         try_reboot, reboot_type = self._retry_reboot(context, instance,
880                                                      current_power_state)
881 
882         if try_reboot:
883             LOG.debug("Instance in transitional state (%(task_state)s) at "
884                       "start-up and power state is (%(power_state)s), "
885                       "triggering reboot",
886                       {'task_state': instance.task_state,
887                        'power_state': current_power_state},
888                       instance=instance)
889 
890             # NOTE(mikal): if the instance was doing a soft reboot that got as
891             # far as shutting down the instance but not as far as starting it
892             # again, then we've just become a hard reboot. That means the
893             # task state for the instance needs to change so that we're in one
894             # of the expected task states for a hard reboot.
895             if (instance.task_state in task_states.soft_reboot_states and
896                 reboot_type == 'HARD'):
897                 instance.task_state = task_states.REBOOT_PENDING_HARD
898                 instance.save()
899 
900             self.reboot_instance(context, instance, block_device_info=None,
901                                  reboot_type=reboot_type)
902             return
903 
904         elif (current_power_state == power_state.RUNNING and
905               instance.task_state in [task_states.REBOOT_STARTED,
906                                       task_states.REBOOT_STARTED_HARD,
907                                       task_states.PAUSING,
908                                       task_states.UNPAUSING]):
909             LOG.warning("Instance in transitional state "
910                         "(%(task_state)s) at start-up and power state "
911                         "is (%(power_state)s), clearing task state",
912                         {'task_state': instance.task_state,
913                          'power_state': current_power_state},
914                         instance=instance)
915             instance.task_state = None
916             instance.vm_state = vm_states.ACTIVE
917             instance.save()
918         elif (current_power_state == power_state.PAUSED and
919               instance.task_state == task_states.UNPAUSING):
920             LOG.warning("Instance in transitional state "
921                         "(%(task_state)s) at start-up and power state "
922                         "is (%(power_state)s), clearing task state "
923                         "and unpausing the instance",
924                         {'task_state': instance.task_state,
925                          'power_state': current_power_state},
926                         instance=instance)
927             try:
928                 self.unpause_instance(context, instance)
929             except NotImplementedError:
930                 # Some virt driver didn't support pause and unpause
931                 pass
932             except Exception:
933                 LOG.exception('Failed to unpause instance', instance=instance)
934             return
935 
936         if instance.task_state == task_states.POWERING_OFF:
937             try:
938                 LOG.debug("Instance in transitional state %s at start-up "
939                           "retrying stop request",
940                           instance.task_state, instance=instance)
941                 self.stop_instance(context, instance, True)
942             except Exception:
943                 # we don't want that an exception blocks the init_host
944                 LOG.exception('Failed to stop instance', instance=instance)
945             return
946 
947         if instance.task_state == task_states.POWERING_ON:
948             try:
949                 LOG.debug("Instance in transitional state %s at start-up "
950                           "retrying start request",
951                           instance.task_state, instance=instance)
952                 self.start_instance(context, instance)
953             except Exception:
954                 # we don't want that an exception blocks the init_host
955                 LOG.exception('Failed to start instance', instance=instance)
956             return
957 
958         net_info = instance.get_network_info()
959         try:
960             self.driver.plug_vifs(instance, net_info)
961         except NotImplementedError as e:
962             LOG.debug(e, instance=instance)
963         except exception.VirtualInterfacePlugException:
964             # NOTE(mriedem): If we get here, it could be because the vif_type
965             # in the cache is "binding_failed" or "unbound".  The only way to
966             # fix this is to try and bind the ports again, which would be
967             # expensive here on host startup. We could add a check to
968             # _heal_instance_info_cache to handle this, but probably only if
969             # the instance task_state is None.
970             LOG.exception('Virtual interface plugging failed for instance. '
971                           'The port binding:host_id may need to be manually '
972                           'updated.', instance=instance)
973             self._set_instance_obj_error_state(context, instance)
974             return
975 
976         if instance.task_state == task_states.RESIZE_MIGRATING:
977             # We crashed during resize/migration, so roll back for safety
978             try:
979                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
980                 # not in system_metadata we default to True for backwards
981                 # compatibility
982                 power_on = (instance.system_metadata.get('old_vm_state') !=
983                             vm_states.STOPPED)
984 
985                 block_dev_info = self._get_instance_block_device_info(context,
986                                                                       instance)
987 
988                 self.driver.finish_revert_migration(context,
989                     instance, net_info, block_dev_info, power_on)
990 
991             except Exception:
992                 LOG.exception('Failed to revert crashed migration',
993                               instance=instance)
994             finally:
995                 LOG.info('Instance found in migrating state during '
996                          'startup. Resetting task_state',
997                          instance=instance)
998                 instance.task_state = None
999                 instance.save()
1000         if instance.task_state == task_states.MIGRATING:
1001             # Live migration did not complete, but instance is on this
1002             # host, so reset the state.
1003             instance.task_state = None
1004             instance.save(expected_task_state=[task_states.MIGRATING])
1005 
1006         db_state = instance.power_state
1007         drv_state = self._get_power_state(context, instance)
1008         expect_running = (db_state == power_state.RUNNING and
1009                           drv_state != db_state)
1010 
1011         LOG.debug('Current state is %(drv_state)s, state in DB is '
1012                   '%(db_state)s.',
1013                   {'drv_state': drv_state, 'db_state': db_state},
1014                   instance=instance)
1015 
1016         if expect_running and CONF.resume_guests_state_on_host_boot:
1017             self._resume_guests_state(context, instance, net_info)
1018         elif drv_state == power_state.RUNNING:
1019             # VMwareAPI drivers will raise an exception
1020             try:
1021                 self.driver.ensure_filtering_rules_for_instance(
1022                                        instance, net_info)
1023             except NotImplementedError:
1024                 LOG.debug('Hypervisor driver does not support '
1025                           'firewall rules', instance=instance)
1026 
1027     def _resume_guests_state(self, context, instance, net_info):
1028         LOG.info('Rebooting instance after nova-compute restart.',
1029                  instance=instance)
1030         block_device_info = \
1031             self._get_instance_block_device_info(context, instance)
1032 
1033         try:
1034             self.driver.resume_state_on_host_boot(
1035                 context, instance, net_info, block_device_info)
1036         except NotImplementedError:
1037             LOG.warning('Hypervisor driver does not support '
1038                         'resume guests', instance=instance)
1039         except Exception:
1040             # NOTE(vish): The instance failed to resume, so we set the
1041             #             instance to error and attempt to continue.
1042             LOG.warning('Failed to resume instance',
1043                         instance=instance)
1044             self._set_instance_obj_error_state(context, instance)
1045 
1046     def _retry_reboot(self, context, instance, current_power_state):
1047         current_task_state = instance.task_state
1048         retry_reboot = False
1049         reboot_type = compute_utils.get_reboot_type(current_task_state,
1050                                                     current_power_state)
1051 
1052         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1053                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1054         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1055                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1056         started_not_running = (current_task_state in
1057                                [task_states.REBOOT_STARTED,
1058                                 task_states.REBOOT_STARTED_HARD] and
1059                                current_power_state != power_state.RUNNING)
1060 
1061         if pending_soft or pending_hard or started_not_running:
1062             retry_reboot = True
1063 
1064         return retry_reboot, reboot_type
1065 
1066     def handle_lifecycle_event(self, event):
1067         LOG.info("VM %(state)s (Lifecycle Event)",
1068                  {'state': event.get_name()},
1069                  instance_uuid=event.get_instance_uuid())
1070         context = nova.context.get_admin_context(read_deleted='yes')
1071         vm_power_state = None
1072         event_transition = event.get_transition()
1073         if event_transition == virtevent.EVENT_LIFECYCLE_STOPPED:
1074             vm_power_state = power_state.SHUTDOWN
1075         elif event_transition == virtevent.EVENT_LIFECYCLE_STARTED:
1076             vm_power_state = power_state.RUNNING
1077         elif event_transition in (
1078                 virtevent.EVENT_LIFECYCLE_PAUSED,
1079                 virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED,
1080                 virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED):
1081             vm_power_state = power_state.PAUSED
1082         elif event_transition == virtevent.EVENT_LIFECYCLE_RESUMED:
1083             vm_power_state = power_state.RUNNING
1084         elif event_transition == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1085             vm_power_state = power_state.SUSPENDED
1086         else:
1087             LOG.warning("Unexpected lifecycle event: %d", event_transition)
1088 
1089         migrate_finish_statuses = {
1090             # This happens on the source node and indicates live migration
1091             # entered post-copy mode.
1092             virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED: 'running (post-copy)',
1093             # Suspended for offline migration.
1094             virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED: 'running'
1095         }
1096 
1097         expected_attrs = []
1098         if event_transition in migrate_finish_statuses:
1099             # Join on info_cache since that's needed in migrate_instance_start.
1100             expected_attrs.append('info_cache')
1101         instance = objects.Instance.get_by_uuid(context,
1102                                                 event.get_instance_uuid(),
1103                                                 expected_attrs=expected_attrs)
1104 
1105         # Note(lpetrut): The event may be delayed, thus not reflecting
1106         # the current instance power state. In that case, ignore the event.
1107         current_power_state = self._get_power_state(context, instance)
1108         if current_power_state == vm_power_state:
1109             LOG.debug('Synchronizing instance power state after lifecycle '
1110                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1111                       'current task_state: %(task_state)s, current DB '
1112                       'power_state: %(db_power_state)s, VM power_state: '
1113                       '%(vm_power_state)s',
1114                       {'event': event.get_name(),
1115                        'vm_state': instance.vm_state,
1116                        'task_state': instance.task_state,
1117                        'db_power_state': instance.power_state,
1118                        'vm_power_state': vm_power_state},
1119                       instance_uuid=instance.uuid)
1120             self._sync_instance_power_state(context,
1121                                             instance,
1122                                             vm_power_state)
1123 
1124         # The following checks are for live migration. We want to activate
1125         # the port binding for the destination host before the live migration
1126         # is resumed on the destination host in order to reduce network
1127         # downtime. Otherwise the ports are bound to the destination host
1128         # in post_live_migration_at_destination.
1129         # TODO(danms): Explore options for using a different live migration
1130         # specific callback for this instead of piggy-backing on the
1131         # handle_lifecycle_event callback.
1132         if (instance.task_state == task_states.MIGRATING and
1133                 event_transition in migrate_finish_statuses):
1134             status = migrate_finish_statuses[event_transition]
1135             try:
1136                 migration = objects.Migration.get_by_instance_and_status(
1137                             context, instance.uuid, status)
1138                 LOG.debug('Binding ports to destination host: %s',
1139                           migration.dest_compute, instance=instance)
1140                 # For neutron, migrate_instance_start will activate the
1141                 # destination host port bindings, if there are any created by
1142                 # conductor before live migration started.
1143                 self.network_api.migrate_instance_start(
1144                     context, instance, migration)
1145             except exception.MigrationNotFoundByStatus:
1146                 LOG.warning("Unable to find migration record with status "
1147                             "'%s' for instance. Port binding will happen in "
1148                             "post live migration.", status, instance=instance)
1149 
1150     def handle_events(self, event):
1151         if isinstance(event, virtevent.LifecycleEvent):
1152             try:
1153                 self.handle_lifecycle_event(event)
1154             except exception.InstanceNotFound:
1155                 LOG.debug("Event %s arrived for non-existent instance. The "
1156                           "instance was probably deleted.", event)
1157         else:
1158             LOG.debug("Ignoring event %s", event)
1159 
1160     def init_virt_events(self):
1161         if CONF.workarounds.handle_virt_lifecycle_events:
1162             self.driver.register_event_listener(self.handle_events)
1163         else:
1164             # NOTE(mriedem): If the _sync_power_states periodic task is
1165             # disabled we should emit a warning in the logs.
1166             if CONF.sync_power_state_interval < 0:
1167                 LOG.warning('Instance lifecycle events from the compute '
1168                             'driver have been disabled. Note that lifecycle '
1169                             'changes to an instance outside of the compute '
1170                             'service will not be synchronized '
1171                             'automatically since the _sync_power_states '
1172                             'periodic task is also disabled.')
1173             else:
1174                 LOG.info('Instance lifecycle events from the compute '
1175                          'driver have been disabled. Note that lifecycle '
1176                          'changes to an instance outside of the compute '
1177                          'service will only be synchronized by the '
1178                          '_sync_power_states periodic task.')
1179 
1180     def init_host(self):
1181         """Initialization for a standalone compute service."""
1182 
1183         if CONF.pci.passthrough_whitelist:
1184             # Simply loading the PCI passthrough whitelist will do a bunch of
1185             # validation that would otherwise wait until the PciDevTracker is
1186             # constructed when updating available resources for the compute
1187             # node(s) in the resource tracker, effectively killing that task.
1188             # So load up the whitelist when starting the compute service to
1189             # flush any invalid configuration early so we can kill the service
1190             # if the configuration is wrong.
1191             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1192 
1193         nova.conf.neutron.register_dynamic_opts(CONF)
1194 
1195         # Override the number of concurrent disk operations allowed if the
1196         # user has specified a limit.
1197         if CONF.compute.max_concurrent_disk_ops != 0:
1198             compute_utils.disk_ops_semaphore = \
1199                 eventlet.semaphore.BoundedSemaphore(
1200                     CONF.compute.max_concurrent_disk_ops)
1201 
1202         self.driver.init_host(host=self.host)
1203         context = nova.context.get_admin_context()
1204         instances = objects.InstanceList.get_by_host(
1205             context, self.host, expected_attrs=['info_cache', 'metadata'])
1206 
1207         if CONF.defer_iptables_apply:
1208             self.driver.filter_defer_apply_on()
1209 
1210         self.init_virt_events()
1211 
1212         try:
1213             # checking that instance was not already evacuated to other host
1214             evacuated_instances = self._destroy_evacuated_instances(context)
1215 
1216             # Initialise instances on the host that are not evacuating
1217             for instance in instances:
1218                 if (not evacuated_instances or
1219                         instance.uuid not in evacuated_instances):
1220                     self._init_instance(context, instance)
1221 
1222         finally:
1223             if CONF.defer_iptables_apply:
1224                 self.driver.filter_defer_apply_off()
1225             if instances:
1226                 # We only send the instance info to the scheduler on startup
1227                 # if there is anything to send, otherwise this host might
1228                 # not be mapped yet in a cell and the scheduler may have
1229                 # issues dealing with the information. Later changes to
1230                 # instances on this host will update the scheduler, or the
1231                 # _sync_scheduler_instance_info periodic task will.
1232                 self._update_scheduler_instance_info(context, instances)
1233 
1234     def cleanup_host(self):
1235         self.driver.register_event_listener(None)
1236         self.instance_events.cancel_all_events()
1237         self.driver.cleanup_host(host=self.host)
1238         self._cleanup_live_migrations_in_pool()
1239 
1240     def _cleanup_live_migrations_in_pool(self):
1241         # Shutdown the pool so we don't get new requests.
1242         self._live_migration_executor.shutdown(wait=False)
1243         # For any queued migrations, cancel the migration and update
1244         # its status.
1245         for migration, future in self._waiting_live_migrations.values():
1246             # If we got here before the Future was submitted then we need
1247             # to move on since there isn't anything we can do.
1248             if future is None:
1249                 continue
1250             if future.cancel():
1251                 self._set_migration_status(migration, 'cancelled')
1252                 LOG.info('Successfully cancelled queued live migration.',
1253                          instance_uuid=migration.instance_uuid)
1254             else:
1255                 LOG.warning('Unable to cancel live migration.',
1256                             instance_uuid=migration.instance_uuid)
1257         self._waiting_live_migrations.clear()
1258 
1259     def pre_start_hook(self):
1260         """After the service is initialized, but before we fully bring
1261         the service up by listening on RPC queues, make sure to update
1262         our available resources (and indirectly our available nodes).
1263         """
1264         self.update_available_resource(nova.context.get_admin_context(),
1265                                        startup=True)
1266 
1267     def _get_power_state(self, context, instance):
1268         """Retrieve the power state for the given instance."""
1269         LOG.debug('Checking state', instance=instance)
1270         try:
1271             return self.driver.get_info(instance).state
1272         except exception.InstanceNotFound:
1273             return power_state.NOSTATE
1274 
1275     def get_console_topic(self, context):
1276         """Retrieves the console host for a project on this host.
1277 
1278         Currently this is just set in the flags for each compute host.
1279 
1280         """
1281         # TODO(mdragon): perhaps make this variable by console_type?
1282         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1283 
1284     @wrap_exception()
1285     def get_console_pool_info(self, context, console_type):
1286         return self.driver.get_console_pool_info(console_type)
1287 
1288     @wrap_exception()
1289     def refresh_instance_security_rules(self, context, instance):
1290         """Tell the virtualization driver to refresh security rules for
1291         an instance.
1292 
1293         Passes straight through to the virtualization driver.
1294 
1295         Synchronize the call because we may still be in the middle of
1296         creating the instance.
1297         """
1298         @utils.synchronized(instance.uuid)
1299         def _sync_refresh():
1300             try:
1301                 return self.driver.refresh_instance_security_rules(instance)
1302             except NotImplementedError:
1303                 LOG.debug('Hypervisor driver does not support '
1304                           'security groups.', instance=instance)
1305 
1306         return _sync_refresh()
1307 
1308     def _await_block_device_map_created(self, context, vol_id):
1309         # TODO(yamahata): creating volume simultaneously
1310         #                 reduces creation time?
1311         # TODO(yamahata): eliminate dumb polling
1312         start = time.time()
1313         retries = CONF.block_device_allocate_retries
1314         if retries < 0:
1315             LOG.warning("Treating negative config value (%(retries)s) for "
1316                         "'block_device_retries' as 0.",
1317                         {'retries': retries})
1318         # (1) treat  negative config value as 0
1319         # (2) the configured value is 0, one attempt should be made
1320         # (3) the configured value is > 0, then the total number attempts
1321         #      is (retries + 1)
1322         attempts = 1
1323         if retries >= 1:
1324             attempts = retries + 1
1325         for attempt in range(1, attempts + 1):
1326             volume = self.volume_api.get(context, vol_id)
1327             volume_status = volume['status']
1328             if volume_status not in ['creating', 'downloading']:
1329                 if volume_status == 'available':
1330                     return attempt
1331                 LOG.warning("Volume id: %(vol_id)s finished being "
1332                             "created but its status is %(vol_status)s.",
1333                             {'vol_id': vol_id,
1334                              'vol_status': volume_status})
1335                 break
1336             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1337         raise exception.VolumeNotCreated(volume_id=vol_id,
1338                                          seconds=int(time.time() - start),
1339                                          attempts=attempt,
1340                                          volume_status=volume_status)
1341 
1342     def _decode_files(self, injected_files):
1343         """Base64 decode the list of files to inject."""
1344         if not injected_files:
1345             return []
1346 
1347         def _decode(f):
1348             path, contents = f
1349             # Py3 raises binascii.Error instead of TypeError as in Py27
1350             try:
1351                 decoded = base64.b64decode(contents)
1352                 return path, decoded
1353             except (TypeError, binascii.Error):
1354                 raise exception.Base64Exception(path=path)
1355 
1356         return [_decode(f) for f in injected_files]
1357 
1358     def _validate_instance_group_policy(self, context, instance,
1359                                         scheduler_hints):
1360         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1361         # However, there is a race condition with the enforcement of
1362         # the policy.  Since more than one instance may be scheduled at the
1363         # same time, it's possible that more than one instance with an
1364         # anti-affinity policy may end up here.  It's also possible that
1365         # multiple instances with an affinity policy could end up on different
1366         # hosts.  This is a validation step to make sure that starting the
1367         # instance here doesn't violate the policy.
1368         group_hint = scheduler_hints.get('group')
1369         if not group_hint:
1370             return
1371 
1372         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1373         # to check the type on the value and pull the single entry out. The
1374         # API request schema validates that the 'group' hint is a single value.
1375         if isinstance(group_hint, list):
1376             group_hint = group_hint[0]
1377 
1378         @utils.synchronized(group_hint)
1379         def _do_validation(context, instance, group_hint):
1380             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1381             if group.policy and 'anti-affinity' == group.policy:
1382                 instances_uuids = objects.InstanceList.get_uuids_by_host(
1383                     context, self.host)
1384                 ins_on_host = set(instances_uuids)
1385                 members = set(group.members)
1386                 # Determine the set of instance group members on this host
1387                 # which are not the instance in question. This is used to
1388                 # determine how many other members from the same anti-affinity
1389                 # group can be on this host.
1390                 members_on_host = ins_on_host & members - set([instance.uuid])
1391                 rules = group.rules
1392                 if rules and 'max_server_per_host' in rules:
1393                     max_server = rules['max_server_per_host']
1394                 else:
1395                     max_server = 1
1396                 if len(members_on_host) >= max_server:
1397                     msg = _("Anti-affinity instance group policy "
1398                             "was violated.")
1399                     raise exception.RescheduledException(
1400                             instance_uuid=instance.uuid,
1401                             reason=msg)
1402             elif group.policy and 'affinity' == group.policy:
1403                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1404                 if group_hosts and self.host not in group_hosts:
1405                     msg = _("Affinity instance group policy was violated.")
1406                     raise exception.RescheduledException(
1407                             instance_uuid=instance.uuid,
1408                             reason=msg)
1409 
1410         if not CONF.workarounds.disable_group_policy_check_upcall:
1411             _do_validation(context, instance, group_hint)
1412 
1413     def _log_original_error(self, exc_info, instance_uuid):
1414         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1415                   exc_info=exc_info)
1416 
1417     # TODO(mriedem): This method is confusing and only ever used for resize
1418     # reschedules; remove it and merge into _reschedule_resize_or_reraise.
1419     def _reschedule(self, context, request_spec, filter_properties,
1420             instance, reschedule_method, method_args, task_state,
1421             exc_info=None, host_list=None):
1422         """Attempt to re-schedule a compute operation."""
1423 
1424         instance_uuid = instance.uuid
1425         retry = filter_properties.get('retry')
1426         if not retry:
1427             # no retry information, do not reschedule.
1428             LOG.debug("Retry info not present, will not reschedule",
1429                       instance_uuid=instance_uuid)
1430             return
1431 
1432         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1433                   {'method': reschedule_method.__name__,
1434                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1435 
1436         # reset the task state:
1437         self._instance_update(context, instance, task_state=task_state)
1438 
1439         if exc_info:
1440             # stringify to avoid circular ref problem in json serialization:
1441             retry['exc'] = traceback.format_exception_only(exc_info[0],
1442                                     exc_info[1])
1443 
1444         reschedule_method(context, *method_args, request_spec=request_spec,
1445                           host_list=host_list)
1446         return True
1447 
1448     @periodic_task.periodic_task
1449     def _check_instance_build_time(self, context):
1450         """Ensure that instances are not stuck in build."""
1451         timeout = CONF.instance_build_timeout
1452         if timeout == 0:
1453             return
1454 
1455         filters = {'vm_state': vm_states.BUILDING,
1456                    'host': self.host}
1457 
1458         building_insts = objects.InstanceList.get_by_filters(context,
1459                            filters, expected_attrs=[], use_slave=True)
1460 
1461         for instance in building_insts:
1462             if timeutils.is_older_than(instance.created_at, timeout):
1463                 self._set_instance_obj_error_state(context, instance)
1464                 LOG.warning("Instance build timed out. Set to error "
1465                             "state.", instance=instance)
1466 
1467     def _check_instance_exists(self, context, instance):
1468         """Ensure an instance with the same name is not already present."""
1469         if self.driver.instance_exists(instance):
1470             raise exception.InstanceExists(name=instance.name)
1471 
1472     def _allocate_network_async(self, context, instance, requested_networks,
1473                                 macs, security_groups, is_vpn):
1474         """Method used to allocate networks in the background.
1475 
1476         Broken out for testing.
1477         """
1478         # First check to see if we're specifically not supposed to allocate
1479         # networks because if so, we can exit early.
1480         if requested_networks and requested_networks.no_allocate:
1481             LOG.debug("Not allocating networking since 'none' was specified.",
1482                       instance=instance)
1483             return network_model.NetworkInfo([])
1484 
1485         LOG.debug("Allocating IP information in the background.",
1486                   instance=instance)
1487         retries = CONF.network_allocate_retries
1488         attempts = retries + 1
1489         retry_time = 1
1490         bind_host_id = self.driver.network_binding_host_id(context, instance)
1491         for attempt in range(1, attempts + 1):
1492             try:
1493                 nwinfo = self.network_api.allocate_for_instance(
1494                         context, instance, vpn=is_vpn,
1495                         requested_networks=requested_networks,
1496                         macs=macs,
1497                         security_groups=security_groups,
1498                         bind_host_id=bind_host_id)
1499                 LOG.debug('Instance network_info: |%s|', nwinfo,
1500                           instance=instance)
1501                 instance.system_metadata['network_allocated'] = 'True'
1502                 # NOTE(JoshNang) do not save the instance here, as it can cause
1503                 # races. The caller shares a reference to instance and waits
1504                 # for this async greenthread to finish before calling
1505                 # instance.save().
1506                 return nwinfo
1507             except Exception:
1508                 exc_info = sys.exc_info()
1509                 log_info = {'attempt': attempt,
1510                             'attempts': attempts}
1511                 if attempt == attempts:
1512                     LOG.exception('Instance failed network setup '
1513                                   'after %(attempts)d attempt(s)',
1514                                   log_info)
1515                     six.reraise(*exc_info)
1516                 LOG.warning('Instance failed network setup '
1517                             '(attempt %(attempt)d of %(attempts)d)',
1518                             log_info, instance=instance)
1519                 time.sleep(retry_time)
1520                 retry_time *= 2
1521                 if retry_time > 30:
1522                     retry_time = 30
1523         # Not reached.
1524 
1525     def _build_networks_for_instance(self, context, instance,
1526             requested_networks, security_groups):
1527 
1528         # If we're here from a reschedule the network may already be allocated.
1529         if strutils.bool_from_string(
1530                 instance.system_metadata.get('network_allocated', 'False')):
1531             # NOTE(alex_xu): The network_allocated is True means the network
1532             # resource already allocated at previous scheduling, and the
1533             # network setup is cleanup at previous. After rescheduling, the
1534             # network resource need setup on the new host.
1535             self.network_api.setup_instance_network_on_host(
1536                 context, instance, instance.host)
1537             return self.network_api.get_instance_nw_info(context, instance)
1538 
1539         if not self.is_neutron_security_groups:
1540             security_groups = []
1541 
1542         macs = self.driver.macs_for_instance(instance)
1543         network_info = self._allocate_network(context, instance,
1544                 requested_networks, macs, security_groups)
1545 
1546         return network_info
1547 
1548     def _allocate_network(self, context, instance, requested_networks, macs,
1549                           security_groups):
1550         """Start network allocation asynchronously.  Return an instance
1551         of NetworkInfoAsyncWrapper that can be used to retrieve the
1552         allocated networks when the operation has finished.
1553         """
1554         # NOTE(comstud): Since we're allocating networks asynchronously,
1555         # this task state has little meaning, as we won't be in this
1556         # state for very long.
1557         instance.vm_state = vm_states.BUILDING
1558         instance.task_state = task_states.NETWORKING
1559         instance.save(expected_task_state=[None])
1560 
1561         is_vpn = False
1562         return network_model.NetworkInfoAsyncWrapper(
1563                 self._allocate_network_async, context, instance,
1564                 requested_networks, macs, security_groups, is_vpn)
1565 
1566     def _default_root_device_name(self, instance, image_meta, root_bdm):
1567         """Gets a default root device name from the driver.
1568 
1569         :param nova.objects.Instance instance:
1570             The instance for which to get the root device name.
1571         :param nova.objects.ImageMeta image_meta:
1572             The metadata of the image of the instance.
1573         :param nova.objects.BlockDeviceMapping root_bdm:
1574             The description of the root device.
1575         :returns: str -- The default root device name.
1576         :raises: InternalError, TooManyDiskDevices
1577         """
1578         try:
1579             return self.driver.default_root_device_name(instance,
1580                                                         image_meta,
1581                                                         root_bdm)
1582         except NotImplementedError:
1583             return compute_utils.get_next_device_name(instance, [])
1584 
1585     def _default_device_names_for_instance(self, instance,
1586                                            root_device_name,
1587                                            *block_device_lists):
1588         """Default the missing device names in the BDM from the driver.
1589 
1590         :param nova.objects.Instance instance:
1591             The instance for which to get default device names.
1592         :param str root_device_name: The root device name.
1593         :param list block_device_lists: List of block device mappings.
1594         :returns: None
1595         :raises: InternalError, TooManyDiskDevices
1596         """
1597         try:
1598             self.driver.default_device_names_for_instance(instance,
1599                                                           root_device_name,
1600                                                           *block_device_lists)
1601         except NotImplementedError:
1602             compute_utils.default_device_names_for_instance(
1603                 instance, root_device_name, *block_device_lists)
1604 
1605     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1606         """Get the next device name from the driver, based on the BDM.
1607 
1608         :param nova.objects.Instance instance:
1609             The instance whose volume is requesting a device name.
1610         :param nova.objects.BlockDeviceMappingList bdms:
1611             The block device mappings for the instance.
1612         :param nova.objects.BlockDeviceMapping block_device_obj:
1613             A block device mapping containing info about the requested block
1614             device.
1615         :returns: The next device name.
1616         :raises: InternalError, TooManyDiskDevices
1617         """
1618         # NOTE(ndipanov): Copy obj to avoid changing the original
1619         block_device_obj = block_device_obj.obj_clone()
1620         try:
1621             return self.driver.get_device_name_for_instance(
1622                 instance, bdms, block_device_obj)
1623         except NotImplementedError:
1624             return compute_utils.get_device_name_for_instance(
1625                 instance, bdms, block_device_obj.get("device_name"))
1626 
1627     def _default_block_device_names(self, instance, image_meta, block_devices):
1628         """Verify that all the devices have the device_name set. If not,
1629         provide a default name.
1630 
1631         It also ensures that there is a root_device_name and is set to the
1632         first block device in the boot sequence (boot_index=0).
1633         """
1634         root_bdm = block_device.get_root_bdm(block_devices)
1635         if not root_bdm:
1636             return
1637 
1638         # Get the root_device_name from the root BDM or the instance
1639         root_device_name = None
1640         update_root_bdm = False
1641 
1642         if root_bdm.device_name:
1643             root_device_name = root_bdm.device_name
1644             instance.root_device_name = root_device_name
1645         elif instance.root_device_name:
1646             root_device_name = instance.root_device_name
1647             root_bdm.device_name = root_device_name
1648             update_root_bdm = True
1649         else:
1650             root_device_name = self._default_root_device_name(instance,
1651                                                               image_meta,
1652                                                               root_bdm)
1653 
1654             instance.root_device_name = root_device_name
1655             root_bdm.device_name = root_device_name
1656             update_root_bdm = True
1657 
1658         if update_root_bdm:
1659             root_bdm.save()
1660 
1661         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1662                             block_devices))
1663         swap = list(filter(block_device.new_format_is_swap,
1664                       block_devices))
1665         block_device_mapping = list(filter(
1666               driver_block_device.is_block_device_mapping, block_devices))
1667 
1668         self._default_device_names_for_instance(instance,
1669                                                 root_device_name,
1670                                                 ephemerals,
1671                                                 swap,
1672                                                 block_device_mapping)
1673 
1674     def _block_device_info_to_legacy(self, block_device_info):
1675         """Convert BDI to the old format for drivers that need it."""
1676 
1677         if self.use_legacy_block_device_info:
1678             ephemerals = driver_block_device.legacy_block_devices(
1679                 driver.block_device_info_get_ephemerals(block_device_info))
1680             mapping = driver_block_device.legacy_block_devices(
1681                 driver.block_device_info_get_mapping(block_device_info))
1682             swap = block_device_info['swap']
1683             if swap:
1684                 swap = swap.legacy()
1685 
1686             block_device_info.update({
1687                 'ephemerals': ephemerals,
1688                 'swap': swap,
1689                 'block_device_mapping': mapping})
1690 
1691     def _add_missing_dev_names(self, bdms, instance):
1692         for bdm in bdms:
1693             if bdm.device_name is not None:
1694                 continue
1695 
1696             device_name = self._get_device_name_for_instance(instance,
1697                                                              bdms, bdm)
1698             values = {'device_name': device_name}
1699             bdm.update(values)
1700             bdm.save()
1701 
1702     def _prep_block_device(self, context, instance, bdms):
1703         """Set up the block device for an instance with error logging."""
1704         try:
1705             self._add_missing_dev_names(bdms, instance)
1706             block_device_info = driver.get_block_device_info(instance, bdms)
1707             mapping = driver.block_device_info_get_mapping(block_device_info)
1708             driver_block_device.attach_block_devices(
1709                 mapping, context, instance, self.volume_api, self.driver,
1710                 wait_func=self._await_block_device_map_created)
1711 
1712             self._block_device_info_to_legacy(block_device_info)
1713             return block_device_info
1714 
1715         except exception.OverQuota as e:
1716             LOG.warning('Failed to create block device for instance due'
1717                         ' to exceeding volume related resource quota.'
1718                         ' Error: %s', e.message, instance=instance)
1719             raise
1720 
1721         except Exception as ex:
1722             LOG.exception('Instance failed block device setup',
1723                           instance=instance)
1724             # InvalidBDM will eventually result in a BuildAbortException when
1725             # booting from volume, and will be recorded as an instance fault.
1726             # Maintain the original exception message which most likely has
1727             # useful details which the standard InvalidBDM error message lacks.
1728             raise exception.InvalidBDM(six.text_type(ex))
1729 
1730     def _update_instance_after_spawn(self, context, instance):
1731         instance.power_state = self._get_power_state(context, instance)
1732         instance.vm_state = vm_states.ACTIVE
1733         instance.task_state = None
1734         instance.launched_at = timeutils.utcnow()
1735         configdrive.update_instance(instance)
1736 
1737     def _update_scheduler_instance_info(self, context, instance):
1738         """Sends an InstanceList with created or updated Instance objects to
1739         the Scheduler client.
1740 
1741         In the case of init_host, the value passed will already be an
1742         InstanceList. Other calls will send individual Instance objects that
1743         have been created or resized. In this case, we create an InstanceList
1744         object containing that Instance.
1745         """
1746         if not self.send_instance_updates:
1747             return
1748         if isinstance(instance, obj_instance.Instance):
1749             instance = objects.InstanceList(objects=[instance])
1750         context = context.elevated()
1751         self.query_client.update_instance_info(context, self.host,
1752                                                instance)
1753 
1754     def _delete_scheduler_instance_info(self, context, instance_uuid):
1755         """Sends the uuid of the deleted Instance to the Scheduler client."""
1756         if not self.send_instance_updates:
1757             return
1758         context = context.elevated()
1759         self.query_client.delete_instance_info(context, self.host,
1760                                                instance_uuid)
1761 
1762     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1763     def _sync_scheduler_instance_info(self, context):
1764         if not self.send_instance_updates:
1765             return
1766         context = context.elevated()
1767         instances = objects.InstanceList.get_by_host(context, self.host,
1768                                                      expected_attrs=[],
1769                                                      use_slave=True)
1770         uuids = [instance.uuid for instance in instances]
1771         self.query_client.sync_instance_info(context, self.host, uuids)
1772 
1773     def _notify_about_instance_usage(self, context, instance, event_suffix,
1774                                      network_info=None, extra_usage_info=None,
1775                                      fault=None):
1776         compute_utils.notify_about_instance_usage(
1777             self.notifier, context, instance, event_suffix,
1778             network_info=network_info,
1779             extra_usage_info=extra_usage_info, fault=fault)
1780 
1781     def _deallocate_network(self, context, instance,
1782                             requested_networks=None):
1783         # If we were told not to allocate networks let's save ourselves
1784         # the trouble of calling the network API.
1785         if requested_networks and requested_networks.no_allocate:
1786             LOG.debug("Skipping network deallocation for instance since "
1787                       "networking was not requested.", instance=instance)
1788             return
1789 
1790         LOG.debug('Deallocating network for instance', instance=instance)
1791         with timeutils.StopWatch() as timer:
1792             self.network_api.deallocate_for_instance(
1793                 context, instance, requested_networks=requested_networks)
1794         # nova-network does an rpc call so we're OK tracking time spent here
1795         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1796                  timer.elapsed(), instance=instance)
1797 
1798     def _get_instance_block_device_info(self, context, instance,
1799                                         refresh_conn_info=False,
1800                                         bdms=None):
1801         """Transform block devices to the driver block_device format."""
1802 
1803         if not bdms:
1804             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1805                     context, instance.uuid)
1806         block_device_info = driver.get_block_device_info(instance, bdms)
1807 
1808         if not refresh_conn_info:
1809             # if the block_device_mapping has no value in connection_info
1810             # (returned as None), don't include in the mapping
1811             block_device_info['block_device_mapping'] = [
1812                 bdm for bdm in driver.block_device_info_get_mapping(
1813                                     block_device_info)
1814                 if bdm.get('connection_info')]
1815         else:
1816             driver_block_device.refresh_conn_infos(
1817                 driver.block_device_info_get_mapping(block_device_info),
1818                 context, instance, self.volume_api, self.driver)
1819 
1820         self._block_device_info_to_legacy(block_device_info)
1821 
1822         return block_device_info
1823 
1824     def _build_failed(self, node):
1825         if CONF.compute.consecutive_build_service_disable_threshold:
1826             # NOTE(danms): Update our counter, but wait for the next
1827             # update_available_resource() periodic to flush it to the DB
1828             self.rt.build_failed(node)
1829 
1830     def _build_succeeded(self, node):
1831         self.rt.build_succeeded(node)
1832 
1833     @wrap_exception()
1834     @reverts_task_state
1835     @wrap_instance_fault
1836     def build_and_run_instance(self, context, instance, image, request_spec,
1837                      filter_properties, admin_password=None,
1838                      injected_files=None, requested_networks=None,
1839                      security_groups=None, block_device_mapping=None,
1840                      node=None, limits=None, host_list=None):
1841 
1842         @utils.synchronized(instance.uuid)
1843         def _locked_do_build_and_run_instance(*args, **kwargs):
1844             # NOTE(danms): We grab the semaphore with the instance uuid
1845             # locked because we could wait in line to build this instance
1846             # for a while and we want to make sure that nothing else tries
1847             # to do anything with this instance while we wait.
1848             with self._build_semaphore:
1849                 try:
1850                     result = self._do_build_and_run_instance(*args, **kwargs)
1851                 except Exception:
1852                     # NOTE(mriedem): This should really only happen if
1853                     # _decode_files in _do_build_and_run_instance fails, and
1854                     # that's before a guest is spawned so it's OK to remove
1855                     # allocations for the instance for this node from Placement
1856                     # below as there is no guest consuming resources anyway.
1857                     # The _decode_files case could be handled more specifically
1858                     # but that's left for another day.
1859                     result = build_results.FAILED
1860                     raise
1861                 finally:
1862                     if result == build_results.FAILED:
1863                         # Remove the allocation records from Placement for the
1864                         # instance if the build failed. The instance.host is
1865                         # likely set to None in _do_build_and_run_instance
1866                         # which means if the user deletes the instance, it
1867                         # will be deleted in the API, not the compute service.
1868                         # Setting the instance.host to None in
1869                         # _do_build_and_run_instance means that the
1870                         # ResourceTracker will no longer consider this instance
1871                         # to be claiming resources against it, so we want to
1872                         # reflect that same thing in Placement.  No need to
1873                         # call this for a reschedule, as the allocations will
1874                         # have already been removed in
1875                         # self._do_build_and_run_instance().
1876                         self.reportclient.delete_allocation_for_instance(
1877                             context, instance.uuid)
1878 
1879                     if result in (build_results.FAILED,
1880                                   build_results.RESCHEDULED):
1881                         self._build_failed(node)
1882                     else:
1883                         self._build_succeeded(node)
1884 
1885         # NOTE(danms): We spawn here to return the RPC worker thread back to
1886         # the pool. Since what follows could take a really long time, we don't
1887         # want to tie up RPC workers.
1888         utils.spawn_n(_locked_do_build_and_run_instance,
1889                       context, instance, image, request_spec,
1890                       filter_properties, admin_password, injected_files,
1891                       requested_networks, security_groups,
1892                       block_device_mapping, node, limits, host_list)
1893 
1894     def _check_device_tagging(self, requested_networks, block_device_mapping):
1895         tagging_requested = False
1896         if requested_networks:
1897             for net in requested_networks:
1898                 if 'tag' in net and net.tag is not None:
1899                     tagging_requested = True
1900                     break
1901         if block_device_mapping and not tagging_requested:
1902             for bdm in block_device_mapping:
1903                 if 'tag' in bdm and bdm.tag is not None:
1904                     tagging_requested = True
1905                     break
1906         if (tagging_requested and
1907                 not self.driver.capabilities.get('supports_device_tagging',
1908                                                  False)):
1909             raise exception.BuildAbortException('Attempt to boot guest with '
1910                                                 'tagged devices on host that '
1911                                                 'does not support tagging.')
1912 
1913     def _check_trusted_certs(self, instance):
1914         if (instance.trusted_certs and
1915                 not self.driver.capabilities.get('supports_trusted_certs',
1916                                                  False)):
1917             raise exception.BuildAbortException(
1918                 'Trusted image certificates provided on host that does not '
1919                 'support certificate validation.')
1920 
1921     @hooks.add_hook('build_instance')
1922     @wrap_exception()
1923     @reverts_task_state
1924     @wrap_instance_event(prefix='compute')
1925     @wrap_instance_fault
1926     def _do_build_and_run_instance(self, context, instance, image,
1927             request_spec, filter_properties, admin_password, injected_files,
1928             requested_networks, security_groups, block_device_mapping,
1929             node=None, limits=None, host_list=None):
1930 
1931         try:
1932             LOG.debug('Starting instance...', instance=instance)
1933             instance.vm_state = vm_states.BUILDING
1934             instance.task_state = None
1935             instance.save(expected_task_state=
1936                     (task_states.SCHEDULING, None))
1937         except exception.InstanceNotFound:
1938             msg = 'Instance disappeared before build.'
1939             LOG.debug(msg, instance=instance)
1940             return build_results.FAILED
1941         except exception.UnexpectedTaskStateError as e:
1942             LOG.debug(e.format_message(), instance=instance)
1943             return build_results.FAILED
1944 
1945         # b64 decode the files to inject:
1946         decoded_files = self._decode_files(injected_files)
1947 
1948         if limits is None:
1949             limits = {}
1950 
1951         if node is None:
1952             node = self._get_nodename(instance, refresh=True)
1953 
1954         try:
1955             with timeutils.StopWatch() as timer:
1956                 self._build_and_run_instance(context, instance, image,
1957                         decoded_files, admin_password, requested_networks,
1958                         security_groups, block_device_mapping, node, limits,
1959                         filter_properties, request_spec)
1960             LOG.info('Took %0.2f seconds to build instance.',
1961                      timer.elapsed(), instance=instance)
1962             return build_results.ACTIVE
1963         except exception.RescheduledException as e:
1964             retry = filter_properties.get('retry')
1965             if not retry:
1966                 # no retry information, do not reschedule.
1967                 LOG.debug("Retry info not present, will not reschedule",
1968                     instance=instance)
1969                 self._cleanup_allocated_networks(context, instance,
1970                     requested_networks)
1971                 self._cleanup_volumes(context, instance,
1972                     block_device_mapping, raise_exc=False)
1973                 compute_utils.add_instance_fault_from_exc(context,
1974                         instance, e, sys.exc_info(),
1975                         fault_message=e.kwargs['reason'])
1976                 self._nil_out_instance_obj_host_and_node(instance)
1977                 self._set_instance_obj_error_state(context, instance,
1978                                                    clean_task_state=True)
1979                 return build_results.FAILED
1980             LOG.debug(e.format_message(), instance=instance)
1981             # This will be used for logging the exception
1982             retry['exc'] = traceback.format_exception(*sys.exc_info())
1983             # This will be used for setting the instance fault message
1984             retry['exc_reason'] = e.kwargs['reason']
1985             # NOTE(comstud): Deallocate networks if the driver wants
1986             # us to do so.
1987             # NOTE(mriedem): Always deallocate networking when using Neutron.
1988             # This is to unbind any ports that the user supplied in the server
1989             # create request, or delete any ports that nova created which were
1990             # meant to be bound to this host. This check intentionally bypasses
1991             # the result of deallocate_networks_on_reschedule because the
1992             # default value in the driver is False, but that method was really
1993             # only meant for Ironic and should be removed when nova-network is
1994             # removed (since is_neutron() will then always be True).
1995             # NOTE(vladikr): SR-IOV ports should be deallocated to
1996             # allow new sriov pci devices to be allocated on a new host.
1997             # Otherwise, if devices with pci addresses are already allocated
1998             # on the destination host, the instance will fail to spawn.
1999             # info_cache.network_info should be present at this stage.
2000             if (self.driver.deallocate_networks_on_reschedule(instance) or
2001                 utils.is_neutron() or
2002                 self.deallocate_sriov_ports_on_reschedule(instance)):
2003                 self._cleanup_allocated_networks(context, instance,
2004                         requested_networks)
2005             else:
2006                 # NOTE(alex_xu): Network already allocated and we don't
2007                 # want to deallocate them before rescheduling. But we need
2008                 # to cleanup those network resources setup on this host before
2009                 # rescheduling.
2010                 self.network_api.cleanup_instance_network_on_host(
2011                     context, instance, self.host)
2012 
2013             self._nil_out_instance_obj_host_and_node(instance)
2014             instance.task_state = task_states.SCHEDULING
2015             instance.save()
2016             # The instance will have already claimed resources from this host
2017             # before this build was attempted. Now that it has failed, we need
2018             # to unclaim those resources before casting to the conductor, so
2019             # that if there are alternate hosts available for a retry, it can
2020             # claim resources on that new host for the instance.
2021             self.reportclient.delete_allocation_for_instance(context,
2022                                                              instance.uuid)
2023 
2024             self.compute_task_api.build_instances(context, [instance],
2025                     image, filter_properties, admin_password,
2026                     injected_files, requested_networks, security_groups,
2027                     block_device_mapping, request_spec=request_spec,
2028                     host_lists=[host_list])
2029             return build_results.RESCHEDULED
2030         except (exception.InstanceNotFound,
2031                 exception.UnexpectedDeletingTaskStateError):
2032             msg = 'Instance disappeared during build.'
2033             LOG.debug(msg, instance=instance)
2034             self._cleanup_allocated_networks(context, instance,
2035                     requested_networks)
2036             return build_results.FAILED
2037         except Exception as e:
2038             if isinstance(e, exception.BuildAbortException):
2039                 LOG.error(e.format_message(), instance=instance)
2040             else:
2041                 # Should not reach here.
2042                 LOG.exception('Unexpected build failure, not rescheduling '
2043                               'build.', instance=instance)
2044             self._cleanup_allocated_networks(context, instance,
2045                     requested_networks)
2046             self._cleanup_volumes(context, instance,
2047                     block_device_mapping, raise_exc=False)
2048             compute_utils.add_instance_fault_from_exc(context, instance,
2049                     e, sys.exc_info())
2050             self._nil_out_instance_obj_host_and_node(instance)
2051             self._set_instance_obj_error_state(context, instance,
2052                                                clean_task_state=True)
2053             return build_results.FAILED
2054 
2055     def deallocate_sriov_ports_on_reschedule(self, instance):
2056         """Determine if networks are needed to be deallocated before reschedule
2057 
2058         Check the cached network info for any assigned SR-IOV ports.
2059         SR-IOV ports should be deallocated prior to rescheduling
2060         in order to allow new sriov pci devices to be allocated on a new host.
2061         """
2062         info_cache = instance.info_cache
2063 
2064         def _has_sriov_port(vif):
2065             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
2066 
2067         if (info_cache and info_cache.network_info):
2068             for vif in info_cache.network_info:
2069                 if _has_sriov_port(vif):
2070                     return True
2071         return False
2072 
2073     @staticmethod
2074     def _get_scheduler_hints(filter_properties, request_spec=None):
2075         """Helper method to get scheduler hints.
2076 
2077         This method prefers to get the hints out of the request spec, but that
2078         might not be provided. Conductor will pass request_spec down to the
2079         first compute chosen for a build but older computes will not pass
2080         the request_spec to conductor's build_instances method for a
2081         a reschedule, so if we're on a host via a retry, request_spec may not
2082         be provided so we need to fallback to use the filter_properties
2083         to get scheduler hints.
2084         """
2085         hints = {}
2086         if request_spec is not None and 'scheduler_hints' in request_spec:
2087             hints = request_spec.scheduler_hints
2088         if not hints:
2089             hints = filter_properties.get('scheduler_hints') or {}
2090         return hints
2091 
2092     def _build_and_run_instance(self, context, instance, image, injected_files,
2093             admin_password, requested_networks, security_groups,
2094             block_device_mapping, node, limits, filter_properties,
2095             request_spec=None):
2096 
2097         image_name = image.get('name')
2098         self._notify_about_instance_usage(context, instance, 'create.start',
2099                 extra_usage_info={'image_name': image_name})
2100         compute_utils.notify_about_instance_create(
2101             context, instance, self.host,
2102             phase=fields.NotificationPhase.START,
2103             bdms=block_device_mapping)
2104 
2105         # NOTE(mikal): cache the keystone roles associated with the instance
2106         # at boot time for later reference
2107         instance.system_metadata.update(
2108             {'boot_roles': ','.join(context.roles)})
2109 
2110         self._check_device_tagging(requested_networks, block_device_mapping)
2111         self._check_trusted_certs(instance)
2112 
2113         try:
2114             scheduler_hints = self._get_scheduler_hints(filter_properties,
2115                                                         request_spec)
2116             with self.rt.instance_claim(context, instance, node, limits):
2117                 # NOTE(russellb) It's important that this validation be done
2118                 # *after* the resource tracker instance claim, as that is where
2119                 # the host is set on the instance.
2120                 self._validate_instance_group_policy(context, instance,
2121                                                      scheduler_hints)
2122                 image_meta = objects.ImageMeta.from_dict(image)
2123                 with self._build_resources(context, instance,
2124                         requested_networks, security_groups, image_meta,
2125                         block_device_mapping) as resources:
2126                     instance.vm_state = vm_states.BUILDING
2127                     instance.task_state = task_states.SPAWNING
2128                     # NOTE(JoshNang) This also saves the changes to the
2129                     # instance from _allocate_network_async, as they aren't
2130                     # saved in that function to prevent races.
2131                     instance.save(expected_task_state=
2132                             task_states.BLOCK_DEVICE_MAPPING)
2133                     block_device_info = resources['block_device_info']
2134                     network_info = resources['network_info']
2135                     allocs = resources['allocations']
2136                     LOG.debug('Start spawning the instance on the hypervisor.',
2137                               instance=instance)
2138                     with timeutils.StopWatch() as timer:
2139                         self.driver.spawn(context, instance, image_meta,
2140                                           injected_files, admin_password,
2141                                           allocs, network_info=network_info,
2142                                           block_device_info=block_device_info)
2143                     LOG.info('Took %0.2f seconds to spawn the instance on '
2144                              'the hypervisor.', timer.elapsed(),
2145                              instance=instance)
2146         except (exception.InstanceNotFound,
2147                 exception.UnexpectedDeletingTaskStateError) as e:
2148             with excutils.save_and_reraise_exception():
2149                 self._notify_about_instance_usage(context, instance,
2150                     'create.error', fault=e)
2151                 tb = traceback.format_exc()
2152                 compute_utils.notify_about_instance_create(
2153                     context, instance, self.host,
2154                     phase=fields.NotificationPhase.ERROR, exception=e,
2155                     bdms=block_device_mapping, tb=tb)
2156         except exception.ComputeResourcesUnavailable as e:
2157             LOG.debug(e.format_message(), instance=instance)
2158             self._notify_about_instance_usage(context, instance,
2159                     'create.error', fault=e)
2160             tb = traceback.format_exc()
2161             compute_utils.notify_about_instance_create(
2162                     context, instance, self.host,
2163                     phase=fields.NotificationPhase.ERROR, exception=e,
2164                     bdms=block_device_mapping, tb=tb)
2165             raise exception.RescheduledException(
2166                     instance_uuid=instance.uuid, reason=e.format_message())
2167         except exception.BuildAbortException as e:
2168             with excutils.save_and_reraise_exception():
2169                 LOG.debug(e.format_message(), instance=instance)
2170                 self._notify_about_instance_usage(context, instance,
2171                     'create.error', fault=e)
2172                 tb = traceback.format_exc()
2173                 compute_utils.notify_about_instance_create(
2174                     context, instance, self.host,
2175                     phase=fields.NotificationPhase.ERROR, exception=e,
2176                     bdms=block_device_mapping, tb=tb)
2177         except (exception.FixedIpLimitExceeded,
2178                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2179             LOG.warning('No more network or fixed IP to be allocated',
2180                         instance=instance)
2181             self._notify_about_instance_usage(context, instance,
2182                     'create.error', fault=e)
2183             tb = traceback.format_exc()
2184             compute_utils.notify_about_instance_create(
2185                     context, instance, self.host,
2186                     phase=fields.NotificationPhase.ERROR, exception=e,
2187                     bdms=block_device_mapping, tb=tb)
2188             msg = _('Failed to allocate the network(s) with error %s, '
2189                     'not rescheduling.') % e.format_message()
2190             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2191                     reason=msg)
2192         except (exception.VirtualInterfaceCreateException,
2193                 exception.VirtualInterfaceMacAddressException,
2194                 exception.FixedIpInvalidOnHost,
2195                 exception.UnableToAutoAllocateNetwork,
2196                 exception.NetworksWithQoSPolicyNotSupported) as e:
2197             LOG.exception('Failed to allocate network(s)',
2198                           instance=instance)
2199             self._notify_about_instance_usage(context, instance,
2200                     'create.error', fault=e)
2201             tb = traceback.format_exc()
2202             compute_utils.notify_about_instance_create(
2203                     context, instance, self.host,
2204                     phase=fields.NotificationPhase.ERROR, exception=e,
2205                     bdms=block_device_mapping, tb=tb)
2206             msg = _('Failed to allocate the network(s), not rescheduling.')
2207             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2208                     reason=msg)
2209         except (exception.FlavorDiskTooSmall,
2210                 exception.FlavorMemoryTooSmall,
2211                 exception.ImageNotActive,
2212                 exception.ImageUnacceptable,
2213                 exception.InvalidDiskInfo,
2214                 exception.InvalidDiskFormat,
2215                 cursive_exception.SignatureVerificationError,
2216                 exception.CertificateValidationFailed,
2217                 exception.VolumeEncryptionNotSupported,
2218                 exception.InvalidInput,
2219                 # TODO(mriedem): We should be validating RequestedVRamTooHigh
2220                 # in the API during server create and rebuild.
2221                 exception.RequestedVRamTooHigh) as e:
2222             self._notify_about_instance_usage(context, instance,
2223                     'create.error', fault=e)
2224             tb = traceback.format_exc()
2225             compute_utils.notify_about_instance_create(
2226                     context, instance, self.host,
2227                     phase=fields.NotificationPhase.ERROR, exception=e,
2228                     bdms=block_device_mapping, tb=tb)
2229             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2230                     reason=e.format_message())
2231         except Exception as e:
2232             self._notify_about_instance_usage(context, instance,
2233                     'create.error', fault=e)
2234             tb = traceback.format_exc()
2235             compute_utils.notify_about_instance_create(
2236                     context, instance, self.host,
2237                     phase=fields.NotificationPhase.ERROR, exception=e,
2238                     bdms=block_device_mapping, tb=tb)
2239             raise exception.RescheduledException(
2240                     instance_uuid=instance.uuid, reason=six.text_type(e))
2241 
2242         # NOTE(alaski): This is only useful during reschedules, remove it now.
2243         instance.system_metadata.pop('network_allocated', None)
2244 
2245         # If CONF.default_access_ip_network_name is set, grab the
2246         # corresponding network and set the access ip values accordingly.
2247         network_name = CONF.default_access_ip_network_name
2248         if (network_name and not instance.access_ip_v4 and
2249                 not instance.access_ip_v6):
2250             # Note that when there are multiple ips to choose from, an
2251             # arbitrary one will be chosen.
2252             for vif in network_info:
2253                 if vif['network']['label'] == network_name:
2254                     for ip in vif.fixed_ips():
2255                         if not instance.access_ip_v4 and ip['version'] == 4:
2256                             instance.access_ip_v4 = ip['address']
2257                         if not instance.access_ip_v6 and ip['version'] == 6:
2258                             instance.access_ip_v6 = ip['address']
2259                     break
2260 
2261         self._update_instance_after_spawn(context, instance)
2262 
2263         try:
2264             instance.save(expected_task_state=task_states.SPAWNING)
2265         except (exception.InstanceNotFound,
2266                 exception.UnexpectedDeletingTaskStateError) as e:
2267             with excutils.save_and_reraise_exception():
2268                 self._notify_about_instance_usage(context, instance,
2269                     'create.error', fault=e)
2270                 tb = traceback.format_exc()
2271                 compute_utils.notify_about_instance_create(
2272                     context, instance, self.host,
2273                     phase=fields.NotificationPhase.ERROR, exception=e,
2274                     bdms=block_device_mapping, tb=tb)
2275 
2276         self._update_scheduler_instance_info(context, instance)
2277         self._notify_about_instance_usage(context, instance, 'create.end',
2278                 extra_usage_info={'message': _('Success')},
2279                 network_info=network_info)
2280         compute_utils.notify_about_instance_create(context, instance,
2281                 self.host, phase=fields.NotificationPhase.END,
2282                 bdms=block_device_mapping)
2283 
2284     @contextlib.contextmanager
2285     def _build_resources(self, context, instance, requested_networks,
2286                          security_groups, image_meta, block_device_mapping):
2287         resources = {}
2288         network_info = None
2289         try:
2290             LOG.debug('Start building networks asynchronously for instance.',
2291                       instance=instance)
2292             network_info = self._build_networks_for_instance(context, instance,
2293                     requested_networks, security_groups)
2294             resources['network_info'] = network_info
2295         except (exception.InstanceNotFound,
2296                 exception.UnexpectedDeletingTaskStateError):
2297             raise
2298         except exception.UnexpectedTaskStateError as e:
2299             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2300                     reason=e.format_message())
2301         except Exception:
2302             # Because this allocation is async any failures are likely to occur
2303             # when the driver accesses network_info during spawn().
2304             LOG.exception('Failed to allocate network(s)',
2305                           instance=instance)
2306             msg = _('Failed to allocate the network(s), not rescheduling.')
2307             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2308                     reason=msg)
2309 
2310         try:
2311             # Perform any driver preparation work for the driver.
2312             self.driver.prepare_for_spawn(instance)
2313 
2314             # Depending on a virt driver, some network configuration is
2315             # necessary before preparing block devices.
2316             self.driver.prepare_networks_before_block_device_mapping(
2317                 instance, network_info)
2318 
2319             # Verify that all the BDMs have a device_name set and assign a
2320             # default to the ones missing it with the help of the driver.
2321             self._default_block_device_names(instance, image_meta,
2322                                              block_device_mapping)
2323 
2324             LOG.debug('Start building block device mappings for instance.',
2325                       instance=instance)
2326             instance.vm_state = vm_states.BUILDING
2327             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2328             instance.save()
2329 
2330             block_device_info = self._prep_block_device(context, instance,
2331                     block_device_mapping)
2332             resources['block_device_info'] = block_device_info
2333         except (exception.InstanceNotFound,
2334                 exception.UnexpectedDeletingTaskStateError):
2335             with excutils.save_and_reraise_exception():
2336                 # Make sure the async call finishes
2337                 if network_info is not None:
2338                     network_info.wait(do_raise=False)
2339                     self.driver.clean_networks_preparation(instance,
2340                                                            network_info)
2341                 self.driver.failed_spawn_cleanup(instance)
2342         except (exception.UnexpectedTaskStateError,
2343                 exception.OverQuota, exception.InvalidBDM) as e:
2344             # Make sure the async call finishes
2345             if network_info is not None:
2346                 network_info.wait(do_raise=False)
2347                 self.driver.clean_networks_preparation(instance, network_info)
2348             self.driver.failed_spawn_cleanup(instance)
2349             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2350                     reason=e.format_message())
2351         except Exception:
2352             LOG.exception('Failure prepping block device',
2353                           instance=instance)
2354             # Make sure the async call finishes
2355             if network_info is not None:
2356                 network_info.wait(do_raise=False)
2357                 self.driver.clean_networks_preparation(instance, network_info)
2358             self.driver.failed_spawn_cleanup(instance)
2359             msg = _('Failure prepping block device.')
2360             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2361                     reason=msg)
2362 
2363         try:
2364             resources['allocations'] = (
2365                 self.reportclient.get_allocations_for_consumer(context,
2366                                                                instance.uuid))
2367         except Exception:
2368             LOG.exception('Failure retrieving placement allocations',
2369                           instance=instance)
2370             # Make sure the async call finishes
2371             if network_info is not None:
2372                 network_info.wait(do_raise=False)
2373             self.driver.failed_spawn_cleanup(instance)
2374             msg = _('Failure retrieving placement allocations')
2375             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2376                                                 reason=msg)
2377 
2378         try:
2379             yield resources
2380         except Exception as exc:
2381             with excutils.save_and_reraise_exception() as ctxt:
2382                 if not isinstance(exc, (
2383                         exception.InstanceNotFound,
2384                         exception.UnexpectedDeletingTaskStateError)):
2385                     LOG.exception('Instance failed to spawn',
2386                                   instance=instance)
2387                 # Make sure the async call finishes
2388                 if network_info is not None:
2389                     network_info.wait(do_raise=False)
2390                 # if network_info is empty we're likely here because of
2391                 # network allocation failure. Since nothing can be reused on
2392                 # rescheduling it's better to deallocate network to eliminate
2393                 # the chance of orphaned ports in neutron
2394                 deallocate_networks = False if network_info else True
2395                 try:
2396                     self._shutdown_instance(context, instance,
2397                             block_device_mapping, requested_networks,
2398                             try_deallocate_networks=deallocate_networks)
2399                 except Exception as exc2:
2400                     ctxt.reraise = False
2401                     LOG.warning('Could not clean up failed build,'
2402                                 ' not rescheduling. Error: %s',
2403                                 six.text_type(exc2))
2404                     raise exception.BuildAbortException(
2405                             instance_uuid=instance.uuid,
2406                             reason=six.text_type(exc))
2407 
2408     def _cleanup_allocated_networks(self, context, instance,
2409             requested_networks):
2410         try:
2411             self._deallocate_network(context, instance, requested_networks)
2412         except Exception:
2413             LOG.exception('Failed to deallocate networks', instance=instance)
2414             return
2415 
2416         instance.system_metadata['network_allocated'] = 'False'
2417         try:
2418             instance.save()
2419         except exception.InstanceNotFound:
2420             # NOTE(alaski): It's possible that we're cleaning up the networks
2421             # because the instance was deleted.  If that's the case then this
2422             # exception will be raised by instance.save()
2423             pass
2424 
2425     def _try_deallocate_network(self, context, instance,
2426                                 requested_networks=None):
2427 
2428         # During auto-scale cleanup, we could be deleting a large number
2429         # of servers at the same time and overloading parts of the system,
2430         # so we retry a few times in case of connection failures to the
2431         # networking service.
2432         @loopingcall.RetryDecorator(
2433             max_retry_count=3, inc_sleep_time=2, max_sleep_time=12,
2434             exceptions=(keystone_exception.connection.ConnectFailure,))
2435         def _deallocate_network_with_retries():
2436             try:
2437                 self._deallocate_network(
2438                     context, instance, requested_networks)
2439             except keystone_exception.connection.ConnectFailure as e:
2440                 # Provide a warning that something is amiss.
2441                 with excutils.save_and_reraise_exception():
2442                     LOG.warning('Failed to deallocate network for instance; '
2443                                 'retrying. Error: %s', six.text_type(e),
2444                                 instance=instance)
2445 
2446         try:
2447             # tear down allocated network structure
2448             _deallocate_network_with_retries()
2449         except Exception as ex:
2450             with excutils.save_and_reraise_exception():
2451                 LOG.error('Failed to deallocate network for instance. '
2452                           'Error: %s', ex, instance=instance)
2453                 self._set_instance_obj_error_state(context, instance)
2454 
2455     def _get_power_off_values(self, context, instance, clean_shutdown):
2456         """Get the timing configuration for powering down this instance."""
2457         if clean_shutdown:
2458             timeout = compute_utils.get_value_from_system_metadata(instance,
2459                           key='image_os_shutdown_timeout', type=int,
2460                           default=CONF.shutdown_timeout)
2461             retry_interval = CONF.compute.shutdown_retry_interval
2462         else:
2463             timeout = 0
2464             retry_interval = 0
2465 
2466         return timeout, retry_interval
2467 
2468     def _power_off_instance(self, context, instance, clean_shutdown=True):
2469         """Power off an instance on this host."""
2470         timeout, retry_interval = self._get_power_off_values(context,
2471                                         instance, clean_shutdown)
2472         self.driver.power_off(instance, timeout, retry_interval)
2473 
2474     def _shutdown_instance(self, context, instance,
2475                            bdms, requested_networks=None, notify=True,
2476                            try_deallocate_networks=True):
2477         """Shutdown an instance on this host.
2478 
2479         :param:context: security context
2480         :param:instance: a nova.objects.Instance object
2481         :param:bdms: the block devices for the instance to be torn
2482                      down
2483         :param:requested_networks: the networks on which the instance
2484                                    has ports
2485         :param:notify: true if a final usage notification should be
2486                        emitted
2487         :param:try_deallocate_networks: false if we should avoid
2488                                         trying to teardown networking
2489         """
2490         context = context.elevated()
2491         LOG.info('Terminating instance', instance=instance)
2492 
2493         if notify:
2494             self._notify_about_instance_usage(context, instance,
2495                                               "shutdown.start")
2496             compute_utils.notify_about_instance_action(context, instance,
2497                     self.host, action=fields.NotificationAction.SHUTDOWN,
2498                     phase=fields.NotificationPhase.START, bdms=bdms)
2499 
2500         network_info = instance.get_network_info()
2501 
2502         # NOTE(vish) get bdms before destroying the instance
2503         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2504         block_device_info = self._get_instance_block_device_info(
2505             context, instance, bdms=bdms)
2506 
2507         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2508         #                want to keep ip allocated for certain failures
2509         try:
2510             LOG.debug('Start destroying the instance on the hypervisor.',
2511                       instance=instance)
2512             with timeutils.StopWatch() as timer:
2513                 self.driver.destroy(context, instance, network_info,
2514                                     block_device_info)
2515             LOG.info('Took %0.2f seconds to destroy the instance on the '
2516                      'hypervisor.', timer.elapsed(), instance=instance)
2517         except exception.InstancePowerOffFailure:
2518             # if the instance can't power off, don't release the ip
2519             with excutils.save_and_reraise_exception():
2520                 pass
2521         except Exception:
2522             with excutils.save_and_reraise_exception():
2523                 # deallocate ip and fail without proceeding to
2524                 # volume api calls, preserving current behavior
2525                 if try_deallocate_networks:
2526                     self._try_deallocate_network(context, instance,
2527                                                  requested_networks)
2528 
2529         if try_deallocate_networks:
2530             self._try_deallocate_network(context, instance, requested_networks)
2531 
2532         timer.restart()
2533         for bdm in vol_bdms:
2534             try:
2535                 if bdm.attachment_id:
2536                     self.volume_api.attachment_delete(context,
2537                                                       bdm.attachment_id)
2538                 else:
2539                     # NOTE(vish): actual driver detach done in driver.destroy,
2540                     #             so just tell cinder that we are done with it.
2541                     connector = self.driver.get_volume_connector(instance)
2542                     self.volume_api.terminate_connection(context,
2543                                                          bdm.volume_id,
2544                                                          connector)
2545                     self.volume_api.detach(context, bdm.volume_id,
2546                                            instance.uuid)
2547 
2548             except exception.VolumeAttachmentNotFound as exc:
2549                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2550                           instance=instance)
2551             except exception.DiskNotFound as exc:
2552                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2553                           instance=instance)
2554             except exception.VolumeNotFound as exc:
2555                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2556                           instance=instance)
2557             except (cinder_exception.EndpointNotFound,
2558                     keystone_exception.EndpointNotFound) as exc:
2559                 LOG.warning('Ignoring EndpointNotFound for '
2560                             'volume %(volume_id)s: %(exc)s',
2561                             {'exc': exc, 'volume_id': bdm.volume_id},
2562                             instance=instance)
2563             except cinder_exception.ClientException as exc:
2564                 LOG.warning('Ignoring unknown cinder exception for '
2565                             'volume %(volume_id)s: %(exc)s',
2566                             {'exc': exc, 'volume_id': bdm.volume_id},
2567                             instance=instance)
2568             except Exception as exc:
2569                 LOG.warning('Ignoring unknown exception for '
2570                             'volume %(volume_id)s: %(exc)s',
2571                             {'exc': exc, 'volume_id': bdm.volume_id},
2572                             instance=instance)
2573         if vol_bdms:
2574             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2575                      'for instance.',
2576                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2577                      instance=instance)
2578 
2579         if notify:
2580             self._notify_about_instance_usage(context, instance,
2581                                               "shutdown.end")
2582             compute_utils.notify_about_instance_action(context, instance,
2583                     self.host, action=fields.NotificationAction.SHUTDOWN,
2584                     phase=fields.NotificationPhase.END, bdms=bdms)
2585 
2586     def _cleanup_volumes(self, context, instance, bdms, raise_exc=True,
2587                          detach=True):
2588         exc_info = None
2589         for bdm in bdms:
2590             if detach and bdm.volume_id:
2591                 try:
2592                     LOG.debug("Detaching volume: %s", bdm.volume_id,
2593                               instance_uuid=instance.uuid)
2594                     destroy = bdm.delete_on_termination
2595                     self._detach_volume(context, bdm, instance,
2596                                         destroy_bdm=destroy)
2597                 except Exception as exc:
2598                     exc_info = sys.exc_info()
2599                     LOG.warning('Failed to detach volume: %(volume_id)s '
2600                                 'due to %(exc)s',
2601                                 {'volume_id': bdm.volume_id, 'exc': exc})
2602 
2603             if bdm.volume_id and bdm.delete_on_termination:
2604                 try:
2605                     LOG.debug("Deleting volume: %s", bdm.volume_id,
2606                               instance_uuid=instance.uuid)
2607                     self.volume_api.delete(context, bdm.volume_id)
2608                 except Exception as exc:
2609                     exc_info = sys.exc_info()
2610                     LOG.warning('Failed to delete volume: %(volume_id)s '
2611                                 'due to %(exc)s',
2612                                 {'volume_id': bdm.volume_id, 'exc': exc})
2613         if exc_info is not None and raise_exc:
2614             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2615 
2616     @hooks.add_hook("delete_instance")
2617     def _delete_instance(self, context, instance, bdms):
2618         """Delete an instance on this host.
2619 
2620         :param context: nova request context
2621         :param instance: nova.objects.instance.Instance object
2622         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2623         """
2624         events = self.instance_events.clear_events_for_instance(instance)
2625         if events:
2626             LOG.debug('Events pending at deletion: %(events)s',
2627                       {'events': ','.join(events.keys())},
2628                       instance=instance)
2629         self._notify_about_instance_usage(context, instance,
2630                                           "delete.start")
2631         compute_utils.notify_about_instance_action(context, instance,
2632                 self.host, action=fields.NotificationAction.DELETE,
2633                 phase=fields.NotificationPhase.START, bdms=bdms)
2634 
2635         self._shutdown_instance(context, instance, bdms)
2636 
2637         # NOTE(vish): We have already deleted the instance, so we have
2638         #             to ignore problems cleaning up the volumes. It
2639         #             would be nice to let the user know somehow that
2640         #             the volume deletion failed, but it is not
2641         #             acceptable to have an instance that can not be
2642         #             deleted. Perhaps this could be reworked in the
2643         #             future to set an instance fault the first time
2644         #             and to only ignore the failure if the instance
2645         #             is already in ERROR.
2646 
2647         # NOTE(ameeda): The volumes already detached during the above
2648         #               _shutdown_instance() call and this is why
2649         #               detach is not requested from _cleanup_volumes()
2650         #               in this case
2651 
2652         self._cleanup_volumes(context, instance, bdms,
2653                 raise_exc=False, detach=False)
2654         # if a delete task succeeded, always update vm state and task
2655         # state without expecting task state to be DELETING
2656         instance.vm_state = vm_states.DELETED
2657         instance.task_state = None
2658         instance.power_state = power_state.NOSTATE
2659         instance.terminated_at = timeutils.utcnow()
2660         instance.save()
2661 
2662         self._complete_deletion(context, instance)
2663         # only destroy the instance in the db if the _complete_deletion
2664         # doesn't raise and therefore allocation is successfully
2665         # deleted in placement
2666         instance.destroy()
2667 
2668         self._notify_about_instance_usage(context, instance, "delete.end")
2669         compute_utils.notify_about_instance_action(context, instance,
2670                 self.host, action=fields.NotificationAction.DELETE,
2671                 phase=fields.NotificationPhase.END, bdms=bdms)
2672 
2673     @wrap_exception()
2674     @reverts_task_state
2675     @wrap_instance_event(prefix='compute')
2676     @wrap_instance_fault
2677     def terminate_instance(self, context, instance, bdms):
2678         """Terminate an instance on this host."""
2679         @utils.synchronized(instance.uuid)
2680         def do_terminate_instance(instance, bdms):
2681             # NOTE(mriedem): If we are deleting the instance while it was
2682             # booting from volume, we could be racing with a database update of
2683             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2684             # to compute here, the BDMs may be stale at this point. So check
2685             # for any volume BDMs that don't have volume_id set and if we
2686             # detect that, we need to refresh the BDM list before proceeding.
2687             # TODO(mriedem): Move this into _delete_instance and make the bdms
2688             # parameter optional.
2689             for bdm in list(bdms):
2690                 if bdm.is_volume and not bdm.volume_id:
2691                     LOG.debug('There are potentially stale BDMs during '
2692                               'delete, refreshing the BlockDeviceMappingList.',
2693                               instance=instance)
2694                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2695                         context, instance.uuid)
2696                     break
2697             try:
2698                 self._delete_instance(context, instance, bdms)
2699             except exception.InstanceNotFound:
2700                 LOG.info("Instance disappeared during terminate",
2701                          instance=instance)
2702             except Exception:
2703                 # As we're trying to delete always go to Error if something
2704                 # goes wrong that _delete_instance can't handle.
2705                 with excutils.save_and_reraise_exception():
2706                     LOG.exception('Setting instance vm_state to ERROR',
2707                                   instance=instance)
2708                     self._set_instance_obj_error_state(context, instance)
2709 
2710         do_terminate_instance(instance, bdms)
2711 
2712     # NOTE(johannes): This is probably better named power_off_instance
2713     # so it matches the driver method, but because of other issues, we
2714     # can't use that name in grizzly.
2715     @wrap_exception()
2716     @reverts_task_state
2717     @wrap_instance_event(prefix='compute')
2718     @wrap_instance_fault
2719     def stop_instance(self, context, instance, clean_shutdown):
2720         """Stopping an instance on this host."""
2721 
2722         @utils.synchronized(instance.uuid)
2723         def do_stop_instance():
2724             current_power_state = self._get_power_state(context, instance)
2725             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2726                       'current task_state: %(task_state)s, current DB '
2727                       'power_state: %(db_power_state)s, current VM '
2728                       'power_state: %(current_power_state)s',
2729                       {'vm_state': instance.vm_state,
2730                        'task_state': instance.task_state,
2731                        'db_power_state': instance.power_state,
2732                        'current_power_state': current_power_state},
2733                       instance_uuid=instance.uuid)
2734 
2735             # NOTE(mriedem): If the instance is already powered off, we are
2736             # possibly tearing down and racing with other operations, so we can
2737             # expect the task_state to be None if something else updates the
2738             # instance and we're not locking it.
2739             expected_task_state = [task_states.POWERING_OFF]
2740             # The list of power states is from _sync_instance_power_state.
2741             if current_power_state in (power_state.NOSTATE,
2742                                        power_state.SHUTDOWN,
2743                                        power_state.CRASHED):
2744                 LOG.info('Instance is already powered off in the '
2745                          'hypervisor when stop is called.',
2746                          instance=instance)
2747                 expected_task_state.append(None)
2748 
2749             self._notify_about_instance_usage(context, instance,
2750                                               "power_off.start")
2751 
2752             compute_utils.notify_about_instance_action(context, instance,
2753                         self.host, action=fields.NotificationAction.POWER_OFF,
2754                         phase=fields.NotificationPhase.START)
2755 
2756             self._power_off_instance(context, instance, clean_shutdown)
2757             instance.power_state = self._get_power_state(context, instance)
2758             instance.vm_state = vm_states.STOPPED
2759             instance.task_state = None
2760             instance.save(expected_task_state=expected_task_state)
2761             self._notify_about_instance_usage(context, instance,
2762                                               "power_off.end")
2763 
2764             compute_utils.notify_about_instance_action(context, instance,
2765                         self.host, action=fields.NotificationAction.POWER_OFF,
2766                         phase=fields.NotificationPhase.END)
2767 
2768         do_stop_instance()
2769 
2770     def _power_on(self, context, instance):
2771         network_info = self.network_api.get_instance_nw_info(context, instance)
2772         block_device_info = self._get_instance_block_device_info(context,
2773                                                                  instance)
2774         self.driver.power_on(context, instance,
2775                              network_info,
2776                              block_device_info)
2777 
2778     def _delete_snapshot_of_shelved_instance(self, context, instance,
2779                                              snapshot_id):
2780         """Delete snapshot of shelved instance."""
2781         try:
2782             self.image_api.delete(context, snapshot_id)
2783         except (exception.ImageNotFound,
2784                 exception.ImageNotAuthorized) as exc:
2785             LOG.warning("Failed to delete snapshot "
2786                         "from shelved instance (%s).",
2787                         exc.format_message(), instance=instance)
2788         except Exception:
2789             LOG.exception("Something wrong happened when trying to "
2790                           "delete snapshot from shelved instance.",
2791                           instance=instance)
2792 
2793     # NOTE(johannes): This is probably better named power_on_instance
2794     # so it matches the driver method, but because of other issues, we
2795     # can't use that name in grizzly.
2796     @wrap_exception()
2797     @reverts_task_state
2798     @wrap_instance_event(prefix='compute')
2799     @wrap_instance_fault
2800     def start_instance(self, context, instance):
2801         """Starting an instance on this host."""
2802         self._notify_about_instance_usage(context, instance, "power_on.start")
2803         compute_utils.notify_about_instance_action(context, instance,
2804             self.host, action=fields.NotificationAction.POWER_ON,
2805             phase=fields.NotificationPhase.START)
2806         self._power_on(context, instance)
2807         instance.power_state = self._get_power_state(context, instance)
2808         instance.vm_state = vm_states.ACTIVE
2809         instance.task_state = None
2810 
2811         # Delete an image(VM snapshot) for a shelved instance
2812         snapshot_id = instance.system_metadata.get('shelved_image_id')
2813         if snapshot_id:
2814             self._delete_snapshot_of_shelved_instance(context, instance,
2815                                                       snapshot_id)
2816 
2817         # Delete system_metadata for a shelved instance
2818         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2819 
2820         instance.save(expected_task_state=task_states.POWERING_ON)
2821         self._notify_about_instance_usage(context, instance, "power_on.end")
2822         compute_utils.notify_about_instance_action(context, instance,
2823             self.host, action=fields.NotificationAction.POWER_ON,
2824             phase=fields.NotificationPhase.END)
2825 
2826     @messaging.expected_exceptions(NotImplementedError,
2827                                    exception.TriggerCrashDumpNotSupported,
2828                                    exception.InstanceNotRunning)
2829     @wrap_exception()
2830     @wrap_instance_event(prefix='compute')
2831     @wrap_instance_fault
2832     def trigger_crash_dump(self, context, instance):
2833         """Trigger crash dump in an instance."""
2834 
2835         self._notify_about_instance_usage(context, instance,
2836                                           "trigger_crash_dump.start")
2837         compute_utils.notify_about_instance_action(context, instance,
2838                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2839                 phase=fields.NotificationPhase.START)
2840 
2841         # This method does not change task_state and power_state because the
2842         # effect of a trigger depends on user's configuration.
2843         self.driver.trigger_crash_dump(instance)
2844 
2845         self._notify_about_instance_usage(context, instance,
2846                                           "trigger_crash_dump.end")
2847         compute_utils.notify_about_instance_action(context, instance,
2848                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2849                 phase=fields.NotificationPhase.END)
2850 
2851     @wrap_exception()
2852     @reverts_task_state
2853     @wrap_instance_event(prefix='compute')
2854     @wrap_instance_fault
2855     def soft_delete_instance(self, context, instance):
2856         """Soft delete an instance on this host."""
2857         with compute_utils.notify_about_instance_delete(
2858                 self.notifier, context, instance, 'soft_delete',
2859                 source=fields.NotificationSource.COMPUTE):
2860             try:
2861                 self.driver.soft_delete(instance)
2862             except NotImplementedError:
2863                 # Fallback to just powering off the instance if the
2864                 # hypervisor doesn't implement the soft_delete method
2865                 self.driver.power_off(instance)
2866             instance.power_state = self._get_power_state(context, instance)
2867             instance.vm_state = vm_states.SOFT_DELETED
2868             instance.task_state = None
2869             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2870 
2871     @wrap_exception()
2872     @reverts_task_state
2873     @wrap_instance_event(prefix='compute')
2874     @wrap_instance_fault
2875     def restore_instance(self, context, instance):
2876         """Restore a soft-deleted instance on this host."""
2877         self._notify_about_instance_usage(context, instance, "restore.start")
2878         compute_utils.notify_about_instance_action(context, instance,
2879             self.host, action=fields.NotificationAction.RESTORE,
2880             phase=fields.NotificationPhase.START)
2881         try:
2882             self.driver.restore(instance)
2883         except NotImplementedError:
2884             # Fallback to just powering on the instance if the hypervisor
2885             # doesn't implement the restore method
2886             self._power_on(context, instance)
2887         instance.power_state = self._get_power_state(context, instance)
2888         instance.vm_state = vm_states.ACTIVE
2889         instance.task_state = None
2890         instance.save(expected_task_state=task_states.RESTORING)
2891         self._notify_about_instance_usage(context, instance, "restore.end")
2892         compute_utils.notify_about_instance_action(context, instance,
2893             self.host, action=fields.NotificationAction.RESTORE,
2894             phase=fields.NotificationPhase.END)
2895 
2896     @staticmethod
2897     def _set_migration_status(migration, status):
2898         """Set the status, and guard against a None being passed in.
2899 
2900         This is useful as some of the compute RPC calls will not pass
2901         a migration object in older versions. The check can be removed when
2902         we move past 4.x major version of the RPC API.
2903         """
2904         if migration:
2905             migration.status = status
2906             migration.save()
2907 
2908     def _rebuild_default_impl(self, context, instance, image_meta,
2909                               injected_files, admin_password, allocations,
2910                               bdms, detach_block_devices, attach_block_devices,
2911                               network_info=None,
2912                               evacuate=False, block_device_info=None,
2913                               preserve_ephemeral=False):
2914         if preserve_ephemeral:
2915             # The default code path does not support preserving ephemeral
2916             # partitions.
2917             raise exception.PreserveEphemeralNotSupported()
2918 
2919         if evacuate:
2920             detach_block_devices(context, bdms)
2921         else:
2922             self._power_off_instance(context, instance, clean_shutdown=True)
2923             detach_block_devices(context, bdms)
2924             self.driver.destroy(context, instance,
2925                                 network_info=network_info,
2926                                 block_device_info=block_device_info)
2927 
2928         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2929         instance.save(expected_task_state=[task_states.REBUILDING])
2930 
2931         new_block_device_info = attach_block_devices(context, instance, bdms)
2932 
2933         instance.task_state = task_states.REBUILD_SPAWNING
2934         instance.save(
2935             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2936 
2937         with instance.mutated_migration_context():
2938             self.driver.spawn(context, instance, image_meta, injected_files,
2939                               admin_password, allocations,
2940                               network_info=network_info,
2941                               block_device_info=new_block_device_info)
2942 
2943     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
2944         tb = traceback.format_exc()
2945         self._notify_about_instance_usage(context, instance,
2946                                           'rebuild.error', fault=error)
2947         compute_utils.notify_about_instance_rebuild(
2948             context, instance, self.host,
2949             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms,
2950             tb=tb)
2951 
2952     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2953     @wrap_exception()
2954     @reverts_task_state
2955     @wrap_instance_event(prefix='compute')
2956     @wrap_instance_fault
2957     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2958                          injected_files, new_pass, orig_sys_metadata,
2959                          bdms, recreate, on_shared_storage,
2960                          preserve_ephemeral, migration,
2961                          scheduled_node, limits, request_spec):
2962         """Destroy and re-make this instance.
2963 
2964         A 'rebuild' effectively purges all existing data from the system and
2965         remakes the VM with given 'metadata' and 'personalities'.
2966 
2967         :param context: `nova.RequestContext` object
2968         :param instance: Instance object
2969         :param orig_image_ref: Original image_ref before rebuild
2970         :param image_ref: New image_ref for rebuild
2971         :param injected_files: Files to inject
2972         :param new_pass: password to set on rebuilt instance
2973         :param orig_sys_metadata: instance system metadata from pre-rebuild
2974         :param bdms: block-device-mappings to use for rebuild
2975         :param recreate: True if the instance is being recreated (e.g. the
2976             hypervisor it was on failed) - cleanup of old state will be
2977             skipped.
2978         :param on_shared_storage: True if instance files on shared storage.
2979                                   If not provided then information from the
2980                                   driver will be used to decide if the instance
2981                                   files are available or not on the target host
2982         :param preserve_ephemeral: True if the default ephemeral storage
2983                                    partition must be preserved on rebuild
2984         :param migration: a Migration object if one was created for this
2985                           rebuild operation (if it's a part of evacuate)
2986         :param scheduled_node: A node of the host chosen by the scheduler. If a
2987                                host was specified by the user, this will be
2988                                None
2989         :param limits: Overcommit limits set by the scheduler. If a host was
2990                        specified by the user, this will be None
2991         :param request_spec: a RequestSpec object used to schedule the instance
2992 
2993         """
2994         # recreate=True means the instance is being evacuated from a failed
2995         # host to a new destination host (this host). The 'recreate' variable
2996         # name is confusing, so rename it to evacuate here at the top, which
2997         # is simpler than renaming a parameter in an RPC versioned method.
2998         evacuate = recreate
2999         context = context.elevated()
3000 
3001         if evacuate:
3002             LOG.info("Evacuating instance", instance=instance)
3003         else:
3004             LOG.info("Rebuilding instance", instance=instance)
3005 
3006         if evacuate:
3007             # This is an evacuation to a new host, so we need to perform a
3008             # resource claim.
3009             rebuild_claim = self.rt.rebuild_claim
3010         else:
3011             # This is a rebuild to the same host, so we don't need to make
3012             # a claim since the instance is already on this host.
3013             rebuild_claim = claims.NopClaim
3014 
3015         if image_ref:
3016             image_meta = objects.ImageMeta.from_image_ref(
3017                 context, self.image_api, image_ref)
3018         elif evacuate:
3019             # For evacuate the API does not send down the image_ref since the
3020             # image does not change so just get it from what was stashed in
3021             # the instance system_metadata when the instance was created (or
3022             # last rebuilt). This also works for volume-backed instances.
3023             image_meta = instance.image_meta
3024         else:
3025             image_meta = objects.ImageMeta()
3026 
3027         # NOTE(mriedem): On an evacuate, we need to update
3028         # the instance's host and node properties to reflect it's
3029         # destination node for the evacuate.
3030         if not scheduled_node:
3031             if evacuate:
3032                 try:
3033                     compute_node = self._get_compute_info(context, self.host)
3034                     scheduled_node = compute_node.hypervisor_hostname
3035                 except exception.ComputeHostNotFound:
3036                     LOG.exception('Failed to get compute_info for %s',
3037                                   self.host)
3038             else:
3039                 scheduled_node = instance.node
3040 
3041         with self._error_out_instance_on_exception(context, instance):
3042             try:
3043                 claim_ctxt = rebuild_claim(
3044                     context, instance, scheduled_node,
3045                     limits=limits, image_meta=image_meta,
3046                     migration=migration)
3047                 self._do_rebuild_instance_with_claim(
3048                     claim_ctxt, context, instance, orig_image_ref,
3049                     image_meta, injected_files, new_pass, orig_sys_metadata,
3050                     bdms, evacuate, on_shared_storage, preserve_ephemeral,
3051                     migration, request_spec)
3052             except (exception.ComputeResourcesUnavailable,
3053                     exception.RescheduledException) as e:
3054                 if isinstance(e, exception.ComputeResourcesUnavailable):
3055                     LOG.debug("Could not rebuild instance on this host, not "
3056                               "enough resources available.", instance=instance)
3057                 else:
3058                     # RescheduledException is raised by the late server group
3059                     # policy check during evacuation if a parallel scheduling
3060                     # violated the policy.
3061                     # We catch the RescheduledException here but we don't have
3062                     # the plumbing to do an actual reschedule so we abort the
3063                     # operation.
3064                     LOG.debug("Could not rebuild instance on this host, "
3065                               "late server group check failed.",
3066                               instance=instance)
3067                 # NOTE(ndipanov): We just abort the build for now and leave a
3068                 # migration record for potential cleanup later
3069                 self._set_migration_status(migration, 'failed')
3070                 # Since the claim failed, we need to remove the allocation
3071                 # created against the destination node. Note that we can only
3072                 # get here when evacuating to a destination node. Rebuilding
3073                 # on the same host (not evacuate) uses the NopClaim which will
3074                 # not raise ComputeResourcesUnavailable.
3075                 self.rt.delete_allocation_for_evacuated_instance(
3076                     context, instance, scheduled_node, node_type='destination')
3077                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3078                 raise exception.BuildAbortException(
3079                     instance_uuid=instance.uuid, reason=e.format_message())
3080             except (exception.InstanceNotFound,
3081                     exception.UnexpectedDeletingTaskStateError) as e:
3082                 LOG.debug('Instance was deleted while rebuilding',
3083                           instance=instance)
3084                 self._set_migration_status(migration, 'failed')
3085                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3086             except Exception as e:
3087                 self._set_migration_status(migration, 'failed')
3088                 if evacuate or scheduled_node is not None:
3089                     self.rt.delete_allocation_for_evacuated_instance(
3090                         context, instance, scheduled_node,
3091                         node_type='destination')
3092                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3093                 raise
3094             else:
3095                 instance.apply_migration_context()
3096                 # NOTE (ndipanov): This save will now update the host and node
3097                 # attributes making sure that next RT pass is consistent since
3098                 # it will be based on the instance and not the migration DB
3099                 # entry.
3100                 instance.host = self.host
3101                 instance.node = scheduled_node
3102                 instance.save()
3103                 instance.drop_migration_context()
3104 
3105                 # NOTE (ndipanov): Mark the migration as done only after we
3106                 # mark the instance as belonging to this host.
3107                 self._set_migration_status(migration, 'done')
3108 
3109     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
3110         """Helper to avoid deep nesting in the top-level method."""
3111 
3112         with claim_context:
3113             self._do_rebuild_instance(*args, **kwargs)
3114 
3115     @staticmethod
3116     def _get_image_name(image_meta):
3117         if image_meta.obj_attr_is_set("name"):
3118             return image_meta.name
3119         else:
3120             return ''
3121 
3122     def _do_rebuild_instance(self, context, instance, orig_image_ref,
3123                              image_meta, injected_files, new_pass,
3124                              orig_sys_metadata, bdms, evacuate,
3125                              on_shared_storage, preserve_ephemeral,
3126                              migration, request_spec):
3127         orig_vm_state = instance.vm_state
3128 
3129         if evacuate:
3130             if request_spec:
3131                 # NOTE(gibi): Do a late check of server group policy as
3132                 # parallel scheduling could violate such policy. This will
3133                 # cause the evacuate to fail as rebuild does not implement
3134                 # reschedule.
3135                 hints = self._get_scheduler_hints({}, request_spec)
3136                 self._validate_instance_group_policy(context, instance, hints)
3137 
3138             if not self.driver.capabilities.get("supports_evacuate", False):
3139                 raise exception.InstanceEvacuateNotSupported
3140 
3141             self._check_instance_exists(context, instance)
3142 
3143             if on_shared_storage is None:
3144                 LOG.debug('on_shared_storage is not provided, using driver '
3145                           'information to decide if the instance needs to '
3146                           'be evacuated')
3147                 on_shared_storage = self.driver.instance_on_disk(instance)
3148 
3149             elif (on_shared_storage !=
3150                     self.driver.instance_on_disk(instance)):
3151                 # To cover case when admin expects that instance files are
3152                 # on shared storage, but not accessible and vice versa
3153                 raise exception.InvalidSharedStorage(
3154                         _("Invalid state of instance files on shared"
3155                             " storage"))
3156 
3157             if on_shared_storage:
3158                 LOG.info('disk on shared storage, evacuating using'
3159                          ' existing disk')
3160             elif instance.image_ref:
3161                 orig_image_ref = instance.image_ref
3162                 LOG.info("disk not on shared storage, evacuating from "
3163                          "image: '%s'", str(orig_image_ref))
3164             else:
3165                 LOG.info('disk on volume, evacuating using existing '
3166                          'volume')
3167 
3168         # We check trusted certs capabilities for both evacuate (rebuild on
3169         # another host) and rebuild (rebuild on the same host) because for
3170         # evacuate we need to make sure an instance with trusted certs can
3171         # have the image verified with those certs during rebuild, and for
3172         # rebuild we could be rebuilding a server that started out with no
3173         # trusted certs on this host, and then was rebuilt with trusted certs
3174         # for a new image, in which case we need to validate that new image
3175         # with the trusted certs during the rebuild.
3176         self._check_trusted_certs(instance)
3177 
3178         # This instance.exists message should contain the original
3179         # image_ref, not the new one.  Since the DB has been updated
3180         # to point to the new one... we have to override it.
3181         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
3182                                                                context)
3183         extra_usage_info = {'image_ref_url': orig_image_ref_url}
3184         compute_utils.notify_usage_exists(
3185                 self.notifier, context, instance, self.host,
3186                 current_period=True, system_metadata=orig_sys_metadata,
3187                 extra_usage_info=extra_usage_info)
3188 
3189         # This message should contain the new image_ref
3190         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
3191         self._notify_about_instance_usage(context, instance,
3192                 "rebuild.start", extra_usage_info=extra_usage_info)
3193         # NOTE: image_name is not included in the versioned notification
3194         # because we already provide the image_uuid in the notification
3195         # payload and the image details can be looked up via the uuid.
3196         compute_utils.notify_about_instance_rebuild(
3197             context, instance, self.host,
3198             phase=fields.NotificationPhase.START,
3199             bdms=bdms)
3200 
3201         instance.power_state = self._get_power_state(context, instance)
3202         instance.task_state = task_states.REBUILDING
3203         instance.save(expected_task_state=[task_states.REBUILDING])
3204 
3205         if evacuate:
3206             self.network_api.setup_networks_on_host(
3207                     context, instance, self.host)
3208             # For nova-network this is needed to move floating IPs
3209             # For neutron this updates the host in the port binding
3210             # TODO(cfriesen): this network_api call and the one above
3211             # are so similar, we should really try to unify them.
3212             self.network_api.setup_instance_network_on_host(
3213                     context, instance, self.host, migration)
3214             # TODO(mriedem): Consider decorating setup_instance_network_on_host
3215             # with @base_api.refresh_cache and then we wouldn't need this
3216             # explicit call to get_instance_nw_info.
3217             network_info = self.network_api.get_instance_nw_info(context,
3218                                                                  instance)
3219         else:
3220             network_info = instance.get_network_info()
3221 
3222         allocations = self.reportclient.get_allocations_for_consumer(
3223             context, instance.uuid)
3224 
3225         if bdms is None:
3226             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3227                     context, instance.uuid)
3228 
3229         block_device_info = \
3230             self._get_instance_block_device_info(
3231                     context, instance, bdms=bdms)
3232 
3233         def detach_block_devices(context, bdms):
3234             for bdm in bdms:
3235                 if bdm.is_volume:
3236                     # NOTE (ildikov): Having the attachment_id set in the BDM
3237                     # means that it's the new Cinder attach/detach flow
3238                     # (available from v3.44). In that case we explicitly
3239                     # attach and detach the volumes through attachment level
3240                     # operations. In this scenario _detach_volume will delete
3241                     # the existing attachment which would make the volume
3242                     # status change to 'available' if we don't pre-create
3243                     # another empty attachment before deleting the old one.
3244                     attachment_id = None
3245                     if bdm.attachment_id:
3246                         attachment_id = self.volume_api.attachment_create(
3247                             context, bdm['volume_id'], instance.uuid)['id']
3248                     self._detach_volume(context, bdm, instance,
3249                                         destroy_bdm=False)
3250                     if attachment_id:
3251                         bdm.attachment_id = attachment_id
3252                         bdm.save()
3253 
3254         files = self._decode_files(injected_files)
3255 
3256         kwargs = dict(
3257             context=context,
3258             instance=instance,
3259             image_meta=image_meta,
3260             injected_files=files,
3261             admin_password=new_pass,
3262             allocations=allocations,
3263             bdms=bdms,
3264             detach_block_devices=detach_block_devices,
3265             attach_block_devices=self._prep_block_device,
3266             block_device_info=block_device_info,
3267             network_info=network_info,
3268             preserve_ephemeral=preserve_ephemeral,
3269             evacuate=evacuate)
3270         try:
3271             with instance.mutated_migration_context():
3272                 self.driver.rebuild(**kwargs)
3273         except NotImplementedError:
3274             # NOTE(rpodolyaka): driver doesn't provide specialized version
3275             # of rebuild, fall back to the default implementation
3276             self._rebuild_default_impl(**kwargs)
3277         self._update_instance_after_spawn(context, instance)
3278         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3279 
3280         if orig_vm_state == vm_states.STOPPED:
3281             LOG.info("bringing vm to original state: '%s'",
3282                      orig_vm_state, instance=instance)
3283             instance.vm_state = vm_states.ACTIVE
3284             instance.task_state = task_states.POWERING_OFF
3285             instance.progress = 0
3286             instance.save()
3287             self.stop_instance(context, instance, False)
3288         # TODO(melwitt): We should clean up instance console tokens here in the
3289         # case of evacuate. The instance is on a new host and will need to
3290         # establish a new console connection.
3291         self._update_scheduler_instance_info(context, instance)
3292         self._notify_about_instance_usage(
3293                 context, instance, "rebuild.end",
3294                 network_info=network_info,
3295                 extra_usage_info=extra_usage_info)
3296         compute_utils.notify_about_instance_rebuild(
3297             context, instance, self.host,
3298             phase=fields.NotificationPhase.END,
3299             bdms=bdms)
3300 
3301     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3302                                      block_device_info):
3303         """Handle cases where the virt-layer had to detach non-working volumes
3304         in order to complete an operation.
3305         """
3306         for bdm in block_device_info['block_device_mapping']:
3307             if bdm.get('mount_device') in bad_devices:
3308                 try:
3309                     volume_id = bdm['connection_info']['data']['volume_id']
3310                 except KeyError:
3311                     continue
3312 
3313                 # NOTE(sirp): ideally we'd just call
3314                 # `compute_api.detach_volume` here but since that hits the
3315                 # DB directly, that's off limits from within the
3316                 # compute-manager.
3317                 #
3318                 # API-detach
3319                 LOG.info("Detaching from volume api: %s", volume_id)
3320                 self.volume_api.begin_detaching(context, volume_id)
3321 
3322                 # Manager-detach
3323                 self.detach_volume(context, volume_id, instance)
3324 
3325     @wrap_exception()
3326     @reverts_task_state
3327     @wrap_instance_event(prefix='compute')
3328     @wrap_instance_fault
3329     def reboot_instance(self, context, instance, block_device_info,
3330                         reboot_type):
3331         """Reboot an instance on this host."""
3332         # acknowledge the request made it to the manager
3333         if reboot_type == "SOFT":
3334             instance.task_state = task_states.REBOOT_PENDING
3335             expected_states = task_states.soft_reboot_states
3336         else:
3337             instance.task_state = task_states.REBOOT_PENDING_HARD
3338             expected_states = task_states.hard_reboot_states
3339 
3340         context = context.elevated()
3341         LOG.info("Rebooting instance", instance=instance)
3342 
3343         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3344             context, instance.uuid)
3345         block_device_info = self._get_instance_block_device_info(
3346             context, instance, bdms=bdms)
3347 
3348         network_info = self.network_api.get_instance_nw_info(context, instance)
3349 
3350         self._notify_about_instance_usage(context, instance, "reboot.start")
3351         compute_utils.notify_about_instance_action(
3352             context, instance, self.host,
3353             action=fields.NotificationAction.REBOOT,
3354             phase=fields.NotificationPhase.START,
3355             bdms=bdms
3356         )
3357 
3358         instance.power_state = self._get_power_state(context, instance)
3359         instance.save(expected_task_state=expected_states)
3360 
3361         if instance.power_state != power_state.RUNNING:
3362             state = instance.power_state
3363             running = power_state.RUNNING
3364             LOG.warning('trying to reboot a non-running instance:'
3365                         ' (state: %(state)s expected: %(running)s)',
3366                         {'state': state, 'running': running},
3367                         instance=instance)
3368 
3369         def bad_volumes_callback(bad_devices):
3370             self._handle_bad_volumes_detached(
3371                     context, instance, bad_devices, block_device_info)
3372 
3373         try:
3374             # Don't change it out of rescue mode
3375             if instance.vm_state == vm_states.RESCUED:
3376                 new_vm_state = vm_states.RESCUED
3377             else:
3378                 new_vm_state = vm_states.ACTIVE
3379             new_power_state = None
3380             if reboot_type == "SOFT":
3381                 instance.task_state = task_states.REBOOT_STARTED
3382                 expected_state = task_states.REBOOT_PENDING
3383             else:
3384                 instance.task_state = task_states.REBOOT_STARTED_HARD
3385                 expected_state = task_states.REBOOT_PENDING_HARD
3386             instance.save(expected_task_state=expected_state)
3387             self.driver.reboot(context, instance,
3388                                network_info,
3389                                reboot_type,
3390                                block_device_info=block_device_info,
3391                                bad_volumes_callback=bad_volumes_callback)
3392 
3393         except Exception as error:
3394             with excutils.save_and_reraise_exception() as ctxt:
3395                 exc_info = sys.exc_info()
3396                 # if the reboot failed but the VM is running don't
3397                 # put it into an error state
3398                 new_power_state = self._get_power_state(context, instance)
3399                 if new_power_state == power_state.RUNNING:
3400                     LOG.warning('Reboot failed but instance is running',
3401                                 instance=instance)
3402                     compute_utils.add_instance_fault_from_exc(context,
3403                             instance, error, exc_info)
3404                     self._notify_about_instance_usage(context, instance,
3405                             'reboot.error', fault=error)
3406                     tb = traceback.format_exc()
3407                     compute_utils.notify_about_instance_action(
3408                         context, instance, self.host,
3409                         action=fields.NotificationAction.REBOOT,
3410                         phase=fields.NotificationPhase.ERROR,
3411                         exception=error, bdms=bdms, tb=tb
3412                     )
3413                     ctxt.reraise = False
3414                 else:
3415                     LOG.error('Cannot reboot instance: %s', error,
3416                               instance=instance)
3417                     self._set_instance_obj_error_state(context, instance)
3418 
3419         if not new_power_state:
3420             new_power_state = self._get_power_state(context, instance)
3421         try:
3422             instance.power_state = new_power_state
3423             instance.vm_state = new_vm_state
3424             instance.task_state = None
3425             instance.save()
3426         except exception.InstanceNotFound:
3427             LOG.warning("Instance disappeared during reboot",
3428                         instance=instance)
3429 
3430         self._notify_about_instance_usage(context, instance, "reboot.end")
3431         compute_utils.notify_about_instance_action(
3432             context, instance, self.host,
3433             action=fields.NotificationAction.REBOOT,
3434             phase=fields.NotificationPhase.END,
3435             bdms=bdms
3436         )
3437 
3438     @delete_image_on_error
3439     def _do_snapshot_instance(self, context, image_id, instance):
3440         self._snapshot_instance(context, image_id, instance,
3441                                 task_states.IMAGE_BACKUP)
3442 
3443     @wrap_exception()
3444     @reverts_task_state
3445     @wrap_instance_event(prefix='compute')
3446     @wrap_instance_fault
3447     def backup_instance(self, context, image_id, instance, backup_type,
3448                         rotation):
3449         """Backup an instance on this host.
3450 
3451         :param backup_type: daily | weekly
3452         :param rotation: int representing how many backups to keep around
3453         """
3454         self._do_snapshot_instance(context, image_id, instance)
3455         self._rotate_backups(context, instance, backup_type, rotation)
3456 
3457     @wrap_exception()
3458     @reverts_task_state
3459     @wrap_instance_event(prefix='compute')
3460     @wrap_instance_fault
3461     @delete_image_on_error
3462     def snapshot_instance(self, context, image_id, instance):
3463         """Snapshot an instance on this host.
3464 
3465         :param context: security context
3466         :param image_id: glance.db.sqlalchemy.models.Image.Id
3467         :param instance: a nova.objects.instance.Instance object
3468         """
3469         # NOTE(dave-mcnally) the task state will already be set by the api
3470         # but if the compute manager has crashed/been restarted prior to the
3471         # request getting here the task state may have been cleared so we set
3472         # it again and things continue normally
3473         try:
3474             instance.task_state = task_states.IMAGE_SNAPSHOT
3475             instance.save(
3476                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3477         except exception.InstanceNotFound:
3478             # possibility instance no longer exists, no point in continuing
3479             LOG.debug("Instance not found, could not set state %s "
3480                       "for instance.",
3481                       task_states.IMAGE_SNAPSHOT, instance=instance)
3482             return
3483 
3484         except exception.UnexpectedDeletingTaskStateError:
3485             LOG.debug("Instance being deleted, snapshot cannot continue",
3486                       instance=instance)
3487             return
3488 
3489         self._snapshot_instance(context, image_id, instance,
3490                                 task_states.IMAGE_SNAPSHOT)
3491 
3492     def _snapshot_instance(self, context, image_id, instance,
3493                            expected_task_state):
3494         context = context.elevated()
3495 
3496         instance.power_state = self._get_power_state(context, instance)
3497         try:
3498             instance.save()
3499 
3500             LOG.info('instance snapshotting', instance=instance)
3501 
3502             if instance.power_state != power_state.RUNNING:
3503                 state = instance.power_state
3504                 running = power_state.RUNNING
3505                 LOG.warning('trying to snapshot a non-running instance: '
3506                             '(state: %(state)s expected: %(running)s)',
3507                             {'state': state, 'running': running},
3508                             instance=instance)
3509 
3510             self._notify_about_instance_usage(
3511                 context, instance, "snapshot.start")
3512             compute_utils.notify_about_instance_snapshot(context, instance,
3513                 self.host, phase=fields.NotificationPhase.START,
3514                 snapshot_image_id=image_id)
3515 
3516             def update_task_state(task_state,
3517                                   expected_state=expected_task_state):
3518                 instance.task_state = task_state
3519                 instance.save(expected_task_state=expected_state)
3520 
3521             with timeutils.StopWatch() as timer:
3522                 self.driver.snapshot(context, instance, image_id,
3523                                      update_task_state)
3524             LOG.info('Took %0.2f seconds to snapshot the instance on '
3525                      'the hypervisor.', timer.elapsed(), instance=instance)
3526 
3527             instance.task_state = None
3528             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3529 
3530             self._notify_about_instance_usage(context, instance,
3531                                               "snapshot.end")
3532             compute_utils.notify_about_instance_snapshot(context, instance,
3533                 self.host, phase=fields.NotificationPhase.END,
3534                 snapshot_image_id=image_id)
3535         except (exception.InstanceNotFound,
3536                 exception.UnexpectedDeletingTaskStateError):
3537             # the instance got deleted during the snapshot
3538             # Quickly bail out of here
3539             msg = 'Instance disappeared during snapshot'
3540             LOG.debug(msg, instance=instance)
3541             try:
3542                 image = self.image_api.get(context, image_id)
3543                 if image['status'] != 'active':
3544                     self.image_api.delete(context, image_id)
3545             except exception.ImageNotFound:
3546                 LOG.debug('Image not found during clean up %s', image_id)
3547             except Exception:
3548                 LOG.warning("Error while trying to clean up image %s",
3549                             image_id, instance=instance)
3550         except exception.ImageNotFound:
3551             instance.task_state = None
3552             instance.save()
3553             LOG.warning("Image not found during snapshot", instance=instance)
3554 
3555     def _post_interrupted_snapshot_cleanup(self, context, instance):
3556         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3557 
3558     @messaging.expected_exceptions(NotImplementedError)
3559     @wrap_exception()
3560     def volume_snapshot_create(self, context, instance, volume_id,
3561                                create_info):
3562         self.driver.volume_snapshot_create(context, instance, volume_id,
3563                                            create_info)
3564 
3565     @messaging.expected_exceptions(NotImplementedError)
3566     @wrap_exception()
3567     def volume_snapshot_delete(self, context, instance, volume_id,
3568                                snapshot_id, delete_info):
3569         self.driver.volume_snapshot_delete(context, instance, volume_id,
3570                                            snapshot_id, delete_info)
3571 
3572     @wrap_instance_fault
3573     def _rotate_backups(self, context, instance, backup_type, rotation):
3574         """Delete excess backups associated to an instance.
3575 
3576         Instances are allowed a fixed number of backups (the rotation number);
3577         this method deletes the oldest backups that exceed the rotation
3578         threshold.
3579 
3580         :param context: security context
3581         :param instance: Instance dict
3582         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3583         :param rotation: int representing how many backups to keep around;
3584             None if rotation shouldn't be used (as in the case of snapshots)
3585         """
3586         filters = {'property-image_type': 'backup',
3587                    'property-backup_type': backup_type,
3588                    'property-instance_uuid': instance.uuid}
3589 
3590         images = self.image_api.get_all(context, filters=filters,
3591                                         sort_key='created_at', sort_dir='desc')
3592         num_images = len(images)
3593         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3594                   {'num_images': num_images, 'rotation': rotation},
3595                   instance=instance)
3596 
3597         if num_images > rotation:
3598             # NOTE(sirp): this deletes all backups that exceed the rotation
3599             # limit
3600             excess = len(images) - rotation
3601             LOG.debug("Rotating out %d backups", excess,
3602                       instance=instance)
3603             for i in range(excess):
3604                 image = images.pop()
3605                 image_id = image['id']
3606                 LOG.debug("Deleting image %s", image_id,
3607                           instance=instance)
3608                 try:
3609                     self.image_api.delete(context, image_id)
3610                 except exception.ImageNotFound:
3611                     LOG.info("Failed to find image %(image_id)s to "
3612                              "delete", {'image_id': image_id},
3613                              instance=instance)
3614                 except (exception.ImageDeleteConflict, Exception) as exc:
3615                     LOG.info("Failed to delete image %(image_id)s during "
3616                              "deleting excess backups. "
3617                              "Continuing for next image.. %(exc)s",
3618                              {'image_id': image_id, 'exc': exc},
3619                              instance=instance)
3620 
3621     @wrap_exception()
3622     @reverts_task_state
3623     @wrap_instance_event(prefix='compute')
3624     @wrap_instance_fault
3625     def set_admin_password(self, context, instance, new_pass):
3626         """Set the root/admin password for an instance on this host.
3627 
3628         This is generally only called by API password resets after an
3629         image has been built.
3630 
3631         @param context: Nova auth context.
3632         @param instance: Nova instance object.
3633         @param new_pass: The admin password for the instance.
3634         """
3635 
3636         context = context.elevated()
3637         if new_pass is None:
3638             # Generate a random password
3639             new_pass = utils.generate_password()
3640 
3641         current_power_state = self._get_power_state(context, instance)
3642         expected_state = power_state.RUNNING
3643 
3644         if current_power_state != expected_state:
3645             instance.task_state = None
3646             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3647             _msg = _('instance %s is not running') % instance.uuid
3648             raise exception.InstancePasswordSetFailed(
3649                 instance=instance.uuid, reason=_msg)
3650 
3651         try:
3652             self.driver.set_admin_password(instance, new_pass)
3653             LOG.info("Admin password set", instance=instance)
3654             instance.task_state = None
3655             instance.save(
3656                 expected_task_state=task_states.UPDATING_PASSWORD)
3657         except exception.InstanceAgentNotEnabled:
3658             with excutils.save_and_reraise_exception():
3659                 LOG.debug('Guest agent is not enabled for the instance.',
3660                           instance=instance)
3661                 instance.task_state = None
3662                 instance.save(
3663                     expected_task_state=task_states.UPDATING_PASSWORD)
3664         except exception.SetAdminPasswdNotSupported:
3665             with excutils.save_and_reraise_exception():
3666                 LOG.info('set_admin_password is not supported '
3667                          'by this driver or guest instance.',
3668                          instance=instance)
3669                 instance.task_state = None
3670                 instance.save(
3671                     expected_task_state=task_states.UPDATING_PASSWORD)
3672         except NotImplementedError:
3673             LOG.warning('set_admin_password is not implemented '
3674                         'by this driver or guest instance.',
3675                         instance=instance)
3676             instance.task_state = None
3677             instance.save(
3678                 expected_task_state=task_states.UPDATING_PASSWORD)
3679             raise NotImplementedError(_('set_admin_password is not '
3680                                         'implemented by this driver or guest '
3681                                         'instance.'))
3682         except exception.UnexpectedTaskStateError:
3683             # interrupted by another (most likely delete) task
3684             # do not retry
3685             raise
3686         except Exception:
3687             # Catch all here because this could be anything.
3688             LOG.exception('set_admin_password failed', instance=instance)
3689             # We create a new exception here so that we won't
3690             # potentially reveal password information to the
3691             # API caller.  The real exception is logged above
3692             _msg = _('error setting admin password')
3693             raise exception.InstancePasswordSetFailed(
3694                 instance=instance.uuid, reason=_msg)
3695 
3696     @wrap_exception()
3697     @reverts_task_state
3698     @wrap_instance_fault
3699     def inject_file(self, context, path, file_contents, instance):
3700         """Write a file to the specified path in an instance on this host."""
3701         # NOTE(russellb) Remove this method, as well as the underlying virt
3702         # driver methods, when the compute rpc interface is bumped to 4.x
3703         # as it is no longer used.
3704         context = context.elevated()
3705         current_power_state = self._get_power_state(context, instance)
3706         expected_state = power_state.RUNNING
3707         if current_power_state != expected_state:
3708             LOG.warning('trying to inject a file into a non-running '
3709                         '(state: %(current_state)s expected: '
3710                         '%(expected_state)s)',
3711                         {'current_state': current_power_state,
3712                          'expected_state': expected_state},
3713                         instance=instance)
3714         LOG.info('injecting file to %s', path, instance=instance)
3715         self.driver.inject_file(instance, path, file_contents)
3716 
3717     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3718         """Determine what image should be used to boot the rescue VM."""
3719         # 1. If rescue_image_ref is passed in, use that for rescue.
3720         # 2. Else, use the base image associated with instance's current image.
3721         #       The idea here is to provide the customer with a rescue
3722         #       environment which they are familiar with.
3723         #       So, if they built their instance off of a Debian image,
3724         #       their rescue VM will also be Debian.
3725         # 3. As a last resort, use instance's current image.
3726         if not rescue_image_ref:
3727             system_meta = utils.instance_sys_meta(instance)
3728             rescue_image_ref = system_meta.get('image_base_image_ref')
3729 
3730         if not rescue_image_ref:
3731             LOG.warning('Unable to find a different image to use for '
3732                         'rescue VM, using instance\'s current image',
3733                         instance=instance)
3734             rescue_image_ref = instance.image_ref
3735 
3736         return objects.ImageMeta.from_image_ref(
3737             context, self.image_api, rescue_image_ref)
3738 
3739     @wrap_exception()
3740     @reverts_task_state
3741     @wrap_instance_event(prefix='compute')
3742     @wrap_instance_fault
3743     def rescue_instance(self, context, instance, rescue_password,
3744                         rescue_image_ref, clean_shutdown):
3745         context = context.elevated()
3746         LOG.info('Rescuing', instance=instance)
3747 
3748         admin_password = (rescue_password if rescue_password else
3749                       utils.generate_password())
3750 
3751         network_info = self.network_api.get_instance_nw_info(context, instance)
3752 
3753         rescue_image_meta = self._get_rescue_image(context, instance,
3754                                                    rescue_image_ref)
3755 
3756         extra_usage_info = {'rescue_image_name':
3757                             self._get_image_name(rescue_image_meta)}
3758         self._notify_about_instance_usage(context, instance,
3759                 "rescue.start", extra_usage_info=extra_usage_info,
3760                 network_info=network_info)
3761         compute_utils.notify_about_instance_rescue_action(
3762             context, instance, self.host, rescue_image_ref,
3763             phase=fields.NotificationPhase.START)
3764 
3765         try:
3766             self._power_off_instance(context, instance, clean_shutdown)
3767 
3768             self.driver.rescue(context, instance,
3769                                network_info,
3770                                rescue_image_meta, admin_password)
3771         except Exception as e:
3772             LOG.exception("Error trying to Rescue Instance",
3773                           instance=instance)
3774             self._set_instance_obj_error_state(context, instance)
3775             raise exception.InstanceNotRescuable(
3776                 instance_id=instance.uuid,
3777                 reason=_("Driver Error: %s") % e)
3778 
3779         compute_utils.notify_usage_exists(self.notifier, context, instance,
3780                                           self.host, current_period=True)
3781 
3782         instance.vm_state = vm_states.RESCUED
3783         instance.task_state = None
3784         instance.power_state = self._get_power_state(context, instance)
3785         instance.launched_at = timeutils.utcnow()
3786         instance.save(expected_task_state=task_states.RESCUING)
3787 
3788         self._notify_about_instance_usage(context, instance,
3789                 "rescue.end", extra_usage_info=extra_usage_info,
3790                 network_info=network_info)
3791         compute_utils.notify_about_instance_rescue_action(
3792             context, instance, self.host, rescue_image_ref,
3793             phase=fields.NotificationPhase.END)
3794 
3795     @wrap_exception()
3796     @reverts_task_state
3797     @wrap_instance_event(prefix='compute')
3798     @wrap_instance_fault
3799     def unrescue_instance(self, context, instance):
3800         context = context.elevated()
3801         LOG.info('Unrescuing', instance=instance)
3802 
3803         network_info = self.network_api.get_instance_nw_info(context, instance)
3804         self._notify_about_instance_usage(context, instance,
3805                 "unrescue.start", network_info=network_info)
3806         compute_utils.notify_about_instance_action(context, instance,
3807             self.host, action=fields.NotificationAction.UNRESCUE,
3808             phase=fields.NotificationPhase.START)
3809 
3810         with self._error_out_instance_on_exception(context, instance):
3811             self.driver.unrescue(instance,
3812                                  network_info)
3813 
3814         instance.vm_state = vm_states.ACTIVE
3815         instance.task_state = None
3816         instance.power_state = self._get_power_state(context, instance)
3817         instance.save(expected_task_state=task_states.UNRESCUING)
3818 
3819         self._notify_about_instance_usage(context,
3820                                           instance,
3821                                           "unrescue.end",
3822                                           network_info=network_info)
3823         compute_utils.notify_about_instance_action(context, instance,
3824             self.host, action=fields.NotificationAction.UNRESCUE,
3825             phase=fields.NotificationPhase.END)
3826 
3827     @wrap_exception()
3828     @wrap_instance_fault
3829     def change_instance_metadata(self, context, diff, instance):
3830         """Update the metadata published to the instance."""
3831         LOG.debug("Changing instance metadata according to %r",
3832                   diff, instance=instance)
3833         self.driver.change_instance_metadata(context, instance, diff)
3834 
3835     @wrap_exception()
3836     @wrap_instance_event(prefix='compute')
3837     @wrap_instance_fault
3838     def confirm_resize(self, context, instance, migration):
3839         """Confirms a migration/resize and deletes the 'old' instance.
3840 
3841         This is called from the API and runs on the source host.
3842 
3843         Nothing needs to happen on the destination host at this point since
3844         the instance is already running there. This routine just cleans up the
3845         source host.
3846         """
3847         @utils.synchronized(instance.uuid)
3848         def do_confirm_resize(context, instance, migration_id):
3849             # NOTE(wangpan): Get the migration status from db, if it has been
3850             #                confirmed, we do nothing and return here
3851             LOG.debug("Going to confirm migration %s", migration_id,
3852                       instance=instance)
3853             try:
3854                 # TODO(russellb) Why are we sending the migration object just
3855                 # to turn around and look it up from the db again?
3856                 migration = objects.Migration.get_by_id(
3857                                     context.elevated(), migration_id)
3858             except exception.MigrationNotFound:
3859                 LOG.error("Migration %s is not found during confirmation",
3860                           migration_id, instance=instance)
3861                 return
3862 
3863             if migration.status == 'confirmed':
3864                 LOG.info("Migration %s is already confirmed",
3865                          migration_id, instance=instance)
3866                 return
3867             elif migration.status not in ('finished', 'confirming'):
3868                 LOG.warning("Unexpected confirmation status '%(status)s' "
3869                             "of migration %(id)s, exit confirmation process",
3870                             {"status": migration.status, "id": migration_id},
3871                             instance=instance)
3872                 return
3873 
3874             # NOTE(wangpan): Get the instance from db, if it has been
3875             #                deleted, we do nothing and return here
3876             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3877             try:
3878                 instance = objects.Instance.get_by_uuid(
3879                         context, instance.uuid,
3880                         expected_attrs=expected_attrs)
3881             except exception.InstanceNotFound:
3882                 LOG.info("Instance is not found during confirmation",
3883                          instance=instance)
3884                 return
3885 
3886             self._confirm_resize(context, instance, migration=migration)
3887 
3888         do_confirm_resize(context, instance, migration.id)
3889 
3890     def _confirm_resize(self, context, instance, migration=None):
3891         """Destroys the source instance."""
3892         self._notify_about_instance_usage(context, instance,
3893                                           "resize.confirm.start")
3894         compute_utils.notify_about_instance_action(context, instance,
3895             self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3896             phase=fields.NotificationPhase.START)
3897 
3898         with self._error_out_instance_on_exception(context, instance):
3899             # NOTE(danms): delete stashed migration information
3900             old_instance_type = instance.old_flavor
3901             instance.old_flavor = None
3902             instance.new_flavor = None
3903             instance.system_metadata.pop('old_vm_state', None)
3904             instance.save()
3905 
3906             # NOTE(tr3buchet): tear down networks on source host
3907             self.network_api.setup_networks_on_host(context, instance,
3908                                migration.source_compute, teardown=True)
3909 
3910             network_info = self.network_api.get_instance_nw_info(context,
3911                                                                  instance)
3912             # TODO(mriedem): Get BDMs here and pass them to the driver.
3913             self.driver.confirm_migration(context, migration, instance,
3914                                           network_info)
3915 
3916             migration.status = 'confirmed'
3917             with migration.obj_as_admin():
3918                 migration.save()
3919 
3920             self.rt.drop_move_claim(context, instance, migration.source_node,
3921                                     old_instance_type, prefix='old_')
3922             self._delete_allocation_after_move(context, instance, migration)
3923             instance.drop_migration_context()
3924 
3925             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3926             # might have manually powered up the instance to confirm the
3927             # resize/migrate, so we need to check the current power state
3928             # on the instance and set the vm_state appropriately. We default
3929             # to ACTIVE because if the power state is not SHUTDOWN, we
3930             # assume _sync_instance_power_state will clean it up.
3931             p_state = instance.power_state
3932             vm_state = None
3933             if p_state == power_state.SHUTDOWN:
3934                 vm_state = vm_states.STOPPED
3935                 LOG.debug("Resized/migrated instance is powered off. "
3936                           "Setting vm_state to '%s'.", vm_state,
3937                           instance=instance)
3938             else:
3939                 vm_state = vm_states.ACTIVE
3940 
3941             instance.vm_state = vm_state
3942             instance.task_state = None
3943             instance.save(expected_task_state=[None, task_states.DELETING,
3944                                                task_states.SOFT_DELETING])
3945 
3946             self._notify_about_instance_usage(
3947                 context, instance, "resize.confirm.end",
3948                 network_info=network_info)
3949             compute_utils.notify_about_instance_action(context, instance,
3950                    self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3951                    phase=fields.NotificationPhase.END)
3952 
3953     def _delete_allocation_after_move(self, context, instance, migration):
3954         """Deletes resource allocations held by the migration record against
3955         the source compute node resource provider after a confirmed cold /
3956         successful live migration.
3957         """
3958         try:
3959             # NOTE(danms): We're finishing on the source node, so try
3960             # to delete the allocation based on the migration uuid
3961             self.reportclient.delete_allocation_for_instance(
3962                 context, migration.uuid)
3963         except exception.AllocationDeleteFailed:
3964             LOG.error('Deleting allocation in placement for migration '
3965                       '%(migration_uuid)s failed. The instance '
3966                       '%(instance_uuid)s will be put to ERROR state '
3967                       'but the allocation held by the migration is '
3968                       'leaked.',
3969                       {'instance_uuid': instance.uuid,
3970                        'migration_uuid': migration.uuid})
3971             raise
3972 
3973     @wrap_exception()
3974     @reverts_task_state
3975     @wrap_instance_event(prefix='compute')
3976     @errors_out_migration
3977     @wrap_instance_fault
3978     def revert_resize(self, context, instance, migration):
3979         """Destroys the new instance on the destination machine.
3980 
3981         Reverts the model changes, and powers on the old instance on the
3982         source machine.
3983 
3984         """
3985         # NOTE(comstud): A revert_resize is essentially a resize back to
3986         # the old size, so we need to send a usage event here.
3987         compute_utils.notify_usage_exists(self.notifier, context, instance,
3988                                           self.host, current_period=True)
3989 
3990         with self._error_out_instance_on_exception(context, instance):
3991             # NOTE(tr3buchet): tear down networks on destination host
3992             self.network_api.setup_networks_on_host(context, instance,
3993                                                     teardown=True)
3994 
3995             migration_p = obj_base.obj_to_primitive(migration)
3996             self.network_api.migrate_instance_start(context,
3997                                                     instance,
3998                                                     migration_p)
3999 
4000             network_info = self.network_api.get_instance_nw_info(context,
4001                                                                  instance)
4002             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4003                     context, instance.uuid)
4004             block_device_info = self._get_instance_block_device_info(
4005                                 context, instance, bdms=bdms)
4006 
4007             destroy_disks = not self._is_instance_storage_shared(
4008                 context, instance, host=migration.source_compute)
4009             self.driver.destroy(context, instance, network_info,
4010                                 block_device_info, destroy_disks)
4011 
4012             self._terminate_volume_connections(context, instance, bdms)
4013 
4014             migration.status = 'reverted'
4015             with migration.obj_as_admin():
4016                 migration.save()
4017 
4018             # NOTE(ndipanov): We need to do this here because dropping the
4019             # claim means we lose the migration_context data. We really should
4020             # fix this by moving the drop_move_claim call to the
4021             # finish_revert_resize method as this is racy (revert is dropped,
4022             # but instance resources will be tracked with the new flavor until
4023             # it gets rolled back in finish_revert_resize, which is
4024             # potentially wrong for a period of time).
4025             instance.revert_migration_context()
4026             instance.save()
4027 
4028             self.rt.drop_move_claim(context, instance, instance.node)
4029 
4030             # RPC cast back to the source host to finish the revert there.
4031             self.compute_rpcapi.finish_revert_resize(context, instance,
4032                     migration, migration.source_compute)
4033 
4034     @wrap_exception()
4035     @reverts_task_state
4036     @wrap_instance_event(prefix='compute')
4037     @errors_out_migration
4038     @wrap_instance_fault
4039     def finish_revert_resize(self, context, instance, migration):
4040         """Finishes the second half of reverting a resize on the source host.
4041 
4042         Bring the original source instance state back (active/shutoff) and
4043         revert the resized attributes in the database.
4044 
4045         """
4046         with self._error_out_instance_on_exception(context, instance):
4047             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4048                 context, instance.uuid)
4049             self._notify_about_instance_usage(
4050                     context, instance, "resize.revert.start")
4051             compute_utils.notify_about_instance_action(context, instance,
4052                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4053                     phase=fields.NotificationPhase.START, bdms=bdms)
4054 
4055             # NOTE(mriedem): delete stashed old_vm_state information; we
4056             # default to ACTIVE for backwards compatibility if old_vm_state
4057             # is not set
4058             old_vm_state = instance.system_metadata.pop('old_vm_state',
4059                                                         vm_states.ACTIVE)
4060 
4061             self._set_instance_info(instance, instance.old_flavor)
4062             instance.old_flavor = None
4063             instance.new_flavor = None
4064             instance.host = migration.source_compute
4065             instance.node = migration.source_node
4066             instance.save()
4067 
4068             try:
4069                 self._revert_allocation(context, instance, migration)
4070             except exception.AllocationMoveFailed:
4071                 LOG.error('Reverting allocation in placement for migration '
4072                           '%(migration_uuid)s failed. The instance '
4073                           '%(instance_uuid)s will be put into ERROR state but '
4074                           'the allocation held by the migration is leaked.',
4075                           {'instance_uuid': instance.uuid,
4076                            'migration_uuid': migration.uuid})
4077                 raise
4078 
4079             self.network_api.setup_networks_on_host(context, instance,
4080                                                     migration.source_compute)
4081             migration_p = obj_base.obj_to_primitive(migration)
4082             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
4083             # source host temporarily. "network_api.migrate_instance_finish"
4084             # will setup the network for the instance on the destination host.
4085             # For revert resize, the instance will back to the source host, the
4086             # setup of the network for instance should be on the source host.
4087             # So set the migration_p['dest_compute'] to source host at here.
4088             migration_p['dest_compute'] = migration.source_compute
4089             self.network_api.migrate_instance_finish(context,
4090                                                      instance,
4091                                                      migration_p)
4092             network_info = self.network_api.get_instance_nw_info(context,
4093                                                                  instance)
4094 
4095             # revert_resize deleted any volume attachments for the instance
4096             # and created new ones to be used on this host, but we
4097             # have to update those attachments with the host connector so the
4098             # BDM.connection_info will get set in the call to
4099             # _get_instance_block_device_info below with refresh_conn_info=True
4100             # and then the volumes can be re-connected via the driver on this
4101             # host.
4102             self._update_volume_attachments(context, instance, bdms)
4103 
4104             block_device_info = self._get_instance_block_device_info(
4105                     context, instance, refresh_conn_info=True, bdms=bdms)
4106 
4107             power_on = old_vm_state != vm_states.STOPPED
4108             self.driver.finish_revert_migration(context, instance,
4109                                        network_info,
4110                                        block_device_info, power_on)
4111 
4112             instance.drop_migration_context()
4113             instance.launched_at = timeutils.utcnow()
4114             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
4115 
4116             # Complete any volume attachments so the volumes are in-use.
4117             self._complete_volume_attachments(context, bdms)
4118 
4119             # if the original vm state was STOPPED, set it back to STOPPED
4120             LOG.info("Updating instance to original state: '%s'",
4121                      old_vm_state, instance=instance)
4122             if power_on:
4123                 instance.vm_state = vm_states.ACTIVE
4124                 instance.task_state = None
4125                 instance.save()
4126             else:
4127                 instance.task_state = task_states.POWERING_OFF
4128                 instance.save()
4129                 self.stop_instance(context, instance=instance,
4130                                    clean_shutdown=True)
4131 
4132             self._notify_about_instance_usage(
4133                     context, instance, "resize.revert.end")
4134             compute_utils.notify_about_instance_action(context, instance,
4135                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4136                     phase=fields.NotificationPhase.END, bdms=bdms)
4137 
4138     def _revert_allocation(self, context, instance, migration):
4139         """Revert an allocation that is held by migration to our instance."""
4140 
4141         # Fetch the original allocation that the instance had on the source
4142         # node, which are now held by the migration
4143         orig_alloc = self.reportclient.get_allocations_for_consumer(
4144             context, migration.uuid)
4145         if not orig_alloc:
4146             LOG.error('Did not find resource allocations for migration '
4147                       '%s on source node %s. Unable to revert source node '
4148                       'allocations back to the instance.',
4149                       migration.uuid, migration.source_node, instance=instance)
4150             return False
4151 
4152         if len(orig_alloc) > 1:
4153             # NOTE(danms): This may change later if we have other allocations
4154             # against other providers that need to be held by the migration
4155             # as well. Perhaps something like shared storage resources that
4156             # will actually be duplicated during a resize type operation.
4157             LOG.error('Migration %(mig)s has allocations against '
4158                       'more than one provider %(rps)s. This should not be '
4159                       'possible, but reverting it anyway.',
4160                       {'mig': migration.uuid,
4161                        'rps': ','.join(orig_alloc.keys())},
4162                       instance=instance)
4163 
4164         # We only have a claim against one provider, it is the source node
4165         cn_uuid = list(orig_alloc.keys())[0]
4166 
4167         # FIXME(danms): This method is flawed in that it asssumes allocations
4168         # against only one provider. So, this may overwite allocations against
4169         # a shared provider, if we had one.
4170         LOG.info('Swapping old allocation on %(node)s held by migration '
4171                  '%(mig)s for instance',
4172                  {'node': cn_uuid, 'mig': migration.uuid},
4173                  instance=instance)
4174         # TODO(cdent): Should we be doing anything with return values here?
4175         self.reportclient.move_allocations(context, migration.uuid,
4176                                            instance.uuid)
4177         return True
4178 
4179     def _prep_resize(self, context, image, instance, instance_type,
4180                      filter_properties, node, migration, clean_shutdown=True):
4181 
4182         if not filter_properties:
4183             filter_properties = {}
4184 
4185         if not instance.host:
4186             self._set_instance_obj_error_state(context, instance)
4187             msg = _('Instance has no source host')
4188             raise exception.MigrationError(reason=msg)
4189 
4190         same_host = instance.host == self.host
4191         # if the flavor IDs match, it's migrate; otherwise resize
4192         if same_host and instance_type.id == instance['instance_type_id']:
4193             # check driver whether support migrate to same host
4194             if not self.driver.capabilities.get(
4195                     'supports_migrate_to_same_host', False):
4196                 raise exception.UnableToMigrateToSelf(
4197                     instance_id=instance.uuid, host=self.host)
4198 
4199         # NOTE(danms): Stash the new instance_type to avoid having to
4200         # look it up in the database later
4201         instance.new_flavor = instance_type
4202         # NOTE(mriedem): Stash the old vm_state so we can set the
4203         # resized/reverted instance back to the same state later.
4204         vm_state = instance.vm_state
4205         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4206         instance.system_metadata['old_vm_state'] = vm_state
4207         instance.save()
4208 
4209         limits = filter_properties.get('limits', {})
4210         with self.rt.resize_claim(context, instance, instance_type, node,
4211                                   migration, image_meta=image,
4212                                   limits=limits) as claim:
4213             LOG.info('Migrating', instance=instance)
4214             # RPC cast to the source host to start the actual resize/migration.
4215             self.compute_rpcapi.resize_instance(
4216                     context, instance, claim.migration, image,
4217                     instance_type, clean_shutdown)
4218 
4219     def _send_prep_resize_notifications(
4220             self, context, instance, phase, flavor):
4221         """Send "resize.prep.*" notifications.
4222 
4223         :param context: nova auth request context
4224         :param instance: The instance being resized
4225         :param phase: The phase of the action (NotificationPhase enum)
4226         :param flavor: The (new) flavor for the resize (same as existing
4227             instance.flavor for a cold migration)
4228         """
4229         # Only send notify_usage_exists if it's the "start" phase.
4230         if phase == fields.NotificationPhase.START:
4231             compute_utils.notify_usage_exists(
4232                 self.notifier, context, instance, self.host,
4233                 current_period=True)
4234 
4235         # Send extra usage info about the flavor if it's the "end" phase for
4236         # the legacy unversioned notification.
4237         extra_usage_info = None
4238         if phase == fields.NotificationPhase.END:
4239             extra_usage_info = dict(
4240                 new_instance_type=flavor.name,
4241                 new_instance_type_id=flavor.id)
4242         self._notify_about_instance_usage(
4243             context, instance, "resize.prep.%s" % phase,
4244             extra_usage_info=extra_usage_info)
4245 
4246         # Send the versioned notification.
4247         compute_utils.notify_about_resize_prep_instance(
4248             context, instance, self.host, phase, flavor)
4249 
4250     @wrap_exception()
4251     @reverts_task_state
4252     @wrap_instance_event(prefix='compute')
4253     @wrap_instance_fault
4254     def prep_resize(self, context, image, instance, instance_type,
4255                     request_spec, filter_properties, node,
4256                     clean_shutdown, migration, host_list):
4257         """Initiates the process of moving a running instance to another host.
4258 
4259         Possibly changes the VCPU, RAM and disk size in the process.
4260 
4261         This is initiated from conductor and runs on the destination host.
4262 
4263         The main purpose of this method is performing some checks on the
4264         destination host and making a claim for resources. If the claim fails
4265         then a reschedule to another host may be attempted which involves
4266         calling back to conductor to start the process over again.
4267         """
4268         if node is None:
4269             node = self._get_nodename(instance, refresh=True)
4270 
4271         with self._error_out_instance_on_exception(context, instance), \
4272                  errors_out_migration_ctxt(migration):
4273             self._send_prep_resize_notifications(
4274                 context, instance, fields.NotificationPhase.START,
4275                 instance_type)
4276             try:
4277                 self._prep_resize(context, image, instance,
4278                                   instance_type, filter_properties,
4279                                   node, migration, clean_shutdown)
4280             except Exception:
4281                 # Since we hit a failure, we're either rescheduling or dead
4282                 # and either way we need to cleanup any allocations created
4283                 # by the scheduler for the destination node.
4284                 self._revert_allocation(context, instance, migration)
4285                 # try to re-schedule the resize elsewhere:
4286                 exc_info = sys.exc_info()
4287                 self._reschedule_resize_or_reraise(context, instance,
4288                         exc_info, instance_type, request_spec,
4289                         filter_properties, host_list)
4290             finally:
4291                 self._send_prep_resize_notifications(
4292                     context, instance, fields.NotificationPhase.END,
4293                     instance_type)
4294 
4295     def _reschedule_resize_or_reraise(self, context, instance, exc_info,
4296             instance_type, request_spec, filter_properties, host_list):
4297         """Try to re-schedule the resize or re-raise the original error to
4298         error out the instance.
4299         """
4300         if not filter_properties:
4301             filter_properties = {}
4302 
4303         rescheduled = False
4304         instance_uuid = instance.uuid
4305 
4306         try:
4307             reschedule_method = self.compute_task_api.resize_instance
4308             scheduler_hint = dict(filter_properties=filter_properties)
4309             method_args = (instance, None, scheduler_hint, instance_type)
4310             task_state = task_states.RESIZE_PREP
4311 
4312             rescheduled = self._reschedule(context, request_spec,
4313                     filter_properties, instance, reschedule_method,
4314                     method_args, task_state, exc_info, host_list=host_list)
4315         except Exception as error:
4316             rescheduled = False
4317             LOG.exception("Error trying to reschedule",
4318                           instance_uuid=instance_uuid)
4319             compute_utils.add_instance_fault_from_exc(context,
4320                     instance, error,
4321                     exc_info=sys.exc_info())
4322             self._notify_about_instance_usage(context, instance,
4323                     'resize.error', fault=error)
4324             compute_utils.notify_about_instance_action(
4325                 context, instance, self.host,
4326                 action=fields.NotificationAction.RESIZE,
4327                 phase=fields.NotificationPhase.ERROR,
4328                 exception=error,
4329                 tb=','.join(traceback.format_exception(*exc_info)))
4330         if rescheduled:
4331             self._log_original_error(exc_info, instance_uuid)
4332             compute_utils.add_instance_fault_from_exc(context,
4333                     instance, exc_info[1], exc_info=exc_info)
4334             self._notify_about_instance_usage(context, instance,
4335                     'resize.error', fault=exc_info[1])
4336             compute_utils.notify_about_instance_action(
4337                 context, instance, self.host,
4338                 action=fields.NotificationAction.RESIZE,
4339                 phase=fields.NotificationPhase.ERROR,
4340                 exception=exc_info[1],
4341                 tb=','.join(traceback.format_exception(*exc_info)))
4342         else:
4343             # not re-scheduling
4344             six.reraise(*exc_info)
4345 
4346     @wrap_exception()
4347     @reverts_task_state
4348     @wrap_instance_event(prefix='compute')
4349     @wrap_instance_fault
4350     def resize_instance(self, context, instance, image,
4351                         migration, instance_type, clean_shutdown):
4352         """Starts the migration of a running instance to another host.
4353 
4354         This is initiated from the destination host's ``prep_resize`` routine
4355         and runs on the source host.
4356         """
4357         try:
4358             self._resize_instance(context, instance, image, migration,
4359                                   instance_type, clean_shutdown)
4360         except Exception:
4361             with excutils.save_and_reraise_exception():
4362                 self._revert_allocation(context, instance, migration)
4363 
4364     def _resize_instance(self, context, instance, image,
4365                          migration, instance_type, clean_shutdown):
4366         with self._error_out_instance_on_exception(context, instance), \
4367              errors_out_migration_ctxt(migration):
4368             network_info = self.network_api.get_instance_nw_info(context,
4369                                                                  instance)
4370 
4371             migration.status = 'migrating'
4372             with migration.obj_as_admin():
4373                 migration.save()
4374 
4375             instance.task_state = task_states.RESIZE_MIGRATING
4376             instance.save(expected_task_state=task_states.RESIZE_PREP)
4377 
4378             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4379                     context, instance.uuid)
4380             self._send_resize_instance_notifications(
4381                 context, instance, bdms, network_info,
4382                 fields.NotificationPhase.START)
4383 
4384             block_device_info = self._get_instance_block_device_info(
4385                                 context, instance, bdms=bdms)
4386 
4387             timeout, retry_interval = self._get_power_off_values(context,
4388                                             instance, clean_shutdown)
4389             disk_info = self.driver.migrate_disk_and_power_off(
4390                     context, instance, migration.dest_host,
4391                     instance_type, network_info,
4392                     block_device_info,
4393                     timeout, retry_interval)
4394 
4395             self._terminate_volume_connections(context, instance, bdms)
4396 
4397             migration_p = obj_base.obj_to_primitive(migration)
4398             self.network_api.migrate_instance_start(context,
4399                                                     instance,
4400                                                     migration_p)
4401 
4402             migration.status = 'post-migrating'
4403             with migration.obj_as_admin():
4404                 migration.save()
4405 
4406             instance.host = migration.dest_compute
4407             instance.node = migration.dest_node
4408             instance.task_state = task_states.RESIZE_MIGRATED
4409             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4410 
4411             # RPC cast to the destination host to finish the resize/migration.
4412             self.compute_rpcapi.finish_resize(context, instance,
4413                     migration, image, disk_info, migration.dest_compute)
4414 
4415         self._send_resize_instance_notifications(
4416             context, instance, bdms, network_info,
4417             fields.NotificationPhase.END)
4418         self.instance_events.clear_events_for_instance(instance)
4419 
4420     def _send_resize_instance_notifications(
4421             self, context, instance, bdms, network_info, phase):
4422         """Send "resize.(start|end)" notifications.
4423 
4424         :param context: nova auth request context
4425         :param instance: The instance being resized
4426         :param bdms: BlockDeviceMappingList for the BDMs associated with the
4427             instance
4428         :param network_info: NetworkInfo for the instance info cache of ports
4429         :param phase: The phase of the action (NotificationPhase enum, either
4430             ``start`` or ``end``)
4431         """
4432         action = fields.NotificationAction.RESIZE
4433         # Send the legacy unversioned notification.
4434         self._notify_about_instance_usage(
4435             context, instance, "%s.%s" % (action, phase),
4436             network_info=network_info)
4437         # Send the versioned notification.
4438         compute_utils.notify_about_instance_action(
4439             context, instance, self.host, action=action, phase=phase,
4440             bdms=bdms)
4441 
4442     def _terminate_volume_connections(self, context, instance, bdms):
4443         connector = None
4444         for bdm in bdms:
4445             if bdm.is_volume:
4446                 if bdm.attachment_id:
4447                     # NOTE(jdg): So here's the thing, the idea behind the new
4448                     # attach API's was to have a new code fork/path that we
4449                     # followed, we're not going to do that so we have to do
4450                     # some extra work in here to make it *behave* just like the
4451                     # old code. Cinder doesn't allow disconnect/reconnect (you
4452                     # just delete the attachment and get a new one)
4453                     # attachments in the new attach code so we have to do
4454                     # a delete and create without a connector (reserve),
4455                     # in other words, beware
4456                     attachment_id = self.volume_api.attachment_create(
4457                         context, bdm.volume_id, instance.uuid)['id']
4458                     self.volume_api.attachment_delete(context,
4459                                                       bdm.attachment_id)
4460                     bdm.attachment_id = attachment_id
4461                     bdm.save()
4462 
4463                 else:
4464                     if connector is None:
4465                         connector = self.driver.get_volume_connector(instance)
4466                     self.volume_api.terminate_connection(context,
4467                                                          bdm.volume_id,
4468                                                          connector)
4469 
4470     @staticmethod
4471     def _set_instance_info(instance, instance_type):
4472         instance.instance_type_id = instance_type.id
4473         instance.memory_mb = instance_type.memory_mb
4474         instance.vcpus = instance_type.vcpus
4475         instance.root_gb = instance_type.root_gb
4476         instance.ephemeral_gb = instance_type.ephemeral_gb
4477         instance.flavor = instance_type
4478 
4479     def _update_volume_attachments(self, context, instance, bdms):
4480         """Updates volume attachments using the virt driver host connector.
4481 
4482         :param context: nova.context.RequestContext - user request context
4483         :param instance: nova.objects.Instance
4484         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4485                      device mappings for the given instance
4486         """
4487         if bdms:
4488             connector = None
4489             for bdm in bdms:
4490                 if bdm.is_volume and bdm.attachment_id:
4491                     if connector is None:
4492                         connector = self.driver.get_volume_connector(instance)
4493                     self.volume_api.attachment_update(
4494                         context, bdm.attachment_id, connector, bdm.device_name)
4495 
4496     def _complete_volume_attachments(self, context, bdms):
4497         """Completes volume attachments for the instance
4498 
4499         :param context: nova.context.RequestContext - user request context
4500         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4501                      device mappings for the given instance
4502         """
4503         if bdms:
4504             for bdm in bdms:
4505                 if bdm.is_volume and bdm.attachment_id:
4506                     self.volume_api.attachment_complete(
4507                         context, bdm.attachment_id)
4508 
4509     def _finish_resize(self, context, instance, migration, disk_info,
4510                        image_meta, bdms):
4511         resize_instance = False
4512         old_instance_type_id = migration['old_instance_type_id']
4513         new_instance_type_id = migration['new_instance_type_id']
4514         old_instance_type = instance.get_flavor()
4515         # NOTE(mriedem): Get the old_vm_state so we know if we should
4516         # power on the instance. If old_vm_state is not set we need to default
4517         # to ACTIVE for backwards compatibility
4518         old_vm_state = instance.system_metadata.get('old_vm_state',
4519                                                     vm_states.ACTIVE)
4520         instance.old_flavor = old_instance_type
4521 
4522         if old_instance_type_id != new_instance_type_id:
4523             instance_type = instance.get_flavor('new')
4524             self._set_instance_info(instance, instance_type)
4525             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4526                 if old_instance_type[key] != instance_type[key]:
4527                     resize_instance = True
4528                     break
4529         instance.apply_migration_context()
4530 
4531         # NOTE(tr3buchet): setup networks on destination host
4532         self.network_api.setup_networks_on_host(context, instance,
4533                                                 migration['dest_compute'])
4534 
4535         migration_p = obj_base.obj_to_primitive(migration)
4536         self.network_api.migrate_instance_finish(context,
4537                                                  instance,
4538                                                  migration_p)
4539 
4540         network_info = self.network_api.get_instance_nw_info(context, instance)
4541 
4542         instance.task_state = task_states.RESIZE_FINISH
4543         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4544 
4545         self._notify_about_instance_usage(
4546             context, instance, "finish_resize.start",
4547             network_info=network_info)
4548         compute_utils.notify_about_instance_action(context, instance,
4549                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4550                phase=fields.NotificationPhase.START, bdms=bdms)
4551 
4552         # We need to update any volume attachments using the destination
4553         # host connector so that we can update the BDM.connection_info
4554         # before calling driver.finish_migration otherwise the driver
4555         # won't know how to connect the volumes to this host.
4556         # Note that _get_instance_block_device_info with
4557         # refresh_conn_info=True will update the BDM.connection_info value
4558         # in the database so we must do this before calling that method.
4559         self._update_volume_attachments(context, instance, bdms)
4560 
4561         block_device_info = self._get_instance_block_device_info(
4562             context, instance, refresh_conn_info=True, bdms=bdms)
4563 
4564         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4565         # automatically power on the instance after it's migrated
4566         power_on = old_vm_state != vm_states.STOPPED
4567 
4568         try:
4569             self.driver.finish_migration(context, migration, instance,
4570                                          disk_info,
4571                                          network_info,
4572                                          image_meta, resize_instance,
4573                                          block_device_info, power_on)
4574         except Exception:
4575             with excutils.save_and_reraise_exception():
4576                 if old_instance_type_id != new_instance_type_id:
4577                     self._set_instance_info(instance,
4578                                             old_instance_type)
4579 
4580         # Now complete any volume attachments that were previously updated.
4581         self._complete_volume_attachments(context, bdms)
4582 
4583         migration.status = 'finished'
4584         with migration.obj_as_admin():
4585             migration.save()
4586 
4587         instance.vm_state = vm_states.RESIZED
4588         instance.task_state = None
4589         instance.launched_at = timeutils.utcnow()
4590         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4591 
4592         return network_info
4593 
4594     @wrap_exception()
4595     @reverts_task_state
4596     @wrap_instance_event(prefix='compute')
4597     @wrap_instance_fault
4598     def finish_resize(self, context, disk_info, image, instance,
4599                       migration):
4600         """Completes the migration process.
4601 
4602         Sets up the newly transferred disk and turns on the instance at its
4603         new host machine.
4604 
4605         """
4606         try:
4607             self._finish_resize_helper(context, disk_info, image, instance,
4608                                        migration)
4609         except Exception:
4610             with excutils.save_and_reraise_exception():
4611                 self._revert_allocation(context, instance, migration)
4612 
4613     def _finish_resize_helper(self, context, disk_info, image, instance,
4614                               migration):
4615         """Completes the migration process.
4616 
4617         The caller must revert the instance's allocations if the migration
4618         process failed.
4619         """
4620         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4621             context, instance.uuid)
4622 
4623         with self._error_out_instance_on_exception(context, instance), \
4624              errors_out_migration_ctxt(migration):
4625             image_meta = objects.ImageMeta.from_dict(image)
4626             network_info = self._finish_resize(context, instance, migration,
4627                                                disk_info, image_meta, bdms)
4628 
4629         # TODO(melwitt): We should clean up instance console tokens here. The
4630         # instance is on a new host and will need to establish a new console
4631         # connection.
4632         self._update_scheduler_instance_info(context, instance)
4633         self._notify_about_instance_usage(
4634             context, instance, "finish_resize.end",
4635             network_info=network_info)
4636         compute_utils.notify_about_instance_action(context, instance,
4637                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4638                phase=fields.NotificationPhase.END, bdms=bdms)
4639 
4640     @wrap_exception()
4641     @wrap_instance_fault
4642     def add_fixed_ip_to_instance(self, context, network_id, instance):
4643         """Calls network_api to add new fixed_ip to instance
4644         then injects the new network info and resets instance networking.
4645 
4646         """
4647         self._notify_about_instance_usage(
4648                 context, instance, "create_ip.start")
4649 
4650         network_info = self.network_api.add_fixed_ip_to_instance(context,
4651                                                                  instance,
4652                                                                  network_id)
4653         self._inject_network_info(context, instance, network_info)
4654         self.reset_network(context, instance)
4655 
4656         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4657         instance.updated_at = timeutils.utcnow()
4658         instance.save()
4659 
4660         self._notify_about_instance_usage(
4661             context, instance, "create_ip.end", network_info=network_info)
4662 
4663     @wrap_exception()
4664     @wrap_instance_fault
4665     def remove_fixed_ip_from_instance(self, context, address, instance):
4666         """Calls network_api to remove existing fixed_ip from instance
4667         by injecting the altered network info and resetting
4668         instance networking.
4669         """
4670         self._notify_about_instance_usage(
4671                 context, instance, "delete_ip.start")
4672 
4673         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4674                                                                       instance,
4675                                                                       address)
4676         self._inject_network_info(context, instance, network_info)
4677         self.reset_network(context, instance)
4678 
4679         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4680         instance.updated_at = timeutils.utcnow()
4681         instance.save()
4682 
4683         self._notify_about_instance_usage(
4684             context, instance, "delete_ip.end", network_info=network_info)
4685 
4686     @wrap_exception()
4687     @reverts_task_state
4688     @wrap_instance_event(prefix='compute')
4689     @wrap_instance_fault
4690     def pause_instance(self, context, instance):
4691         """Pause an instance on this host."""
4692         context = context.elevated()
4693         LOG.info('Pausing', instance=instance)
4694         self._notify_about_instance_usage(context, instance, 'pause.start')
4695         compute_utils.notify_about_instance_action(context, instance,
4696                self.host, action=fields.NotificationAction.PAUSE,
4697                phase=fields.NotificationPhase.START)
4698         self.driver.pause(instance)
4699         instance.power_state = self._get_power_state(context, instance)
4700         instance.vm_state = vm_states.PAUSED
4701         instance.task_state = None
4702         instance.save(expected_task_state=task_states.PAUSING)
4703         self._notify_about_instance_usage(context, instance, 'pause.end')
4704         compute_utils.notify_about_instance_action(context, instance,
4705                self.host, action=fields.NotificationAction.PAUSE,
4706                phase=fields.NotificationPhase.END)
4707 
4708     @wrap_exception()
4709     @reverts_task_state
4710     @wrap_instance_event(prefix='compute')
4711     @wrap_instance_fault
4712     def unpause_instance(self, context, instance):
4713         """Unpause a paused instance on this host."""
4714         context = context.elevated()
4715         LOG.info('Unpausing', instance=instance)
4716         self._notify_about_instance_usage(context, instance, 'unpause.start')
4717         compute_utils.notify_about_instance_action(context, instance,
4718             self.host, action=fields.NotificationAction.UNPAUSE,
4719             phase=fields.NotificationPhase.START)
4720         self.driver.unpause(instance)
4721         instance.power_state = self._get_power_state(context, instance)
4722         instance.vm_state = vm_states.ACTIVE
4723         instance.task_state = None
4724         instance.save(expected_task_state=task_states.UNPAUSING)
4725         self._notify_about_instance_usage(context, instance, 'unpause.end')
4726         compute_utils.notify_about_instance_action(context, instance,
4727             self.host, action=fields.NotificationAction.UNPAUSE,
4728             phase=fields.NotificationPhase.END)
4729 
4730     @wrap_exception()
4731     def host_power_action(self, context, action):
4732         """Reboots, shuts down or powers up the host."""
4733         return self.driver.host_power_action(action)
4734 
4735     @wrap_exception()
4736     def host_maintenance_mode(self, context, host, mode):
4737         """Start/Stop host maintenance window. On start, it triggers
4738         guest VMs evacuation.
4739         """
4740         return self.driver.host_maintenance_mode(host, mode)
4741 
4742     @wrap_exception()
4743     def set_host_enabled(self, context, enabled):
4744         """Sets the specified host's ability to accept new instances."""
4745         return self.driver.set_host_enabled(enabled)
4746 
4747     @wrap_exception()
4748     def get_host_uptime(self, context):
4749         """Returns the result of calling "uptime" on the target host."""
4750         return self.driver.get_host_uptime()
4751 
4752     @wrap_exception()
4753     @wrap_instance_fault
4754     def get_diagnostics(self, context, instance):
4755         """Retrieve diagnostics for an instance on this host."""
4756         current_power_state = self._get_power_state(context, instance)
4757         if current_power_state == power_state.RUNNING:
4758             LOG.info("Retrieving diagnostics", instance=instance)
4759             return self.driver.get_diagnostics(instance)
4760         else:
4761             raise exception.InstanceInvalidState(
4762                 attr='power state',
4763                 instance_uuid=instance.uuid,
4764                 state=power_state.STATE_MAP[instance.power_state],
4765                 method='get_diagnostics')
4766 
4767     @wrap_exception()
4768     @wrap_instance_fault
4769     def get_instance_diagnostics(self, context, instance):
4770         """Retrieve diagnostics for an instance on this host."""
4771         current_power_state = self._get_power_state(context, instance)
4772         if current_power_state == power_state.RUNNING:
4773             LOG.info("Retrieving diagnostics", instance=instance)
4774             return self.driver.get_instance_diagnostics(instance)
4775         else:
4776             raise exception.InstanceInvalidState(
4777                 attr='power state',
4778                 instance_uuid=instance.uuid,
4779                 state=power_state.STATE_MAP[instance.power_state],
4780                 method='get_diagnostics')
4781 
4782     @wrap_exception()
4783     @reverts_task_state
4784     @wrap_instance_event(prefix='compute')
4785     @wrap_instance_fault
4786     def suspend_instance(self, context, instance):
4787         """Suspend the given instance."""
4788         context = context.elevated()
4789 
4790         # Store the old state
4791         instance.system_metadata['old_vm_state'] = instance.vm_state
4792         self._notify_about_instance_usage(context, instance, 'suspend.start')
4793         compute_utils.notify_about_instance_action(context, instance,
4794                 self.host, action=fields.NotificationAction.SUSPEND,
4795                 phase=fields.NotificationPhase.START)
4796         with self._error_out_instance_on_exception(context, instance,
4797              instance_state=instance.vm_state):
4798             self.driver.suspend(context, instance)
4799         instance.power_state = self._get_power_state(context, instance)
4800         instance.vm_state = vm_states.SUSPENDED
4801         instance.task_state = None
4802         instance.save(expected_task_state=task_states.SUSPENDING)
4803         self._notify_about_instance_usage(context, instance, 'suspend.end')
4804         compute_utils.notify_about_instance_action(context, instance,
4805                 self.host, action=fields.NotificationAction.SUSPEND,
4806                 phase=fields.NotificationPhase.END)
4807 
4808     @wrap_exception()
4809     @reverts_task_state
4810     @wrap_instance_event(prefix='compute')
4811     @wrap_instance_fault
4812     def resume_instance(self, context, instance):
4813         """Resume the given suspended instance."""
4814         context = context.elevated()
4815         LOG.info('Resuming', instance=instance)
4816 
4817         self._notify_about_instance_usage(context, instance, 'resume.start')
4818 
4819         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4820             context, instance.uuid)
4821         block_device_info = self._get_instance_block_device_info(
4822             context, instance, bdms=bdms)
4823 
4824         compute_utils.notify_about_instance_action(context, instance,
4825             self.host, action=fields.NotificationAction.RESUME,
4826             phase=fields.NotificationPhase.START, bdms=bdms)
4827 
4828         network_info = self.network_api.get_instance_nw_info(context, instance)
4829 
4830         with self._error_out_instance_on_exception(context, instance,
4831              instance_state=instance.vm_state):
4832             self.driver.resume(context, instance, network_info,
4833                                block_device_info)
4834 
4835         instance.power_state = self._get_power_state(context, instance)
4836 
4837         # We default to the ACTIVE state for backwards compatibility
4838         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4839                                                          vm_states.ACTIVE)
4840 
4841         instance.task_state = None
4842         instance.save(expected_task_state=task_states.RESUMING)
4843         self._notify_about_instance_usage(context, instance, 'resume.end')
4844         compute_utils.notify_about_instance_action(context, instance,
4845             self.host, action=fields.NotificationAction.RESUME,
4846             phase=fields.NotificationPhase.END, bdms=bdms)
4847 
4848     @wrap_exception()
4849     @reverts_task_state
4850     @wrap_instance_event(prefix='compute')
4851     @wrap_instance_fault
4852     def shelve_instance(self, context, instance, image_id,
4853                         clean_shutdown):
4854         """Shelve an instance.
4855 
4856         This should be used when you want to take a snapshot of the instance.
4857         It also adds system_metadata that can be used by a periodic task to
4858         offload the shelved instance after a period of time.
4859 
4860         :param context: request context
4861         :param instance: an Instance object
4862         :param image_id: an image id to snapshot to.
4863         :param clean_shutdown: give the GuestOS a chance to stop
4864         """
4865 
4866         @utils.synchronized(instance.uuid)
4867         def do_shelve_instance():
4868             self._shelve_instance(context, instance, image_id, clean_shutdown)
4869         do_shelve_instance()
4870 
4871     def _shelve_instance(self, context, instance, image_id,
4872                          clean_shutdown):
4873         LOG.info('Shelving', instance=instance)
4874         offload = CONF.shelved_offload_time == 0
4875         if offload:
4876             # Get the BDMs early so we can pass them into versioned
4877             # notifications since _shelve_offload_instance needs the
4878             # BDMs anyway.
4879             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4880                 context, instance.uuid)
4881         else:
4882             bdms = None
4883         compute_utils.notify_usage_exists(self.notifier, context, instance,
4884                                           self.host, current_period=True)
4885         self._notify_about_instance_usage(context, instance, 'shelve.start')
4886         compute_utils.notify_about_instance_action(context, instance,
4887                 self.host, action=fields.NotificationAction.SHELVE,
4888                 phase=fields.NotificationPhase.START, bdms=bdms)
4889 
4890         def update_task_state(task_state, expected_state=task_states.SHELVING):
4891             shelving_state_map = {
4892                     task_states.IMAGE_PENDING_UPLOAD:
4893                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4894                     task_states.IMAGE_UPLOADING:
4895                         task_states.SHELVING_IMAGE_UPLOADING,
4896                     task_states.SHELVING: task_states.SHELVING}
4897             task_state = shelving_state_map[task_state]
4898             expected_state = shelving_state_map[expected_state]
4899             instance.task_state = task_state
4900             instance.save(expected_task_state=expected_state)
4901         # Do not attempt a clean shutdown of a paused guest since some
4902         # hypervisors will fail the clean shutdown if the guest is not
4903         # running.
4904         if instance.power_state == power_state.PAUSED:
4905             clean_shutdown = False
4906         self._power_off_instance(context, instance, clean_shutdown)
4907         self.driver.snapshot(context, instance, image_id, update_task_state)
4908 
4909         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4910         instance.system_metadata['shelved_image_id'] = image_id
4911         instance.system_metadata['shelved_host'] = self.host
4912         instance.vm_state = vm_states.SHELVED
4913         instance.task_state = None
4914         if CONF.shelved_offload_time == 0:
4915             instance.task_state = task_states.SHELVING_OFFLOADING
4916         instance.power_state = self._get_power_state(context, instance)
4917         instance.save(expected_task_state=[
4918                 task_states.SHELVING,
4919                 task_states.SHELVING_IMAGE_UPLOADING])
4920 
4921         self._notify_about_instance_usage(context, instance, 'shelve.end')
4922         compute_utils.notify_about_instance_action(context, instance,
4923                 self.host, action=fields.NotificationAction.SHELVE,
4924                 phase=fields.NotificationPhase.END, bdms=bdms)
4925 
4926         if offload:
4927             self._shelve_offload_instance(context, instance,
4928                                           clean_shutdown=False, bdms=bdms)
4929 
4930     @wrap_exception()
4931     @reverts_task_state
4932     @wrap_instance_event(prefix='compute')
4933     @wrap_instance_fault
4934     def shelve_offload_instance(self, context, instance, clean_shutdown):
4935         """Remove a shelved instance from the hypervisor.
4936 
4937         This frees up those resources for use by other instances, but may lead
4938         to slower unshelve times for this instance.  This method is used by
4939         volume backed instances since restoring them doesn't involve the
4940         potentially large download of an image.
4941 
4942         :param context: request context
4943         :param instance: nova.objects.instance.Instance
4944         :param clean_shutdown: give the GuestOS a chance to stop
4945         """
4946 
4947         @utils.synchronized(instance.uuid)
4948         def do_shelve_offload_instance():
4949             self._shelve_offload_instance(context, instance, clean_shutdown)
4950         do_shelve_offload_instance()
4951 
4952     def _shelve_offload_instance(self, context, instance, clean_shutdown,
4953                                  bdms=None):
4954         LOG.info('Shelve offloading', instance=instance)
4955         if bdms is None:
4956             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4957                 context, instance.uuid)
4958         self._notify_about_instance_usage(context, instance,
4959                 'shelve_offload.start')
4960         compute_utils.notify_about_instance_action(context, instance,
4961                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4962                 phase=fields.NotificationPhase.START, bdms=bdms)
4963 
4964         self._power_off_instance(context, instance, clean_shutdown)
4965         current_power_state = self._get_power_state(context, instance)
4966 
4967         self.network_api.cleanup_instance_network_on_host(context, instance,
4968                                                           instance.host)
4969         network_info = self.network_api.get_instance_nw_info(context, instance)
4970 
4971         block_device_info = self._get_instance_block_device_info(context,
4972                                                                  instance,
4973                                                                  bdms=bdms)
4974         self.driver.destroy(context, instance, network_info,
4975                 block_device_info)
4976 
4977         # the instance is going to be removed from the host so we want to
4978         # terminate all the connections with the volume server and the host
4979         self._terminate_volume_connections(context, instance, bdms)
4980 
4981         # Free up the resource allocations in the placement service.
4982         # This should happen *before* the vm_state is changed to
4983         # SHELVED_OFFLOADED in case client-side code is polling the API to
4984         # schedule more instances (or unshelve) once this server is offloaded.
4985         self.rt.delete_allocation_for_shelve_offloaded_instance(context,
4986                                                                 instance)
4987 
4988         instance.power_state = current_power_state
4989         # NOTE(mriedem): The vm_state has to be set before updating the
4990         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4991         # values cannot be nulled out until after updating the resource tracker
4992         # though.
4993         instance.vm_state = vm_states.SHELVED_OFFLOADED
4994         instance.task_state = None
4995         instance.save(expected_task_state=[task_states.SHELVING,
4996                                            task_states.SHELVING_OFFLOADING])
4997 
4998         # NOTE(ndipanov): Free resources from the resource tracker
4999         self._update_resource_tracker(context, instance)
5000 
5001         # NOTE(sfinucan): RPC calls should no longer be attempted against this
5002         # instance, so ensure any calls result in errors
5003         self._nil_out_instance_obj_host_and_node(instance)
5004         instance.save(expected_task_state=None)
5005 
5006         # TODO(melwitt): We should clean up instance console tokens here. The
5007         # instance has no host at this point and will need to establish a new
5008         # console connection in the future after it is unshelved.
5009         self._delete_scheduler_instance_info(context, instance.uuid)
5010         self._notify_about_instance_usage(context, instance,
5011                 'shelve_offload.end')
5012         compute_utils.notify_about_instance_action(context, instance,
5013                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
5014                 phase=fields.NotificationPhase.END, bdms=bdms)
5015 
5016     @wrap_exception()
5017     @reverts_task_state
5018     @wrap_instance_event(prefix='compute')
5019     @wrap_instance_fault
5020     def unshelve_instance(self, context, instance, image,
5021                           filter_properties, node):
5022         """Unshelve the instance.
5023 
5024         :param context: request context
5025         :param instance: a nova.objects.instance.Instance object
5026         :param image: an image to build from.  If None we assume a
5027             volume backed instance.
5028         :param filter_properties: dict containing limits, retry info etc.
5029         :param node: target compute node
5030         """
5031         if filter_properties is None:
5032             filter_properties = {}
5033 
5034         @utils.synchronized(instance.uuid)
5035         def do_unshelve_instance():
5036             self._unshelve_instance(context, instance, image,
5037                                     filter_properties, node)
5038         do_unshelve_instance()
5039 
5040     def _unshelve_instance_key_scrub(self, instance):
5041         """Remove data from the instance that may cause side effects."""
5042         cleaned_keys = dict(
5043                 key_data=instance.key_data,
5044                 auto_disk_config=instance.auto_disk_config)
5045         instance.key_data = None
5046         instance.auto_disk_config = False
5047         return cleaned_keys
5048 
5049     def _unshelve_instance_key_restore(self, instance, keys):
5050         """Restore previously scrubbed keys before saving the instance."""
5051         instance.update(keys)
5052 
5053     def _unshelve_instance(self, context, instance, image, filter_properties,
5054                            node):
5055         LOG.info('Unshelving', instance=instance)
5056         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5057                 context, instance.uuid)
5058 
5059         self._notify_about_instance_usage(context, instance, 'unshelve.start')
5060         compute_utils.notify_about_instance_action(context, instance,
5061                 self.host, action=fields.NotificationAction.UNSHELVE,
5062                 phase=fields.NotificationPhase.START, bdms=bdms)
5063 
5064         instance.task_state = task_states.SPAWNING
5065         instance.save()
5066 
5067         block_device_info = self._prep_block_device(context, instance, bdms)
5068         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
5069 
5070         if node is None:
5071             node = self._get_nodename(instance)
5072 
5073         limits = filter_properties.get('limits', {})
5074 
5075         allocations = self.reportclient.get_allocations_for_consumer(
5076             context, instance.uuid)
5077 
5078         shelved_image_ref = instance.image_ref
5079         if image:
5080             instance.image_ref = image['id']
5081             image_meta = objects.ImageMeta.from_dict(image)
5082         else:
5083             image_meta = objects.ImageMeta.from_dict(
5084                 utils.get_image_from_system_metadata(
5085                     instance.system_metadata))
5086 
5087         self.network_api.setup_instance_network_on_host(context, instance,
5088                                                         self.host)
5089         network_info = self.network_api.get_instance_nw_info(context, instance)
5090         try:
5091             with self.rt.instance_claim(context, instance, node, limits):
5092                 self.driver.spawn(context, instance, image_meta,
5093                                   injected_files=[],
5094                                   admin_password=None,
5095                                   allocations=allocations,
5096                                   network_info=network_info,
5097                                   block_device_info=block_device_info)
5098         except Exception:
5099             with excutils.save_and_reraise_exception(logger=LOG):
5100                 LOG.exception('Instance failed to spawn',
5101                               instance=instance)
5102                 # Cleanup allocations created by the scheduler on this host
5103                 # since we failed to spawn the instance. We do this both if
5104                 # the instance claim failed with ComputeResourcesUnavailable
5105                 # or if we did claim but the spawn failed, because aborting the
5106                 # instance claim will not remove the allocations.
5107                 self.reportclient.delete_allocation_for_instance(context,
5108                                                                  instance.uuid)
5109                 # FIXME: Umm, shouldn't we be rolling back port bindings too?
5110                 self._terminate_volume_connections(context, instance, bdms)
5111                 # The reverts_task_state decorator on unshelve_instance will
5112                 # eventually save these updates.
5113                 self._nil_out_instance_obj_host_and_node(instance)
5114 
5115         if image:
5116             instance.image_ref = shelved_image_ref
5117             self._delete_snapshot_of_shelved_instance(context, instance,
5118                                                       image['id'])
5119 
5120         self._unshelve_instance_key_restore(instance, scrubbed_keys)
5121         self._update_instance_after_spawn(context, instance)
5122         # Delete system_metadata for a shelved instance
5123         compute_utils.remove_shelved_keys_from_system_metadata(instance)
5124 
5125         instance.save(expected_task_state=task_states.SPAWNING)
5126         self._update_scheduler_instance_info(context, instance)
5127         self._notify_about_instance_usage(context, instance, 'unshelve.end')
5128         compute_utils.notify_about_instance_action(context, instance,
5129                 self.host, action=fields.NotificationAction.UNSHELVE,
5130                 phase=fields.NotificationPhase.END, bdms=bdms)
5131 
5132     @messaging.expected_exceptions(NotImplementedError)
5133     @wrap_instance_fault
5134     def reset_network(self, context, instance):
5135         """Reset networking on the given instance."""
5136         LOG.debug('Reset network', instance=instance)
5137         self.driver.reset_network(instance)
5138 
5139     def _inject_network_info(self, context, instance, network_info):
5140         """Inject network info for the given instance."""
5141         LOG.debug('Inject network info', instance=instance)
5142         LOG.debug('network_info to inject: |%s|', network_info,
5143                   instance=instance)
5144 
5145         self.driver.inject_network_info(instance,
5146                                         network_info)
5147 
5148     @wrap_instance_fault
5149     def inject_network_info(self, context, instance):
5150         """Inject network info, but don't return the info."""
5151         network_info = self.network_api.get_instance_nw_info(context, instance)
5152         self._inject_network_info(context, instance, network_info)
5153 
5154     @messaging.expected_exceptions(NotImplementedError,
5155                                    exception.ConsoleNotAvailable,
5156                                    exception.InstanceNotFound)
5157     @wrap_exception()
5158     @wrap_instance_fault
5159     def get_console_output(self, context, instance, tail_length):
5160         """Send the console output for the given instance."""
5161         context = context.elevated()
5162         LOG.info("Get console output", instance=instance)
5163         output = self.driver.get_console_output(context, instance)
5164 
5165         if type(output) is six.text_type:
5166             output = six.b(output)
5167 
5168         if tail_length is not None:
5169             output = self._tail_log(output, tail_length)
5170 
5171         return output.decode('ascii', 'replace')
5172 
5173     def _tail_log(self, log, length):
5174         try:
5175             length = int(length)
5176         except ValueError:
5177             length = 0
5178 
5179         if length == 0:
5180             return b''
5181         else:
5182             return b'\n'.join(log.split(b'\n')[-int(length):])
5183 
5184     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5185                                    exception.InstanceNotReady,
5186                                    exception.InstanceNotFound,
5187                                    exception.ConsoleTypeUnavailable,
5188                                    NotImplementedError)
5189     @wrap_exception()
5190     @wrap_instance_fault
5191     def get_vnc_console(self, context, console_type, instance):
5192         """Return connection information for a vnc console."""
5193         context = context.elevated()
5194         LOG.debug("Getting vnc console", instance=instance)
5195 
5196         if not CONF.vnc.enabled:
5197             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5198 
5199         if console_type == 'novnc':
5200             # For essex, novncproxy_base_url must include the full path
5201             # including the html file (like http://myhost/vnc_auto.html)
5202             access_url_base = CONF.vnc.novncproxy_base_url
5203         elif console_type == 'xvpvnc':
5204             access_url_base = CONF.vnc.xvpvncproxy_base_url
5205         else:
5206             raise exception.ConsoleTypeInvalid(console_type=console_type)
5207 
5208         try:
5209             # Retrieve connect info from driver, and then decorate with our
5210             # access info token
5211             console = self.driver.get_vnc_console(context, instance)
5212             console_auth = objects.ConsoleAuthToken(
5213                 context=context,
5214                 console_type=console_type,
5215                 host=console.host,
5216                 port=console.port,
5217                 internal_access_path=console.internal_access_path,
5218                 instance_uuid=instance.uuid,
5219                 access_url_base=access_url_base,
5220             )
5221             console_auth.authorize(CONF.consoleauth.token_ttl)
5222             connect_info = console.get_connection_info(
5223                 console_auth.token, console_auth.access_url)
5224 
5225         except exception.InstanceNotFound:
5226             if instance.vm_state != vm_states.BUILDING:
5227                 raise
5228             raise exception.InstanceNotReady(instance_id=instance.uuid)
5229 
5230         return connect_info
5231 
5232     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5233                                    exception.InstanceNotReady,
5234                                    exception.InstanceNotFound,
5235                                    exception.ConsoleTypeUnavailable,
5236                                    NotImplementedError)
5237     @wrap_exception()
5238     @wrap_instance_fault
5239     def get_spice_console(self, context, console_type, instance):
5240         """Return connection information for a spice console."""
5241         context = context.elevated()
5242         LOG.debug("Getting spice console", instance=instance)
5243 
5244         if not CONF.spice.enabled:
5245             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5246 
5247         if console_type != 'spice-html5':
5248             raise exception.ConsoleTypeInvalid(console_type=console_type)
5249 
5250         try:
5251             # Retrieve connect info from driver, and then decorate with our
5252             # access info token
5253             console = self.driver.get_spice_console(context, instance)
5254             console_auth = objects.ConsoleAuthToken(
5255                 context=context,
5256                 console_type=console_type,
5257                 host=console.host,
5258                 port=console.port,
5259                 internal_access_path=console.internal_access_path,
5260                 instance_uuid=instance.uuid,
5261                 access_url_base=CONF.spice.html5proxy_base_url,
5262             )
5263             console_auth.authorize(CONF.consoleauth.token_ttl)
5264             connect_info = console.get_connection_info(
5265                 console_auth.token, console_auth.access_url)
5266 
5267         except exception.InstanceNotFound:
5268             if instance.vm_state != vm_states.BUILDING:
5269                 raise
5270             raise exception.InstanceNotReady(instance_id=instance.uuid)
5271 
5272         return connect_info
5273 
5274     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5275                                    exception.InstanceNotReady,
5276                                    exception.InstanceNotFound,
5277                                    exception.ConsoleTypeUnavailable,
5278                                    NotImplementedError)
5279     @wrap_exception()
5280     @wrap_instance_fault
5281     def get_rdp_console(self, context, console_type, instance):
5282         """Return connection information for a RDP console."""
5283         context = context.elevated()
5284         LOG.debug("Getting RDP console", instance=instance)
5285 
5286         if not CONF.rdp.enabled:
5287             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5288 
5289         if console_type != 'rdp-html5':
5290             raise exception.ConsoleTypeInvalid(console_type=console_type)
5291 
5292         try:
5293             # Retrieve connect info from driver, and then decorate with our
5294             # access info token
5295             console = self.driver.get_rdp_console(context, instance)
5296             console_auth = objects.ConsoleAuthToken(
5297                 context=context,
5298                 console_type=console_type,
5299                 host=console.host,
5300                 port=console.port,
5301                 internal_access_path=console.internal_access_path,
5302                 instance_uuid=instance.uuid,
5303                 access_url_base=CONF.rdp.html5_proxy_base_url,
5304             )
5305             console_auth.authorize(CONF.consoleauth.token_ttl)
5306             connect_info = console.get_connection_info(
5307                 console_auth.token, console_auth.access_url)
5308 
5309         except exception.InstanceNotFound:
5310             if instance.vm_state != vm_states.BUILDING:
5311                 raise
5312             raise exception.InstanceNotReady(instance_id=instance.uuid)
5313 
5314         return connect_info
5315 
5316     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5317                                    exception.InstanceNotReady,
5318                                    exception.InstanceNotFound,
5319                                    exception.ConsoleTypeUnavailable,
5320                                    NotImplementedError)
5321     @wrap_exception()
5322     @wrap_instance_fault
5323     def get_mks_console(self, context, console_type, instance):
5324         """Return connection information for a MKS console."""
5325         context = context.elevated()
5326         LOG.debug("Getting MKS console", instance=instance)
5327 
5328         if not CONF.mks.enabled:
5329             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5330 
5331         if console_type != 'webmks':
5332             raise exception.ConsoleTypeInvalid(console_type=console_type)
5333 
5334         try:
5335             # Retrieve connect info from driver, and then decorate with our
5336             # access info token
5337             console = self.driver.get_mks_console(context, instance)
5338             console_auth = objects.ConsoleAuthToken(
5339                 context=context,
5340                 console_type=console_type,
5341                 host=console.host,
5342                 port=console.port,
5343                 internal_access_path=console.internal_access_path,
5344                 instance_uuid=instance.uuid,
5345                 access_url_base=CONF.mks.mksproxy_base_url,
5346             )
5347             console_auth.authorize(CONF.consoleauth.token_ttl)
5348             connect_info = console.get_connection_info(
5349                 console_auth.token, console_auth.access_url)
5350 
5351         except exception.InstanceNotFound:
5352             if instance.vm_state != vm_states.BUILDING:
5353                 raise
5354             raise exception.InstanceNotReady(instance_id=instance.uuid)
5355 
5356         return connect_info
5357 
5358     @messaging.expected_exceptions(
5359         exception.ConsoleTypeInvalid,
5360         exception.InstanceNotReady,
5361         exception.InstanceNotFound,
5362         exception.ConsoleTypeUnavailable,
5363         exception.SocketPortRangeExhaustedException,
5364         exception.ImageSerialPortNumberInvalid,
5365         exception.ImageSerialPortNumberExceedFlavorValue,
5366         NotImplementedError)
5367     @wrap_exception()
5368     @wrap_instance_fault
5369     def get_serial_console(self, context, console_type, instance):
5370         """Returns connection information for a serial console."""
5371 
5372         LOG.debug("Getting serial console", instance=instance)
5373 
5374         if not CONF.serial_console.enabled:
5375             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5376 
5377         context = context.elevated()
5378 
5379         try:
5380             # Retrieve connect info from driver, and then decorate with our
5381             # access info token
5382             console = self.driver.get_serial_console(context, instance)
5383             console_auth = objects.ConsoleAuthToken(
5384                 context=context,
5385                 console_type=console_type,
5386                 host=console.host,
5387                 port=console.port,
5388                 internal_access_path=console.internal_access_path,
5389                 instance_uuid=instance.uuid,
5390                 access_url_base=CONF.serial_console.base_url,
5391             )
5392             console_auth.authorize(CONF.consoleauth.token_ttl)
5393             connect_info = console.get_connection_info(
5394                 console_auth.token, console_auth.access_url)
5395 
5396         except exception.InstanceNotFound:
5397             if instance.vm_state != vm_states.BUILDING:
5398                 raise
5399             raise exception.InstanceNotReady(instance_id=instance.uuid)
5400 
5401         return connect_info
5402 
5403     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5404                                    exception.InstanceNotReady,
5405                                    exception.InstanceNotFound)
5406     @wrap_exception()
5407     @wrap_instance_fault
5408     def validate_console_port(self, ctxt, instance, port, console_type):
5409         if console_type == "spice-html5":
5410             console_info = self.driver.get_spice_console(ctxt, instance)
5411         elif console_type == "rdp-html5":
5412             console_info = self.driver.get_rdp_console(ctxt, instance)
5413         elif console_type == "serial":
5414             console_info = self.driver.get_serial_console(ctxt, instance)
5415         elif console_type == "webmks":
5416             console_info = self.driver.get_mks_console(ctxt, instance)
5417         else:
5418             console_info = self.driver.get_vnc_console(ctxt, instance)
5419 
5420         # Some drivers may return an int on console_info.port but the port
5421         # variable in this method is a string, so cast to be sure we are
5422         # comparing the correct types.
5423         return str(console_info.port) == port
5424 
5425     @wrap_exception()
5426     @reverts_task_state
5427     @wrap_instance_fault
5428     def reserve_block_device_name(self, context, instance, device,
5429                                   volume_id, disk_bus, device_type, tag,
5430                                   multiattach):
5431         if (tag and not
5432                 self.driver.capabilities.get('supports_tagged_attach_volume',
5433                                              False)):
5434             raise exception.VolumeTaggedAttachNotSupported()
5435 
5436         if (multiattach and not
5437                 self.driver.capabilities.get('supports_multiattach', False)):
5438             raise exception.MultiattachNotSupportedByVirtDriver(
5439                 volume_id=volume_id)
5440 
5441         @utils.synchronized(instance.uuid)
5442         def do_reserve():
5443             bdms = (
5444                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5445                     context, instance.uuid))
5446 
5447             # NOTE(ndipanov): We need to explicitly set all the fields on the
5448             #                 object so that obj_load_attr does not fail
5449             new_bdm = objects.BlockDeviceMapping(
5450                     context=context,
5451                     source_type='volume', destination_type='volume',
5452                     instance_uuid=instance.uuid, boot_index=None,
5453                     volume_id=volume_id,
5454                     device_name=device, guest_format=None,
5455                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5456 
5457             new_bdm.device_name = self._get_device_name_for_instance(
5458                     instance, bdms, new_bdm)
5459 
5460             # NOTE(vish): create bdm here to avoid race condition
5461             new_bdm.create()
5462             return new_bdm
5463 
5464         return do_reserve()
5465 
5466     @wrap_exception()
5467     @wrap_instance_event(prefix='compute')
5468     @wrap_instance_fault
5469     def attach_volume(self, context, instance, bdm):
5470         """Attach a volume to an instance."""
5471         driver_bdm = driver_block_device.convert_volume(bdm)
5472 
5473         @utils.synchronized(instance.uuid)
5474         def do_attach_volume(context, instance, driver_bdm):
5475             try:
5476                 return self._attach_volume(context, instance, driver_bdm)
5477             except Exception:
5478                 with excutils.save_and_reraise_exception():
5479                     bdm.destroy()
5480 
5481         do_attach_volume(context, instance, driver_bdm)
5482 
5483     def _attach_volume(self, context, instance, bdm):
5484         context = context.elevated()
5485         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5486                  {'volume_id': bdm.volume_id,
5487                   'mountpoint': bdm['mount_device']},
5488                  instance=instance)
5489         compute_utils.notify_about_volume_attach_detach(
5490             context, instance, self.host,
5491             action=fields.NotificationAction.VOLUME_ATTACH,
5492             phase=fields.NotificationPhase.START,
5493             volume_id=bdm.volume_id)
5494         try:
5495             bdm.attach(context, instance, self.volume_api, self.driver,
5496                        do_driver_attach=True)
5497         except Exception as e:
5498             with excutils.save_and_reraise_exception():
5499                 LOG.exception("Failed to attach %(volume_id)s "
5500                               "at %(mountpoint)s",
5501                               {'volume_id': bdm.volume_id,
5502                                'mountpoint': bdm['mount_device']},
5503                               instance=instance)
5504                 if bdm['attachment_id']:
5505                     self.volume_api.attachment_delete(context,
5506                                                       bdm['attachment_id'])
5507                 else:
5508                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5509                 tb = traceback.format_exc()
5510                 compute_utils.notify_about_volume_attach_detach(
5511                     context, instance, self.host,
5512                     action=fields.NotificationAction.VOLUME_ATTACH,
5513                     phase=fields.NotificationPhase.ERROR,
5514                     exception=e,
5515                     volume_id=bdm.volume_id, tb=tb)
5516 
5517         info = {'volume_id': bdm.volume_id}
5518         self._notify_about_instance_usage(
5519             context, instance, "volume.attach", extra_usage_info=info)
5520         compute_utils.notify_about_volume_attach_detach(
5521             context, instance, self.host,
5522             action=fields.NotificationAction.VOLUME_ATTACH,
5523             phase=fields.NotificationPhase.END,
5524             volume_id=bdm.volume_id)
5525 
5526     def _notify_volume_usage_detach(self, context, instance, bdm):
5527         if CONF.volume_usage_poll_interval <= 0:
5528             return
5529 
5530         mp = bdm.device_name
5531         # Handle bootable volumes which will not contain /dev/
5532         if '/dev/' in mp:
5533             mp = mp[5:]
5534         try:
5535             vol_stats = self.driver.block_stats(instance, mp)
5536             if vol_stats is None:
5537                 return
5538         except NotImplementedError:
5539             return
5540 
5541         LOG.debug("Updating volume usage cache with totals", instance=instance)
5542         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5543         vol_usage = objects.VolumeUsage(context)
5544         vol_usage.volume_id = bdm.volume_id
5545         vol_usage.instance_uuid = instance.uuid
5546         vol_usage.project_id = instance.project_id
5547         vol_usage.user_id = instance.user_id
5548         vol_usage.availability_zone = instance.availability_zone
5549         vol_usage.curr_reads = rd_req
5550         vol_usage.curr_read_bytes = rd_bytes
5551         vol_usage.curr_writes = wr_req
5552         vol_usage.curr_write_bytes = wr_bytes
5553         vol_usage.save(update_totals=True)
5554         self.notifier.info(context, 'volume.usage', vol_usage.to_dict())
5555         compute_utils.notify_about_volume_usage(context, vol_usage, self.host)
5556 
5557     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5558                        attachment_id=None):
5559         """Detach a volume from an instance.
5560 
5561         :param context: security context
5562         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5563         :param instance: the Instance object to detach the volume from
5564         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5565                             as deleted. Disabling this is useful for operations
5566                             like rebuild, when we don't want to destroy BDM
5567         :param attachment_id: The volume attachment_id for the given instance
5568                               and volume.
5569         """
5570         volume_id = bdm.volume_id
5571         compute_utils.notify_about_volume_attach_detach(
5572             context, instance, self.host,
5573             action=fields.NotificationAction.VOLUME_DETACH,
5574             phase=fields.NotificationPhase.START,
5575             volume_id=volume_id)
5576 
5577         self._notify_volume_usage_detach(context, instance, bdm)
5578 
5579         LOG.info('Detaching volume %(volume_id)s',
5580                  {'volume_id': volume_id}, instance=instance)
5581 
5582         driver_bdm = driver_block_device.convert_volume(bdm)
5583         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5584                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5585 
5586         info = dict(volume_id=volume_id)
5587         self._notify_about_instance_usage(
5588             context, instance, "volume.detach", extra_usage_info=info)
5589         compute_utils.notify_about_volume_attach_detach(
5590             context, instance, self.host,
5591             action=fields.NotificationAction.VOLUME_DETACH,
5592             phase=fields.NotificationPhase.END,
5593             volume_id=volume_id)
5594 
5595         if 'tag' in bdm and bdm.tag:
5596             self._delete_disk_metadata(instance, bdm)
5597         if destroy_bdm:
5598             bdm.destroy()
5599 
5600     def _delete_disk_metadata(self, instance, bdm):
5601         for device in instance.device_metadata.devices:
5602             if isinstance(device, objects.DiskMetadata):
5603                 if 'serial' in device:
5604                     if device.serial == bdm.volume_id:
5605                         instance.device_metadata.devices.remove(device)
5606                         instance.save()
5607                         break
5608                 else:
5609                     # NOTE(artom) We log the entire device object because all
5610                     # fields are nullable and may not be set
5611                     LOG.warning('Unable to determine whether to clean up '
5612                                 'device metadata for disk %s', device,
5613                                 instance=instance)
5614 
5615     @wrap_exception()
5616     @wrap_instance_event(prefix='compute')
5617     @wrap_instance_fault
5618     def detach_volume(self, context, volume_id, instance, attachment_id):
5619         """Detach a volume from an instance.
5620 
5621         :param context: security context
5622         :param volume_id: the volume id
5623         :param instance: the Instance object to detach the volume from
5624         :param attachment_id: The volume attachment_id for the given instance
5625                               and volume.
5626 
5627         """
5628         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5629                 context, volume_id, instance.uuid)
5630 
5631         @utils.synchronized(instance.uuid)
5632         def do_detach_volume(context, volume_id, instance, attachment_id):
5633             self._detach_volume(context, bdm, instance,
5634                                 attachment_id=attachment_id)
5635 
5636         do_detach_volume(context, volume_id, instance, attachment_id)
5637 
5638     def _init_volume_connection(self, context, new_volume,
5639                                 old_volume_id, connector, bdm,
5640                                 new_attachment_id, mountpoint):
5641         new_volume_id = new_volume['id']
5642         if new_attachment_id is None:
5643             # We're dealing with an old-style attachment so initialize the
5644             # connection so we can get the connection_info.
5645             new_cinfo = self.volume_api.initialize_connection(context,
5646                                                               new_volume_id,
5647                                                               connector)
5648         else:
5649             # Check for multiattach on the new volume and if True, check to
5650             # see if the virt driver supports multiattach.
5651             # TODO(mriedem): This is copied from DriverVolumeBlockDevice
5652             # and should be consolidated into some common code at some point.
5653             vol_multiattach = new_volume.get('multiattach', False)
5654             virt_multiattach = self.driver.capabilities.get(
5655                 'supports_multiattach', False)
5656             if vol_multiattach and not virt_multiattach:
5657                 raise exception.MultiattachNotSupportedByVirtDriver(
5658                     volume_id=new_volume_id)
5659 
5660             # This is a new style attachment and the API created the new
5661             # volume attachment and passed the id to the compute over RPC.
5662             # At this point we need to update the new volume attachment with
5663             # the host connector, which will give us back the new attachment
5664             # connection_info.
5665             new_cinfo = self.volume_api.attachment_update(
5666                 context, new_attachment_id, connector,
5667                 mountpoint)['connection_info']
5668 
5669             if vol_multiattach:
5670                 # This will be used by the volume driver to determine the
5671                 # proper disk configuration.
5672                 new_cinfo['multiattach'] = True
5673 
5674         old_cinfo = jsonutils.loads(bdm['connection_info'])
5675         if old_cinfo and 'serial' not in old_cinfo:
5676             old_cinfo['serial'] = old_volume_id
5677         # NOTE(lyarwood): serial is not always present in the returned
5678         # connection_info so set it if it is missing as we do in
5679         # DriverVolumeBlockDevice.attach().
5680         if 'serial' not in new_cinfo:
5681             new_cinfo['serial'] = new_volume_id
5682         return (old_cinfo, new_cinfo)
5683 
5684     def _swap_volume(self, context, instance, bdm, connector,
5685                      old_volume_id, new_volume, resize_to,
5686                      new_attachment_id, is_cinder_migration):
5687         new_volume_id = new_volume['id']
5688         mountpoint = bdm['device_name']
5689         failed = False
5690         new_cinfo = None
5691         try:
5692             old_cinfo, new_cinfo = self._init_volume_connection(
5693                 context, new_volume, old_volume_id, connector,
5694                 bdm, new_attachment_id, mountpoint)
5695             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5696             # currently implementing swap_volume, will modify the contents of
5697             # new_cinfo when connect_volume is called. This is then saved to
5698             # the BDM in swap_volume for future use outside of this flow.
5699             msg = ("swap_volume: Calling driver volume swap with "
5700                    "connection infos: new: %(new_cinfo)s; "
5701                    "old: %(old_cinfo)s" %
5702                    {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo})
5703             # Both new and old info might contain password
5704             LOG.debug(strutils.mask_password(msg), instance=instance)
5705 
5706             self.driver.swap_volume(context, old_cinfo, new_cinfo, instance,
5707                                     mountpoint, resize_to)
5708             if new_attachment_id:
5709                 self.volume_api.attachment_complete(context, new_attachment_id)
5710             msg = ("swap_volume: Driver volume swap returned, new "
5711                    "connection_info is now : %(new_cinfo)s" %
5712                    {'new_cinfo': new_cinfo})
5713             LOG.debug(strutils.mask_password(msg))
5714         except Exception as ex:
5715             failed = True
5716             with excutils.save_and_reraise_exception():
5717                 tb = traceback.format_exc()
5718                 compute_utils.notify_about_volume_swap(
5719                     context, instance, self.host,
5720                     fields.NotificationPhase.ERROR,
5721                     old_volume_id, new_volume_id, ex, tb)
5722                 if new_cinfo:
5723                     msg = ("Failed to swap volume %(old_volume_id)s "
5724                            "for %(new_volume_id)s")
5725                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5726                                         'new_volume_id': new_volume_id},
5727                                   instance=instance)
5728                 else:
5729                     msg = ("Failed to connect to volume %(volume_id)s "
5730                            "with volume at %(mountpoint)s")
5731                     LOG.exception(msg, {'volume_id': new_volume_id,
5732                                         'mountpoint': bdm['device_name']},
5733                                   instance=instance)
5734 
5735                 # The API marked the volume as 'detaching' for the old volume
5736                 # so we need to roll that back so the volume goes back to
5737                 # 'in-use' state.
5738                 self.volume_api.roll_detaching(context, old_volume_id)
5739 
5740                 if new_attachment_id is None:
5741                     # The API reserved the new volume so it would be in
5742                     # 'attaching' status, so we need to unreserve it so it
5743                     # goes back to 'available' status.
5744                     self.volume_api.unreserve_volume(context, new_volume_id)
5745                 else:
5746                     # This is a new style attachment for the new volume, which
5747                     # was created in the API. We just need to delete it here
5748                     # to put the new volume back into 'available' status.
5749                     self.volume_api.attachment_delete(
5750                         context, new_attachment_id)
5751         finally:
5752             # TODO(mriedem): This finally block is terribly confusing and is
5753             # trying to do too much. We should consider removing the finally
5754             # block and move whatever needs to happen on success and failure
5755             # into the blocks above for clarity, even if it means a bit of
5756             # redundant code.
5757             conn_volume = new_volume_id if failed else old_volume_id
5758             if new_cinfo:
5759                 LOG.debug("swap_volume: removing Cinder connection "
5760                           "for volume %(volume)s", {'volume': conn_volume},
5761                           instance=instance)
5762                 if bdm.attachment_id is None:
5763                     # This is the pre-3.44 flow for new-style volume
5764                     # attachments so just terminate the connection.
5765                     self.volume_api.terminate_connection(context,
5766                                                          conn_volume,
5767                                                          connector)
5768                 else:
5769                     # This is a new style volume attachment. If we failed, then
5770                     # the new attachment was already deleted above in the
5771                     # exception block and we have nothing more to do here. If
5772                     # swap_volume was successful in the driver, then we need to
5773                     # "detach" the original attachment by deleting it.
5774                     if not failed:
5775                         self.volume_api.attachment_delete(
5776                             context, bdm.attachment_id)
5777 
5778             # Need to make some decisions based on whether this was
5779             # a Cinder initiated migration or not. The callback to
5780             # migration completion isn't needed in the case of a
5781             # nova initiated simple swap of two volume
5782             # "volume-update" call so skip that. The new attachment
5783             # scenarios will give us a new attachment record and
5784             # that's what we want.
5785             if bdm.attachment_id and not is_cinder_migration:
5786                 # we don't callback to cinder
5787                 comp_ret = {'save_volume_id': new_volume_id}
5788             else:
5789                 # NOTE(lyarwood): The following call to
5790                 # os-migrate-volume-completion returns a dict containing
5791                 # save_volume_id, this volume id has two possible values :
5792                 # 1. old_volume_id if we are migrating (retyping) volumes
5793                 # 2. new_volume_id if we are swapping between two existing
5794                 #    volumes
5795                 # This volume id is later used to update the volume_id and
5796                 # connection_info['serial'] of the BDM.
5797                 comp_ret = self.volume_api.migrate_volume_completion(
5798                                                           context,
5799                                                           old_volume_id,
5800                                                           new_volume_id,
5801                                                           error=failed)
5802                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5803                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5804                           instance=instance)
5805 
5806         return (comp_ret, new_cinfo)
5807 
5808     @wrap_exception()
5809     @wrap_instance_event(prefix='compute')
5810     @wrap_instance_fault
5811     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
5812                     new_attachment_id):
5813         """Swap volume for an instance."""
5814         context = context.elevated()
5815 
5816         compute_utils.notify_about_volume_swap(
5817             context, instance, self.host,
5818             fields.NotificationPhase.START,
5819             old_volume_id, new_volume_id)
5820 
5821         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5822                 context, old_volume_id, instance.uuid)
5823         connector = self.driver.get_volume_connector(instance)
5824 
5825         resize_to = 0
5826         old_volume = self.volume_api.get(context, old_volume_id)
5827         # Yes this is a tightly-coupled state check of what's going on inside
5828         # cinder, but we need this while we still support old (v1/v2) and
5829         # new style attachments (v3.44). Once we drop support for old style
5830         # attachments we could think about cleaning up the cinder-initiated
5831         # swap volume API flows.
5832         is_cinder_migration = (
5833             True if old_volume['status'] in ('retyping',
5834                                              'migrating') else False)
5835         old_vol_size = old_volume['size']
5836         new_volume = self.volume_api.get(context, new_volume_id)
5837         new_vol_size = new_volume['size']
5838         if new_vol_size > old_vol_size:
5839             resize_to = new_vol_size
5840 
5841         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5842                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5843                  instance=instance)
5844         comp_ret, new_cinfo = self._swap_volume(context,
5845                                                 instance,
5846                                                 bdm,
5847                                                 connector,
5848                                                 old_volume_id,
5849                                                 new_volume,
5850                                                 resize_to,
5851                                                 new_attachment_id,
5852                                                 is_cinder_migration)
5853 
5854         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5855         # correct volume_id returned by Cinder.
5856         save_volume_id = comp_ret['save_volume_id']
5857         new_cinfo['serial'] = save_volume_id
5858         values = {
5859             'connection_info': jsonutils.dumps(new_cinfo),
5860             'source_type': 'volume',
5861             'destination_type': 'volume',
5862             'snapshot_id': None,
5863             'volume_id': save_volume_id,
5864             'no_device': None}
5865 
5866         if resize_to:
5867             values['volume_size'] = resize_to
5868 
5869         if new_attachment_id is not None:
5870             # This was a volume swap for a new-style attachment so we
5871             # need to update the BDM attachment_id for the new attachment.
5872             values['attachment_id'] = new_attachment_id
5873 
5874         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5875                   "%(updates)s", {'volume_id': bdm.volume_id,
5876                                   'updates': values},
5877                   instance=instance)
5878         bdm.update(values)
5879         bdm.save()
5880 
5881         compute_utils.notify_about_volume_swap(
5882             context, instance, self.host,
5883             fields.NotificationPhase.END,
5884             old_volume_id, new_volume_id)
5885 
5886     @wrap_exception()
5887     def remove_volume_connection(self, context, volume_id, instance):
5888         """Remove the volume connection on this host
5889 
5890         Detach the volume from this instance on this host, and if this is
5891         the cinder v2 flow, call cinder to terminate the connection.
5892         """
5893         try:
5894             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5895                     context, volume_id, instance.uuid)
5896             driver_bdm = driver_block_device.convert_volume(bdm)
5897             driver_bdm.driver_detach(context, instance,
5898                                      self.volume_api, self.driver)
5899             if bdm.attachment_id is None:
5900                 # cinder v2 api flow
5901                 connector = self.driver.get_volume_connector(instance)
5902                 self.volume_api.terminate_connection(context, volume_id,
5903                                                      connector)
5904         except exception.NotFound:
5905             pass
5906 
5907     @wrap_exception()
5908     @wrap_instance_event(prefix='compute')
5909     @wrap_instance_fault
5910     def attach_interface(self, context, instance, network_id, port_id,
5911                          requested_ip, tag):
5912         """Use hotplug to add an network adapter to an instance."""
5913         if not self.driver.capabilities.get('supports_attach_interface',
5914                                             False):
5915             raise exception.AttachInterfaceNotSupported(
5916                 instance_uuid=instance.uuid)
5917         if (tag and not
5918             self.driver.capabilities.get('supports_tagged_attach_interface',
5919                                          False)):
5920             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5921 
5922         compute_utils.notify_about_instance_action(
5923             context, instance, self.host,
5924             action=fields.NotificationAction.INTERFACE_ATTACH,
5925             phase=fields.NotificationPhase.START)
5926 
5927         bind_host_id = self.driver.network_binding_host_id(context, instance)
5928         network_info = self.network_api.allocate_port_for_instance(
5929             context, instance, port_id, network_id, requested_ip,
5930             bind_host_id=bind_host_id, tag=tag)
5931         if len(network_info) != 1:
5932             LOG.error('allocate_port_for_instance returned %(ports)s '
5933                       'ports', {'ports': len(network_info)})
5934             # TODO(elod.illes): an instance.interface_attach.error notification
5935             # should be sent here
5936             raise exception.InterfaceAttachFailed(
5937                     instance_uuid=instance.uuid)
5938         image_meta = objects.ImageMeta.from_instance(instance)
5939 
5940         try:
5941             self.driver.attach_interface(context, instance, image_meta,
5942                                          network_info[0])
5943         except exception.NovaException as ex:
5944             port_id = network_info[0].get('id')
5945             LOG.warning("attach interface failed , try to deallocate "
5946                         "port %(port_id)s, reason: %(msg)s",
5947                         {'port_id': port_id, 'msg': ex},
5948                         instance=instance)
5949             try:
5950                 self.network_api.deallocate_port_for_instance(
5951                     context, instance, port_id)
5952             except Exception:
5953                 LOG.warning("deallocate port %(port_id)s failed",
5954                             {'port_id': port_id}, instance=instance)
5955 
5956             tb = traceback.format_exc()
5957             compute_utils.notify_about_instance_action(
5958                 context, instance, self.host,
5959                 action=fields.NotificationAction.INTERFACE_ATTACH,
5960                 phase=fields.NotificationPhase.ERROR,
5961                 exception=ex, tb=tb)
5962 
5963             raise exception.InterfaceAttachFailed(
5964                 instance_uuid=instance.uuid)
5965 
5966         compute_utils.notify_about_instance_action(
5967             context, instance, self.host,
5968             action=fields.NotificationAction.INTERFACE_ATTACH,
5969             phase=fields.NotificationPhase.END)
5970 
5971         return network_info[0]
5972 
5973     @wrap_exception()
5974     @wrap_instance_event(prefix='compute')
5975     @wrap_instance_fault
5976     def detach_interface(self, context, instance, port_id):
5977         """Detach a network adapter from an instance."""
5978         network_info = instance.info_cache.network_info
5979         condemned = None
5980         for vif in network_info:
5981             if vif['id'] == port_id:
5982                 condemned = vif
5983                 break
5984         if condemned is None:
5985             raise exception.PortNotFound(_("Port %s is not "
5986                                            "attached") % port_id)
5987 
5988         compute_utils.notify_about_instance_action(
5989             context, instance, self.host,
5990             action=fields.NotificationAction.INTERFACE_DETACH,
5991             phase=fields.NotificationPhase.START)
5992 
5993         try:
5994             self.driver.detach_interface(context, instance, condemned)
5995         except exception.NovaException as ex:
5996             # If the instance was deleted before the interface was detached,
5997             # just log it at debug.
5998             log_level = (logging.DEBUG
5999                          if isinstance(ex, exception.InstanceNotFound)
6000                          else logging.WARNING)
6001             LOG.log(log_level,
6002                     "Detach interface failed, port_id=%(port_id)s, reason: "
6003                     "%(msg)s", {'port_id': port_id, 'msg': ex},
6004                     instance=instance)
6005             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
6006         else:
6007             try:
6008                 self.network_api.deallocate_port_for_instance(
6009                     context, instance, port_id)
6010             except Exception as ex:
6011                 with excutils.save_and_reraise_exception():
6012                     # Since this is a cast operation, log the failure for
6013                     # triage.
6014                     LOG.warning('Failed to deallocate port %(port_id)s '
6015                                 'for instance. Error: %(error)s',
6016                                 {'port_id': port_id, 'error': ex},
6017                                 instance=instance)
6018 
6019         compute_utils.notify_about_instance_action(
6020             context, instance, self.host,
6021             action=fields.NotificationAction.INTERFACE_DETACH,
6022             phase=fields.NotificationPhase.END)
6023 
6024     def _get_compute_info(self, context, host):
6025         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
6026             context, host)
6027 
6028     @wrap_exception()
6029     def check_instance_shared_storage(self, ctxt, instance, data):
6030         """Check if the instance files are shared
6031 
6032         :param ctxt: security context
6033         :param instance: dict of instance data
6034         :param data: result of driver.check_instance_shared_storage_local
6035 
6036         Returns True if instance disks located on shared storage and
6037         False otherwise.
6038         """
6039         return self.driver.check_instance_shared_storage_remote(ctxt, data)
6040 
6041     @wrap_exception()
6042     @wrap_instance_event(prefix='compute')
6043     @wrap_instance_fault
6044     def check_can_live_migrate_destination(self, ctxt, instance,
6045                                            block_migration, disk_over_commit):
6046         """Check if it is possible to execute live migration.
6047 
6048         This runs checks on the destination host, and then calls
6049         back to the source host to check the results.
6050 
6051         :param context: security context
6052         :param instance: dict of instance data
6053         :param block_migration: if true, prepare for block migration
6054                                 if None, calculate it in driver
6055         :param disk_over_commit: if true, allow disk over commit
6056                                  if None, ignore disk usage checking
6057         :returns: a dict containing migration info
6058         """
6059         src_compute_info = obj_base.obj_to_primitive(
6060             self._get_compute_info(ctxt, instance.host))
6061         dst_compute_info = obj_base.obj_to_primitive(
6062             self._get_compute_info(ctxt, CONF.host))
6063         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
6064             instance, src_compute_info, dst_compute_info,
6065             block_migration, disk_over_commit)
6066         LOG.debug('destination check data is %s', dest_check_data)
6067         try:
6068             migrate_data = self.compute_rpcapi.\
6069                                 check_can_live_migrate_source(ctxt, instance,
6070                                                               dest_check_data)
6071         finally:
6072             self.driver.cleanup_live_migration_destination_check(ctxt,
6073                     dest_check_data)
6074         return migrate_data
6075 
6076     @wrap_exception()
6077     @wrap_instance_event(prefix='compute')
6078     @wrap_instance_fault
6079     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
6080         """Check if it is possible to execute live migration.
6081 
6082         This checks if the live migration can succeed, based on the
6083         results from check_can_live_migrate_destination.
6084 
6085         :param ctxt: security context
6086         :param instance: dict of instance data
6087         :param dest_check_data: result of check_can_live_migrate_destination
6088         :returns: a dict containing migration info
6089         """
6090         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6091             ctxt, instance.uuid)
6092         is_volume_backed = compute_utils.is_volume_backed_instance(
6093             ctxt, instance, bdms)
6094         dest_check_data.is_volume_backed = is_volume_backed
6095         block_device_info = self._get_instance_block_device_info(
6096                             ctxt, instance, refresh_conn_info=False, bdms=bdms)
6097         result = self.driver.check_can_live_migrate_source(ctxt, instance,
6098                                                            dest_check_data,
6099                                                            block_device_info)
6100         LOG.debug('source check data is %s', result)
6101         return result
6102 
6103     @wrap_exception()
6104     @wrap_instance_event(prefix='compute')
6105     @wrap_instance_fault
6106     def pre_live_migration(self, context, instance, block_migration, disk,
6107                            migrate_data):
6108         """Preparations for live migration at dest host.
6109 
6110         :param context: security context
6111         :param instance: dict of instance data
6112         :param block_migration: if true, prepare for block migration
6113         :param disk: disk info of instance
6114         :param migrate_data: A dict or LiveMigrateData object holding data
6115                              required for live migration without shared
6116                              storage.
6117         :returns: migrate_data containing additional migration info
6118         """
6119         LOG.debug('pre_live_migration data is %s', migrate_data)
6120 
6121         migrate_data.old_vol_attachment_ids = {}
6122         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6123             context, instance.uuid)
6124         network_info = self.network_api.get_instance_nw_info(context, instance)
6125         self._notify_about_instance_usage(
6126             context, instance, "live_migration.pre.start",
6127             network_info=network_info)
6128         compute_utils.notify_about_instance_action(
6129             context, instance, self.host,
6130             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6131             phase=fields.NotificationPhase.START, bdms=bdms)
6132 
6133         connector = self.driver.get_volume_connector(instance)
6134         try:
6135             for bdm in bdms:
6136                 if bdm.is_volume and bdm.attachment_id is not None:
6137                     # This bdm uses the new cinder v3.44 API.
6138                     # We will create a new attachment for this
6139                     # volume on this migration destination host. The old
6140                     # attachment will be deleted on the source host
6141                     # when the migration succeeds. The old attachment_id
6142                     # is stored in dict with the key being the bdm.volume_id
6143                     # so it can be restored on rollback.
6144                     #
6145                     # Also note that attachment_update is not needed as we
6146                     # are providing the connector in the create call.
6147                     attach_ref = self.volume_api.attachment_create(
6148                         context, bdm.volume_id, bdm.instance_uuid,
6149                         connector=connector, mountpoint=bdm.device_name)
6150 
6151                     # save current attachment so we can detach it on success,
6152                     # or restore it on a rollback.
6153                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
6154                         bdm.attachment_id
6155 
6156                     # update the bdm with the new attachment_id.
6157                     bdm.attachment_id = attach_ref['id']
6158                     bdm.save()
6159 
6160             block_device_info = self._get_instance_block_device_info(
6161                                 context, instance, refresh_conn_info=True,
6162                                 bdms=bdms)
6163 
6164             # The driver pre_live_migration will plug vifs on the host. We call
6165             # plug_vifs before calling ensure_filtering_rules_for_instance, to
6166             # ensure bridge is set up.
6167             migrate_data = self.driver.pre_live_migration(context,
6168                                            instance,
6169                                            block_device_info,
6170                                            network_info,
6171                                            disk,
6172                                            migrate_data)
6173             LOG.debug('driver pre_live_migration data is %s', migrate_data)
6174             # driver.pre_live_migration is what plugs vifs on the destination
6175             # host so now we can set the wait_for_vif_plugged flag in the
6176             # migrate_data object which the source compute will use to
6177             # determine if it should wait for a 'network-vif-plugged' event
6178             # from neutron before starting the actual guest transfer in the
6179             # hypervisor
6180             migrate_data.wait_for_vif_plugged = (
6181                 CONF.compute.live_migration_wait_for_vif_plug)
6182 
6183             # NOTE(tr3buchet): setup networks on destination host
6184             self.network_api.setup_networks_on_host(context, instance,
6185                                                              self.host)
6186 
6187             # Creating filters to hypervisors and firewalls.
6188             # An example is that nova-instance-instance-xxx,
6189             # which is written to libvirt.xml(Check "virsh nwfilter-list")
6190             # This nwfilter is necessary on the destination host.
6191             # In addition, this method is creating filtering rule
6192             # onto destination host.
6193             self.driver.ensure_filtering_rules_for_instance(instance,
6194                                                 network_info)
6195         except Exception:
6196             # If we raise, migrate_data with the updated attachment ids
6197             # will not be returned to the source host for rollback.
6198             # So we need to rollback new attachments here.
6199             with excutils.save_and_reraise_exception():
6200                 old_attachments = migrate_data.old_vol_attachment_ids
6201                 for bdm in bdms:
6202                     if (bdm.is_volume and bdm.attachment_id is not None and
6203                             bdm.volume_id in old_attachments):
6204                         self.volume_api.attachment_delete(context,
6205                                                           bdm.attachment_id)
6206                         bdm.attachment_id = old_attachments[bdm.volume_id]
6207                         bdm.save()
6208 
6209         # Volume connections are complete, tell cinder that all the
6210         # attachments have completed.
6211         for bdm in bdms:
6212             if bdm.is_volume and bdm.attachment_id is not None:
6213                 self.volume_api.attachment_complete(context,
6214                                                     bdm.attachment_id)
6215 
6216         self._notify_about_instance_usage(
6217                      context, instance, "live_migration.pre.end",
6218                      network_info=network_info)
6219         compute_utils.notify_about_instance_action(
6220             context, instance, self.host,
6221             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6222             phase=fields.NotificationPhase.END, bdms=bdms)
6223 
6224         LOG.debug('pre_live_migration result data is %s', migrate_data)
6225         return migrate_data
6226 
6227     @staticmethod
6228     def _neutron_failed_live_migration_callback(event_name, instance):
6229         msg = ('Neutron reported failure during live migration '
6230                'with %(event)s for instance %(uuid)s')
6231         msg_args = {'event': event_name, 'uuid': instance.uuid}
6232         if CONF.vif_plugging_is_fatal:
6233             raise exception.VirtualInterfacePlugException(msg % msg_args)
6234         LOG.error(msg, msg_args)
6235 
6236     @staticmethod
6237     def _get_neutron_events_for_live_migration(instance):
6238         # We don't generate events if CONF.vif_plugging_timeout=0
6239         # meaning that the operator disabled using them.
6240         if CONF.vif_plugging_timeout and utils.is_neutron():
6241             return [('network-vif-plugged', vif['id'])
6242                     for vif in instance.get_network_info()]
6243         else:
6244             return []
6245 
6246     def _cleanup_pre_live_migration(self, context, dest, instance,
6247                                     migration, migrate_data):
6248         """Helper method for when pre_live_migration fails
6249 
6250         Sets the migration status to "error" and rolls back the live migration
6251         setup on the destination host.
6252 
6253         :param context: The user request context.
6254         :type context: nova.context.RequestContext
6255         :param dest: The live migration destination hostname.
6256         :type dest: str
6257         :param instance: The instance being live migrated.
6258         :type instance: nova.objects.Instance
6259         :param migration: The migration record tracking this live migration.
6260         :type migration: nova.objects.Migration
6261         :param migrate_data: Data about the live migration, populated from
6262                              the destination host.
6263         :type migrate_data: Subclass of nova.objects.LiveMigrateData
6264         """
6265         self._set_migration_status(migration, 'error')
6266         # Make sure we set this for _rollback_live_migration()
6267         # so it can find it, as expected if it was called later
6268         migrate_data.migration = migration
6269         self._rollback_live_migration(context, instance, dest,
6270                                       migrate_data)
6271 
6272     def _do_live_migration(self, context, dest, instance, block_migration,
6273                            migration, migrate_data):
6274         # NOTE(danms): We should enhance the RT to account for migrations
6275         # and use the status field to denote when the accounting has been
6276         # done on source/destination. For now, this is just here for status
6277         # reporting
6278         self._set_migration_status(migration, 'preparing')
6279 
6280         class _BreakWaitForInstanceEvent(Exception):
6281             """Used as a signal to stop waiting for the network-vif-plugged
6282             event when we discover that
6283             [compute]/live_migration_wait_for_vif_plug is not set on the
6284             destination.
6285             """
6286             pass
6287 
6288         events = self._get_neutron_events_for_live_migration(instance)
6289         try:
6290             if ('block_migration' in migrate_data and
6291                     migrate_data.block_migration):
6292                 block_device_info = self._get_instance_block_device_info(
6293                     context, instance)
6294                 disk = self.driver.get_instance_disk_info(
6295                     instance, block_device_info=block_device_info)
6296             else:
6297                 disk = None
6298 
6299             deadline = CONF.vif_plugging_timeout
6300             error_cb = self._neutron_failed_live_migration_callback
6301             # In order to avoid a race with the vif plugging that the virt
6302             # driver does on the destination host, we register our events
6303             # to wait for before calling pre_live_migration. Then if the
6304             # dest host reports back that we shouldn't wait, we can break
6305             # out of the context manager using _BreakWaitForInstanceEvent.
6306             with self.virtapi.wait_for_instance_event(
6307                     instance, events, deadline=deadline,
6308                     error_callback=error_cb):
6309                 with timeutils.StopWatch() as timer:
6310                     migrate_data = self.compute_rpcapi.pre_live_migration(
6311                         context, instance,
6312                         block_migration, disk, dest, migrate_data)
6313                 LOG.info('Took %0.2f seconds for pre_live_migration on '
6314                          'destination host %s.',
6315                          timer.elapsed(), dest, instance=instance)
6316                 wait_for_vif_plugged = (
6317                     'wait_for_vif_plugged' in migrate_data and
6318                     migrate_data.wait_for_vif_plugged)
6319                 if events and not wait_for_vif_plugged:
6320                     raise _BreakWaitForInstanceEvent
6321         except _BreakWaitForInstanceEvent:
6322             if events:
6323                 LOG.debug('Not waiting for events after pre_live_migration: '
6324                           '%s. ', events, instance=instance)
6325             # This is a bit weird, but we need to clear sys.exc_info() so that
6326             # oslo.log formatting does not inadvertently use it later if an
6327             # error message is logged without an explicit exc_info. This is
6328             # only a problem with python 2.
6329             if six.PY2:
6330                 sys.exc_clear()
6331         except exception.VirtualInterfacePlugException:
6332             with excutils.save_and_reraise_exception():
6333                 LOG.exception('Failed waiting for network virtual interfaces '
6334                               'to be plugged on the destination host %s.',
6335                               dest, instance=instance)
6336                 self._cleanup_pre_live_migration(
6337                     context, dest, instance, migration, migrate_data)
6338         except eventlet.timeout.Timeout:
6339             msg = 'Timed out waiting for events: %s'
6340             LOG.warning(msg, events, instance=instance)
6341             if CONF.vif_plugging_is_fatal:
6342                 self._cleanup_pre_live_migration(
6343                     context, dest, instance, migration, migrate_data)
6344                 raise exception.MigrationError(reason=msg % events)
6345         except Exception:
6346             with excutils.save_and_reraise_exception():
6347                 LOG.exception('Pre live migration failed at %s',
6348                               dest, instance=instance)
6349                 self._cleanup_pre_live_migration(
6350                     context, dest, instance, migration, migrate_data)
6351 
6352         # NOTE(Kevin_Zheng): Pop the migration from the waiting queue
6353         # if it exist in the queue, then we are good to moving on, if
6354         # not, some other process must have aborted it, then we should
6355         # rollback.
6356         try:
6357             self._waiting_live_migrations.pop(instance.uuid)
6358         except KeyError:
6359             LOG.debug('Migration %s aborted by another process, rollback.',
6360                       migration.uuid, instance=instance)
6361             migrate_data.migration = migration
6362             self._rollback_live_migration(context, instance, dest,
6363                                           migrate_data, 'cancelled')
6364             self._notify_live_migrate_abort_end(context, instance)
6365             return
6366 
6367         self._set_migration_status(migration, 'running')
6368         if migrate_data:
6369             migrate_data.migration = migration
6370         LOG.debug('live_migration data is %s', migrate_data)
6371         try:
6372             self.driver.live_migration(context, instance, dest,
6373                                        self._post_live_migration,
6374                                        self._rollback_live_migration,
6375                                        block_migration, migrate_data)
6376         except Exception:
6377             LOG.exception('Live migration failed.', instance=instance)
6378             with excutils.save_and_reraise_exception():
6379                 # Put instance and migration into error state,
6380                 # as its almost certainly too late to rollback
6381                 self._set_migration_status(migration, 'error')
6382                 # first refresh instance as it may have got updated by
6383                 # post_live_migration_at_destination
6384                 instance.refresh()
6385                 self._set_instance_obj_error_state(context, instance,
6386                                                    clean_task_state=True)
6387 
6388     @wrap_exception()
6389     @wrap_instance_event(prefix='compute')
6390     @wrap_instance_fault
6391     def live_migration(self, context, dest, instance, block_migration,
6392                        migration, migrate_data):
6393         """Executing live migration.
6394 
6395         :param context: security context
6396         :param dest: destination host
6397         :param instance: a nova.objects.instance.Instance object
6398         :param block_migration: if true, prepare for block migration
6399         :param migration: an nova.objects.Migration object
6400         :param migrate_data: implementation specific params
6401 
6402         """
6403         self._set_migration_status(migration, 'queued')
6404         # NOTE(Kevin_Zheng): Submit the live_migration job to the pool and
6405         # put the returned Future object into dict mapped with migration.uuid
6406         # in order to be able to track and abort it in the future.
6407         self._waiting_live_migrations[instance.uuid] = (None, None)
6408         try:
6409             future = self._live_migration_executor.submit(
6410                 self._do_live_migration, context, dest, instance,
6411                 block_migration, migration, migrate_data)
6412             self._waiting_live_migrations[instance.uuid] = (migration, future)
6413         except RuntimeError:
6414             # GreenThreadPoolExecutor.submit will raise RuntimeError if the
6415             # pool is shutdown, which happens in
6416             # _cleanup_live_migrations_in_pool.
6417             LOG.info('Migration %s failed to submit as the compute service '
6418                      'is shutting down.', migration.uuid, instance=instance)
6419             self._set_migration_status(migration, 'error')
6420             raise exception.LiveMigrationNotSubmitted(
6421                 migration_uuid=migration.uuid, instance_uuid=instance.uuid)
6422 
6423     @wrap_exception()
6424     @wrap_instance_event(prefix='compute')
6425     @wrap_instance_fault
6426     def live_migration_force_complete(self, context, instance):
6427         """Force live migration to complete.
6428 
6429         :param context: Security context
6430         :param instance: The instance that is being migrated
6431         """
6432 
6433         self._notify_about_instance_usage(
6434             context, instance, 'live.migration.force.complete.start')
6435         compute_utils.notify_about_instance_action(
6436             context, instance, self.host,
6437             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6438             phase=fields.NotificationPhase.START)
6439         self.driver.live_migration_force_complete(instance)
6440         self._notify_about_instance_usage(
6441             context, instance, 'live.migration.force.complete.end')
6442         compute_utils.notify_about_instance_action(
6443             context, instance, self.host,
6444             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6445             phase=fields.NotificationPhase.END)
6446 
6447     def _notify_live_migrate_abort_end(self, context, instance):
6448         self._notify_about_instance_usage(
6449             context, instance, 'live.migration.abort.end')
6450         compute_utils.notify_about_instance_action(
6451             context, instance, self.host,
6452             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6453             phase=fields.NotificationPhase.END)
6454 
6455     @wrap_exception()
6456     @wrap_instance_event(prefix='compute')
6457     @wrap_instance_fault
6458     def live_migration_abort(self, context, instance, migration_id):
6459         """Abort an in-progress live migration.
6460 
6461         :param context: Security context
6462         :param instance: The instance that is being migrated
6463         :param migration_id: ID of in-progress live migration
6464 
6465         """
6466         self._notify_about_instance_usage(
6467             context, instance, 'live.migration.abort.start')
6468         compute_utils.notify_about_instance_action(
6469             context, instance, self.host,
6470             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6471             phase=fields.NotificationPhase.START)
6472         # NOTE(Kevin_Zheng): Pop the migration out from the queue, this might
6473         # lead to 3 scenarios:
6474         # 1. The selected migration is still in queue, and the future.cancel()
6475         #    succeed, then the abort action is succeed, mark the migration
6476         #    status to 'cancelled'.
6477         # 2. The selected migration is still in queue, but the future.cancel()
6478         #    failed, then the _do_live_migration() has started executing, and
6479         #    the migration status is 'preparing', then we just pop it from the
6480         #    queue, and the migration process will handle it later. And the
6481         #    migration status couldn't be 'running' in this scenario because
6482         #    if _do_live_migration has started executing and we've already
6483         #    popped it from the queue and set the migration status to
6484         #    'running' at this point, popping it here will raise KeyError at
6485         #    which point we check if it's running and if so, we abort the old
6486         #    way.
6487         # 3. The selected migration is not in the queue, then the migration
6488         #    status is 'running', let the driver handle it.
6489         try:
6490             migration, future = (
6491                 self._waiting_live_migrations.pop(instance.uuid))
6492             if future and future.cancel():
6493                 # If we got here, we've successfully aborted the queued
6494                 # migration and _do_live_migration won't run so we need
6495                 # to set the migration status to cancelled and send the
6496                 # notification. If Future.cancel() fails, it means
6497                 # _do_live_migration is running and the migration status
6498                 # is preparing, and _do_live_migration() itself will attempt
6499                 # to pop the queued migration, hit a KeyError, and rollback,
6500                 # set the migration to cancelled and send the
6501                 # live.migration.abort.end notification.
6502                 self._set_migration_status(migration, 'cancelled')
6503         except KeyError:
6504             migration = objects.Migration.get_by_id(context, migration_id)
6505             if migration.status != 'running':
6506                 raise exception.InvalidMigrationState(
6507                     migration_id=migration_id, instance_uuid=instance.uuid,
6508                     state=migration.status, method='abort live migration')
6509             self.driver.live_migration_abort(instance)
6510         self._notify_live_migrate_abort_end(context, instance)
6511 
6512     def _live_migration_cleanup_flags(self, migrate_data):
6513         """Determine whether disks or instance path need to be cleaned up after
6514         live migration (at source on success, at destination on rollback)
6515 
6516         Block migration needs empty image at destination host before migration
6517         starts, so if any failure occurs, any empty images has to be deleted.
6518 
6519         Also Volume backed live migration w/o shared storage needs to delete
6520         newly created instance-xxx dir on the destination as a part of its
6521         rollback process
6522 
6523         :param migrate_data: implementation specific data
6524         :returns: (bool, bool) -- do_cleanup, destroy_disks
6525         """
6526         # NOTE(pkoniszewski): block migration specific params are set inside
6527         # migrate_data objects for drivers that expose block live migration
6528         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6529         # cleanup is not needed.
6530         do_cleanup = False
6531         destroy_disks = False
6532         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6533             # No instance booting at source host, but instance dir
6534             # must be deleted for preparing next block migration
6535             # must be deleted for preparing next live migration w/o shared
6536             # storage
6537             do_cleanup = not migrate_data.is_shared_instance_path
6538             destroy_disks = not migrate_data.is_shared_block_storage
6539         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6540             do_cleanup = migrate_data.block_migration
6541             destroy_disks = migrate_data.block_migration
6542         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6543             # NOTE(claudiub): We need to cleanup any zombie Planned VM.
6544             do_cleanup = True
6545             destroy_disks = not migrate_data.is_shared_instance_path
6546 
6547         return (do_cleanup, destroy_disks)
6548 
6549     @wrap_exception()
6550     @wrap_instance_fault
6551     def _post_live_migration(self, ctxt, instance,
6552                             dest, block_migration=False, migrate_data=None):
6553         """Post operations for live migration.
6554 
6555         This method is called from live_migration
6556         and mainly updating database record.
6557 
6558         :param ctxt: security context
6559         :param instance: instance dict
6560         :param dest: destination host
6561         :param block_migration: if true, prepare for block migration
6562         :param migrate_data: if not None, it is a dict which has data
6563         required for live migration without shared storage
6564 
6565         """
6566         LOG.info('_post_live_migration() is started..',
6567                  instance=instance)
6568 
6569         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6570                 ctxt, instance.uuid)
6571 
6572         # Cleanup source host post live-migration
6573         block_device_info = self._get_instance_block_device_info(
6574                             ctxt, instance, bdms=bdms)
6575         self.driver.post_live_migration(ctxt, instance, block_device_info,
6576                                         migrate_data)
6577 
6578         # Detaching volumes.
6579         connector = self.driver.get_volume_connector(instance)
6580         for bdm in bdms:
6581             if bdm.is_volume:
6582                 # Detaching volumes is a call to an external API that can fail.
6583                 # If it does, we need to handle it gracefully so that the call
6584                 # to post_live_migration_at_destination - where we set instance
6585                 # host and task state - still happens. We need to rethink the
6586                 # current approach of setting instance host and task state
6587                 # AFTER a whole bunch of things that could fail in unhandled
6588                 # ways, but that is left as a TODO(artom).
6589                 try:
6590                     if bdm.attachment_id is None:
6591                         # Prior to cinder v3.44:
6592                         # We don't want to actually mark the volume detached,
6593                         # or delete the bdm, just remove the connection from
6594                         # this host.
6595                         #
6596                         # remove the volume connection without detaching from
6597                         # hypervisor because the instance is not running
6598                         # anymore on the current host
6599                         self.volume_api.terminate_connection(ctxt,
6600                                                              bdm.volume_id,
6601                                                              connector)
6602                     else:
6603                         # cinder v3.44 api flow - delete the old attachment
6604                         # for the source host
6605                         old_attachment_id = \
6606                             migrate_data.old_vol_attachment_ids[bdm.volume_id]
6607                         self.volume_api.attachment_delete(ctxt,
6608                                                           old_attachment_id)
6609                 except Exception as e:
6610                     if bdm.attachment_id is None:
6611                         LOG.error('Connection for volume %s not terminated on '
6612                                   'source host %s during post_live_migration: '
6613                                    '%s', bdm.volume_id, self.host,
6614                                    six.text_type(e), instance=instance)
6615                     else:
6616                         LOG.error('Volume attachment %s not deleted on source '
6617                                   'host %s during post_live_migration: %s',
6618                                   old_attachment_id, self.host,
6619                                   six.text_type(e), instance=instance)
6620 
6621         # Releasing vlan.
6622         # (not necessary in current implementation?)
6623 
6624         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
6625 
6626         self._notify_about_instance_usage(ctxt, instance,
6627                                           "live_migration._post.start",
6628                                           network_info=network_info)
6629         compute_utils.notify_about_instance_action(
6630             ctxt, instance, self.host,
6631             action=fields.NotificationAction.LIVE_MIGRATION_POST,
6632             phase=fields.NotificationPhase.START)
6633         # Releasing security group ingress rule.
6634         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
6635                   instance=instance)
6636         self.driver.unfilter_instance(instance,
6637                                       network_info)
6638 
6639         migration = {'source_compute': self.host,
6640                      'dest_compute': dest, }
6641         # For neutron, migrate_instance_start will activate the destination
6642         # host port bindings, if there are any created by conductor before live
6643         # migration started.
6644         self.network_api.migrate_instance_start(ctxt,
6645                                                 instance,
6646                                                 migration)
6647 
6648         destroy_vifs = False
6649         try:
6650             # It's possible that the vif type changed on the destination
6651             # host and is already bound and active, so we need to use the
6652             # stashed source vifs in migrate_data.vifs (if present) to unplug
6653             # on the source host.
6654             unplug_nw_info = network_info
6655             if migrate_data and 'vifs' in migrate_data:
6656                 nw_info = []
6657                 for migrate_vif in migrate_data.vifs:
6658                     nw_info.append(migrate_vif.source_vif)
6659                 unplug_nw_info = network_model.NetworkInfo.hydrate(nw_info)
6660                 LOG.debug('Calling driver.post_live_migration_at_source '
6661                           'with original source VIFs from migrate_data: %s',
6662                           unplug_nw_info, instance=instance)
6663             self.driver.post_live_migration_at_source(ctxt, instance,
6664                                                       unplug_nw_info)
6665         except NotImplementedError as ex:
6666             LOG.debug(ex, instance=instance)
6667             # For all hypervisors other than libvirt, there is a possibility
6668             # they are unplugging networks from source node in the cleanup
6669             # method
6670             destroy_vifs = True
6671 
6672         # NOTE(danms): Save source node before calling post method on
6673         # destination, which will update it
6674         source_node = instance.node
6675 
6676         # Define domain at destination host, without doing it,
6677         # pause/suspend/terminate do not work.
6678         post_at_dest_success = True
6679         try:
6680             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
6681                     instance, block_migration, dest)
6682         except Exception as error:
6683             post_at_dest_success = False
6684             # We don't want to break _post_live_migration() if
6685             # post_live_migration_at_destination() fails as it should never
6686             # affect cleaning up source node.
6687             LOG.exception("Post live migration at destination %s failed",
6688                           dest, instance=instance, error=error)
6689 
6690         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6691                 migrate_data)
6692 
6693         if do_cleanup:
6694             LOG.debug('Calling driver.cleanup from _post_live_migration',
6695                       instance=instance)
6696             self.driver.cleanup(ctxt, instance, unplug_nw_info,
6697                                 destroy_disks=destroy_disks,
6698                                 migrate_data=migrate_data,
6699                                 destroy_vifs=destroy_vifs)
6700 
6701         self.instance_events.clear_events_for_instance(instance)
6702 
6703         # NOTE(timello): make sure we update available resources on source
6704         # host even before next periodic task.
6705         self.update_available_resource(ctxt)
6706 
6707         self._update_scheduler_instance_info(ctxt, instance)
6708         self._notify_about_instance_usage(ctxt, instance,
6709                                           "live_migration._post.end",
6710                                           network_info=network_info)
6711         compute_utils.notify_about_instance_action(
6712             ctxt, instance, self.host,
6713             action=fields.NotificationAction.LIVE_MIGRATION_POST,
6714             phase=fields.NotificationPhase.END)
6715         if post_at_dest_success:
6716             LOG.info('Migrating instance to %s finished successfully.',
6717                      dest, instance=instance)
6718 
6719         self._clean_instance_console_tokens(ctxt, instance)
6720         if migrate_data and migrate_data.obj_attr_is_set('migration'):
6721             migrate_data.migration.status = 'completed'
6722             migrate_data.migration.save()
6723             self._delete_allocation_after_move(ctxt,
6724                                                instance,
6725                                                migrate_data.migration)
6726         else:
6727             # We didn't have data on a migration, which means we can't
6728             # look up to see if we had new-style migration-based
6729             # allocations. This should really only happen in cases of
6730             # a buggy virt driver. Log a warning so we know it happened.
6731             LOG.warning('Live migration ended with no migrate_data '
6732                         'record. Unable to clean up migration-based '
6733                         'allocations for node %s which is almost certainly '
6734                         'not an expected situation.', source_node,
6735                         instance=instance)
6736 
6737     def _consoles_enabled(self):
6738         """Returns whether a console is enable."""
6739         return (CONF.vnc.enabled or CONF.spice.enabled or
6740                 CONF.rdp.enabled or CONF.serial_console.enabled or
6741                 CONF.mks.enabled)
6742 
6743     def _clean_instance_console_tokens(self, ctxt, instance):
6744         """Clean console tokens stored for an instance."""
6745         # If the database backend isn't in use, don't bother trying to clean
6746         # tokens. The database backend is not supported for cells v1.
6747         if not CONF.cells.enable and self._consoles_enabled():
6748             objects.ConsoleAuthToken.\
6749                 clean_console_auths_for_instance(ctxt, instance.uuid)
6750 
6751     @wrap_exception()
6752     @wrap_instance_event(prefix='compute')
6753     @wrap_instance_fault
6754     def post_live_migration_at_destination(self, context, instance,
6755                                            block_migration):
6756         """Post operations for live migration .
6757 
6758         :param context: security context
6759         :param instance: Instance dict
6760         :param block_migration: if true, prepare for block migration
6761 
6762         """
6763         LOG.info('Post operation of migration started',
6764                  instance=instance)
6765 
6766         # NOTE(tr3buchet): setup networks on destination host
6767         #                  this is called a second time because
6768         #                  multi_host does not create the bridge in
6769         #                  plug_vifs
6770         # NOTE(mriedem): This is a no-op for neutron.
6771         self.network_api.setup_networks_on_host(context, instance,
6772                                                          self.host)
6773         migration = {'source_compute': instance.host,
6774                      'dest_compute': self.host, }
6775         self.network_api.migrate_instance_finish(context,
6776                                                  instance,
6777                                                  migration)
6778 
6779         network_info = self.network_api.get_instance_nw_info(context, instance)
6780         self._notify_about_instance_usage(
6781                      context, instance, "live_migration.post.dest.start",
6782                      network_info=network_info)
6783         compute_utils.notify_about_instance_action(context, instance,
6784                 self.host,
6785                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6786                 phase=fields.NotificationPhase.START)
6787         block_device_info = self._get_instance_block_device_info(context,
6788                                                                  instance)
6789 
6790         try:
6791             self.driver.post_live_migration_at_destination(
6792                 context, instance, network_info, block_migration,
6793                 block_device_info)
6794         except Exception:
6795             with excutils.save_and_reraise_exception():
6796                 instance.vm_state = vm_states.ERROR
6797                 LOG.error('Unexpected error during post live migration at '
6798                           'destination host.', instance=instance)
6799         finally:
6800             # Restore instance state and update host
6801             current_power_state = self._get_power_state(context, instance)
6802             node_name = None
6803             prev_host = instance.host
6804             try:
6805                 compute_node = self._get_compute_info(context, self.host)
6806                 node_name = compute_node.hypervisor_hostname
6807             except exception.ComputeHostNotFound:
6808                 LOG.exception('Failed to get compute_info for %s', self.host)
6809             finally:
6810                 instance.host = self.host
6811                 instance.power_state = current_power_state
6812                 instance.task_state = None
6813                 instance.node = node_name
6814                 instance.progress = 0
6815                 instance.save(expected_task_state=task_states.MIGRATING)
6816 
6817         # NOTE(tr3buchet): tear down networks on source host (nova-net)
6818         # NOTE(mriedem): For neutron, this will delete any inactive source
6819         # host port bindings.
6820         try:
6821             self.network_api.setup_networks_on_host(context, instance,
6822                                                     prev_host, teardown=True)
6823         except exception.PortBindingDeletionFailed as e:
6824             # Removing the inactive port bindings from the source host is not
6825             # critical so just log an error but don't fail.
6826             LOG.error('Network cleanup failed for source host %s during post '
6827                       'live migration. You may need to manually clean up '
6828                       'resources in the network service. Error: %s',
6829                       prev_host, six.text_type(e))
6830         # NOTE(vish): this is necessary to update dhcp for nova-network
6831         # NOTE(mriedem): This is a no-op for neutron.
6832         self.network_api.setup_networks_on_host(context, instance, self.host)
6833         self._notify_about_instance_usage(
6834                      context, instance, "live_migration.post.dest.end",
6835                      network_info=network_info)
6836         compute_utils.notify_about_instance_action(context, instance,
6837                 self.host,
6838                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6839                 phase=fields.NotificationPhase.END)
6840 
6841     @wrap_exception()
6842     @wrap_instance_fault
6843     def _rollback_live_migration(self, context, instance,
6844                                  dest, migrate_data=None,
6845                                  migration_status='error'):
6846         """Recovers Instance/volume state from migrating -> running.
6847 
6848         :param context: security context
6849         :param instance: nova.objects.instance.Instance object
6850         :param dest:
6851             This method is called from live migration src host.
6852             This param specifies destination host.
6853         :param migrate_data:
6854             if not none, contains implementation specific data.
6855         :param migration_status:
6856             Contains the status we want to set for the migration object
6857 
6858         """
6859         if (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
6860               migrate_data.obj_attr_is_set('migration')):
6861             migration = migrate_data.migration
6862         else:
6863             migration = None
6864 
6865         if migration:
6866             # Remove allocations created in Placement for the dest node.
6867             # If migration is None, the virt driver didn't pass it which is
6868             # a bug.
6869             self._revert_allocation(context, instance, migration)
6870         else:
6871             LOG.error('Unable to revert allocations during live migration '
6872                       'rollback; compute driver did not provide migrate_data',
6873                       instance=instance)
6874 
6875         instance.task_state = None
6876         instance.progress = 0
6877         instance.save(expected_task_state=[task_states.MIGRATING])
6878 
6879         # NOTE(tr3buchet): setup networks on source host (really it's re-setup
6880         #                  for nova-network)
6881         # NOTE(mriedem): This is a no-op for neutron.
6882         self.network_api.setup_networks_on_host(context, instance, self.host)
6883 
6884         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6885                 context, instance.uuid)
6886         for bdm in bdms:
6887             if bdm.is_volume:
6888                 # remove the connection on the destination host
6889                 self.compute_rpcapi.remove_volume_connection(
6890                         context, instance, bdm.volume_id, dest)
6891 
6892                 if bdm.attachment_id:
6893                     # 3.44 cinder api flow. Set the bdm's
6894                     # attachment_id to the old attachment of the source
6895                     # host. If old_attachments is not there, then
6896                     # there was an error before the new attachment was made.
6897                     old_attachments = migrate_data.old_vol_attachment_ids \
6898                         if 'old_vol_attachment_ids' in migrate_data else None
6899                     if old_attachments and bdm.volume_id in old_attachments:
6900                         self.volume_api.attachment_delete(context,
6901                                                           bdm.attachment_id)
6902                         bdm.attachment_id = old_attachments[bdm.volume_id]
6903                         bdm.save()
6904 
6905         self._notify_about_instance_usage(context, instance,
6906                                           "live_migration._rollback.start")
6907         compute_utils.notify_about_instance_action(context, instance,
6908                 self.host,
6909                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6910                 phase=fields.NotificationPhase.START,
6911                 bdms=bdms)
6912 
6913         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6914                 migrate_data)
6915 
6916         if do_cleanup:
6917             self.compute_rpcapi.rollback_live_migration_at_destination(
6918                     context, instance, dest, destroy_disks=destroy_disks,
6919                     migrate_data=migrate_data)
6920         elif utils.is_neutron():
6921             # The port binding profiles need to be cleaned up.
6922             with errors_out_migration_ctxt(migration):
6923                 try:
6924                     # This call will delete any inactive destination host
6925                     # port bindings.
6926                     self.network_api.setup_networks_on_host(
6927                         context, instance, host=dest, teardown=True)
6928                 except exception.PortBindingDeletionFailed as e:
6929                     # Removing the inactive port bindings from the destination
6930                     # host is not critical so just log an error but don't fail.
6931                     LOG.error(
6932                         'Network cleanup failed for destination host %s '
6933                         'during live migration rollback. You may need to '
6934                         'manually clean up resources in the network service. '
6935                         'Error: %s', dest, six.text_type(e))
6936                 except Exception:
6937                     with excutils.save_and_reraise_exception():
6938                         LOG.exception(
6939                             'An error occurred while cleaning up networking '
6940                             'during live migration rollback.',
6941                             instance=instance)
6942 
6943         self._notify_about_instance_usage(context, instance,
6944                                           "live_migration._rollback.end")
6945         compute_utils.notify_about_instance_action(context, instance,
6946                 self.host,
6947                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6948                 phase=fields.NotificationPhase.END,
6949                 bdms=bdms)
6950 
6951         self._set_migration_status(migration, migration_status)
6952 
6953     @wrap_exception()
6954     @wrap_instance_event(prefix='compute')
6955     @wrap_instance_fault
6956     def rollback_live_migration_at_destination(self, context, instance,
6957                                                destroy_disks,
6958                                                migrate_data):
6959         """Cleaning up image directory that is created pre_live_migration.
6960 
6961         :param context: security context
6962         :param instance: a nova.objects.instance.Instance object sent over rpc
6963         :param destroy_disks: whether to destroy volumes or not
6964         :param migrate_data: contains migration info
6965         """
6966         network_info = self.network_api.get_instance_nw_info(context, instance)
6967         self._notify_about_instance_usage(
6968                       context, instance, "live_migration.rollback.dest.start",
6969                       network_info=network_info)
6970         compute_utils.notify_about_instance_action(
6971             context, instance, self.host,
6972             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
6973             phase=fields.NotificationPhase.START)
6974         try:
6975             # NOTE(tr3buchet): tear down networks on dest host (nova-net)
6976             # NOTE(mriedem): For neutron, this call will delete any
6977             # destination host port bindings.
6978             # TODO(mriedem): We should eventually remove this call from
6979             # this method (rollback_live_migration_at_destination) since this
6980             # method is only called conditionally based on whether or not the
6981             # instance is running on shared storage. _rollback_live_migration
6982             # already calls this method for neutron if we are running on
6983             # shared storage.
6984             self.network_api.setup_networks_on_host(context, instance,
6985                                                     self.host, teardown=True)
6986         except exception.PortBindingDeletionFailed as e:
6987             # Removing the inactive port bindings from the destination
6988             # host is not critical so just log an error but don't fail.
6989             LOG.error(
6990                 'Network cleanup failed for destination host %s '
6991                 'during live migration rollback. You may need to '
6992                 'manually clean up resources in the network service. '
6993                 'Error: %s', self.host, six.text_type(e))
6994         except Exception:
6995             with excutils.save_and_reraise_exception():
6996                 # NOTE(tdurakov): even if teardown networks fails driver
6997                 # should try to rollback live migration on destination.
6998                 LOG.exception('An error occurred while deallocating network.',
6999                               instance=instance)
7000         finally:
7001             # always run this even if setup_networks_on_host fails
7002             # NOTE(vish): The mapping is passed in so the driver can disconnect
7003             #             from remote volumes if necessary
7004             block_device_info = self._get_instance_block_device_info(context,
7005                                                                      instance)
7006             self.driver.rollback_live_migration_at_destination(
7007                 context, instance, network_info, block_device_info,
7008                 destroy_disks=destroy_disks, migrate_data=migrate_data)
7009 
7010         self._notify_about_instance_usage(
7011                         context, instance, "live_migration.rollback.dest.end",
7012                         network_info=network_info)
7013         compute_utils.notify_about_instance_action(
7014             context, instance, self.host,
7015             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
7016             phase=fields.NotificationPhase.END)
7017 
7018     @periodic_task.periodic_task(
7019         spacing=CONF.heal_instance_info_cache_interval)
7020     def _heal_instance_info_cache(self, context):
7021         """Called periodically.  On every call, try to update the
7022         info_cache's network information for another instance by
7023         calling to the network manager.
7024 
7025         This is implemented by keeping a cache of uuids of instances
7026         that live on this host.  On each call, we pop one off of a
7027         list, pull the DB record, and try the call to the network API.
7028         If anything errors don't fail, as it's possible the instance
7029         has been deleted, etc.
7030         """
7031         heal_interval = CONF.heal_instance_info_cache_interval
7032         if not heal_interval:
7033             return
7034 
7035         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
7036         instance = None
7037 
7038         LOG.debug('Starting heal instance info cache')
7039 
7040         if not instance_uuids:
7041             # The list of instances to heal is empty so rebuild it
7042             LOG.debug('Rebuilding the list of instances to heal')
7043             db_instances = objects.InstanceList.get_by_host(
7044                 context, self.host, expected_attrs=[], use_slave=True)
7045             for inst in db_instances:
7046                 # We don't want to refresh the cache for instances
7047                 # which are building or deleting so don't put them
7048                 # in the list. If they are building they will get
7049                 # added to the list next time we build it.
7050                 if (inst.vm_state == vm_states.BUILDING):
7051                     LOG.debug('Skipping network cache update for instance '
7052                               'because it is Building.', instance=inst)
7053                     continue
7054                 if (inst.task_state == task_states.DELETING):
7055                     LOG.debug('Skipping network cache update for instance '
7056                               'because it is being deleted.', instance=inst)
7057                     continue
7058 
7059                 if not instance:
7060                     # Save the first one we find so we don't
7061                     # have to get it again
7062                     instance = inst
7063                 else:
7064                     instance_uuids.append(inst['uuid'])
7065 
7066             self._instance_uuids_to_heal = instance_uuids
7067         else:
7068             # Find the next valid instance on the list
7069             while instance_uuids:
7070                 try:
7071                     inst = objects.Instance.get_by_uuid(
7072                             context, instance_uuids.pop(0),
7073                             expected_attrs=['system_metadata', 'info_cache',
7074                                             'flavor'],
7075                             use_slave=True)
7076                 except exception.InstanceNotFound:
7077                     # Instance is gone.  Try to grab another.
7078                     continue
7079 
7080                 # Check the instance hasn't been migrated
7081                 if inst.host != self.host:
7082                     LOG.debug('Skipping network cache update for instance '
7083                               'because it has been migrated to another '
7084                               'host.', instance=inst)
7085                 # Check the instance isn't being deleting
7086                 elif inst.task_state == task_states.DELETING:
7087                     LOG.debug('Skipping network cache update for instance '
7088                               'because it is being deleted.', instance=inst)
7089                 else:
7090                     instance = inst
7091                     break
7092 
7093         if instance:
7094             # We have an instance now to refresh
7095             try:
7096                 # Call to network API to get instance info.. this will
7097                 # force an update to the instance's info_cache
7098                 self.network_api.get_instance_nw_info(
7099                     context, instance, force_refresh=True)
7100                 LOG.debug('Updated the network info_cache for instance',
7101                           instance=instance)
7102             except exception.InstanceNotFound:
7103                 # Instance is gone.
7104                 LOG.debug('Instance no longer exists. Unable to refresh',
7105                           instance=instance)
7106                 return
7107             except exception.InstanceInfoCacheNotFound:
7108                 # InstanceInfoCache is gone.
7109                 LOG.debug('InstanceInfoCache no longer exists. '
7110                           'Unable to refresh', instance=instance)
7111             except Exception:
7112                 LOG.error('An error occurred while refreshing the network '
7113                           'cache.', instance=instance, exc_info=True)
7114         else:
7115             LOG.debug("Didn't find any instances for network info cache "
7116                       "update.")
7117 
7118     @periodic_task.periodic_task
7119     def _poll_rebooting_instances(self, context):
7120         if CONF.reboot_timeout > 0:
7121             filters = {'task_state':
7122                        [task_states.REBOOTING,
7123                         task_states.REBOOT_STARTED,
7124                         task_states.REBOOT_PENDING],
7125                        'host': self.host}
7126             rebooting = objects.InstanceList.get_by_filters(
7127                 context, filters, expected_attrs=[], use_slave=True)
7128 
7129             to_poll = []
7130             for instance in rebooting:
7131                 if timeutils.is_older_than(instance.updated_at,
7132                                            CONF.reboot_timeout):
7133                     to_poll.append(instance)
7134 
7135             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
7136 
7137     @periodic_task.periodic_task
7138     def _poll_rescued_instances(self, context):
7139         if CONF.rescue_timeout > 0:
7140             filters = {'vm_state': vm_states.RESCUED,
7141                        'host': self.host}
7142             rescued_instances = objects.InstanceList.get_by_filters(
7143                 context, filters, expected_attrs=["system_metadata"],
7144                 use_slave=True)
7145 
7146             to_unrescue = []
7147             for instance in rescued_instances:
7148                 if timeutils.is_older_than(instance.launched_at,
7149                                            CONF.rescue_timeout):
7150                     to_unrescue.append(instance)
7151 
7152             for instance in to_unrescue:
7153                 self.compute_api.unrescue(context, instance)
7154 
7155     @periodic_task.periodic_task
7156     def _poll_unconfirmed_resizes(self, context):
7157         if CONF.resize_confirm_window == 0:
7158             return
7159 
7160         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
7161                 context, CONF.resize_confirm_window, self.host,
7162                 use_slave=True)
7163 
7164         migrations_info = dict(migration_count=len(migrations),
7165                 confirm_window=CONF.resize_confirm_window)
7166 
7167         if migrations_info["migration_count"] > 0:
7168             LOG.info("Found %(migration_count)d unconfirmed migrations "
7169                      "older than %(confirm_window)d seconds",
7170                      migrations_info)
7171 
7172         def _set_migration_to_error(migration, reason, **kwargs):
7173             LOG.warning("Setting migration %(migration_id)s to error: "
7174                         "%(reason)s",
7175                         {'migration_id': migration['id'], 'reason': reason},
7176                         **kwargs)
7177             migration.status = 'error'
7178             with migration.obj_as_admin():
7179                 migration.save()
7180 
7181         for migration in migrations:
7182             instance_uuid = migration.instance_uuid
7183             LOG.info("Automatically confirming migration "
7184                      "%(migration_id)s for instance %(instance_uuid)s",
7185                      {'migration_id': migration.id,
7186                       'instance_uuid': instance_uuid})
7187             expected_attrs = ['metadata', 'system_metadata']
7188             try:
7189                 instance = objects.Instance.get_by_uuid(context,
7190                             instance_uuid, expected_attrs=expected_attrs,
7191                             use_slave=True)
7192             except exception.InstanceNotFound:
7193                 reason = (_("Instance %s not found") %
7194                           instance_uuid)
7195                 _set_migration_to_error(migration, reason)
7196                 continue
7197             if instance.vm_state == vm_states.ERROR:
7198                 reason = _("In ERROR state")
7199                 _set_migration_to_error(migration, reason,
7200                                         instance=instance)
7201                 continue
7202             # race condition: The instance in DELETING state should not be
7203             # set the migration state to error, otherwise the instance in
7204             # to be deleted which is in RESIZED state
7205             # will not be able to confirm resize
7206             if instance.task_state in [task_states.DELETING,
7207                                        task_states.SOFT_DELETING]:
7208                 msg = ("Instance being deleted or soft deleted during resize "
7209                        "confirmation. Skipping.")
7210                 LOG.debug(msg, instance=instance)
7211                 continue
7212 
7213             # race condition: This condition is hit when this method is
7214             # called between the save of the migration record with a status of
7215             # finished and the save of the instance object with a state of
7216             # RESIZED. The migration record should not be set to error.
7217             if instance.task_state == task_states.RESIZE_FINISH:
7218                 msg = ("Instance still resizing during resize "
7219                        "confirmation. Skipping.")
7220                 LOG.debug(msg, instance=instance)
7221                 continue
7222 
7223             vm_state = instance.vm_state
7224             task_state = instance.task_state
7225             if vm_state != vm_states.RESIZED or task_state is not None:
7226                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
7227                            "RESIZED/None") %
7228                           {'vm_state': vm_state,
7229                            'task_state': task_state})
7230                 _set_migration_to_error(migration, reason,
7231                                         instance=instance)
7232                 continue
7233             try:
7234                 self.compute_api.confirm_resize(context, instance,
7235                                                 migration=migration)
7236             except Exception as e:
7237                 LOG.info("Error auto-confirming resize: %s. "
7238                          "Will retry later.", e, instance=instance)
7239 
7240     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
7241     def _poll_shelved_instances(self, context):
7242 
7243         if CONF.shelved_offload_time <= 0:
7244             return
7245 
7246         filters = {'vm_state': vm_states.SHELVED,
7247                    'task_state': None,
7248                    'host': self.host}
7249         shelved_instances = objects.InstanceList.get_by_filters(
7250             context, filters=filters, expected_attrs=['system_metadata'],
7251             use_slave=True)
7252 
7253         to_gc = []
7254         for instance in shelved_instances:
7255             sys_meta = instance.system_metadata
7256             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
7257             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
7258                 to_gc.append(instance)
7259 
7260         for instance in to_gc:
7261             try:
7262                 instance.task_state = task_states.SHELVING_OFFLOADING
7263                 instance.save(expected_task_state=(None,))
7264                 self.shelve_offload_instance(context, instance,
7265                                              clean_shutdown=False)
7266             except Exception:
7267                 LOG.exception('Periodic task failed to offload instance.',
7268                               instance=instance)
7269 
7270     @periodic_task.periodic_task
7271     def _instance_usage_audit(self, context):
7272         if not CONF.instance_usage_audit:
7273             return
7274 
7275         begin, end = utils.last_completed_audit_period()
7276         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
7277                                self.host):
7278             return
7279 
7280         instances = objects.InstanceList.get_active_by_window_joined(
7281             context, begin, end, host=self.host,
7282             expected_attrs=['system_metadata', 'info_cache', 'metadata',
7283                             'flavor'],
7284             use_slave=True)
7285         num_instances = len(instances)
7286         errors = 0
7287         successes = 0
7288         LOG.info("Running instance usage audit for host %(host)s "
7289                  "from %(begin_time)s to %(end_time)s. "
7290                  "%(number_instances)s instances.",
7291                  {'host': self.host,
7292                   'begin_time': begin,
7293                   'end_time': end,
7294                   'number_instances': num_instances})
7295         start_time = time.time()
7296         task_log = objects.TaskLog(context)
7297         task_log.task_name = 'instance_usage_audit'
7298         task_log.period_beginning = begin
7299         task_log.period_ending = end
7300         task_log.host = self.host
7301         task_log.task_items = num_instances
7302         task_log.message = 'Instance usage audit started...'
7303         task_log.begin_task()
7304         for instance in instances:
7305             try:
7306                 compute_utils.notify_usage_exists(
7307                     self.notifier, context, instance, self.host,
7308                     ignore_missing_network_data=False)
7309                 successes += 1
7310             except Exception:
7311                 LOG.exception('Failed to generate usage '
7312                               'audit for instance '
7313                               'on host %s', self.host,
7314                               instance=instance)
7315                 errors += 1
7316         task_log.errors = errors
7317         task_log.message = (
7318             'Instance usage audit ran for host %s, %s instances in %s seconds.'
7319             % (self.host, num_instances, time.time() - start_time))
7320         task_log.end_task()
7321 
7322     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
7323     def _poll_bandwidth_usage(self, context):
7324 
7325         if not self._bw_usage_supported:
7326             return
7327 
7328         prev_time, start_time = utils.last_completed_audit_period()
7329 
7330         curr_time = time.time()
7331         if (curr_time - self._last_bw_usage_poll >
7332                 CONF.bandwidth_poll_interval):
7333             self._last_bw_usage_poll = curr_time
7334             LOG.info("Updating bandwidth usage cache")
7335             cells_update_interval = CONF.cells.bandwidth_update_interval
7336             if (cells_update_interval > 0 and
7337                    curr_time - self._last_bw_usage_cell_update >
7338                            cells_update_interval):
7339                 self._last_bw_usage_cell_update = curr_time
7340                 update_cells = True
7341             else:
7342                 update_cells = False
7343 
7344             instances = objects.InstanceList.get_by_host(context,
7345                                                               self.host,
7346                                                               use_slave=True)
7347             try:
7348                 bw_counters = self.driver.get_all_bw_counters(instances)
7349             except NotImplementedError:
7350                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
7351                 # implemented yet.  If they don't it doesn't break anything,
7352                 # they just don't get the info in the usage events.
7353                 # NOTE(PhilDay): Record that its not supported so we can
7354                 # skip fast on future calls rather than waste effort getting
7355                 # the list of instances.
7356                 LOG.info("Bandwidth usage not supported by %(driver)s.",
7357                          {'driver': CONF.compute_driver})
7358                 self._bw_usage_supported = False
7359                 return
7360 
7361             refreshed = timeutils.utcnow()
7362             for bw_ctr in bw_counters:
7363                 # Allow switching of greenthreads between queries.
7364                 greenthread.sleep(0)
7365                 bw_in = 0
7366                 bw_out = 0
7367                 last_ctr_in = None
7368                 last_ctr_out = None
7369                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
7370                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
7371                     start_period=start_time, use_slave=True)
7372                 if usage:
7373                     bw_in = usage.bw_in
7374                     bw_out = usage.bw_out
7375                     last_ctr_in = usage.last_ctr_in
7376                     last_ctr_out = usage.last_ctr_out
7377                 else:
7378                     usage = (objects.BandwidthUsage.
7379                              get_by_instance_uuid_and_mac(
7380                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
7381                         start_period=prev_time, use_slave=True))
7382                     if usage:
7383                         last_ctr_in = usage.last_ctr_in
7384                         last_ctr_out = usage.last_ctr_out
7385 
7386                 if last_ctr_in is not None:
7387                     if bw_ctr['bw_in'] < last_ctr_in:
7388                         # counter rollover
7389                         bw_in += bw_ctr['bw_in']
7390                     else:
7391                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
7392 
7393                 if last_ctr_out is not None:
7394                     if bw_ctr['bw_out'] < last_ctr_out:
7395                         # counter rollover
7396                         bw_out += bw_ctr['bw_out']
7397                     else:
7398                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
7399 
7400                 objects.BandwidthUsage(context=context).create(
7401                                               bw_ctr['uuid'],
7402                                               bw_ctr['mac_address'],
7403                                               bw_in,
7404                                               bw_out,
7405                                               bw_ctr['bw_in'],
7406                                               bw_ctr['bw_out'],
7407                                               start_period=start_time,
7408                                               last_refreshed=refreshed,
7409                                               update_cells=update_cells)
7410 
7411     def _get_host_volume_bdms(self, context, use_slave=False):
7412         """Return all block device mappings on a compute host."""
7413         compute_host_bdms = []
7414         instances = objects.InstanceList.get_by_host(context, self.host,
7415             use_slave=use_slave)
7416         for instance in instances:
7417             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7418                     context, instance.uuid, use_slave=use_slave)
7419             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
7420             compute_host_bdms.append(dict(instance=instance,
7421                                           instance_bdms=instance_bdms))
7422 
7423         return compute_host_bdms
7424 
7425     def _update_volume_usage_cache(self, context, vol_usages):
7426         """Updates the volume usage cache table with a list of stats."""
7427         for usage in vol_usages:
7428             # Allow switching of greenthreads between queries.
7429             greenthread.sleep(0)
7430             vol_usage = objects.VolumeUsage(context)
7431             vol_usage.volume_id = usage['volume']
7432             vol_usage.instance_uuid = usage['instance'].uuid
7433             vol_usage.project_id = usage['instance'].project_id
7434             vol_usage.user_id = usage['instance'].user_id
7435             vol_usage.availability_zone = usage['instance'].availability_zone
7436             vol_usage.curr_reads = usage['rd_req']
7437             vol_usage.curr_read_bytes = usage['rd_bytes']
7438             vol_usage.curr_writes = usage['wr_req']
7439             vol_usage.curr_write_bytes = usage['wr_bytes']
7440             vol_usage.save()
7441             self.notifier.info(context, 'volume.usage', vol_usage.to_dict())
7442             compute_utils.notify_about_volume_usage(context, vol_usage,
7443                                                     self.host)
7444 
7445     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
7446     def _poll_volume_usage(self, context):
7447         if CONF.volume_usage_poll_interval == 0:
7448             return
7449 
7450         compute_host_bdms = self._get_host_volume_bdms(context,
7451                                                        use_slave=True)
7452         if not compute_host_bdms:
7453             return
7454 
7455         LOG.debug("Updating volume usage cache")
7456         try:
7457             vol_usages = self.driver.get_all_volume_usage(context,
7458                                                           compute_host_bdms)
7459         except NotImplementedError:
7460             return
7461 
7462         self._update_volume_usage_cache(context, vol_usages)
7463 
7464     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
7465                                  run_immediately=True)
7466     def _sync_power_states(self, context):
7467         """Align power states between the database and the hypervisor.
7468 
7469         To sync power state data we make a DB call to get the number of
7470         virtual machines known by the hypervisor and if the number matches the
7471         number of virtual machines known by the database, we proceed in a lazy
7472         loop, one database record at a time, checking if the hypervisor has the
7473         same power state as is in the database.
7474         """
7475         db_instances = objects.InstanceList.get_by_host(context, self.host,
7476                                                         expected_attrs=[],
7477                                                         use_slave=True)
7478 
7479         try:
7480             num_vm_instances = self.driver.get_num_instances()
7481         except exception.VirtDriverNotReady as e:
7482             # If the virt driver is not ready, like ironic-api not being up
7483             # yet in the case of ironic, just log it and exit.
7484             LOG.info('Skipping _sync_power_states periodic task due to: %s', e)
7485             return
7486 
7487         num_db_instances = len(db_instances)
7488 
7489         if num_vm_instances != num_db_instances:
7490             LOG.warning("While synchronizing instance power states, found "
7491                         "%(num_db_instances)s instances in the database "
7492                         "and %(num_vm_instances)s instances on the "
7493                         "hypervisor.",
7494                         {'num_db_instances': num_db_instances,
7495                          'num_vm_instances': num_vm_instances})
7496 
7497         def _sync(db_instance):
7498             # NOTE(melwitt): This must be synchronized as we query state from
7499             #                two separate sources, the driver and the database.
7500             #                They are set (in stop_instance) and read, in sync.
7501             @utils.synchronized(db_instance.uuid)
7502             def query_driver_power_state_and_sync():
7503                 self._query_driver_power_state_and_sync(context, db_instance)
7504 
7505             try:
7506                 query_driver_power_state_and_sync()
7507             except Exception:
7508                 LOG.exception("Periodic sync_power_state task had an "
7509                               "error while processing an instance.",
7510                               instance=db_instance)
7511 
7512             self._syncs_in_progress.pop(db_instance.uuid)
7513 
7514         for db_instance in db_instances:
7515             # process syncs asynchronously - don't want instance locking to
7516             # block entire periodic task thread
7517             uuid = db_instance.uuid
7518             if uuid in self._syncs_in_progress:
7519                 LOG.debug('Sync already in progress for %s', uuid)
7520             else:
7521                 LOG.debug('Triggering sync for uuid %s', uuid)
7522                 self._syncs_in_progress[uuid] = True
7523                 self._sync_power_pool.spawn_n(_sync, db_instance)
7524 
7525     def _query_driver_power_state_and_sync(self, context, db_instance):
7526         if db_instance.task_state is not None:
7527             LOG.info("During sync_power_state the instance has a "
7528                      "pending task (%(task)s). Skip.",
7529                      {'task': db_instance.task_state}, instance=db_instance)
7530             return
7531         # No pending tasks. Now try to figure out the real vm_power_state.
7532         try:
7533             vm_instance = self.driver.get_info(db_instance)
7534             vm_power_state = vm_instance.state
7535         except exception.InstanceNotFound:
7536             vm_power_state = power_state.NOSTATE
7537         # Note(maoy): the above get_info call might take a long time,
7538         # for example, because of a broken libvirt driver.
7539         try:
7540             self._sync_instance_power_state(context,
7541                                             db_instance,
7542                                             vm_power_state,
7543                                             use_slave=True)
7544         except exception.InstanceNotFound:
7545             # NOTE(hanlind): If the instance gets deleted during sync,
7546             # silently ignore.
7547             pass
7548 
7549     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
7550                                    use_slave=False):
7551         """Align instance power state between the database and hypervisor.
7552 
7553         If the instance is not found on the hypervisor, but is in the database,
7554         then a stop() API will be called on the instance.
7555         """
7556 
7557         # We re-query the DB to get the latest instance info to minimize
7558         # (not eliminate) race condition.
7559         db_instance.refresh(use_slave=use_slave)
7560         db_power_state = db_instance.power_state
7561         vm_state = db_instance.vm_state
7562 
7563         if self.host != db_instance.host:
7564             # on the sending end of nova-compute _sync_power_state
7565             # may have yielded to the greenthread performing a live
7566             # migration; this in turn has changed the resident-host
7567             # for the VM; However, the instance is still active, it
7568             # is just in the process of migrating to another host.
7569             # This implies that the compute source must relinquish
7570             # control to the compute destination.
7571             LOG.info("During the sync_power process the "
7572                      "instance has moved from "
7573                      "host %(src)s to host %(dst)s",
7574                      {'src': db_instance.host,
7575                       'dst': self.host},
7576                      instance=db_instance)
7577             return
7578         elif db_instance.task_state is not None:
7579             # on the receiving end of nova-compute, it could happen
7580             # that the DB instance already report the new resident
7581             # but the actual VM has not showed up on the hypervisor
7582             # yet. In this case, let's allow the loop to continue
7583             # and run the state sync in a later round
7584             LOG.info("During sync_power_state the instance has a "
7585                      "pending task (%(task)s). Skip.",
7586                      {'task': db_instance.task_state},
7587                      instance=db_instance)
7588             return
7589 
7590         orig_db_power_state = db_power_state
7591         if vm_power_state != db_power_state:
7592             LOG.info('During _sync_instance_power_state the DB '
7593                      'power_state (%(db_power_state)s) does not match '
7594                      'the vm_power_state from the hypervisor '
7595                      '(%(vm_power_state)s). Updating power_state in the '
7596                      'DB to match the hypervisor.',
7597                      {'db_power_state': db_power_state,
7598                       'vm_power_state': vm_power_state},
7599                      instance=db_instance)
7600             # power_state is always updated from hypervisor to db
7601             db_instance.power_state = vm_power_state
7602             db_instance.save()
7603             db_power_state = vm_power_state
7604 
7605         # Note(maoy): Now resolve the discrepancy between vm_state and
7606         # vm_power_state. We go through all possible vm_states.
7607         if vm_state in (vm_states.BUILDING,
7608                         vm_states.RESCUED,
7609                         vm_states.RESIZED,
7610                         vm_states.SUSPENDED,
7611                         vm_states.ERROR):
7612             # TODO(maoy): we ignore these vm_state for now.
7613             pass
7614         elif vm_state == vm_states.ACTIVE:
7615             # The only rational power state should be RUNNING
7616             if vm_power_state in (power_state.SHUTDOWN,
7617                                   power_state.CRASHED):
7618                 LOG.warning("Instance shutdown by itself. Calling the "
7619                             "stop API. Current vm_state: %(vm_state)s, "
7620                             "current task_state: %(task_state)s, "
7621                             "original DB power_state: %(db_power_state)s, "
7622                             "current VM power_state: %(vm_power_state)s",
7623                             {'vm_state': vm_state,
7624                              'task_state': db_instance.task_state,
7625                              'db_power_state': orig_db_power_state,
7626                              'vm_power_state': vm_power_state},
7627                             instance=db_instance)
7628                 try:
7629                     # Note(maoy): here we call the API instead of
7630                     # brutally updating the vm_state in the database
7631                     # to allow all the hooks and checks to be performed.
7632                     if db_instance.shutdown_terminate:
7633                         self.compute_api.delete(context, db_instance)
7634                     else:
7635                         self.compute_api.stop(context, db_instance)
7636                 except Exception:
7637                     # Note(maoy): there is no need to propagate the error
7638                     # because the same power_state will be retrieved next
7639                     # time and retried.
7640                     # For example, there might be another task scheduled.
7641                     LOG.exception("error during stop() in sync_power_state.",
7642                                   instance=db_instance)
7643             elif vm_power_state == power_state.SUSPENDED:
7644                 LOG.warning("Instance is suspended unexpectedly. Calling "
7645                             "the stop API.", instance=db_instance)
7646                 try:
7647                     self.compute_api.stop(context, db_instance)
7648                 except Exception:
7649                     LOG.exception("error during stop() in sync_power_state.",
7650                                   instance=db_instance)
7651             elif vm_power_state == power_state.PAUSED:
7652                 # Note(maoy): a VM may get into the paused state not only
7653                 # because the user request via API calls, but also
7654                 # due to (temporary) external instrumentations.
7655                 # Before the virt layer can reliably report the reason,
7656                 # we simply ignore the state discrepancy. In many cases,
7657                 # the VM state will go back to running after the external
7658                 # instrumentation is done. See bug 1097806 for details.
7659                 LOG.warning("Instance is paused unexpectedly. Ignore.",
7660                             instance=db_instance)
7661             elif vm_power_state == power_state.NOSTATE:
7662                 # Occasionally, depending on the status of the hypervisor,
7663                 # which could be restarting for example, an instance may
7664                 # not be found.  Therefore just log the condition.
7665                 LOG.warning("Instance is unexpectedly not found. Ignore.",
7666                             instance=db_instance)
7667         elif vm_state == vm_states.STOPPED:
7668             if vm_power_state not in (power_state.NOSTATE,
7669                                       power_state.SHUTDOWN,
7670                                       power_state.CRASHED):
7671                 LOG.warning("Instance is not stopped. Calling "
7672                             "the stop API. Current vm_state: %(vm_state)s,"
7673                             " current task_state: %(task_state)s, "
7674                             "original DB power_state: %(db_power_state)s, "
7675                             "current VM power_state: %(vm_power_state)s",
7676                             {'vm_state': vm_state,
7677                              'task_state': db_instance.task_state,
7678                              'db_power_state': orig_db_power_state,
7679                              'vm_power_state': vm_power_state},
7680                             instance=db_instance)
7681                 try:
7682                     # NOTE(russellb) Force the stop, because normally the
7683                     # compute API would not allow an attempt to stop a stopped
7684                     # instance.
7685                     self.compute_api.force_stop(context, db_instance)
7686                 except Exception:
7687                     LOG.exception("error during stop() in sync_power_state.",
7688                                   instance=db_instance)
7689         elif vm_state == vm_states.PAUSED:
7690             if vm_power_state in (power_state.SHUTDOWN,
7691                                   power_state.CRASHED):
7692                 LOG.warning("Paused instance shutdown by itself. Calling "
7693                             "the stop API.", instance=db_instance)
7694                 try:
7695                     self.compute_api.force_stop(context, db_instance)
7696                 except Exception:
7697                     LOG.exception("error during stop() in sync_power_state.",
7698                                   instance=db_instance)
7699         elif vm_state in (vm_states.SOFT_DELETED,
7700                           vm_states.DELETED):
7701             if vm_power_state not in (power_state.NOSTATE,
7702                                       power_state.SHUTDOWN):
7703                 # Note(maoy): this should be taken care of periodically in
7704                 # _cleanup_running_deleted_instances().
7705                 LOG.warning("Instance is not (soft-)deleted.",
7706                             instance=db_instance)
7707 
7708     @periodic_task.periodic_task
7709     def _reclaim_queued_deletes(self, context):
7710         """Reclaim instances that are queued for deletion."""
7711         interval = CONF.reclaim_instance_interval
7712         if interval <= 0:
7713             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
7714             return
7715 
7716         filters = {'vm_state': vm_states.SOFT_DELETED,
7717                    'task_state': None,
7718                    'host': self.host}
7719         instances = objects.InstanceList.get_by_filters(
7720             context, filters,
7721             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
7722             use_slave=True)
7723         for instance in instances:
7724             if self._deleted_old_enough(instance, interval):
7725                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7726                         context, instance.uuid)
7727                 LOG.info('Reclaiming deleted instance', instance=instance)
7728                 try:
7729                     self._delete_instance(context, instance, bdms)
7730                 except Exception as e:
7731                     LOG.warning("Periodic reclaim failed to delete "
7732                                 "instance: %s",
7733                                 e, instance=instance)
7734 
7735     def _get_nodename(self, instance, refresh=False):
7736         """Helper method to get the name of the first available node
7737         on this host. This method should not be used with any operations
7738         on ironic instances since it does not handle multiple nodes.
7739         """
7740         node = self.driver.get_available_nodes(refresh=refresh)[0]
7741         LOG.debug("No node specified, defaulting to %s", node,
7742                   instance=instance)
7743         return node
7744 
7745     def _update_available_resource_for_node(self, context, nodename,
7746                                             startup=False):
7747 
7748         try:
7749             self.rt.update_available_resource(context, nodename,
7750                                               startup=startup)
7751         except exception.ComputeHostNotFound:
7752             LOG.warning("Compute node '%s' not found in "
7753                         "update_available_resource.", nodename)
7754         except exception.ReshapeFailed:
7755             # We're only supposed to get here on startup, if a reshape was
7756             # needed, was attempted, and failed. We want to kill the service.
7757             with excutils.save_and_reraise_exception():
7758                 LOG.critical("Resource provider data migration failed "
7759                              "fatally during startup for node %s.", nodename)
7760         except exception.ReshapeNeeded:
7761             # This exception should only find its way here if the virt driver's
7762             # update_provider_tree raised it incorrectly: either
7763             # a) After the resource tracker already caught it once and
7764             # reinvoked update_provider_tree with allocations. At this point
7765             # the driver is just supposed to *do* the reshape, so if it raises
7766             # ReshapeNeeded, it's a bug, and we want to kill the compute
7767             # service.
7768             # b) On periodic rather than startup (we only allow reshapes to
7769             # happen on startup). In this case we'll just make the logs red and
7770             # go again at the next periodic interval, where the same thing may
7771             # or may not happen again. Depending on the previous and intended
7772             # shape of the providers/inventories, this may not actually cause
7773             # any immediately visible symptoms (in terms of scheduling, etc.)
7774             # If this becomes a problem, we may wish to make it pop immediately
7775             # (e.g. disable the service).
7776             with excutils.save_and_reraise_exception():
7777                 LOG.exception("ReshapeNeeded exception is unexpected here!")
7778         except Exception:
7779             LOG.exception("Error updating resources for node %(node)s.",
7780                           {'node': nodename})
7781 
7782     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
7783     def update_available_resource(self, context, startup=False):
7784         """See driver.get_available_resource()
7785 
7786         Periodic process that keeps that the compute host's understanding of
7787         resource availability and usage in sync with the underlying hypervisor.
7788 
7789         :param context: security context
7790         :param startup: True if this is being called when the nova-compute
7791             service is starting, False otherwise.
7792         """
7793 
7794         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
7795                                                             use_slave=True,
7796                                                             startup=startup)
7797         try:
7798             nodenames = set(self.driver.get_available_nodes())
7799         except exception.VirtDriverNotReady:
7800             LOG.warning("Virt driver is not ready.")
7801             return
7802 
7803         # Delete orphan compute node not reported by driver but still in db
7804         for cn in compute_nodes_in_db:
7805             if cn.hypervisor_hostname not in nodenames:
7806                 LOG.info("Deleting orphan compute node %(id)s "
7807                          "hypervisor host is %(hh)s, "
7808                          "nodes are %(nodes)s",
7809                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
7810                           'nodes': nodenames})
7811                 cn.destroy()
7812                 self.rt.remove_node(cn.hypervisor_hostname)
7813                 # Delete the corresponding resource provider in placement,
7814                 # along with any associated allocations and inventory.
7815                 self.reportclient.delete_resource_provider(context, cn,
7816                                                            cascade=True)
7817 
7818         for nodename in nodenames:
7819             self._update_available_resource_for_node(context, nodename,
7820                                                      startup=startup)
7821 
7822     def _get_compute_nodes_in_db(self, context, use_slave=False,
7823                                  startup=False):
7824         try:
7825             return objects.ComputeNodeList.get_all_by_host(context, self.host,
7826                                                            use_slave=use_slave)
7827         except exception.NotFound:
7828             if startup:
7829                 LOG.warning(
7830                     "No compute node record found for host %s. If this is "
7831                     "the first time this service is starting on this "
7832                     "host, then you can ignore this warning.", self.host)
7833             else:
7834                 LOG.error("No compute node record for host %s", self.host)
7835             return []
7836 
7837     @periodic_task.periodic_task(
7838         spacing=CONF.running_deleted_instance_poll_interval)
7839     def _cleanup_running_deleted_instances(self, context):
7840         """Cleanup any instances which are erroneously still running after
7841         having been deleted.
7842 
7843         Valid actions to take are:
7844 
7845             1. noop - do nothing
7846             2. log - log which instances are erroneously running
7847             3. reap - shutdown and cleanup any erroneously running instances
7848             4. shutdown - power off *and disable* any erroneously running
7849                           instances
7850 
7851         The use-case for this cleanup task is: for various reasons, it may be
7852         possible for the database to show an instance as deleted but for that
7853         instance to still be running on a host machine (see bug
7854         https://bugs.launchpad.net/nova/+bug/911366).
7855 
7856         This cleanup task is a cross-hypervisor utility for finding these
7857         zombied instances and either logging the discrepancy (likely what you
7858         should do in production), or automatically reaping the instances (more
7859         appropriate for dev environments).
7860         """
7861         action = CONF.running_deleted_instance_action
7862 
7863         if action == "noop":
7864             return
7865 
7866         # NOTE(sirp): admin contexts don't ordinarily return deleted records
7867         with utils.temporary_mutation(context, read_deleted="yes"):
7868             for instance in self._running_deleted_instances(context):
7869                 if action == "log":
7870                     LOG.warning("Detected instance with name label "
7871                                 "'%s' which is marked as "
7872                                 "DELETED but still present on host.",
7873                                 instance.name, instance=instance)
7874 
7875                 elif action == 'shutdown':
7876                     LOG.info("Powering off instance with name label "
7877                              "'%s' which is marked as "
7878                              "DELETED but still present on host.",
7879                              instance.name, instance=instance)
7880                     try:
7881                         try:
7882                             # disable starting the instance
7883                             self.driver.set_bootable(instance, False)
7884                         except NotImplementedError:
7885                             LOG.debug("set_bootable is not implemented "
7886                                       "for the current driver")
7887                         # and power it off
7888                         self.driver.power_off(instance)
7889                     except Exception:
7890                         LOG.warning("Failed to power off instance",
7891                                     instance=instance, exc_info=True)
7892 
7893                 elif action == 'reap':
7894                     LOG.info("Destroying instance with name label "
7895                              "'%s' which is marked as "
7896                              "DELETED but still present on host.",
7897                              instance.name, instance=instance)
7898                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7899                         context, instance.uuid, use_slave=True)
7900                     self.instance_events.clear_events_for_instance(instance)
7901                     try:
7902                         self._shutdown_instance(context, instance, bdms,
7903                                                 notify=False)
7904                         self._cleanup_volumes(context, instance, bdms,
7905                                               detach=False)
7906                     except Exception as e:
7907                         LOG.warning("Periodic cleanup failed to delete "
7908                                     "instance: %s",
7909                                     e, instance=instance)
7910                 else:
7911                     raise Exception(_("Unrecognized value '%s'"
7912                                       " for CONF.running_deleted_"
7913                                       "instance_action") % action)
7914 
7915     def _running_deleted_instances(self, context):
7916         """Returns a list of instances nova thinks is deleted,
7917         but the hypervisor thinks is still running.
7918         """
7919         timeout = CONF.running_deleted_instance_timeout
7920         filters = {'deleted': True,
7921                    'soft_deleted': False}
7922         instances = self._get_instances_on_driver(context, filters)
7923         return [i for i in instances if self._deleted_old_enough(i, timeout)]
7924 
7925     def _deleted_old_enough(self, instance, timeout):
7926         deleted_at = instance.deleted_at
7927         if deleted_at:
7928             deleted_at = deleted_at.replace(tzinfo=None)
7929         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
7930 
7931     @contextlib.contextmanager
7932     def _error_out_instance_on_exception(self, context, instance,
7933                                          instance_state=vm_states.ACTIVE):
7934         instance_uuid = instance.uuid
7935         try:
7936             yield
7937         except NotImplementedError as error:
7938             with excutils.save_and_reraise_exception():
7939                 LOG.info("Setting instance back to %(state)s after: "
7940                          "%(error)s",
7941                          {'state': instance_state, 'error': error},
7942                          instance_uuid=instance_uuid)
7943                 self._instance_update(context, instance,
7944                                       vm_state=instance_state,
7945                                       task_state=None)
7946         except exception.InstanceFaultRollback as error:
7947             LOG.info("Setting instance back to ACTIVE after: %s",
7948                      error, instance_uuid=instance_uuid)
7949             self._instance_update(context, instance,
7950                                   vm_state=vm_states.ACTIVE,
7951                                   task_state=None)
7952             raise error.inner_exception
7953         except Exception:
7954             LOG.exception('Setting instance vm_state to ERROR',
7955                           instance_uuid=instance_uuid)
7956             with excutils.save_and_reraise_exception():
7957                 self._set_instance_obj_error_state(context, instance)
7958 
7959     @wrap_exception()
7960     def add_aggregate_host(self, context, aggregate, host, slave_info):
7961         """Notify hypervisor of change (for hypervisor pools)."""
7962         try:
7963             self.driver.add_to_aggregate(context, aggregate, host,
7964                                          slave_info=slave_info)
7965         except NotImplementedError:
7966             LOG.debug('Hypervisor driver does not support '
7967                       'add_aggregate_host')
7968         except exception.AggregateError:
7969             with excutils.save_and_reraise_exception():
7970                 self.driver.undo_aggregate_operation(
7971                                     context,
7972                                     aggregate.delete_host,
7973                                     aggregate, host)
7974 
7975     @wrap_exception()
7976     def remove_aggregate_host(self, context, host, slave_info, aggregate):
7977         """Removes a host from a physical hypervisor pool."""
7978         try:
7979             self.driver.remove_from_aggregate(context, aggregate, host,
7980                                               slave_info=slave_info)
7981         except NotImplementedError:
7982             LOG.debug('Hypervisor driver does not support '
7983                       'remove_aggregate_host')
7984         except (exception.AggregateError,
7985                 exception.InvalidAggregateAction) as e:
7986             with excutils.save_and_reraise_exception():
7987                 self.driver.undo_aggregate_operation(
7988                                     context,
7989                                     aggregate.add_host,
7990                                     aggregate, host,
7991                                     isinstance(e, exception.AggregateError))
7992 
7993     def _process_instance_event(self, instance, event):
7994         _event = self.instance_events.pop_instance_event(instance, event)
7995         if _event:
7996             LOG.debug('Processing event %(event)s',
7997                       {'event': event.key}, instance=instance)
7998             _event.send(event)
7999         else:
8000             # If it's a network-vif-unplugged event and the instance is being
8001             # deleted then we don't need to make this a warning as it's
8002             # expected. There are other things which could trigger this like
8003             # detaching an interface, but we don't have a task state for that.
8004             if (event.name == 'network-vif-unplugged' and
8005                     instance.task_state == task_states.DELETING):
8006                 LOG.debug('Received event %s for instance which is being '
8007                           'deleted.', event.key, instance=instance)
8008             else:
8009                 LOG.warning('Received unexpected event %(event)s for '
8010                             'instance with vm_state %(vm_state)s and '
8011                             'task_state %(task_state)s.',
8012                             {'event': event.key,
8013                              'vm_state': instance.vm_state,
8014                              'task_state': instance.task_state},
8015                             instance=instance)
8016 
8017     def _process_instance_vif_deleted_event(self, context, instance,
8018                                             deleted_vif_id):
8019         # If an attached port is deleted by neutron, it needs to
8020         # be detached from the instance.
8021         # And info cache needs to be updated.
8022         network_info = instance.info_cache.network_info
8023         for index, vif in enumerate(network_info):
8024             if vif['id'] == deleted_vif_id:
8025                 LOG.info('Neutron deleted interface %(intf)s; '
8026                          'detaching it from the instance and '
8027                          'deleting it from the info cache',
8028                          {'intf': vif['id']},
8029                          instance=instance)
8030                 del network_info[index]
8031                 base_net_api.update_instance_cache_with_nw_info(
8032                                  self.network_api, context,
8033                                  instance,
8034                                  nw_info=network_info)
8035                 try:
8036                     self.driver.detach_interface(context, instance, vif)
8037                 except NotImplementedError:
8038                     # Not all virt drivers support attach/detach of interfaces
8039                     # yet (like Ironic), so just ignore this.
8040                     pass
8041                 except exception.NovaException as ex:
8042                     # If the instance was deleted before the interface was
8043                     # detached, just log it at debug.
8044                     log_level = (logging.DEBUG
8045                                  if isinstance(ex, exception.InstanceNotFound)
8046                                  else logging.WARNING)
8047                     LOG.log(log_level,
8048                             "Detach interface failed, "
8049                             "port_id=%(port_id)s, reason: %(msg)s",
8050                             {'port_id': deleted_vif_id, 'msg': ex},
8051                             instance=instance)
8052                 break
8053 
8054     @wrap_instance_event(prefix='compute')
8055     @wrap_instance_fault
8056     def extend_volume(self, context, instance, extended_volume_id):
8057 
8058         # If an attached volume is extended by cinder, it needs to
8059         # be extended by virt driver so host can detect its new size.
8060         # And bdm needs to be updated.
8061         LOG.debug('Handling volume-extended event for volume %(vol)s',
8062                   {'vol': extended_volume_id}, instance=instance)
8063 
8064         try:
8065             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
8066                    context, extended_volume_id, instance.uuid)
8067         except exception.NotFound:
8068             LOG.warning('Extend volume failed, '
8069                         'volume %(vol)s is not attached to instance.',
8070                         {'vol': extended_volume_id},
8071                         instance=instance)
8072             return
8073 
8074         LOG.info('Cinder extended volume %(vol)s; '
8075                  'extending it to detect new size',
8076                  {'vol': extended_volume_id},
8077                  instance=instance)
8078         volume = self.volume_api.get(context, bdm.volume_id)
8079 
8080         if bdm.connection_info is None:
8081             LOG.warning('Extend volume failed, '
8082                         'attached volume %(vol)s has no connection_info',
8083                         {'vol': extended_volume_id},
8084                         instance=instance)
8085             return
8086 
8087         connection_info = jsonutils.loads(bdm.connection_info)
8088         bdm.volume_size = volume['size']
8089         bdm.save()
8090 
8091         if not self.driver.capabilities.get('supports_extend_volume', False):
8092             raise exception.ExtendVolumeNotSupported()
8093 
8094         try:
8095             self.driver.extend_volume(connection_info,
8096                                       instance)
8097         except Exception as ex:
8098             LOG.warning('Extend volume failed, '
8099                         'volume_id=%(volume_id)s, reason: %(msg)s',
8100                         {'volume_id': extended_volume_id, 'msg': ex},
8101                         instance=instance)
8102             raise
8103 
8104     @wrap_exception()
8105     def external_instance_event(self, context, instances, events):
8106         # NOTE(danms): Some event types are handled by the manager, such
8107         # as when we're asked to update the instance's info_cache. If it's
8108         # not one of those, look for some thread(s) waiting for the event and
8109         # unblock them if so.
8110         for event in events:
8111             instance = [inst for inst in instances
8112                         if inst.uuid == event.instance_uuid][0]
8113             LOG.debug('Received event %(event)s',
8114                       {'event': event.key},
8115                       instance=instance)
8116             if event.name == 'network-changed':
8117                 try:
8118                     LOG.debug('Refreshing instance network info cache due to '
8119                               'event %s.', event.key, instance=instance)
8120                     self.network_api.get_instance_nw_info(
8121                         context, instance, refresh_vif_id=event.tag)
8122                 except exception.NotFound as e:
8123                     LOG.info('Failed to process external instance event '
8124                              '%(event)s due to: %(error)s',
8125                              {'event': event.key, 'error': six.text_type(e)},
8126                              instance=instance)
8127             elif event.name == 'network-vif-deleted':
8128                 try:
8129                     self._process_instance_vif_deleted_event(context,
8130                                                              instance,
8131                                                              event.tag)
8132                 except exception.NotFound as e:
8133                     LOG.info('Failed to process external instance event '
8134                              '%(event)s due to: %(error)s',
8135                              {'event': event.key, 'error': six.text_type(e)},
8136                              instance=instance)
8137             elif event.name == 'volume-extended':
8138                 self.extend_volume(context, instance, event.tag)
8139             else:
8140                 self._process_instance_event(instance, event)
8141 
8142     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
8143                                  external_process_ok=True)
8144     def _run_image_cache_manager_pass(self, context):
8145         """Run a single pass of the image cache manager."""
8146 
8147         if not self.driver.capabilities.get("has_imagecache", False):
8148             return
8149 
8150         # Determine what other nodes use this storage
8151         storage_users.register_storage_use(CONF.instances_path, CONF.host)
8152         nodes = storage_users.get_storage_users(CONF.instances_path)
8153 
8154         # Filter all_instances to only include those nodes which share this
8155         # storage path.
8156         # TODO(mikal): this should be further refactored so that the cache
8157         # cleanup code doesn't know what those instances are, just a remote
8158         # count, and then this logic should be pushed up the stack.
8159         filters = {'deleted': False,
8160                    'soft_deleted': True,
8161                    'host': nodes}
8162         filtered_instances = objects.InstanceList.get_by_filters(context,
8163                                  filters, expected_attrs=[], use_slave=True)
8164 
8165         self.driver.manage_image_cache(context, filtered_instances)
8166 
8167     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8168     def _run_pending_deletes(self, context):
8169         """Retry any pending instance file deletes."""
8170         LOG.debug('Cleaning up deleted instances')
8171         filters = {'deleted': True,
8172                    'soft_deleted': False,
8173                    'host': CONF.host,
8174                    'cleaned': False}
8175         attrs = ['system_metadata']
8176         with utils.temporary_mutation(context, read_deleted='yes'):
8177             instances = objects.InstanceList.get_by_filters(
8178                 context, filters, expected_attrs=attrs, use_slave=True)
8179         LOG.debug('There are %d instances to clean', len(instances))
8180 
8181         for instance in instances:
8182             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
8183             LOG.debug('Instance has had %(attempts)s of %(max)s '
8184                       'cleanup attempts',
8185                       {'attempts': attempts,
8186                        'max': CONF.maximum_instance_delete_attempts},
8187                       instance=instance)
8188             if attempts < CONF.maximum_instance_delete_attempts:
8189                 success = self.driver.delete_instance_files(instance)
8190 
8191                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
8192                 if success:
8193                     instance.cleaned = True
8194                 with utils.temporary_mutation(context, read_deleted='yes'):
8195                     instance.save()
8196 
8197     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8198     def _cleanup_incomplete_migrations(self, context):
8199         """Delete instance files on failed resize/revert-resize operation
8200 
8201         During resize/revert-resize operation, if that instance gets deleted
8202         in-between then instance files might remain either on source or
8203         destination compute node because of race condition.
8204         """
8205         LOG.debug('Cleaning up deleted instances with incomplete migration ')
8206         migration_filters = {'host': CONF.host,
8207                              'status': 'error'}
8208         migrations = objects.MigrationList.get_by_filters(context,
8209                                                           migration_filters)
8210 
8211         if not migrations:
8212             return
8213 
8214         inst_uuid_from_migrations = set([migration.instance_uuid for migration
8215                                          in migrations])
8216 
8217         inst_filters = {'deleted': True, 'soft_deleted': False,
8218                         'uuid': inst_uuid_from_migrations}
8219         attrs = ['info_cache', 'security_groups', 'system_metadata']
8220         with utils.temporary_mutation(context, read_deleted='yes'):
8221             instances = objects.InstanceList.get_by_filters(
8222                 context, inst_filters, expected_attrs=attrs, use_slave=True)
8223 
8224         for instance in instances:
8225             if instance.host != CONF.host:
8226                 for migration in migrations:
8227                     if instance.uuid == migration.instance_uuid:
8228                         # Delete instance files if not cleanup properly either
8229                         # from the source or destination compute nodes when
8230                         # the instance is deleted during resizing.
8231                         self.driver.delete_instance_files(instance)
8232                         try:
8233                             migration.status = 'failed'
8234                             with migration.obj_as_admin():
8235                                 migration.save()
8236                         except exception.MigrationNotFound:
8237                             LOG.warning("Migration %s is not found.",
8238                                         migration.id,
8239                                         instance=instance)
8240                         break
8241 
8242     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8243                                    exception.QemuGuestAgentNotEnabled,
8244                                    exception.NovaException,
8245                                    NotImplementedError)
8246     @wrap_exception()
8247     def quiesce_instance(self, context, instance):
8248         """Quiesce an instance on this host."""
8249         context = context.elevated()
8250         image_meta = objects.ImageMeta.from_instance(instance)
8251         self.driver.quiesce(context, instance, image_meta)
8252 
8253     def _wait_for_snapshots_completion(self, context, mapping):
8254         for mapping_dict in mapping:
8255             if mapping_dict.get('source_type') == 'snapshot':
8256 
8257                 def _wait_snapshot():
8258                     snapshot = self.volume_api.get_snapshot(
8259                         context, mapping_dict['snapshot_id'])
8260                     if snapshot.get('status') != 'creating':
8261                         raise loopingcall.LoopingCallDone()
8262 
8263                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
8264                 timer.start(interval=0.5).wait()
8265 
8266     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8267                                    exception.QemuGuestAgentNotEnabled,
8268                                    exception.NovaException,
8269                                    NotImplementedError)
8270     @wrap_exception()
8271     def unquiesce_instance(self, context, instance, mapping=None):
8272         """Unquiesce an instance on this host.
8273 
8274         If snapshots' image mapping is provided, it waits until snapshots are
8275         completed before unqueiscing.
8276         """
8277         context = context.elevated()
8278         if mapping:
8279             try:
8280                 self._wait_for_snapshots_completion(context, mapping)
8281             except Exception as error:
8282                 LOG.exception("Exception while waiting completion of "
8283                               "volume snapshots: %s",
8284                               error, instance=instance)
8285         image_meta = objects.ImageMeta.from_instance(instance)
8286         self.driver.unquiesce(context, instance, image_meta)
8287 
8288     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8289     def _cleanup_expired_console_auth_tokens(self, context):
8290         """Remove expired console auth tokens for this host.
8291 
8292         Console authorization tokens and their connection data are stored
8293         in the database when a user asks for a console connection to an
8294         instance. After a time they expire. We periodically remove any expired
8295         tokens from the database.
8296         """
8297         # If the database backend isn't in use, don't bother looking for
8298         # expired tokens. The database backend is not supported for cells v1.
8299         if not CONF.cells.enable:
8300             objects.ConsoleAuthToken.\
8301                 clean_expired_console_auths_for_host(context, self.host)
