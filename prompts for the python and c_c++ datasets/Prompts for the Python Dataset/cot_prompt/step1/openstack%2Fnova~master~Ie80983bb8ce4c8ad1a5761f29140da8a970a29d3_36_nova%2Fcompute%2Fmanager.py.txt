Based on the given code from a commit, please generate supplementary code files according to the commit message.
####commit message
live-mig: Add claims and proper resource tracking

This patch adds the claims mechanism to the live migration control flow.
There are several points that are worth noting about this (somewhat
beefy) patch.

 * Adds migration object, and other scheduler related data to the
   check_can_live_migrate_destination which is where the claim happens.
   Since the claim logic updates the migration record with the target
   host, we remove this update from the conductor.

   The claim happens on the first call to the destination node. It is
   worth noting that in case the destination was specified when live
   migration API was called, no claims will happen.
 * We do not drop the claim at any point - this could be improved in a
   future patch, but was left out to keep this patch easier to review.
 * Makes sure that we apply the migration context after a successful
   live migration, and that we drop it upon failure.
 * Makes sure that the migration record status is updated in failure
   and success scenarios, as this is necessary for correct resource
   tracking
 * We can now track live migration records in the resource tracker so we
   remove the check that would skip them when updating resources.
 * Currently missing (in libvirt's case) is applying the migration
   context to the xml we pass to the migrateToURI2 API call.
   This makes this no more broken than it was before, and is addressed
   in a follow-up patch

Change-Id: Ie80983bb8ce4c8ad1a5761f29140da8a970a29d3
Co-Authored-By: Sylvain Bauza <sbauza@redhat.com>
Co-Authored-By: Sahid Ferdjaoui <sahid.ferdjaoui@redhat.com>
Co-Authored-By: Pawel Koniszewski <pawel.koniszewski@intel.com>
Partial-bug: 1417667
Partial-bug: 1289064

####code 
1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 import eventlet.event
39 from eventlet import greenthread
40 import eventlet.semaphore
41 import eventlet.timeout
42 from keystoneauth1 import exceptions as keystone_exception
43 from oslo_log import log as logging
44 import oslo_messaging as messaging
45 from oslo_serialization import jsonutils
46 from oslo_service import loopingcall
47 from oslo_service import periodic_task
48 from oslo_utils import excutils
49 from oslo_utils import strutils
50 from oslo_utils import timeutils
51 from oslo_utils import uuidutils
52 import six
53 from six.moves import range
54 
55 from nova import block_device
56 from nova.cells import rpcapi as cells_rpcapi
57 from nova.cloudpipe import pipelib
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova import consoleauth
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova.i18n import _LE
77 from nova.i18n import _LI
78 from nova.i18n import _LW
79 from nova import image
80 from nova.image import glance
81 from nova import manager
82 from nova import network
83 from nova.network import base_api as base_net_api
84 from nova.network import model as network_model
85 from nova.network.security_group import openstack_driver
86 from nova import objects
87 from nova.objects import base as obj_base
88 from nova.objects import fields
89 from nova.objects import instance as obj_instance
90 from nova.objects import migrate_data as migrate_data_obj
91 from nova.pci import whitelist
92 from nova import rpc
93 from nova import safe_utils
94 from nova.scheduler import client as scheduler_client
95 from nova import utils
96 from nova.virt import block_device as driver_block_device
97 from nova.virt import configdrive
98 from nova.virt import driver
99 from nova.virt import event as virtevent
100 from nova.virt import storage_users
101 from nova.virt import virtapi
102 from nova.volume import cinder
103 from nova.volume import encryptors
104 
105 CONF = nova.conf.CONF
106 
107 LOG = logging.getLogger(__name__)
108 
109 get_notifier = functools.partial(rpc.get_notifier, service='compute')
110 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
111                                    get_notifier=get_notifier,
112                                    binary='nova-compute')
113 
114 
115 @utils.expects_func_args('migration')
116 def errors_out_migration(function):
117     """Decorator to error out migration on failure."""
118 
119     @functools.wraps(function)
120     def decorated_function(self, context, *args, **kwargs):
121         try:
122             return function(self, context, *args, **kwargs)
123         except Exception as ex:
124             with excutils.save_and_reraise_exception():
125                 wrapped_func = safe_utils.get_wrapped_function(function)
126                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
127                                                  *args, **kwargs)
128                 migration = keyed_args['migration']
129 
130                 # NOTE(rajesht): If InstanceNotFound error is thrown from
131                 # decorated function, migration status should be set to
132                 # 'error', without checking current migration status.
133                 if not isinstance(ex, exception.InstanceNotFound):
134                     status = migration.status
135                     if status not in ['migrating', 'post-migrating']:
136                         return
137 
138                 migration.status = 'error'
139                 try:
140                     with migration.obj_as_admin():
141                         migration.save()
142                 except Exception:
143                     LOG.debug('Error setting migration status '
144                               'for instance %s.',
145                               migration.instance_uuid, exc_info=True)
146 
147     return decorated_function
148 
149 
150 @utils.expects_func_args('instance')
151 def reverts_task_state(function):
152     """Decorator to revert task_state on failure."""
153 
154     @functools.wraps(function)
155     def decorated_function(self, context, *args, **kwargs):
156         try:
157             return function(self, context, *args, **kwargs)
158         except exception.UnexpectedTaskStateError as e:
159             # Note(maoy): unexpected task state means the current
160             # task is preempted. Do not clear task state in this
161             # case.
162             with excutils.save_and_reraise_exception():
163                 LOG.info(_LI("Task possibly preempted: %s"),
164                          e.format_message())
165         except Exception:
166             with excutils.save_and_reraise_exception():
167                 wrapped_func = safe_utils.get_wrapped_function(function)
168                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
169                                                  *args, **kwargs)
170                 # NOTE(mriedem): 'instance' must be in keyed_args because we
171                 # have utils.expects_func_args('instance') decorating this
172                 # method.
173                 instance = keyed_args['instance']
174                 original_task_state = instance.task_state
175                 try:
176                     self._instance_update(context, instance, task_state=None)
177                     LOG.info(_LI("Successfully reverted task state from %s on "
178                                  "failure for instance."), original_task_state,
179                                                            instance=instance)
180                 except exception.InstanceNotFound:
181                     # We might delete an instance that failed to build shortly
182                     # after it errored out this is an expected case and we
183                     # should not trace on it.
184                     pass
185                 except Exception as e:
186                     msg = _LW("Failed to revert task state for instance. "
187                               "Error: %s")
188                     LOG.warning(msg, e, instance=instance)
189 
190     return decorated_function
191 
192 
193 @utils.expects_func_args('instance')
194 def wrap_instance_fault(function):
195     """Wraps a method to catch exceptions related to instances.
196 
197     This decorator wraps a method to catch any exceptions having to do with
198     an instance that may get thrown. It then logs an instance fault in the db.
199     """
200 
201     @functools.wraps(function)
202     def decorated_function(self, context, *args, **kwargs):
203         try:
204             return function(self, context, *args, **kwargs)
205         except exception.InstanceNotFound:
206             raise
207         except Exception as e:
208             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
209             # we will get a KeyError exception which will cover up the real
210             # exception. So, we update kwargs with the values from args first.
211             # then, we can get 'instance' from kwargs easily.
212             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
213 
214             with excutils.save_and_reraise_exception():
215                 compute_utils.add_instance_fault_from_exc(context,
216                         kwargs['instance'], e, sys.exc_info())
217 
218     return decorated_function
219 
220 
221 @utils.expects_func_args('image_id', 'instance')
222 def delete_image_on_error(function):
223     """Used for snapshot related method to ensure the image created in
224     compute.api is deleted when an error occurs.
225     """
226 
227     @functools.wraps(function)
228     def decorated_function(self, context, image_id, instance,
229                            *args, **kwargs):
230         try:
231             return function(self, context, image_id, instance,
232                             *args, **kwargs)
233         except Exception:
234             with excutils.save_and_reraise_exception():
235                 LOG.debug("Cleaning up image %s", image_id,
236                           exc_info=True, instance=instance)
237                 try:
238                     self.image_api.delete(context, image_id)
239                 except Exception:
240                     LOG.exception(_LE("Error while trying to clean up "
241                                       "image %s"), image_id,
242                                   instance=instance)
243 
244     return decorated_function
245 
246 
247 # TODO(danms): Remove me after Icehouse
248 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
249 # NOTE(mikal): if the method being decorated has more than one decorator, then
250 # put this one first. Otherwise the various exception handling decorators do
251 # not function correctly.
252 def object_compat(function):
253     """Wraps a method that expects a new-world instance
254 
255     This provides compatibility for callers passing old-style dict
256     instances.
257     """
258 
259     @functools.wraps(function)
260     def decorated_function(self, context, *args, **kwargs):
261         def _load_instance(instance_or_dict):
262             if isinstance(instance_or_dict, dict):
263                 # try to get metadata and system_metadata for most cases but
264                 # only attempt to load those if the db instance already has
265                 # those fields joined
266                 metas = [meta for meta in ('metadata', 'system_metadata')
267                          if meta in instance_or_dict]
268                 instance = objects.Instance._from_db_object(
269                     context, objects.Instance(), instance_or_dict,
270                     expected_attrs=metas)
271                 instance._context = context
272                 return instance
273             return instance_or_dict
274 
275         try:
276             kwargs['instance'] = _load_instance(kwargs['instance'])
277         except KeyError:
278             args = (_load_instance(args[0]),) + args[1:]
279 
280         migration = kwargs.get('migration')
281         if isinstance(migration, dict):
282             migration = objects.Migration._from_db_object(
283                     context.elevated(), objects.Migration(),
284                     migration)
285             kwargs['migration'] = migration
286 
287         return function(self, context, *args, **kwargs)
288 
289     return decorated_function
290 
291 
292 class InstanceEvents(object):
293     def __init__(self):
294         self._events = {}
295 
296     @staticmethod
297     def _lock_name(instance):
298         return '%s-%s' % (instance.uuid, 'events')
299 
300     def prepare_for_instance_event(self, instance, event_name):
301         """Prepare to receive an event for an instance.
302 
303         This will register an event for the given instance that we will
304         wait on later. This should be called before initiating whatever
305         action will trigger the event. The resulting eventlet.event.Event
306         object should be wait()'d on to ensure completion.
307 
308         :param instance: the instance for which the event will be generated
309         :param event_name: the name of the event we're expecting
310         :returns: an event object that should be wait()'d on
311         """
312         if self._events is None:
313             # NOTE(danms): We really should have a more specific error
314             # here, but this is what we use for our default error case
315             raise exception.NovaException('In shutdown, no new events '
316                                           'can be scheduled')
317 
318         @utils.synchronized(self._lock_name(instance))
319         def _create_or_get_event():
320             instance_events = self._events.setdefault(instance.uuid, {})
321             return instance_events.setdefault(event_name,
322                                               eventlet.event.Event())
323         LOG.debug('Preparing to wait for external event %(event)s',
324                   {'event': event_name}, instance=instance)
325         return _create_or_get_event()
326 
327     def pop_instance_event(self, instance, event):
328         """Remove a pending event from the wait list.
329 
330         This will remove a pending event from the wait list so that it
331         can be used to signal the waiters to wake up.
332 
333         :param instance: the instance for which the event was generated
334         :param event: the nova.objects.external_event.InstanceExternalEvent
335                       that describes the event
336         :returns: the eventlet.event.Event object on which the waiters
337                   are blocked
338         """
339         no_events_sentinel = object()
340         no_matching_event_sentinel = object()
341 
342         @utils.synchronized(self._lock_name(instance))
343         def _pop_event():
344             if not self._events:
345                 LOG.debug('Unexpected attempt to pop events during shutdown',
346                           instance=instance)
347                 return no_events_sentinel
348             events = self._events.get(instance.uuid)
349             if not events:
350                 return no_events_sentinel
351             _event = events.pop(event.key, None)
352             if not events:
353                 del self._events[instance.uuid]
354             if _event is None:
355                 return no_matching_event_sentinel
356             return _event
357 
358         result = _pop_event()
359         if result is no_events_sentinel:
360             LOG.debug('No waiting events found dispatching %(event)s',
361                       {'event': event.key},
362                       instance=instance)
363             return None
364         elif result is no_matching_event_sentinel:
365             LOG.debug('No event matching %(event)s in %(events)s',
366                       {'event': event.key,
367                        'events': self._events.get(instance.uuid, {}).keys()},
368                       instance=instance)
369             return None
370         else:
371             return result
372 
373     def clear_events_for_instance(self, instance):
374         """Remove all pending events for an instance.
375 
376         This will remove all events currently pending for an instance
377         and return them (indexed by event name).
378 
379         :param instance: the instance for which events should be purged
380         :returns: a dictionary of {event_name: eventlet.event.Event}
381         """
382         @utils.synchronized(self._lock_name(instance))
383         def _clear_events():
384             if self._events is None:
385                 LOG.debug('Unexpected attempt to clear events during shutdown',
386                           instance=instance)
387                 return dict()
388             return self._events.pop(instance.uuid, {})
389         return _clear_events()
390 
391     def cancel_all_events(self):
392         if self._events is None:
393             LOG.debug('Unexpected attempt to cancel events during shutdown.')
394             return
395         our_events = self._events
396         # NOTE(danms): Block new events
397         self._events = None
398 
399         for instance_uuid, events in our_events.items():
400             for event_name, eventlet_event in events.items():
401                 LOG.debug('Canceling in-flight event %(event)s for '
402                           'instance %(instance_uuid)s',
403                           {'event': event_name,
404                            'instance_uuid': instance_uuid})
405                 name, tag = event_name.rsplit('-', 1)
406                 event = objects.InstanceExternalEvent(
407                     instance_uuid=instance_uuid,
408                     name=name, status='failed',
409                     tag=tag, data={})
410                 eventlet_event.send(event)
411 
412 
413 class ComputeVirtAPI(virtapi.VirtAPI):
414     def __init__(self, compute):
415         super(ComputeVirtAPI, self).__init__()
416         self._compute = compute
417 
418     def _default_error_callback(self, event_name, instance):
419         raise exception.NovaException(_('Instance event failed'))
420 
421     @contextlib.contextmanager
422     def wait_for_instance_event(self, instance, event_names, deadline=300,
423                                 error_callback=None):
424         """Plan to wait for some events, run some code, then wait.
425 
426         This context manager will first create plans to wait for the
427         provided event_names, yield, and then wait for all the scheduled
428         events to complete.
429 
430         Note that this uses an eventlet.timeout.Timeout to bound the
431         operation, so callers should be prepared to catch that
432         failure and handle that situation appropriately.
433 
434         If the event is not received by the specified timeout deadline,
435         eventlet.timeout.Timeout is raised.
436 
437         If the event is received but did not have a 'completed'
438         status, a NovaException is raised.  If an error_callback is
439         provided, instead of raising an exception as detailed above
440         for the failure case, the callback will be called with the
441         event_name and instance, and can return True to continue
442         waiting for the rest of the events, False to stop processing,
443         or raise an exception which will bubble up to the waiter.
444 
445         :param instance: The instance for which an event is expected
446         :param event_names: A list of event names. Each element can be a
447                             string event name or tuple of strings to
448                             indicate (name, tag).
449         :param deadline: Maximum number of seconds we should wait for all
450                          of the specified events to arrive.
451         :param error_callback: A function to be called if an event arrives
452 
453         """
454 
455         if error_callback is None:
456             error_callback = self._default_error_callback
457         events = {}
458         for event_name in event_names:
459             if isinstance(event_name, tuple):
460                 name, tag = event_name
461                 event_name = objects.InstanceExternalEvent.make_key(
462                     name, tag)
463             try:
464                 events[event_name] = (
465                     self._compute.instance_events.prepare_for_instance_event(
466                         instance, event_name))
467             except exception.NovaException:
468                 error_callback(event_name, instance)
469                 # NOTE(danms): Don't wait for any of the events. They
470                 # should all be canceled and fired immediately below,
471                 # but don't stick around if not.
472                 deadline = 0
473         yield
474         with eventlet.timeout.Timeout(deadline):
475             for event_name, event in events.items():
476                 actual_event = event.wait()
477                 if actual_event.status == 'completed':
478                     continue
479                 decision = error_callback(event_name, instance)
480                 if decision is False:
481                     break
482 
483 
484 _SENTINEL = object()
485 
486 
487 class ComputeManager(manager.Manager):
488     """Manages the running instances from creation to destruction."""
489 
490     target = messaging.Target(version='4.14')
491 
492     # How long to wait in seconds before re-issuing a shutdown
493     # signal to an instance during power off.  The overall
494     # time to wait is set by CONF.shutdown_timeout.
495     SHUTDOWN_RETRY_INTERVAL = 10
496 
497     def __init__(self, compute_driver=None, *args, **kwargs):
498         """Load configuration options and connect to the hypervisor."""
499         self.virtapi = ComputeVirtAPI(self)
500         self.network_api = network.API()
501         self.volume_api = cinder.API()
502         self.image_api = image.API()
503         self._last_host_check = 0
504         self._last_bw_usage_poll = 0
505         self._bw_usage_supported = True
506         self._last_bw_usage_cell_update = 0
507         self.compute_api = compute.API()
508         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
509         self.conductor_api = conductor.API()
510         self.compute_task_api = conductor.ComputeTaskAPI()
511         self.is_neutron_security_groups = (
512             openstack_driver.is_neutron_security_groups())
513         self.consoleauth_rpcapi = consoleauth.rpcapi.ConsoleAuthAPI()
514         self.cells_rpcapi = cells_rpcapi.CellsAPI()
515         self.scheduler_client = scheduler_client.SchedulerClient()
516         self._resource_tracker_dict = {}
517         self.instance_events = InstanceEvents()
518         self._sync_power_pool = eventlet.GreenPool(
519             size=CONF.sync_power_state_pool_size)
520         self._syncs_in_progress = {}
521         self.send_instance_updates = (
522             CONF.filter_scheduler.track_instance_changes)
523         if CONF.max_concurrent_builds != 0:
524             self._build_semaphore = eventlet.semaphore.Semaphore(
525                 CONF.max_concurrent_builds)
526         else:
527             self._build_semaphore = compute_utils.UnlimitedSemaphore()
528         if max(CONF.max_concurrent_live_migrations, 0) != 0:
529             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
530                 CONF.max_concurrent_live_migrations)
531         else:
532             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
533 
534         super(ComputeManager, self).__init__(service_name="compute",
535                                              *args, **kwargs)
536 
537         # NOTE(russellb) Load the driver last.  It may call back into the
538         # compute manager via the virtapi, so we want it to be fully
539         # initialized before that happens.
540         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
541         self.use_legacy_block_device_info = \
542                             self.driver.need_legacy_block_device_info
543 
544     def reset(self):
545         LOG.info(_LI('Reloading compute RPC API'))
546         compute_rpcapi.LAST_VERSION = None
547         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
548 
549     def _get_resource_tracker(self, nodename):
550         rt = self._resource_tracker_dict.get(nodename)
551         if not rt:
552             if not self.driver.node_is_available(nodename):
553                 raise exception.NovaException(
554                         _("%s is not a valid node managed by this "
555                           "compute host.") % nodename)
556 
557             rt = resource_tracker.ResourceTracker(self.host,
558                                                   self.driver,
559                                                   nodename)
560             self._resource_tracker_dict[nodename] = rt
561         return rt
562 
563     def _update_resource_tracker(self, context, instance):
564         """Let the resource tracker know that an instance has changed state."""
565 
566         if (instance.host == self.host and
567                 self.driver.node_is_available(instance.node)):
568             rt = self._get_resource_tracker(instance.node)
569             rt.update_usage(context, instance)
570 
571     def _instance_update(self, context, instance, **kwargs):
572         """Update an instance in the database using kwargs as value."""
573 
574         for k, v in kwargs.items():
575             setattr(instance, k, v)
576         instance.save()
577         self._update_resource_tracker(context, instance)
578 
579     def _nil_out_instance_obj_host_and_node(self, instance):
580         # NOTE(jwcroppe): We don't do instance.save() here for performance
581         # reasons; a call to this is expected to be immediately followed by
582         # another call that does instance.save(), thus avoiding two writes
583         # to the database layer.
584         instance.host = None
585         instance.node = None
586 
587     def _set_instance_obj_error_state(self, context, instance,
588                                       clean_task_state=False):
589         try:
590             instance.vm_state = vm_states.ERROR
591             if clean_task_state:
592                 instance.task_state = None
593             instance.save()
594         except exception.InstanceNotFound:
595             LOG.debug('Instance has been destroyed from under us while '
596                       'trying to set it to ERROR', instance=instance)
597 
598     def _get_instances_on_driver(self, context, filters=None):
599         """Return a list of instance records for the instances found
600         on the hypervisor which satisfy the specified filters. If filters=None
601         return a list of instance records for all the instances found on the
602         hypervisor.
603         """
604         if not filters:
605             filters = {}
606         try:
607             driver_uuids = self.driver.list_instance_uuids()
608             if len(driver_uuids) == 0:
609                 # Short circuit, don't waste a DB call
610                 return objects.InstanceList()
611             filters['uuid'] = driver_uuids
612             local_instances = objects.InstanceList.get_by_filters(
613                 context, filters, use_slave=True)
614             return local_instances
615         except NotImplementedError:
616             pass
617 
618         # The driver doesn't support uuids listing, so we'll have
619         # to brute force.
620         driver_instances = self.driver.list_instances()
621         instances = objects.InstanceList.get_by_filters(context, filters,
622                                                         use_slave=True)
623         name_map = {instance.name: instance for instance in instances}
624         local_instances = []
625         for driver_instance in driver_instances:
626             instance = name_map.get(driver_instance)
627             if not instance:
628                 continue
629             local_instances.append(instance)
630         return local_instances
631 
632     def _destroy_evacuated_instances(self, context):
633         """Destroys evacuated instances.
634 
635         While nova-compute was down, the instances running on it could be
636         evacuated to another host. Check that the instances reported
637         by the driver are still associated with this host.  If they are
638         not, destroy them, with the exception of instances which are in
639         the MIGRATING, RESIZE_MIGRATING, RESIZE_MIGRATED, RESIZE_FINISH
640         task state or RESIZED vm state.
641         """
642         filters = {
643             'source_compute': self.host,
644             'status': ['accepted', 'done'],
645             'migration_type': 'evacuation',
646         }
647         evacuations = objects.MigrationList.get_by_filters(context, filters)
648         if not evacuations:
649             return
650         evacuations = {mig.instance_uuid: mig for mig in evacuations}
651 
652         filters = {'deleted': False}
653         local_instances = self._get_instances_on_driver(context, filters)
654         evacuated = [inst for inst in local_instances
655                      if inst.uuid in evacuations]
656         for instance in evacuated:
657             migration = evacuations[instance.uuid]
658             LOG.info(_LI('Deleting instance as it has been evacuated from '
659                          'this host'), instance=instance)
660             try:
661                 network_info = self.network_api.get_instance_nw_info(
662                     context, instance)
663                 bdi = self._get_instance_block_device_info(context,
664                                                            instance)
665                 destroy_disks = not (self._is_instance_storage_shared(
666                     context, instance))
667             except exception.InstanceNotFound:
668                 network_info = network_model.NetworkInfo()
669                 bdi = {}
670                 LOG.info(_LI('Instance has been marked deleted already, '
671                              'removing it from the hypervisor.'),
672                          instance=instance)
673                 # always destroy disks if the instance was deleted
674                 destroy_disks = True
675             self.driver.destroy(context, instance,
676                                 network_info,
677                                 bdi, destroy_disks)
678             migration.status = 'completed'
679             migration.save()
680 
681     def _is_instance_storage_shared(self, context, instance, host=None):
682         shared_storage = True
683         data = None
684         try:
685             data = self.driver.check_instance_shared_storage_local(context,
686                                                        instance)
687             if data:
688                 shared_storage = (self.compute_rpcapi.
689                                   check_instance_shared_storage(context,
690                                   instance, data, host=host))
691         except NotImplementedError:
692             LOG.debug('Hypervisor driver does not support '
693                       'instance shared storage check, '
694                       'assuming it\'s not on shared storage',
695                       instance=instance)
696             shared_storage = False
697         except Exception:
698             LOG.exception(_LE('Failed to check if instance shared'),
699                       instance=instance)
700         finally:
701             if data:
702                 self.driver.check_instance_shared_storage_cleanup(context,
703                                                                   data)
704         return shared_storage
705 
706     def _complete_partial_deletion(self, context, instance):
707         """Complete deletion for instances in DELETED status but not marked as
708         deleted in the DB
709         """
710         system_meta = instance.system_metadata
711         instance.destroy()
712         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
713                 context, instance.uuid)
714         quotas = objects.Quotas(context=context)
715         project_id, user_id = objects.quotas.ids_from_instance(context,
716                                                                instance)
717         quotas.reserve(project_id=project_id, user_id=user_id, instances=-1,
718                        cores=-instance.flavor.vcpus,
719                        ram=-instance.flavor.memory_mb)
720         self._complete_deletion(context,
721                                 instance,
722                                 bdms,
723                                 quotas,
724                                 system_meta)
725 
726     def _complete_deletion(self, context, instance, bdms,
727                            quotas, system_meta):
728         if quotas:
729             quotas.commit()
730 
731         # ensure block device mappings are not leaked
732         for bdm in bdms:
733             bdm.destroy()
734 
735         self._update_resource_tracker(context, instance)
736         self._notify_about_instance_usage(context, instance, "delete.end",
737                 system_metadata=system_meta)
738         compute_utils.notify_about_instance_action(context, instance,
739                 self.host, action=fields.NotificationAction.DELETE,
740                 phase=fields.NotificationPhase.END)
741         self._clean_instance_console_tokens(context, instance)
742         self._delete_scheduler_instance_info(context, instance.uuid)
743 
744     def _create_reservations(self, context, instance, project_id, user_id):
745         vcpus = instance.flavor.vcpus
746         mem_mb = instance.flavor.memory_mb
747 
748         quotas = objects.Quotas(context=context)
749         quotas.reserve(project_id=project_id,
750                        user_id=user_id,
751                        instances=-1,
752                        cores=-vcpus,
753                        ram=-mem_mb)
754         return quotas
755 
756     def _init_instance(self, context, instance):
757         '''Initialize this instance during service init.'''
758 
759         # NOTE(danms): If the instance appears to not be owned by this
760         # host, it may have been evacuated away, but skipped by the
761         # evacuation cleanup code due to configuration. Thus, if that
762         # is a possibility, don't touch the instance in any way, but
763         # log the concern. This will help avoid potential issues on
764         # startup due to misconfiguration.
765         if instance.host != self.host:
766             LOG.warning(_LW('Instance %(uuid)s appears to not be owned '
767                             'by this host, but by %(host)s. Startup '
768                             'processing is being skipped.'),
769                         {'uuid': instance.uuid,
770                          'host': instance.host})
771             return
772 
773         # Instances that are shut down, or in an error state can not be
774         # initialized and are not attempted to be recovered. The exception
775         # to this are instances that are in RESIZE_MIGRATING or DELETING,
776         # which are dealt with further down.
777         if (instance.vm_state == vm_states.SOFT_DELETED or
778             (instance.vm_state == vm_states.ERROR and
779             instance.task_state not in
780             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
781             LOG.debug("Instance is in %s state.",
782                       instance.vm_state, instance=instance)
783             return
784 
785         if instance.vm_state == vm_states.DELETED:
786             try:
787                 self._complete_partial_deletion(context, instance)
788             except Exception:
789                 # we don't want that an exception blocks the init_host
790                 msg = _LE('Failed to complete a deletion')
791                 LOG.exception(msg, instance=instance)
792             return
793 
794         if (instance.vm_state == vm_states.BUILDING or
795             instance.task_state in [task_states.SCHEDULING,
796                                     task_states.BLOCK_DEVICE_MAPPING,
797                                     task_states.NETWORKING,
798                                     task_states.SPAWNING]):
799             # NOTE(dave-mcnally) compute stopped before instance was fully
800             # spawned so set to ERROR state. This is safe to do as the state
801             # may be set by the api but the host is not so if we get here the
802             # instance has already been scheduled to this particular host.
803             LOG.debug("Instance failed to spawn correctly, "
804                       "setting to ERROR state", instance=instance)
805             instance.task_state = None
806             instance.vm_state = vm_states.ERROR
807             instance.save()
808             return
809 
810         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
811             instance.task_state in [task_states.REBUILDING,
812                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
813                                     task_states.REBUILD_SPAWNING]):
814             # NOTE(jichenjc) compute stopped before instance was fully
815             # spawned so set to ERROR state. This is consistent to BUILD
816             LOG.debug("Instance failed to rebuild correctly, "
817                       "setting to ERROR state", instance=instance)
818             instance.task_state = None
819             instance.vm_state = vm_states.ERROR
820             instance.save()
821             return
822 
823         if (instance.vm_state != vm_states.ERROR and
824             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
825                                     task_states.IMAGE_PENDING_UPLOAD,
826                                     task_states.IMAGE_UPLOADING,
827                                     task_states.IMAGE_SNAPSHOT]):
828             LOG.debug("Instance in transitional state %s at start-up "
829                       "clearing task state",
830                       instance.task_state, instance=instance)
831             try:
832                 self._post_interrupted_snapshot_cleanup(context, instance)
833             except Exception:
834                 # we don't want that an exception blocks the init_host
835                 msg = _LE('Failed to cleanup snapshot.')
836                 LOG.exception(msg, instance=instance)
837             instance.task_state = None
838             instance.save()
839 
840         if (instance.vm_state != vm_states.ERROR and
841             instance.task_state in [task_states.RESIZE_PREP]):
842             LOG.debug("Instance in transitional state %s at start-up "
843                       "clearing task state",
844                       instance['task_state'], instance=instance)
845             instance.task_state = None
846             instance.save()
847 
848         if instance.task_state == task_states.DELETING:
849             try:
850                 LOG.info(_LI('Service started deleting the instance during '
851                              'the previous run, but did not finish. Restarting'
852                              ' the deletion now.'), instance=instance)
853                 instance.obj_load_attr('metadata')
854                 instance.obj_load_attr('system_metadata')
855                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
856                         context, instance.uuid)
857                 project_id, user_id = objects.quotas.ids_from_instance(
858                     context, instance)
859                 quotas = self._create_reservations(context, instance,
860                                                    project_id, user_id)
861 
862                 self._delete_instance(context, instance, bdms, quotas)
863             except Exception:
864                 # we don't want that an exception blocks the init_host
865                 msg = _LE('Failed to complete a deletion')
866                 LOG.exception(msg, instance=instance)
867                 self._set_instance_obj_error_state(context, instance)
868             return
869 
870         current_power_state = self._get_power_state(context, instance)
871         try_reboot, reboot_type = self._retry_reboot(context, instance,
872                                                      current_power_state)
873 
874         if try_reboot:
875             LOG.debug("Instance in transitional state (%(task_state)s) at "
876                       "start-up and power state is (%(power_state)s), "
877                       "triggering reboot",
878                       {'task_state': instance.task_state,
879                        'power_state': current_power_state},
880                       instance=instance)
881 
882             # NOTE(mikal): if the instance was doing a soft reboot that got as
883             # far as shutting down the instance but not as far as starting it
884             # again, then we've just become a hard reboot. That means the
885             # task state for the instance needs to change so that we're in one
886             # of the expected task states for a hard reboot.
887             soft_types = [task_states.REBOOT_STARTED,
888                           task_states.REBOOT_PENDING,
889                           task_states.REBOOTING]
890             if instance.task_state in soft_types and reboot_type == 'HARD':
891                 instance.task_state = task_states.REBOOT_PENDING_HARD
892                 instance.save()
893 
894             self.reboot_instance(context, instance, block_device_info=None,
895                                  reboot_type=reboot_type)
896             return
897 
898         elif (current_power_state == power_state.RUNNING and
899               instance.task_state in [task_states.REBOOT_STARTED,
900                                       task_states.REBOOT_STARTED_HARD,
901                                       task_states.PAUSING,
902                                       task_states.UNPAUSING]):
903             LOG.warning(_LW("Instance in transitional state "
904                             "(%(task_state)s) at start-up and power state "
905                             "is (%(power_state)s), clearing task state"),
906                         {'task_state': instance.task_state,
907                          'power_state': current_power_state},
908                         instance=instance)
909             instance.task_state = None
910             instance.vm_state = vm_states.ACTIVE
911             instance.save()
912         elif (current_power_state == power_state.PAUSED and
913               instance.task_state == task_states.UNPAUSING):
914             LOG.warning(_LW("Instance in transitional state "
915                             "(%(task_state)s) at start-up and power state "
916                             "is (%(power_state)s), clearing task state "
917                             "and unpausing the instance"),
918                         {'task_state': instance.task_state,
919                          'power_state': current_power_state},
920                         instance=instance)
921             try:
922                 self.unpause_instance(context, instance)
923             except NotImplementedError:
924                 # Some virt driver didn't support pause and unpause
925                 pass
926             except Exception:
927                 LOG.exception(_LE('Failed to unpause instance'),
928                               instance=instance)
929             return
930 
931         if instance.task_state == task_states.POWERING_OFF:
932             try:
933                 LOG.debug("Instance in transitional state %s at start-up "
934                           "retrying stop request",
935                           instance.task_state, instance=instance)
936                 self.stop_instance(context, instance, True)
937             except Exception:
938                 # we don't want that an exception blocks the init_host
939                 msg = _LE('Failed to stop instance')
940                 LOG.exception(msg, instance=instance)
941             return
942 
943         if instance.task_state == task_states.POWERING_ON:
944             try:
945                 LOG.debug("Instance in transitional state %s at start-up "
946                           "retrying start request",
947                           instance.task_state, instance=instance)
948                 self.start_instance(context, instance)
949             except Exception:
950                 # we don't want that an exception blocks the init_host
951                 msg = _LE('Failed to start instance')
952                 LOG.exception(msg, instance=instance)
953             return
954 
955         net_info = compute_utils.get_nw_info_for_instance(instance)
956         try:
957             self.driver.plug_vifs(instance, net_info)
958         except NotImplementedError as e:
959             LOG.debug(e, instance=instance)
960         except exception.VirtualInterfacePlugException:
961             # we don't want an exception to block the init_host
962             LOG.exception(_LE("Vifs plug failed"), instance=instance)
963             self._set_instance_obj_error_state(context, instance)
964             return
965 
966         if instance.task_state == task_states.RESIZE_MIGRATING:
967             # We crashed during resize/migration, so roll back for safety
968             try:
969                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
970                 # not in system_metadata we default to True for backwards
971                 # compatibility
972                 power_on = (instance.system_metadata.get('old_vm_state') !=
973                             vm_states.STOPPED)
974 
975                 block_dev_info = self._get_instance_block_device_info(context,
976                                                                       instance)
977 
978                 self.driver.finish_revert_migration(context,
979                     instance, net_info, block_dev_info, power_on)
980 
981             except Exception:
982                 LOG.exception(_LE('Failed to revert crashed migration'),
983                               instance=instance)
984             finally:
985                 LOG.info(_LI('Instance found in migrating state during '
986                              'startup. Resetting task_state'),
987                          instance=instance)
988                 instance.task_state = None
989                 instance.save()
990         if instance.task_state == task_states.MIGRATING:
991             # Live migration did not complete, but instance is on this
992             # host, so reset the state.
993             instance.task_state = None
994             instance.save(expected_task_state=[task_states.MIGRATING])
995 
996         db_state = instance.power_state
997         drv_state = self._get_power_state(context, instance)
998         expect_running = (db_state == power_state.RUNNING and
999                           drv_state != db_state)
1000 
1001         LOG.debug('Current state is %(drv_state)s, state in DB is '
1002                   '%(db_state)s.',
1003                   {'drv_state': drv_state, 'db_state': db_state},
1004                   instance=instance)
1005 
1006         if expect_running and CONF.resume_guests_state_on_host_boot:
1007             LOG.info(_LI('Rebooting instance after nova-compute restart.'),
1008                      instance=instance)
1009 
1010             block_device_info = \
1011                 self._get_instance_block_device_info(context, instance)
1012 
1013             try:
1014                 self.driver.resume_state_on_host_boot(
1015                     context, instance, net_info, block_device_info)
1016             except NotImplementedError:
1017                 LOG.warning(_LW('Hypervisor driver does not support '
1018                                 'resume guests'), instance=instance)
1019             except Exception:
1020                 # NOTE(vish): The instance failed to resume, so we set the
1021                 #             instance to error and attempt to continue.
1022                 LOG.warning(_LW('Failed to resume instance'),
1023                             instance=instance)
1024                 self._set_instance_obj_error_state(context, instance)
1025 
1026         elif drv_state == power_state.RUNNING:
1027             # VMwareAPI drivers will raise an exception
1028             try:
1029                 self.driver.ensure_filtering_rules_for_instance(
1030                                        instance, net_info)
1031             except NotImplementedError:
1032                 LOG.debug('Hypervisor driver does not support '
1033                           'firewall rules', instance=instance)
1034 
1035     def _retry_reboot(self, context, instance, current_power_state):
1036         current_task_state = instance.task_state
1037         retry_reboot = False
1038         reboot_type = compute_utils.get_reboot_type(current_task_state,
1039                                                     current_power_state)
1040 
1041         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1042                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1043         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1044                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1045         started_not_running = (current_task_state in
1046                                [task_states.REBOOT_STARTED,
1047                                 task_states.REBOOT_STARTED_HARD] and
1048                                current_power_state != power_state.RUNNING)
1049 
1050         if pending_soft or pending_hard or started_not_running:
1051             retry_reboot = True
1052 
1053         return retry_reboot, reboot_type
1054 
1055     def handle_lifecycle_event(self, event):
1056         LOG.info(_LI("VM %(state)s (Lifecycle Event)"),
1057                  {'state': event.get_name()},
1058                  instance_uuid=event.get_instance_uuid())
1059         context = nova.context.get_admin_context(read_deleted='yes')
1060         instance = objects.Instance.get_by_uuid(context,
1061                                                 event.get_instance_uuid(),
1062                                                 expected_attrs=[])
1063         vm_power_state = None
1064         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1065             vm_power_state = power_state.SHUTDOWN
1066         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1067             vm_power_state = power_state.RUNNING
1068         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1069             vm_power_state = power_state.PAUSED
1070         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1071             vm_power_state = power_state.RUNNING
1072         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1073             vm_power_state = power_state.SUSPENDED
1074         else:
1075             LOG.warning(_LW("Unexpected power state %d"),
1076                         event.get_transition())
1077 
1078         # Note(lpetrut): The event may be delayed, thus not reflecting
1079         # the current instance power state. In that case, ignore the event.
1080         current_power_state = self._get_power_state(context, instance)
1081         if current_power_state == vm_power_state:
1082             LOG.debug('Synchronizing instance power state after lifecycle '
1083                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1084                       'current task_state: %(task_state)s, current DB '
1085                       'power_state: %(db_power_state)s, VM power_state: '
1086                       '%(vm_power_state)s',
1087                       {'event': event.get_name(),
1088                        'vm_state': instance.vm_state,
1089                        'task_state': instance.task_state,
1090                        'db_power_state': instance.power_state,
1091                        'vm_power_state': vm_power_state},
1092                       instance_uuid=instance.uuid)
1093             self._sync_instance_power_state(context,
1094                                             instance,
1095                                             vm_power_state)
1096 
1097     def handle_events(self, event):
1098         if isinstance(event, virtevent.LifecycleEvent):
1099             try:
1100                 self.handle_lifecycle_event(event)
1101             except exception.InstanceNotFound:
1102                 LOG.debug("Event %s arrived for non-existent instance. The "
1103                           "instance was probably deleted.", event)
1104         else:
1105             LOG.debug("Ignoring event %s", event)
1106 
1107     def init_virt_events(self):
1108         if CONF.workarounds.handle_virt_lifecycle_events:
1109             self.driver.register_event_listener(self.handle_events)
1110         else:
1111             # NOTE(mriedem): If the _sync_power_states periodic task is
1112             # disabled we should emit a warning in the logs.
1113             if CONF.sync_power_state_interval < 0:
1114                 LOG.warning(_LW('Instance lifecycle events from the compute '
1115                              'driver have been disabled. Note that lifecycle '
1116                              'changes to an instance outside of the compute '
1117                              'service will not be synchronized '
1118                              'automatically since the _sync_power_states '
1119                              'periodic task is also disabled.'))
1120             else:
1121                 LOG.info(_LI('Instance lifecycle events from the compute '
1122                              'driver have been disabled. Note that lifecycle '
1123                              'changes to an instance outside of the compute '
1124                              'service will only be synchronized by the '
1125                              '_sync_power_states periodic task.'))
1126 
1127     def init_host(self):
1128         """Initialization for a standalone compute service."""
1129 
1130         if CONF.pci.passthrough_whitelist:
1131             # Simply loading the PCI passthrough whitelist will do a bunch of
1132             # validation that would otherwise wait until the PciDevTracker is
1133             # constructed when updating available resources for the compute
1134             # node(s) in the resource tracker, effectively killing that task.
1135             # So load up the whitelist when starting the compute service to
1136             # flush any invalid configuration early so we can kill the service
1137             # if the configuration is wrong.
1138             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1139 
1140         self.driver.init_host(host=self.host)
1141         context = nova.context.get_admin_context()
1142         instances = objects.InstanceList.get_by_host(
1143             context, self.host, expected_attrs=['info_cache', 'metadata'])
1144 
1145         if CONF.defer_iptables_apply:
1146             self.driver.filter_defer_apply_on()
1147 
1148         self.init_virt_events()
1149 
1150         try:
1151             # checking that instance was not already evacuated to other host
1152             self._destroy_evacuated_instances(context)
1153             for instance in instances:
1154                 self._init_instance(context, instance)
1155         finally:
1156             if CONF.defer_iptables_apply:
1157                 self.driver.filter_defer_apply_off()
1158             self._update_scheduler_instance_info(context, instances)
1159 
1160     def cleanup_host(self):
1161         self.driver.register_event_listener(None)
1162         self.instance_events.cancel_all_events()
1163         self.driver.cleanup_host(host=self.host)
1164 
1165     def pre_start_hook(self):
1166         """After the service is initialized, but before we fully bring
1167         the service up by listening on RPC queues, make sure to update
1168         our available resources (and indirectly our available nodes).
1169         """
1170         self.update_available_resource(nova.context.get_admin_context())
1171 
1172     def _get_power_state(self, context, instance):
1173         """Retrieve the power state for the given instance."""
1174         LOG.debug('Checking state', instance=instance)
1175         try:
1176             return self.driver.get_info(instance).state
1177         except exception.InstanceNotFound:
1178             return power_state.NOSTATE
1179 
1180     def get_console_topic(self, context):
1181         """Retrieves the console host for a project on this host.
1182 
1183         Currently this is just set in the flags for each compute host.
1184 
1185         """
1186         # TODO(mdragon): perhaps make this variable by console_type?
1187         return '%s.%s' % (CONF.console_topic, CONF.console_host)
1188 
1189     @wrap_exception()
1190     def get_console_pool_info(self, context, console_type):
1191         return self.driver.get_console_pool_info(console_type)
1192 
1193     # NOTE(hanlind): This and the virt method it calls can be removed in
1194     # version 5.0 of the RPC API
1195     @wrap_exception()
1196     def refresh_security_group_rules(self, context, security_group_id):
1197         """Tell the virtualization driver to refresh security group rules.
1198 
1199         Passes straight through to the virtualization driver.
1200 
1201         """
1202         return self.driver.refresh_security_group_rules(security_group_id)
1203 
1204     # TODO(alaski): Remove object_compat for RPC version 5.0
1205     @object_compat
1206     @wrap_exception()
1207     def refresh_instance_security_rules(self, context, instance):
1208         """Tell the virtualization driver to refresh security rules for
1209         an instance.
1210 
1211         Passes straight through to the virtualization driver.
1212 
1213         Synchronize the call because we may still be in the middle of
1214         creating the instance.
1215         """
1216         @utils.synchronized(instance.uuid)
1217         def _sync_refresh():
1218             try:
1219                 return self.driver.refresh_instance_security_rules(instance)
1220             except NotImplementedError:
1221                 LOG.debug('Hypervisor driver does not support '
1222                           'security groups.', instance=instance)
1223 
1224         return _sync_refresh()
1225 
1226     def _await_block_device_map_created(self, context, vol_id):
1227         # TODO(yamahata): creating volume simultaneously
1228         #                 reduces creation time?
1229         # TODO(yamahata): eliminate dumb polling
1230         start = time.time()
1231         retries = CONF.block_device_allocate_retries
1232         if retries < 0:
1233             LOG.warning(_LW("Treating negative config value (%(retries)s) for "
1234                             "'block_device_retries' as 0."),
1235                         {'retries': retries})
1236         # (1) treat  negative config value as 0
1237         # (2) the configured value is 0, one attempt should be made
1238         # (3) the configured value is > 0, then the total number attempts
1239         #      is (retries + 1)
1240         attempts = 1
1241         if retries >= 1:
1242             attempts = retries + 1
1243         for attempt in range(1, attempts + 1):
1244             volume = self.volume_api.get(context, vol_id)
1245             volume_status = volume['status']
1246             if volume_status not in ['creating', 'downloading']:
1247                 if volume_status == 'available':
1248                     return attempt
1249                 LOG.warning(_LW("Volume id: %(vol_id)s finished being "
1250                                 "created but its status is %(vol_status)s."),
1251                             {'vol_id': vol_id,
1252                              'vol_status': volume_status})
1253                 break
1254             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1255         raise exception.VolumeNotCreated(volume_id=vol_id,
1256                                          seconds=int(time.time() - start),
1257                                          attempts=attempt,
1258                                          volume_status=volume_status)
1259 
1260     def _decode_files(self, injected_files):
1261         """Base64 decode the list of files to inject."""
1262         if not injected_files:
1263             return []
1264 
1265         def _decode(f):
1266             path, contents = f
1267             # Py3 raises binascii.Error instead of TypeError as in Py27
1268             try:
1269                 decoded = base64.b64decode(contents)
1270                 return path, decoded
1271             except (TypeError, binascii.Error):
1272                 raise exception.Base64Exception(path=path)
1273 
1274         return [_decode(f) for f in injected_files]
1275 
1276     def _validate_instance_group_policy(self, context, instance,
1277             filter_properties):
1278         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1279         # However, there is a race condition with the enforcement of
1280         # the policy.  Since more than one instance may be scheduled at the
1281         # same time, it's possible that more than one instance with an
1282         # anti-affinity policy may end up here.  It's also possible that
1283         # multiple instances with an affinity policy could end up on different
1284         # hosts.  This is a validation step to make sure that starting the
1285         # instance here doesn't violate the policy.
1286 
1287         scheduler_hints = filter_properties.get('scheduler_hints') or {}
1288         group_hint = scheduler_hints.get('group')
1289         if not group_hint:
1290             return
1291 
1292         @utils.synchronized(group_hint)
1293         def _do_validation(context, instance, group_hint):
1294             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1295             if 'anti-affinity' in group.policies:
1296                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1297                 if self.host in group_hosts:
1298                     msg = _("Anti-affinity instance group policy "
1299                             "was violated.")
1300                     raise exception.RescheduledException(
1301                             instance_uuid=instance.uuid,
1302                             reason=msg)
1303             elif 'affinity' in group.policies:
1304                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1305                 if group_hosts and self.host not in group_hosts:
1306                     msg = _("Affinity instance group policy was violated.")
1307                     raise exception.RescheduledException(
1308                             instance_uuid=instance.uuid,
1309                             reason=msg)
1310 
1311         _do_validation(context, instance, group_hint)
1312 
1313     def _log_original_error(self, exc_info, instance_uuid):
1314         LOG.error(_LE('Error: %s'), exc_info[1], instance_uuid=instance_uuid,
1315                   exc_info=exc_info)
1316 
1317     def _reschedule(self, context, request_spec, filter_properties,
1318             instance, reschedule_method, method_args, task_state,
1319             exc_info=None):
1320         """Attempt to re-schedule a compute operation."""
1321 
1322         instance_uuid = instance.uuid
1323         retry = filter_properties.get('retry')
1324         if not retry:
1325             # no retry information, do not reschedule.
1326             LOG.debug("Retry info not present, will not reschedule",
1327                       instance_uuid=instance_uuid)
1328             return
1329 
1330         if not request_spec:
1331             LOG.debug("No request spec, will not reschedule",
1332                       instance_uuid=instance_uuid)
1333             return
1334 
1335         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1336                   {'method': reschedule_method.__name__,
1337                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1338 
1339         # reset the task state:
1340         self._instance_update(context, instance, task_state=task_state)
1341 
1342         if exc_info:
1343             # stringify to avoid circular ref problem in json serialization:
1344             retry['exc'] = traceback.format_exception_only(exc_info[0],
1345                                     exc_info[1])
1346 
1347         reschedule_method(context, *method_args)
1348         return True
1349 
1350     @periodic_task.periodic_task
1351     def _check_instance_build_time(self, context):
1352         """Ensure that instances are not stuck in build."""
1353         timeout = CONF.instance_build_timeout
1354         if timeout == 0:
1355             return
1356 
1357         filters = {'vm_state': vm_states.BUILDING,
1358                    'host': self.host}
1359 
1360         building_insts = objects.InstanceList.get_by_filters(context,
1361                            filters, expected_attrs=[], use_slave=True)
1362 
1363         for instance in building_insts:
1364             if timeutils.is_older_than(instance.created_at, timeout):
1365                 self._set_instance_obj_error_state(context, instance)
1366                 LOG.warning(_LW("Instance build timed out. Set to error "
1367                                 "state."), instance=instance)
1368 
1369     def _check_instance_exists(self, context, instance):
1370         """Ensure an instance with the same name is not already present."""
1371         if self.driver.instance_exists(instance):
1372             raise exception.InstanceExists(name=instance.name)
1373 
1374     def _allocate_network_async(self, context, instance, requested_networks,
1375                                 macs, security_groups, is_vpn, dhcp_options):
1376         """Method used to allocate networks in the background.
1377 
1378         Broken out for testing.
1379         """
1380         # First check to see if we're specifically not supposed to allocate
1381         # networks because if so, we can exit early.
1382         if requested_networks and requested_networks.no_allocate:
1383             LOG.debug("Not allocating networking since 'none' was specified.",
1384                       instance=instance)
1385             return network_model.NetworkInfo([])
1386 
1387         LOG.debug("Allocating IP information in the background.",
1388                   instance=instance)
1389         retries = CONF.network_allocate_retries
1390         attempts = retries + 1
1391         retry_time = 1
1392         bind_host_id = self.driver.network_binding_host_id(context, instance)
1393         for attempt in range(1, attempts + 1):
1394             try:
1395                 nwinfo = self.network_api.allocate_for_instance(
1396                         context, instance, vpn=is_vpn,
1397                         requested_networks=requested_networks,
1398                         macs=macs,
1399                         security_groups=security_groups,
1400                         dhcp_options=dhcp_options,
1401                         bind_host_id=bind_host_id)
1402                 LOG.debug('Instance network_info: |%s|', nwinfo,
1403                           instance=instance)
1404                 instance.system_metadata['network_allocated'] = 'True'
1405                 # NOTE(JoshNang) do not save the instance here, as it can cause
1406                 # races. The caller shares a reference to instance and waits
1407                 # for this async greenthread to finish before calling
1408                 # instance.save().
1409                 return nwinfo
1410             except Exception:
1411                 exc_info = sys.exc_info()
1412                 log_info = {'attempt': attempt,
1413                             'attempts': attempts}
1414                 if attempt == attempts:
1415                     LOG.exception(_LE('Instance failed network setup '
1416                                       'after %(attempts)d attempt(s)'),
1417                                   log_info)
1418                     six.reraise(*exc_info)
1419                 LOG.warning(_LW('Instance failed network setup '
1420                                 '(attempt %(attempt)d of %(attempts)d)'),
1421                             log_info, instance=instance)
1422                 time.sleep(retry_time)
1423                 retry_time *= 2
1424                 if retry_time > 30:
1425                     retry_time = 30
1426         # Not reached.
1427 
1428     def _build_networks_for_instance(self, context, instance,
1429             requested_networks, security_groups):
1430 
1431         # If we're here from a reschedule the network may already be allocated.
1432         if strutils.bool_from_string(
1433                 instance.system_metadata.get('network_allocated', 'False')):
1434             # NOTE(alex_xu): The network_allocated is True means the network
1435             # resource already allocated at previous scheduling, and the
1436             # network setup is cleanup at previous. After rescheduling, the
1437             # network resource need setup on the new host.
1438             self.network_api.setup_instance_network_on_host(
1439                 context, instance, instance.host)
1440             return self.network_api.get_instance_nw_info(context, instance)
1441 
1442         if not self.is_neutron_security_groups:
1443             security_groups = []
1444 
1445         macs = self.driver.macs_for_instance(instance)
1446         dhcp_options = self.driver.dhcp_options_for_instance(instance)
1447         network_info = self._allocate_network(context, instance,
1448                 requested_networks, macs, security_groups, dhcp_options)
1449 
1450         return network_info
1451 
1452     def _allocate_network(self, context, instance, requested_networks, macs,
1453                           security_groups, dhcp_options):
1454         """Start network allocation asynchronously.  Return an instance
1455         of NetworkInfoAsyncWrapper that can be used to retrieve the
1456         allocated networks when the operation has finished.
1457         """
1458         # NOTE(comstud): Since we're allocating networks asynchronously,
1459         # this task state has little meaning, as we won't be in this
1460         # state for very long.
1461         instance.vm_state = vm_states.BUILDING
1462         instance.task_state = task_states.NETWORKING
1463         instance.save(expected_task_state=[None])
1464         self._update_resource_tracker(context, instance)
1465 
1466         is_vpn = pipelib.is_vpn_image(instance.image_ref)
1467         return network_model.NetworkInfoAsyncWrapper(
1468                 self._allocate_network_async, context, instance,
1469                 requested_networks, macs, security_groups, is_vpn,
1470                 dhcp_options)
1471 
1472     def _default_root_device_name(self, instance, image_meta, root_bdm):
1473         try:
1474             return self.driver.default_root_device_name(instance,
1475                                                         image_meta,
1476                                                         root_bdm)
1477         except NotImplementedError:
1478             return compute_utils.get_next_device_name(instance, [])
1479 
1480     def _default_device_names_for_instance(self, instance,
1481                                            root_device_name,
1482                                            *block_device_lists):
1483         try:
1484             self.driver.default_device_names_for_instance(instance,
1485                                                           root_device_name,
1486                                                           *block_device_lists)
1487         except NotImplementedError:
1488             compute_utils.default_device_names_for_instance(
1489                 instance, root_device_name, *block_device_lists)
1490 
1491     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1492         # NOTE(ndipanov): Copy obj to avoid changing the original
1493         block_device_obj = block_device_obj.obj_clone()
1494         try:
1495             return self.driver.get_device_name_for_instance(
1496                 instance, bdms, block_device_obj)
1497         except NotImplementedError:
1498             return compute_utils.get_device_name_for_instance(
1499                 instance, bdms, block_device_obj.get("device_name"))
1500 
1501     def _default_block_device_names(self, instance, image_meta, block_devices):
1502         """Verify that all the devices have the device_name set. If not,
1503         provide a default name.
1504 
1505         It also ensures that there is a root_device_name and is set to the
1506         first block device in the boot sequence (boot_index=0).
1507         """
1508         root_bdm = block_device.get_root_bdm(block_devices)
1509         if not root_bdm:
1510             return
1511 
1512         # Get the root_device_name from the root BDM or the instance
1513         root_device_name = None
1514         update_root_bdm = False
1515 
1516         if root_bdm.device_name:
1517             root_device_name = root_bdm.device_name
1518             instance.root_device_name = root_device_name
1519         elif instance.root_device_name:
1520             root_device_name = instance.root_device_name
1521             root_bdm.device_name = root_device_name
1522             update_root_bdm = True
1523         else:
1524             root_device_name = self._default_root_device_name(instance,
1525                                                               image_meta,
1526                                                               root_bdm)
1527 
1528             instance.root_device_name = root_device_name
1529             root_bdm.device_name = root_device_name
1530             update_root_bdm = True
1531 
1532         if update_root_bdm:
1533             root_bdm.save()
1534 
1535         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1536                             block_devices))
1537         swap = list(filter(block_device.new_format_is_swap,
1538                       block_devices))
1539         block_device_mapping = list(filter(
1540               driver_block_device.is_block_device_mapping, block_devices))
1541 
1542         self._default_device_names_for_instance(instance,
1543                                                 root_device_name,
1544                                                 ephemerals,
1545                                                 swap,
1546                                                 block_device_mapping)
1547 
1548     def _block_device_info_to_legacy(self, block_device_info):
1549         """Convert BDI to the old format for drivers that need it."""
1550 
1551         if self.use_legacy_block_device_info:
1552             ephemerals = driver_block_device.legacy_block_devices(
1553                 driver.block_device_info_get_ephemerals(block_device_info))
1554             mapping = driver_block_device.legacy_block_devices(
1555                 driver.block_device_info_get_mapping(block_device_info))
1556             swap = block_device_info['swap']
1557             if swap:
1558                 swap = swap.legacy()
1559 
1560             block_device_info.update({
1561                 'ephemerals': ephemerals,
1562                 'swap': swap,
1563                 'block_device_mapping': mapping})
1564 
1565     def _add_missing_dev_names(self, bdms, instance):
1566         for bdm in bdms:
1567             if bdm.device_name is not None:
1568                 continue
1569 
1570             device_name = self._get_device_name_for_instance(instance,
1571                                                              bdms, bdm)
1572             values = {'device_name': device_name}
1573             bdm.update(values)
1574             bdm.save()
1575 
1576     def _prep_block_device(self, context, instance, bdms,
1577                            do_check_attach=True):
1578         """Set up the block device for an instance with error logging."""
1579         try:
1580             self._add_missing_dev_names(bdms, instance)
1581             block_device_info = driver.get_block_device_info(instance, bdms)
1582             mapping = driver.block_device_info_get_mapping(block_device_info)
1583             driver_block_device.attach_block_devices(
1584                 mapping, context, instance, self.volume_api, self.driver,
1585                 do_check_attach=do_check_attach,
1586                 wait_func=self._await_block_device_map_created)
1587 
1588             self._block_device_info_to_legacy(block_device_info)
1589             return block_device_info
1590 
1591         except exception.OverQuota:
1592             msg = _LW('Failed to create block device for instance due to '
1593                       'being over volume resource quota')
1594             LOG.warning(msg, instance=instance)
1595             raise exception.VolumeLimitExceeded()
1596 
1597         except Exception:
1598             LOG.exception(_LE('Instance failed block device setup'),
1599                           instance=instance)
1600             raise exception.InvalidBDM()
1601 
1602     def _update_instance_after_spawn(self, context, instance):
1603         instance.power_state = self._get_power_state(context, instance)
1604         instance.vm_state = vm_states.ACTIVE
1605         instance.task_state = None
1606         instance.launched_at = timeutils.utcnow()
1607         configdrive.update_instance(instance)
1608 
1609     def _update_scheduler_instance_info(self, context, instance):
1610         """Sends an InstanceList with created or updated Instance objects to
1611         the Scheduler client.
1612 
1613         In the case of init_host, the value passed will already be an
1614         InstanceList. Other calls will send individual Instance objects that
1615         have been created or resized. In this case, we create an InstanceList
1616         object containing that Instance.
1617         """
1618         if not self.send_instance_updates:
1619             return
1620         if isinstance(instance, obj_instance.Instance):
1621             instance = objects.InstanceList(objects=[instance])
1622         context = context.elevated()
1623         self.scheduler_client.update_instance_info(context, self.host,
1624                                                    instance)
1625 
1626     def _delete_scheduler_instance_info(self, context, instance_uuid):
1627         """Sends the uuid of the deleted Instance to the Scheduler client."""
1628         if not self.send_instance_updates:
1629             return
1630         context = context.elevated()
1631         self.scheduler_client.delete_instance_info(context, self.host,
1632                                                    instance_uuid)
1633 
1634     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1635     def _sync_scheduler_instance_info(self, context):
1636         if not self.send_instance_updates:
1637             return
1638         context = context.elevated()
1639         instances = objects.InstanceList.get_by_host(context, self.host,
1640                                                      expected_attrs=[],
1641                                                      use_slave=True)
1642         uuids = [instance.uuid for instance in instances]
1643         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1644 
1645     def _notify_about_instance_usage(self, context, instance, event_suffix,
1646                                      network_info=None, system_metadata=None,
1647                                      extra_usage_info=None, fault=None):
1648         compute_utils.notify_about_instance_usage(
1649             self.notifier, context, instance, event_suffix,
1650             network_info=network_info,
1651             system_metadata=system_metadata,
1652             extra_usage_info=extra_usage_info, fault=fault)
1653 
1654     def _deallocate_network(self, context, instance,
1655                             requested_networks=None):
1656         # If we were told not to allocate networks let's save ourselves
1657         # the trouble of calling the network API.
1658         if requested_networks and requested_networks.no_allocate:
1659             LOG.debug("Skipping network deallocation for instance since "
1660                       "networking was not requested.", instance=instance)
1661             return
1662 
1663         LOG.debug('Deallocating network for instance', instance=instance)
1664         with timeutils.StopWatch() as timer:
1665             self.network_api.deallocate_for_instance(
1666                 context, instance, requested_networks=requested_networks)
1667         # nova-network does an rpc call so we're OK tracking time spent here
1668         LOG.info(_LI('Took %0.2f seconds to deallocate network for instance.'),
1669                  timer.elapsed(), instance=instance)
1670 
1671     def _get_instance_block_device_info(self, context, instance,
1672                                         refresh_conn_info=False,
1673                                         bdms=None):
1674         """Transform block devices to the driver block_device format."""
1675 
1676         if not bdms:
1677             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1678                     context, instance.uuid)
1679         block_device_info = driver.get_block_device_info(instance, bdms)
1680 
1681         if not refresh_conn_info:
1682             # if the block_device_mapping has no value in connection_info
1683             # (returned as None), don't include in the mapping
1684             block_device_info['block_device_mapping'] = [
1685                 bdm for bdm in driver.block_device_info_get_mapping(
1686                                     block_device_info)
1687                 if bdm.get('connection_info')]
1688         else:
1689             driver_block_device.refresh_conn_infos(
1690                 driver.block_device_info_get_mapping(block_device_info),
1691                 context, instance, self.volume_api, self.driver)
1692 
1693         self._block_device_info_to_legacy(block_device_info)
1694 
1695         return block_device_info
1696 
1697     @wrap_exception()
1698     @reverts_task_state
1699     @wrap_instance_fault
1700     def build_and_run_instance(self, context, instance, image, request_spec,
1701                      filter_properties, admin_password=None,
1702                      injected_files=None, requested_networks=None,
1703                      security_groups=None, block_device_mapping=None,
1704                      node=None, limits=None):
1705 
1706         @utils.synchronized(instance.uuid)
1707         def _locked_do_build_and_run_instance(*args, **kwargs):
1708             # NOTE(danms): We grab the semaphore with the instance uuid
1709             # locked because we could wait in line to build this instance
1710             # for a while and we want to make sure that nothing else tries
1711             # to do anything with this instance while we wait.
1712             with self._build_semaphore:
1713                 self._do_build_and_run_instance(*args, **kwargs)
1714 
1715         # NOTE(danms): We spawn here to return the RPC worker thread back to
1716         # the pool. Since what follows could take a really long time, we don't
1717         # want to tie up RPC workers.
1718         utils.spawn_n(_locked_do_build_and_run_instance,
1719                       context, instance, image, request_spec,
1720                       filter_properties, admin_password, injected_files,
1721                       requested_networks, security_groups,
1722                       block_device_mapping, node, limits)
1723 
1724     def _check_device_tagging(self, requested_networks, block_device_mapping):
1725         tagging_requested = False
1726         if requested_networks:
1727             for net in requested_networks:
1728                 if 'tag' in net and net.tag is not None:
1729                     tagging_requested = True
1730                     break
1731         if block_device_mapping and not tagging_requested:
1732             for bdm in block_device_mapping:
1733                 if 'tag' in bdm and bdm.tag is not None:
1734                     tagging_requested = True
1735                     break
1736         if (tagging_requested and
1737                 not self.driver.capabilities.get('supports_device_tagging')):
1738             raise exception.BuildAbortException('Attempt to boot guest with '
1739                                                 'tagged devices on host that '
1740                                                 'does not support tagging.')
1741 
1742     @hooks.add_hook('build_instance')
1743     @wrap_exception()
1744     @reverts_task_state
1745     @wrap_instance_event(prefix='compute')
1746     @wrap_instance_fault
1747     def _do_build_and_run_instance(self, context, instance, image,
1748             request_spec, filter_properties, admin_password, injected_files,
1749             requested_networks, security_groups, block_device_mapping,
1750             node=None, limits=None):
1751 
1752         try:
1753             LOG.debug('Starting instance...', instance=instance)
1754             instance.vm_state = vm_states.BUILDING
1755             instance.task_state = None
1756             instance.save(expected_task_state=
1757                     (task_states.SCHEDULING, None))
1758         except exception.InstanceNotFound:
1759             msg = 'Instance disappeared before build.'
1760             LOG.debug(msg, instance=instance)
1761             return build_results.FAILED
1762         except exception.UnexpectedTaskStateError as e:
1763             LOG.debug(e.format_message(), instance=instance)
1764             return build_results.FAILED
1765 
1766         # b64 decode the files to inject:
1767         decoded_files = self._decode_files(injected_files)
1768 
1769         if limits is None:
1770             limits = {}
1771 
1772         if node is None:
1773             node = self.driver.get_available_nodes(refresh=True)[0]
1774             LOG.debug('No node specified, defaulting to %s', node,
1775                       instance=instance)
1776 
1777         try:
1778             with timeutils.StopWatch() as timer:
1779                 self._build_and_run_instance(context, instance, image,
1780                         decoded_files, admin_password, requested_networks,
1781                         security_groups, block_device_mapping, node, limits,
1782                         filter_properties)
1783             LOG.info(_LI('Took %0.2f seconds to build instance.'),
1784                      timer.elapsed(), instance=instance)
1785             return build_results.ACTIVE
1786         except exception.RescheduledException as e:
1787             retry = filter_properties.get('retry')
1788             if not retry:
1789                 # no retry information, do not reschedule.
1790                 LOG.debug("Retry info not present, will not reschedule",
1791                     instance=instance)
1792                 self._cleanup_allocated_networks(context, instance,
1793                     requested_networks)
1794                 compute_utils.add_instance_fault_from_exc(context,
1795                         instance, e, sys.exc_info(),
1796                         fault_message=e.kwargs['reason'])
1797                 self._nil_out_instance_obj_host_and_node(instance)
1798                 self._set_instance_obj_error_state(context, instance,
1799                                                    clean_task_state=True)
1800                 return build_results.FAILED
1801             LOG.debug(e.format_message(), instance=instance)
1802             # This will be used for logging the exception
1803             retry['exc'] = traceback.format_exception(*sys.exc_info())
1804             # This will be used for setting the instance fault message
1805             retry['exc_reason'] = e.kwargs['reason']
1806             # NOTE(comstud): Deallocate networks if the driver wants
1807             # us to do so.
1808             # NOTE(vladikr): SR-IOV ports should be deallocated to
1809             # allow new sriov pci devices to be allocated on a new host.
1810             # Otherwise, if devices with pci addresses are already allocated
1811             # on the destination host, the instance will fail to spawn.
1812             # info_cache.network_info should be present at this stage.
1813             if (self.driver.deallocate_networks_on_reschedule(instance) or
1814                 self.deallocate_sriov_ports_on_reschedule(instance)):
1815                 self._cleanup_allocated_networks(context, instance,
1816                         requested_networks)
1817             else:
1818                 # NOTE(alex_xu): Network already allocated and we don't
1819                 # want to deallocate them before rescheduling. But we need
1820                 # to cleanup those network resources setup on this host before
1821                 # rescheduling.
1822                 self.network_api.cleanup_instance_network_on_host(
1823                     context, instance, self.host)
1824 
1825             self._nil_out_instance_obj_host_and_node(instance)
1826             instance.task_state = task_states.SCHEDULING
1827             instance.save()
1828 
1829             self.compute_task_api.build_instances(context, [instance],
1830                     image, filter_properties, admin_password,
1831                     injected_files, requested_networks, security_groups,
1832                     block_device_mapping)
1833             return build_results.RESCHEDULED
1834         except (exception.InstanceNotFound,
1835                 exception.UnexpectedDeletingTaskStateError):
1836             msg = 'Instance disappeared during build.'
1837             LOG.debug(msg, instance=instance)
1838             self._cleanup_allocated_networks(context, instance,
1839                     requested_networks)
1840             return build_results.FAILED
1841         except exception.BuildAbortException as e:
1842             LOG.exception(e.format_message(), instance=instance)
1843             self._cleanup_allocated_networks(context, instance,
1844                     requested_networks)
1845             self._cleanup_volumes(context, instance.uuid,
1846                     block_device_mapping, raise_exc=False)
1847             compute_utils.add_instance_fault_from_exc(context, instance,
1848                     e, sys.exc_info())
1849             self._nil_out_instance_obj_host_and_node(instance)
1850             self._set_instance_obj_error_state(context, instance,
1851                                                clean_task_state=True)
1852             return build_results.FAILED
1853         except Exception as e:
1854             # Should not reach here.
1855             msg = _LE('Unexpected build failure, not rescheduling build.')
1856             LOG.exception(msg, instance=instance)
1857             self._cleanup_allocated_networks(context, instance,
1858                     requested_networks)
1859             self._cleanup_volumes(context, instance.uuid,
1860                     block_device_mapping, raise_exc=False)
1861             compute_utils.add_instance_fault_from_exc(context, instance,
1862                     e, sys.exc_info())
1863             self._nil_out_instance_obj_host_and_node(instance)
1864             self._set_instance_obj_error_state(context, instance,
1865                                                clean_task_state=True)
1866             return build_results.FAILED
1867 
1868     def deallocate_sriov_ports_on_reschedule(self, instance):
1869         """Determine if networks are needed to be deallocated before reschedule
1870 
1871         Check the cached network info for any assigned SR-IOV ports.
1872         SR-IOV ports should be deallocated prior to rescheduling
1873         in order to allow new sriov pci devices to be allocated on a new host.
1874         """
1875         info_cache = instance.info_cache
1876 
1877         def _has_sriov_port(vif):
1878             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1879 
1880         if (info_cache and info_cache.network_info):
1881             for vif in info_cache.network_info:
1882                 if _has_sriov_port(vif):
1883                     return True
1884         return False
1885 
1886     def _build_and_run_instance(self, context, instance, image, injected_files,
1887             admin_password, requested_networks, security_groups,
1888             block_device_mapping, node, limits, filter_properties):
1889 
1890         image_name = image.get('name')
1891         self._notify_about_instance_usage(context, instance, 'create.start',
1892                 extra_usage_info={'image_name': image_name})
1893 
1894         self._check_device_tagging(requested_networks, block_device_mapping)
1895 
1896         try:
1897             rt = self._get_resource_tracker(node)
1898             with rt.instance_claim(context, instance, limits):
1899                 # NOTE(russellb) It's important that this validation be done
1900                 # *after* the resource tracker instance claim, as that is where
1901                 # the host is set on the instance.
1902                 self._validate_instance_group_policy(context, instance,
1903                         filter_properties)
1904                 image_meta = objects.ImageMeta.from_dict(image)
1905                 with self._build_resources(context, instance,
1906                         requested_networks, security_groups, image_meta,
1907                         block_device_mapping) as resources:
1908                     instance.vm_state = vm_states.BUILDING
1909                     instance.task_state = task_states.SPAWNING
1910                     # NOTE(JoshNang) This also saves the changes to the
1911                     # instance from _allocate_network_async, as they aren't
1912                     # saved in that function to prevent races.
1913                     instance.save(expected_task_state=
1914                             task_states.BLOCK_DEVICE_MAPPING)
1915                     block_device_info = resources['block_device_info']
1916                     network_info = resources['network_info']
1917                     LOG.debug('Start spawning the instance on the hypervisor.',
1918                               instance=instance)
1919                     with timeutils.StopWatch() as timer:
1920                         self.driver.spawn(context, instance, image_meta,
1921                                           injected_files, admin_password,
1922                                           network_info=network_info,
1923                                           block_device_info=block_device_info)
1924                     LOG.info(_LI('Took %0.2f seconds to spawn the instance on '
1925                                  'the hypervisor.'), timer.elapsed(),
1926                              instance=instance)
1927         except (exception.InstanceNotFound,
1928                 exception.UnexpectedDeletingTaskStateError) as e:
1929             with excutils.save_and_reraise_exception():
1930                 self._notify_about_instance_usage(context, instance,
1931                     'create.error', fault=e)
1932         except exception.ComputeResourcesUnavailable as e:
1933             LOG.debug(e.format_message(), instance=instance)
1934             self._notify_about_instance_usage(context, instance,
1935                     'create.error', fault=e)
1936             raise exception.RescheduledException(
1937                     instance_uuid=instance.uuid, reason=e.format_message())
1938         except exception.BuildAbortException as e:
1939             with excutils.save_and_reraise_exception():
1940                 LOG.debug(e.format_message(), instance=instance)
1941                 self._notify_about_instance_usage(context, instance,
1942                     'create.error', fault=e)
1943         except (exception.FixedIpLimitExceeded,
1944                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
1945             LOG.warning(_LW('No more network or fixed IP to be allocated'),
1946                         instance=instance)
1947             self._notify_about_instance_usage(context, instance,
1948                     'create.error', fault=e)
1949             msg = _('Failed to allocate the network(s) with error %s, '
1950                     'not rescheduling.') % e.format_message()
1951             raise exception.BuildAbortException(instance_uuid=instance.uuid,
1952                     reason=msg)
1953         except (exception.VirtualInterfaceCreateException,
1954                 exception.VirtualInterfaceMacAddressException,
1955                 exception.FixedIpInvalidOnHost,
1956                 exception.UnableToAutoAllocateNetwork) as e:
1957             LOG.exception(_LE('Failed to allocate network(s)'),
1958                           instance=instance)
1959             self._notify_about_instance_usage(context, instance,
1960                     'create.error', fault=e)
1961             msg = _('Failed to allocate the network(s), not rescheduling.')
1962             raise exception.BuildAbortException(instance_uuid=instance.uuid,
1963                     reason=msg)
1964         except (exception.FlavorDiskTooSmall,
1965                 exception.FlavorMemoryTooSmall,
1966                 exception.ImageNotActive,
1967                 exception.ImageUnacceptable,
1968                 exception.InvalidDiskInfo,
1969                 exception.InvalidDiskFormat,
1970                 exception.SignatureVerificationError) as e:
1971             self._notify_about_instance_usage(context, instance,
1972                     'create.error', fault=e)
1973             raise exception.BuildAbortException(instance_uuid=instance.uuid,
1974                     reason=e.format_message())
1975         except Exception as e:
1976             self._notify_about_instance_usage(context, instance,
1977                     'create.error', fault=e)
1978             raise exception.RescheduledException(
1979                     instance_uuid=instance.uuid, reason=six.text_type(e))
1980 
1981         # NOTE(alaski): This is only useful during reschedules, remove it now.
1982         instance.system_metadata.pop('network_allocated', None)
1983 
1984         # If CONF.default_access_ip_network_name is set, grab the
1985         # corresponding network and set the access ip values accordingly.
1986         network_name = CONF.default_access_ip_network_name
1987         if (network_name and not instance.access_ip_v4 and
1988                 not instance.access_ip_v6):
1989             # Note that when there are multiple ips to choose from, an
1990             # arbitrary one will be chosen.
1991             for vif in network_info:
1992                 if vif['network']['label'] == network_name:
1993                     for ip in vif.fixed_ips():
1994                         if not instance.access_ip_v4 and ip['version'] == 4:
1995                             instance.access_ip_v4 = ip['address']
1996                         if not instance.access_ip_v6 and ip['version'] == 6:
1997                             instance.access_ip_v6 = ip['address']
1998                     break
1999 
2000         self._update_instance_after_spawn(context, instance)
2001 
2002         try:
2003             instance.save(expected_task_state=task_states.SPAWNING)
2004         except (exception.InstanceNotFound,
2005                 exception.UnexpectedDeletingTaskStateError) as e:
2006             with excutils.save_and_reraise_exception():
2007                 self._notify_about_instance_usage(context, instance,
2008                     'create.error', fault=e)
2009 
2010         self._update_scheduler_instance_info(context, instance)
2011         self._notify_about_instance_usage(context, instance, 'create.end',
2012                 extra_usage_info={'message': _('Success')},
2013                 network_info=network_info)
2014 
2015     @contextlib.contextmanager
2016     def _build_resources(self, context, instance, requested_networks,
2017                          security_groups, image_meta, block_device_mapping):
2018         resources = {}
2019         network_info = None
2020         try:
2021             LOG.debug('Start building networks asynchronously for instance.',
2022                       instance=instance)
2023             network_info = self._build_networks_for_instance(context, instance,
2024                     requested_networks, security_groups)
2025             resources['network_info'] = network_info
2026         except (exception.InstanceNotFound,
2027                 exception.UnexpectedDeletingTaskStateError):
2028             raise
2029         except exception.UnexpectedTaskStateError as e:
2030             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2031                     reason=e.format_message())
2032         except Exception:
2033             # Because this allocation is async any failures are likely to occur
2034             # when the driver accesses network_info during spawn().
2035             LOG.exception(_LE('Failed to allocate network(s)'),
2036                           instance=instance)
2037             msg = _('Failed to allocate the network(s), not rescheduling.')
2038             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2039                     reason=msg)
2040 
2041         try:
2042             # Verify that all the BDMs have a device_name set and assign a
2043             # default to the ones missing it with the help of the driver.
2044             self._default_block_device_names(instance, image_meta,
2045                                              block_device_mapping)
2046 
2047             LOG.debug('Start building block device mappings for instance.',
2048                       instance=instance)
2049             instance.vm_state = vm_states.BUILDING
2050             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2051             instance.save()
2052 
2053             block_device_info = self._prep_block_device(context, instance,
2054                     block_device_mapping)
2055             resources['block_device_info'] = block_device_info
2056         except (exception.InstanceNotFound,
2057                 exception.UnexpectedDeletingTaskStateError):
2058             with excutils.save_and_reraise_exception():
2059                 # Make sure the async call finishes
2060                 if network_info is not None:
2061                     network_info.wait(do_raise=False)
2062         except (exception.UnexpectedTaskStateError,
2063                 exception.VolumeLimitExceeded,
2064                 exception.InvalidBDM) as e:
2065             # Make sure the async call finishes
2066             if network_info is not None:
2067                 network_info.wait(do_raise=False)
2068             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2069                     reason=e.format_message())
2070         except Exception:
2071             LOG.exception(_LE('Failure prepping block device'),
2072                     instance=instance)
2073             # Make sure the async call finishes
2074             if network_info is not None:
2075                 network_info.wait(do_raise=False)
2076             msg = _('Failure prepping block device.')
2077             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2078                     reason=msg)
2079 
2080         try:
2081             yield resources
2082         except Exception as exc:
2083             with excutils.save_and_reraise_exception() as ctxt:
2084                 if not isinstance(exc, (
2085                         exception.InstanceNotFound,
2086                         exception.UnexpectedDeletingTaskStateError)):
2087                     LOG.exception(_LE('Instance failed to spawn'),
2088                                   instance=instance)
2089                 # Make sure the async call finishes
2090                 if network_info is not None:
2091                     network_info.wait(do_raise=False)
2092                 # if network_info is empty we're likely here because of
2093                 # network allocation failure. Since nothing can be reused on
2094                 # rescheduling it's better to deallocate network to eliminate
2095                 # the chance of orphaned ports in neutron
2096                 deallocate_networks = False if network_info else True
2097                 try:
2098                     self._shutdown_instance(context, instance,
2099                             block_device_mapping, requested_networks,
2100                             try_deallocate_networks=deallocate_networks)
2101                 except Exception as exc2:
2102                     ctxt.reraise = False
2103                     LOG.warning(_LW('Could not clean up failed build,'
2104                                     ' not rescheduling. Error: %s'),
2105                                 six.text_type(exc2))
2106                     raise exception.BuildAbortException(
2107                             instance_uuid=instance.uuid,
2108                             reason=six.text_type(exc))
2109 
2110     def _cleanup_allocated_networks(self, context, instance,
2111             requested_networks):
2112         try:
2113             self._deallocate_network(context, instance, requested_networks)
2114         except Exception:
2115             msg = _LE('Failed to deallocate networks')
2116             LOG.exception(msg, instance=instance)
2117             return
2118 
2119         instance.system_metadata['network_allocated'] = 'False'
2120         try:
2121             instance.save()
2122         except exception.InstanceNotFound:
2123             # NOTE(alaski): It's possible that we're cleaning up the networks
2124             # because the instance was deleted.  If that's the case then this
2125             # exception will be raised by instance.save()
2126             pass
2127 
2128     def _try_deallocate_network(self, context, instance,
2129                                 requested_networks=None):
2130         try:
2131             # tear down allocated network structure
2132             self._deallocate_network(context, instance, requested_networks)
2133         except Exception as ex:
2134             with excutils.save_and_reraise_exception():
2135                 LOG.error(_LE('Failed to deallocate network for instance. '
2136                               'Error: %s'), ex,
2137                           instance=instance)
2138                 self._set_instance_obj_error_state(context, instance)
2139 
2140     def _get_power_off_values(self, context, instance, clean_shutdown):
2141         """Get the timing configuration for powering down this instance."""
2142         if clean_shutdown:
2143             timeout = compute_utils.get_value_from_system_metadata(instance,
2144                           key='image_os_shutdown_timeout', type=int,
2145                           default=CONF.shutdown_timeout)
2146             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2147         else:
2148             timeout = 0
2149             retry_interval = 0
2150 
2151         return timeout, retry_interval
2152 
2153     def _power_off_instance(self, context, instance, clean_shutdown=True):
2154         """Power off an instance on this host."""
2155         timeout, retry_interval = self._get_power_off_values(context,
2156                                         instance, clean_shutdown)
2157         self.driver.power_off(instance, timeout, retry_interval)
2158 
2159     def _shutdown_instance(self, context, instance,
2160                            bdms, requested_networks=None, notify=True,
2161                            try_deallocate_networks=True):
2162         """Shutdown an instance on this host.
2163 
2164         :param:context: security context
2165         :param:instance: a nova.objects.Instance object
2166         :param:bdms: the block devices for the instance to be torn
2167                      down
2168         :param:requested_networks: the networks on which the instance
2169                                    has ports
2170         :param:notify: true if a final usage notification should be
2171                        emitted
2172         :param:try_deallocate_networks: false if we should avoid
2173                                         trying to teardown networking
2174         """
2175         context = context.elevated()
2176         LOG.info(_LI('Terminating instance'), instance=instance)
2177 
2178         if notify:
2179             self._notify_about_instance_usage(context, instance,
2180                                               "shutdown.start")
2181 
2182         network_info = compute_utils.get_nw_info_for_instance(instance)
2183 
2184         # NOTE(vish) get bdms before destroying the instance
2185         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2186         block_device_info = self._get_instance_block_device_info(
2187             context, instance, bdms=bdms)
2188 
2189         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2190         #                want to keep ip allocated for certain failures
2191         timer = timeutils.StopWatch()
2192         try:
2193             LOG.debug('Start destroying the instance on the hypervisor.',
2194                       instance=instance)
2195             timer.start()
2196             self.driver.destroy(context, instance, network_info,
2197                     block_device_info)
2198             LOG.info(_LI('Took %0.2f seconds to destroy the instance on the '
2199                          'hypervisor.'), timer.elapsed(), instance=instance)
2200         except exception.InstancePowerOffFailure:
2201             # if the instance can't power off, don't release the ip
2202             with excutils.save_and_reraise_exception():
2203                 pass
2204         except Exception:
2205             with excutils.save_and_reraise_exception():
2206                 # deallocate ip and fail without proceeding to
2207                 # volume api calls, preserving current behavior
2208                 if try_deallocate_networks:
2209                     self._try_deallocate_network(context, instance,
2210                                                  requested_networks)
2211 
2212         if try_deallocate_networks:
2213             self._try_deallocate_network(context, instance, requested_networks)
2214 
2215         timer.restart()
2216         for bdm in vol_bdms:
2217             try:
2218                 # NOTE(vish): actual driver detach done in driver.destroy, so
2219                 #             just tell cinder that we are done with it.
2220                 connector = self.driver.get_volume_connector(instance)
2221                 self.volume_api.terminate_connection(context,
2222                                                      bdm.volume_id,
2223                                                      connector)
2224                 self.volume_api.detach(context, bdm.volume_id, instance.uuid)
2225             except exception.DiskNotFound as exc:
2226                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2227                           instance=instance)
2228             except exception.VolumeNotFound as exc:
2229                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2230                           instance=instance)
2231             except (cinder_exception.EndpointNotFound,
2232                     keystone_exception.EndpointNotFound) as exc:
2233                 LOG.warning(_LW('Ignoring EndpointNotFound for '
2234                                 'volume %(volume_id)s: %(exc)s'),
2235                             {'exc': exc, 'volume_id': bdm.volume_id},
2236                             instance=instance)
2237             except cinder_exception.ClientException as exc:
2238                 LOG.warning(_LW('Ignoring unknown cinder exception for '
2239                                 'volume %(volume_id)s: %(exc)s'),
2240                             {'exc': exc, 'volume_id': bdm.volume_id},
2241                             instance=instance)
2242             except Exception as exc:
2243                 LOG.warning(_LW('Ignoring unknown exception for '
2244                                 'volume %(volume_id)s: %(exc)s'),
2245                             {'exc': exc, 'volume_id': bdm.volume_id},
2246                             instance=instance)
2247         if vol_bdms:
2248             LOG.info(_LI('Took %(time).2f seconds to detach %(num)s volumes '
2249                          'for instance.'),
2250                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2251                      instance=instance)
2252 
2253         if notify:
2254             self._notify_about_instance_usage(context, instance,
2255                                               "shutdown.end")
2256 
2257     def _cleanup_volumes(self, context, instance_uuid, bdms, raise_exc=True):
2258         exc_info = None
2259 
2260         for bdm in bdms:
2261             LOG.debug("terminating bdm %s", bdm,
2262                       instance_uuid=instance_uuid)
2263             if bdm.volume_id and bdm.delete_on_termination:
2264                 try:
2265                     self.volume_api.delete(context, bdm.volume_id)
2266                 except Exception as exc:
2267                     exc_info = sys.exc_info()
2268                     LOG.warning(_LW('Failed to delete volume: %(volume_id)s '
2269                                     'due to %(exc)s'),
2270                                 {'volume_id': bdm.volume_id, 'exc': exc})
2271         if exc_info is not None and raise_exc:
2272             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2273 
2274     @hooks.add_hook("delete_instance")
2275     def _delete_instance(self, context, instance, bdms, quotas):
2276         """Delete an instance on this host.  Commit or rollback quotas
2277         as necessary.
2278 
2279         :param context: nova request context
2280         :param instance: nova.objects.instance.Instance object
2281         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2282         :param quotas: nova.objects.quotas.Quotas object
2283         """
2284         was_soft_deleted = instance.vm_state == vm_states.SOFT_DELETED
2285         if was_soft_deleted:
2286             # Instances in SOFT_DELETED vm_state have already had quotas
2287             # decremented.
2288             try:
2289                 quotas.rollback()
2290             except Exception:
2291                 pass
2292 
2293         try:
2294             events = self.instance_events.clear_events_for_instance(instance)
2295             if events:
2296                 LOG.debug('Events pending at deletion: %(events)s',
2297                           {'events': ','.join(events.keys())},
2298                           instance=instance)
2299             self._notify_about_instance_usage(context, instance,
2300                                               "delete.start")
2301             compute_utils.notify_about_instance_action(context, instance,
2302                     self.host, action=fields.NotificationAction.DELETE,
2303                     phase=fields.NotificationPhase.START)
2304 
2305             self._shutdown_instance(context, instance, bdms)
2306             # NOTE(dims): instance.info_cache.delete() should be called after
2307             # _shutdown_instance in the compute manager as shutdown calls
2308             # deallocate_for_instance so the info_cache is still needed
2309             # at this point.
2310             if instance.info_cache is not None:
2311                 instance.info_cache.delete()
2312             else:
2313                 # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2314                 # is None. When the root cause that instance.info_cache becomes
2315                 # None is fixed, the log level should be reconsidered.
2316                 LOG.warning(_LW("Info cache for instance could not be found. "
2317                                 "Ignore."), instance=instance)
2318 
2319             # NOTE(vish): We have already deleted the instance, so we have
2320             #             to ignore problems cleaning up the volumes. It
2321             #             would be nice to let the user know somehow that
2322             #             the volume deletion failed, but it is not
2323             #             acceptable to have an instance that can not be
2324             #             deleted. Perhaps this could be reworked in the
2325             #             future to set an instance fault the first time
2326             #             and to only ignore the failure if the instance
2327             #             is already in ERROR.
2328             self._cleanup_volumes(context, instance.uuid, bdms,
2329                     raise_exc=False)
2330             # if a delete task succeeded, always update vm state and task
2331             # state without expecting task state to be DELETING
2332             instance.vm_state = vm_states.DELETED
2333             instance.task_state = None
2334             instance.power_state = power_state.NOSTATE
2335             instance.terminated_at = timeutils.utcnow()
2336             instance.save()
2337             system_meta = instance.system_metadata
2338             instance.destroy()
2339         except Exception:
2340             with excutils.save_and_reraise_exception():
2341                 quotas.rollback()
2342 
2343         self._complete_deletion(context,
2344                                 instance,
2345                                 bdms,
2346                                 quotas,
2347                                 system_meta)
2348 
2349     @wrap_exception()
2350     @reverts_task_state
2351     @wrap_instance_event(prefix='compute')
2352     @wrap_instance_fault
2353     def terminate_instance(self, context, instance, bdms, reservations):
2354         """Terminate an instance on this host."""
2355         quotas = objects.Quotas.from_reservations(context,
2356                                                   reservations,
2357                                                   instance=instance)
2358 
2359         @utils.synchronized(instance.uuid)
2360         def do_terminate_instance(instance, bdms):
2361             # NOTE(mriedem): If we are deleting the instance while it was
2362             # booting from volume, we could be racing with a database update of
2363             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2364             # to compute here, the BDMs may be stale at this point. So check
2365             # for any volume BDMs that don't have volume_id set and if we
2366             # detect that, we need to refresh the BDM list before proceeding.
2367             # TODO(mriedem): Move this into _delete_instance and make the bdms
2368             # parameter optional.
2369             for bdm in list(bdms):
2370                 if bdm.is_volume and not bdm.volume_id:
2371                     LOG.debug('There are potentially stale BDMs during '
2372                               'delete, refreshing the BlockDeviceMappingList.',
2373                               instance=instance)
2374                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2375                         context, instance.uuid)
2376                     break
2377             try:
2378                 self._delete_instance(context, instance, bdms, quotas)
2379             except exception.InstanceNotFound:
2380                 LOG.info(_LI("Instance disappeared during terminate"),
2381                          instance=instance)
2382             except Exception:
2383                 # As we're trying to delete always go to Error if something
2384                 # goes wrong that _delete_instance can't handle.
2385                 with excutils.save_and_reraise_exception():
2386                     LOG.exception(_LE('Setting instance vm_state to ERROR'),
2387                                   instance=instance)
2388                     self._set_instance_obj_error_state(context, instance)
2389 
2390         do_terminate_instance(instance, bdms)
2391 
2392     # NOTE(johannes): This is probably better named power_off_instance
2393     # so it matches the driver method, but because of other issues, we
2394     # can't use that name in grizzly.
2395     @wrap_exception()
2396     @reverts_task_state
2397     @wrap_instance_event(prefix='compute')
2398     @wrap_instance_fault
2399     def stop_instance(self, context, instance, clean_shutdown):
2400         """Stopping an instance on this host."""
2401 
2402         @utils.synchronized(instance.uuid)
2403         def do_stop_instance():
2404             current_power_state = self._get_power_state(context, instance)
2405             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2406                       'current task_state: %(task_state)s, current DB '
2407                       'power_state: %(db_power_state)s, current VM '
2408                       'power_state: %(current_power_state)s',
2409                       {'vm_state': instance.vm_state,
2410                        'task_state': instance.task_state,
2411                        'db_power_state': instance.power_state,
2412                        'current_power_state': current_power_state},
2413                       instance_uuid=instance.uuid)
2414 
2415             # NOTE(mriedem): If the instance is already powered off, we are
2416             # possibly tearing down and racing with other operations, so we can
2417             # expect the task_state to be None if something else updates the
2418             # instance and we're not locking it.
2419             expected_task_state = [task_states.POWERING_OFF]
2420             # The list of power states is from _sync_instance_power_state.
2421             if current_power_state in (power_state.NOSTATE,
2422                                        power_state.SHUTDOWN,
2423                                        power_state.CRASHED):
2424                 LOG.info(_LI('Instance is already powered off in the '
2425                              'hypervisor when stop is called.'),
2426                          instance=instance)
2427                 expected_task_state.append(None)
2428 
2429             self._notify_about_instance_usage(context, instance,
2430                                               "power_off.start")
2431             self._power_off_instance(context, instance, clean_shutdown)
2432             instance.power_state = self._get_power_state(context, instance)
2433             instance.vm_state = vm_states.STOPPED
2434             instance.task_state = None
2435             instance.save(expected_task_state=expected_task_state)
2436             self._notify_about_instance_usage(context, instance,
2437                                               "power_off.end")
2438 
2439         do_stop_instance()
2440 
2441     def _power_on(self, context, instance):
2442         network_info = self.network_api.get_instance_nw_info(context, instance)
2443         block_device_info = self._get_instance_block_device_info(context,
2444                                                                  instance)
2445         self.driver.power_on(context, instance,
2446                              network_info,
2447                              block_device_info)
2448 
2449     def _delete_snapshot_of_shelved_instance(self, context, instance,
2450                                              snapshot_id):
2451         """Delete snapshot of shelved instance."""
2452         try:
2453             self.image_api.delete(context, snapshot_id)
2454         except (exception.ImageNotFound,
2455                 exception.ImageNotAuthorized) as exc:
2456             LOG.warning(_LW("Failed to delete snapshot "
2457                             "from shelved instance (%s)."),
2458                         exc.format_message(), instance=instance)
2459         except Exception:
2460             LOG.exception(_LE("Something wrong happened when trying to "
2461                               "delete snapshot from shelved instance."),
2462                           instance=instance)
2463 
2464     # NOTE(johannes): This is probably better named power_on_instance
2465     # so it matches the driver method, but because of other issues, we
2466     # can't use that name in grizzly.
2467     @wrap_exception()
2468     @reverts_task_state
2469     @wrap_instance_event(prefix='compute')
2470     @wrap_instance_fault
2471     def start_instance(self, context, instance):
2472         """Starting an instance on this host."""
2473         self._notify_about_instance_usage(context, instance, "power_on.start")
2474         compute_utils.notify_about_instance_action(context, instance,
2475             self.host, action=fields.NotificationAction.POWER_ON,
2476             phase=fields.NotificationPhase.START)
2477         self._power_on(context, instance)
2478         instance.power_state = self._get_power_state(context, instance)
2479         instance.vm_state = vm_states.ACTIVE
2480         instance.task_state = None
2481 
2482         # Delete an image(VM snapshot) for a shelved instance
2483         snapshot_id = instance.system_metadata.get('shelved_image_id')
2484         if snapshot_id:
2485             self._delete_snapshot_of_shelved_instance(context, instance,
2486                                                       snapshot_id)
2487 
2488         # Delete system_metadata for a shelved instance
2489         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2490 
2491         instance.save(expected_task_state=task_states.POWERING_ON)
2492         self._notify_about_instance_usage(context, instance, "power_on.end")
2493         compute_utils.notify_about_instance_action(context, instance,
2494             self.host, action=fields.NotificationAction.POWER_ON,
2495             phase=fields.NotificationPhase.END)
2496 
2497     @messaging.expected_exceptions(NotImplementedError,
2498                                    exception.TriggerCrashDumpNotSupported,
2499                                    exception.InstanceNotRunning)
2500     @wrap_exception()
2501     @wrap_instance_event(prefix='compute')
2502     @wrap_instance_fault
2503     def trigger_crash_dump(self, context, instance):
2504         """Trigger crash dump in an instance."""
2505 
2506         self._notify_about_instance_usage(context, instance,
2507                                           "trigger_crash_dump.start")
2508 
2509         # This method does not change task_state and power_state because the
2510         # effect of a trigger depends on user's configuration.
2511         self.driver.trigger_crash_dump(instance)
2512 
2513         self._notify_about_instance_usage(context, instance,
2514                                           "trigger_crash_dump.end")
2515 
2516     @wrap_exception()
2517     @reverts_task_state
2518     @wrap_instance_event(prefix='compute')
2519     @wrap_instance_fault
2520     def soft_delete_instance(self, context, instance, reservations):
2521         """Soft delete an instance on this host."""
2522 
2523         quotas = objects.Quotas.from_reservations(context,
2524                                                   reservations,
2525                                                   instance=instance)
2526         try:
2527             self._notify_about_instance_usage(context, instance,
2528                                               "soft_delete.start")
2529             try:
2530                 self.driver.soft_delete(instance)
2531             except NotImplementedError:
2532                 # Fallback to just powering off the instance if the
2533                 # hypervisor doesn't implement the soft_delete method
2534                 self.driver.power_off(instance)
2535             instance.power_state = self._get_power_state(context, instance)
2536             instance.vm_state = vm_states.SOFT_DELETED
2537             instance.task_state = None
2538             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2539         except Exception:
2540             with excutils.save_and_reraise_exception():
2541                 quotas.rollback()
2542         quotas.commit()
2543         self._notify_about_instance_usage(context, instance, "soft_delete.end")
2544 
2545     @wrap_exception()
2546     @reverts_task_state
2547     @wrap_instance_event(prefix='compute')
2548     @wrap_instance_fault
2549     def restore_instance(self, context, instance):
2550         """Restore a soft-deleted instance on this host."""
2551         self._notify_about_instance_usage(context, instance, "restore.start")
2552         compute_utils.notify_about_instance_action(context, instance,
2553             self.host, action=fields.NotificationAction.RESTORE,
2554             phase=fields.NotificationPhase.START)
2555         try:
2556             self.driver.restore(instance)
2557         except NotImplementedError:
2558             # Fallback to just powering on the instance if the hypervisor
2559             # doesn't implement the restore method
2560             self._power_on(context, instance)
2561         instance.power_state = self._get_power_state(context, instance)
2562         instance.vm_state = vm_states.ACTIVE
2563         instance.task_state = None
2564         instance.save(expected_task_state=task_states.RESTORING)
2565         self._notify_about_instance_usage(context, instance, "restore.end")
2566         compute_utils.notify_about_instance_action(context, instance,
2567             self.host, action=fields.NotificationAction.RESTORE,
2568             phase=fields.NotificationPhase.END)
2569 
2570     @staticmethod
2571     def _set_migration_status(migration, status, unless_status=_SENTINEL):
2572         """Set the status, and guard against a None being passed in.
2573 
2574         This is useful as some of the compute RPC calls will not pass
2575         a migration object in older versions. The check can be removed when
2576         we move past 4.x major version of the RPC API.
2577 
2578         If unless_status is passed in - it will guard against clobbering a
2579         terminal status (for example 'failed' or 'finished')
2580         """
2581         if migration:
2582             if (unless_status is _SENTINEL or
2583                     migration.status not in unless_status):
2584                 migration.status = status
2585                 migration.save()
2586             else:
2587                 current_status = next(
2588                         mig_status for mig_status in unless_status
2589                         if mig_status == migration.status)
2590                 LOG.debug("Attempt to override migration status "
2591                           "%(status)s with %(new_status)s was skipped.",
2592                           {"status": current_status, "new_status": status},
2593                           instance=migration.instance)
2594 
2595     def _rebuild_default_impl(self, context, instance, image_meta,
2596                               injected_files, admin_password, bdms,
2597                               detach_block_devices, attach_block_devices,
2598                               network_info=None,
2599                               recreate=False, block_device_info=None,
2600                               preserve_ephemeral=False):
2601         if preserve_ephemeral:
2602             # The default code path does not support preserving ephemeral
2603             # partitions.
2604             raise exception.PreserveEphemeralNotSupported()
2605 
2606         if recreate:
2607             detach_block_devices(context, bdms)
2608         else:
2609             self._power_off_instance(context, instance, clean_shutdown=True)
2610             detach_block_devices(context, bdms)
2611             self.driver.destroy(context, instance,
2612                                 network_info=network_info,
2613                                 block_device_info=block_device_info)
2614 
2615         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2616         instance.save(expected_task_state=[task_states.REBUILDING])
2617 
2618         new_block_device_info = attach_block_devices(context, instance, bdms)
2619 
2620         instance.task_state = task_states.REBUILD_SPAWNING
2621         instance.save(
2622             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2623 
2624         with instance.mutated_migration_context():
2625             self.driver.spawn(context, instance, image_meta, injected_files,
2626                               admin_password, network_info=network_info,
2627                               block_device_info=new_block_device_info)
2628 
2629     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2630     @wrap_exception()
2631     @reverts_task_state
2632     @wrap_instance_event(prefix='compute')
2633     @wrap_instance_fault
2634     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2635                          injected_files, new_pass, orig_sys_metadata,
2636                          bdms, recreate, on_shared_storage=None,
2637                          preserve_ephemeral=False, migration=None,
2638                          scheduled_node=None, limits=None):
2639         """Destroy and re-make this instance.
2640 
2641         A 'rebuild' effectively purges all existing data from the system and
2642         remakes the VM with given 'metadata' and 'personalities'.
2643 
2644         :param context: `nova.RequestContext` object
2645         :param instance: Instance object
2646         :param orig_image_ref: Original image_ref before rebuild
2647         :param image_ref: New image_ref for rebuild
2648         :param injected_files: Files to inject
2649         :param new_pass: password to set on rebuilt instance
2650         :param orig_sys_metadata: instance system metadata from pre-rebuild
2651         :param bdms: block-device-mappings to use for rebuild
2652         :param recreate: True if the instance is being recreated (e.g. the
2653             hypervisor it was on failed) - cleanup of old state will be
2654             skipped.
2655         :param on_shared_storage: True if instance files on shared storage.
2656                                   If not provided then information from the
2657                                   driver will be used to decide if the instance
2658                                   files are available or not on the target host
2659         :param preserve_ephemeral: True if the default ephemeral storage
2660                                    partition must be preserved on rebuild
2661         :param migration: a Migration object if one was created for this
2662                           rebuild operation (if it's a part of evacuate)
2663         :param scheduled_node: A node of the host chosen by the scheduler. If a
2664                                host was specified by the user, this will be
2665                                None
2666         :param limits: Overcommit limits set by the scheduler. If a host was
2667                        specified by the user, this will be None
2668         """
2669         context = context.elevated()
2670 
2671         LOG.info(_LI("Rebuilding instance"), instance=instance)
2672         if scheduled_node is not None:
2673             rt = self._get_resource_tracker(scheduled_node)
2674             rebuild_claim = rt.rebuild_claim
2675         else:
2676             rebuild_claim = claims.NopClaim
2677 
2678         image_meta = {}
2679         if image_ref:
2680             image_meta = self.image_api.get(context, image_ref)
2681 
2682         # NOTE(mriedem): On a recreate (evacuate), we need to update
2683         # the instance's host and node properties to reflect it's
2684         # destination node for the recreate.
2685         if not scheduled_node:
2686             if recreate:
2687                 try:
2688                     compute_node = self._get_compute_info(context, self.host)
2689                     scheduled_node = compute_node.hypervisor_hostname
2690                 except exception.ComputeHostNotFound:
2691                     LOG.exception(_LE('Failed to get compute_info for %s'),
2692                                   self.host)
2693             else:
2694                 scheduled_node = instance.node
2695 
2696         with self._error_out_instance_on_exception(context, instance):
2697             try:
2698                 claim_ctxt = rebuild_claim(
2699                     context, instance, limits=limits, image_meta=image_meta,
2700                     migration=migration)
2701                 self._do_rebuild_instance_with_claim(
2702                     claim_ctxt, context, instance, orig_image_ref,
2703                     image_ref, injected_files, new_pass, orig_sys_metadata,
2704                     bdms, recreate, on_shared_storage, preserve_ephemeral)
2705             except exception.ComputeResourcesUnavailable as e:
2706                 LOG.debug("Could not rebuild instance on this host, not "
2707                           "enough resources available.", instance=instance)
2708 
2709                 # NOTE(ndipanov): We just abort the build for now and leave a
2710                 # migration record for potential cleanup later
2711                 self._set_migration_status(migration, 'failed')
2712 
2713                 self._notify_about_instance_usage(context, instance,
2714                         'rebuild.error', fault=e)
2715                 raise exception.BuildAbortException(
2716                     instance_uuid=instance.uuid, reason=e.format_message())
2717             except (exception.InstanceNotFound,
2718                     exception.UnexpectedDeletingTaskStateError) as e:
2719                 LOG.debug('Instance was deleted while rebuilding',
2720                           instance=instance)
2721                 self._set_migration_status(migration, 'failed')
2722                 self._notify_about_instance_usage(context, instance,
2723                         'rebuild.error', fault=e)
2724             except Exception as e:
2725                 self._set_migration_status(migration, 'failed')
2726                 self._notify_about_instance_usage(context, instance,
2727                         'rebuild.error', fault=e)
2728                 raise
2729             else:
2730                 instance.apply_migration_context()
2731                 # NOTE (ndipanov): This save will now update the host and node
2732                 # attributes making sure that next RT pass is consistent since
2733                 # it will be based on the instance and not the migration DB
2734                 # entry.
2735                 instance.host = self.host
2736                 instance.node = scheduled_node
2737                 instance.save()
2738                 instance.drop_migration_context()
2739 
2740                 # NOTE (ndipanov): Mark the migration as done only after we
2741                 # mark the instance as belonging to this host.
2742                 self._set_migration_status(migration, 'done')
2743 
2744     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2745         """Helper to avoid deep nesting in the top-level method."""
2746 
2747         with claim_context:
2748             self._do_rebuild_instance(*args, **kwargs)
2749 
2750     @staticmethod
2751     def _get_image_name(image_meta):
2752         if image_meta.obj_attr_is_set("name"):
2753             return image_meta.name
2754         else:
2755             return ''
2756 
2757     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2758                              image_ref, injected_files, new_pass,
2759                              orig_sys_metadata, bdms, recreate,
2760                              on_shared_storage, preserve_ephemeral):
2761         orig_vm_state = instance.vm_state
2762 
2763         if recreate:
2764             if not self.driver.capabilities["supports_recreate"]:
2765                 raise exception.InstanceRecreateNotSupported
2766 
2767             self._check_instance_exists(context, instance)
2768 
2769             if on_shared_storage is None:
2770                 LOG.debug('on_shared_storage is not provided, using driver'
2771                             'information to decide if the instance needs to'
2772                             'be recreated')
2773                 on_shared_storage = self.driver.instance_on_disk(instance)
2774 
2775             elif (on_shared_storage !=
2776                     self.driver.instance_on_disk(instance)):
2777                 # To cover case when admin expects that instance files are
2778                 # on shared storage, but not accessible and vice versa
2779                 raise exception.InvalidSharedStorage(
2780                         _("Invalid state of instance files on shared"
2781                             " storage"))
2782 
2783             if on_shared_storage:
2784                 LOG.info(_LI('disk on shared storage, recreating using'
2785                                 ' existing disk'))
2786             else:
2787                 image_ref = orig_image_ref = instance.image_ref
2788                 LOG.info(_LI("disk not on shared storage, rebuilding from:"
2789                                 " '%s'"), str(image_ref))
2790 
2791         if image_ref:
2792             image_meta = objects.ImageMeta.from_image_ref(
2793                 context, self.image_api, image_ref)
2794         else:
2795             image_meta = instance.image_meta
2796 
2797         # This instance.exists message should contain the original
2798         # image_ref, not the new one.  Since the DB has been updated
2799         # to point to the new one... we have to override it.
2800         # TODO(jaypipes): Move generate_image_url() into the nova.image.api
2801         orig_image_ref_url = glance.generate_image_url(orig_image_ref)
2802         extra_usage_info = {'image_ref_url': orig_image_ref_url}
2803         compute_utils.notify_usage_exists(
2804                 self.notifier, context, instance,
2805                 current_period=True, system_metadata=orig_sys_metadata,
2806                 extra_usage_info=extra_usage_info)
2807 
2808         # This message should contain the new image_ref
2809         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
2810         self._notify_about_instance_usage(context, instance,
2811                 "rebuild.start", extra_usage_info=extra_usage_info)
2812 
2813         instance.power_state = self._get_power_state(context, instance)
2814         instance.task_state = task_states.REBUILDING
2815         instance.save(expected_task_state=[task_states.REBUILDING])
2816 
2817         if recreate:
2818             self.network_api.setup_networks_on_host(
2819                     context, instance, self.host)
2820             # For nova-network this is needed to move floating IPs
2821             # For neutron this updates the host in the port binding
2822             # TODO(cfriesen): this network_api call and the one above
2823             # are so similar, we should really try to unify them.
2824             self.network_api.setup_instance_network_on_host(
2825                     context, instance, self.host)
2826 
2827         network_info = compute_utils.get_nw_info_for_instance(instance)
2828         if bdms is None:
2829             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2830                     context, instance.uuid)
2831 
2832         block_device_info = \
2833             self._get_instance_block_device_info(
2834                     context, instance, bdms=bdms)
2835 
2836         def detach_block_devices(context, bdms):
2837             for bdm in bdms:
2838                 if bdm.is_volume:
2839                     self._detach_volume(context, bdm.volume_id, instance,
2840                                         destroy_bdm=False)
2841 
2842         files = self._decode_files(injected_files)
2843 
2844         kwargs = dict(
2845             context=context,
2846             instance=instance,
2847             image_meta=image_meta,
2848             injected_files=files,
2849             admin_password=new_pass,
2850             bdms=bdms,
2851             detach_block_devices=detach_block_devices,
2852             attach_block_devices=self._prep_block_device,
2853             block_device_info=block_device_info,
2854             network_info=network_info,
2855             preserve_ephemeral=preserve_ephemeral,
2856             recreate=recreate)
2857         try:
2858             with instance.mutated_migration_context():
2859                 self.driver.rebuild(**kwargs)
2860         except NotImplementedError:
2861             # NOTE(rpodolyaka): driver doesn't provide specialized version
2862             # of rebuild, fall back to the default implementation
2863             self._rebuild_default_impl(**kwargs)
2864         self._update_instance_after_spawn(context, instance)
2865         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
2866 
2867         if orig_vm_state == vm_states.STOPPED:
2868             LOG.info(_LI("bringing vm to original state: '%s'"),
2869                         orig_vm_state, instance=instance)
2870             instance.vm_state = vm_states.ACTIVE
2871             instance.task_state = task_states.POWERING_OFF
2872             instance.progress = 0
2873             instance.save()
2874             self.stop_instance(context, instance, False)
2875         self._update_scheduler_instance_info(context, instance)
2876         self._notify_about_instance_usage(
2877                 context, instance, "rebuild.end",
2878                 network_info=network_info,
2879                 extra_usage_info=extra_usage_info)
2880 
2881     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
2882                                      block_device_info):
2883         """Handle cases where the virt-layer had to detach non-working volumes
2884         in order to complete an operation.
2885         """
2886         for bdm in block_device_info['block_device_mapping']:
2887             if bdm.get('mount_device') in bad_devices:
2888                 try:
2889                     volume_id = bdm['connection_info']['data']['volume_id']
2890                 except KeyError:
2891                     continue
2892 
2893                 # NOTE(sirp): ideally we'd just call
2894                 # `compute_api.detach_volume` here but since that hits the
2895                 # DB directly, that's off limits from within the
2896                 # compute-manager.
2897                 #
2898                 # API-detach
2899                 LOG.info(_LI("Detaching from volume api: %s"), volume_id)
2900                 volume = self.volume_api.get(context, volume_id)
2901                 self.volume_api.check_detach(context, volume)
2902                 self.volume_api.begin_detaching(context, volume_id)
2903 
2904                 # Manager-detach
2905                 self.detach_volume(context, volume_id, instance)
2906 
2907     @wrap_exception()
2908     @reverts_task_state
2909     @wrap_instance_event(prefix='compute')
2910     @wrap_instance_fault
2911     def reboot_instance(self, context, instance, block_device_info,
2912                         reboot_type):
2913         """Reboot an instance on this host."""
2914         # acknowledge the request made it to the manager
2915         if reboot_type == "SOFT":
2916             instance.task_state = task_states.REBOOT_PENDING
2917             expected_states = (task_states.REBOOTING,
2918                                task_states.REBOOT_PENDING,
2919                                task_states.REBOOT_STARTED)
2920         else:
2921             instance.task_state = task_states.REBOOT_PENDING_HARD
2922             expected_states = (task_states.REBOOTING_HARD,
2923                                task_states.REBOOT_PENDING_HARD,
2924                                task_states.REBOOT_STARTED_HARD)
2925         context = context.elevated()
2926         LOG.info(_LI("Rebooting instance"), instance=instance)
2927 
2928         block_device_info = self._get_instance_block_device_info(context,
2929                                                                  instance)
2930 
2931         network_info = self.network_api.get_instance_nw_info(context, instance)
2932 
2933         self._notify_about_instance_usage(context, instance, "reboot.start")
2934 
2935         instance.power_state = self._get_power_state(context, instance)
2936         instance.save(expected_task_state=expected_states)
2937 
2938         if instance.power_state != power_state.RUNNING:
2939             state = instance.power_state
2940             running = power_state.RUNNING
2941             LOG.warning(_LW('trying to reboot a non-running instance:'
2942                             ' (state: %(state)s expected: %(running)s)'),
2943                         {'state': state, 'running': running},
2944                         instance=instance)
2945 
2946         def bad_volumes_callback(bad_devices):
2947             self._handle_bad_volumes_detached(
2948                     context, instance, bad_devices, block_device_info)
2949 
2950         try:
2951             # Don't change it out of rescue mode
2952             if instance.vm_state == vm_states.RESCUED:
2953                 new_vm_state = vm_states.RESCUED
2954             else:
2955                 new_vm_state = vm_states.ACTIVE
2956             new_power_state = None
2957             if reboot_type == "SOFT":
2958                 instance.task_state = task_states.REBOOT_STARTED
2959                 expected_state = task_states.REBOOT_PENDING
2960             else:
2961                 instance.task_state = task_states.REBOOT_STARTED_HARD
2962                 expected_state = task_states.REBOOT_PENDING_HARD
2963             instance.save(expected_task_state=expected_state)
2964             self.driver.reboot(context, instance,
2965                                network_info,
2966                                reboot_type,
2967                                block_device_info=block_device_info,
2968                                bad_volumes_callback=bad_volumes_callback)
2969 
2970         except Exception as error:
2971             with excutils.save_and_reraise_exception() as ctxt:
2972                 exc_info = sys.exc_info()
2973                 # if the reboot failed but the VM is running don't
2974                 # put it into an error state
2975                 new_power_state = self._get_power_state(context, instance)
2976                 if new_power_state == power_state.RUNNING:
2977                     LOG.warning(_LW('Reboot failed but instance is running'),
2978                                 instance=instance)
2979                     compute_utils.add_instance_fault_from_exc(context,
2980                             instance, error, exc_info)
2981                     self._notify_about_instance_usage(context, instance,
2982                             'reboot.error', fault=error)
2983                     ctxt.reraise = False
2984                 else:
2985                     LOG.error(_LE('Cannot reboot instance: %s'), error,
2986                               instance=instance)
2987                     self._set_instance_obj_error_state(context, instance)
2988 
2989         if not new_power_state:
2990             new_power_state = self._get_power_state(context, instance)
2991         try:
2992             instance.power_state = new_power_state
2993             instance.vm_state = new_vm_state
2994             instance.task_state = None
2995             instance.save()
2996         except exception.InstanceNotFound:
2997             LOG.warning(_LW("Instance disappeared during reboot"),
2998                         instance=instance)
2999 
3000         self._notify_about_instance_usage(context, instance, "reboot.end")
3001 
3002     @delete_image_on_error
3003     def _do_snapshot_instance(self, context, image_id, instance):
3004         self._snapshot_instance(context, image_id, instance,
3005                                 task_states.IMAGE_BACKUP)
3006 
3007     @wrap_exception()
3008     @reverts_task_state
3009     @wrap_instance_fault
3010     def backup_instance(self, context, image_id, instance, backup_type,
3011                         rotation):
3012         """Backup an instance on this host.
3013 
3014         :param backup_type: daily | weekly
3015         :param rotation: int representing how many backups to keep around
3016         """
3017         self._do_snapshot_instance(context, image_id, instance)
3018         self._rotate_backups(context, instance, backup_type, rotation)
3019 
3020     @wrap_exception()
3021     @reverts_task_state
3022     @wrap_instance_fault
3023     @delete_image_on_error
3024     def snapshot_instance(self, context, image_id, instance):
3025         """Snapshot an instance on this host.
3026 
3027         :param context: security context
3028         :param image_id: glance.db.sqlalchemy.models.Image.Id
3029         :param instance: a nova.objects.instance.Instance object
3030         """
3031         # NOTE(dave-mcnally) the task state will already be set by the api
3032         # but if the compute manager has crashed/been restarted prior to the
3033         # request getting here the task state may have been cleared so we set
3034         # it again and things continue normally
3035         try:
3036             instance.task_state = task_states.IMAGE_SNAPSHOT
3037             instance.save(
3038                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3039         except exception.InstanceNotFound:
3040             # possibility instance no longer exists, no point in continuing
3041             LOG.debug("Instance not found, could not set state %s "
3042                       "for instance.",
3043                       task_states.IMAGE_SNAPSHOT, instance=instance)
3044             return
3045 
3046         except exception.UnexpectedDeletingTaskStateError:
3047             LOG.debug("Instance being deleted, snapshot cannot continue",
3048                       instance=instance)
3049             return
3050 
3051         self._snapshot_instance(context, image_id, instance,
3052                                 task_states.IMAGE_SNAPSHOT)
3053 
3054     def _snapshot_instance(self, context, image_id, instance,
3055                            expected_task_state):
3056         context = context.elevated()
3057 
3058         instance.power_state = self._get_power_state(context, instance)
3059         try:
3060             instance.save()
3061 
3062             LOG.info(_LI('instance snapshotting'), instance=instance)
3063 
3064             if instance.power_state != power_state.RUNNING:
3065                 state = instance.power_state
3066                 running = power_state.RUNNING
3067                 LOG.warning(_LW('trying to snapshot a non-running instance: '
3068                                 '(state: %(state)s expected: %(running)s)'),
3069                             {'state': state, 'running': running},
3070                             instance=instance)
3071 
3072             self._notify_about_instance_usage(
3073                 context, instance, "snapshot.start")
3074 
3075             def update_task_state(task_state,
3076                                   expected_state=expected_task_state):
3077                 instance.task_state = task_state
3078                 instance.save(expected_task_state=expected_state)
3079 
3080             self.driver.snapshot(context, instance, image_id,
3081                                  update_task_state)
3082 
3083             instance.task_state = None
3084             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3085 
3086             self._notify_about_instance_usage(context, instance,
3087                                               "snapshot.end")
3088         except (exception.InstanceNotFound,
3089                 exception.UnexpectedDeletingTaskStateError):
3090             # the instance got deleted during the snapshot
3091             # Quickly bail out of here
3092             msg = 'Instance disappeared during snapshot'
3093             LOG.debug(msg, instance=instance)
3094             try:
3095                 image_service = glance.get_default_image_service()
3096                 image = image_service.show(context, image_id)
3097                 if image['status'] != 'active':
3098                     image_service.delete(context, image_id)
3099             except Exception:
3100                 LOG.warning(_LW("Error while trying to clean up image %s"),
3101                             image_id, instance=instance)
3102         except exception.ImageNotFound:
3103             instance.task_state = None
3104             instance.save()
3105             msg = _LW("Image not found during snapshot")
3106             LOG.warning(msg, instance=instance)
3107 
3108     def _post_interrupted_snapshot_cleanup(self, context, instance):
3109         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3110 
3111     @messaging.expected_exceptions(NotImplementedError)
3112     @wrap_exception()
3113     def volume_snapshot_create(self, context, instance, volume_id,
3114                                create_info):
3115         self.driver.volume_snapshot_create(context, instance, volume_id,
3116                                            create_info)
3117 
3118     @messaging.expected_exceptions(NotImplementedError)
3119     @wrap_exception()
3120     def volume_snapshot_delete(self, context, instance, volume_id,
3121                                snapshot_id, delete_info):
3122         self.driver.volume_snapshot_delete(context, instance, volume_id,
3123                                            snapshot_id, delete_info)
3124 
3125     @wrap_instance_fault
3126     def _rotate_backups(self, context, instance, backup_type, rotation):
3127         """Delete excess backups associated to an instance.
3128 
3129         Instances are allowed a fixed number of backups (the rotation number);
3130         this method deletes the oldest backups that exceed the rotation
3131         threshold.
3132 
3133         :param context: security context
3134         :param instance: Instance dict
3135         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3136         :param rotation: int representing how many backups to keep around;
3137             None if rotation shouldn't be used (as in the case of snapshots)
3138         """
3139         filters = {'property-image_type': 'backup',
3140                    'property-backup_type': backup_type,
3141                    'property-instance_uuid': instance.uuid}
3142 
3143         images = self.image_api.get_all(context, filters=filters,
3144                                         sort_key='created_at', sort_dir='desc')
3145         num_images = len(images)
3146         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3147                   {'num_images': num_images, 'rotation': rotation},
3148                   instance=instance)
3149 
3150         if num_images > rotation:
3151             # NOTE(sirp): this deletes all backups that exceed the rotation
3152             # limit
3153             excess = len(images) - rotation
3154             LOG.debug("Rotating out %d backups", excess,
3155                       instance=instance)
3156             for i in range(excess):
3157                 image = images.pop()
3158                 image_id = image['id']
3159                 LOG.debug("Deleting image %s", image_id,
3160                           instance=instance)
3161                 self.image_api.delete(context, image_id)
3162 
3163     @wrap_exception()
3164     @reverts_task_state
3165     @wrap_instance_event(prefix='compute')
3166     @wrap_instance_fault
3167     def set_admin_password(self, context, instance, new_pass):
3168         """Set the root/admin password for an instance on this host.
3169 
3170         This is generally only called by API password resets after an
3171         image has been built.
3172 
3173         @param context: Nova auth context.
3174         @param instance: Nova instance object.
3175         @param new_pass: The admin password for the instance.
3176         """
3177 
3178         context = context.elevated()
3179         if new_pass is None:
3180             # Generate a random password
3181             new_pass = utils.generate_password()
3182 
3183         current_power_state = self._get_power_state(context, instance)
3184         expected_state = power_state.RUNNING
3185 
3186         if current_power_state != expected_state:
3187             instance.task_state = None
3188             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3189             _msg = _('instance %s is not running') % instance.uuid
3190             raise exception.InstancePasswordSetFailed(
3191                 instance=instance.uuid, reason=_msg)
3192 
3193         try:
3194             self.driver.set_admin_password(instance, new_pass)
3195             LOG.info(_LI("Root password set"), instance=instance)
3196             instance.task_state = None
3197             instance.save(
3198                 expected_task_state=task_states.UPDATING_PASSWORD)
3199         except exception.InstanceAgentNotEnabled:
3200             with excutils.save_and_reraise_exception():
3201                 LOG.debug('Guest agent is not enabled for the instance.',
3202                           instance=instance)
3203                 instance.task_state = None
3204                 instance.save(
3205                     expected_task_state=task_states.UPDATING_PASSWORD)
3206         except exception.SetAdminPasswdNotSupported:
3207             with excutils.save_and_reraise_exception():
3208                 LOG.info(_LI('set_admin_password is not supported '
3209                                 'by this driver or guest instance.'),
3210                             instance=instance)
3211                 instance.task_state = None
3212                 instance.save(
3213                     expected_task_state=task_states.UPDATING_PASSWORD)
3214         except NotImplementedError:
3215             LOG.warning(_LW('set_admin_password is not implemented '
3216                             'by this driver or guest instance.'),
3217                         instance=instance)
3218             instance.task_state = None
3219             instance.save(
3220                 expected_task_state=task_states.UPDATING_PASSWORD)
3221             raise NotImplementedError(_('set_admin_password is not '
3222                                         'implemented by this driver or guest '
3223                                         'instance.'))
3224         except exception.UnexpectedTaskStateError:
3225             # interrupted by another (most likely delete) task
3226             # do not retry
3227             raise
3228         except Exception:
3229             # Catch all here because this could be anything.
3230             LOG.exception(_LE('set_admin_password failed'),
3231                           instance=instance)
3232             self._set_instance_obj_error_state(context, instance)
3233             # We create a new exception here so that we won't
3234             # potentially reveal password information to the
3235             # API caller.  The real exception is logged above
3236             _msg = _('error setting admin password')
3237             raise exception.InstancePasswordSetFailed(
3238                 instance=instance.uuid, reason=_msg)
3239 
3240     @wrap_exception()
3241     @reverts_task_state
3242     @wrap_instance_fault
3243     def inject_file(self, context, path, file_contents, instance):
3244         """Write a file to the specified path in an instance on this host."""
3245         # NOTE(russellb) Remove this method, as well as the underlying virt
3246         # driver methods, when the compute rpc interface is bumped to 4.x
3247         # as it is no longer used.
3248         context = context.elevated()
3249         current_power_state = self._get_power_state(context, instance)
3250         expected_state = power_state.RUNNING
3251         if current_power_state != expected_state:
3252             LOG.warning(_LW('trying to inject a file into a non-running '
3253                             '(state: %(current_state)s expected: '
3254                             '%(expected_state)s)'),
3255                         {'current_state': current_power_state,
3256                          'expected_state': expected_state},
3257                         instance=instance)
3258         LOG.info(_LI('injecting file to %s'), path,
3259                     instance=instance)
3260         self.driver.inject_file(instance, path, file_contents)
3261 
3262     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3263         """Determine what image should be used to boot the rescue VM."""
3264         # 1. If rescue_image_ref is passed in, use that for rescue.
3265         # 2. Else, use the base image associated with instance's current image.
3266         #       The idea here is to provide the customer with a rescue
3267         #       environment which they are familiar with.
3268         #       So, if they built their instance off of a Debian image,
3269         #       their rescue VM will also be Debian.
3270         # 3. As a last resort, use instance's current image.
3271         if not rescue_image_ref:
3272             system_meta = utils.instance_sys_meta(instance)
3273             rescue_image_ref = system_meta.get('image_base_image_ref')
3274 
3275         if not rescue_image_ref:
3276             LOG.warning(_LW('Unable to find a different image to use for '
3277                             'rescue VM, using instance\'s current image'),
3278                         instance=instance)
3279             rescue_image_ref = instance.image_ref
3280 
3281         return objects.ImageMeta.from_image_ref(
3282             context, self.image_api, rescue_image_ref)
3283 
3284     @wrap_exception()
3285     @reverts_task_state
3286     @wrap_instance_event(prefix='compute')
3287     @wrap_instance_fault
3288     def rescue_instance(self, context, instance, rescue_password,
3289                         rescue_image_ref, clean_shutdown):
3290         context = context.elevated()
3291         LOG.info(_LI('Rescuing'), instance=instance)
3292 
3293         admin_password = (rescue_password if rescue_password else
3294                       utils.generate_password())
3295 
3296         network_info = self.network_api.get_instance_nw_info(context, instance)
3297 
3298         rescue_image_meta = self._get_rescue_image(context, instance,
3299                                                    rescue_image_ref)
3300 
3301         extra_usage_info = {'rescue_image_name':
3302                             self._get_image_name(rescue_image_meta)}
3303         self._notify_about_instance_usage(context, instance,
3304                 "rescue.start", extra_usage_info=extra_usage_info,
3305                 network_info=network_info)
3306 
3307         try:
3308             self._power_off_instance(context, instance, clean_shutdown)
3309 
3310             self.driver.rescue(context, instance,
3311                                network_info,
3312                                rescue_image_meta, admin_password)
3313         except Exception as e:
3314             LOG.exception(_LE("Error trying to Rescue Instance"),
3315                           instance=instance)
3316             self._set_instance_obj_error_state(context, instance)
3317             raise exception.InstanceNotRescuable(
3318                 instance_id=instance.uuid,
3319                 reason=_("Driver Error: %s") % e)
3320 
3321         compute_utils.notify_usage_exists(self.notifier, context, instance,
3322                                           current_period=True)
3323 
3324         instance.vm_state = vm_states.RESCUED
3325         instance.task_state = None
3326         instance.power_state = self._get_power_state(context, instance)
3327         instance.launched_at = timeutils.utcnow()
3328         instance.save(expected_task_state=task_states.RESCUING)
3329 
3330         self._notify_about_instance_usage(context, instance,
3331                 "rescue.end", extra_usage_info=extra_usage_info,
3332                 network_info=network_info)
3333 
3334     @wrap_exception()
3335     @reverts_task_state
3336     @wrap_instance_event(prefix='compute')
3337     @wrap_instance_fault
3338     def unrescue_instance(self, context, instance):
3339         context = context.elevated()
3340         LOG.info(_LI('Unrescuing'), instance=instance)
3341 
3342         network_info = self.network_api.get_instance_nw_info(context, instance)
3343         self._notify_about_instance_usage(context, instance,
3344                 "unrescue.start", network_info=network_info)
3345         with self._error_out_instance_on_exception(context, instance):
3346             self.driver.unrescue(instance,
3347                                  network_info)
3348 
3349         instance.vm_state = vm_states.ACTIVE
3350         instance.task_state = None
3351         instance.power_state = self._get_power_state(context, instance)
3352         instance.save(expected_task_state=task_states.UNRESCUING)
3353 
3354         self._notify_about_instance_usage(context,
3355                                           instance,
3356                                           "unrescue.end",
3357                                           network_info=network_info)
3358 
3359     @wrap_exception()
3360     @wrap_instance_fault
3361     def change_instance_metadata(self, context, diff, instance):
3362         """Update the metadata published to the instance."""
3363         LOG.debug("Changing instance metadata according to %r",
3364                   diff, instance=instance)
3365         self.driver.change_instance_metadata(context, instance, diff)
3366 
3367     @wrap_exception()
3368     @wrap_instance_event(prefix='compute')
3369     @wrap_instance_fault
3370     def confirm_resize(self, context, instance, reservations, migration):
3371 
3372         quotas = objects.Quotas.from_reservations(context,
3373                                                   reservations,
3374                                                   instance=instance)
3375 
3376         @utils.synchronized(instance.uuid)
3377         def do_confirm_resize(context, instance, migration_id):
3378             # NOTE(wangpan): Get the migration status from db, if it has been
3379             #                confirmed, we do nothing and return here
3380             LOG.debug("Going to confirm migration %s", migration_id,
3381                       instance=instance)
3382             try:
3383                 # TODO(russellb) Why are we sending the migration object just
3384                 # to turn around and look it up from the db again?
3385                 migration = objects.Migration.get_by_id(
3386                                     context.elevated(), migration_id)
3387             except exception.MigrationNotFound:
3388                 LOG.error(_LE("Migration %s is not found during confirmation"),
3389                           migration_id, instance=instance)
3390                 quotas.rollback()
3391                 return
3392 
3393             if migration.status == 'confirmed':
3394                 LOG.info(_LI("Migration %s is already confirmed"),
3395                          migration_id, instance=instance)
3396                 quotas.rollback()
3397                 return
3398             elif migration.status not in ('finished', 'confirming'):
3399                 LOG.warning(_LW("Unexpected confirmation status '%(status)s' "
3400                                 "of migration %(id)s, exit confirmation "
3401                                 "process"),
3402                             {"status": migration.status, "id": migration_id},
3403                             instance=instance)
3404                 quotas.rollback()
3405                 return
3406 
3407             # NOTE(wangpan): Get the instance from db, if it has been
3408             #                deleted, we do nothing and return here
3409             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3410             try:
3411                 instance = objects.Instance.get_by_uuid(
3412                         context, instance.uuid,
3413                         expected_attrs=expected_attrs)
3414             except exception.InstanceNotFound:
3415                 LOG.info(_LI("Instance is not found during confirmation"),
3416                          instance=instance)
3417                 quotas.rollback()
3418                 return
3419 
3420             self._confirm_resize(context, instance, quotas,
3421                                  migration=migration)
3422 
3423         do_confirm_resize(context, instance, migration.id)
3424 
3425     def _confirm_resize(self, context, instance, quotas,
3426                         migration=None):
3427         """Destroys the source instance."""
3428         self._notify_about_instance_usage(context, instance,
3429                                           "resize.confirm.start")
3430 
3431         with self._error_out_instance_on_exception(context, instance,
3432                                                    quotas=quotas):
3433             # NOTE(danms): delete stashed migration information
3434             old_instance_type = instance.old_flavor
3435             instance.old_flavor = None
3436             instance.new_flavor = None
3437             instance.system_metadata.pop('old_vm_state', None)
3438             instance.save()
3439 
3440             # NOTE(tr3buchet): tear down networks on source host
3441             self.network_api.setup_networks_on_host(context, instance,
3442                                migration.source_compute, teardown=True)
3443 
3444             network_info = self.network_api.get_instance_nw_info(context,
3445                                                                  instance)
3446             self.driver.confirm_migration(migration, instance,
3447                                           network_info)
3448 
3449             migration.status = 'confirmed'
3450             with migration.obj_as_admin():
3451                 migration.save()
3452 
3453             rt = self._get_resource_tracker(migration.source_node)
3454             rt.drop_move_claim(context, instance, old_instance_type,
3455                                prefix='old_')
3456             instance.drop_migration_context()
3457 
3458             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3459             # might have manually powered up the instance to confirm the
3460             # resize/migrate, so we need to check the current power state
3461             # on the instance and set the vm_state appropriately. We default
3462             # to ACTIVE because if the power state is not SHUTDOWN, we
3463             # assume _sync_instance_power_state will clean it up.
3464             p_state = instance.power_state
3465             vm_state = None
3466             if p_state == power_state.SHUTDOWN:
3467                 vm_state = vm_states.STOPPED
3468                 LOG.debug("Resized/migrated instance is powered off. "
3469                           "Setting vm_state to '%s'.", vm_state,
3470                           instance=instance)
3471             else:
3472                 vm_state = vm_states.ACTIVE
3473 
3474             instance.vm_state = vm_state
3475             instance.task_state = None
3476             instance.save(expected_task_state=[None, task_states.DELETING])
3477 
3478             self._notify_about_instance_usage(
3479                 context, instance, "resize.confirm.end",
3480                 network_info=network_info)
3481 
3482             quotas.commit()
3483 
3484     @wrap_exception()
3485     @reverts_task_state
3486     @wrap_instance_event(prefix='compute')
3487     @errors_out_migration
3488     @wrap_instance_fault
3489     def revert_resize(self, context, instance, migration, reservations):
3490         """Destroys the new instance on the destination machine.
3491 
3492         Reverts the model changes, and powers on the old instance on the
3493         source machine.
3494 
3495         """
3496 
3497         quotas = objects.Quotas.from_reservations(context,
3498                                                   reservations,
3499                                                   instance=instance)
3500 
3501         # NOTE(comstud): A revert_resize is essentially a resize back to
3502         # the old size, so we need to send a usage event here.
3503         compute_utils.notify_usage_exists(self.notifier, context, instance,
3504                                           current_period=True)
3505 
3506         with self._error_out_instance_on_exception(context, instance,
3507                                                    quotas=quotas):
3508             # NOTE(tr3buchet): tear down networks on destination host
3509             self.network_api.setup_networks_on_host(context, instance,
3510                                                     teardown=True)
3511 
3512             migration_p = obj_base.obj_to_primitive(migration)
3513             self.network_api.migrate_instance_start(context,
3514                                                     instance,
3515                                                     migration_p)
3516 
3517             network_info = self.network_api.get_instance_nw_info(context,
3518                                                                  instance)
3519             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3520                     context, instance.uuid)
3521             block_device_info = self._get_instance_block_device_info(
3522                                 context, instance, bdms=bdms)
3523 
3524             destroy_disks = not self._is_instance_storage_shared(
3525                 context, instance, host=migration.source_compute)
3526             self.driver.destroy(context, instance, network_info,
3527                                 block_device_info, destroy_disks)
3528 
3529             self._terminate_volume_connections(context, instance, bdms)
3530 
3531             migration.status = 'reverted'
3532             with migration.obj_as_admin():
3533                 migration.save()
3534 
3535             # NOTE(ndipanov): We need to do this here because dropping the
3536             # claim means we lose the migration_context data. We really should
3537             # fix this by moving the drop_move_claim call to the
3538             # finish_revert_resize method as this is racy (revert is dropped,
3539             # but instance resources will be tracked with the new flavor until
3540             # it gets rolled back in finish_revert_resize, which is
3541             # potentially wrong for a period of time).
3542             instance.revert_migration_context()
3543             instance.save()
3544 
3545             rt = self._get_resource_tracker(instance.node)
3546             rt.drop_move_claim(context, instance)
3547 
3548             self.compute_rpcapi.finish_revert_resize(context, instance,
3549                     migration, migration.source_compute,
3550                     quotas.reservations)
3551 
3552     @wrap_exception()
3553     @reverts_task_state
3554     @wrap_instance_event(prefix='compute')
3555     @errors_out_migration
3556     @wrap_instance_fault
3557     def finish_revert_resize(self, context, instance, reservations, migration):
3558         """Finishes the second half of reverting a resize.
3559 
3560         Bring the original source instance state back (active/shutoff) and
3561         revert the resized attributes in the database.
3562 
3563         """
3564 
3565         quotas = objects.Quotas.from_reservations(context,
3566                                                   reservations,
3567                                                   instance=instance)
3568 
3569         with self._error_out_instance_on_exception(context, instance,
3570                                                    quotas=quotas):
3571             self._notify_about_instance_usage(
3572                     context, instance, "resize.revert.start")
3573 
3574             # NOTE(mriedem): delete stashed old_vm_state information; we
3575             # default to ACTIVE for backwards compatibility if old_vm_state
3576             # is not set
3577             old_vm_state = instance.system_metadata.pop('old_vm_state',
3578                                                         vm_states.ACTIVE)
3579 
3580             self._set_instance_info(instance, instance.old_flavor)
3581             instance.old_flavor = None
3582             instance.new_flavor = None
3583             instance.host = migration.source_compute
3584             instance.node = migration.source_node
3585             instance.save()
3586 
3587             migration.dest_compute = migration.source_compute
3588             with migration.obj_as_admin():
3589                 migration.save()
3590 
3591             self.network_api.setup_networks_on_host(context, instance,
3592                                                     migration.source_compute)
3593             migration_p = obj_base.obj_to_primitive(migration)
3594             self.network_api.migrate_instance_finish(context,
3595                                                      instance,
3596                                                      migration_p)
3597             network_info = self.network_api.get_instance_nw_info(context,
3598                                                                  instance)
3599 
3600             block_device_info = self._get_instance_block_device_info(
3601                     context, instance, refresh_conn_info=True)
3602 
3603             power_on = old_vm_state != vm_states.STOPPED
3604             self.driver.finish_revert_migration(context, instance,
3605                                        network_info,
3606                                        block_device_info, power_on)
3607 
3608             instance.drop_migration_context()
3609             instance.launched_at = timeutils.utcnow()
3610             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
3611 
3612             # if the original vm state was STOPPED, set it back to STOPPED
3613             LOG.info(_LI("Updating instance to original state: '%s'"),
3614                      old_vm_state, instance=instance)
3615             if power_on:
3616                 instance.vm_state = vm_states.ACTIVE
3617                 instance.task_state = None
3618                 instance.save()
3619             else:
3620                 instance.task_state = task_states.POWERING_OFF
3621                 instance.save()
3622                 self.stop_instance(context, instance=instance,
3623                                    clean_shutdown=True)
3624 
3625             self._notify_about_instance_usage(
3626                     context, instance, "resize.revert.end")
3627             quotas.commit()
3628 
3629     def _prep_resize(self, context, image, instance, instance_type,
3630             quotas, request_spec, filter_properties, node,
3631             clean_shutdown=True):
3632 
3633         if not filter_properties:
3634             filter_properties = {}
3635 
3636         if not instance.host:
3637             self._set_instance_obj_error_state(context, instance)
3638             msg = _('Instance has no source host')
3639             raise exception.MigrationError(reason=msg)
3640 
3641         same_host = instance.host == self.host
3642         # if the flavor IDs match, it's migrate; otherwise resize
3643         if same_host and instance_type.id == instance['instance_type_id']:
3644             # check driver whether support migrate to same host
3645             if not self.driver.capabilities['supports_migrate_to_same_host']:
3646                 raise exception.UnableToMigrateToSelf(
3647                     instance_id=instance.uuid, host=self.host)
3648 
3649         # NOTE(danms): Stash the new instance_type to avoid having to
3650         # look it up in the database later
3651         instance.new_flavor = instance_type
3652         # NOTE(mriedem): Stash the old vm_state so we can set the
3653         # resized/reverted instance back to the same state later.
3654         vm_state = instance.vm_state
3655         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
3656         instance.system_metadata['old_vm_state'] = vm_state
3657         instance.save()
3658 
3659         limits = filter_properties.get('limits', {})
3660         rt = self._get_resource_tracker(node)
3661         with rt.resize_claim(context, instance, instance_type,
3662                              image_meta=image, limits=limits) as claim:
3663             LOG.info(_LI('Migrating'), instance=instance)
3664             self.compute_rpcapi.resize_instance(
3665                     context, instance, claim.migration, image,
3666                     instance_type, quotas.reservations,
3667                     clean_shutdown)
3668 
3669     @wrap_exception()
3670     @reverts_task_state
3671     @wrap_instance_event(prefix='compute')
3672     @wrap_instance_fault
3673     def prep_resize(self, context, image, instance, instance_type,
3674                     reservations, request_spec, filter_properties, node,
3675                     clean_shutdown):
3676         """Initiates the process of moving a running instance to another host.
3677 
3678         Possibly changes the RAM and disk size in the process.
3679 
3680         """
3681         if node is None:
3682             node = self.driver.get_available_nodes(refresh=True)[0]
3683             LOG.debug("No node specified, defaulting to %s", node,
3684                       instance=instance)
3685 
3686         # NOTE(melwitt): Remove this in version 5.0 of the RPC API
3687         # Code downstream may expect extra_specs to be populated since it
3688         # is receiving an object, so lookup the flavor to ensure this.
3689         if not isinstance(instance_type, objects.Flavor):
3690             instance_type = objects.Flavor.get_by_id(context,
3691                                                      instance_type['id'])
3692 
3693         quotas = objects.Quotas.from_reservations(context,
3694                                                   reservations,
3695                                                   instance=instance)
3696         with self._error_out_instance_on_exception(context, instance,
3697                                                    quotas=quotas):
3698             compute_utils.notify_usage_exists(self.notifier, context, instance,
3699                                               current_period=True)
3700             self._notify_about_instance_usage(
3701                     context, instance, "resize.prep.start")
3702             try:
3703                 self._prep_resize(context, image, instance,
3704                                   instance_type, quotas,
3705                                   request_spec, filter_properties,
3706                                   node, clean_shutdown)
3707             # NOTE(dgenin): This is thrown in LibvirtDriver when the
3708             #               instance to be migrated is backed by LVM.
3709             #               Remove when LVM migration is implemented.
3710             except exception.MigrationPreCheckError:
3711                 raise
3712             except Exception:
3713                 # try to re-schedule the resize elsewhere:
3714                 exc_info = sys.exc_info()
3715                 self._reschedule_resize_or_reraise(context, image, instance,
3716                         exc_info, instance_type, quotas, request_spec,
3717                         filter_properties)
3718             finally:
3719                 extra_usage_info = dict(
3720                         new_instance_type=instance_type.name,
3721                         new_instance_type_id=instance_type.id)
3722 
3723                 self._notify_about_instance_usage(
3724                     context, instance, "resize.prep.end",
3725                     extra_usage_info=extra_usage_info)
3726 
3727     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
3728             instance_type, quotas, request_spec, filter_properties):
3729         """Try to re-schedule the resize or re-raise the original error to
3730         error out the instance.
3731         """
3732         if not request_spec:
3733             request_spec = {}
3734         if not filter_properties:
3735             filter_properties = {}
3736 
3737         rescheduled = False
3738         instance_uuid = instance.uuid
3739 
3740         try:
3741             reschedule_method = self.compute_task_api.resize_instance
3742             scheduler_hint = dict(filter_properties=filter_properties)
3743             method_args = (instance, None, scheduler_hint, instance_type,
3744                            quotas.reservations)
3745             task_state = task_states.RESIZE_PREP
3746 
3747             rescheduled = self._reschedule(context, request_spec,
3748                     filter_properties, instance, reschedule_method,
3749                     method_args, task_state, exc_info)
3750         except Exception as error:
3751             rescheduled = False
3752             LOG.exception(_LE("Error trying to reschedule"),
3753                           instance_uuid=instance_uuid)
3754             compute_utils.add_instance_fault_from_exc(context,
3755                     instance, error,
3756                     exc_info=sys.exc_info())
3757             self._notify_about_instance_usage(context, instance,
3758                     'resize.error', fault=error)
3759 
3760         if rescheduled:
3761             self._log_original_error(exc_info, instance_uuid)
3762             compute_utils.add_instance_fault_from_exc(context,
3763                     instance, exc_info[1], exc_info=exc_info)
3764             self._notify_about_instance_usage(context, instance,
3765                     'resize.error', fault=exc_info[1])
3766         else:
3767             # not re-scheduling
3768             six.reraise(*exc_info)
3769 
3770     @wrap_exception()
3771     @reverts_task_state
3772     @wrap_instance_event(prefix='compute')
3773     @errors_out_migration
3774     @wrap_instance_fault
3775     def resize_instance(self, context, instance, image,
3776                         reservations, migration, instance_type,
3777                         clean_shutdown):
3778         """Starts the migration of a running instance to another host."""
3779 
3780         quotas = objects.Quotas.from_reservations(context,
3781                                                   reservations,
3782                                                   instance=instance)
3783         with self._error_out_instance_on_exception(context, instance,
3784                                                    quotas=quotas):
3785             # TODO(chaochin) Remove this until v5 RPC API
3786             # Code downstream may expect extra_specs to be populated since it
3787             # is receiving an object, so lookup the flavor to ensure this.
3788             if (not instance_type or
3789                 not isinstance(instance_type, objects.Flavor)):
3790                 instance_type = objects.Flavor.get_by_id(
3791                     context, migration['new_instance_type_id'])
3792 
3793             network_info = self.network_api.get_instance_nw_info(context,
3794                                                                  instance)
3795 
3796             migration.status = 'migrating'
3797             with migration.obj_as_admin():
3798                 migration.save()
3799 
3800             instance.task_state = task_states.RESIZE_MIGRATING
3801             instance.save(expected_task_state=task_states.RESIZE_PREP)
3802 
3803             self._notify_about_instance_usage(
3804                 context, instance, "resize.start", network_info=network_info)
3805 
3806             compute_utils.notify_about_instance_action(context, instance,
3807                    self.host, action=fields.NotificationAction.RESIZE,
3808                    phase=fields.NotificationPhase.START)
3809 
3810             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3811                     context, instance.uuid)
3812             block_device_info = self._get_instance_block_device_info(
3813                                 context, instance, bdms=bdms)
3814 
3815             timeout, retry_interval = self._get_power_off_values(context,
3816                                             instance, clean_shutdown)
3817             disk_info = self.driver.migrate_disk_and_power_off(
3818                     context, instance, migration.dest_host,
3819                     instance_type, network_info,
3820                     block_device_info,
3821                     timeout, retry_interval)
3822 
3823             self._terminate_volume_connections(context, instance, bdms)
3824 
3825             migration_p = obj_base.obj_to_primitive(migration)
3826             self.network_api.migrate_instance_start(context,
3827                                                     instance,
3828                                                     migration_p)
3829 
3830             migration.status = 'post-migrating'
3831             with migration.obj_as_admin():
3832                 migration.save()
3833 
3834             instance.host = migration.dest_compute
3835             instance.node = migration.dest_node
3836             instance.task_state = task_states.RESIZE_MIGRATED
3837             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
3838 
3839             self.compute_rpcapi.finish_resize(context, instance,
3840                     migration, image, disk_info,
3841                     migration.dest_compute, reservations=quotas.reservations)
3842 
3843             self._notify_about_instance_usage(context, instance, "resize.end",
3844                                               network_info=network_info)
3845 
3846             compute_utils.notify_about_instance_action(context, instance,
3847                    self.host, action=fields.NotificationAction.RESIZE,
3848                    phase=fields.NotificationPhase.END)
3849             self.instance_events.clear_events_for_instance(instance)
3850 
3851     def _terminate_volume_connections(self, context, instance, bdms):
3852         connector = self.driver.get_volume_connector(instance)
3853         for bdm in bdms:
3854             if bdm.is_volume:
3855                 self.volume_api.terminate_connection(context, bdm.volume_id,
3856                                                      connector)
3857 
3858     @staticmethod
3859     def _set_instance_info(instance, instance_type):
3860         instance.instance_type_id = instance_type.id
3861         # NOTE(danms): These are purely for any legacy code that still
3862         # looks at them.
3863         instance.memory_mb = instance_type.memory_mb
3864         instance.vcpus = instance_type.vcpus
3865         instance.root_gb = instance_type.root_gb
3866         instance.ephemeral_gb = instance_type.ephemeral_gb
3867         instance.flavor = instance_type
3868 
3869     def _finish_resize(self, context, instance, migration, disk_info,
3870                        image_meta):
3871         resize_instance = False
3872         old_instance_type_id = migration['old_instance_type_id']
3873         new_instance_type_id = migration['new_instance_type_id']
3874         old_instance_type = instance.get_flavor()
3875         # NOTE(mriedem): Get the old_vm_state so we know if we should
3876         # power on the instance. If old_vm_state is not set we need to default
3877         # to ACTIVE for backwards compatibility
3878         old_vm_state = instance.system_metadata.get('old_vm_state',
3879                                                     vm_states.ACTIVE)
3880         instance.old_flavor = old_instance_type
3881 
3882         if old_instance_type_id != new_instance_type_id:
3883             instance_type = instance.get_flavor('new')
3884             self._set_instance_info(instance, instance_type)
3885             for key in ('root_gb', 'swap', 'ephemeral_gb'):
3886                 if old_instance_type[key] != instance_type[key]:
3887                     resize_instance = True
3888                     break
3889         instance.apply_migration_context()
3890 
3891         # NOTE(tr3buchet): setup networks on destination host
3892         self.network_api.setup_networks_on_host(context, instance,
3893                                                 migration['dest_compute'])
3894 
3895         migration_p = obj_base.obj_to_primitive(migration)
3896         self.network_api.migrate_instance_finish(context,
3897                                                  instance,
3898                                                  migration_p)
3899 
3900         network_info = self.network_api.get_instance_nw_info(context, instance)
3901 
3902         instance.task_state = task_states.RESIZE_FINISH
3903         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
3904 
3905         self._notify_about_instance_usage(
3906             context, instance, "finish_resize.start",
3907             network_info=network_info)
3908 
3909         block_device_info = self._get_instance_block_device_info(
3910                             context, instance, refresh_conn_info=True)
3911 
3912         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
3913         # automatically power on the instance after it's migrated
3914         power_on = old_vm_state != vm_states.STOPPED
3915 
3916         try:
3917             self.driver.finish_migration(context, migration, instance,
3918                                          disk_info,
3919                                          network_info,
3920                                          image_meta, resize_instance,
3921                                          block_device_info, power_on)
3922         except Exception:
3923             with excutils.save_and_reraise_exception():
3924                 if old_instance_type_id != new_instance_type_id:
3925                     self._set_instance_info(instance,
3926                                             old_instance_type)
3927 
3928         migration.status = 'finished'
3929         with migration.obj_as_admin():
3930             migration.save()
3931 
3932         instance.vm_state = vm_states.RESIZED
3933         instance.task_state = None
3934         instance.launched_at = timeutils.utcnow()
3935         instance.save(expected_task_state=task_states.RESIZE_FINISH)
3936 
3937         self._update_scheduler_instance_info(context, instance)
3938         self._notify_about_instance_usage(
3939             context, instance, "finish_resize.end",
3940             network_info=network_info)
3941 
3942     @wrap_exception()
3943     @reverts_task_state
3944     @wrap_instance_event(prefix='compute')
3945     @errors_out_migration
3946     @wrap_instance_fault
3947     def finish_resize(self, context, disk_info, image, instance,
3948                       reservations, migration):
3949         """Completes the migration process.
3950 
3951         Sets up the newly transferred disk and turns on the instance at its
3952         new host machine.
3953 
3954         """
3955         quotas = objects.Quotas.from_reservations(context,
3956                                                   reservations,
3957                                                   instance=instance)
3958         try:
3959             image_meta = objects.ImageMeta.from_dict(image)
3960             self._finish_resize(context, instance, migration,
3961                                 disk_info, image_meta)
3962             quotas.commit()
3963         except Exception:
3964             LOG.exception(_LE('Setting instance vm_state to ERROR'),
3965                           instance=instance)
3966             with excutils.save_and_reraise_exception():
3967                 try:
3968                     quotas.rollback()
3969                 except Exception:
3970                     LOG.exception(_LE("Failed to rollback quota for failed "
3971                                       "finish_resize"),
3972                                   instance=instance)
3973                 self._set_instance_obj_error_state(context, instance)
3974 
3975     @wrap_exception()
3976     @wrap_instance_fault
3977     def add_fixed_ip_to_instance(self, context, network_id, instance):
3978         """Calls network_api to add new fixed_ip to instance
3979         then injects the new network info and resets instance networking.
3980 
3981         """
3982         self._notify_about_instance_usage(
3983                 context, instance, "create_ip.start")
3984 
3985         network_info = self.network_api.add_fixed_ip_to_instance(context,
3986                                                                  instance,
3987                                                                  network_id)
3988         self._inject_network_info(context, instance, network_info)
3989         self.reset_network(context, instance)
3990 
3991         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
3992         instance.updated_at = timeutils.utcnow()
3993         instance.save()
3994 
3995         self._notify_about_instance_usage(
3996             context, instance, "create_ip.end", network_info=network_info)
3997 
3998     @wrap_exception()
3999     @wrap_instance_fault
4000     def remove_fixed_ip_from_instance(self, context, address, instance):
4001         """Calls network_api to remove existing fixed_ip from instance
4002         by injecting the altered network info and resetting
4003         instance networking.
4004         """
4005         self._notify_about_instance_usage(
4006                 context, instance, "delete_ip.start")
4007 
4008         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4009                                                                       instance,
4010                                                                       address)
4011         self._inject_network_info(context, instance, network_info)
4012         self.reset_network(context, instance)
4013 
4014         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4015         instance.updated_at = timeutils.utcnow()
4016         instance.save()
4017 
4018         self._notify_about_instance_usage(
4019             context, instance, "delete_ip.end", network_info=network_info)
4020 
4021     @wrap_exception()
4022     @reverts_task_state
4023     @wrap_instance_event(prefix='compute')
4024     @wrap_instance_fault
4025     def pause_instance(self, context, instance):
4026         """Pause an instance on this host."""
4027         context = context.elevated()
4028         LOG.info(_LI('Pausing'), instance=instance)
4029         self._notify_about_instance_usage(context, instance, 'pause.start')
4030         compute_utils.notify_about_instance_action(context, instance,
4031                self.host, action=fields.NotificationAction.PAUSE,
4032                phase=fields.NotificationPhase.START)
4033         self.driver.pause(instance)
4034         instance.power_state = self._get_power_state(context, instance)
4035         instance.vm_state = vm_states.PAUSED
4036         instance.task_state = None
4037         instance.save(expected_task_state=task_states.PAUSING)
4038         self._notify_about_instance_usage(context, instance, 'pause.end')
4039         compute_utils.notify_about_instance_action(context, instance,
4040                self.host, action=fields.NotificationAction.PAUSE,
4041                phase=fields.NotificationPhase.END)
4042 
4043     @wrap_exception()
4044     @reverts_task_state
4045     @wrap_instance_event(prefix='compute')
4046     @wrap_instance_fault
4047     def unpause_instance(self, context, instance):
4048         """Unpause a paused instance on this host."""
4049         context = context.elevated()
4050         LOG.info(_LI('Unpausing'), instance=instance)
4051         self._notify_about_instance_usage(context, instance, 'unpause.start')
4052         self.driver.unpause(instance)
4053         instance.power_state = self._get_power_state(context, instance)
4054         instance.vm_state = vm_states.ACTIVE
4055         instance.task_state = None
4056         instance.save(expected_task_state=task_states.UNPAUSING)
4057         self._notify_about_instance_usage(context, instance, 'unpause.end')
4058 
4059     @wrap_exception()
4060     def host_power_action(self, context, action):
4061         """Reboots, shuts down or powers up the host."""
4062         return self.driver.host_power_action(action)
4063 
4064     @wrap_exception()
4065     def host_maintenance_mode(self, context, host, mode):
4066         """Start/Stop host maintenance window. On start, it triggers
4067         guest VMs evacuation.
4068         """
4069         return self.driver.host_maintenance_mode(host, mode)
4070 
4071     @wrap_exception()
4072     def set_host_enabled(self, context, enabled):
4073         """Sets the specified host's ability to accept new instances."""
4074         return self.driver.set_host_enabled(enabled)
4075 
4076     @wrap_exception()
4077     def get_host_uptime(self, context):
4078         """Returns the result of calling "uptime" on the target host."""
4079         return self.driver.get_host_uptime()
4080 
4081     @wrap_exception()
4082     @wrap_instance_fault
4083     def get_diagnostics(self, context, instance):
4084         """Retrieve diagnostics for an instance on this host."""
4085         current_power_state = self._get_power_state(context, instance)
4086         if current_power_state == power_state.RUNNING:
4087             LOG.info(_LI("Retrieving diagnostics"), instance=instance)
4088             return self.driver.get_diagnostics(instance)
4089         else:
4090             raise exception.InstanceInvalidState(
4091                 attr='power state',
4092                 instance_uuid=instance.uuid,
4093                 state=power_state.STATE_MAP[instance.power_state],
4094                 method='get_diagnostics')
4095 
4096     # TODO(alaski): Remove object_compat for RPC version 5.0
4097     @object_compat
4098     @wrap_exception()
4099     @wrap_instance_fault
4100     def get_instance_diagnostics(self, context, instance):
4101         """Retrieve diagnostics for an instance on this host."""
4102         current_power_state = self._get_power_state(context, instance)
4103         if current_power_state == power_state.RUNNING:
4104             LOG.info(_LI("Retrieving diagnostics"), instance=instance)
4105             diags = self.driver.get_instance_diagnostics(instance)
4106             return diags.serialize()
4107         else:
4108             raise exception.InstanceInvalidState(
4109                 attr='power state',
4110                 instance_uuid=instance.uuid,
4111                 state=power_state.STATE_MAP[instance.power_state],
4112                 method='get_diagnostics')
4113 
4114     @wrap_exception()
4115     @reverts_task_state
4116     @wrap_instance_event(prefix='compute')
4117     @wrap_instance_fault
4118     def suspend_instance(self, context, instance):
4119         """Suspend the given instance."""
4120         context = context.elevated()
4121 
4122         # Store the old state
4123         instance.system_metadata['old_vm_state'] = instance.vm_state
4124         self._notify_about_instance_usage(context, instance, 'suspend.start')
4125         compute_utils.notify_about_instance_action(context, instance,
4126                 self.host, action=fields.NotificationAction.SUSPEND,
4127                 phase=fields.NotificationPhase.START)
4128         with self._error_out_instance_on_exception(context, instance,
4129              instance_state=instance.vm_state):
4130             self.driver.suspend(context, instance)
4131         instance.power_state = self._get_power_state(context, instance)
4132         instance.vm_state = vm_states.SUSPENDED
4133         instance.task_state = None
4134         instance.save(expected_task_state=task_states.SUSPENDING)
4135         self._notify_about_instance_usage(context, instance, 'suspend.end')
4136         compute_utils.notify_about_instance_action(context, instance,
4137                 self.host, action=fields.NotificationAction.SUSPEND,
4138                 phase=fields.NotificationPhase.END)
4139 
4140     @wrap_exception()
4141     @reverts_task_state
4142     @wrap_instance_event(prefix='compute')
4143     @wrap_instance_fault
4144     def resume_instance(self, context, instance):
4145         """Resume the given suspended instance."""
4146         context = context.elevated()
4147         LOG.info(_LI('Resuming'), instance=instance)
4148 
4149         self._notify_about_instance_usage(context, instance, 'resume.start')
4150         network_info = self.network_api.get_instance_nw_info(context, instance)
4151         block_device_info = self._get_instance_block_device_info(
4152                             context, instance)
4153 
4154         with self._error_out_instance_on_exception(context, instance,
4155              instance_state=instance.vm_state):
4156             self.driver.resume(context, instance, network_info,
4157                                block_device_info)
4158 
4159         instance.power_state = self._get_power_state(context, instance)
4160 
4161         # We default to the ACTIVE state for backwards compatibility
4162         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4163                                                          vm_states.ACTIVE)
4164 
4165         instance.task_state = None
4166         instance.save(expected_task_state=task_states.RESUMING)
4167         self._notify_about_instance_usage(context, instance, 'resume.end')
4168 
4169     @wrap_exception()
4170     @reverts_task_state
4171     @wrap_instance_event(prefix='compute')
4172     @wrap_instance_fault
4173     def shelve_instance(self, context, instance, image_id,
4174                         clean_shutdown):
4175         """Shelve an instance.
4176 
4177         This should be used when you want to take a snapshot of the instance.
4178         It also adds system_metadata that can be used by a periodic task to
4179         offload the shelved instance after a period of time.
4180 
4181         :param context: request context
4182         :param instance: an Instance object
4183         :param image_id: an image id to snapshot to.
4184         :param clean_shutdown: give the GuestOS a chance to stop
4185         """
4186 
4187         @utils.synchronized(instance.uuid)
4188         def do_shelve_instance():
4189             self._shelve_instance(context, instance, image_id, clean_shutdown)
4190         do_shelve_instance()
4191 
4192     def _shelve_instance(self, context, instance, image_id,
4193                          clean_shutdown):
4194         LOG.info(_LI('Shelving'), instance=instance)
4195         compute_utils.notify_usage_exists(self.notifier, context, instance,
4196                                           current_period=True)
4197         self._notify_about_instance_usage(context, instance, 'shelve.start')
4198         compute_utils.notify_about_instance_action(context, instance,
4199                 self.host, action=fields.NotificationAction.SHELVE,
4200                 phase=fields.NotificationPhase.START)
4201 
4202         def update_task_state(task_state, expected_state=task_states.SHELVING):
4203             shelving_state_map = {
4204                     task_states.IMAGE_PENDING_UPLOAD:
4205                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4206                     task_states.IMAGE_UPLOADING:
4207                         task_states.SHELVING_IMAGE_UPLOADING,
4208                     task_states.SHELVING: task_states.SHELVING}
4209             task_state = shelving_state_map[task_state]
4210             expected_state = shelving_state_map[expected_state]
4211             instance.task_state = task_state
4212             instance.save(expected_task_state=expected_state)
4213 
4214         self._power_off_instance(context, instance, clean_shutdown)
4215         self.driver.snapshot(context, instance, image_id, update_task_state)
4216 
4217         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4218         instance.system_metadata['shelved_image_id'] = image_id
4219         instance.system_metadata['shelved_host'] = self.host
4220         instance.vm_state = vm_states.SHELVED
4221         instance.task_state = None
4222         if CONF.shelved_offload_time == 0:
4223             instance.task_state = task_states.SHELVING_OFFLOADING
4224         instance.power_state = self._get_power_state(context, instance)
4225         instance.save(expected_task_state=[
4226                 task_states.SHELVING,
4227                 task_states.SHELVING_IMAGE_UPLOADING])
4228 
4229         self._notify_about_instance_usage(context, instance, 'shelve.end')
4230         compute_utils.notify_about_instance_action(context, instance,
4231                 self.host, action=fields.NotificationAction.SHELVE,
4232                 phase=fields.NotificationPhase.END)
4233 
4234         if CONF.shelved_offload_time == 0:
4235             self._shelve_offload_instance(context, instance,
4236                                           clean_shutdown=False)
4237 
4238     @wrap_exception()
4239     @reverts_task_state
4240     @wrap_instance_fault
4241     def shelve_offload_instance(self, context, instance, clean_shutdown):
4242         """Remove a shelved instance from the hypervisor.
4243 
4244         This frees up those resources for use by other instances, but may lead
4245         to slower unshelve times for this instance.  This method is used by
4246         volume backed instances since restoring them doesn't involve the
4247         potentially large download of an image.
4248 
4249         :param context: request context
4250         :param instance: nova.objects.instance.Instance
4251         :param clean_shutdown: give the GuestOS a chance to stop
4252         """
4253 
4254         @utils.synchronized(instance.uuid)
4255         def do_shelve_offload_instance():
4256             self._shelve_offload_instance(context, instance, clean_shutdown)
4257         do_shelve_offload_instance()
4258 
4259     def _shelve_offload_instance(self, context, instance, clean_shutdown):
4260         LOG.info(_LI('Shelve offloading'), instance=instance)
4261         self._notify_about_instance_usage(context, instance,
4262                 'shelve_offload.start')
4263 
4264         self._power_off_instance(context, instance, clean_shutdown)
4265         current_power_state = self._get_power_state(context, instance)
4266 
4267         self.network_api.cleanup_instance_network_on_host(context, instance,
4268                                                           instance.host)
4269         network_info = self.network_api.get_instance_nw_info(context, instance)
4270         block_device_info = self._get_instance_block_device_info(context,
4271                                                                  instance)
4272         self.driver.destroy(context, instance, network_info,
4273                 block_device_info)
4274 
4275         instance.power_state = current_power_state
4276         # NOTE(mriedem): The vm_state has to be set before updating the
4277         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4278         # values cannot be nulled out until after updating the resource tracker
4279         # though.
4280         instance.vm_state = vm_states.SHELVED_OFFLOADED
4281         instance.task_state = None
4282         instance.save(expected_task_state=[task_states.SHELVING,
4283                                            task_states.SHELVING_OFFLOADING])
4284 
4285         # NOTE(ndipanov): Free resources from the resource tracker
4286         self._update_resource_tracker(context, instance)
4287 
4288         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4289         # instance, so ensure any calls result in errors
4290         self._nil_out_instance_obj_host_and_node(instance)
4291         instance.save(expected_task_state=None)
4292 
4293         self._delete_scheduler_instance_info(context, instance.uuid)
4294         self._notify_about_instance_usage(context, instance,
4295                 'shelve_offload.end')
4296 
4297     @wrap_exception()
4298     @reverts_task_state
4299     @wrap_instance_event(prefix='compute')
4300     @wrap_instance_fault
4301     def unshelve_instance(self, context, instance, image,
4302                           filter_properties, node):
4303         """Unshelve the instance.
4304 
4305         :param context: request context
4306         :param instance: a nova.objects.instance.Instance object
4307         :param image: an image to build from.  If None we assume a
4308             volume backed instance.
4309         :param filter_properties: dict containing limits, retry info etc.
4310         :param node: target compute node
4311         """
4312         if filter_properties is None:
4313             filter_properties = {}
4314 
4315         @utils.synchronized(instance.uuid)
4316         def do_unshelve_instance():
4317             self._unshelve_instance(context, instance, image,
4318                                     filter_properties, node)
4319         do_unshelve_instance()
4320 
4321     def _unshelve_instance_key_scrub(self, instance):
4322         """Remove data from the instance that may cause side effects."""
4323         cleaned_keys = dict(
4324                 key_data=instance.key_data,
4325                 auto_disk_config=instance.auto_disk_config)
4326         instance.key_data = None
4327         instance.auto_disk_config = False
4328         return cleaned_keys
4329 
4330     def _unshelve_instance_key_restore(self, instance, keys):
4331         """Restore previously scrubbed keys before saving the instance."""
4332         instance.update(keys)
4333 
4334     def _unshelve_instance(self, context, instance, image, filter_properties,
4335                            node):
4336         LOG.info(_LI('Unshelving'), instance=instance)
4337         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4338         instance.task_state = task_states.SPAWNING
4339         instance.save()
4340 
4341         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4342                 context, instance.uuid)
4343         block_device_info = self._prep_block_device(context, instance, bdms,
4344                                                     do_check_attach=False)
4345         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4346 
4347         if node is None:
4348             node = self.driver.get_available_nodes()[0]
4349             LOG.debug('No node specified, defaulting to %s', node,
4350                       instance=instance)
4351 
4352         rt = self._get_resource_tracker(node)
4353         limits = filter_properties.get('limits', {})
4354 
4355         shelved_image_ref = instance.image_ref
4356         if image:
4357             instance.image_ref = image['id']
4358             image_meta = objects.ImageMeta.from_dict(image)
4359         else:
4360             image_meta = objects.ImageMeta.from_dict(
4361                 utils.get_image_from_system_metadata(
4362                     instance.system_metadata))
4363 
4364         self.network_api.setup_instance_network_on_host(context, instance,
4365                                                         self.host)
4366         network_info = self.network_api.get_instance_nw_info(context, instance)
4367         try:
4368             with rt.instance_claim(context, instance, limits):
4369                 self.driver.spawn(context, instance, image_meta,
4370                                   injected_files=[],
4371                                   admin_password=None,
4372                                   network_info=network_info,
4373                                   block_device_info=block_device_info)
4374         except Exception:
4375             with excutils.save_and_reraise_exception():
4376                 LOG.exception(_LE('Instance failed to spawn'),
4377                               instance=instance)
4378 
4379         if image:
4380             instance.image_ref = shelved_image_ref
4381             self._delete_snapshot_of_shelved_instance(context, instance,
4382                                                       image['id'])
4383 
4384         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4385         self._update_instance_after_spawn(context, instance)
4386         # Delete system_metadata for a shelved instance
4387         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4388 
4389         instance.save(expected_task_state=task_states.SPAWNING)
4390         self._update_scheduler_instance_info(context, instance)
4391         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4392 
4393     @messaging.expected_exceptions(NotImplementedError)
4394     @wrap_instance_fault
4395     def reset_network(self, context, instance):
4396         """Reset networking on the given instance."""
4397         LOG.debug('Reset network', instance=instance)
4398         self.driver.reset_network(instance)
4399 
4400     def _inject_network_info(self, context, instance, network_info):
4401         """Inject network info for the given instance."""
4402         LOG.debug('Inject network info', instance=instance)
4403         LOG.debug('network_info to inject: |%s|', network_info,
4404                   instance=instance)
4405 
4406         self.driver.inject_network_info(instance,
4407                                         network_info)
4408 
4409     @wrap_instance_fault
4410     def inject_network_info(self, context, instance):
4411         """Inject network info, but don't return the info."""
4412         network_info = self.network_api.get_instance_nw_info(context, instance)
4413         self._inject_network_info(context, instance, network_info)
4414 
4415     @messaging.expected_exceptions(NotImplementedError,
4416                                    exception.ConsoleNotAvailable,
4417                                    exception.InstanceNotFound)
4418     @wrap_exception()
4419     @wrap_instance_fault
4420     def get_console_output(self, context, instance, tail_length):
4421         """Send the console output for the given instance."""
4422         context = context.elevated()
4423         LOG.info(_LI("Get console output"), instance=instance)
4424         output = self.driver.get_console_output(context, instance)
4425 
4426         if type(output) is six.text_type:
4427             output = six.b(output)
4428 
4429         if tail_length is not None:
4430             output = self._tail_log(output, tail_length)
4431 
4432         return output.decode('ascii', 'replace')
4433 
4434     def _tail_log(self, log, length):
4435         try:
4436             length = int(length)
4437         except ValueError:
4438             length = 0
4439 
4440         if length == 0:
4441             return b''
4442         else:
4443             return b'\n'.join(log.split(b'\n')[-int(length):])
4444 
4445     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4446                                    exception.InstanceNotReady,
4447                                    exception.InstanceNotFound,
4448                                    exception.ConsoleTypeUnavailable,
4449                                    NotImplementedError)
4450     @wrap_exception()
4451     @wrap_instance_fault
4452     def get_vnc_console(self, context, console_type, instance):
4453         """Return connection information for a vnc console."""
4454         context = context.elevated()
4455         LOG.debug("Getting vnc console", instance=instance)
4456         token = uuidutils.generate_uuid()
4457 
4458         if not CONF.vnc.enabled:
4459             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4460 
4461         if console_type == 'novnc':
4462             # For essex, novncproxy_base_url must include the full path
4463             # including the html file (like http://myhost/vnc_auto.html)
4464             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
4465         elif console_type == 'xvpvnc':
4466             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
4467         else:
4468             raise exception.ConsoleTypeInvalid(console_type=console_type)
4469 
4470         try:
4471             # Retrieve connect info from driver, and then decorate with our
4472             # access info token
4473             console = self.driver.get_vnc_console(context, instance)
4474             connect_info = console.get_connection_info(token, access_url)
4475         except exception.InstanceNotFound:
4476             if instance.vm_state != vm_states.BUILDING:
4477                 raise
4478             raise exception.InstanceNotReady(instance_id=instance.uuid)
4479 
4480         return connect_info
4481 
4482     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4483                                    exception.InstanceNotReady,
4484                                    exception.InstanceNotFound,
4485                                    exception.ConsoleTypeUnavailable,
4486                                    NotImplementedError)
4487     @wrap_exception()
4488     @wrap_instance_fault
4489     def get_spice_console(self, context, console_type, instance):
4490         """Return connection information for a spice console."""
4491         context = context.elevated()
4492         LOG.debug("Getting spice console", instance=instance)
4493         token = uuidutils.generate_uuid()
4494 
4495         if not CONF.spice.enabled:
4496             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4497 
4498         if console_type == 'spice-html5':
4499             # For essex, spicehtml5proxy_base_url must include the full path
4500             # including the html file (like http://myhost/spice_auto.html)
4501             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
4502                                           token)
4503         else:
4504             raise exception.ConsoleTypeInvalid(console_type=console_type)
4505 
4506         try:
4507             # Retrieve connect info from driver, and then decorate with our
4508             # access info token
4509             console = self.driver.get_spice_console(context, instance)
4510             connect_info = console.get_connection_info(token, access_url)
4511         except exception.InstanceNotFound:
4512             if instance.vm_state != vm_states.BUILDING:
4513                 raise
4514             raise exception.InstanceNotReady(instance_id=instance.uuid)
4515 
4516         return connect_info
4517 
4518     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4519                                    exception.InstanceNotReady,
4520                                    exception.InstanceNotFound,
4521                                    exception.ConsoleTypeUnavailable,
4522                                    NotImplementedError)
4523     @wrap_exception()
4524     @wrap_instance_fault
4525     def get_rdp_console(self, context, console_type, instance):
4526         """Return connection information for a RDP console."""
4527         context = context.elevated()
4528         LOG.debug("Getting RDP console", instance=instance)
4529         token = uuidutils.generate_uuid()
4530 
4531         if not CONF.rdp.enabled:
4532             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4533 
4534         if console_type == 'rdp-html5':
4535             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
4536                                           token)
4537         else:
4538             raise exception.ConsoleTypeInvalid(console_type=console_type)
4539 
4540         try:
4541             # Retrieve connect info from driver, and then decorate with our
4542             # access info token
4543             console = self.driver.get_rdp_console(context, instance)
4544             connect_info = console.get_connection_info(token, access_url)
4545         except exception.InstanceNotFound:
4546             if instance.vm_state != vm_states.BUILDING:
4547                 raise
4548             raise exception.InstanceNotReady(instance_id=instance.uuid)
4549 
4550         return connect_info
4551 
4552     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4553                                    exception.InstanceNotReady,
4554                                    exception.InstanceNotFound,
4555                                    exception.ConsoleTypeUnavailable,
4556                                    NotImplementedError)
4557     @wrap_exception()
4558     @wrap_instance_fault
4559     def get_mks_console(self, context, console_type, instance):
4560         """Return connection information for a MKS console."""
4561         context = context.elevated()
4562         LOG.debug("Getting MKS console", instance=instance)
4563         token = uuidutils.generate_uuid()
4564 
4565         if not CONF.mks.enabled:
4566             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4567 
4568         if console_type == 'webmks':
4569             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
4570                                           token)
4571         else:
4572             raise exception.ConsoleTypeInvalid(console_type=console_type)
4573 
4574         try:
4575             # Retrieve connect info from driver, and then decorate with our
4576             # access info token
4577             console = self.driver.get_mks_console(context, instance)
4578             connect_info = console.get_connection_info(token, access_url)
4579         except exception.InstanceNotFound:
4580             if instance.vm_state != vm_states.BUILDING:
4581                 raise
4582             raise exception.InstanceNotReady(instance_id=instance.uuid)
4583 
4584         return connect_info
4585 
4586     @messaging.expected_exceptions(
4587         exception.ConsoleTypeInvalid,
4588         exception.InstanceNotReady,
4589         exception.InstanceNotFound,
4590         exception.ConsoleTypeUnavailable,
4591         exception.SocketPortRangeExhaustedException,
4592         exception.ImageSerialPortNumberInvalid,
4593         exception.ImageSerialPortNumberExceedFlavorValue,
4594         NotImplementedError)
4595     @wrap_exception()
4596     @wrap_instance_fault
4597     def get_serial_console(self, context, console_type, instance):
4598         """Returns connection information for a serial console."""
4599 
4600         LOG.debug("Getting serial console", instance=instance)
4601 
4602         if not CONF.serial_console.enabled:
4603             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4604 
4605         context = context.elevated()
4606 
4607         token = uuidutils.generate_uuid()
4608         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
4609 
4610         try:
4611             # Retrieve connect info from driver, and then decorate with our
4612             # access info token
4613             console = self.driver.get_serial_console(context, instance)
4614             connect_info = console.get_connection_info(token, access_url)
4615         except exception.InstanceNotFound:
4616             if instance.vm_state != vm_states.BUILDING:
4617                 raise
4618             raise exception.InstanceNotReady(instance_id=instance.uuid)
4619 
4620         return connect_info
4621 
4622     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4623                                    exception.InstanceNotReady,
4624                                    exception.InstanceNotFound)
4625     @wrap_exception()
4626     @wrap_instance_fault
4627     def validate_console_port(self, ctxt, instance, port, console_type):
4628         if console_type == "spice-html5":
4629             console_info = self.driver.get_spice_console(ctxt, instance)
4630         elif console_type == "rdp-html5":
4631             console_info = self.driver.get_rdp_console(ctxt, instance)
4632         elif console_type == "serial":
4633             console_info = self.driver.get_serial_console(ctxt, instance)
4634         elif console_type == "webmks":
4635             console_info = self.driver.get_mks_console(ctxt, instance)
4636         else:
4637             console_info = self.driver.get_vnc_console(ctxt, instance)
4638 
4639         return console_info.port == port
4640 
4641     @wrap_exception()
4642     @reverts_task_state
4643     @wrap_instance_fault
4644     def reserve_block_device_name(self, context, instance, device,
4645                                   volume_id, disk_bus, device_type):
4646         @utils.synchronized(instance.uuid)
4647         def do_reserve():
4648             bdms = (
4649                 objects.BlockDeviceMappingList.get_by_instance_uuid(
4650                     context, instance.uuid))
4651 
4652             # NOTE(ndipanov): We need to explicitly set all the fields on the
4653             #                 object so that obj_load_attr does not fail
4654             new_bdm = objects.BlockDeviceMapping(
4655                     context=context,
4656                     source_type='volume', destination_type='volume',
4657                     instance_uuid=instance.uuid, boot_index=None,
4658                     volume_id=volume_id,
4659                     device_name=device, guest_format=None,
4660                     disk_bus=disk_bus, device_type=device_type)
4661 
4662             new_bdm.device_name = self._get_device_name_for_instance(
4663                     instance, bdms, new_bdm)
4664 
4665             # NOTE(vish): create bdm here to avoid race condition
4666             new_bdm.create()
4667             return new_bdm
4668 
4669         return do_reserve()
4670 
4671     @wrap_exception()
4672     @wrap_instance_fault
4673     def attach_volume(self, context, instance, bdm):
4674         """Attach a volume to an instance."""
4675         driver_bdm = driver_block_device.convert_volume(bdm)
4676 
4677         @utils.synchronized(instance.uuid)
4678         def do_attach_volume(context, instance, driver_bdm):
4679             try:
4680                 return self._attach_volume(context, instance, driver_bdm)
4681             except Exception:
4682                 with excutils.save_and_reraise_exception():
4683                     bdm.destroy()
4684 
4685         do_attach_volume(context, instance, driver_bdm)
4686 
4687     def _attach_volume(self, context, instance, bdm):
4688         context = context.elevated()
4689         LOG.info(_LI('Attaching volume %(volume_id)s to %(mountpoint)s'),
4690                   {'volume_id': bdm.volume_id,
4691                   'mountpoint': bdm['mount_device']},
4692                  instance=instance)
4693         try:
4694             bdm.attach(context, instance, self.volume_api, self.driver,
4695                        do_check_attach=False, do_driver_attach=True)
4696         except Exception:
4697             with excutils.save_and_reraise_exception():
4698                 LOG.exception(_LE("Failed to attach %(volume_id)s "
4699                                   "at %(mountpoint)s"),
4700                               {'volume_id': bdm.volume_id,
4701                                'mountpoint': bdm['mount_device']},
4702                               instance=instance)
4703                 self.volume_api.unreserve_volume(context, bdm.volume_id)
4704 
4705         info = {'volume_id': bdm.volume_id}
4706         self._notify_about_instance_usage(
4707             context, instance, "volume.attach", extra_usage_info=info)
4708 
4709     def _driver_detach_volume(self, context, instance, bdm, connection_info):
4710         """Do the actual driver detach using block device mapping."""
4711         mp = bdm.device_name
4712         volume_id = bdm.volume_id
4713 
4714         LOG.info(_LI('Detach volume %(volume_id)s from mountpoint %(mp)s'),
4715                   {'volume_id': volume_id, 'mp': mp},
4716                   instance=instance)
4717 
4718         try:
4719             if not self.driver.instance_exists(instance):
4720                 LOG.warning(_LW('Detaching volume from unknown instance'),
4721                             instance=instance)
4722 
4723             encryption = encryptors.get_encryption_metadata(
4724                 context, self.volume_api, volume_id, connection_info)
4725 
4726             self.driver.detach_volume(connection_info,
4727                                       instance,
4728                                       mp,
4729                                       encryption=encryption)
4730         except exception.DiskNotFound as err:
4731             LOG.warning(_LW('Ignoring DiskNotFound exception while detaching '
4732                             'volume %(volume_id)s from %(mp)s: %(err)s'),
4733                         {'volume_id': volume_id, 'mp': mp, 'err': err},
4734                         instance=instance)
4735         except Exception:
4736             with excutils.save_and_reraise_exception():
4737                 LOG.exception(_LE('Failed to detach volume %(volume_id)s '
4738                                   'from %(mp)s'),
4739                               {'volume_id': volume_id, 'mp': mp},
4740                               instance=instance)
4741                 self.volume_api.roll_detaching(context, volume_id)
4742 
4743     def _detach_volume(self, context, volume_id, instance, destroy_bdm=True,
4744                        attachment_id=None):
4745         """Detach a volume from an instance.
4746 
4747         :param context: security context
4748         :param volume_id: the volume id
4749         :param instance: the Instance object to detach the volume from
4750         :param destroy_bdm: if True, the corresponding BDM entry will be marked
4751                             as deleted. Disabling this is useful for operations
4752                             like rebuild, when we don't want to destroy BDM
4753 
4754         """
4755 
4756         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4757                 context, volume_id, instance.uuid)
4758         if CONF.volume_usage_poll_interval > 0:
4759             vol_stats = []
4760             mp = bdm.device_name
4761             # Handle bootable volumes which will not contain /dev/
4762             if '/dev/' in mp:
4763                 mp = mp[5:]
4764             try:
4765                 vol_stats = self.driver.block_stats(instance, mp)
4766             except NotImplementedError:
4767                 pass
4768 
4769             if vol_stats:
4770                 LOG.debug("Updating volume usage cache with totals",
4771                           instance=instance)
4772                 rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
4773                 vol_usage = objects.VolumeUsage(context)
4774                 vol_usage.volume_id = volume_id
4775                 vol_usage.instance_uuid = instance.uuid
4776                 vol_usage.project_id = instance.project_id
4777                 vol_usage.user_id = instance.user_id
4778                 vol_usage.availability_zone = instance.availability_zone
4779                 vol_usage.curr_reads = rd_req
4780                 vol_usage.curr_read_bytes = rd_bytes
4781                 vol_usage.curr_writes = wr_req
4782                 vol_usage.curr_write_bytes = wr_bytes
4783                 vol_usage.save(update_totals=True)
4784                 self.notifier.info(context, 'volume.usage',
4785                                    compute_utils.usage_volume_info(vol_usage))
4786 
4787         connection_info = jsonutils.loads(bdm.connection_info)
4788         connector = self.driver.get_volume_connector(instance)
4789         if CONF.host == instance.host:
4790             # Only attempt to detach and disconnect from the volume if the
4791             # instance is currently associated with the local compute host.
4792             self._driver_detach_volume(context, instance, bdm, connection_info)
4793         elif not destroy_bdm:
4794             LOG.debug("Skipping _driver_detach_volume during remote rebuild.",
4795                       instance=instance)
4796         elif destroy_bdm:
4797             LOG.error(_LE("Unable to call for a driver detach of volume "
4798                           "%(vol_id)s due to the instance being registered to "
4799                           "the remote host %(inst_host)s."),
4800                       {'vol_id': volume_id, 'inst_host': instance.host},
4801                       instance=instance)
4802 
4803         if connection_info and not destroy_bdm and (
4804            connector.get('host') != instance.host):
4805             # If the volume is attached to another host (evacuate) then
4806             # this connector is for the wrong host. Use the connector that
4807             # was stored in connection_info instead (if we have one, and it
4808             # is for the expected host).
4809             stashed_connector = connection_info.get('connector')
4810             if not stashed_connector:
4811                 # Volume was attached before we began stashing connectors
4812                 LOG.warning(_LW("Host mismatch detected, but stashed "
4813                                 "volume connector not found. Instance host is "
4814                                 "%(ihost)s, but volume connector host is "
4815                                 "%(chost)s."),
4816                             {'ihost': instance.host,
4817                              'chost': connector.get('host')})
4818             elif stashed_connector.get('host') != instance.host:
4819                 # Unexpected error. The stashed connector is also not matching
4820                 # the needed instance host.
4821                 LOG.error(_LE("Host mismatch detected in stashed volume "
4822                               "connector. Will use local volume connector. "
4823                               "Instance host is %(ihost)s. Local volume "
4824                               "connector host is %(chost)s. Stashed volume "
4825                               "connector host is %(schost)s."),
4826                           {'ihost': instance.host,
4827                            'chost': connector.get('host'),
4828                            'schost': stashed_connector.get('host')})
4829             else:
4830                 # Fix found. Use stashed connector.
4831                 LOG.debug("Host mismatch detected. Found usable stashed "
4832                           "volume connector. Instance host is %(ihost)s. "
4833                           "Local volume connector host was %(chost)s. "
4834                           "Stashed volume connector host is %(schost)s.",
4835                           {'ihost': instance.host,
4836                            'chost': connector.get('host'),
4837                            'schost': stashed_connector.get('host')})
4838                 connector = stashed_connector
4839 
4840         self.volume_api.terminate_connection(context, volume_id, connector)
4841 
4842         if destroy_bdm:
4843             bdm.destroy()
4844 
4845         info = dict(volume_id=volume_id)
4846         self._notify_about_instance_usage(
4847             context, instance, "volume.detach", extra_usage_info=info)
4848         self.volume_api.detach(context.elevated(), volume_id, instance.uuid,
4849                                attachment_id)
4850 
4851     @wrap_exception()
4852     @wrap_instance_fault
4853     def detach_volume(self, context, volume_id, instance, attachment_id=None):
4854         """Detach a volume from an instance."""
4855 
4856         self._detach_volume(context, volume_id, instance,
4857                             attachment_id=attachment_id)
4858 
4859     def _init_volume_connection(self, context, new_volume_id,
4860                                 old_volume_id, connector, instance, bdm):
4861 
4862         new_cinfo = self.volume_api.initialize_connection(context,
4863                                                           new_volume_id,
4864                                                           connector)
4865         old_cinfo = jsonutils.loads(bdm['connection_info'])
4866         if old_cinfo and 'serial' not in old_cinfo:
4867             old_cinfo['serial'] = old_volume_id
4868         new_cinfo['serial'] = old_cinfo['serial']
4869         return (old_cinfo, new_cinfo)
4870 
4871     def _swap_volume(self, context, instance, bdm, connector,
4872                      old_volume_id, new_volume_id, resize_to):
4873         mountpoint = bdm['device_name']
4874         failed = False
4875         new_cinfo = None
4876         try:
4877             old_cinfo, new_cinfo = self._init_volume_connection(context,
4878                                                                 new_volume_id,
4879                                                                 old_volume_id,
4880                                                                 connector,
4881                                                                 instance,
4882                                                                 bdm)
4883             LOG.debug("swap_volume: Calling driver volume swap with "
4884                       "connection infos: new: %(new_cinfo)s; "
4885                       "old: %(old_cinfo)s",
4886                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo},
4887                       instance=instance)
4888             self.driver.swap_volume(old_cinfo, new_cinfo, instance, mountpoint,
4889                                     resize_to)
4890         except Exception:
4891             failed = True
4892             with excutils.save_and_reraise_exception():
4893                 if new_cinfo:
4894                     msg = _LE("Failed to swap volume %(old_volume_id)s "
4895                               "for %(new_volume_id)s")
4896                     LOG.exception(msg, {'old_volume_id': old_volume_id,
4897                                         'new_volume_id': new_volume_id},
4898                                   instance=instance)
4899                 else:
4900                     msg = _LE("Failed to connect to volume %(volume_id)s "
4901                               "with volume at %(mountpoint)s")
4902                     LOG.exception(msg, {'volume_id': new_volume_id,
4903                                         'mountpoint': bdm['device_name']},
4904                                   instance=instance)
4905                 self.volume_api.roll_detaching(context, old_volume_id)
4906                 self.volume_api.unreserve_volume(context, new_volume_id)
4907         finally:
4908             conn_volume = new_volume_id if failed else old_volume_id
4909             if new_cinfo:
4910                 LOG.debug("swap_volume: calling Cinder terminate_connection "
4911                           "for %(volume)s", {'volume': conn_volume},
4912                           instance=instance)
4913                 self.volume_api.terminate_connection(context,
4914                                                      conn_volume,
4915                                                      connector)
4916             # If Cinder initiated the swap, it will keep
4917             # the original ID
4918             comp_ret = self.volume_api.migrate_volume_completion(
4919                                                       context,
4920                                                       old_volume_id,
4921                                                       new_volume_id,
4922                                                       error=failed)
4923             LOG.debug("swap_volume: Cinder migrate_volume_completion "
4924                       "returned: %(comp_ret)s", {'comp_ret': comp_ret},
4925                       instance=instance)
4926 
4927         return (comp_ret, new_cinfo)
4928 
4929     @wrap_exception()
4930     @reverts_task_state
4931     @wrap_instance_fault
4932     def swap_volume(self, context, old_volume_id, new_volume_id, instance):
4933         """Swap volume for an instance."""
4934         context = context.elevated()
4935 
4936         compute_utils.notify_about_volume_swap(
4937             context, instance, self.host,
4938             fields.NotificationAction.VOLUME_SWAP,
4939             fields.NotificationPhase.START,
4940             old_volume_id, new_volume_id)
4941 
4942         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4943                 context, old_volume_id, instance.uuid)
4944         connector = self.driver.get_volume_connector(instance)
4945 
4946         resize_to = 0
4947         old_vol_size = self.volume_api.get(context, old_volume_id)['size']
4948         new_vol_size = self.volume_api.get(context, new_volume_id)['size']
4949         if new_vol_size > old_vol_size:
4950             resize_to = new_vol_size
4951 
4952         LOG.info(_LI('Swapping volume %(old_volume)s for %(new_volume)s'),
4953                   {'old_volume': old_volume_id, 'new_volume': new_volume_id},
4954                  instance=instance)
4955         comp_ret, new_cinfo = self._swap_volume(context, instance,
4956                                                          bdm,
4957                                                          connector,
4958                                                          old_volume_id,
4959                                                          new_volume_id,
4960                                                          resize_to)
4961 
4962         save_volume_id = comp_ret['save_volume_id']
4963 
4964         # Update bdm
4965         values = {
4966             'connection_info': jsonutils.dumps(new_cinfo),
4967             'source_type': 'volume',
4968             'destination_type': 'volume',
4969             'snapshot_id': None,
4970             'volume_id': save_volume_id,
4971             'no_device': None}
4972 
4973         if resize_to:
4974             values['volume_size'] = resize_to
4975 
4976         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
4977                   "%(updates)s", {'volume_id': bdm.volume_id,
4978                                   'updates': values},
4979                   instance=instance)
4980         bdm.update(values)
4981         bdm.save()
4982 
4983         compute_utils.notify_about_volume_swap(
4984             context, instance, self.host,
4985             fields.NotificationAction.VOLUME_SWAP,
4986             fields.NotificationPhase.END,
4987             old_volume_id, new_volume_id)
4988 
4989     @wrap_exception()
4990     def remove_volume_connection(self, context, volume_id, instance):
4991         """Remove a volume connection using the volume api."""
4992         # NOTE(vish): We don't want to actually mark the volume
4993         #             detached, or delete the bdm, just remove the
4994         #             connection from this host.
4995 
4996         try:
4997             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4998                     context, volume_id, instance.uuid)
4999             connection_info = jsonutils.loads(bdm.connection_info)
5000             self._driver_detach_volume(context, instance, bdm, connection_info)
5001             connector = self.driver.get_volume_connector(instance)
5002             self.volume_api.terminate_connection(context, volume_id, connector)
5003         except exception.NotFound:
5004             pass
5005 
5006     @wrap_exception()
5007     @wrap_instance_fault
5008     def attach_interface(self, context, instance, network_id, port_id,
5009                          requested_ip):
5010         """Use hotplug to add an network adapter to an instance."""
5011         if not self.driver.capabilities['supports_attach_interface']:
5012             raise exception.AttachInterfaceNotSupported(
5013                 instance_id=instance.uuid)
5014         bind_host_id = self.driver.network_binding_host_id(context, instance)
5015         network_info = self.network_api.allocate_port_for_instance(
5016             context, instance, port_id, network_id, requested_ip,
5017             bind_host_id=bind_host_id)
5018         if len(network_info) != 1:
5019             LOG.error(_LE('allocate_port_for_instance returned %(ports)s '
5020                           'ports'), {'ports': len(network_info)})
5021             raise exception.InterfaceAttachFailed(
5022                     instance_uuid=instance.uuid)
5023         image_meta = objects.ImageMeta.from_instance(instance)
5024 
5025         try:
5026             self.driver.attach_interface(instance, image_meta, network_info[0])
5027         except exception.NovaException as ex:
5028             port_id = network_info[0].get('id')
5029             LOG.warning(_LW("attach interface failed , try to deallocate "
5030                          "port %(port_id)s, reason: %(msg)s"),
5031                      {'port_id': port_id, 'msg': ex},
5032                      instance=instance)
5033             try:
5034                 self.network_api.deallocate_port_for_instance(
5035                     context, instance, port_id)
5036             except Exception:
5037                 LOG.warning(_LW("deallocate port %(port_id)s failed"),
5038                              {'port_id': port_id}, instance=instance)
5039             raise exception.InterfaceAttachFailed(
5040                 instance_uuid=instance.uuid)
5041 
5042         return network_info[0]
5043 
5044     @wrap_exception()
5045     @wrap_instance_fault
5046     def detach_interface(self, context, instance, port_id):
5047         """Detach a network adapter from an instance."""
5048         network_info = instance.info_cache.network_info
5049         condemned = None
5050         for vif in network_info:
5051             if vif['id'] == port_id:
5052                 condemned = vif
5053                 break
5054         if condemned is None:
5055             raise exception.PortNotFound(_("Port %s is not "
5056                                            "attached") % port_id)
5057         try:
5058             self.driver.detach_interface(instance, condemned)
5059         except exception.NovaException as ex:
5060             LOG.warning(_LW("Detach interface failed, port_id=%(port_id)s,"
5061                             " reason: %(msg)s"),
5062                         {'port_id': port_id, 'msg': ex}, instance=instance)
5063             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5064         else:
5065             try:
5066                 self.network_api.deallocate_port_for_instance(
5067                     context, instance, port_id)
5068             except Exception as ex:
5069                 with excutils.save_and_reraise_exception():
5070                     # Since this is a cast operation, log the failure for
5071                     # triage.
5072                     LOG.warning(_LW('Failed to deallocate port %(port_id)s '
5073                                     'for instance. Error: %(error)s'),
5074                                 {'port_id': port_id, 'error': ex},
5075                                 instance=instance)
5076 
5077     def _get_compute_info(self, context, host):
5078         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5079             context, host)
5080 
5081     @wrap_exception()
5082     def check_instance_shared_storage(self, ctxt, instance, data):
5083         """Check if the instance files are shared
5084 
5085         :param ctxt: security context
5086         :param instance: dict of instance data
5087         :param data: result of driver.check_instance_shared_storage_local
5088 
5089         Returns True if instance disks located on shared storage and
5090         False otherwise.
5091         """
5092         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5093 
5094     @wrap_exception()
5095     @wrap_instance_event(prefix='compute')
5096     @wrap_instance_fault
5097     def check_can_live_migrate_destination(self, ctxt, instance,
5098                                            block_migration, disk_over_commit,
5099                                            migration=None, limits=None):
5100         """Check if it is possible to execute live migration.
5101 
5102         This runs checks on the destination host, and then calls
5103         back to the source host to check the results.
5104 
5105         :param context: security context
5106         :param instance: dict of instance data
5107         :param block_migration: if true, prepare for block migration
5108                                 if None, calculate it in driver
5109         :param disk_over_commit: if true, allow disk over commit
5110                                  if None, ignore disk usage checking
5111         :param migration: the migration object that tracks data about this
5112                           migration
5113         :param limits: objects.Limits instance that the scheduler
5114                                returned when this host was chosen
5115         :returns: a dict containing migration info
5116         """
5117         scheduled_node = None
5118         try:
5119             compute_node = self._get_compute_info(ctxt, self.host)
5120             scheduled_node = compute_node.hypervisor_hostname
5121         except exception.ComputeHostNotFound:
5122             LOG.exception(_LE('Failed to get compute_info for %s'),
5123                           self.host)
5124 
5125         if scheduled_node is not None:
5126             rt = self._get_resource_tracker(scheduled_node)
5127             live_mig_claim = rt.live_migration_claim
5128         else:
5129             live_mig_claim = claims.NopClaim
5130         try:
5131             with live_mig_claim(ctxt, instance, migration, limits=limits):
5132                 return self._do_check_can_live_migrate_destination(
5133                     ctxt, instance, block_migration, disk_over_commit)
5134         except exception.ComputeResourcesUnavailable as e:
5135             LOG.debug("Could not claim resources for live migrating the "
5136                       "instance to this host. Not enough resources available.",
5137                       instance=instance)
5138             raise exception.MigrationPreCheckError(reason=e.format_message())
5139 
5140     def _do_check_can_live_migrate_destination(self, ctxt, instance,
5141                                                block_migration,
5142                                                disk_over_commit):
5143         src_compute_info = obj_base.obj_to_primitive(
5144             self._get_compute_info(ctxt, instance.host))
5145         dst_compute_info = obj_base.obj_to_primitive(
5146             self._get_compute_info(ctxt, CONF.host))
5147         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5148             instance, src_compute_info, dst_compute_info,
5149             block_migration, disk_over_commit)
5150         LOG.debug('destination check data is %s', dest_check_data)
5151         try:
5152             migrate_data = self.compute_rpcapi.\
5153                                 check_can_live_migrate_source(ctxt, instance,
5154                                                               dest_check_data)
5155         finally:
5156             self.driver.cleanup_live_migration_destination_check(ctxt,
5157                     dest_check_data)
5158         return migrate_data
5159 
5160     @wrap_exception()
5161     @wrap_instance_event(prefix='compute')
5162     @wrap_instance_fault
5163     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5164         """Check if it is possible to execute live migration.
5165 
5166         This checks if the live migration can succeed, based on the
5167         results from check_can_live_migrate_destination.
5168 
5169         :param ctxt: security context
5170         :param instance: dict of instance data
5171         :param dest_check_data: result of check_can_live_migrate_destination
5172         :returns: a dict containing migration info
5173         """
5174         is_volume_backed = compute_utils.is_volume_backed_instance(ctxt,
5175                                                                       instance)
5176         # TODO(tdurakov): remove dict to object conversion once RPC API version
5177         # is bumped to 5.x
5178         got_migrate_data_object = isinstance(dest_check_data,
5179                                              migrate_data_obj.LiveMigrateData)
5180         if not got_migrate_data_object:
5181             dest_check_data = \
5182                 migrate_data_obj.LiveMigrateData.detect_implementation(
5183                     dest_check_data)
5184         dest_check_data.is_volume_backed = is_volume_backed
5185         block_device_info = self._get_instance_block_device_info(
5186                             ctxt, instance, refresh_conn_info=False)
5187         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5188                                                            dest_check_data,
5189                                                            block_device_info)
5190         if not got_migrate_data_object:
5191             result = result.to_legacy_dict()
5192         LOG.debug('source check data is %s', result)
5193         return result
5194 
5195     @wrap_exception()
5196     @wrap_instance_event(prefix='compute')
5197     @wrap_instance_fault
5198     def pre_live_migration(self, context, instance, block_migration, disk,
5199                            migrate_data):
5200         """Preparations for live migration at dest host.
5201 
5202         :param context: security context
5203         :param instance: dict of instance data
5204         :param block_migration: if true, prepare for block migration
5205         :param migrate_data: A dict or LiveMigrateData object holding data
5206                              required for live migration without shared
5207                              storage.
5208 
5209         """
5210         LOG.debug('pre_live_migration data is %s', migrate_data)
5211         # TODO(tdurakov): remove dict to object conversion once RPC API version
5212         # is bumped to 5.x
5213         got_migrate_data_object = isinstance(migrate_data,
5214                                              migrate_data_obj.LiveMigrateData)
5215         if not got_migrate_data_object:
5216             migrate_data = \
5217                 migrate_data_obj.LiveMigrateData.detect_implementation(
5218                     migrate_data)
5219         block_device_info = self._get_instance_block_device_info(
5220                             context, instance, refresh_conn_info=True)
5221 
5222         network_info = self.network_api.get_instance_nw_info(context, instance)
5223         self._notify_about_instance_usage(
5224                      context, instance, "live_migration.pre.start",
5225                      network_info=network_info)
5226 
5227         migrate_data = self.driver.pre_live_migration(context,
5228                                        instance,
5229                                        block_device_info,
5230                                        network_info,
5231                                        disk,
5232                                        migrate_data)
5233         LOG.debug('driver pre_live_migration data is %s', migrate_data)
5234 
5235         # NOTE(tr3buchet): setup networks on destination host
5236         self.network_api.setup_networks_on_host(context, instance,
5237                                                          self.host)
5238 
5239         # Creating filters to hypervisors and firewalls.
5240         # An example is that nova-instance-instance-xxx,
5241         # which is written to libvirt.xml(Check "virsh nwfilter-list")
5242         # This nwfilter is necessary on the destination host.
5243         # In addition, this method is creating filtering rule
5244         # onto destination host.
5245         self.driver.ensure_filtering_rules_for_instance(instance,
5246                                             network_info)
5247 
5248         self._notify_about_instance_usage(
5249                      context, instance, "live_migration.pre.end",
5250                      network_info=network_info)
5251         # TODO(tdurakov): remove dict to object conversion once RPC API version
5252         # is bumped to 5.x
5253         if not got_migrate_data_object and migrate_data:
5254             migrate_data = migrate_data.to_legacy_dict(
5255                 pre_migration_result=True)
5256             migrate_data = migrate_data['pre_live_migration_result']
5257         LOG.debug('pre_live_migration result data is %s', migrate_data)
5258         return migrate_data
5259 
5260     def _do_live_migration(self, context, dest, instance, block_migration,
5261                            migration, migrate_data):
5262         # NOTE(danms): We should enhance the RT to account for migrations
5263         # and use the status field to denote when the accounting has been
5264         # done on source/destination. For now, this is just here for status
5265         # reporting
5266         self._set_migration_status(migration, 'preparing')
5267 
5268         got_migrate_data_object = isinstance(migrate_data,
5269                                              migrate_data_obj.LiveMigrateData)
5270         if not got_migrate_data_object:
5271             migrate_data = \
5272                 migrate_data_obj.LiveMigrateData.detect_implementation(
5273                     migrate_data)
5274 
5275         try:
5276             if ('block_migration' in migrate_data and
5277                     migrate_data.block_migration):
5278                 block_device_info = self._get_instance_block_device_info(
5279                     context, instance)
5280                 disk = self.driver.get_instance_disk_info(
5281                     instance, block_device_info=block_device_info)
5282             else:
5283                 disk = None
5284 
5285             migrate_data = self.compute_rpcapi.pre_live_migration(
5286                 context, instance,
5287                 block_migration, disk, dest, migrate_data)
5288         except Exception:
5289             with excutils.save_and_reraise_exception():
5290                 LOG.exception(_LE('Pre live migration failed at %s'),
5291                               dest, instance=instance)
5292                 self._set_migration_status(migration, 'error')
5293                 self._rollback_live_migration(context, instance, dest,
5294                                               block_migration, migrate_data)
5295 
5296         self._set_migration_status(migration, 'running')
5297 
5298         if migrate_data:
5299             migrate_data.migration = migration
5300         LOG.debug('live_migration data is %s', migrate_data)
5301         try:
5302             with instance.mutated_migration_context():
5303                 self.driver.live_migration(context, instance, dest,
5304                                            self._post_live_migration,
5305                                            self._rollback_live_migration,
5306                                            block_migration, migrate_data)
5307         except Exception:
5308             # Executing live migration
5309             # live_migration might raises exceptions, but
5310             # nothing must be recovered in this version.
5311             LOG.exception(_LE('Live migration failed.'), instance=instance)
5312             with excutils.save_and_reraise_exception():
5313                 self._set_migration_status(migration, 'error')
5314 
5315     @wrap_exception()
5316     @wrap_instance_event(prefix='compute')
5317     @wrap_instance_fault
5318     def live_migration(self, context, dest, instance, block_migration,
5319                        migration, migrate_data):
5320         """Executing live migration.
5321 
5322         :param context: security context
5323         :param dest: destination host
5324         :param instance: a nova.objects.instance.Instance object
5325         :param block_migration: if true, prepare for block migration
5326         :param migration: an nova.objects.Migration object
5327         :param migrate_data: implementation specific params
5328 
5329         """
5330         self._set_migration_status(migration, 'queued')
5331 
5332         def dispatch_live_migration(*args, **kwargs):
5333             with self._live_migration_semaphore:
5334                 self._do_live_migration(*args, **kwargs)
5335 
5336         # NOTE(danms): We spawn here to return the RPC worker thread back to
5337         # the pool. Since what follows could take a really long time, we don't
5338         # want to tie up RPC workers.
5339         utils.spawn_n(dispatch_live_migration,
5340                       context, dest, instance,
5341                       block_migration, migration,
5342                       migrate_data)
5343 
5344     # TODO(tdurakov): migration_id is used since 4.12 rpc api version
5345     # remove migration_id parameter when the compute RPC version
5346     # is bumped to 5.x.
5347     @wrap_exception()
5348     @wrap_instance_event(prefix='compute')
5349     @wrap_instance_fault
5350     def live_migration_force_complete(self, context, instance,
5351                                       migration_id=None):
5352         """Force live migration to complete.
5353 
5354         :param context: Security context
5355         :param instance: The instance that is being migrated
5356         :param migration_id: ID of ongoing migration; is currently not used,
5357         and isn't removed for backward compatibility
5358         """
5359 
5360         self._notify_about_instance_usage(
5361             context, instance, 'live.migration.force.complete.start')
5362         self.driver.live_migration_force_complete(instance)
5363         self._notify_about_instance_usage(
5364             context, instance, 'live.migration.force.complete.end')
5365 
5366     @wrap_exception()
5367     @wrap_instance_event(prefix='compute')
5368     @wrap_instance_fault
5369     def live_migration_abort(self, context, instance, migration_id):
5370         """Abort an in-progress live migration.
5371 
5372         :param context: Security context
5373         :param instance: The instance that is being migrated
5374         :param migration_id: ID of in-progress live migration
5375 
5376         """
5377         migration = objects.Migration.get_by_id(context, migration_id)
5378         if migration.status != 'running':
5379             raise exception.InvalidMigrationState(migration_id=migration_id,
5380                     instance_uuid=instance.uuid,
5381                     state=migration.status,
5382                     method='abort live migration')
5383 
5384         self._notify_about_instance_usage(
5385             context, instance, 'live.migration.abort.start')
5386         self.driver.live_migration_abort(instance)
5387         self._notify_about_instance_usage(
5388             context, instance, 'live.migration.abort.end')
5389 
5390     def _live_migration_cleanup_flags(self, migrate_data):
5391         """Determine whether disks or instance path need to be cleaned up after
5392         live migration (at source on success, at destination on rollback)
5393 
5394         Block migration needs empty image at destination host before migration
5395         starts, so if any failure occurs, any empty images has to be deleted.
5396 
5397         Also Volume backed live migration w/o shared storage needs to delete
5398         newly created instance-xxx dir on the destination as a part of its
5399         rollback process
5400 
5401         :param migrate_data: implementation specific data
5402         :returns: (bool, bool) -- do_cleanup, destroy_disks
5403         """
5404         # NOTE(pkoniszewski): block migration specific params are set inside
5405         # migrate_data objects for drivers that expose block live migration
5406         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
5407         # cleanup is not needed.
5408         is_shared_block_storage = True
5409         is_shared_instance_path = True
5410         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
5411             is_shared_block_storage = migrate_data.is_shared_block_storage
5412             is_shared_instance_path = migrate_data.is_shared_instance_path
5413         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
5414             is_shared_block_storage = not migrate_data.block_migration
5415             is_shared_instance_path = not migrate_data.block_migration
5416         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
5417             is_shared_instance_path = migrate_data.is_shared_instance_path
5418             is_shared_block_storage = migrate_data.is_shared_instance_path
5419 
5420         # No instance booting at source host, but instance dir
5421         # must be deleted for preparing next block migration
5422         # must be deleted for preparing next live migration w/o shared storage
5423         do_cleanup = not is_shared_instance_path
5424         destroy_disks = not is_shared_block_storage
5425 
5426         return (do_cleanup, destroy_disks)
5427 
5428     @wrap_exception()
5429     @wrap_instance_fault
5430     def _post_live_migration(self, ctxt, instance,
5431                             dest, block_migration=False, migrate_data=None):
5432         """Post operations for live migration.
5433 
5434         This method is called from live_migration
5435         and mainly updating database record.
5436 
5437         :param ctxt: security context
5438         :param instance: instance dict
5439         :param dest: destination host
5440         :param block_migration: if true, prepare for block migration
5441         :param migrate_data: if not None, it is a dict which has data
5442         required for live migration without shared storage
5443 
5444         """
5445         LOG.info(_LI('_post_live_migration() is started..'),
5446                  instance=instance)
5447 
5448         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5449                 ctxt, instance.uuid)
5450 
5451         # Cleanup source host post live-migration
5452         block_device_info = self._get_instance_block_device_info(
5453                             ctxt, instance, bdms=bdms)
5454         self.driver.post_live_migration(ctxt, instance, block_device_info,
5455                                         migrate_data)
5456 
5457         # Detaching volumes.
5458         connector = self.driver.get_volume_connector(instance)
5459         for bdm in bdms:
5460             # NOTE(vish): We don't want to actually mark the volume
5461             #             detached, or delete the bdm, just remove the
5462             #             connection from this host.
5463 
5464             # remove the volume connection without detaching from hypervisor
5465             # because the instance is not running anymore on the current host
5466             if bdm.is_volume:
5467                 self.volume_api.terminate_connection(ctxt, bdm.volume_id,
5468                                                      connector)
5469 
5470         # Releasing vlan.
5471         # (not necessary in current implementation?)
5472 
5473         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
5474 
5475         self._notify_about_instance_usage(ctxt, instance,
5476                                           "live_migration._post.start",
5477                                           network_info=network_info)
5478         # Releasing security group ingress rule.
5479         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
5480                   instance=instance)
5481         self.driver.unfilter_instance(instance,
5482                                       network_info)
5483 
5484         migration = {'source_compute': self.host,
5485                      'dest_compute': dest, }
5486         self.network_api.migrate_instance_start(ctxt,
5487                                                 instance,
5488                                                 migration)
5489 
5490         destroy_vifs = False
5491         try:
5492             self.driver.post_live_migration_at_source(ctxt, instance,
5493                                                       network_info)
5494         except NotImplementedError as ex:
5495             LOG.debug(ex, instance=instance)
5496             # For all hypervisors other than libvirt, there is a possibility
5497             # they are unplugging networks from source node in the cleanup
5498             # method
5499             destroy_vifs = True
5500 
5501         # Define domain at destination host, without doing it,
5502         # pause/suspend/terminate do not work.
5503         self.compute_rpcapi.post_live_migration_at_destination(ctxt,
5504                 instance, block_migration, dest)
5505 
5506         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5507                 migrate_data)
5508 
5509         if do_cleanup:
5510             LOG.debug('Calling driver.cleanup from _post_live_migration',
5511                       instance=instance)
5512             self.driver.cleanup(ctxt, instance, network_info,
5513                                 destroy_disks=destroy_disks,
5514                                 migrate_data=migrate_data,
5515                                 destroy_vifs=destroy_vifs)
5516 
5517         self.instance_events.clear_events_for_instance(instance)
5518 
5519         # NOTE(timello): make sure we update available resources on source
5520         # host even before next periodic task.
5521         self.update_available_resource(ctxt)
5522 
5523         self._update_scheduler_instance_info(ctxt, instance)
5524         self._notify_about_instance_usage(ctxt, instance,
5525                                           "live_migration._post.end",
5526                                           network_info=network_info)
5527         LOG.info(_LI('Migrating instance to %s finished successfully.'),
5528                  dest, instance=instance)
5529         LOG.info(_LI("You may see the error \"libvirt: QEMU error: "
5530                      "Domain not found: no domain with matching name.\" "
5531                      "This error can be safely ignored."),
5532                  instance=instance)
5533 
5534         self._clean_instance_console_tokens(ctxt, instance)
5535         if migrate_data and migrate_data.obj_attr_is_set('migration'):
5536             migrate_data.migration.status = 'completed'
5537             migrate_data.migration.save()
5538 
5539     def _consoles_enabled(self):
5540         """Returns whether a console is enable."""
5541         return (CONF.vnc.enabled or CONF.spice.enabled or
5542                 CONF.rdp.enabled or CONF.serial_console.enabled or
5543                 CONF.mks.enabled)
5544 
5545     def _clean_instance_console_tokens(self, ctxt, instance):
5546         """Clean console tokens stored for an instance."""
5547         if self._consoles_enabled():
5548             if CONF.cells.enable:
5549                 self.cells_rpcapi.consoleauth_delete_tokens(
5550                     ctxt, instance.uuid)
5551             else:
5552                 self.consoleauth_rpcapi.delete_tokens_for_instance(
5553                     ctxt, instance.uuid)
5554 
5555     @wrap_exception()
5556     @wrap_instance_event(prefix='compute')
5557     @wrap_instance_fault
5558     def post_live_migration_at_destination(self, context, instance,
5559                                            block_migration):
5560         """Post operations for live migration .
5561 
5562         :param context: security context
5563         :param instance: Instance dict
5564         :param block_migration: if true, prepare for block migration
5565 
5566         """
5567         LOG.info(_LI('Post operation of migration started'),
5568                  instance=instance)
5569 
5570         # NOTE(tr3buchet): setup networks on destination host
5571         #                  this is called a second time because
5572         #                  multi_host does not create the bridge in
5573         #                  plug_vifs
5574         self.network_api.setup_networks_on_host(context, instance,
5575                                                          self.host)
5576         # TODO(ndipanov): We should be passing the migration over RPC here
5577         # instead
5578         try:
5579             migration = objects.Migration.get_by_instance_and_status(
5580                 context, instance.uuid, 'running')
5581         except exception.MigrationNotFoundByStatus:
5582             LOG.warning(_LW("No migration record found for this instance "
5583                             "during post_live_migrate routine"),
5584                         instance=instance)
5585             migration = None
5586         self.network_api.migrate_instance_finish(
5587             context, instance,
5588             {'source_compute': instance.host, 'dest_compute': self.host, })
5589 
5590         network_info = self.network_api.get_instance_nw_info(context, instance)
5591         self._notify_about_instance_usage(
5592                      context, instance, "live_migration.post.dest.start",
5593                      network_info=network_info)
5594         block_device_info = self._get_instance_block_device_info(context,
5595                                                                  instance)
5596 
5597         try:
5598             with instance.mutated_migration_context():
5599                 self.driver.post_live_migration_at_destination(
5600                     context, instance, network_info, block_migration,
5601                     block_device_info)
5602         except Exception:
5603             with excutils.save_and_reraise_exception():
5604                 instance.vm_state = vm_states.ERROR
5605                 self._set_migration_status(migration, 'failed')
5606                 LOG.error(_LE('Unexpected error during post live migration at '
5607                               'destination host.'), instance=instance)
5608         finally:
5609             # Restore instance state and update host
5610             current_power_state = self._get_power_state(context, instance)
5611             node_name = None
5612             prev_host = instance.host
5613             try:
5614                 compute_node = self._get_compute_info(context, self.host)
5615                 node_name = compute_node.hypervisor_hostname
5616             except exception.ComputeHostNotFound:
5617                 LOG.exception(_LE('Failed to get compute_info for %s'),
5618                               self.host)
5619             finally:
5620                 instance.apply_migration_context()
5621                 instance.host = self.host
5622                 instance.power_state = current_power_state
5623                 instance.task_state = None
5624                 instance.node = node_name
5625                 instance.progress = 0
5626                 instance.save(expected_task_state=task_states.MIGRATING)
5627                 instance.drop_migration_context()
5628                 self._set_migration_status(migration, 'finished',
5629                                            unless_status=['failed',
5630                                                           'completed'])
5631 
5632         # NOTE(tr3buchet): tear down networks on source host
5633         self.network_api.setup_networks_on_host(context, instance,
5634                                                 prev_host, teardown=True)
5635         # NOTE(vish): this is necessary to update dhcp
5636         self.network_api.setup_networks_on_host(context, instance, self.host)
5637         self._notify_about_instance_usage(
5638                      context, instance, "live_migration.post.dest.end",
5639                      network_info=network_info)
5640 
5641     @wrap_exception()
5642     @wrap_instance_fault
5643     def _rollback_live_migration(self, context, instance,
5644                                  dest, block_migration, migrate_data=None,
5645                                  migration_status='error'):
5646         """Recovers Instance/volume state from migrating -> running.
5647 
5648         :param context: security context
5649         :param instance: nova.objects.instance.Instance object
5650         :param dest:
5651             This method is called from live migration src host.
5652             This param specifies destination host.
5653         :param block_migration: if true, prepare for block migration
5654         :param migrate_data:
5655             if not none, contains implementation specific data.
5656         :param migration_status:
5657             Contains the status we want to set for the migration object
5658 
5659         """
5660         instance.task_state = None
5661         instance.progress = 0
5662         instance.save(expected_task_state=[task_states.MIGRATING])
5663 
5664         # TODO(tdurakov): remove dict to object conversion once RPC API version
5665         # is bumped to 5.x
5666         if isinstance(migrate_data, dict):
5667             migration = migrate_data.pop('migration', None)
5668             migrate_data = \
5669                 migrate_data_obj.LiveMigrateData.detect_implementation(
5670                     migrate_data)
5671         elif (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
5672               migrate_data.obj_attr_is_set('migration')):
5673             migration = migrate_data.migration
5674         else:
5675             migration = None
5676 
5677         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
5678         self.network_api.setup_networks_on_host(context, instance, self.host)
5679 
5680         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5681                 context, instance.uuid)
5682         for bdm in bdms:
5683             if bdm.is_volume:
5684                 self.compute_rpcapi.remove_volume_connection(
5685                         context, instance, bdm.volume_id, dest)
5686 
5687         self._notify_about_instance_usage(context, instance,
5688                                           "live_migration._rollback.start")
5689 
5690         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5691                 migrate_data)
5692 
5693         if do_cleanup:
5694             self.compute_rpcapi.rollback_live_migration_at_destination(
5695                     context, instance, dest, destroy_disks=destroy_disks,
5696                     migrate_data=migrate_data)
5697 
5698         self._notify_about_instance_usage(context, instance,
5699                                           "live_migration._rollback.end")
5700 
5701         self._set_migration_status(migration, migration_status)
5702 
5703     @wrap_exception()
5704     @wrap_instance_event(prefix='compute')
5705     @wrap_instance_fault
5706     def rollback_live_migration_at_destination(self, context, instance,
5707                                                destroy_disks,
5708                                                migrate_data):
5709         """Cleaning up image directory that is created pre_live_migration.
5710 
5711         :param context: security context
5712         :param instance: a nova.objects.instance.Instance object sent over rpc
5713         """
5714         network_info = self.network_api.get_instance_nw_info(context, instance)
5715         self._notify_about_instance_usage(
5716                       context, instance, "live_migration.rollback.dest.start",
5717                       network_info=network_info)
5718         try:
5719             # NOTE(tr3buchet): tear down networks on destination host
5720             self.network_api.setup_networks_on_host(context, instance,
5721                                                     self.host, teardown=True)
5722         except Exception:
5723             with excutils.save_and_reraise_exception():
5724                 # NOTE(tdurakov): even if teardown networks fails driver
5725                 # should try to rollback live migration on destination.
5726                 LOG.exception(
5727                     _LE('An error occurred while deallocating network.'),
5728                     instance=instance)
5729         finally:
5730             # always run this even if setup_networks_on_host fails
5731             # NOTE(vish): The mapping is passed in so the driver can disconnect
5732             #             from remote volumes if necessary
5733             block_device_info = self._get_instance_block_device_info(context,
5734                                                                      instance)
5735             # TODO(tdurakov): remove dict to object conversion once RPC API
5736             # version is bumped to 5.x
5737             if isinstance(migrate_data, dict):
5738                 migrate_data = \
5739                     migrate_data_obj.LiveMigrateData.detect_implementation(
5740                         migrate_data)
5741             with instance.mutated_migration_context():
5742                 self.driver.rollback_live_migration_at_destination(
5743                     context, instance, network_info, block_device_info,
5744                     destroy_disks=destroy_disks, migrate_data=migrate_data)
5745             # TODO(ndipanov): We should drop the claim here too, as we are
5746             # currently "leaking" resources, but only until the next run of the
5747             # update_available_resource periodic task, since we error the
5748             # migration. For that, we need to be passing migration objects over
5749             # RPC
5750             instance.drop_migration_context()
5751 
5752         self._notify_about_instance_usage(
5753                         context, instance, "live_migration.rollback.dest.end",
5754                         network_info=network_info)
5755 
5756     @periodic_task.periodic_task(
5757         spacing=CONF.heal_instance_info_cache_interval)
5758     def _heal_instance_info_cache(self, context):
5759         """Called periodically.  On every call, try to update the
5760         info_cache's network information for another instance by
5761         calling to the network manager.
5762 
5763         This is implemented by keeping a cache of uuids of instances
5764         that live on this host.  On each call, we pop one off of a
5765         list, pull the DB record, and try the call to the network API.
5766         If anything errors don't fail, as it's possible the instance
5767         has been deleted, etc.
5768         """
5769         heal_interval = CONF.heal_instance_info_cache_interval
5770         if not heal_interval:
5771             return
5772 
5773         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
5774         instance = None
5775 
5776         LOG.debug('Starting heal instance info cache')
5777 
5778         if not instance_uuids:
5779             # The list of instances to heal is empty so rebuild it
5780             LOG.debug('Rebuilding the list of instances to heal')
5781             db_instances = objects.InstanceList.get_by_host(
5782                 context, self.host, expected_attrs=[], use_slave=True)
5783             for inst in db_instances:
5784                 # We don't want to refresh the cache for instances
5785                 # which are building or deleting so don't put them
5786                 # in the list. If they are building they will get
5787                 # added to the list next time we build it.
5788                 if (inst.vm_state == vm_states.BUILDING):
5789                     LOG.debug('Skipping network cache update for instance '
5790                               'because it is Building.', instance=inst)
5791                     continue
5792                 if (inst.task_state == task_states.DELETING):
5793                     LOG.debug('Skipping network cache update for instance '
5794                               'because it is being deleted.', instance=inst)
5795                     continue
5796 
5797                 if not instance:
5798                     # Save the first one we find so we don't
5799                     # have to get it again
5800                     instance = inst
5801                 else:
5802                     instance_uuids.append(inst['uuid'])
5803 
5804             self._instance_uuids_to_heal = instance_uuids
5805         else:
5806             # Find the next valid instance on the list
5807             while instance_uuids:
5808                 try:
5809                     inst = objects.Instance.get_by_uuid(
5810                             context, instance_uuids.pop(0),
5811                             expected_attrs=['system_metadata', 'info_cache',
5812                                             'flavor'],
5813                             use_slave=True)
5814                 except exception.InstanceNotFound:
5815                     # Instance is gone.  Try to grab another.
5816                     continue
5817 
5818                 # Check the instance hasn't been migrated
5819                 if inst.host != self.host:
5820                     LOG.debug('Skipping network cache update for instance '
5821                               'because it has been migrated to another '
5822                               'host.', instance=inst)
5823                 # Check the instance isn't being deleting
5824                 elif inst.task_state == task_states.DELETING:
5825                     LOG.debug('Skipping network cache update for instance '
5826                               'because it is being deleted.', instance=inst)
5827                 else:
5828                     instance = inst
5829                     break
5830 
5831         if instance:
5832             # We have an instance now to refresh
5833             try:
5834                 # Call to network API to get instance info.. this will
5835                 # force an update to the instance's info_cache
5836                 self.network_api.get_instance_nw_info(context, instance)
5837                 LOG.debug('Updated the network info_cache for instance',
5838                           instance=instance)
5839             except exception.InstanceNotFound:
5840                 # Instance is gone.
5841                 LOG.debug('Instance no longer exists. Unable to refresh',
5842                           instance=instance)
5843                 return
5844             except exception.InstanceInfoCacheNotFound:
5845                 # InstanceInfoCache is gone.
5846                 LOG.debug('InstanceInfoCache no longer exists. '
5847                           'Unable to refresh', instance=instance)
5848             except Exception:
5849                 LOG.error(_LE('An error occurred while refreshing the network '
5850                               'cache.'), instance=instance, exc_info=True)
5851         else:
5852             LOG.debug("Didn't find any instances for network info cache "
5853                       "update.")
5854 
5855     @periodic_task.periodic_task
5856     def _poll_rebooting_instances(self, context):
5857         if CONF.reboot_timeout > 0:
5858             filters = {'task_state':
5859                        [task_states.REBOOTING,
5860                         task_states.REBOOT_STARTED,
5861                         task_states.REBOOT_PENDING],
5862                        'host': self.host}
5863             rebooting = objects.InstanceList.get_by_filters(
5864                 context, filters, expected_attrs=[], use_slave=True)
5865 
5866             to_poll = []
5867             for instance in rebooting:
5868                 if timeutils.is_older_than(instance.updated_at,
5869                                            CONF.reboot_timeout):
5870                     to_poll.append(instance)
5871 
5872             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
5873 
5874     @periodic_task.periodic_task
5875     def _poll_rescued_instances(self, context):
5876         if CONF.rescue_timeout > 0:
5877             filters = {'vm_state': vm_states.RESCUED,
5878                        'host': self.host}
5879             rescued_instances = objects.InstanceList.get_by_filters(
5880                 context, filters, expected_attrs=["system_metadata"],
5881                 use_slave=True)
5882 
5883             to_unrescue = []
5884             for instance in rescued_instances:
5885                 if timeutils.is_older_than(instance.launched_at,
5886                                            CONF.rescue_timeout):
5887                     to_unrescue.append(instance)
5888 
5889             for instance in to_unrescue:
5890                 self.compute_api.unrescue(context, instance)
5891 
5892     @periodic_task.periodic_task
5893     def _poll_unconfirmed_resizes(self, context):
5894         if CONF.resize_confirm_window == 0:
5895             return
5896 
5897         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
5898                 context, CONF.resize_confirm_window, self.host,
5899                 use_slave=True)
5900 
5901         migrations_info = dict(migration_count=len(migrations),
5902                 confirm_window=CONF.resize_confirm_window)
5903 
5904         if migrations_info["migration_count"] > 0:
5905             LOG.info(_LI("Found %(migration_count)d unconfirmed migrations "
5906                          "older than %(confirm_window)d seconds"),
5907                      migrations_info)
5908 
5909         def _set_migration_to_error(migration, reason, **kwargs):
5910             LOG.warning(_LW("Setting migration %(migration_id)s to error: "
5911                          "%(reason)s"),
5912                      {'migration_id': migration['id'], 'reason': reason},
5913                      **kwargs)
5914             migration.status = 'error'
5915             with migration.obj_as_admin():
5916                 migration.save()
5917 
5918         for migration in migrations:
5919             instance_uuid = migration.instance_uuid
5920             LOG.info(_LI("Automatically confirming migration "
5921                          "%(migration_id)s for instance %(instance_uuid)s"),
5922                      {'migration_id': migration.id,
5923                       'instance_uuid': instance_uuid})
5924             expected_attrs = ['metadata', 'system_metadata']
5925             try:
5926                 instance = objects.Instance.get_by_uuid(context,
5927                             instance_uuid, expected_attrs=expected_attrs,
5928                             use_slave=True)
5929             except exception.InstanceNotFound:
5930                 reason = (_("Instance %s not found") %
5931                           instance_uuid)
5932                 _set_migration_to_error(migration, reason)
5933                 continue
5934             if instance.vm_state == vm_states.ERROR:
5935                 reason = _("In ERROR state")
5936                 _set_migration_to_error(migration, reason,
5937                                         instance=instance)
5938                 continue
5939             # race condition: The instance in DELETING state should not be
5940             # set the migration state to error, otherwise the instance in
5941             # to be deleted which is in RESIZED state
5942             # will not be able to confirm resize
5943             if instance.task_state in [task_states.DELETING,
5944                                        task_states.SOFT_DELETING]:
5945                 msg = ("Instance being deleted or soft deleted during resize "
5946                        "confirmation. Skipping.")
5947                 LOG.debug(msg, instance=instance)
5948                 continue
5949 
5950             # race condition: This condition is hit when this method is
5951             # called between the save of the migration record with a status of
5952             # finished and the save of the instance object with a state of
5953             # RESIZED. The migration record should not be set to error.
5954             if instance.task_state == task_states.RESIZE_FINISH:
5955                 msg = ("Instance still resizing during resize "
5956                        "confirmation. Skipping.")
5957                 LOG.debug(msg, instance=instance)
5958                 continue
5959 
5960             vm_state = instance.vm_state
5961             task_state = instance.task_state
5962             if vm_state != vm_states.RESIZED or task_state is not None:
5963                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
5964                            "RESIZED/None") %
5965                           {'vm_state': vm_state,
5966                            'task_state': task_state})
5967                 _set_migration_to_error(migration, reason,
5968                                         instance=instance)
5969                 continue
5970             try:
5971                 self.compute_api.confirm_resize(context, instance,
5972                                                 migration=migration)
5973             except Exception as e:
5974                 LOG.info(_LI("Error auto-confirming resize: %s. "
5975                              "Will retry later."),
5976                          e, instance=instance)
5977 
5978     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
5979     def _poll_shelved_instances(self, context):
5980 
5981         if CONF.shelved_offload_time <= 0:
5982             return
5983 
5984         filters = {'vm_state': vm_states.SHELVED,
5985                    'task_state': None,
5986                    'host': self.host}
5987         shelved_instances = objects.InstanceList.get_by_filters(
5988             context, filters=filters, expected_attrs=['system_metadata'],
5989             use_slave=True)
5990 
5991         to_gc = []
5992         for instance in shelved_instances:
5993             sys_meta = instance.system_metadata
5994             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
5995             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
5996                 to_gc.append(instance)
5997 
5998         for instance in to_gc:
5999             try:
6000                 instance.task_state = task_states.SHELVING_OFFLOADING
6001                 instance.save(expected_task_state=(None,))
6002                 self.shelve_offload_instance(context, instance,
6003                                              clean_shutdown=False)
6004             except Exception:
6005                 LOG.exception(_LE('Periodic task failed to offload instance.'),
6006                         instance=instance)
6007 
6008     @periodic_task.periodic_task
6009     def _instance_usage_audit(self, context):
6010         if not CONF.instance_usage_audit:
6011             return
6012 
6013         begin, end = utils.last_completed_audit_period()
6014         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
6015                                self.host):
6016             return
6017 
6018         instances = objects.InstanceList.get_active_by_window_joined(
6019             context, begin, end, host=self.host,
6020             expected_attrs=['system_metadata', 'info_cache', 'metadata',
6021                             'flavor'],
6022             use_slave=True)
6023         num_instances = len(instances)
6024         errors = 0
6025         successes = 0
6026         LOG.info(_LI("Running instance usage audit for"
6027                      " host %(host)s from %(begin_time)s to "
6028                      "%(end_time)s. %(number_instances)s"
6029                      " instances."),
6030                  {'host': self.host,
6031                   'begin_time': begin,
6032                   'end_time': end,
6033                   'number_instances': num_instances})
6034         start_time = time.time()
6035         task_log = objects.TaskLog(context)
6036         task_log.task_name = 'instance_usage_audit'
6037         task_log.period_beginning = begin
6038         task_log.period_ending = end
6039         task_log.host = self.host
6040         task_log.task_items = num_instances
6041         task_log.message = 'Instance usage audit started...'
6042         task_log.begin_task()
6043         for instance in instances:
6044             try:
6045                 compute_utils.notify_usage_exists(
6046                     self.notifier, context, instance,
6047                     ignore_missing_network_data=False)
6048                 successes += 1
6049             except Exception:
6050                 LOG.exception(_LE('Failed to generate usage '
6051                                   'audit for instance '
6052                                   'on host %s'), self.host,
6053                               instance=instance)
6054                 errors += 1
6055         task_log.errors = errors
6056         task_log.message = (
6057             'Instance usage audit ran for host %s, %s instances in %s seconds.'
6058             % (self.host, num_instances, time.time() - start_time))
6059         task_log.end_task()
6060 
6061     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
6062     def _poll_bandwidth_usage(self, context):
6063 
6064         if not self._bw_usage_supported:
6065             return
6066 
6067         prev_time, start_time = utils.last_completed_audit_period()
6068 
6069         curr_time = time.time()
6070         if (curr_time - self._last_bw_usage_poll >
6071                 CONF.bandwidth_poll_interval):
6072             self._last_bw_usage_poll = curr_time
6073             LOG.info(_LI("Updating bandwidth usage cache"))
6074             cells_update_interval = CONF.cells.bandwidth_update_interval
6075             if (cells_update_interval > 0 and
6076                    curr_time - self._last_bw_usage_cell_update >
6077                            cells_update_interval):
6078                 self._last_bw_usage_cell_update = curr_time
6079                 update_cells = True
6080             else:
6081                 update_cells = False
6082 
6083             instances = objects.InstanceList.get_by_host(context,
6084                                                               self.host,
6085                                                               use_slave=True)
6086             try:
6087                 bw_counters = self.driver.get_all_bw_counters(instances)
6088             except NotImplementedError:
6089                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
6090                 # implemented yet.  If they don't it doesn't break anything,
6091                 # they just don't get the info in the usage events.
6092                 # NOTE(PhilDay): Record that its not supported so we can
6093                 # skip fast on future calls rather than waste effort getting
6094                 # the list of instances.
6095                 LOG.info(_LI("Bandwidth usage not supported by "
6096                              "hypervisor."))
6097                 self._bw_usage_supported = False
6098                 return
6099 
6100             refreshed = timeutils.utcnow()
6101             for bw_ctr in bw_counters:
6102                 # Allow switching of greenthreads between queries.
6103                 greenthread.sleep(0)
6104                 bw_in = 0
6105                 bw_out = 0
6106                 last_ctr_in = None
6107                 last_ctr_out = None
6108                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6109                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6110                     start_period=start_time, use_slave=True)
6111                 if usage:
6112                     bw_in = usage.bw_in
6113                     bw_out = usage.bw_out
6114                     last_ctr_in = usage.last_ctr_in
6115                     last_ctr_out = usage.last_ctr_out
6116                 else:
6117                     usage = (objects.BandwidthUsage.
6118                              get_by_instance_uuid_and_mac(
6119                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6120                         start_period=prev_time, use_slave=True))
6121                     if usage:
6122                         last_ctr_in = usage.last_ctr_in
6123                         last_ctr_out = usage.last_ctr_out
6124 
6125                 if last_ctr_in is not None:
6126                     if bw_ctr['bw_in'] < last_ctr_in:
6127                         # counter rollover
6128                         bw_in += bw_ctr['bw_in']
6129                     else:
6130                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6131 
6132                 if last_ctr_out is not None:
6133                     if bw_ctr['bw_out'] < last_ctr_out:
6134                         # counter rollover
6135                         bw_out += bw_ctr['bw_out']
6136                     else:
6137                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6138 
6139                 objects.BandwidthUsage(context=context).create(
6140                                               bw_ctr['uuid'],
6141                                               bw_ctr['mac_address'],
6142                                               bw_in,
6143                                               bw_out,
6144                                               bw_ctr['bw_in'],
6145                                               bw_ctr['bw_out'],
6146                                               start_period=start_time,
6147                                               last_refreshed=refreshed,
6148                                               update_cells=update_cells)
6149 
6150     def _get_host_volume_bdms(self, context, use_slave=False):
6151         """Return all block device mappings on a compute host."""
6152         compute_host_bdms = []
6153         instances = objects.InstanceList.get_by_host(context, self.host,
6154             use_slave=use_slave)
6155         for instance in instances:
6156             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6157                     context, instance.uuid, use_slave=use_slave)
6158             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6159             compute_host_bdms.append(dict(instance=instance,
6160                                           instance_bdms=instance_bdms))
6161 
6162         return compute_host_bdms
6163 
6164     def _update_volume_usage_cache(self, context, vol_usages):
6165         """Updates the volume usage cache table with a list of stats."""
6166         for usage in vol_usages:
6167             # Allow switching of greenthreads between queries.
6168             greenthread.sleep(0)
6169             vol_usage = objects.VolumeUsage(context)
6170             vol_usage.volume_id = usage['volume']
6171             vol_usage.instance_uuid = usage['instance'].uuid
6172             vol_usage.project_id = usage['instance'].project_id
6173             vol_usage.user_id = usage['instance'].user_id
6174             vol_usage.availability_zone = usage['instance'].availability_zone
6175             vol_usage.curr_reads = usage['rd_req']
6176             vol_usage.curr_read_bytes = usage['rd_bytes']
6177             vol_usage.curr_writes = usage['wr_req']
6178             vol_usage.curr_write_bytes = usage['wr_bytes']
6179             vol_usage.save()
6180             self.notifier.info(context, 'volume.usage',
6181                                compute_utils.usage_volume_info(vol_usage))
6182 
6183     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
6184     def _poll_volume_usage(self, context):
6185         if CONF.volume_usage_poll_interval == 0:
6186             return
6187 
6188         compute_host_bdms = self._get_host_volume_bdms(context,
6189                                                        use_slave=True)
6190         if not compute_host_bdms:
6191             return
6192 
6193         LOG.debug("Updating volume usage cache")
6194         try:
6195             vol_usages = self.driver.get_all_volume_usage(context,
6196                                                           compute_host_bdms)
6197         except NotImplementedError:
6198             return
6199 
6200         self._update_volume_usage_cache(context, vol_usages)
6201 
6202     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
6203                                  run_immediately=True)
6204     def _sync_power_states(self, context):
6205         """Align power states between the database and the hypervisor.
6206 
6207         To sync power state data we make a DB call to get the number of
6208         virtual machines known by the hypervisor and if the number matches the
6209         number of virtual machines known by the database, we proceed in a lazy
6210         loop, one database record at a time, checking if the hypervisor has the
6211         same power state as is in the database.
6212         """
6213         db_instances = objects.InstanceList.get_by_host(context, self.host,
6214                                                         expected_attrs=[],
6215                                                         use_slave=True)
6216 
6217         num_vm_instances = self.driver.get_num_instances()
6218         num_db_instances = len(db_instances)
6219 
6220         if num_vm_instances != num_db_instances:
6221             LOG.warning(_LW("While synchronizing instance power states, found "
6222                             "%(num_db_instances)s instances in the database "
6223                             "and %(num_vm_instances)s instances on the "
6224                             "hypervisor."),
6225                         {'num_db_instances': num_db_instances,
6226                          'num_vm_instances': num_vm_instances})
6227 
6228         def _sync(db_instance):
6229             # NOTE(melwitt): This must be synchronized as we query state from
6230             #                two separate sources, the driver and the database.
6231             #                They are set (in stop_instance) and read, in sync.
6232             @utils.synchronized(db_instance.uuid)
6233             def query_driver_power_state_and_sync():
6234                 self._query_driver_power_state_and_sync(context, db_instance)
6235 
6236             try:
6237                 query_driver_power_state_and_sync()
6238             except Exception:
6239                 LOG.exception(_LE("Periodic sync_power_state task had an "
6240                                   "error while processing an instance."),
6241                               instance=db_instance)
6242 
6243             self._syncs_in_progress.pop(db_instance.uuid)
6244 
6245         for db_instance in db_instances:
6246             # process syncs asynchronously - don't want instance locking to
6247             # block entire periodic task thread
6248             uuid = db_instance.uuid
6249             if uuid in self._syncs_in_progress:
6250                 LOG.debug('Sync already in progress for %s', uuid)
6251             else:
6252                 LOG.debug('Triggering sync for uuid %s', uuid)
6253                 self._syncs_in_progress[uuid] = True
6254                 self._sync_power_pool.spawn_n(_sync, db_instance)
6255 
6256     def _query_driver_power_state_and_sync(self, context, db_instance):
6257         if db_instance.task_state is not None:
6258             LOG.info(_LI("During sync_power_state the instance has a "
6259                          "pending task (%(task)s). Skip."),
6260                      {'task': db_instance.task_state}, instance=db_instance)
6261             return
6262         # No pending tasks. Now try to figure out the real vm_power_state.
6263         try:
6264             vm_instance = self.driver.get_info(db_instance)
6265             vm_power_state = vm_instance.state
6266         except exception.InstanceNotFound:
6267             vm_power_state = power_state.NOSTATE
6268         # Note(maoy): the above get_info call might take a long time,
6269         # for example, because of a broken libvirt driver.
6270         try:
6271             self._sync_instance_power_state(context,
6272                                             db_instance,
6273                                             vm_power_state,
6274                                             use_slave=True)
6275         except exception.InstanceNotFound:
6276             # NOTE(hanlind): If the instance gets deleted during sync,
6277             # silently ignore.
6278             pass
6279 
6280     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
6281                                    use_slave=False):
6282         """Align instance power state between the database and hypervisor.
6283 
6284         If the instance is not found on the hypervisor, but is in the database,
6285         then a stop() API will be called on the instance.
6286         """
6287 
6288         # We re-query the DB to get the latest instance info to minimize
6289         # (not eliminate) race condition.
6290         db_instance.refresh(use_slave=use_slave)
6291         db_power_state = db_instance.power_state
6292         vm_state = db_instance.vm_state
6293 
6294         if self.host != db_instance.host:
6295             # on the sending end of nova-compute _sync_power_state
6296             # may have yielded to the greenthread performing a live
6297             # migration; this in turn has changed the resident-host
6298             # for the VM; However, the instance is still active, it
6299             # is just in the process of migrating to another host.
6300             # This implies that the compute source must relinquish
6301             # control to the compute destination.
6302             LOG.info(_LI("During the sync_power process the "
6303                          "instance has moved from "
6304                          "host %(src)s to host %(dst)s"),
6305                      {'src': db_instance.host,
6306                       'dst': self.host},
6307                      instance=db_instance)
6308             return
6309         elif db_instance.task_state is not None:
6310             # on the receiving end of nova-compute, it could happen
6311             # that the DB instance already report the new resident
6312             # but the actual VM has not showed up on the hypervisor
6313             # yet. In this case, let's allow the loop to continue
6314             # and run the state sync in a later round
6315             LOG.info(_LI("During sync_power_state the instance has a "
6316                          "pending task (%(task)s). Skip."),
6317                      {'task': db_instance.task_state},
6318                      instance=db_instance)
6319             return
6320 
6321         orig_db_power_state = db_power_state
6322         if vm_power_state != db_power_state:
6323             LOG.info(_LI('During _sync_instance_power_state the DB '
6324                          'power_state (%(db_power_state)s) does not match '
6325                          'the vm_power_state from the hypervisor '
6326                          '(%(vm_power_state)s). Updating power_state in the '
6327                          'DB to match the hypervisor.'),
6328                      {'db_power_state': db_power_state,
6329                       'vm_power_state': vm_power_state},
6330                      instance=db_instance)
6331             # power_state is always updated from hypervisor to db
6332             db_instance.power_state = vm_power_state
6333             db_instance.save()
6334             db_power_state = vm_power_state
6335 
6336         # Note(maoy): Now resolve the discrepancy between vm_state and
6337         # vm_power_state. We go through all possible vm_states.
6338         if vm_state in (vm_states.BUILDING,
6339                         vm_states.RESCUED,
6340                         vm_states.RESIZED,
6341                         vm_states.SUSPENDED,
6342                         vm_states.ERROR):
6343             # TODO(maoy): we ignore these vm_state for now.
6344             pass
6345         elif vm_state == vm_states.ACTIVE:
6346             # The only rational power state should be RUNNING
6347             if vm_power_state in (power_state.SHUTDOWN,
6348                                   power_state.CRASHED):
6349                 LOG.warning(_LW("Instance shutdown by itself. Calling the "
6350                                 "stop API. Current vm_state: %(vm_state)s, "
6351                                 "current task_state: %(task_state)s, "
6352                                 "original DB power_state: %(db_power_state)s, "
6353                                 "current VM power_state: %(vm_power_state)s"),
6354                             {'vm_state': vm_state,
6355                              'task_state': db_instance.task_state,
6356                              'db_power_state': orig_db_power_state,
6357                              'vm_power_state': vm_power_state},
6358                             instance=db_instance)
6359                 try:
6360                     # Note(maoy): here we call the API instead of
6361                     # brutally updating the vm_state in the database
6362                     # to allow all the hooks and checks to be performed.
6363                     if db_instance.shutdown_terminate:
6364                         self.compute_api.delete(context, db_instance)
6365                     else:
6366                         self.compute_api.stop(context, db_instance)
6367                 except Exception:
6368                     # Note(maoy): there is no need to propagate the error
6369                     # because the same power_state will be retrieved next
6370                     # time and retried.
6371                     # For example, there might be another task scheduled.
6372                     LOG.exception(_LE("error during stop() in "
6373                                       "sync_power_state."),
6374                                   instance=db_instance)
6375             elif vm_power_state == power_state.SUSPENDED:
6376                 LOG.warning(_LW("Instance is suspended unexpectedly. Calling "
6377                                 "the stop API."), instance=db_instance)
6378                 try:
6379                     self.compute_api.stop(context, db_instance)
6380                 except Exception:
6381                     LOG.exception(_LE("error during stop() in "
6382                                       "sync_power_state."),
6383                                   instance=db_instance)
6384             elif vm_power_state == power_state.PAUSED:
6385                 # Note(maoy): a VM may get into the paused state not only
6386                 # because the user request via API calls, but also
6387                 # due to (temporary) external instrumentations.
6388                 # Before the virt layer can reliably report the reason,
6389                 # we simply ignore the state discrepancy. In many cases,
6390                 # the VM state will go back to running after the external
6391                 # instrumentation is done. See bug 1097806 for details.
6392                 LOG.warning(_LW("Instance is paused unexpectedly. Ignore."),
6393                             instance=db_instance)
6394             elif vm_power_state == power_state.NOSTATE:
6395                 # Occasionally, depending on the status of the hypervisor,
6396                 # which could be restarting for example, an instance may
6397                 # not be found.  Therefore just log the condition.
6398                 LOG.warning(_LW("Instance is unexpectedly not found. Ignore."),
6399                             instance=db_instance)
6400         elif vm_state == vm_states.STOPPED:
6401             if vm_power_state not in (power_state.NOSTATE,
6402                                       power_state.SHUTDOWN,
6403                                       power_state.CRASHED):
6404                 LOG.warning(_LW("Instance is not stopped. Calling "
6405                                 "the stop API. Current vm_state: %(vm_state)s,"
6406                                 " current task_state: %(task_state)s, "
6407                                 "original DB power_state: %(db_power_state)s, "
6408                                 "current VM power_state: %(vm_power_state)s"),
6409                             {'vm_state': vm_state,
6410                              'task_state': db_instance.task_state,
6411                              'db_power_state': orig_db_power_state,
6412                              'vm_power_state': vm_power_state},
6413                             instance=db_instance)
6414                 try:
6415                     # NOTE(russellb) Force the stop, because normally the
6416                     # compute API would not allow an attempt to stop a stopped
6417                     # instance.
6418                     self.compute_api.force_stop(context, db_instance)
6419                 except Exception:
6420                     LOG.exception(_LE("error during stop() in "
6421                                       "sync_power_state."),
6422                                   instance=db_instance)
6423         elif vm_state == vm_states.PAUSED:
6424             if vm_power_state in (power_state.SHUTDOWN,
6425                                   power_state.CRASHED):
6426                 LOG.warning(_LW("Paused instance shutdown by itself. Calling "
6427                                 "the stop API."), instance=db_instance)
6428                 try:
6429                     self.compute_api.force_stop(context, db_instance)
6430                 except Exception:
6431                     LOG.exception(_LE("error during stop() in "
6432                                       "sync_power_state."),
6433                                   instance=db_instance)
6434         elif vm_state in (vm_states.SOFT_DELETED,
6435                           vm_states.DELETED):
6436             if vm_power_state not in (power_state.NOSTATE,
6437                                       power_state.SHUTDOWN):
6438                 # Note(maoy): this should be taken care of periodically in
6439                 # _cleanup_running_deleted_instances().
6440                 LOG.warning(_LW("Instance is not (soft-)deleted."),
6441                             instance=db_instance)
6442 
6443     @periodic_task.periodic_task
6444     def _reclaim_queued_deletes(self, context):
6445         """Reclaim instances that are queued for deletion."""
6446         interval = CONF.reclaim_instance_interval
6447         if interval <= 0:
6448             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
6449             return
6450 
6451         # TODO(comstud, jichenjc): Dummy quota object for now See bug 1296414.
6452         # The only case that the quota might be inconsistent is
6453         # the compute node died between set instance state to SOFT_DELETED
6454         # and quota commit to DB. When compute node starts again
6455         # it will have no idea the reservation is committed or not or even
6456         # expired, since it's a rare case, so marked as todo.
6457         quotas = objects.Quotas.from_reservations(context, None)
6458 
6459         filters = {'vm_state': vm_states.SOFT_DELETED,
6460                    'task_state': None,
6461                    'host': self.host}
6462         instances = objects.InstanceList.get_by_filters(
6463             context, filters,
6464             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
6465             use_slave=True)
6466         for instance in instances:
6467             if self._deleted_old_enough(instance, interval):
6468                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6469                         context, instance.uuid)
6470                 LOG.info(_LI('Reclaiming deleted instance'), instance=instance)
6471                 try:
6472                     self._delete_instance(context, instance, bdms, quotas)
6473                 except Exception as e:
6474                     LOG.warning(_LW("Periodic reclaim failed to delete "
6475                                     "instance: %s"),
6476                                 e, instance=instance)
6477 
6478     def update_available_resource_for_node(self, context, nodename):
6479 
6480         rt = self._get_resource_tracker(nodename)
6481         try:
6482             rt.update_available_resource(context)
6483         except exception.ComputeHostNotFound:
6484             # NOTE(comstud): We can get to this case if a node was
6485             # marked 'deleted' in the DB and then re-added with a
6486             # different auto-increment id. The cached resource
6487             # tracker tried to update a deleted record and failed.
6488             # Don't add this resource tracker to the new dict, so
6489             # that this will resolve itself on the next run.
6490             LOG.info(_LI("Compute node '%s' not found in "
6491                          "update_available_resource."), nodename)
6492             self._resource_tracker_dict.pop(nodename, None)
6493             return
6494         except Exception:
6495             LOG.exception(_LE("Error updating resources for node "
6496                           "%(node)s."), {'node': nodename})
6497 
6498         # NOTE(comstud): Replace the RT cache before looping through
6499         # compute nodes to delete below, as we can end up doing greenthread
6500         # switches there. Best to have everyone using the newest cache
6501         # ASAP.
6502         self._resource_tracker_dict[nodename] = rt
6503 
6504     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
6505     def update_available_resource(self, context):
6506         """See driver.get_available_resource()
6507 
6508         Periodic process that keeps that the compute host's understanding of
6509         resource availability and usage in sync with the underlying hypervisor.
6510 
6511         :param context: security context
6512         """
6513 
6514         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
6515                                                             use_slave=True)
6516         nodenames = set(self.driver.get_available_nodes())
6517         for nodename in nodenames:
6518             self.update_available_resource_for_node(context, nodename)
6519 
6520         self._resource_tracker_dict = {
6521             k: v for k, v in self._resource_tracker_dict.items()
6522             if k in nodenames}
6523 
6524         # Delete orphan compute node not reported by driver but still in db
6525         for cn in compute_nodes_in_db:
6526             if cn.hypervisor_hostname not in nodenames:
6527                 LOG.info(_LI("Deleting orphan compute node %s"), cn.id)
6528                 cn.destroy()
6529 
6530     def _get_compute_nodes_in_db(self, context, use_slave=False):
6531         try:
6532             return objects.ComputeNodeList.get_all_by_host(context, self.host,
6533                                                            use_slave=use_slave)
6534         except exception.NotFound:
6535             LOG.error(_LE("No compute node record for host %s"), self.host)
6536             return []
6537 
6538     @periodic_task.periodic_task(
6539         spacing=CONF.running_deleted_instance_poll_interval)
6540     def _cleanup_running_deleted_instances(self, context):
6541         """Cleanup any instances which are erroneously still running after
6542         having been deleted.
6543 
6544         Valid actions to take are:
6545 
6546             1. noop - do nothing
6547             2. log - log which instances are erroneously running
6548             3. reap - shutdown and cleanup any erroneously running instances
6549             4. shutdown - power off *and disable* any erroneously running
6550                           instances
6551 
6552         The use-case for this cleanup task is: for various reasons, it may be
6553         possible for the database to show an instance as deleted but for that
6554         instance to still be running on a host machine (see bug
6555         https://bugs.launchpad.net/nova/+bug/911366).
6556 
6557         This cleanup task is a cross-hypervisor utility for finding these
6558         zombied instances and either logging the discrepancy (likely what you
6559         should do in production), or automatically reaping the instances (more
6560         appropriate for dev environments).
6561         """
6562         action = CONF.running_deleted_instance_action
6563 
6564         if action == "noop":
6565             return
6566 
6567         # NOTE(sirp): admin contexts don't ordinarily return deleted records
6568         with utils.temporary_mutation(context, read_deleted="yes"):
6569             for instance in self._running_deleted_instances(context):
6570                 if action == "log":
6571                     LOG.warning(_LW("Detected instance with name label "
6572                                     "'%s' which is marked as "
6573                                     "DELETED but still present on host."),
6574                                 instance.name, instance=instance)
6575 
6576                 elif action == 'shutdown':
6577                     LOG.info(_LI("Powering off instance with name label "
6578                                  "'%s' which is marked as "
6579                                  "DELETED but still present on host."),
6580                              instance.name, instance=instance)
6581                     try:
6582                         try:
6583                             # disable starting the instance
6584                             self.driver.set_bootable(instance, False)
6585                         except NotImplementedError:
6586                             LOG.debug("set_bootable is not implemented "
6587                                       "for the current driver")
6588                         # and power it off
6589                         self.driver.power_off(instance)
6590                     except Exception:
6591                         msg = _LW("Failed to power off instance")
6592                         LOG.warning(msg, instance=instance, exc_info=True)
6593 
6594                 elif action == 'reap':
6595                     LOG.info(_LI("Destroying instance with name label "
6596                                  "'%s' which is marked as "
6597                                  "DELETED but still present on host."),
6598                              instance.name, instance=instance)
6599                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6600                         context, instance.uuid, use_slave=True)
6601                     self.instance_events.clear_events_for_instance(instance)
6602                     try:
6603                         self._shutdown_instance(context, instance, bdms,
6604                                                 notify=False)
6605                         self._cleanup_volumes(context, instance.uuid, bdms)
6606                     except Exception as e:
6607                         LOG.warning(_LW("Periodic cleanup failed to delete "
6608                                         "instance: %s"),
6609                                     e, instance=instance)
6610                 else:
6611                     raise Exception(_("Unrecognized value '%s'"
6612                                       " for CONF.running_deleted_"
6613                                       "instance_action") % action)
6614 
6615     def _running_deleted_instances(self, context):
6616         """Returns a list of instances nova thinks is deleted,
6617         but the hypervisor thinks is still running.
6618         """
6619         timeout = CONF.running_deleted_instance_timeout
6620         filters = {'deleted': True,
6621                    'soft_deleted': False,
6622                    'host': self.host}
6623         instances = self._get_instances_on_driver(context, filters)
6624         return [i for i in instances if self._deleted_old_enough(i, timeout)]
6625 
6626     def _deleted_old_enough(self, instance, timeout):
6627         deleted_at = instance.deleted_at
6628         if deleted_at:
6629             deleted_at = deleted_at.replace(tzinfo=None)
6630         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
6631 
6632     @contextlib.contextmanager
6633     def _error_out_instance_on_exception(self, context, instance,
6634                                          quotas=None,
6635                                          instance_state=vm_states.ACTIVE):
6636         instance_uuid = instance.uuid
6637         try:
6638             yield
6639         except NotImplementedError as error:
6640             with excutils.save_and_reraise_exception():
6641                 if quotas:
6642                     quotas.rollback()
6643                 LOG.info(_LI("Setting instance back to %(state)s after: "
6644                              "%(error)s"),
6645                          {'state': instance_state, 'error': error},
6646                          instance_uuid=instance_uuid)
6647                 self._instance_update(context, instance,
6648                                       vm_state=instance_state,
6649                                       task_state=None)
6650         except exception.InstanceFaultRollback as error:
6651             if quotas:
6652                 quotas.rollback()
6653             LOG.info(_LI("Setting instance back to ACTIVE after: %s"),
6654                      error, instance_uuid=instance_uuid)
6655             self._instance_update(context, instance,
6656                                   vm_state=vm_states.ACTIVE,
6657                                   task_state=None)
6658             raise error.inner_exception
6659         except Exception:
6660             LOG.exception(_LE('Setting instance vm_state to ERROR'),
6661                           instance_uuid=instance_uuid)
6662             with excutils.save_and_reraise_exception():
6663                 if quotas:
6664                     quotas.rollback()
6665                 self._set_instance_obj_error_state(context, instance)
6666 
6667     @wrap_exception()
6668     def add_aggregate_host(self, context, aggregate, host, slave_info):
6669         """Notify hypervisor of change (for hypervisor pools)."""
6670         try:
6671             self.driver.add_to_aggregate(context, aggregate, host,
6672                                          slave_info=slave_info)
6673         except NotImplementedError:
6674             LOG.debug('Hypervisor driver does not support '
6675                       'add_aggregate_host')
6676         except exception.AggregateError:
6677             with excutils.save_and_reraise_exception():
6678                 self.driver.undo_aggregate_operation(
6679                                     context,
6680                                     aggregate.delete_host,
6681                                     aggregate, host)
6682 
6683     @wrap_exception()
6684     def remove_aggregate_host(self, context, host, slave_info, aggregate):
6685         """Removes a host from a physical hypervisor pool."""
6686         try:
6687             self.driver.remove_from_aggregate(context, aggregate, host,
6688                                               slave_info=slave_info)
6689         except NotImplementedError:
6690             LOG.debug('Hypervisor driver does not support '
6691                       'remove_aggregate_host')
6692         except (exception.AggregateError,
6693                 exception.InvalidAggregateAction) as e:
6694             with excutils.save_and_reraise_exception():
6695                 self.driver.undo_aggregate_operation(
6696                                     context,
6697                                     aggregate.add_host,
6698                                     aggregate, host,
6699                                     isinstance(e, exception.AggregateError))
6700 
6701     def _process_instance_event(self, instance, event):
6702         _event = self.instance_events.pop_instance_event(instance, event)
6703         if _event:
6704             LOG.debug('Processing event %(event)s',
6705                       {'event': event.key}, instance=instance)
6706             _event.send(event)
6707         else:
6708             LOG.warning(_LW('Received unexpected event %(event)s for '
6709                             'instance'),
6710                         {'event': event.key}, instance=instance)
6711 
6712     def _process_instance_vif_deleted_event(self, context, instance,
6713                                             deleted_vif_id):
6714         # If an attached port is deleted by neutron, it needs to
6715         # be detached from the instance.
6716         # And info cache needs to be updated.
6717         network_info = instance.info_cache.network_info
6718         for index, vif in enumerate(network_info):
6719             if vif['id'] == deleted_vif_id:
6720                 LOG.info(_LI('Neutron deleted interface %(intf)s; '
6721                              'detaching it from the instance and '
6722                              'deleting it from the info cache'),
6723                          {'intf': vif['id']},
6724                          instance=instance)
6725                 del network_info[index]
6726                 base_net_api.update_instance_cache_with_nw_info(
6727                                  self.network_api, context,
6728                                  instance,
6729                                  nw_info=network_info)
6730                 try:
6731                     self.driver.detach_interface(instance, vif)
6732                 except exception.NovaException as ex:
6733                     LOG.warning(_LW("Detach interface failed, "
6734                                     "port_id=%(port_id)s, reason: %(msg)s"),
6735                                 {'port_id': deleted_vif_id, 'msg': ex},
6736                                 instance=instance)
6737                 break
6738 
6739     @wrap_exception()
6740     def external_instance_event(self, context, instances, events):
6741         # NOTE(danms): Some event types are handled by the manager, such
6742         # as when we're asked to update the instance's info_cache. If it's
6743         # not one of those, look for some thread(s) waiting for the event and
6744         # unblock them if so.
6745         for event in events:
6746             instance = [inst for inst in instances
6747                         if inst.uuid == event.instance_uuid][0]
6748             LOG.debug('Received event %(event)s',
6749                       {'event': event.key},
6750                       instance=instance)
6751             if event.name == 'network-changed':
6752                 try:
6753                     self.network_api.get_instance_nw_info(context, instance)
6754                 except exception.NotFound as e:
6755                     LOG.info(_LI('Failed to process external instance event '
6756                                  '%(event)s due to: %(error)s'),
6757                              {'event': event.key, 'error': six.text_type(e)},
6758                              instance=instance)
6759             elif event.name == 'network-vif-deleted':
6760                 self._process_instance_vif_deleted_event(context,
6761                                                          instance,
6762                                                          event.tag)
6763             else:
6764                 self._process_instance_event(instance, event)
6765 
6766     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
6767                                  external_process_ok=True)
6768     def _run_image_cache_manager_pass(self, context):
6769         """Run a single pass of the image cache manager."""
6770 
6771         if not self.driver.capabilities["has_imagecache"]:
6772             return
6773 
6774         # Determine what other nodes use this storage
6775         storage_users.register_storage_use(CONF.instances_path, CONF.host)
6776         nodes = storage_users.get_storage_users(CONF.instances_path)
6777 
6778         # Filter all_instances to only include those nodes which share this
6779         # storage path.
6780         # TODO(mikal): this should be further refactored so that the cache
6781         # cleanup code doesn't know what those instances are, just a remote
6782         # count, and then this logic should be pushed up the stack.
6783         filters = {'deleted': False,
6784                    'soft_deleted': True,
6785                    'host': nodes}
6786         filtered_instances = objects.InstanceList.get_by_filters(context,
6787                                  filters, expected_attrs=[], use_slave=True)
6788 
6789         self.driver.manage_image_cache(context, filtered_instances)
6790 
6791     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6792     def _run_pending_deletes(self, context):
6793         """Retry any pending instance file deletes."""
6794         LOG.debug('Cleaning up deleted instances')
6795         filters = {'deleted': True,
6796                    'soft_deleted': False,
6797                    'host': CONF.host,
6798                    'cleaned': False}
6799         attrs = ['info_cache', 'security_groups', 'system_metadata']
6800         with utils.temporary_mutation(context, read_deleted='yes'):
6801             instances = objects.InstanceList.get_by_filters(
6802                 context, filters, expected_attrs=attrs, use_slave=True)
6803         LOG.debug('There are %d instances to clean', len(instances))
6804 
6805         for instance in instances:
6806             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
6807             LOG.debug('Instance has had %(attempts)s of %(max)s '
6808                       'cleanup attempts',
6809                       {'attempts': attempts,
6810                        'max': CONF.maximum_instance_delete_attempts},
6811                       instance=instance)
6812             if attempts < CONF.maximum_instance_delete_attempts:
6813                 success = self.driver.delete_instance_files(instance)
6814 
6815                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
6816                 if success:
6817                     instance.cleaned = True
6818                 with utils.temporary_mutation(context, read_deleted='yes'):
6819                     instance.save()
6820 
6821     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6822     def _cleanup_incomplete_migrations(self, context):
6823         """Delete instance files on failed resize/revert-resize operation
6824 
6825         During resize/revert-resize operation, if that instance gets deleted
6826         in-between then instance files might remain either on source or
6827         destination compute node because of race condition.
6828         """
6829         LOG.debug('Cleaning up deleted instances with incomplete migration ')
6830         migration_filters = {'host': CONF.host,
6831                              'status': 'error'}
6832         migrations = objects.MigrationList.get_by_filters(context,
6833                                                           migration_filters)
6834 
6835         if not migrations:
6836             return
6837 
6838         inst_uuid_from_migrations = set([migration.instance_uuid for migration
6839                                          in migrations])
6840 
6841         inst_filters = {'deleted': True, 'soft_deleted': False,
6842                         'uuid': inst_uuid_from_migrations}
6843         attrs = ['info_cache', 'security_groups', 'system_metadata']
6844         with utils.temporary_mutation(context, read_deleted='yes'):
6845             instances = objects.InstanceList.get_by_filters(
6846                 context, inst_filters, expected_attrs=attrs, use_slave=True)
6847 
6848         for instance in instances:
6849             if instance.host != CONF.host:
6850                 for migration in migrations:
6851                     if instance.uuid == migration.instance_uuid:
6852                         # Delete instance files if not cleanup properly either
6853                         # from the source or destination compute nodes when
6854                         # the instance is deleted during resizing.
6855                         self.driver.delete_instance_files(instance)
6856                         try:
6857                             migration.status = 'failed'
6858                             with migration.obj_as_admin():
6859                                 migration.save()
6860                         except exception.MigrationNotFound:
6861                             LOG.warning(_LW("Migration %s is not found."),
6862                                         migration.id,
6863                                         instance=instance)
6864                         break
6865 
6866     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
6867                                    exception.QemuGuestAgentNotEnabled,
6868                                    exception.NovaException,
6869                                    NotImplementedError)
6870     @wrap_exception()
6871     def quiesce_instance(self, context, instance):
6872         """Quiesce an instance on this host."""
6873         context = context.elevated()
6874         image_meta = objects.ImageMeta.from_instance(instance)
6875         self.driver.quiesce(context, instance, image_meta)
6876 
6877     def _wait_for_snapshots_completion(self, context, mapping):
6878         for mapping_dict in mapping:
6879             if mapping_dict.get('source_type') == 'snapshot':
6880 
6881                 def _wait_snapshot():
6882                     snapshot = self.volume_api.get_snapshot(
6883                         context, mapping_dict['snapshot_id'])
6884                     if snapshot.get('status') != 'creating':
6885                         raise loopingcall.LoopingCallDone()
6886 
6887                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
6888                 timer.start(interval=0.5).wait()
6889 
6890     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
6891                                    exception.QemuGuestAgentNotEnabled,
6892                                    exception.NovaException,
6893                                    NotImplementedError)
6894     @wrap_exception()
6895     def unquiesce_instance(self, context, instance, mapping=None):
6896         """Unquiesce an instance on this host.
6897 
6898         If snapshots' image mapping is provided, it waits until snapshots are
6899         completed before unqueiscing.
6900         """
6901         context = context.elevated()
6902         if mapping:
6903             try:
6904                 self._wait_for_snapshots_completion(context, mapping)
6905             except Exception as error:
6906                 LOG.exception(_LE("Exception while waiting completion of "
6907                                   "volume snapshots: %s"),
6908                               error, instance=instance)
6909         image_meta = objects.ImageMeta.from_instance(instance)
6910         self.driver.unquiesce(context, instance, image_meta)
