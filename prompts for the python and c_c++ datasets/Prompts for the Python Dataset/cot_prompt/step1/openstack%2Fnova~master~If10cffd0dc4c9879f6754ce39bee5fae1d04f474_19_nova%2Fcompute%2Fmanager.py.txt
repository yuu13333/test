Based on the given code from a commit, please generate supplementary code files according to the commit message.
####commit message
Add ability to signal and perform online volume size change

Allow Cinder to use external events to signal a volume extension.

1) Nova will then call os-brick to perform the volume extension
   so the host can detect its new size.
2) Compute driver will resize the device in QEMU so instance can detect
   the new disk size without rebooting.

This change:
* Adds the 'volume-extended' external event.
  The event tag needs to be the extended volume id.
* Bump microversion to 2.49

Blueprint: nova-support-attached-volume-extend

Change-Id: If10cffd0dc4c9879f6754ce39bee5fae1d04f474

####code 
1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 from cursive import exception as cursive_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 from keystoneauth1 import exceptions as keystone_exception
44 from oslo_log import log as logging
45 import oslo_messaging as messaging
46 from oslo_serialization import jsonutils
47 from oslo_service import loopingcall
48 from oslo_service import periodic_task
49 from oslo_utils import excutils
50 from oslo_utils import strutils
51 from oslo_utils import timeutils
52 from oslo_utils import uuidutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 import nova.context
71 from nova import exception
72 from nova import exception_wrapper
73 from nova import hooks
74 from nova.i18n import _
75 from nova import image
76 from nova.image import glance
77 from nova import manager
78 from nova import network
79 from nova.network import base_api as base_net_api
80 from nova.network import model as network_model
81 from nova.network.security_group import openstack_driver
82 from nova import objects
83 from nova.objects import base as obj_base
84 from nova.objects import fields
85 from nova.objects import instance as obj_instance
86 from nova.objects import migrate_data as migrate_data_obj
87 from nova.pci import whitelist
88 from nova import rpc
89 from nova import safe_utils
90 from nova.scheduler import client as scheduler_client
91 from nova import utils
92 from nova.virt import block_device as driver_block_device
93 from nova.virt import configdrive
94 from nova.virt import driver
95 from nova.virt import event as virtevent
96 from nova.virt import storage_users
97 from nova.virt import virtapi
98 from nova.volume import cinder
99 
100 CONF = nova.conf.CONF
101 
102 LOG = logging.getLogger(__name__)
103 
104 get_notifier = functools.partial(rpc.get_notifier, service='compute')
105 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
106                                    get_notifier=get_notifier,
107                                    binary='nova-compute')
108 
109 
110 @utils.expects_func_args('migration')
111 def errors_out_migration(function):
112     """Decorator to error out migration on failure."""
113 
114     @functools.wraps(function)
115     def decorated_function(self, context, *args, **kwargs):
116         try:
117             return function(self, context, *args, **kwargs)
118         except Exception as ex:
119             with excutils.save_and_reraise_exception():
120                 wrapped_func = safe_utils.get_wrapped_function(function)
121                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
122                                                  *args, **kwargs)
123                 migration = keyed_args['migration']
124 
125                 # NOTE(rajesht): If InstanceNotFound error is thrown from
126                 # decorated function, migration status should be set to
127                 # 'error', without checking current migration status.
128                 if not isinstance(ex, exception.InstanceNotFound):
129                     status = migration.status
130                     if status not in ['migrating', 'post-migrating']:
131                         return
132 
133                 migration.status = 'error'
134                 try:
135                     with migration.obj_as_admin():
136                         migration.save()
137                 except Exception:
138                     LOG.debug('Error setting migration status '
139                               'for instance %s.',
140                               migration.instance_uuid, exc_info=True)
141 
142     return decorated_function
143 
144 
145 @utils.expects_func_args('instance')
146 def reverts_task_state(function):
147     """Decorator to revert task_state on failure."""
148 
149     @functools.wraps(function)
150     def decorated_function(self, context, *args, **kwargs):
151         try:
152             return function(self, context, *args, **kwargs)
153         except exception.UnexpectedTaskStateError as e:
154             # Note(maoy): unexpected task state means the current
155             # task is preempted. Do not clear task state in this
156             # case.
157             with excutils.save_and_reraise_exception():
158                 LOG.info("Task possibly preempted: %s",
159                          e.format_message())
160         except Exception:
161             with excutils.save_and_reraise_exception():
162                 wrapped_func = safe_utils.get_wrapped_function(function)
163                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
164                                                  *args, **kwargs)
165                 # NOTE(mriedem): 'instance' must be in keyed_args because we
166                 # have utils.expects_func_args('instance') decorating this
167                 # method.
168                 instance = keyed_args['instance']
169                 original_task_state = instance.task_state
170                 try:
171                     self._instance_update(context, instance, task_state=None)
172                     LOG.info("Successfully reverted task state from %s on "
173                              "failure for instance.",
174                              original_task_state, instance=instance)
175                 except exception.InstanceNotFound:
176                     # We might delete an instance that failed to build shortly
177                     # after it errored out this is an expected case and we
178                     # should not trace on it.
179                     pass
180                 except Exception as e:
181                     LOG.warning("Failed to revert task state for instance. "
182                                 "Error: %s", e, instance=instance)
183 
184     return decorated_function
185 
186 
187 @utils.expects_func_args('instance')
188 def wrap_instance_fault(function):
189     """Wraps a method to catch exceptions related to instances.
190 
191     This decorator wraps a method to catch any exceptions having to do with
192     an instance that may get thrown. It then logs an instance fault in the db.
193     """
194 
195     @functools.wraps(function)
196     def decorated_function(self, context, *args, **kwargs):
197         try:
198             return function(self, context, *args, **kwargs)
199         except exception.InstanceNotFound:
200             raise
201         except Exception as e:
202             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
203             # we will get a KeyError exception which will cover up the real
204             # exception. So, we update kwargs with the values from args first.
205             # then, we can get 'instance' from kwargs easily.
206             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
207 
208             with excutils.save_and_reraise_exception():
209                 compute_utils.add_instance_fault_from_exc(context,
210                         kwargs['instance'], e, sys.exc_info())
211 
212     return decorated_function
213 
214 
215 @utils.expects_func_args('image_id', 'instance')
216 def delete_image_on_error(function):
217     """Used for snapshot related method to ensure the image created in
218     compute.api is deleted when an error occurs.
219     """
220 
221     @functools.wraps(function)
222     def decorated_function(self, context, image_id, instance,
223                            *args, **kwargs):
224         try:
225             return function(self, context, image_id, instance,
226                             *args, **kwargs)
227         except Exception:
228             with excutils.save_and_reraise_exception():
229                 LOG.debug("Cleaning up image %s", image_id,
230                           exc_info=True, instance=instance)
231                 try:
232                     self.image_api.delete(context, image_id)
233                 except exception.ImageNotFound:
234                     # Since we're trying to cleanup an image, we don't care if
235                     # if it's already gone.
236                     pass
237                 except Exception:
238                     LOG.exception("Error while trying to clean up image %s",
239                                   image_id, instance=instance)
240 
241     return decorated_function
242 
243 
244 # TODO(danms): Remove me after Icehouse
245 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
246 # NOTE(mikal): if the method being decorated has more than one decorator, then
247 # put this one first. Otherwise the various exception handling decorators do
248 # not function correctly.
249 def object_compat(function):
250     """Wraps a method that expects a new-world instance
251 
252     This provides compatibility for callers passing old-style dict
253     instances.
254     """
255 
256     @functools.wraps(function)
257     def decorated_function(self, context, *args, **kwargs):
258         def _load_instance(instance_or_dict):
259             if isinstance(instance_or_dict, dict):
260                 # try to get metadata and system_metadata for most cases but
261                 # only attempt to load those if the db instance already has
262                 # those fields joined
263                 metas = [meta for meta in ('metadata', 'system_metadata')
264                          if meta in instance_or_dict]
265                 instance = objects.Instance._from_db_object(
266                     context, objects.Instance(), instance_or_dict,
267                     expected_attrs=metas)
268                 instance._context = context
269                 return instance
270             return instance_or_dict
271 
272         try:
273             kwargs['instance'] = _load_instance(kwargs['instance'])
274         except KeyError:
275             args = (_load_instance(args[0]),) + args[1:]
276 
277         migration = kwargs.get('migration')
278         if isinstance(migration, dict):
279             migration = objects.Migration._from_db_object(
280                     context.elevated(), objects.Migration(),
281                     migration)
282             kwargs['migration'] = migration
283 
284         return function(self, context, *args, **kwargs)
285 
286     return decorated_function
287 
288 
289 class InstanceEvents(object):
290     def __init__(self):
291         self._events = {}
292 
293     @staticmethod
294     def _lock_name(instance):
295         return '%s-%s' % (instance.uuid, 'events')
296 
297     def prepare_for_instance_event(self, instance, event_name):
298         """Prepare to receive an event for an instance.
299 
300         This will register an event for the given instance that we will
301         wait on later. This should be called before initiating whatever
302         action will trigger the event. The resulting eventlet.event.Event
303         object should be wait()'d on to ensure completion.
304 
305         :param instance: the instance for which the event will be generated
306         :param event_name: the name of the event we're expecting
307         :returns: an event object that should be wait()'d on
308         """
309         if self._events is None:
310             # NOTE(danms): We really should have a more specific error
311             # here, but this is what we use for our default error case
312             raise exception.NovaException('In shutdown, no new events '
313                                           'can be scheduled')
314 
315         @utils.synchronized(self._lock_name(instance))
316         def _create_or_get_event():
317             instance_events = self._events.setdefault(instance.uuid, {})
318             return instance_events.setdefault(event_name,
319                                               eventlet.event.Event())
320         LOG.debug('Preparing to wait for external event %(event)s',
321                   {'event': event_name}, instance=instance)
322         return _create_or_get_event()
323 
324     def pop_instance_event(self, instance, event):
325         """Remove a pending event from the wait list.
326 
327         This will remove a pending event from the wait list so that it
328         can be used to signal the waiters to wake up.
329 
330         :param instance: the instance for which the event was generated
331         :param event: the nova.objects.external_event.InstanceExternalEvent
332                       that describes the event
333         :returns: the eventlet.event.Event object on which the waiters
334                   are blocked
335         """
336         no_events_sentinel = object()
337         no_matching_event_sentinel = object()
338 
339         @utils.synchronized(self._lock_name(instance))
340         def _pop_event():
341             if not self._events:
342                 LOG.debug('Unexpected attempt to pop events during shutdown',
343                           instance=instance)
344                 return no_events_sentinel
345             events = self._events.get(instance.uuid)
346             if not events:
347                 return no_events_sentinel
348             _event = events.pop(event.key, None)
349             if not events:
350                 del self._events[instance.uuid]
351             if _event is None:
352                 return no_matching_event_sentinel
353             return _event
354 
355         result = _pop_event()
356         if result is no_events_sentinel:
357             LOG.debug('No waiting events found dispatching %(event)s',
358                       {'event': event.key},
359                       instance=instance)
360             return None
361         elif result is no_matching_event_sentinel:
362             LOG.debug('No event matching %(event)s in %(events)s',
363                       {'event': event.key,
364                        'events': self._events.get(instance.uuid, {}).keys()},
365                       instance=instance)
366             return None
367         else:
368             return result
369 
370     def clear_events_for_instance(self, instance):
371         """Remove all pending events for an instance.
372 
373         This will remove all events currently pending for an instance
374         and return them (indexed by event name).
375 
376         :param instance: the instance for which events should be purged
377         :returns: a dictionary of {event_name: eventlet.event.Event}
378         """
379         @utils.synchronized(self._lock_name(instance))
380         def _clear_events():
381             if self._events is None:
382                 LOG.debug('Unexpected attempt to clear events during shutdown',
383                           instance=instance)
384                 return dict()
385             return self._events.pop(instance.uuid, {})
386         return _clear_events()
387 
388     def cancel_all_events(self):
389         if self._events is None:
390             LOG.debug('Unexpected attempt to cancel events during shutdown.')
391             return
392         our_events = self._events
393         # NOTE(danms): Block new events
394         self._events = None
395 
396         for instance_uuid, events in our_events.items():
397             for event_name, eventlet_event in events.items():
398                 LOG.debug('Canceling in-flight event %(event)s for '
399                           'instance %(instance_uuid)s',
400                           {'event': event_name,
401                            'instance_uuid': instance_uuid})
402                 name, tag = event_name.rsplit('-', 1)
403                 event = objects.InstanceExternalEvent(
404                     instance_uuid=instance_uuid,
405                     name=name, status='failed',
406                     tag=tag, data={})
407                 eventlet_event.send(event)
408 
409 
410 class ComputeVirtAPI(virtapi.VirtAPI):
411     def __init__(self, compute):
412         super(ComputeVirtAPI, self).__init__()
413         self._compute = compute
414 
415     def _default_error_callback(self, event_name, instance):
416         raise exception.NovaException(_('Instance event failed'))
417 
418     @contextlib.contextmanager
419     def wait_for_instance_event(self, instance, event_names, deadline=300,
420                                 error_callback=None):
421         """Plan to wait for some events, run some code, then wait.
422 
423         This context manager will first create plans to wait for the
424         provided event_names, yield, and then wait for all the scheduled
425         events to complete.
426 
427         Note that this uses an eventlet.timeout.Timeout to bound the
428         operation, so callers should be prepared to catch that
429         failure and handle that situation appropriately.
430 
431         If the event is not received by the specified timeout deadline,
432         eventlet.timeout.Timeout is raised.
433 
434         If the event is received but did not have a 'completed'
435         status, a NovaException is raised.  If an error_callback is
436         provided, instead of raising an exception as detailed above
437         for the failure case, the callback will be called with the
438         event_name and instance, and can return True to continue
439         waiting for the rest of the events, False to stop processing,
440         or raise an exception which will bubble up to the waiter.
441 
442         :param instance: The instance for which an event is expected
443         :param event_names: A list of event names. Each element can be a
444                             string event name or tuple of strings to
445                             indicate (name, tag).
446         :param deadline: Maximum number of seconds we should wait for all
447                          of the specified events to arrive.
448         :param error_callback: A function to be called if an event arrives
449 
450         """
451 
452         if error_callback is None:
453             error_callback = self._default_error_callback
454         events = {}
455         for event_name in event_names:
456             if isinstance(event_name, tuple):
457                 name, tag = event_name
458                 event_name = objects.InstanceExternalEvent.make_key(
459                     name, tag)
460             try:
461                 events[event_name] = (
462                     self._compute.instance_events.prepare_for_instance_event(
463                         instance, event_name))
464             except exception.NovaException:
465                 error_callback(event_name, instance)
466                 # NOTE(danms): Don't wait for any of the events. They
467                 # should all be canceled and fired immediately below,
468                 # but don't stick around if not.
469                 deadline = 0
470         yield
471         with eventlet.timeout.Timeout(deadline):
472             for event_name, event in events.items():
473                 actual_event = event.wait()
474                 if actual_event.status == 'completed':
475                     continue
476                 decision = error_callback(event_name, instance)
477                 if decision is False:
478                     break
479 
480 
481 class ComputeManager(manager.Manager):
482     """Manages the running instances from creation to destruction."""
483 
484     target = messaging.Target(version='4.14')
485 
486     # How long to wait in seconds before re-issuing a shutdown
487     # signal to an instance during power off.  The overall
488     # time to wait is set by CONF.shutdown_timeout.
489     SHUTDOWN_RETRY_INTERVAL = 10
490 
491     def __init__(self, compute_driver=None, *args, **kwargs):
492         """Load configuration options and connect to the hypervisor."""
493         self.virtapi = ComputeVirtAPI(self)
494         self.network_api = network.API()
495         self.volume_api = cinder.API()
496         self.image_api = image.API()
497         self._last_host_check = 0
498         self._last_bw_usage_poll = 0
499         self._bw_usage_supported = True
500         self._last_bw_usage_cell_update = 0
501         self.compute_api = compute.API()
502         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
503         self.conductor_api = conductor.API()
504         self.compute_task_api = conductor.ComputeTaskAPI()
505         self.is_neutron_security_groups = (
506             openstack_driver.is_neutron_security_groups())
507         self.cells_rpcapi = cells_rpcapi.CellsAPI()
508         self.scheduler_client = scheduler_client.SchedulerClient()
509         self._resource_tracker = None
510         self.instance_events = InstanceEvents()
511         self._sync_power_pool = eventlet.GreenPool(
512             size=CONF.sync_power_state_pool_size)
513         self._syncs_in_progress = {}
514         self.send_instance_updates = (
515             CONF.filter_scheduler.track_instance_changes)
516         if CONF.max_concurrent_builds != 0:
517             self._build_semaphore = eventlet.semaphore.Semaphore(
518                 CONF.max_concurrent_builds)
519         else:
520             self._build_semaphore = compute_utils.UnlimitedSemaphore()
521         if max(CONF.max_concurrent_live_migrations, 0) != 0:
522             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
523                 CONF.max_concurrent_live_migrations)
524         else:
525             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
526         self._failed_builds = 0
527 
528         super(ComputeManager, self).__init__(service_name="compute",
529                                              *args, **kwargs)
530 
531         # NOTE(russellb) Load the driver last.  It may call back into the
532         # compute manager via the virtapi, so we want it to be fully
533         # initialized before that happens.
534         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
535         self.use_legacy_block_device_info = \
536                             self.driver.need_legacy_block_device_info
537 
538     def reset(self):
539         LOG.info('Reloading compute RPC API')
540         compute_rpcapi.LAST_VERSION = None
541         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
542 
543     def _get_resource_tracker(self):
544         if not self._resource_tracker:
545             rt = resource_tracker.ResourceTracker(self.host, self.driver)
546             self._resource_tracker = rt
547         return self._resource_tracker
548 
549     def _update_resource_tracker(self, context, instance):
550         """Let the resource tracker know that an instance has changed state."""
551 
552         if instance.host == self.host:
553             rt = self._get_resource_tracker()
554             rt.update_usage(context, instance, instance.node)
555 
556     def _instance_update(self, context, instance, **kwargs):
557         """Update an instance in the database using kwargs as value."""
558 
559         for k, v in kwargs.items():
560             setattr(instance, k, v)
561         instance.save()
562         self._update_resource_tracker(context, instance)
563 
564     def _nil_out_instance_obj_host_and_node(self, instance):
565         # NOTE(jwcroppe): We don't do instance.save() here for performance
566         # reasons; a call to this is expected to be immediately followed by
567         # another call that does instance.save(), thus avoiding two writes
568         # to the database layer.
569         instance.host = None
570         instance.node = None
571 
572     def _set_instance_obj_error_state(self, context, instance,
573                                       clean_task_state=False):
574         try:
575             instance.vm_state = vm_states.ERROR
576             if clean_task_state:
577                 instance.task_state = None
578             instance.save()
579         except exception.InstanceNotFound:
580             LOG.debug('Instance has been destroyed from under us while '
581                       'trying to set it to ERROR', instance=instance)
582 
583     def _get_instances_on_driver(self, context, filters=None):
584         """Return a list of instance records for the instances found
585         on the hypervisor which satisfy the specified filters. If filters=None
586         return a list of instance records for all the instances found on the
587         hypervisor.
588         """
589         if not filters:
590             filters = {}
591         try:
592             driver_uuids = self.driver.list_instance_uuids()
593             if len(driver_uuids) == 0:
594                 # Short circuit, don't waste a DB call
595                 return objects.InstanceList()
596             filters['uuid'] = driver_uuids
597             local_instances = objects.InstanceList.get_by_filters(
598                 context, filters, use_slave=True)
599             return local_instances
600         except NotImplementedError:
601             pass
602 
603         # The driver doesn't support uuids listing, so we'll have
604         # to brute force.
605         driver_instances = self.driver.list_instances()
606         instances = objects.InstanceList.get_by_filters(context, filters,
607                                                         use_slave=True)
608         name_map = {instance.name: instance for instance in instances}
609         local_instances = []
610         for driver_instance in driver_instances:
611             instance = name_map.get(driver_instance)
612             if not instance:
613                 continue
614             local_instances.append(instance)
615         return local_instances
616 
617     def _destroy_evacuated_instances(self, context):
618         """Destroys evacuated instances.
619 
620         While nova-compute was down, the instances running on it could be
621         evacuated to another host. Check that the instances reported
622         by the driver are still associated with this host.  If they are
623         not, destroy them, with the exception of instances which are in
624         the MIGRATING, RESIZE_MIGRATING, RESIZE_MIGRATED, RESIZE_FINISH
625         task state or RESIZED vm state.
626         """
627         filters = {
628             'source_compute': self.host,
629             'status': ['accepted', 'done'],
630             'migration_type': 'evacuation',
631         }
632         evacuations = objects.MigrationList.get_by_filters(context, filters)
633         if not evacuations:
634             return
635         evacuations = {mig.instance_uuid: mig for mig in evacuations}
636 
637         filters = {'deleted': False}
638         local_instances = self._get_instances_on_driver(context, filters)
639         evacuated = [inst for inst in local_instances
640                      if inst.uuid in evacuations]
641         for instance in evacuated:
642             migration = evacuations[instance.uuid]
643             LOG.info('Deleting instance as it has been evacuated from '
644                      'this host', instance=instance)
645             try:
646                 network_info = self.network_api.get_instance_nw_info(
647                     context, instance)
648                 bdi = self._get_instance_block_device_info(context,
649                                                            instance)
650                 destroy_disks = not (self._is_instance_storage_shared(
651                     context, instance))
652             except exception.InstanceNotFound:
653                 network_info = network_model.NetworkInfo()
654                 bdi = {}
655                 LOG.info('Instance has been marked deleted already, '
656                          'removing it from the hypervisor.',
657                          instance=instance)
658                 # always destroy disks if the instance was deleted
659                 destroy_disks = True
660             self.driver.destroy(context, instance,
661                                 network_info,
662                                 bdi, destroy_disks)
663             migration.status = 'completed'
664             migration.save()
665 
666     def _is_instance_storage_shared(self, context, instance, host=None):
667         shared_storage = True
668         data = None
669         try:
670             data = self.driver.check_instance_shared_storage_local(context,
671                                                        instance)
672             if data:
673                 shared_storage = (self.compute_rpcapi.
674                                   check_instance_shared_storage(context,
675                                   instance, data, host=host))
676         except NotImplementedError:
677             LOG.debug('Hypervisor driver does not support '
678                       'instance shared storage check, '
679                       'assuming it\'s not on shared storage',
680                       instance=instance)
681             shared_storage = False
682         except Exception:
683             LOG.exception('Failed to check if instance shared',
684                           instance=instance)
685         finally:
686             if data:
687                 self.driver.check_instance_shared_storage_cleanup(context,
688                                                                   data)
689         return shared_storage
690 
691     def _complete_partial_deletion(self, context, instance):
692         """Complete deletion for instances in DELETED status but not marked as
693         deleted in the DB
694         """
695         system_meta = instance.system_metadata
696         instance.destroy()
697         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
698                 context, instance.uuid)
699         quotas = objects.Quotas(context=context)
700         project_id, user_id = objects.quotas.ids_from_instance(context,
701                                                                instance)
702         quotas.reserve(project_id=project_id, user_id=user_id, instances=-1,
703                        cores=-instance.flavor.vcpus,
704                        ram=-instance.flavor.memory_mb)
705         self._complete_deletion(context,
706                                 instance,
707                                 bdms,
708                                 quotas,
709                                 system_meta)
710 
711     def _complete_deletion(self, context, instance, bdms,
712                            quotas, system_meta):
713         if quotas:
714             quotas.commit()
715 
716         # ensure block device mappings are not leaked
717         for bdm in bdms:
718             bdm.destroy()
719 
720         self._update_resource_tracker(context, instance)
721         self._notify_about_instance_usage(context, instance, "delete.end",
722                 system_metadata=system_meta)
723         compute_utils.notify_about_instance_action(context, instance,
724                 self.host, action=fields.NotificationAction.DELETE,
725                 phase=fields.NotificationPhase.END)
726         self._delete_scheduler_instance_info(context, instance.uuid)
727 
728     def _create_reservations(self, context, instance, project_id, user_id):
729         vcpus = instance.flavor.vcpus
730         mem_mb = instance.flavor.memory_mb
731 
732         quotas = objects.Quotas(context=context)
733         quotas.reserve(project_id=project_id,
734                        user_id=user_id,
735                        instances=-1,
736                        cores=-vcpus,
737                        ram=-mem_mb)
738         return quotas
739 
740     def _init_instance(self, context, instance):
741         '''Initialize this instance during service init.'''
742 
743         # NOTE(danms): If the instance appears to not be owned by this
744         # host, it may have been evacuated away, but skipped by the
745         # evacuation cleanup code due to configuration. Thus, if that
746         # is a possibility, don't touch the instance in any way, but
747         # log the concern. This will help avoid potential issues on
748         # startup due to misconfiguration.
749         if instance.host != self.host:
750             LOG.warning('Instance %(uuid)s appears to not be owned '
751                         'by this host, but by %(host)s. Startup '
752                         'processing is being skipped.',
753                         {'uuid': instance.uuid,
754                          'host': instance.host})
755             return
756 
757         # Instances that are shut down, or in an error state can not be
758         # initialized and are not attempted to be recovered. The exception
759         # to this are instances that are in RESIZE_MIGRATING or DELETING,
760         # which are dealt with further down.
761         if (instance.vm_state == vm_states.SOFT_DELETED or
762             (instance.vm_state == vm_states.ERROR and
763             instance.task_state not in
764             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
765             LOG.debug("Instance is in %s state.",
766                       instance.vm_state, instance=instance)
767             return
768 
769         if instance.vm_state == vm_states.DELETED:
770             try:
771                 self._complete_partial_deletion(context, instance)
772             except Exception:
773                 # we don't want that an exception blocks the init_host
774                 LOG.exception('Failed to complete a deletion',
775                               instance=instance)
776             return
777 
778         if (instance.vm_state == vm_states.BUILDING or
779             instance.task_state in [task_states.SCHEDULING,
780                                     task_states.BLOCK_DEVICE_MAPPING,
781                                     task_states.NETWORKING,
782                                     task_states.SPAWNING]):
783             # NOTE(dave-mcnally) compute stopped before instance was fully
784             # spawned so set to ERROR state. This is safe to do as the state
785             # may be set by the api but the host is not so if we get here the
786             # instance has already been scheduled to this particular host.
787             LOG.debug("Instance failed to spawn correctly, "
788                       "setting to ERROR state", instance=instance)
789             instance.task_state = None
790             instance.vm_state = vm_states.ERROR
791             instance.save()
792             return
793 
794         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
795             instance.task_state in [task_states.REBUILDING,
796                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
797                                     task_states.REBUILD_SPAWNING]):
798             # NOTE(jichenjc) compute stopped before instance was fully
799             # spawned so set to ERROR state. This is consistent to BUILD
800             LOG.debug("Instance failed to rebuild correctly, "
801                       "setting to ERROR state", instance=instance)
802             instance.task_state = None
803             instance.vm_state = vm_states.ERROR
804             instance.save()
805             return
806 
807         if (instance.vm_state != vm_states.ERROR and
808             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
809                                     task_states.IMAGE_PENDING_UPLOAD,
810                                     task_states.IMAGE_UPLOADING,
811                                     task_states.IMAGE_SNAPSHOT]):
812             LOG.debug("Instance in transitional state %s at start-up "
813                       "clearing task state",
814                       instance.task_state, instance=instance)
815             try:
816                 self._post_interrupted_snapshot_cleanup(context, instance)
817             except Exception:
818                 # we don't want that an exception blocks the init_host
819                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
820             instance.task_state = None
821             instance.save()
822 
823         if (instance.vm_state != vm_states.ERROR and
824             instance.task_state in [task_states.RESIZE_PREP]):
825             LOG.debug("Instance in transitional state %s at start-up "
826                       "clearing task state",
827                       instance['task_state'], instance=instance)
828             instance.task_state = None
829             instance.save()
830 
831         if instance.task_state == task_states.DELETING:
832             try:
833                 LOG.info('Service started deleting the instance during '
834                          'the previous run, but did not finish. Restarting'
835                          ' the deletion now.', instance=instance)
836                 instance.obj_load_attr('metadata')
837                 instance.obj_load_attr('system_metadata')
838                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
839                         context, instance.uuid)
840                 project_id, user_id = objects.quotas.ids_from_instance(
841                     context, instance)
842                 quotas = self._create_reservations(context, instance,
843                                                    project_id, user_id)
844 
845                 self._delete_instance(context, instance, bdms, quotas)
846             except Exception:
847                 # we don't want that an exception blocks the init_host
848                 LOG.exception('Failed to complete a deletion',
849                               instance=instance)
850                 self._set_instance_obj_error_state(context, instance)
851             return
852 
853         current_power_state = self._get_power_state(context, instance)
854         try_reboot, reboot_type = self._retry_reboot(context, instance,
855                                                      current_power_state)
856 
857         if try_reboot:
858             LOG.debug("Instance in transitional state (%(task_state)s) at "
859                       "start-up and power state is (%(power_state)s), "
860                       "triggering reboot",
861                       {'task_state': instance.task_state,
862                        'power_state': current_power_state},
863                       instance=instance)
864 
865             # NOTE(mikal): if the instance was doing a soft reboot that got as
866             # far as shutting down the instance but not as far as starting it
867             # again, then we've just become a hard reboot. That means the
868             # task state for the instance needs to change so that we're in one
869             # of the expected task states for a hard reboot.
870             soft_types = [task_states.REBOOT_STARTED,
871                           task_states.REBOOT_PENDING,
872                           task_states.REBOOTING]
873             if instance.task_state in soft_types and reboot_type == 'HARD':
874                 instance.task_state = task_states.REBOOT_PENDING_HARD
875                 instance.save()
876 
877             self.reboot_instance(context, instance, block_device_info=None,
878                                  reboot_type=reboot_type)
879             return
880 
881         elif (current_power_state == power_state.RUNNING and
882               instance.task_state in [task_states.REBOOT_STARTED,
883                                       task_states.REBOOT_STARTED_HARD,
884                                       task_states.PAUSING,
885                                       task_states.UNPAUSING]):
886             LOG.warning("Instance in transitional state "
887                         "(%(task_state)s) at start-up and power state "
888                         "is (%(power_state)s), clearing task state",
889                         {'task_state': instance.task_state,
890                          'power_state': current_power_state},
891                         instance=instance)
892             instance.task_state = None
893             instance.vm_state = vm_states.ACTIVE
894             instance.save()
895         elif (current_power_state == power_state.PAUSED and
896               instance.task_state == task_states.UNPAUSING):
897             LOG.warning("Instance in transitional state "
898                         "(%(task_state)s) at start-up and power state "
899                         "is (%(power_state)s), clearing task state "
900                         "and unpausing the instance",
901                         {'task_state': instance.task_state,
902                          'power_state': current_power_state},
903                         instance=instance)
904             try:
905                 self.unpause_instance(context, instance)
906             except NotImplementedError:
907                 # Some virt driver didn't support pause and unpause
908                 pass
909             except Exception:
910                 LOG.exception('Failed to unpause instance', instance=instance)
911             return
912 
913         if instance.task_state == task_states.POWERING_OFF:
914             try:
915                 LOG.debug("Instance in transitional state %s at start-up "
916                           "retrying stop request",
917                           instance.task_state, instance=instance)
918                 self.stop_instance(context, instance, True)
919             except Exception:
920                 # we don't want that an exception blocks the init_host
921                 LOG.exception('Failed to stop instance', instance=instance)
922             return
923 
924         if instance.task_state == task_states.POWERING_ON:
925             try:
926                 LOG.debug("Instance in transitional state %s at start-up "
927                           "retrying start request",
928                           instance.task_state, instance=instance)
929                 self.start_instance(context, instance)
930             except Exception:
931                 # we don't want that an exception blocks the init_host
932                 LOG.exception('Failed to start instance', instance=instance)
933             return
934 
935         net_info = compute_utils.get_nw_info_for_instance(instance)
936         try:
937             self.driver.plug_vifs(instance, net_info)
938         except NotImplementedError as e:
939             LOG.debug(e, instance=instance)
940         except exception.VirtualInterfacePlugException:
941             # we don't want an exception to block the init_host
942             LOG.exception("Vifs plug failed", instance=instance)
943             self._set_instance_obj_error_state(context, instance)
944             return
945 
946         if instance.task_state == task_states.RESIZE_MIGRATING:
947             # We crashed during resize/migration, so roll back for safety
948             try:
949                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
950                 # not in system_metadata we default to True for backwards
951                 # compatibility
952                 power_on = (instance.system_metadata.get('old_vm_state') !=
953                             vm_states.STOPPED)
954 
955                 block_dev_info = self._get_instance_block_device_info(context,
956                                                                       instance)
957 
958                 self.driver.finish_revert_migration(context,
959                     instance, net_info, block_dev_info, power_on)
960 
961             except Exception:
962                 LOG.exception('Failed to revert crashed migration',
963                               instance=instance)
964             finally:
965                 LOG.info('Instance found in migrating state during '
966                          'startup. Resetting task_state',
967                          instance=instance)
968                 instance.task_state = None
969                 instance.save()
970         if instance.task_state == task_states.MIGRATING:
971             # Live migration did not complete, but instance is on this
972             # host, so reset the state.
973             instance.task_state = None
974             instance.save(expected_task_state=[task_states.MIGRATING])
975 
976         db_state = instance.power_state
977         drv_state = self._get_power_state(context, instance)
978         expect_running = (db_state == power_state.RUNNING and
979                           drv_state != db_state)
980 
981         LOG.debug('Current state is %(drv_state)s, state in DB is '
982                   '%(db_state)s.',
983                   {'drv_state': drv_state, 'db_state': db_state},
984                   instance=instance)
985 
986         if expect_running and CONF.resume_guests_state_on_host_boot:
987             LOG.info('Rebooting instance after nova-compute restart.',
988                      instance=instance)
989 
990             block_device_info = \
991                 self._get_instance_block_device_info(context, instance)
992 
993             try:
994                 self.driver.resume_state_on_host_boot(
995                     context, instance, net_info, block_device_info)
996             except NotImplementedError:
997                 LOG.warning('Hypervisor driver does not support '
998                             'resume guests', instance=instance)
999             except Exception:
1000                 # NOTE(vish): The instance failed to resume, so we set the
1001                 #             instance to error and attempt to continue.
1002                 LOG.warning('Failed to resume instance',
1003                             instance=instance)
1004                 self._set_instance_obj_error_state(context, instance)
1005 
1006         elif drv_state == power_state.RUNNING:
1007             # VMwareAPI drivers will raise an exception
1008             try:
1009                 self.driver.ensure_filtering_rules_for_instance(
1010                                        instance, net_info)
1011             except NotImplementedError:
1012                 LOG.debug('Hypervisor driver does not support '
1013                           'firewall rules', instance=instance)
1014 
1015     def _retry_reboot(self, context, instance, current_power_state):
1016         current_task_state = instance.task_state
1017         retry_reboot = False
1018         reboot_type = compute_utils.get_reboot_type(current_task_state,
1019                                                     current_power_state)
1020 
1021         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1022                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1023         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1024                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1025         started_not_running = (current_task_state in
1026                                [task_states.REBOOT_STARTED,
1027                                 task_states.REBOOT_STARTED_HARD] and
1028                                current_power_state != power_state.RUNNING)
1029 
1030         if pending_soft or pending_hard or started_not_running:
1031             retry_reboot = True
1032 
1033         return retry_reboot, reboot_type
1034 
1035     def handle_lifecycle_event(self, event):
1036         LOG.info("VM %(state)s (Lifecycle Event)",
1037                  {'state': event.get_name()},
1038                  instance_uuid=event.get_instance_uuid())
1039         context = nova.context.get_admin_context(read_deleted='yes')
1040         instance = objects.Instance.get_by_uuid(context,
1041                                                 event.get_instance_uuid(),
1042                                                 expected_attrs=[])
1043         vm_power_state = None
1044         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1045             vm_power_state = power_state.SHUTDOWN
1046         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1047             vm_power_state = power_state.RUNNING
1048         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1049             vm_power_state = power_state.PAUSED
1050         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1051             vm_power_state = power_state.RUNNING
1052         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1053             vm_power_state = power_state.SUSPENDED
1054         else:
1055             LOG.warning("Unexpected power state %d", event.get_transition())
1056 
1057         # Note(lpetrut): The event may be delayed, thus not reflecting
1058         # the current instance power state. In that case, ignore the event.
1059         current_power_state = self._get_power_state(context, instance)
1060         if current_power_state == vm_power_state:
1061             LOG.debug('Synchronizing instance power state after lifecycle '
1062                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1063                       'current task_state: %(task_state)s, current DB '
1064                       'power_state: %(db_power_state)s, VM power_state: '
1065                       '%(vm_power_state)s',
1066                       {'event': event.get_name(),
1067                        'vm_state': instance.vm_state,
1068                        'task_state': instance.task_state,
1069                        'db_power_state': instance.power_state,
1070                        'vm_power_state': vm_power_state},
1071                       instance_uuid=instance.uuid)
1072             self._sync_instance_power_state(context,
1073                                             instance,
1074                                             vm_power_state)
1075 
1076     def handle_events(self, event):
1077         if isinstance(event, virtevent.LifecycleEvent):
1078             try:
1079                 self.handle_lifecycle_event(event)
1080             except exception.InstanceNotFound:
1081                 LOG.debug("Event %s arrived for non-existent instance. The "
1082                           "instance was probably deleted.", event)
1083         else:
1084             LOG.debug("Ignoring event %s", event)
1085 
1086     def init_virt_events(self):
1087         if CONF.workarounds.handle_virt_lifecycle_events:
1088             self.driver.register_event_listener(self.handle_events)
1089         else:
1090             # NOTE(mriedem): If the _sync_power_states periodic task is
1091             # disabled we should emit a warning in the logs.
1092             if CONF.sync_power_state_interval < 0:
1093                 LOG.warning('Instance lifecycle events from the compute '
1094                             'driver have been disabled. Note that lifecycle '
1095                             'changes to an instance outside of the compute '
1096                             'service will not be synchronized '
1097                             'automatically since the _sync_power_states '
1098                             'periodic task is also disabled.')
1099             else:
1100                 LOG.info('Instance lifecycle events from the compute '
1101                          'driver have been disabled. Note that lifecycle '
1102                          'changes to an instance outside of the compute '
1103                          'service will only be synchronized by the '
1104                          '_sync_power_states periodic task.')
1105 
1106     def init_host(self):
1107         """Initialization for a standalone compute service."""
1108 
1109         if CONF.pci.passthrough_whitelist:
1110             # Simply loading the PCI passthrough whitelist will do a bunch of
1111             # validation that would otherwise wait until the PciDevTracker is
1112             # constructed when updating available resources for the compute
1113             # node(s) in the resource tracker, effectively killing that task.
1114             # So load up the whitelist when starting the compute service to
1115             # flush any invalid configuration early so we can kill the service
1116             # if the configuration is wrong.
1117             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1118 
1119         # NOTE(sbauza): We want the compute node to hard fail if it can't be
1120         # able to provide its resources to the placement API, or it would not
1121         # be able to be eligible as a destination.
1122         if CONF.placement.os_region_name is None:
1123             raise exception.PlacementNotConfigured()
1124 
1125         self.driver.init_host(host=self.host)
1126         context = nova.context.get_admin_context()
1127         instances = objects.InstanceList.get_by_host(
1128             context, self.host, expected_attrs=['info_cache', 'metadata'])
1129 
1130         if CONF.defer_iptables_apply:
1131             self.driver.filter_defer_apply_on()
1132 
1133         self.init_virt_events()
1134 
1135         try:
1136             # checking that instance was not already evacuated to other host
1137             self._destroy_evacuated_instances(context)
1138             for instance in instances:
1139                 self._init_instance(context, instance)
1140         finally:
1141             if CONF.defer_iptables_apply:
1142                 self.driver.filter_defer_apply_off()
1143             if instances:
1144                 # We only send the instance info to the scheduler on startup
1145                 # if there is anything to send, otherwise this host might
1146                 # not be mapped yet in a cell and the scheduler may have
1147                 # issues dealing with the information. Later changes to
1148                 # instances on this host will update the scheduler, or the
1149                 # _sync_scheduler_instance_info periodic task will.
1150                 self._update_scheduler_instance_info(context, instances)
1151 
1152     def cleanup_host(self):
1153         self.driver.register_event_listener(None)
1154         self.instance_events.cancel_all_events()
1155         self.driver.cleanup_host(host=self.host)
1156 
1157     def pre_start_hook(self):
1158         """After the service is initialized, but before we fully bring
1159         the service up by listening on RPC queues, make sure to update
1160         our available resources (and indirectly our available nodes).
1161         """
1162         self.update_available_resource(nova.context.get_admin_context(),
1163                                        startup=True)
1164 
1165     def _get_power_state(self, context, instance):
1166         """Retrieve the power state for the given instance."""
1167         LOG.debug('Checking state', instance=instance)
1168         try:
1169             return self.driver.get_info(instance).state
1170         except exception.InstanceNotFound:
1171             return power_state.NOSTATE
1172 
1173     def get_console_topic(self, context):
1174         """Retrieves the console host for a project on this host.
1175 
1176         Currently this is just set in the flags for each compute host.
1177 
1178         """
1179         # TODO(mdragon): perhaps make this variable by console_type?
1180         return '%s.%s' % (CONF.console_topic, CONF.console_host)
1181 
1182     @wrap_exception()
1183     def get_console_pool_info(self, context, console_type):
1184         return self.driver.get_console_pool_info(console_type)
1185 
1186     # NOTE(hanlind): This and the virt method it calls can be removed in
1187     # version 5.0 of the RPC API
1188     @wrap_exception()
1189     def refresh_security_group_rules(self, context, security_group_id):
1190         """Tell the virtualization driver to refresh security group rules.
1191 
1192         Passes straight through to the virtualization driver.
1193 
1194         """
1195         return self.driver.refresh_security_group_rules(security_group_id)
1196 
1197     # TODO(alaski): Remove object_compat for RPC version 5.0
1198     @object_compat
1199     @wrap_exception()
1200     def refresh_instance_security_rules(self, context, instance):
1201         """Tell the virtualization driver to refresh security rules for
1202         an instance.
1203 
1204         Passes straight through to the virtualization driver.
1205 
1206         Synchronize the call because we may still be in the middle of
1207         creating the instance.
1208         """
1209         @utils.synchronized(instance.uuid)
1210         def _sync_refresh():
1211             try:
1212                 return self.driver.refresh_instance_security_rules(instance)
1213             except NotImplementedError:
1214                 LOG.debug('Hypervisor driver does not support '
1215                           'security groups.', instance=instance)
1216 
1217         return _sync_refresh()
1218 
1219     def _await_block_device_map_created(self, context, vol_id):
1220         # TODO(yamahata): creating volume simultaneously
1221         #                 reduces creation time?
1222         # TODO(yamahata): eliminate dumb polling
1223         start = time.time()
1224         retries = CONF.block_device_allocate_retries
1225         if retries < 0:
1226             LOG.warning("Treating negative config value (%(retries)s) for "
1227                         "'block_device_retries' as 0.",
1228                         {'retries': retries})
1229         # (1) treat  negative config value as 0
1230         # (2) the configured value is 0, one attempt should be made
1231         # (3) the configured value is > 0, then the total number attempts
1232         #      is (retries + 1)
1233         attempts = 1
1234         if retries >= 1:
1235             attempts = retries + 1
1236         for attempt in range(1, attempts + 1):
1237             volume = self.volume_api.get(context, vol_id)
1238             volume_status = volume['status']
1239             if volume_status not in ['creating', 'downloading']:
1240                 if volume_status == 'available':
1241                     return attempt
1242                 LOG.warning("Volume id: %(vol_id)s finished being "
1243                             "created but its status is %(vol_status)s.",
1244                             {'vol_id': vol_id,
1245                              'vol_status': volume_status})
1246                 break
1247             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1248         raise exception.VolumeNotCreated(volume_id=vol_id,
1249                                          seconds=int(time.time() - start),
1250                                          attempts=attempt,
1251                                          volume_status=volume_status)
1252 
1253     def _decode_files(self, injected_files):
1254         """Base64 decode the list of files to inject."""
1255         if not injected_files:
1256             return []
1257 
1258         def _decode(f):
1259             path, contents = f
1260             # Py3 raises binascii.Error instead of TypeError as in Py27
1261             try:
1262                 decoded = base64.b64decode(contents)
1263                 return path, decoded
1264             except (TypeError, binascii.Error):
1265                 raise exception.Base64Exception(path=path)
1266 
1267         return [_decode(f) for f in injected_files]
1268 
1269     def _validate_instance_group_policy(self, context, instance,
1270             filter_properties):
1271         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1272         # However, there is a race condition with the enforcement of
1273         # the policy.  Since more than one instance may be scheduled at the
1274         # same time, it's possible that more than one instance with an
1275         # anti-affinity policy may end up here.  It's also possible that
1276         # multiple instances with an affinity policy could end up on different
1277         # hosts.  This is a validation step to make sure that starting the
1278         # instance here doesn't violate the policy.
1279 
1280         scheduler_hints = filter_properties.get('scheduler_hints') or {}
1281         group_hint = scheduler_hints.get('group')
1282         if not group_hint:
1283             return
1284 
1285         @utils.synchronized(group_hint)
1286         def _do_validation(context, instance, group_hint):
1287             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1288             if 'anti-affinity' in group.policies:
1289                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1290                 if self.host in group_hosts:
1291                     msg = _("Anti-affinity instance group policy "
1292                             "was violated.")
1293                     raise exception.RescheduledException(
1294                             instance_uuid=instance.uuid,
1295                             reason=msg)
1296             elif 'affinity' in group.policies:
1297                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1298                 if group_hosts and self.host not in group_hosts:
1299                     msg = _("Affinity instance group policy was violated.")
1300                     raise exception.RescheduledException(
1301                             instance_uuid=instance.uuid,
1302                             reason=msg)
1303 
1304         if not CONF.workarounds.disable_group_policy_check_upcall:
1305             _do_validation(context, instance, group_hint)
1306 
1307     def _log_original_error(self, exc_info, instance_uuid):
1308         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1309                   exc_info=exc_info)
1310 
1311     def _reschedule(self, context, request_spec, filter_properties,
1312             instance, reschedule_method, method_args, task_state,
1313             exc_info=None):
1314         """Attempt to re-schedule a compute operation."""
1315 
1316         instance_uuid = instance.uuid
1317         retry = filter_properties.get('retry')
1318         if not retry:
1319             # no retry information, do not reschedule.
1320             LOG.debug("Retry info not present, will not reschedule",
1321                       instance_uuid=instance_uuid)
1322             return
1323 
1324         if not request_spec:
1325             LOG.debug("No request spec, will not reschedule",
1326                       instance_uuid=instance_uuid)
1327             return
1328 
1329         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1330                   {'method': reschedule_method.__name__,
1331                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1332 
1333         # reset the task state:
1334         self._instance_update(context, instance, task_state=task_state)
1335 
1336         if exc_info:
1337             # stringify to avoid circular ref problem in json serialization:
1338             retry['exc'] = traceback.format_exception_only(exc_info[0],
1339                                     exc_info[1])
1340 
1341         reschedule_method(context, *method_args)
1342         return True
1343 
1344     @periodic_task.periodic_task
1345     def _check_instance_build_time(self, context):
1346         """Ensure that instances are not stuck in build."""
1347         timeout = CONF.instance_build_timeout
1348         if timeout == 0:
1349             return
1350 
1351         filters = {'vm_state': vm_states.BUILDING,
1352                    'host': self.host}
1353 
1354         building_insts = objects.InstanceList.get_by_filters(context,
1355                            filters, expected_attrs=[], use_slave=True)
1356 
1357         for instance in building_insts:
1358             if timeutils.is_older_than(instance.created_at, timeout):
1359                 self._set_instance_obj_error_state(context, instance)
1360                 LOG.warning("Instance build timed out. Set to error "
1361                             "state.", instance=instance)
1362 
1363     def _check_instance_exists(self, context, instance):
1364         """Ensure an instance with the same name is not already present."""
1365         if self.driver.instance_exists(instance):
1366             raise exception.InstanceExists(name=instance.name)
1367 
1368     def _allocate_network_async(self, context, instance, requested_networks,
1369                                 macs, security_groups, is_vpn, dhcp_options):
1370         """Method used to allocate networks in the background.
1371 
1372         Broken out for testing.
1373         """
1374         # First check to see if we're specifically not supposed to allocate
1375         # networks because if so, we can exit early.
1376         if requested_networks and requested_networks.no_allocate:
1377             LOG.debug("Not allocating networking since 'none' was specified.",
1378                       instance=instance)
1379             return network_model.NetworkInfo([])
1380 
1381         LOG.debug("Allocating IP information in the background.",
1382                   instance=instance)
1383         retries = CONF.network_allocate_retries
1384         attempts = retries + 1
1385         retry_time = 1
1386         bind_host_id = self.driver.network_binding_host_id(context, instance)
1387         for attempt in range(1, attempts + 1):
1388             try:
1389                 nwinfo = self.network_api.allocate_for_instance(
1390                         context, instance, vpn=is_vpn,
1391                         requested_networks=requested_networks,
1392                         macs=macs,
1393                         security_groups=security_groups,
1394                         dhcp_options=dhcp_options,
1395                         bind_host_id=bind_host_id)
1396                 LOG.debug('Instance network_info: |%s|', nwinfo,
1397                           instance=instance)
1398                 instance.system_metadata['network_allocated'] = 'True'
1399                 # NOTE(JoshNang) do not save the instance here, as it can cause
1400                 # races. The caller shares a reference to instance and waits
1401                 # for this async greenthread to finish before calling
1402                 # instance.save().
1403                 return nwinfo
1404             except Exception:
1405                 exc_info = sys.exc_info()
1406                 log_info = {'attempt': attempt,
1407                             'attempts': attempts}
1408                 if attempt == attempts:
1409                     LOG.exception('Instance failed network setup '
1410                                   'after %(attempts)d attempt(s)',
1411                                   log_info)
1412                     six.reraise(*exc_info)
1413                 LOG.warning('Instance failed network setup '
1414                             '(attempt %(attempt)d of %(attempts)d)',
1415                             log_info, instance=instance)
1416                 time.sleep(retry_time)
1417                 retry_time *= 2
1418                 if retry_time > 30:
1419                     retry_time = 30
1420         # Not reached.
1421 
1422     def _build_networks_for_instance(self, context, instance,
1423             requested_networks, security_groups):
1424 
1425         # If we're here from a reschedule the network may already be allocated.
1426         if strutils.bool_from_string(
1427                 instance.system_metadata.get('network_allocated', 'False')):
1428             # NOTE(alex_xu): The network_allocated is True means the network
1429             # resource already allocated at previous scheduling, and the
1430             # network setup is cleanup at previous. After rescheduling, the
1431             # network resource need setup on the new host.
1432             self.network_api.setup_instance_network_on_host(
1433                 context, instance, instance.host)
1434             return self.network_api.get_instance_nw_info(context, instance)
1435 
1436         if not self.is_neutron_security_groups:
1437             security_groups = []
1438 
1439         macs = self.driver.macs_for_instance(instance)
1440         dhcp_options = self.driver.dhcp_options_for_instance(instance)
1441         network_info = self._allocate_network(context, instance,
1442                 requested_networks, macs, security_groups, dhcp_options)
1443 
1444         return network_info
1445 
1446     def _allocate_network(self, context, instance, requested_networks, macs,
1447                           security_groups, dhcp_options):
1448         """Start network allocation asynchronously.  Return an instance
1449         of NetworkInfoAsyncWrapper that can be used to retrieve the
1450         allocated networks when the operation has finished.
1451         """
1452         # NOTE(comstud): Since we're allocating networks asynchronously,
1453         # this task state has little meaning, as we won't be in this
1454         # state for very long.
1455         instance.vm_state = vm_states.BUILDING
1456         instance.task_state = task_states.NETWORKING
1457         instance.save(expected_task_state=[None])
1458         self._update_resource_tracker(context, instance)
1459 
1460         is_vpn = False
1461         return network_model.NetworkInfoAsyncWrapper(
1462                 self._allocate_network_async, context, instance,
1463                 requested_networks, macs, security_groups, is_vpn,
1464                 dhcp_options)
1465 
1466     def _default_root_device_name(self, instance, image_meta, root_bdm):
1467         try:
1468             return self.driver.default_root_device_name(instance,
1469                                                         image_meta,
1470                                                         root_bdm)
1471         except NotImplementedError:
1472             return compute_utils.get_next_device_name(instance, [])
1473 
1474     def _default_device_names_for_instance(self, instance,
1475                                            root_device_name,
1476                                            *block_device_lists):
1477         try:
1478             self.driver.default_device_names_for_instance(instance,
1479                                                           root_device_name,
1480                                                           *block_device_lists)
1481         except NotImplementedError:
1482             compute_utils.default_device_names_for_instance(
1483                 instance, root_device_name, *block_device_lists)
1484 
1485     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1486         # NOTE(ndipanov): Copy obj to avoid changing the original
1487         block_device_obj = block_device_obj.obj_clone()
1488         try:
1489             return self.driver.get_device_name_for_instance(
1490                 instance, bdms, block_device_obj)
1491         except NotImplementedError:
1492             return compute_utils.get_device_name_for_instance(
1493                 instance, bdms, block_device_obj.get("device_name"))
1494 
1495     def _default_block_device_names(self, instance, image_meta, block_devices):
1496         """Verify that all the devices have the device_name set. If not,
1497         provide a default name.
1498 
1499         It also ensures that there is a root_device_name and is set to the
1500         first block device in the boot sequence (boot_index=0).
1501         """
1502         root_bdm = block_device.get_root_bdm(block_devices)
1503         if not root_bdm:
1504             return
1505 
1506         # Get the root_device_name from the root BDM or the instance
1507         root_device_name = None
1508         update_root_bdm = False
1509 
1510         if root_bdm.device_name:
1511             root_device_name = root_bdm.device_name
1512             instance.root_device_name = root_device_name
1513         elif instance.root_device_name:
1514             root_device_name = instance.root_device_name
1515             root_bdm.device_name = root_device_name
1516             update_root_bdm = True
1517         else:
1518             root_device_name = self._default_root_device_name(instance,
1519                                                               image_meta,
1520                                                               root_bdm)
1521 
1522             instance.root_device_name = root_device_name
1523             root_bdm.device_name = root_device_name
1524             update_root_bdm = True
1525 
1526         if update_root_bdm:
1527             root_bdm.save()
1528 
1529         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1530                             block_devices))
1531         swap = list(filter(block_device.new_format_is_swap,
1532                       block_devices))
1533         block_device_mapping = list(filter(
1534               driver_block_device.is_block_device_mapping, block_devices))
1535 
1536         self._default_device_names_for_instance(instance,
1537                                                 root_device_name,
1538                                                 ephemerals,
1539                                                 swap,
1540                                                 block_device_mapping)
1541 
1542     def _block_device_info_to_legacy(self, block_device_info):
1543         """Convert BDI to the old format for drivers that need it."""
1544 
1545         if self.use_legacy_block_device_info:
1546             ephemerals = driver_block_device.legacy_block_devices(
1547                 driver.block_device_info_get_ephemerals(block_device_info))
1548             mapping = driver_block_device.legacy_block_devices(
1549                 driver.block_device_info_get_mapping(block_device_info))
1550             swap = block_device_info['swap']
1551             if swap:
1552                 swap = swap.legacy()
1553 
1554             block_device_info.update({
1555                 'ephemerals': ephemerals,
1556                 'swap': swap,
1557                 'block_device_mapping': mapping})
1558 
1559     def _add_missing_dev_names(self, bdms, instance):
1560         for bdm in bdms:
1561             if bdm.device_name is not None:
1562                 continue
1563 
1564             device_name = self._get_device_name_for_instance(instance,
1565                                                              bdms, bdm)
1566             values = {'device_name': device_name}
1567             bdm.update(values)
1568             bdm.save()
1569 
1570     def _prep_block_device(self, context, instance, bdms):
1571         """Set up the block device for an instance with error logging."""
1572         try:
1573             self._add_missing_dev_names(bdms, instance)
1574             block_device_info = driver.get_block_device_info(instance, bdms)
1575             mapping = driver.block_device_info_get_mapping(block_device_info)
1576             driver_block_device.attach_block_devices(
1577                 mapping, context, instance, self.volume_api, self.driver,
1578                 wait_func=self._await_block_device_map_created)
1579 
1580             self._block_device_info_to_legacy(block_device_info)
1581             return block_device_info
1582 
1583         except exception.OverQuota as e:
1584             LOG.warning('Failed to create block device for instance due'
1585                         ' to exceeding volume related resource quota.'
1586                         ' Error: %s', e.message, instance=instance)
1587             raise
1588 
1589         except Exception:
1590             LOG.exception('Instance failed block device setup',
1591                           instance=instance)
1592             raise exception.InvalidBDM()
1593 
1594     def _update_instance_after_spawn(self, context, instance):
1595         instance.power_state = self._get_power_state(context, instance)
1596         instance.vm_state = vm_states.ACTIVE
1597         instance.task_state = None
1598         instance.launched_at = timeutils.utcnow()
1599         configdrive.update_instance(instance)
1600 
1601     def _update_scheduler_instance_info(self, context, instance):
1602         """Sends an InstanceList with created or updated Instance objects to
1603         the Scheduler client.
1604 
1605         In the case of init_host, the value passed will already be an
1606         InstanceList. Other calls will send individual Instance objects that
1607         have been created or resized. In this case, we create an InstanceList
1608         object containing that Instance.
1609         """
1610         if not self.send_instance_updates:
1611             return
1612         if isinstance(instance, obj_instance.Instance):
1613             instance = objects.InstanceList(objects=[instance])
1614         context = context.elevated()
1615         self.scheduler_client.update_instance_info(context, self.host,
1616                                                    instance)
1617 
1618     def _delete_scheduler_instance_info(self, context, instance_uuid):
1619         """Sends the uuid of the deleted Instance to the Scheduler client."""
1620         if not self.send_instance_updates:
1621             return
1622         context = context.elevated()
1623         self.scheduler_client.delete_instance_info(context, self.host,
1624                                                    instance_uuid)
1625 
1626     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1627     def _sync_scheduler_instance_info(self, context):
1628         if not self.send_instance_updates:
1629             return
1630         context = context.elevated()
1631         instances = objects.InstanceList.get_by_host(context, self.host,
1632                                                      expected_attrs=[],
1633                                                      use_slave=True)
1634         uuids = [instance.uuid for instance in instances]
1635         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1636 
1637     def _notify_about_instance_usage(self, context, instance, event_suffix,
1638                                      network_info=None, system_metadata=None,
1639                                      extra_usage_info=None, fault=None):
1640         compute_utils.notify_about_instance_usage(
1641             self.notifier, context, instance, event_suffix,
1642             network_info=network_info,
1643             system_metadata=system_metadata,
1644             extra_usage_info=extra_usage_info, fault=fault)
1645 
1646     def _deallocate_network(self, context, instance,
1647                             requested_networks=None):
1648         # If we were told not to allocate networks let's save ourselves
1649         # the trouble of calling the network API.
1650         if requested_networks and requested_networks.no_allocate:
1651             LOG.debug("Skipping network deallocation for instance since "
1652                       "networking was not requested.", instance=instance)
1653             return
1654 
1655         LOG.debug('Deallocating network for instance', instance=instance)
1656         with timeutils.StopWatch() as timer:
1657             self.network_api.deallocate_for_instance(
1658                 context, instance, requested_networks=requested_networks)
1659         # nova-network does an rpc call so we're OK tracking time spent here
1660         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1661                  timer.elapsed(), instance=instance)
1662 
1663     def _get_instance_block_device_info(self, context, instance,
1664                                         refresh_conn_info=False,
1665                                         bdms=None):
1666         """Transform block devices to the driver block_device format."""
1667 
1668         if not bdms:
1669             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1670                     context, instance.uuid)
1671         block_device_info = driver.get_block_device_info(instance, bdms)
1672 
1673         if not refresh_conn_info:
1674             # if the block_device_mapping has no value in connection_info
1675             # (returned as None), don't include in the mapping
1676             block_device_info['block_device_mapping'] = [
1677                 bdm for bdm in driver.block_device_info_get_mapping(
1678                                     block_device_info)
1679                 if bdm.get('connection_info')]
1680         else:
1681             driver_block_device.refresh_conn_infos(
1682                 driver.block_device_info_get_mapping(block_device_info),
1683                 context, instance, self.volume_api, self.driver)
1684 
1685         self._block_device_info_to_legacy(block_device_info)
1686 
1687         return block_device_info
1688 
1689     def _build_failed(self):
1690         self._failed_builds += 1
1691         limit = CONF.compute.consecutive_build_service_disable_threshold
1692         if limit and self._failed_builds >= limit:
1693             # NOTE(danms): If we're doing a bunch of parallel builds,
1694             # it is possible (although not likely) that we have already
1695             # failed N-1 builds before this and we race with a successful
1696             # build and disable ourselves here when we might've otherwise
1697             # not.
1698             LOG.error('Disabling service due to %(fails)i '
1699                       'consecutive build failures',
1700                       {'fails': self._failed_builds})
1701             ctx = nova.context.get_admin_context()
1702             service = objects.Service.get_by_compute_host(ctx, CONF.host)
1703             service.disabled = True
1704             service.disabled_reason = (
1705                 'Auto-disabled due to %i build failures' % self._failed_builds)
1706             service.save()
1707             # NOTE(danms): Reset our counter now so that when the admin
1708             # re-enables us we can start fresh
1709             self._failed_builds = 0
1710         elif self._failed_builds > 1:
1711             LOG.warning('%(fails)i consecutive build failures',
1712                         {'fails': self._failed_builds})
1713 
1714     @wrap_exception()
1715     @reverts_task_state
1716     @wrap_instance_fault
1717     def build_and_run_instance(self, context, instance, image, request_spec,
1718                      filter_properties, admin_password=None,
1719                      injected_files=None, requested_networks=None,
1720                      security_groups=None, block_device_mapping=None,
1721                      node=None, limits=None):
1722 
1723         @utils.synchronized(instance.uuid)
1724         def _locked_do_build_and_run_instance(*args, **kwargs):
1725             # NOTE(danms): We grab the semaphore with the instance uuid
1726             # locked because we could wait in line to build this instance
1727             # for a while and we want to make sure that nothing else tries
1728             # to do anything with this instance while we wait.
1729             with self._build_semaphore:
1730                 try:
1731                     result = self._do_build_and_run_instance(*args, **kwargs)
1732                 except Exception:
1733                     result = build_results.FAILED
1734                     raise
1735                 finally:
1736                     fails = (build_results.FAILED,
1737                              build_results.RESCHEDULED)
1738                     if result in fails:
1739                         self._build_failed()
1740                     else:
1741                         self._failed_builds = 0
1742 
1743         # NOTE(danms): We spawn here to return the RPC worker thread back to
1744         # the pool. Since what follows could take a really long time, we don't
1745         # want to tie up RPC workers.
1746         utils.spawn_n(_locked_do_build_and_run_instance,
1747                       context, instance, image, request_spec,
1748                       filter_properties, admin_password, injected_files,
1749                       requested_networks, security_groups,
1750                       block_device_mapping, node, limits)
1751 
1752     def _check_device_tagging(self, requested_networks, block_device_mapping):
1753         tagging_requested = False
1754         if requested_networks:
1755             for net in requested_networks:
1756                 if 'tag' in net and net.tag is not None:
1757                     tagging_requested = True
1758                     break
1759         if block_device_mapping and not tagging_requested:
1760             for bdm in block_device_mapping:
1761                 if 'tag' in bdm and bdm.tag is not None:
1762                     tagging_requested = True
1763                     break
1764         if (tagging_requested and
1765                 not self.driver.capabilities.get('supports_device_tagging')):
1766             raise exception.BuildAbortException('Attempt to boot guest with '
1767                                                 'tagged devices on host that '
1768                                                 'does not support tagging.')
1769 
1770     @hooks.add_hook('build_instance')
1771     @wrap_exception()
1772     @reverts_task_state
1773     @wrap_instance_event(prefix='compute')
1774     @wrap_instance_fault
1775     def _do_build_and_run_instance(self, context, instance, image,
1776             request_spec, filter_properties, admin_password, injected_files,
1777             requested_networks, security_groups, block_device_mapping,
1778             node=None, limits=None):
1779 
1780         try:
1781             LOG.debug('Starting instance...', instance=instance)
1782             instance.vm_state = vm_states.BUILDING
1783             instance.task_state = None
1784             instance.save(expected_task_state=
1785                     (task_states.SCHEDULING, None))
1786         except exception.InstanceNotFound:
1787             msg = 'Instance disappeared before build.'
1788             LOG.debug(msg, instance=instance)
1789             return build_results.FAILED
1790         except exception.UnexpectedTaskStateError as e:
1791             LOG.debug(e.format_message(), instance=instance)
1792             return build_results.FAILED
1793 
1794         # b64 decode the files to inject:
1795         decoded_files = self._decode_files(injected_files)
1796 
1797         if limits is None:
1798             limits = {}
1799 
1800         if node is None:
1801             node = self.driver.get_available_nodes(refresh=True)[0]
1802             LOG.debug('No node specified, defaulting to %s', node,
1803                       instance=instance)
1804 
1805         try:
1806             with timeutils.StopWatch() as timer:
1807                 self._build_and_run_instance(context, instance, image,
1808                         decoded_files, admin_password, requested_networks,
1809                         security_groups, block_device_mapping, node, limits,
1810                         filter_properties)
1811             LOG.info('Took %0.2f seconds to build instance.',
1812                      timer.elapsed(), instance=instance)
1813             return build_results.ACTIVE
1814         except exception.RescheduledException as e:
1815             retry = filter_properties.get('retry')
1816             if not retry:
1817                 # no retry information, do not reschedule.
1818                 LOG.debug("Retry info not present, will not reschedule",
1819                     instance=instance)
1820                 self._cleanup_allocated_networks(context, instance,
1821                     requested_networks)
1822                 compute_utils.add_instance_fault_from_exc(context,
1823                         instance, e, sys.exc_info(),
1824                         fault_message=e.kwargs['reason'])
1825                 self._nil_out_instance_obj_host_and_node(instance)
1826                 self._set_instance_obj_error_state(context, instance,
1827                                                    clean_task_state=True)
1828                 return build_results.FAILED
1829             LOG.debug(e.format_message(), instance=instance)
1830             # This will be used for logging the exception
1831             retry['exc'] = traceback.format_exception(*sys.exc_info())
1832             # This will be used for setting the instance fault message
1833             retry['exc_reason'] = e.kwargs['reason']
1834             # NOTE(comstud): Deallocate networks if the driver wants
1835             # us to do so.
1836             # NOTE(vladikr): SR-IOV ports should be deallocated to
1837             # allow new sriov pci devices to be allocated on a new host.
1838             # Otherwise, if devices with pci addresses are already allocated
1839             # on the destination host, the instance will fail to spawn.
1840             # info_cache.network_info should be present at this stage.
1841             if (self.driver.deallocate_networks_on_reschedule(instance) or
1842                 self.deallocate_sriov_ports_on_reschedule(instance)):
1843                 self._cleanup_allocated_networks(context, instance,
1844                         requested_networks)
1845             else:
1846                 # NOTE(alex_xu): Network already allocated and we don't
1847                 # want to deallocate them before rescheduling. But we need
1848                 # to cleanup those network resources setup on this host before
1849                 # rescheduling.
1850                 self.network_api.cleanup_instance_network_on_host(
1851                     context, instance, self.host)
1852 
1853             self._nil_out_instance_obj_host_and_node(instance)
1854             instance.task_state = task_states.SCHEDULING
1855             instance.save()
1856 
1857             self.compute_task_api.build_instances(context, [instance],
1858                     image, filter_properties, admin_password,
1859                     injected_files, requested_networks, security_groups,
1860                     block_device_mapping)
1861             return build_results.RESCHEDULED
1862         except (exception.InstanceNotFound,
1863                 exception.UnexpectedDeletingTaskStateError):
1864             msg = 'Instance disappeared during build.'
1865             LOG.debug(msg, instance=instance)
1866             self._cleanup_allocated_networks(context, instance,
1867                     requested_networks)
1868             return build_results.FAILED
1869         except exception.BuildAbortException as e:
1870             LOG.exception(e.format_message(), instance=instance)
1871             self._cleanup_allocated_networks(context, instance,
1872                     requested_networks)
1873             self._cleanup_volumes(context, instance.uuid,
1874                     block_device_mapping, raise_exc=False)
1875             compute_utils.add_instance_fault_from_exc(context, instance,
1876                     e, sys.exc_info())
1877             self._nil_out_instance_obj_host_and_node(instance)
1878             self._set_instance_obj_error_state(context, instance,
1879                                                clean_task_state=True)
1880             return build_results.FAILED
1881         except Exception as e:
1882             # Should not reach here.
1883             LOG.exception('Unexpected build failure, not rescheduling build.',
1884                           instance=instance)
1885             self._cleanup_allocated_networks(context, instance,
1886                     requested_networks)
1887             self._cleanup_volumes(context, instance.uuid,
1888                     block_device_mapping, raise_exc=False)
1889             compute_utils.add_instance_fault_from_exc(context, instance,
1890                     e, sys.exc_info())
1891             self._nil_out_instance_obj_host_and_node(instance)
1892             self._set_instance_obj_error_state(context, instance,
1893                                                clean_task_state=True)
1894             return build_results.FAILED
1895 
1896     def deallocate_sriov_ports_on_reschedule(self, instance):
1897         """Determine if networks are needed to be deallocated before reschedule
1898 
1899         Check the cached network info for any assigned SR-IOV ports.
1900         SR-IOV ports should be deallocated prior to rescheduling
1901         in order to allow new sriov pci devices to be allocated on a new host.
1902         """
1903         info_cache = instance.info_cache
1904 
1905         def _has_sriov_port(vif):
1906             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1907 
1908         if (info_cache and info_cache.network_info):
1909             for vif in info_cache.network_info:
1910                 if _has_sriov_port(vif):
1911                     return True
1912         return False
1913 
1914     def _build_and_run_instance(self, context, instance, image, injected_files,
1915             admin_password, requested_networks, security_groups,
1916             block_device_mapping, node, limits, filter_properties):
1917 
1918         image_name = image.get('name')
1919         self._notify_about_instance_usage(context, instance, 'create.start',
1920                 extra_usage_info={'image_name': image_name})
1921         compute_utils.notify_about_instance_action(
1922             context, instance, self.host,
1923             action=fields.NotificationAction.CREATE,
1924             phase=fields.NotificationPhase.START)
1925 
1926         # NOTE(mikal): cache the keystone roles associated with the instance
1927         # at boot time for later reference
1928         instance.system_metadata.update(
1929             {'boot_roles': ','.join(context.roles)})
1930 
1931         self._check_device_tagging(requested_networks, block_device_mapping)
1932 
1933         try:
1934             rt = self._get_resource_tracker()
1935             with rt.instance_claim(context, instance, node, limits):
1936                 # NOTE(russellb) It's important that this validation be done
1937                 # *after* the resource tracker instance claim, as that is where
1938                 # the host is set on the instance.
1939                 self._validate_instance_group_policy(context, instance,
1940                         filter_properties)
1941                 image_meta = objects.ImageMeta.from_dict(image)
1942                 with self._build_resources(context, instance,
1943                         requested_networks, security_groups, image_meta,
1944                         block_device_mapping) as resources:
1945                     instance.vm_state = vm_states.BUILDING
1946                     instance.task_state = task_states.SPAWNING
1947                     # NOTE(JoshNang) This also saves the changes to the
1948                     # instance from _allocate_network_async, as they aren't
1949                     # saved in that function to prevent races.
1950                     instance.save(expected_task_state=
1951                             task_states.BLOCK_DEVICE_MAPPING)
1952                     block_device_info = resources['block_device_info']
1953                     network_info = resources['network_info']
1954                     LOG.debug('Start spawning the instance on the hypervisor.',
1955                               instance=instance)
1956                     with timeutils.StopWatch() as timer:
1957                         self.driver.spawn(context, instance, image_meta,
1958                                           injected_files, admin_password,
1959                                           network_info=network_info,
1960                                           block_device_info=block_device_info)
1961                     LOG.info('Took %0.2f seconds to spawn the instance on '
1962                              'the hypervisor.', timer.elapsed(),
1963                              instance=instance)
1964         except (exception.InstanceNotFound,
1965                 exception.UnexpectedDeletingTaskStateError) as e:
1966             with excutils.save_and_reraise_exception():
1967                 self._notify_about_instance_usage(context, instance,
1968                     'create.error', fault=e)
1969                 compute_utils.notify_about_instance_action(
1970                     context, instance, self.host,
1971                     action=fields.NotificationAction.CREATE,
1972                     phase=fields.NotificationPhase.ERROR, exception=e)
1973         except exception.ComputeResourcesUnavailable as e:
1974             LOG.debug(e.format_message(), instance=instance)
1975             self._notify_about_instance_usage(context, instance,
1976                     'create.error', fault=e)
1977             compute_utils.notify_about_instance_action(
1978                     context, instance, self.host,
1979                     action=fields.NotificationAction.CREATE,
1980                     phase=fields.NotificationPhase.ERROR, exception=e)
1981             raise exception.RescheduledException(
1982                     instance_uuid=instance.uuid, reason=e.format_message())
1983         except exception.BuildAbortException as e:
1984             with excutils.save_and_reraise_exception():
1985                 LOG.debug(e.format_message(), instance=instance)
1986                 self._notify_about_instance_usage(context, instance,
1987                     'create.error', fault=e)
1988                 compute_utils.notify_about_instance_action(
1989                     context, instance, self.host,
1990                     action=fields.NotificationAction.CREATE,
1991                     phase=fields.NotificationPhase.ERROR, exception=e)
1992         except (exception.FixedIpLimitExceeded,
1993                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
1994             LOG.warning('No more network or fixed IP to be allocated',
1995                         instance=instance)
1996             self._notify_about_instance_usage(context, instance,
1997                     'create.error', fault=e)
1998             compute_utils.notify_about_instance_action(
1999                     context, instance, self.host,
2000                     action=fields.NotificationAction.CREATE,
2001                     phase=fields.NotificationPhase.ERROR, exception=e)
2002             msg = _('Failed to allocate the network(s) with error %s, '
2003                     'not rescheduling.') % e.format_message()
2004             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2005                     reason=msg)
2006         except (exception.VirtualInterfaceCreateException,
2007                 exception.VirtualInterfaceMacAddressException,
2008                 exception.FixedIpInvalidOnHost,
2009                 exception.UnableToAutoAllocateNetwork) as e:
2010             LOG.exception('Failed to allocate network(s)',
2011                           instance=instance)
2012             self._notify_about_instance_usage(context, instance,
2013                     'create.error', fault=e)
2014             compute_utils.notify_about_instance_action(
2015                     context, instance, self.host,
2016                     action=fields.NotificationAction.CREATE,
2017                     phase=fields.NotificationPhase.ERROR, exception=e)
2018             msg = _('Failed to allocate the network(s), not rescheduling.')
2019             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2020                     reason=msg)
2021         except (exception.FlavorDiskTooSmall,
2022                 exception.FlavorMemoryTooSmall,
2023                 exception.ImageNotActive,
2024                 exception.ImageUnacceptable,
2025                 exception.InvalidDiskInfo,
2026                 exception.InvalidDiskFormat,
2027                 cursive_exception.SignatureVerificationError,
2028                 exception.VolumeEncryptionNotSupported,
2029                 exception.InvalidInput) as e:
2030             self._notify_about_instance_usage(context, instance,
2031                     'create.error', fault=e)
2032             compute_utils.notify_about_instance_action(
2033                     context, instance, self.host,
2034                     action=fields.NotificationAction.CREATE,
2035                     phase=fields.NotificationPhase.ERROR, exception=e)
2036             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2037                     reason=e.format_message())
2038         except Exception as e:
2039             self._notify_about_instance_usage(context, instance,
2040                     'create.error', fault=e)
2041             compute_utils.notify_about_instance_action(
2042                     context, instance, self.host,
2043                     action=fields.NotificationAction.CREATE,
2044                     phase=fields.NotificationPhase.ERROR, exception=e)
2045             raise exception.RescheduledException(
2046                     instance_uuid=instance.uuid, reason=six.text_type(e))
2047 
2048         # NOTE(alaski): This is only useful during reschedules, remove it now.
2049         instance.system_metadata.pop('network_allocated', None)
2050 
2051         # If CONF.default_access_ip_network_name is set, grab the
2052         # corresponding network and set the access ip values accordingly.
2053         network_name = CONF.default_access_ip_network_name
2054         if (network_name and not instance.access_ip_v4 and
2055                 not instance.access_ip_v6):
2056             # Note that when there are multiple ips to choose from, an
2057             # arbitrary one will be chosen.
2058             for vif in network_info:
2059                 if vif['network']['label'] == network_name:
2060                     for ip in vif.fixed_ips():
2061                         if not instance.access_ip_v4 and ip['version'] == 4:
2062                             instance.access_ip_v4 = ip['address']
2063                         if not instance.access_ip_v6 and ip['version'] == 6:
2064                             instance.access_ip_v6 = ip['address']
2065                     break
2066 
2067         self._update_instance_after_spawn(context, instance)
2068 
2069         try:
2070             instance.save(expected_task_state=task_states.SPAWNING)
2071         except (exception.InstanceNotFound,
2072                 exception.UnexpectedDeletingTaskStateError) as e:
2073             with excutils.save_and_reraise_exception():
2074                 self._notify_about_instance_usage(context, instance,
2075                     'create.error', fault=e)
2076                 compute_utils.notify_about_instance_action(
2077                     context, instance, self.host,
2078                     action=fields.NotificationAction.CREATE,
2079                     phase=fields.NotificationPhase.ERROR, exception=e)
2080 
2081         self._update_scheduler_instance_info(context, instance)
2082         self._notify_about_instance_usage(context, instance, 'create.end',
2083                 extra_usage_info={'message': _('Success')},
2084                 network_info=network_info)
2085         compute_utils.notify_about_instance_action(context, instance,
2086                 self.host, action=fields.NotificationAction.CREATE,
2087                 phase=fields.NotificationPhase.END)
2088 
2089     @contextlib.contextmanager
2090     def _build_resources(self, context, instance, requested_networks,
2091                          security_groups, image_meta, block_device_mapping):
2092         resources = {}
2093         network_info = None
2094         try:
2095             LOG.debug('Start building networks asynchronously for instance.',
2096                       instance=instance)
2097             network_info = self._build_networks_for_instance(context, instance,
2098                     requested_networks, security_groups)
2099             resources['network_info'] = network_info
2100         except (exception.InstanceNotFound,
2101                 exception.UnexpectedDeletingTaskStateError):
2102             raise
2103         except exception.UnexpectedTaskStateError as e:
2104             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2105                     reason=e.format_message())
2106         except Exception:
2107             # Because this allocation is async any failures are likely to occur
2108             # when the driver accesses network_info during spawn().
2109             LOG.exception('Failed to allocate network(s)',
2110                           instance=instance)
2111             msg = _('Failed to allocate the network(s), not rescheduling.')
2112             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2113                     reason=msg)
2114 
2115         try:
2116             # Verify that all the BDMs have a device_name set and assign a
2117             # default to the ones missing it with the help of the driver.
2118             self._default_block_device_names(instance, image_meta,
2119                                              block_device_mapping)
2120 
2121             LOG.debug('Start building block device mappings for instance.',
2122                       instance=instance)
2123             instance.vm_state = vm_states.BUILDING
2124             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2125             instance.save()
2126 
2127             block_device_info = self._prep_block_device(context, instance,
2128                     block_device_mapping)
2129             resources['block_device_info'] = block_device_info
2130         except (exception.InstanceNotFound,
2131                 exception.UnexpectedDeletingTaskStateError):
2132             with excutils.save_and_reraise_exception():
2133                 # Make sure the async call finishes
2134                 if network_info is not None:
2135                     network_info.wait(do_raise=False)
2136         except (exception.UnexpectedTaskStateError,
2137                 exception.OverQuota, exception.InvalidBDM) as e:
2138             # Make sure the async call finishes
2139             if network_info is not None:
2140                 network_info.wait(do_raise=False)
2141             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2142                     reason=e.format_message())
2143         except Exception:
2144             LOG.exception('Failure prepping block device',
2145                           instance=instance)
2146             # Make sure the async call finishes
2147             if network_info is not None:
2148                 network_info.wait(do_raise=False)
2149             msg = _('Failure prepping block device.')
2150             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2151                     reason=msg)
2152 
2153         try:
2154             yield resources
2155         except Exception as exc:
2156             with excutils.save_and_reraise_exception() as ctxt:
2157                 if not isinstance(exc, (
2158                         exception.InstanceNotFound,
2159                         exception.UnexpectedDeletingTaskStateError)):
2160                     LOG.exception('Instance failed to spawn',
2161                                   instance=instance)
2162                 # Make sure the async call finishes
2163                 if network_info is not None:
2164                     network_info.wait(do_raise=False)
2165                 # if network_info is empty we're likely here because of
2166                 # network allocation failure. Since nothing can be reused on
2167                 # rescheduling it's better to deallocate network to eliminate
2168                 # the chance of orphaned ports in neutron
2169                 deallocate_networks = False if network_info else True
2170                 try:
2171                     self._shutdown_instance(context, instance,
2172                             block_device_mapping, requested_networks,
2173                             try_deallocate_networks=deallocate_networks)
2174                 except Exception as exc2:
2175                     ctxt.reraise = False
2176                     LOG.warning('Could not clean up failed build,'
2177                                 ' not rescheduling. Error: %s',
2178                                 six.text_type(exc2))
2179                     raise exception.BuildAbortException(
2180                             instance_uuid=instance.uuid,
2181                             reason=six.text_type(exc))
2182 
2183     def _cleanup_allocated_networks(self, context, instance,
2184             requested_networks):
2185         try:
2186             self._deallocate_network(context, instance, requested_networks)
2187         except Exception:
2188             LOG.exception('Failed to deallocate networks', instance=instance)
2189             return
2190 
2191         instance.system_metadata['network_allocated'] = 'False'
2192         try:
2193             instance.save()
2194         except exception.InstanceNotFound:
2195             # NOTE(alaski): It's possible that we're cleaning up the networks
2196             # because the instance was deleted.  If that's the case then this
2197             # exception will be raised by instance.save()
2198             pass
2199 
2200     def _try_deallocate_network(self, context, instance,
2201                                 requested_networks=None):
2202         try:
2203             # tear down allocated network structure
2204             self._deallocate_network(context, instance, requested_networks)
2205         except Exception as ex:
2206             with excutils.save_and_reraise_exception():
2207                 LOG.error('Failed to deallocate network for instance. '
2208                           'Error: %s', ex, instance=instance)
2209                 self._set_instance_obj_error_state(context, instance)
2210 
2211     def _get_power_off_values(self, context, instance, clean_shutdown):
2212         """Get the timing configuration for powering down this instance."""
2213         if clean_shutdown:
2214             timeout = compute_utils.get_value_from_system_metadata(instance,
2215                           key='image_os_shutdown_timeout', type=int,
2216                           default=CONF.shutdown_timeout)
2217             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2218         else:
2219             timeout = 0
2220             retry_interval = 0
2221 
2222         return timeout, retry_interval
2223 
2224     def _power_off_instance(self, context, instance, clean_shutdown=True):
2225         """Power off an instance on this host."""
2226         timeout, retry_interval = self._get_power_off_values(context,
2227                                         instance, clean_shutdown)
2228         self.driver.power_off(instance, timeout, retry_interval)
2229 
2230     def _shutdown_instance(self, context, instance,
2231                            bdms, requested_networks=None, notify=True,
2232                            try_deallocate_networks=True):
2233         """Shutdown an instance on this host.
2234 
2235         :param:context: security context
2236         :param:instance: a nova.objects.Instance object
2237         :param:bdms: the block devices for the instance to be torn
2238                      down
2239         :param:requested_networks: the networks on which the instance
2240                                    has ports
2241         :param:notify: true if a final usage notification should be
2242                        emitted
2243         :param:try_deallocate_networks: false if we should avoid
2244                                         trying to teardown networking
2245         """
2246         context = context.elevated()
2247         LOG.info('Terminating instance', instance=instance)
2248 
2249         if notify:
2250             self._notify_about_instance_usage(context, instance,
2251                                               "shutdown.start")
2252             compute_utils.notify_about_instance_action(context, instance,
2253                     self.host, action=fields.NotificationAction.SHUTDOWN,
2254                     phase=fields.NotificationPhase.START)
2255 
2256         network_info = compute_utils.get_nw_info_for_instance(instance)
2257 
2258         # NOTE(vish) get bdms before destroying the instance
2259         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2260         block_device_info = self._get_instance_block_device_info(
2261             context, instance, bdms=bdms)
2262 
2263         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2264         #                want to keep ip allocated for certain failures
2265         timer = timeutils.StopWatch()
2266         try:
2267             LOG.debug('Start destroying the instance on the hypervisor.',
2268                       instance=instance)
2269             timer.start()
2270             self.driver.destroy(context, instance, network_info,
2271                     block_device_info)
2272             LOG.info('Took %0.2f seconds to destroy the instance on the '
2273                      'hypervisor.', timer.elapsed(), instance=instance)
2274         except exception.InstancePowerOffFailure:
2275             # if the instance can't power off, don't release the ip
2276             with excutils.save_and_reraise_exception():
2277                 pass
2278         except Exception:
2279             with excutils.save_and_reraise_exception():
2280                 # deallocate ip and fail without proceeding to
2281                 # volume api calls, preserving current behavior
2282                 if try_deallocate_networks:
2283                     self._try_deallocate_network(context, instance,
2284                                                  requested_networks)
2285 
2286         if try_deallocate_networks:
2287             self._try_deallocate_network(context, instance, requested_networks)
2288 
2289         timer.restart()
2290         for bdm in vol_bdms:
2291             try:
2292                 if bdm.attachment_id:
2293                     self.volume_api.attachment_delete(context,
2294                                                       bdm.attachment_id)
2295                 else:
2296                     # NOTE(vish): actual driver detach done in driver.destroy,
2297                     #             so just tell cinder that we are done with it.
2298                     connector = self.driver.get_volume_connector(instance)
2299                     self.volume_api.terminate_connection(context,
2300                                                          bdm.volume_id,
2301                                                          connector)
2302                     self.volume_api.detach(context, bdm.volume_id,
2303                                            instance.uuid)
2304 
2305             except exception.VolumeAttachmentNotFound as exc:
2306                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2307                           instance=instance)
2308             except exception.DiskNotFound as exc:
2309                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2310                           instance=instance)
2311             except exception.VolumeNotFound as exc:
2312                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2313                           instance=instance)
2314             except (cinder_exception.EndpointNotFound,
2315                     keystone_exception.EndpointNotFound) as exc:
2316                 LOG.warning('Ignoring EndpointNotFound for '
2317                             'volume %(volume_id)s: %(exc)s',
2318                             {'exc': exc, 'volume_id': bdm.volume_id},
2319                             instance=instance)
2320             except cinder_exception.ClientException as exc:
2321                 LOG.warning('Ignoring unknown cinder exception for '
2322                             'volume %(volume_id)s: %(exc)s',
2323                             {'exc': exc, 'volume_id': bdm.volume_id},
2324                             instance=instance)
2325             except Exception as exc:
2326                 LOG.warning('Ignoring unknown exception for '
2327                             'volume %(volume_id)s: %(exc)s',
2328                             {'exc': exc, 'volume_id': bdm.volume_id},
2329                             instance=instance)
2330         if vol_bdms:
2331             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2332                      'for instance.',
2333                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2334                      instance=instance)
2335 
2336         if notify:
2337             self._notify_about_instance_usage(context, instance,
2338                                               "shutdown.end")
2339             compute_utils.notify_about_instance_action(context, instance,
2340                     self.host, action=fields.NotificationAction.SHUTDOWN,
2341                     phase=fields.NotificationPhase.END)
2342 
2343     def _cleanup_volumes(self, context, instance_uuid, bdms, raise_exc=True):
2344         exc_info = None
2345 
2346         for bdm in bdms:
2347             LOG.debug("terminating bdm %s", bdm,
2348                       instance_uuid=instance_uuid)
2349             if bdm.volume_id and bdm.delete_on_termination:
2350                 try:
2351                     self.volume_api.delete(context, bdm.volume_id)
2352                 except Exception as exc:
2353                     exc_info = sys.exc_info()
2354                     LOG.warning('Failed to delete volume: %(volume_id)s '
2355                                 'due to %(exc)s',
2356                                 {'volume_id': bdm.volume_id, 'exc': exc})
2357         if exc_info is not None and raise_exc:
2358             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2359 
2360     @hooks.add_hook("delete_instance")
2361     def _delete_instance(self, context, instance, bdms, quotas):
2362         """Delete an instance on this host.  Commit or rollback quotas
2363         as necessary.
2364 
2365         :param context: nova request context
2366         :param instance: nova.objects.instance.Instance object
2367         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2368         :param quotas: nova.objects.quotas.Quotas object
2369         """
2370         was_soft_deleted = instance.vm_state == vm_states.SOFT_DELETED
2371         if was_soft_deleted:
2372             # Instances in SOFT_DELETED vm_state have already had quotas
2373             # decremented.
2374             try:
2375                 quotas.rollback()
2376             except Exception:
2377                 pass
2378 
2379         try:
2380             events = self.instance_events.clear_events_for_instance(instance)
2381             if events:
2382                 LOG.debug('Events pending at deletion: %(events)s',
2383                           {'events': ','.join(events.keys())},
2384                           instance=instance)
2385             self._notify_about_instance_usage(context, instance,
2386                                               "delete.start")
2387             compute_utils.notify_about_instance_action(context, instance,
2388                     self.host, action=fields.NotificationAction.DELETE,
2389                     phase=fields.NotificationPhase.START)
2390 
2391             self._shutdown_instance(context, instance, bdms)
2392             # NOTE(dims): instance.info_cache.delete() should be called after
2393             # _shutdown_instance in the compute manager as shutdown calls
2394             # deallocate_for_instance so the info_cache is still needed
2395             # at this point.
2396             if instance.info_cache is not None:
2397                 instance.info_cache.delete()
2398             else:
2399                 # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2400                 # is None. When the root cause that instance.info_cache becomes
2401                 # None is fixed, the log level should be reconsidered.
2402                 LOG.warning("Info cache for instance could not be found. "
2403                             "Ignore.", instance=instance)
2404 
2405             # NOTE(vish): We have already deleted the instance, so we have
2406             #             to ignore problems cleaning up the volumes. It
2407             #             would be nice to let the user know somehow that
2408             #             the volume deletion failed, but it is not
2409             #             acceptable to have an instance that can not be
2410             #             deleted. Perhaps this could be reworked in the
2411             #             future to set an instance fault the first time
2412             #             and to only ignore the failure if the instance
2413             #             is already in ERROR.
2414             self._cleanup_volumes(context, instance.uuid, bdms,
2415                     raise_exc=False)
2416             # if a delete task succeeded, always update vm state and task
2417             # state without expecting task state to be DELETING
2418             instance.vm_state = vm_states.DELETED
2419             instance.task_state = None
2420             instance.power_state = power_state.NOSTATE
2421             instance.terminated_at = timeutils.utcnow()
2422             instance.save()
2423             system_meta = instance.system_metadata
2424             instance.destroy()
2425         except Exception:
2426             with excutils.save_and_reraise_exception():
2427                 quotas.rollback()
2428 
2429         self._complete_deletion(context,
2430                                 instance,
2431                                 bdms,
2432                                 quotas,
2433                                 system_meta)
2434 
2435     @wrap_exception()
2436     @reverts_task_state
2437     @wrap_instance_event(prefix='compute')
2438     @wrap_instance_fault
2439     def terminate_instance(self, context, instance, bdms, reservations):
2440         """Terminate an instance on this host."""
2441         quotas = objects.Quotas.from_reservations(context,
2442                                                   reservations,
2443                                                   instance=instance)
2444 
2445         @utils.synchronized(instance.uuid)
2446         def do_terminate_instance(instance, bdms):
2447             # NOTE(mriedem): If we are deleting the instance while it was
2448             # booting from volume, we could be racing with a database update of
2449             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2450             # to compute here, the BDMs may be stale at this point. So check
2451             # for any volume BDMs that don't have volume_id set and if we
2452             # detect that, we need to refresh the BDM list before proceeding.
2453             # TODO(mriedem): Move this into _delete_instance and make the bdms
2454             # parameter optional.
2455             for bdm in list(bdms):
2456                 if bdm.is_volume and not bdm.volume_id:
2457                     LOG.debug('There are potentially stale BDMs during '
2458                               'delete, refreshing the BlockDeviceMappingList.',
2459                               instance=instance)
2460                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2461                         context, instance.uuid)
2462                     break
2463             try:
2464                 self._delete_instance(context, instance, bdms, quotas)
2465             except exception.InstanceNotFound:
2466                 LOG.info("Instance disappeared during terminate",
2467                          instance=instance)
2468             except Exception:
2469                 # As we're trying to delete always go to Error if something
2470                 # goes wrong that _delete_instance can't handle.
2471                 with excutils.save_and_reraise_exception():
2472                     LOG.exception('Setting instance vm_state to ERROR',
2473                                   instance=instance)
2474                     self._set_instance_obj_error_state(context, instance)
2475 
2476         do_terminate_instance(instance, bdms)
2477 
2478     # NOTE(johannes): This is probably better named power_off_instance
2479     # so it matches the driver method, but because of other issues, we
2480     # can't use that name in grizzly.
2481     @wrap_exception()
2482     @reverts_task_state
2483     @wrap_instance_event(prefix='compute')
2484     @wrap_instance_fault
2485     def stop_instance(self, context, instance, clean_shutdown):
2486         """Stopping an instance on this host."""
2487 
2488         @utils.synchronized(instance.uuid)
2489         def do_stop_instance():
2490             current_power_state = self._get_power_state(context, instance)
2491             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2492                       'current task_state: %(task_state)s, current DB '
2493                       'power_state: %(db_power_state)s, current VM '
2494                       'power_state: %(current_power_state)s',
2495                       {'vm_state': instance.vm_state,
2496                        'task_state': instance.task_state,
2497                        'db_power_state': instance.power_state,
2498                        'current_power_state': current_power_state},
2499                       instance_uuid=instance.uuid)
2500 
2501             # NOTE(mriedem): If the instance is already powered off, we are
2502             # possibly tearing down and racing with other operations, so we can
2503             # expect the task_state to be None if something else updates the
2504             # instance and we're not locking it.
2505             expected_task_state = [task_states.POWERING_OFF]
2506             # The list of power states is from _sync_instance_power_state.
2507             if current_power_state in (power_state.NOSTATE,
2508                                        power_state.SHUTDOWN,
2509                                        power_state.CRASHED):
2510                 LOG.info('Instance is already powered off in the '
2511                          'hypervisor when stop is called.',
2512                          instance=instance)
2513                 expected_task_state.append(None)
2514 
2515             self._notify_about_instance_usage(context, instance,
2516                                               "power_off.start")
2517 
2518             compute_utils.notify_about_instance_action(context, instance,
2519                         self.host, action=fields.NotificationAction.POWER_OFF,
2520                         phase=fields.NotificationPhase.START)
2521 
2522             self._power_off_instance(context, instance, clean_shutdown)
2523             instance.power_state = self._get_power_state(context, instance)
2524             instance.vm_state = vm_states.STOPPED
2525             instance.task_state = None
2526             instance.save(expected_task_state=expected_task_state)
2527             self._notify_about_instance_usage(context, instance,
2528                                               "power_off.end")
2529 
2530             compute_utils.notify_about_instance_action(context, instance,
2531                         self.host, action=fields.NotificationAction.POWER_OFF,
2532                         phase=fields.NotificationPhase.END)
2533 
2534         do_stop_instance()
2535 
2536     def _power_on(self, context, instance):
2537         network_info = self.network_api.get_instance_nw_info(context, instance)
2538         block_device_info = self._get_instance_block_device_info(context,
2539                                                                  instance)
2540         self.driver.power_on(context, instance,
2541                              network_info,
2542                              block_device_info)
2543 
2544     def _delete_snapshot_of_shelved_instance(self, context, instance,
2545                                              snapshot_id):
2546         """Delete snapshot of shelved instance."""
2547         try:
2548             self.image_api.delete(context, snapshot_id)
2549         except (exception.ImageNotFound,
2550                 exception.ImageNotAuthorized) as exc:
2551             LOG.warning("Failed to delete snapshot "
2552                         "from shelved instance (%s).",
2553                         exc.format_message(), instance=instance)
2554         except Exception:
2555             LOG.exception("Something wrong happened when trying to "
2556                           "delete snapshot from shelved instance.",
2557                           instance=instance)
2558 
2559     # NOTE(johannes): This is probably better named power_on_instance
2560     # so it matches the driver method, but because of other issues, we
2561     # can't use that name in grizzly.
2562     @wrap_exception()
2563     @reverts_task_state
2564     @wrap_instance_event(prefix='compute')
2565     @wrap_instance_fault
2566     def start_instance(self, context, instance):
2567         """Starting an instance on this host."""
2568         self._notify_about_instance_usage(context, instance, "power_on.start")
2569         compute_utils.notify_about_instance_action(context, instance,
2570             self.host, action=fields.NotificationAction.POWER_ON,
2571             phase=fields.NotificationPhase.START)
2572         self._power_on(context, instance)
2573         instance.power_state = self._get_power_state(context, instance)
2574         instance.vm_state = vm_states.ACTIVE
2575         instance.task_state = None
2576 
2577         # Delete an image(VM snapshot) for a shelved instance
2578         snapshot_id = instance.system_metadata.get('shelved_image_id')
2579         if snapshot_id:
2580             self._delete_snapshot_of_shelved_instance(context, instance,
2581                                                       snapshot_id)
2582 
2583         # Delete system_metadata for a shelved instance
2584         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2585 
2586         instance.save(expected_task_state=task_states.POWERING_ON)
2587         self._notify_about_instance_usage(context, instance, "power_on.end")
2588         compute_utils.notify_about_instance_action(context, instance,
2589             self.host, action=fields.NotificationAction.POWER_ON,
2590             phase=fields.NotificationPhase.END)
2591 
2592     @messaging.expected_exceptions(NotImplementedError,
2593                                    exception.TriggerCrashDumpNotSupported,
2594                                    exception.InstanceNotRunning)
2595     @wrap_exception()
2596     @wrap_instance_event(prefix='compute')
2597     @wrap_instance_fault
2598     def trigger_crash_dump(self, context, instance):
2599         """Trigger crash dump in an instance."""
2600 
2601         self._notify_about_instance_usage(context, instance,
2602                                           "trigger_crash_dump.start")
2603 
2604         # This method does not change task_state and power_state because the
2605         # effect of a trigger depends on user's configuration.
2606         self.driver.trigger_crash_dump(instance)
2607 
2608         self._notify_about_instance_usage(context, instance,
2609                                           "trigger_crash_dump.end")
2610 
2611     @wrap_exception()
2612     @reverts_task_state
2613     @wrap_instance_event(prefix='compute')
2614     @wrap_instance_fault
2615     def soft_delete_instance(self, context, instance, reservations):
2616         """Soft delete an instance on this host."""
2617 
2618         quotas = objects.Quotas.from_reservations(context,
2619                                                   reservations,
2620                                                   instance=instance)
2621         try:
2622             self._notify_about_instance_usage(context, instance,
2623                                               "soft_delete.start")
2624             try:
2625                 self.driver.soft_delete(instance)
2626             except NotImplementedError:
2627                 # Fallback to just powering off the instance if the
2628                 # hypervisor doesn't implement the soft_delete method
2629                 self.driver.power_off(instance)
2630             instance.power_state = self._get_power_state(context, instance)
2631             instance.vm_state = vm_states.SOFT_DELETED
2632             instance.task_state = None
2633             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2634         except Exception:
2635             with excutils.save_and_reraise_exception():
2636                 quotas.rollback()
2637         quotas.commit()
2638         self._notify_about_instance_usage(context, instance, "soft_delete.end")
2639 
2640     @wrap_exception()
2641     @reverts_task_state
2642     @wrap_instance_event(prefix='compute')
2643     @wrap_instance_fault
2644     def restore_instance(self, context, instance):
2645         """Restore a soft-deleted instance on this host."""
2646         self._notify_about_instance_usage(context, instance, "restore.start")
2647         compute_utils.notify_about_instance_action(context, instance,
2648             self.host, action=fields.NotificationAction.RESTORE,
2649             phase=fields.NotificationPhase.START)
2650         try:
2651             self.driver.restore(instance)
2652         except NotImplementedError:
2653             # Fallback to just powering on the instance if the hypervisor
2654             # doesn't implement the restore method
2655             self._power_on(context, instance)
2656         instance.power_state = self._get_power_state(context, instance)
2657         instance.vm_state = vm_states.ACTIVE
2658         instance.task_state = None
2659         instance.save(expected_task_state=task_states.RESTORING)
2660         self._notify_about_instance_usage(context, instance, "restore.end")
2661         compute_utils.notify_about_instance_action(context, instance,
2662             self.host, action=fields.NotificationAction.RESTORE,
2663             phase=fields.NotificationPhase.END)
2664 
2665     @staticmethod
2666     def _set_migration_status(migration, status):
2667         """Set the status, and guard against a None being passed in.
2668 
2669         This is useful as some of the compute RPC calls will not pass
2670         a migration object in older versions. The check can be removed when
2671         we move past 4.x major version of the RPC API.
2672         """
2673         if migration:
2674             migration.status = status
2675             migration.save()
2676 
2677     def _rebuild_default_impl(self, context, instance, image_meta,
2678                               injected_files, admin_password, bdms,
2679                               detach_block_devices, attach_block_devices,
2680                               network_info=None,
2681                               recreate=False, block_device_info=None,
2682                               preserve_ephemeral=False):
2683         if preserve_ephemeral:
2684             # The default code path does not support preserving ephemeral
2685             # partitions.
2686             raise exception.PreserveEphemeralNotSupported()
2687 
2688         if recreate:
2689             detach_block_devices(context, bdms)
2690         else:
2691             self._power_off_instance(context, instance, clean_shutdown=True)
2692             detach_block_devices(context, bdms)
2693             self.driver.destroy(context, instance,
2694                                 network_info=network_info,
2695                                 block_device_info=block_device_info)
2696 
2697         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2698         instance.save(expected_task_state=[task_states.REBUILDING])
2699 
2700         new_block_device_info = attach_block_devices(context, instance, bdms)
2701 
2702         instance.task_state = task_states.REBUILD_SPAWNING
2703         instance.save(
2704             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2705 
2706         with instance.mutated_migration_context():
2707             self.driver.spawn(context, instance, image_meta, injected_files,
2708                               admin_password, network_info=network_info,
2709                               block_device_info=new_block_device_info)
2710 
2711     def _notify_instance_rebuild_error(self, context, instance, error):
2712         self._notify_about_instance_usage(context, instance,
2713                                           'rebuild.error', fault=error)
2714         compute_utils.notify_about_instance_action(
2715             context, instance, self.host,
2716             action=fields.NotificationAction.REBUILD,
2717             phase=fields.NotificationPhase.ERROR, exception=error)
2718 
2719     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2720     @wrap_exception()
2721     @reverts_task_state
2722     @wrap_instance_event(prefix='compute')
2723     @wrap_instance_fault
2724     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2725                          injected_files, new_pass, orig_sys_metadata,
2726                          bdms, recreate, on_shared_storage=None,
2727                          preserve_ephemeral=False, migration=None,
2728                          scheduled_node=None, limits=None):
2729         """Destroy and re-make this instance.
2730 
2731         A 'rebuild' effectively purges all existing data from the system and
2732         remakes the VM with given 'metadata' and 'personalities'.
2733 
2734         :param context: `nova.RequestContext` object
2735         :param instance: Instance object
2736         :param orig_image_ref: Original image_ref before rebuild
2737         :param image_ref: New image_ref for rebuild
2738         :param injected_files: Files to inject
2739         :param new_pass: password to set on rebuilt instance
2740         :param orig_sys_metadata: instance system metadata from pre-rebuild
2741         :param bdms: block-device-mappings to use for rebuild
2742         :param recreate: True if the instance is being recreated (e.g. the
2743             hypervisor it was on failed) - cleanup of old state will be
2744             skipped.
2745         :param on_shared_storage: True if instance files on shared storage.
2746                                   If not provided then information from the
2747                                   driver will be used to decide if the instance
2748                                   files are available or not on the target host
2749         :param preserve_ephemeral: True if the default ephemeral storage
2750                                    partition must be preserved on rebuild
2751         :param migration: a Migration object if one was created for this
2752                           rebuild operation (if it's a part of evacuate)
2753         :param scheduled_node: A node of the host chosen by the scheduler. If a
2754                                host was specified by the user, this will be
2755                                None
2756         :param limits: Overcommit limits set by the scheduler. If a host was
2757                        specified by the user, this will be None
2758         """
2759         context = context.elevated()
2760 
2761         LOG.info("Rebuilding instance", instance=instance)
2762 
2763         # NOTE(gyee): there are three possible scenarios.
2764         #
2765         #   1. instance is being rebuilt on the same node. In this case,
2766         #      recreate should be False and scheduled_node should be None.
2767         #   2. instance is being rebuilt on a node chosen by the
2768         #      scheduler (i.e. evacuate). In this case, scheduled_node should
2769         #      be specified and recreate should be True.
2770         #   3. instance is being rebuilt on a node chosen by the user. (i.e.
2771         #      force evacuate). In this case, scheduled_node is not specified
2772         #      and recreate is set to True.
2773         #
2774         # For scenarios #2 and #3, we must do rebuild claim as server is
2775         # being evacuated to a different node.
2776         if recreate or scheduled_node is not None:
2777             rt = self._get_resource_tracker()
2778             rebuild_claim = rt.rebuild_claim
2779         else:
2780             rebuild_claim = claims.NopClaim
2781 
2782         image_meta = {}
2783         if image_ref:
2784             image_meta = self.image_api.get(context, image_ref)
2785 
2786         # NOTE(mriedem): On a recreate (evacuate), we need to update
2787         # the instance's host and node properties to reflect it's
2788         # destination node for the recreate.
2789         if not scheduled_node:
2790             if recreate:
2791                 try:
2792                     compute_node = self._get_compute_info(context, self.host)
2793                     scheduled_node = compute_node.hypervisor_hostname
2794                 except exception.ComputeHostNotFound:
2795                     LOG.exception('Failed to get compute_info for %s',
2796                                   self.host)
2797             else:
2798                 scheduled_node = instance.node
2799 
2800         with self._error_out_instance_on_exception(context, instance):
2801             try:
2802                 claim_ctxt = rebuild_claim(
2803                     context, instance, scheduled_node,
2804                     limits=limits, image_meta=image_meta,
2805                     migration=migration)
2806                 self._do_rebuild_instance_with_claim(
2807                     claim_ctxt, context, instance, orig_image_ref,
2808                     image_ref, injected_files, new_pass, orig_sys_metadata,
2809                     bdms, recreate, on_shared_storage, preserve_ephemeral)
2810             except exception.ComputeResourcesUnavailable as e:
2811                 LOG.debug("Could not rebuild instance on this host, not "
2812                           "enough resources available.", instance=instance)
2813 
2814                 # NOTE(ndipanov): We just abort the build for now and leave a
2815                 # migration record for potential cleanup later
2816                 self._set_migration_status(migration, 'failed')
2817                 self._notify_instance_rebuild_error(context, instance, e)
2818 
2819                 raise exception.BuildAbortException(
2820                     instance_uuid=instance.uuid, reason=e.format_message())
2821             except (exception.InstanceNotFound,
2822                     exception.UnexpectedDeletingTaskStateError) as e:
2823                 LOG.debug('Instance was deleted while rebuilding',
2824                           instance=instance)
2825                 self._set_migration_status(migration, 'failed')
2826                 self._notify_instance_rebuild_error(context, instance, e)
2827             except Exception as e:
2828                 self._set_migration_status(migration, 'failed')
2829                 self._notify_instance_rebuild_error(context, instance, e)
2830                 raise
2831             else:
2832                 instance.apply_migration_context()
2833                 # NOTE (ndipanov): This save will now update the host and node
2834                 # attributes making sure that next RT pass is consistent since
2835                 # it will be based on the instance and not the migration DB
2836                 # entry.
2837                 instance.host = self.host
2838                 instance.node = scheduled_node
2839                 instance.save()
2840                 instance.drop_migration_context()
2841 
2842                 # NOTE (ndipanov): Mark the migration as done only after we
2843                 # mark the instance as belonging to this host.
2844                 self._set_migration_status(migration, 'done')
2845 
2846     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2847         """Helper to avoid deep nesting in the top-level method."""
2848 
2849         with claim_context:
2850             self._do_rebuild_instance(*args, **kwargs)
2851 
2852     @staticmethod
2853     def _get_image_name(image_meta):
2854         if image_meta.obj_attr_is_set("name"):
2855             return image_meta.name
2856         else:
2857             return ''
2858 
2859     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2860                              image_ref, injected_files, new_pass,
2861                              orig_sys_metadata, bdms, recreate,
2862                              on_shared_storage, preserve_ephemeral):
2863         orig_vm_state = instance.vm_state
2864 
2865         if recreate:
2866             if not self.driver.capabilities["supports_recreate"]:
2867                 raise exception.InstanceRecreateNotSupported
2868 
2869             self._check_instance_exists(context, instance)
2870 
2871             if on_shared_storage is None:
2872                 LOG.debug('on_shared_storage is not provided, using driver'
2873                             'information to decide if the instance needs to'
2874                             'be recreated')
2875                 on_shared_storage = self.driver.instance_on_disk(instance)
2876 
2877             elif (on_shared_storage !=
2878                     self.driver.instance_on_disk(instance)):
2879                 # To cover case when admin expects that instance files are
2880                 # on shared storage, but not accessible and vice versa
2881                 raise exception.InvalidSharedStorage(
2882                         _("Invalid state of instance files on shared"
2883                             " storage"))
2884 
2885             if on_shared_storage:
2886                 LOG.info('disk on shared storage, recreating using'
2887                          ' existing disk')
2888             else:
2889                 image_ref = orig_image_ref = instance.image_ref
2890                 LOG.info("disk not on shared storage, rebuilding from:"
2891                          " '%s'", str(image_ref))
2892 
2893         if image_ref:
2894             image_meta = objects.ImageMeta.from_image_ref(
2895                 context, self.image_api, image_ref)
2896         else:
2897             image_meta = instance.image_meta
2898 
2899         # This instance.exists message should contain the original
2900         # image_ref, not the new one.  Since the DB has been updated
2901         # to point to the new one... we have to override it.
2902         # TODO(jaypipes): Move generate_image_url() into the nova.image.api
2903         orig_image_ref_url = glance.generate_image_url(orig_image_ref)
2904         extra_usage_info = {'image_ref_url': orig_image_ref_url}
2905         compute_utils.notify_usage_exists(
2906                 self.notifier, context, instance,
2907                 current_period=True, system_metadata=orig_sys_metadata,
2908                 extra_usage_info=extra_usage_info)
2909 
2910         # This message should contain the new image_ref
2911         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
2912         self._notify_about_instance_usage(context, instance,
2913                 "rebuild.start", extra_usage_info=extra_usage_info)
2914         # NOTE: image_name is not included in the versioned notification
2915         # because we already provide the image_uuid in the notification
2916         # payload and the image details can be looked up via the uuid.
2917         compute_utils.notify_about_instance_action(
2918             context, instance, self.host,
2919             action=fields.NotificationAction.REBUILD,
2920             phase=fields.NotificationPhase.START)
2921 
2922         instance.power_state = self._get_power_state(context, instance)
2923         instance.task_state = task_states.REBUILDING
2924         instance.save(expected_task_state=[task_states.REBUILDING])
2925 
2926         if recreate:
2927             self.network_api.setup_networks_on_host(
2928                     context, instance, self.host)
2929             # For nova-network this is needed to move floating IPs
2930             # For neutron this updates the host in the port binding
2931             # TODO(cfriesen): this network_api call and the one above
2932             # are so similar, we should really try to unify them.
2933             self.network_api.setup_instance_network_on_host(
2934                     context, instance, self.host)
2935 
2936         network_info = compute_utils.get_nw_info_for_instance(instance)
2937         if bdms is None:
2938             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2939                     context, instance.uuid)
2940 
2941         block_device_info = \
2942             self._get_instance_block_device_info(
2943                     context, instance, bdms=bdms)
2944 
2945         def detach_block_devices(context, bdms):
2946             for bdm in bdms:
2947                 if bdm.is_volume:
2948                     self._detach_volume(context, bdm.volume_id, instance,
2949                                         destroy_bdm=False)
2950 
2951         files = self._decode_files(injected_files)
2952 
2953         kwargs = dict(
2954             context=context,
2955             instance=instance,
2956             image_meta=image_meta,
2957             injected_files=files,
2958             admin_password=new_pass,
2959             bdms=bdms,
2960             detach_block_devices=detach_block_devices,
2961             attach_block_devices=self._prep_block_device,
2962             block_device_info=block_device_info,
2963             network_info=network_info,
2964             preserve_ephemeral=preserve_ephemeral,
2965             recreate=recreate)
2966         try:
2967             with instance.mutated_migration_context():
2968                 self.driver.rebuild(**kwargs)
2969         except NotImplementedError:
2970             # NOTE(rpodolyaka): driver doesn't provide specialized version
2971             # of rebuild, fall back to the default implementation
2972             self._rebuild_default_impl(**kwargs)
2973         self._update_instance_after_spawn(context, instance)
2974         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
2975 
2976         if orig_vm_state == vm_states.STOPPED:
2977             LOG.info("bringing vm to original state: '%s'",
2978                      orig_vm_state, instance=instance)
2979             instance.vm_state = vm_states.ACTIVE
2980             instance.task_state = task_states.POWERING_OFF
2981             instance.progress = 0
2982             instance.save()
2983             self.stop_instance(context, instance, False)
2984         self._update_scheduler_instance_info(context, instance)
2985         self._notify_about_instance_usage(
2986                 context, instance, "rebuild.end",
2987                 network_info=network_info,
2988                 extra_usage_info=extra_usage_info)
2989         compute_utils.notify_about_instance_action(
2990             context, instance, self.host,
2991             action=fields.NotificationAction.REBUILD,
2992             phase=fields.NotificationPhase.END)
2993 
2994     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
2995                                      block_device_info):
2996         """Handle cases where the virt-layer had to detach non-working volumes
2997         in order to complete an operation.
2998         """
2999         for bdm in block_device_info['block_device_mapping']:
3000             if bdm.get('mount_device') in bad_devices:
3001                 try:
3002                     volume_id = bdm['connection_info']['data']['volume_id']
3003                 except KeyError:
3004                     continue
3005 
3006                 # NOTE(sirp): ideally we'd just call
3007                 # `compute_api.detach_volume` here but since that hits the
3008                 # DB directly, that's off limits from within the
3009                 # compute-manager.
3010                 #
3011                 # API-detach
3012                 LOG.info("Detaching from volume api: %s", volume_id)
3013                 volume = self.volume_api.get(context, volume_id)
3014                 self.volume_api.check_detach(context, volume)
3015                 self.volume_api.begin_detaching(context, volume_id)
3016 
3017                 # Manager-detach
3018                 self.detach_volume(context, volume_id, instance)
3019 
3020     @wrap_exception()
3021     @reverts_task_state
3022     @wrap_instance_event(prefix='compute')
3023     @wrap_instance_fault
3024     def reboot_instance(self, context, instance, block_device_info,
3025                         reboot_type):
3026         """Reboot an instance on this host."""
3027         # acknowledge the request made it to the manager
3028         if reboot_type == "SOFT":
3029             instance.task_state = task_states.REBOOT_PENDING
3030             expected_states = (task_states.REBOOTING,
3031                                task_states.REBOOT_PENDING,
3032                                task_states.REBOOT_STARTED)
3033         else:
3034             instance.task_state = task_states.REBOOT_PENDING_HARD
3035             expected_states = (task_states.REBOOTING_HARD,
3036                                task_states.REBOOT_PENDING_HARD,
3037                                task_states.REBOOT_STARTED_HARD)
3038         context = context.elevated()
3039         LOG.info("Rebooting instance", instance=instance)
3040 
3041         block_device_info = self._get_instance_block_device_info(context,
3042                                                                  instance)
3043 
3044         network_info = self.network_api.get_instance_nw_info(context, instance)
3045 
3046         self._notify_about_instance_usage(context, instance, "reboot.start")
3047         compute_utils.notify_about_instance_action(
3048             context, instance, self.host,
3049             action=fields.NotificationAction.REBOOT,
3050             phase=fields.NotificationPhase.START
3051         )
3052 
3053         instance.power_state = self._get_power_state(context, instance)
3054         instance.save(expected_task_state=expected_states)
3055 
3056         if instance.power_state != power_state.RUNNING:
3057             state = instance.power_state
3058             running = power_state.RUNNING
3059             LOG.warning('trying to reboot a non-running instance:'
3060                         ' (state: %(state)s expected: %(running)s)',
3061                         {'state': state, 'running': running},
3062                         instance=instance)
3063 
3064         def bad_volumes_callback(bad_devices):
3065             self._handle_bad_volumes_detached(
3066                     context, instance, bad_devices, block_device_info)
3067 
3068         try:
3069             # Don't change it out of rescue mode
3070             if instance.vm_state == vm_states.RESCUED:
3071                 new_vm_state = vm_states.RESCUED
3072             else:
3073                 new_vm_state = vm_states.ACTIVE
3074             new_power_state = None
3075             if reboot_type == "SOFT":
3076                 instance.task_state = task_states.REBOOT_STARTED
3077                 expected_state = task_states.REBOOT_PENDING
3078             else:
3079                 instance.task_state = task_states.REBOOT_STARTED_HARD
3080                 expected_state = task_states.REBOOT_PENDING_HARD
3081             instance.save(expected_task_state=expected_state)
3082             self.driver.reboot(context, instance,
3083                                network_info,
3084                                reboot_type,
3085                                block_device_info=block_device_info,
3086                                bad_volumes_callback=bad_volumes_callback)
3087 
3088         except Exception as error:
3089             with excutils.save_and_reraise_exception() as ctxt:
3090                 exc_info = sys.exc_info()
3091                 # if the reboot failed but the VM is running don't
3092                 # put it into an error state
3093                 new_power_state = self._get_power_state(context, instance)
3094                 if new_power_state == power_state.RUNNING:
3095                     LOG.warning('Reboot failed but instance is running',
3096                                 instance=instance)
3097                     compute_utils.add_instance_fault_from_exc(context,
3098                             instance, error, exc_info)
3099                     self._notify_about_instance_usage(context, instance,
3100                             'reboot.error', fault=error)
3101                     compute_utils.notify_about_instance_action(
3102                         context, instance, self.host,
3103                         action=fields.NotificationAction.REBOOT,
3104                         phase=fields.NotificationPhase.ERROR,
3105                         exception=error
3106                     )
3107                     ctxt.reraise = False
3108                 else:
3109                     LOG.error('Cannot reboot instance: %s', error,
3110                               instance=instance)
3111                     self._set_instance_obj_error_state(context, instance)
3112 
3113         if not new_power_state:
3114             new_power_state = self._get_power_state(context, instance)
3115         try:
3116             instance.power_state = new_power_state
3117             instance.vm_state = new_vm_state
3118             instance.task_state = None
3119             instance.save()
3120         except exception.InstanceNotFound:
3121             LOG.warning("Instance disappeared during reboot",
3122                         instance=instance)
3123 
3124         self._notify_about_instance_usage(context, instance, "reboot.end")
3125         compute_utils.notify_about_instance_action(
3126             context, instance, self.host,
3127             action=fields.NotificationAction.REBOOT,
3128             phase=fields.NotificationPhase.END
3129         )
3130 
3131     @delete_image_on_error
3132     def _do_snapshot_instance(self, context, image_id, instance):
3133         self._snapshot_instance(context, image_id, instance,
3134                                 task_states.IMAGE_BACKUP)
3135 
3136     @wrap_exception()
3137     @reverts_task_state
3138     @wrap_instance_fault
3139     def backup_instance(self, context, image_id, instance, backup_type,
3140                         rotation):
3141         """Backup an instance on this host.
3142 
3143         :param backup_type: daily | weekly
3144         :param rotation: int representing how many backups to keep around
3145         """
3146         self._do_snapshot_instance(context, image_id, instance)
3147         self._rotate_backups(context, instance, backup_type, rotation)
3148 
3149     @wrap_exception()
3150     @reverts_task_state
3151     @wrap_instance_fault
3152     @delete_image_on_error
3153     def snapshot_instance(self, context, image_id, instance):
3154         """Snapshot an instance on this host.
3155 
3156         :param context: security context
3157         :param image_id: glance.db.sqlalchemy.models.Image.Id
3158         :param instance: a nova.objects.instance.Instance object
3159         """
3160         # NOTE(dave-mcnally) the task state will already be set by the api
3161         # but if the compute manager has crashed/been restarted prior to the
3162         # request getting here the task state may have been cleared so we set
3163         # it again and things continue normally
3164         try:
3165             instance.task_state = task_states.IMAGE_SNAPSHOT
3166             instance.save(
3167                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3168         except exception.InstanceNotFound:
3169             # possibility instance no longer exists, no point in continuing
3170             LOG.debug("Instance not found, could not set state %s "
3171                       "for instance.",
3172                       task_states.IMAGE_SNAPSHOT, instance=instance)
3173             return
3174 
3175         except exception.UnexpectedDeletingTaskStateError:
3176             LOG.debug("Instance being deleted, snapshot cannot continue",
3177                       instance=instance)
3178             return
3179 
3180         self._snapshot_instance(context, image_id, instance,
3181                                 task_states.IMAGE_SNAPSHOT)
3182 
3183     def _snapshot_instance(self, context, image_id, instance,
3184                            expected_task_state):
3185         context = context.elevated()
3186 
3187         instance.power_state = self._get_power_state(context, instance)
3188         try:
3189             instance.save()
3190 
3191             LOG.info('instance snapshotting', instance=instance)
3192 
3193             if instance.power_state != power_state.RUNNING:
3194                 state = instance.power_state
3195                 running = power_state.RUNNING
3196                 LOG.warning('trying to snapshot a non-running instance: '
3197                             '(state: %(state)s expected: %(running)s)',
3198                             {'state': state, 'running': running},
3199                             instance=instance)
3200 
3201             self._notify_about_instance_usage(
3202                 context, instance, "snapshot.start")
3203             compute_utils.notify_about_instance_action(context, instance,
3204                 self.host, action=fields.NotificationAction.SNAPSHOT,
3205                 phase=fields.NotificationPhase.START)
3206 
3207             def update_task_state(task_state,
3208                                   expected_state=expected_task_state):
3209                 instance.task_state = task_state
3210                 instance.save(expected_task_state=expected_state)
3211 
3212             self.driver.snapshot(context, instance, image_id,
3213                                  update_task_state)
3214 
3215             instance.task_state = None
3216             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3217 
3218             self._notify_about_instance_usage(context, instance,
3219                                               "snapshot.end")
3220             compute_utils.notify_about_instance_action(context, instance,
3221                 self.host, action=fields.NotificationAction.SNAPSHOT,
3222                 phase=fields.NotificationPhase.END)
3223         except (exception.InstanceNotFound,
3224                 exception.UnexpectedDeletingTaskStateError):
3225             # the instance got deleted during the snapshot
3226             # Quickly bail out of here
3227             msg = 'Instance disappeared during snapshot'
3228             LOG.debug(msg, instance=instance)
3229             try:
3230                 image_service = glance.get_default_image_service()
3231                 image = image_service.show(context, image_id)
3232                 if image['status'] != 'active':
3233                     image_service.delete(context, image_id)
3234             except Exception:
3235                 LOG.warning("Error while trying to clean up image %s",
3236                             image_id, instance=instance)
3237         except exception.ImageNotFound:
3238             instance.task_state = None
3239             instance.save()
3240             LOG.warning("Image not found during snapshot", instance=instance)
3241 
3242     def _post_interrupted_snapshot_cleanup(self, context, instance):
3243         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3244 
3245     @messaging.expected_exceptions(NotImplementedError)
3246     @wrap_exception()
3247     def volume_snapshot_create(self, context, instance, volume_id,
3248                                create_info):
3249         self.driver.volume_snapshot_create(context, instance, volume_id,
3250                                            create_info)
3251 
3252     @messaging.expected_exceptions(NotImplementedError)
3253     @wrap_exception()
3254     def volume_snapshot_delete(self, context, instance, volume_id,
3255                                snapshot_id, delete_info):
3256         self.driver.volume_snapshot_delete(context, instance, volume_id,
3257                                            snapshot_id, delete_info)
3258 
3259     @wrap_instance_fault
3260     def _rotate_backups(self, context, instance, backup_type, rotation):
3261         """Delete excess backups associated to an instance.
3262 
3263         Instances are allowed a fixed number of backups (the rotation number);
3264         this method deletes the oldest backups that exceed the rotation
3265         threshold.
3266 
3267         :param context: security context
3268         :param instance: Instance dict
3269         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3270         :param rotation: int representing how many backups to keep around;
3271             None if rotation shouldn't be used (as in the case of snapshots)
3272         """
3273         filters = {'property-image_type': 'backup',
3274                    'property-backup_type': backup_type,
3275                    'property-instance_uuid': instance.uuid}
3276 
3277         images = self.image_api.get_all(context, filters=filters,
3278                                         sort_key='created_at', sort_dir='desc')
3279         num_images = len(images)
3280         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3281                   {'num_images': num_images, 'rotation': rotation},
3282                   instance=instance)
3283 
3284         if num_images > rotation:
3285             # NOTE(sirp): this deletes all backups that exceed the rotation
3286             # limit
3287             excess = len(images) - rotation
3288             LOG.debug("Rotating out %d backups", excess,
3289                       instance=instance)
3290             for i in range(excess):
3291                 image = images.pop()
3292                 image_id = image['id']
3293                 LOG.debug("Deleting image %s", image_id,
3294                           instance=instance)
3295                 try:
3296                     self.image_api.delete(context, image_id)
3297                 except exception.ImageNotFound:
3298                     LOG.info("Failed to find image %(image_id)s to "
3299                              "delete", {'image_id': image_id},
3300                              instance=instance)
3301 
3302     @wrap_exception()
3303     @reverts_task_state
3304     @wrap_instance_event(prefix='compute')
3305     @wrap_instance_fault
3306     def set_admin_password(self, context, instance, new_pass):
3307         """Set the root/admin password for an instance on this host.
3308 
3309         This is generally only called by API password resets after an
3310         image has been built.
3311 
3312         @param context: Nova auth context.
3313         @param instance: Nova instance object.
3314         @param new_pass: The admin password for the instance.
3315         """
3316 
3317         context = context.elevated()
3318         if new_pass is None:
3319             # Generate a random password
3320             new_pass = utils.generate_password()
3321 
3322         current_power_state = self._get_power_state(context, instance)
3323         expected_state = power_state.RUNNING
3324 
3325         if current_power_state != expected_state:
3326             instance.task_state = None
3327             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3328             _msg = _('instance %s is not running') % instance.uuid
3329             raise exception.InstancePasswordSetFailed(
3330                 instance=instance.uuid, reason=_msg)
3331 
3332         try:
3333             self.driver.set_admin_password(instance, new_pass)
3334             LOG.info("Root password set", instance=instance)
3335             instance.task_state = None
3336             instance.save(
3337                 expected_task_state=task_states.UPDATING_PASSWORD)
3338         except exception.InstanceAgentNotEnabled:
3339             with excutils.save_and_reraise_exception():
3340                 LOG.debug('Guest agent is not enabled for the instance.',
3341                           instance=instance)
3342                 instance.task_state = None
3343                 instance.save(
3344                     expected_task_state=task_states.UPDATING_PASSWORD)
3345         except exception.SetAdminPasswdNotSupported:
3346             with excutils.save_and_reraise_exception():
3347                 LOG.info('set_admin_password is not supported '
3348                          'by this driver or guest instance.',
3349                          instance=instance)
3350                 instance.task_state = None
3351                 instance.save(
3352                     expected_task_state=task_states.UPDATING_PASSWORD)
3353         except NotImplementedError:
3354             LOG.warning('set_admin_password is not implemented '
3355                         'by this driver or guest instance.',
3356                         instance=instance)
3357             instance.task_state = None
3358             instance.save(
3359                 expected_task_state=task_states.UPDATING_PASSWORD)
3360             raise NotImplementedError(_('set_admin_password is not '
3361                                         'implemented by this driver or guest '
3362                                         'instance.'))
3363         except exception.UnexpectedTaskStateError:
3364             # interrupted by another (most likely delete) task
3365             # do not retry
3366             raise
3367         except Exception:
3368             # Catch all here because this could be anything.
3369             LOG.exception('set_admin_password failed', instance=instance)
3370             self._set_instance_obj_error_state(context, instance)
3371             # We create a new exception here so that we won't
3372             # potentially reveal password information to the
3373             # API caller.  The real exception is logged above
3374             _msg = _('error setting admin password')
3375             raise exception.InstancePasswordSetFailed(
3376                 instance=instance.uuid, reason=_msg)
3377 
3378     @wrap_exception()
3379     @reverts_task_state
3380     @wrap_instance_fault
3381     def inject_file(self, context, path, file_contents, instance):
3382         """Write a file to the specified path in an instance on this host."""
3383         # NOTE(russellb) Remove this method, as well as the underlying virt
3384         # driver methods, when the compute rpc interface is bumped to 4.x
3385         # as it is no longer used.
3386         context = context.elevated()
3387         current_power_state = self._get_power_state(context, instance)
3388         expected_state = power_state.RUNNING
3389         if current_power_state != expected_state:
3390             LOG.warning('trying to inject a file into a non-running '
3391                         '(state: %(current_state)s expected: '
3392                         '%(expected_state)s)',
3393                         {'current_state': current_power_state,
3394                          'expected_state': expected_state},
3395                         instance=instance)
3396         LOG.info('injecting file to %s', path, instance=instance)
3397         self.driver.inject_file(instance, path, file_contents)
3398 
3399     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3400         """Determine what image should be used to boot the rescue VM."""
3401         # 1. If rescue_image_ref is passed in, use that for rescue.
3402         # 2. Else, use the base image associated with instance's current image.
3403         #       The idea here is to provide the customer with a rescue
3404         #       environment which they are familiar with.
3405         #       So, if they built their instance off of a Debian image,
3406         #       their rescue VM will also be Debian.
3407         # 3. As a last resort, use instance's current image.
3408         if not rescue_image_ref:
3409             system_meta = utils.instance_sys_meta(instance)
3410             rescue_image_ref = system_meta.get('image_base_image_ref')
3411 
3412         if not rescue_image_ref:
3413             LOG.warning('Unable to find a different image to use for '
3414                         'rescue VM, using instance\'s current image',
3415                         instance=instance)
3416             rescue_image_ref = instance.image_ref
3417 
3418         return objects.ImageMeta.from_image_ref(
3419             context, self.image_api, rescue_image_ref)
3420 
3421     @wrap_exception()
3422     @reverts_task_state
3423     @wrap_instance_event(prefix='compute')
3424     @wrap_instance_fault
3425     def rescue_instance(self, context, instance, rescue_password,
3426                         rescue_image_ref, clean_shutdown):
3427         context = context.elevated()
3428         LOG.info('Rescuing', instance=instance)
3429 
3430         admin_password = (rescue_password if rescue_password else
3431                       utils.generate_password())
3432 
3433         network_info = self.network_api.get_instance_nw_info(context, instance)
3434 
3435         rescue_image_meta = self._get_rescue_image(context, instance,
3436                                                    rescue_image_ref)
3437 
3438         extra_usage_info = {'rescue_image_name':
3439                             self._get_image_name(rescue_image_meta)}
3440         self._notify_about_instance_usage(context, instance,
3441                 "rescue.start", extra_usage_info=extra_usage_info,
3442                 network_info=network_info)
3443 
3444         try:
3445             self._power_off_instance(context, instance, clean_shutdown)
3446 
3447             self.driver.rescue(context, instance,
3448                                network_info,
3449                                rescue_image_meta, admin_password)
3450         except Exception as e:
3451             LOG.exception("Error trying to Rescue Instance",
3452                           instance=instance)
3453             self._set_instance_obj_error_state(context, instance)
3454             raise exception.InstanceNotRescuable(
3455                 instance_id=instance.uuid,
3456                 reason=_("Driver Error: %s") % e)
3457 
3458         compute_utils.notify_usage_exists(self.notifier, context, instance,
3459                                           current_period=True)
3460 
3461         instance.vm_state = vm_states.RESCUED
3462         instance.task_state = None
3463         instance.power_state = self._get_power_state(context, instance)
3464         instance.launched_at = timeutils.utcnow()
3465         instance.save(expected_task_state=task_states.RESCUING)
3466 
3467         self._notify_about_instance_usage(context, instance,
3468                 "rescue.end", extra_usage_info=extra_usage_info,
3469                 network_info=network_info)
3470 
3471     @wrap_exception()
3472     @reverts_task_state
3473     @wrap_instance_event(prefix='compute')
3474     @wrap_instance_fault
3475     def unrescue_instance(self, context, instance):
3476         context = context.elevated()
3477         LOG.info('Unrescuing', instance=instance)
3478 
3479         network_info = self.network_api.get_instance_nw_info(context, instance)
3480         self._notify_about_instance_usage(context, instance,
3481                 "unrescue.start", network_info=network_info)
3482         with self._error_out_instance_on_exception(context, instance):
3483             self.driver.unrescue(instance,
3484                                  network_info)
3485 
3486         instance.vm_state = vm_states.ACTIVE
3487         instance.task_state = None
3488         instance.power_state = self._get_power_state(context, instance)
3489         instance.save(expected_task_state=task_states.UNRESCUING)
3490 
3491         self._notify_about_instance_usage(context,
3492                                           instance,
3493                                           "unrescue.end",
3494                                           network_info=network_info)
3495 
3496     @wrap_exception()
3497     @wrap_instance_fault
3498     def change_instance_metadata(self, context, diff, instance):
3499         """Update the metadata published to the instance."""
3500         LOG.debug("Changing instance metadata according to %r",
3501                   diff, instance=instance)
3502         self.driver.change_instance_metadata(context, instance, diff)
3503 
3504     @wrap_exception()
3505     @wrap_instance_event(prefix='compute')
3506     @wrap_instance_fault
3507     def confirm_resize(self, context, instance, reservations, migration):
3508 
3509         quotas = objects.Quotas.from_reservations(context,
3510                                                   reservations,
3511                                                   instance=instance)
3512 
3513         @utils.synchronized(instance.uuid)
3514         def do_confirm_resize(context, instance, migration_id):
3515             # NOTE(wangpan): Get the migration status from db, if it has been
3516             #                confirmed, we do nothing and return here
3517             LOG.debug("Going to confirm migration %s", migration_id,
3518                       instance=instance)
3519             try:
3520                 # TODO(russellb) Why are we sending the migration object just
3521                 # to turn around and look it up from the db again?
3522                 migration = objects.Migration.get_by_id(
3523                                     context.elevated(), migration_id)
3524             except exception.MigrationNotFound:
3525                 LOG.error("Migration %s is not found during confirmation",
3526                           migration_id, instance=instance)
3527                 quotas.rollback()
3528                 return
3529 
3530             if migration.status == 'confirmed':
3531                 LOG.info("Migration %s is already confirmed",
3532                          migration_id, instance=instance)
3533                 quotas.rollback()
3534                 return
3535             elif migration.status not in ('finished', 'confirming'):
3536                 LOG.warning("Unexpected confirmation status '%(status)s' "
3537                             "of migration %(id)s, exit confirmation process",
3538                             {"status": migration.status, "id": migration_id},
3539                             instance=instance)
3540                 quotas.rollback()
3541                 return
3542 
3543             # NOTE(wangpan): Get the instance from db, if it has been
3544             #                deleted, we do nothing and return here
3545             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3546             try:
3547                 instance = objects.Instance.get_by_uuid(
3548                         context, instance.uuid,
3549                         expected_attrs=expected_attrs)
3550             except exception.InstanceNotFound:
3551                 LOG.info("Instance is not found during confirmation",
3552                          instance=instance)
3553                 quotas.rollback()
3554                 return
3555 
3556             self._confirm_resize(context, instance, quotas,
3557                                  migration=migration)
3558 
3559         do_confirm_resize(context, instance, migration.id)
3560 
3561     def _confirm_resize(self, context, instance, quotas,
3562                         migration=None):
3563         """Destroys the source instance."""
3564         self._notify_about_instance_usage(context, instance,
3565                                           "resize.confirm.start")
3566 
3567         with self._error_out_instance_on_exception(context, instance,
3568                                                    quotas=quotas):
3569             # NOTE(danms): delete stashed migration information
3570             old_instance_type = instance.old_flavor
3571             instance.old_flavor = None
3572             instance.new_flavor = None
3573             instance.system_metadata.pop('old_vm_state', None)
3574             instance.save()
3575 
3576             # NOTE(tr3buchet): tear down networks on source host
3577             self.network_api.setup_networks_on_host(context, instance,
3578                                migration.source_compute, teardown=True)
3579 
3580             network_info = self.network_api.get_instance_nw_info(context,
3581                                                                  instance)
3582             self.driver.confirm_migration(context, migration, instance,
3583                                           network_info)
3584 
3585             migration.status = 'confirmed'
3586             with migration.obj_as_admin():
3587                 migration.save()
3588 
3589             rt = self._get_resource_tracker()
3590             rt.drop_move_claim(context, instance, migration.source_node,
3591                                old_instance_type, prefix='old_')
3592             instance.drop_migration_context()
3593 
3594             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3595             # might have manually powered up the instance to confirm the
3596             # resize/migrate, so we need to check the current power state
3597             # on the instance and set the vm_state appropriately. We default
3598             # to ACTIVE because if the power state is not SHUTDOWN, we
3599             # assume _sync_instance_power_state will clean it up.
3600             p_state = instance.power_state
3601             vm_state = None
3602             if p_state == power_state.SHUTDOWN:
3603                 vm_state = vm_states.STOPPED
3604                 LOG.debug("Resized/migrated instance is powered off. "
3605                           "Setting vm_state to '%s'.", vm_state,
3606                           instance=instance)
3607             else:
3608                 vm_state = vm_states.ACTIVE
3609 
3610             instance.vm_state = vm_state
3611             instance.task_state = None
3612             instance.save(expected_task_state=[None, task_states.DELETING])
3613 
3614             self._notify_about_instance_usage(
3615                 context, instance, "resize.confirm.end",
3616                 network_info=network_info)
3617 
3618             quotas.commit()
3619 
3620     @wrap_exception()
3621     @reverts_task_state
3622     @wrap_instance_event(prefix='compute')
3623     @errors_out_migration
3624     @wrap_instance_fault
3625     def revert_resize(self, context, instance, migration, reservations):
3626         """Destroys the new instance on the destination machine.
3627 
3628         Reverts the model changes, and powers on the old instance on the
3629         source machine.
3630 
3631         """
3632 
3633         quotas = objects.Quotas.from_reservations(context,
3634                                                   reservations,
3635                                                   instance=instance)
3636 
3637         # NOTE(comstud): A revert_resize is essentially a resize back to
3638         # the old size, so we need to send a usage event here.
3639         compute_utils.notify_usage_exists(self.notifier, context, instance,
3640                                           current_period=True)
3641 
3642         with self._error_out_instance_on_exception(context, instance,
3643                                                    quotas=quotas):
3644             # NOTE(tr3buchet): tear down networks on destination host
3645             self.network_api.setup_networks_on_host(context, instance,
3646                                                     teardown=True)
3647 
3648             migration_p = obj_base.obj_to_primitive(migration)
3649             self.network_api.migrate_instance_start(context,
3650                                                     instance,
3651                                                     migration_p)
3652 
3653             network_info = self.network_api.get_instance_nw_info(context,
3654                                                                  instance)
3655             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3656                     context, instance.uuid)
3657             block_device_info = self._get_instance_block_device_info(
3658                                 context, instance, bdms=bdms)
3659 
3660             destroy_disks = not self._is_instance_storage_shared(
3661                 context, instance, host=migration.source_compute)
3662             self.driver.destroy(context, instance, network_info,
3663                                 block_device_info, destroy_disks)
3664 
3665             self._terminate_volume_connections(context, instance, bdms)
3666 
3667             migration.status = 'reverted'
3668             with migration.obj_as_admin():
3669                 migration.save()
3670 
3671             # NOTE(ndipanov): We need to do this here because dropping the
3672             # claim means we lose the migration_context data. We really should
3673             # fix this by moving the drop_move_claim call to the
3674             # finish_revert_resize method as this is racy (revert is dropped,
3675             # but instance resources will be tracked with the new flavor until
3676             # it gets rolled back in finish_revert_resize, which is
3677             # potentially wrong for a period of time).
3678             instance.revert_migration_context()
3679             instance.save()
3680 
3681             rt = self._get_resource_tracker()
3682             rt.drop_move_claim(context, instance, instance.node)
3683 
3684             self.compute_rpcapi.finish_revert_resize(context, instance,
3685                     migration, migration.source_compute,
3686                     quotas.reservations)
3687 
3688     @wrap_exception()
3689     @reverts_task_state
3690     @wrap_instance_event(prefix='compute')
3691     @errors_out_migration
3692     @wrap_instance_fault
3693     def finish_revert_resize(self, context, instance, reservations, migration):
3694         """Finishes the second half of reverting a resize.
3695 
3696         Bring the original source instance state back (active/shutoff) and
3697         revert the resized attributes in the database.
3698 
3699         """
3700 
3701         quotas = objects.Quotas.from_reservations(context,
3702                                                   reservations,
3703                                                   instance=instance)
3704 
3705         with self._error_out_instance_on_exception(context, instance,
3706                                                    quotas=quotas):
3707             self._notify_about_instance_usage(
3708                     context, instance, "resize.revert.start")
3709 
3710             # NOTE(mriedem): delete stashed old_vm_state information; we
3711             # default to ACTIVE for backwards compatibility if old_vm_state
3712             # is not set
3713             old_vm_state = instance.system_metadata.pop('old_vm_state',
3714                                                         vm_states.ACTIVE)
3715 
3716             self._set_instance_info(instance, instance.old_flavor)
3717             instance.old_flavor = None
3718             instance.new_flavor = None
3719             instance.host = migration.source_compute
3720             instance.node = migration.source_node
3721             instance.save()
3722 
3723             self.network_api.setup_networks_on_host(context, instance,
3724                                                     migration.source_compute)
3725             migration_p = obj_base.obj_to_primitive(migration)
3726             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
3727             # source host temporarily. "network_api.migrate_instance_finish"
3728             # will setup the network for the instance on the destination host.
3729             # For revert resize, the instance will back to the source host, the
3730             # setup of the network for instance should be on the source host.
3731             # So set the migration_p['dest_compute'] to source host at here.
3732             migration_p['dest_compute'] = migration.source_compute
3733             self.network_api.migrate_instance_finish(context,
3734                                                      instance,
3735                                                      migration_p)
3736             network_info = self.network_api.get_instance_nw_info(context,
3737                                                                  instance)
3738 
3739             block_device_info = self._get_instance_block_device_info(
3740                     context, instance, refresh_conn_info=True)
3741 
3742             power_on = old_vm_state != vm_states.STOPPED
3743             self.driver.finish_revert_migration(context, instance,
3744                                        network_info,
3745                                        block_device_info, power_on)
3746 
3747             instance.drop_migration_context()
3748             instance.launched_at = timeutils.utcnow()
3749             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
3750 
3751             # if the original vm state was STOPPED, set it back to STOPPED
3752             LOG.info("Updating instance to original state: '%s'",
3753                      old_vm_state, instance=instance)
3754             if power_on:
3755                 instance.vm_state = vm_states.ACTIVE
3756                 instance.task_state = None
3757                 instance.save()
3758             else:
3759                 instance.task_state = task_states.POWERING_OFF
3760                 instance.save()
3761                 self.stop_instance(context, instance=instance,
3762                                    clean_shutdown=True)
3763 
3764             self._notify_about_instance_usage(
3765                     context, instance, "resize.revert.end")
3766             quotas.commit()
3767 
3768     def _prep_resize(self, context, image, instance, instance_type,
3769             quotas, request_spec, filter_properties, node,
3770             clean_shutdown=True):
3771 
3772         if not filter_properties:
3773             filter_properties = {}
3774 
3775         if not instance.host:
3776             self._set_instance_obj_error_state(context, instance)
3777             msg = _('Instance has no source host')
3778             raise exception.MigrationError(reason=msg)
3779 
3780         same_host = instance.host == self.host
3781         # if the flavor IDs match, it's migrate; otherwise resize
3782         if same_host and instance_type.id == instance['instance_type_id']:
3783             # check driver whether support migrate to same host
3784             if not self.driver.capabilities['supports_migrate_to_same_host']:
3785                 raise exception.UnableToMigrateToSelf(
3786                     instance_id=instance.uuid, host=self.host)
3787 
3788         # NOTE(danms): Stash the new instance_type to avoid having to
3789         # look it up in the database later
3790         instance.new_flavor = instance_type
3791         # NOTE(mriedem): Stash the old vm_state so we can set the
3792         # resized/reverted instance back to the same state later.
3793         vm_state = instance.vm_state
3794         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
3795         instance.system_metadata['old_vm_state'] = vm_state
3796         instance.save()
3797 
3798         limits = filter_properties.get('limits', {})
3799         rt = self._get_resource_tracker()
3800         with rt.resize_claim(context, instance, instance_type, node,
3801                              image_meta=image, limits=limits) as claim:
3802             LOG.info('Migrating', instance=instance)
3803             self.compute_rpcapi.resize_instance(
3804                     context, instance, claim.migration, image,
3805                     instance_type, quotas.reservations,
3806                     clean_shutdown)
3807 
3808     @wrap_exception()
3809     @reverts_task_state
3810     @wrap_instance_event(prefix='compute')
3811     @wrap_instance_fault
3812     def prep_resize(self, context, image, instance, instance_type,
3813                     reservations, request_spec, filter_properties, node,
3814                     clean_shutdown):
3815         """Initiates the process of moving a running instance to another host.
3816 
3817         Possibly changes the RAM and disk size in the process.
3818 
3819         """
3820         if node is None:
3821             node = self.driver.get_available_nodes(refresh=True)[0]
3822             LOG.debug("No node specified, defaulting to %s", node,
3823                       instance=instance)
3824 
3825         # NOTE(melwitt): Remove this in version 5.0 of the RPC API
3826         # Code downstream may expect extra_specs to be populated since it
3827         # is receiving an object, so lookup the flavor to ensure this.
3828         if not isinstance(instance_type, objects.Flavor):
3829             instance_type = objects.Flavor.get_by_id(context,
3830                                                      instance_type['id'])
3831 
3832         quotas = objects.Quotas.from_reservations(context,
3833                                                   reservations,
3834                                                   instance=instance)
3835         with self._error_out_instance_on_exception(context, instance,
3836                                                    quotas=quotas):
3837             compute_utils.notify_usage_exists(self.notifier, context, instance,
3838                                               current_period=True)
3839             self._notify_about_instance_usage(
3840                     context, instance, "resize.prep.start")
3841             try:
3842                 self._prep_resize(context, image, instance,
3843                                   instance_type, quotas,
3844                                   request_spec, filter_properties,
3845                                   node, clean_shutdown)
3846             # NOTE(dgenin): This is thrown in LibvirtDriver when the
3847             #               instance to be migrated is backed by LVM.
3848             #               Remove when LVM migration is implemented.
3849             except exception.MigrationPreCheckError:
3850                 raise
3851             except Exception:
3852                 # try to re-schedule the resize elsewhere:
3853                 exc_info = sys.exc_info()
3854                 self._reschedule_resize_or_reraise(context, image, instance,
3855                         exc_info, instance_type, quotas, request_spec,
3856                         filter_properties)
3857             finally:
3858                 extra_usage_info = dict(
3859                         new_instance_type=instance_type.name,
3860                         new_instance_type_id=instance_type.id)
3861 
3862                 self._notify_about_instance_usage(
3863                     context, instance, "resize.prep.end",
3864                     extra_usage_info=extra_usage_info)
3865 
3866     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
3867             instance_type, quotas, request_spec, filter_properties):
3868         """Try to re-schedule the resize or re-raise the original error to
3869         error out the instance.
3870         """
3871         if not request_spec:
3872             request_spec = {}
3873         if not filter_properties:
3874             filter_properties = {}
3875 
3876         rescheduled = False
3877         instance_uuid = instance.uuid
3878 
3879         try:
3880             reschedule_method = self.compute_task_api.resize_instance
3881             scheduler_hint = dict(filter_properties=filter_properties)
3882             method_args = (instance, None, scheduler_hint, instance_type,
3883                            quotas.reservations)
3884             task_state = task_states.RESIZE_PREP
3885 
3886             rescheduled = self._reschedule(context, request_spec,
3887                     filter_properties, instance, reschedule_method,
3888                     method_args, task_state, exc_info)
3889         except Exception as error:
3890             rescheduled = False
3891             LOG.exception("Error trying to reschedule",
3892                           instance_uuid=instance_uuid)
3893             compute_utils.add_instance_fault_from_exc(context,
3894                     instance, error,
3895                     exc_info=sys.exc_info())
3896             self._notify_about_instance_usage(context, instance,
3897                     'resize.error', fault=error)
3898 
3899         if rescheduled:
3900             self._log_original_error(exc_info, instance_uuid)
3901             compute_utils.add_instance_fault_from_exc(context,
3902                     instance, exc_info[1], exc_info=exc_info)
3903             self._notify_about_instance_usage(context, instance,
3904                     'resize.error', fault=exc_info[1])
3905         else:
3906             # not re-scheduling
3907             six.reraise(*exc_info)
3908 
3909     @wrap_exception()
3910     @reverts_task_state
3911     @wrap_instance_event(prefix='compute')
3912     @errors_out_migration
3913     @wrap_instance_fault
3914     def resize_instance(self, context, instance, image,
3915                         reservations, migration, instance_type,
3916                         clean_shutdown):
3917         """Starts the migration of a running instance to another host."""
3918 
3919         quotas = objects.Quotas.from_reservations(context,
3920                                                   reservations,
3921                                                   instance=instance)
3922         with self._error_out_instance_on_exception(context, instance,
3923                                                    quotas=quotas):
3924             # TODO(chaochin) Remove this until v5 RPC API
3925             # Code downstream may expect extra_specs to be populated since it
3926             # is receiving an object, so lookup the flavor to ensure this.
3927             if (not instance_type or
3928                 not isinstance(instance_type, objects.Flavor)):
3929                 instance_type = objects.Flavor.get_by_id(
3930                     context, migration['new_instance_type_id'])
3931 
3932             network_info = self.network_api.get_instance_nw_info(context,
3933                                                                  instance)
3934 
3935             migration.status = 'migrating'
3936             with migration.obj_as_admin():
3937                 migration.save()
3938 
3939             instance.task_state = task_states.RESIZE_MIGRATING
3940             instance.save(expected_task_state=task_states.RESIZE_PREP)
3941 
3942             self._notify_about_instance_usage(
3943                 context, instance, "resize.start", network_info=network_info)
3944 
3945             compute_utils.notify_about_instance_action(context, instance,
3946                    self.host, action=fields.NotificationAction.RESIZE,
3947                    phase=fields.NotificationPhase.START)
3948 
3949             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3950                     context, instance.uuid)
3951             block_device_info = self._get_instance_block_device_info(
3952                                 context, instance, bdms=bdms)
3953 
3954             timeout, retry_interval = self._get_power_off_values(context,
3955                                             instance, clean_shutdown)
3956             disk_info = self.driver.migrate_disk_and_power_off(
3957                     context, instance, migration.dest_host,
3958                     instance_type, network_info,
3959                     block_device_info,
3960                     timeout, retry_interval)
3961 
3962             self._terminate_volume_connections(context, instance, bdms)
3963 
3964             migration_p = obj_base.obj_to_primitive(migration)
3965             self.network_api.migrate_instance_start(context,
3966                                                     instance,
3967                                                     migration_p)
3968 
3969             migration.status = 'post-migrating'
3970             with migration.obj_as_admin():
3971                 migration.save()
3972 
3973             instance.host = migration.dest_compute
3974             instance.node = migration.dest_node
3975             instance.task_state = task_states.RESIZE_MIGRATED
3976             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
3977 
3978             self.compute_rpcapi.finish_resize(context, instance,
3979                     migration, image, disk_info,
3980                     migration.dest_compute, reservations=quotas.reservations)
3981 
3982             self._notify_about_instance_usage(context, instance, "resize.end",
3983                                               network_info=network_info)
3984 
3985             compute_utils.notify_about_instance_action(context, instance,
3986                    self.host, action=fields.NotificationAction.RESIZE,
3987                    phase=fields.NotificationPhase.END)
3988             self.instance_events.clear_events_for_instance(instance)
3989 
3990     def _terminate_volume_connections(self, context, instance, bdms):
3991         connector = None
3992         for bdm in bdms:
3993             if bdm.is_volume:
3994                 if bdm.attachment_id:
3995                     self.volume_api.attachment_delete(context,
3996                                                       bdm.attachment_id)
3997                 else:
3998                     if connector is None:
3999                         connector = self.driver.get_volume_connector(instance)
4000                     self.volume_api.terminate_connection(context,
4001                                                          bdm.volume_id,
4002                                                          connector)
4003 
4004     @staticmethod
4005     def _set_instance_info(instance, instance_type):
4006         instance.instance_type_id = instance_type.id
4007         # NOTE(danms): These are purely for any legacy code that still
4008         # looks at them.
4009         instance.memory_mb = instance_type.memory_mb
4010         instance.vcpus = instance_type.vcpus
4011         instance.root_gb = instance_type.root_gb
4012         instance.ephemeral_gb = instance_type.ephemeral_gb
4013         instance.flavor = instance_type
4014 
4015     def _finish_resize(self, context, instance, migration, disk_info,
4016                        image_meta):
4017         resize_instance = False
4018         old_instance_type_id = migration['old_instance_type_id']
4019         new_instance_type_id = migration['new_instance_type_id']
4020         old_instance_type = instance.get_flavor()
4021         # NOTE(mriedem): Get the old_vm_state so we know if we should
4022         # power on the instance. If old_vm_state is not set we need to default
4023         # to ACTIVE for backwards compatibility
4024         old_vm_state = instance.system_metadata.get('old_vm_state',
4025                                                     vm_states.ACTIVE)
4026         instance.old_flavor = old_instance_type
4027 
4028         if old_instance_type_id != new_instance_type_id:
4029             instance_type = instance.get_flavor('new')
4030             self._set_instance_info(instance, instance_type)
4031             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4032                 if old_instance_type[key] != instance_type[key]:
4033                     resize_instance = True
4034                     break
4035         instance.apply_migration_context()
4036 
4037         # NOTE(tr3buchet): setup networks on destination host
4038         self.network_api.setup_networks_on_host(context, instance,
4039                                                 migration['dest_compute'])
4040 
4041         migration_p = obj_base.obj_to_primitive(migration)
4042         self.network_api.migrate_instance_finish(context,
4043                                                  instance,
4044                                                  migration_p)
4045 
4046         network_info = self.network_api.get_instance_nw_info(context, instance)
4047 
4048         instance.task_state = task_states.RESIZE_FINISH
4049         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4050 
4051         self._notify_about_instance_usage(
4052             context, instance, "finish_resize.start",
4053             network_info=network_info)
4054         compute_utils.notify_about_instance_action(context, instance,
4055                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4056                phase=fields.NotificationPhase.START)
4057 
4058         block_device_info = self._get_instance_block_device_info(
4059                             context, instance, refresh_conn_info=True)
4060 
4061         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4062         # automatically power on the instance after it's migrated
4063         power_on = old_vm_state != vm_states.STOPPED
4064 
4065         try:
4066             self.driver.finish_migration(context, migration, instance,
4067                                          disk_info,
4068                                          network_info,
4069                                          image_meta, resize_instance,
4070                                          block_device_info, power_on)
4071         except Exception:
4072             with excutils.save_and_reraise_exception():
4073                 if old_instance_type_id != new_instance_type_id:
4074                     self._set_instance_info(instance,
4075                                             old_instance_type)
4076 
4077         migration.status = 'finished'
4078         with migration.obj_as_admin():
4079             migration.save()
4080 
4081         instance.vm_state = vm_states.RESIZED
4082         instance.task_state = None
4083         instance.launched_at = timeutils.utcnow()
4084         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4085 
4086         self._update_scheduler_instance_info(context, instance)
4087         self._notify_about_instance_usage(
4088             context, instance, "finish_resize.end",
4089             network_info=network_info)
4090         compute_utils.notify_about_instance_action(context, instance,
4091                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4092                phase=fields.NotificationPhase.END)
4093 
4094     @wrap_exception()
4095     @reverts_task_state
4096     @wrap_instance_event(prefix='compute')
4097     @errors_out_migration
4098     @wrap_instance_fault
4099     def finish_resize(self, context, disk_info, image, instance,
4100                       reservations, migration):
4101         """Completes the migration process.
4102 
4103         Sets up the newly transferred disk and turns on the instance at its
4104         new host machine.
4105 
4106         """
4107         quotas = objects.Quotas.from_reservations(context,
4108                                                   reservations,
4109                                                   instance=instance)
4110         try:
4111             image_meta = objects.ImageMeta.from_dict(image)
4112             self._finish_resize(context, instance, migration,
4113                                 disk_info, image_meta)
4114             quotas.commit()
4115         except Exception:
4116             LOG.exception('Setting instance vm_state to ERROR',
4117                           instance=instance)
4118             with excutils.save_and_reraise_exception():
4119                 try:
4120                     quotas.rollback()
4121                 except Exception:
4122                     LOG.exception("Failed to rollback quota for failed "
4123                                   "finish_resize",
4124                                   instance=instance)
4125                 self._set_instance_obj_error_state(context, instance)
4126 
4127     @wrap_exception()
4128     @wrap_instance_fault
4129     def add_fixed_ip_to_instance(self, context, network_id, instance):
4130         """Calls network_api to add new fixed_ip to instance
4131         then injects the new network info and resets instance networking.
4132 
4133         """
4134         self._notify_about_instance_usage(
4135                 context, instance, "create_ip.start")
4136 
4137         network_info = self.network_api.add_fixed_ip_to_instance(context,
4138                                                                  instance,
4139                                                                  network_id)
4140         self._inject_network_info(context, instance, network_info)
4141         self.reset_network(context, instance)
4142 
4143         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4144         instance.updated_at = timeutils.utcnow()
4145         instance.save()
4146 
4147         self._notify_about_instance_usage(
4148             context, instance, "create_ip.end", network_info=network_info)
4149 
4150     @wrap_exception()
4151     @wrap_instance_fault
4152     def remove_fixed_ip_from_instance(self, context, address, instance):
4153         """Calls network_api to remove existing fixed_ip from instance
4154         by injecting the altered network info and resetting
4155         instance networking.
4156         """
4157         self._notify_about_instance_usage(
4158                 context, instance, "delete_ip.start")
4159 
4160         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4161                                                                       instance,
4162                                                                       address)
4163         self._inject_network_info(context, instance, network_info)
4164         self.reset_network(context, instance)
4165 
4166         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4167         instance.updated_at = timeutils.utcnow()
4168         instance.save()
4169 
4170         self._notify_about_instance_usage(
4171             context, instance, "delete_ip.end", network_info=network_info)
4172 
4173     @wrap_exception()
4174     @reverts_task_state
4175     @wrap_instance_event(prefix='compute')
4176     @wrap_instance_fault
4177     def pause_instance(self, context, instance):
4178         """Pause an instance on this host."""
4179         context = context.elevated()
4180         LOG.info('Pausing', instance=instance)
4181         self._notify_about_instance_usage(context, instance, 'pause.start')
4182         compute_utils.notify_about_instance_action(context, instance,
4183                self.host, action=fields.NotificationAction.PAUSE,
4184                phase=fields.NotificationPhase.START)
4185         self.driver.pause(instance)
4186         instance.power_state = self._get_power_state(context, instance)
4187         instance.vm_state = vm_states.PAUSED
4188         instance.task_state = None
4189         instance.save(expected_task_state=task_states.PAUSING)
4190         self._notify_about_instance_usage(context, instance, 'pause.end')
4191         compute_utils.notify_about_instance_action(context, instance,
4192                self.host, action=fields.NotificationAction.PAUSE,
4193                phase=fields.NotificationPhase.END)
4194 
4195     @wrap_exception()
4196     @reverts_task_state
4197     @wrap_instance_event(prefix='compute')
4198     @wrap_instance_fault
4199     def unpause_instance(self, context, instance):
4200         """Unpause a paused instance on this host."""
4201         context = context.elevated()
4202         LOG.info('Unpausing', instance=instance)
4203         self._notify_about_instance_usage(context, instance, 'unpause.start')
4204         compute_utils.notify_about_instance_action(context, instance,
4205             self.host, action=fields.NotificationAction.UNPAUSE,
4206             phase=fields.NotificationPhase.START)
4207         self.driver.unpause(instance)
4208         instance.power_state = self._get_power_state(context, instance)
4209         instance.vm_state = vm_states.ACTIVE
4210         instance.task_state = None
4211         instance.save(expected_task_state=task_states.UNPAUSING)
4212         self._notify_about_instance_usage(context, instance, 'unpause.end')
4213         compute_utils.notify_about_instance_action(context, instance,
4214             self.host, action=fields.NotificationAction.UNPAUSE,
4215             phase=fields.NotificationPhase.END)
4216 
4217     @wrap_exception()
4218     def host_power_action(self, context, action):
4219         """Reboots, shuts down or powers up the host."""
4220         return self.driver.host_power_action(action)
4221 
4222     @wrap_exception()
4223     def host_maintenance_mode(self, context, host, mode):
4224         """Start/Stop host maintenance window. On start, it triggers
4225         guest VMs evacuation.
4226         """
4227         return self.driver.host_maintenance_mode(host, mode)
4228 
4229     @wrap_exception()
4230     def set_host_enabled(self, context, enabled):
4231         """Sets the specified host's ability to accept new instances."""
4232         return self.driver.set_host_enabled(enabled)
4233 
4234     @wrap_exception()
4235     def get_host_uptime(self, context):
4236         """Returns the result of calling "uptime" on the target host."""
4237         return self.driver.get_host_uptime()
4238 
4239     @wrap_exception()
4240     @wrap_instance_fault
4241     def get_diagnostics(self, context, instance):
4242         """Retrieve diagnostics for an instance on this host."""
4243         current_power_state = self._get_power_state(context, instance)
4244         if current_power_state == power_state.RUNNING:
4245             LOG.info("Retrieving diagnostics", instance=instance)
4246             return self.driver.get_diagnostics(instance)
4247         else:
4248             raise exception.InstanceInvalidState(
4249                 attr='power state',
4250                 instance_uuid=instance.uuid,
4251                 state=power_state.STATE_MAP[instance.power_state],
4252                 method='get_diagnostics')
4253 
4254     # TODO(alaski): Remove object_compat for RPC version 5.0
4255     @object_compat
4256     @wrap_exception()
4257     @wrap_instance_fault
4258     def get_instance_diagnostics(self, context, instance):
4259         """Retrieve diagnostics for an instance on this host."""
4260         current_power_state = self._get_power_state(context, instance)
4261         if current_power_state == power_state.RUNNING:
4262             LOG.info("Retrieving diagnostics", instance=instance)
4263             return self.driver.get_instance_diagnostics(instance)
4264         else:
4265             raise exception.InstanceInvalidState(
4266                 attr='power state',
4267                 instance_uuid=instance.uuid,
4268                 state=power_state.STATE_MAP[instance.power_state],
4269                 method='get_diagnostics')
4270 
4271     @wrap_exception()
4272     @reverts_task_state
4273     @wrap_instance_event(prefix='compute')
4274     @wrap_instance_fault
4275     def suspend_instance(self, context, instance):
4276         """Suspend the given instance."""
4277         context = context.elevated()
4278 
4279         # Store the old state
4280         instance.system_metadata['old_vm_state'] = instance.vm_state
4281         self._notify_about_instance_usage(context, instance, 'suspend.start')
4282         compute_utils.notify_about_instance_action(context, instance,
4283                 self.host, action=fields.NotificationAction.SUSPEND,
4284                 phase=fields.NotificationPhase.START)
4285         with self._error_out_instance_on_exception(context, instance,
4286              instance_state=instance.vm_state):
4287             self.driver.suspend(context, instance)
4288         instance.power_state = self._get_power_state(context, instance)
4289         instance.vm_state = vm_states.SUSPENDED
4290         instance.task_state = None
4291         instance.save(expected_task_state=task_states.SUSPENDING)
4292         self._notify_about_instance_usage(context, instance, 'suspend.end')
4293         compute_utils.notify_about_instance_action(context, instance,
4294                 self.host, action=fields.NotificationAction.SUSPEND,
4295                 phase=fields.NotificationPhase.END)
4296 
4297     @wrap_exception()
4298     @reverts_task_state
4299     @wrap_instance_event(prefix='compute')
4300     @wrap_instance_fault
4301     def resume_instance(self, context, instance):
4302         """Resume the given suspended instance."""
4303         context = context.elevated()
4304         LOG.info('Resuming', instance=instance)
4305 
4306         self._notify_about_instance_usage(context, instance, 'resume.start')
4307         compute_utils.notify_about_instance_action(context, instance,
4308             self.host, action=fields.NotificationAction.RESUME,
4309             phase=fields.NotificationPhase.START)
4310 
4311         network_info = self.network_api.get_instance_nw_info(context, instance)
4312         block_device_info = self._get_instance_block_device_info(
4313                             context, instance)
4314 
4315         with self._error_out_instance_on_exception(context, instance,
4316              instance_state=instance.vm_state):
4317             self.driver.resume(context, instance, network_info,
4318                                block_device_info)
4319 
4320         instance.power_state = self._get_power_state(context, instance)
4321 
4322         # We default to the ACTIVE state for backwards compatibility
4323         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4324                                                          vm_states.ACTIVE)
4325 
4326         instance.task_state = None
4327         instance.save(expected_task_state=task_states.RESUMING)
4328         self._notify_about_instance_usage(context, instance, 'resume.end')
4329         compute_utils.notify_about_instance_action(context, instance,
4330             self.host, action=fields.NotificationAction.RESUME,
4331             phase=fields.NotificationPhase.END)
4332 
4333     @wrap_exception()
4334     @reverts_task_state
4335     @wrap_instance_event(prefix='compute')
4336     @wrap_instance_fault
4337     def shelve_instance(self, context, instance, image_id,
4338                         clean_shutdown):
4339         """Shelve an instance.
4340 
4341         This should be used when you want to take a snapshot of the instance.
4342         It also adds system_metadata that can be used by a periodic task to
4343         offload the shelved instance after a period of time.
4344 
4345         :param context: request context
4346         :param instance: an Instance object
4347         :param image_id: an image id to snapshot to.
4348         :param clean_shutdown: give the GuestOS a chance to stop
4349         """
4350 
4351         @utils.synchronized(instance.uuid)
4352         def do_shelve_instance():
4353             self._shelve_instance(context, instance, image_id, clean_shutdown)
4354         do_shelve_instance()
4355 
4356     def _shelve_instance(self, context, instance, image_id,
4357                          clean_shutdown):
4358         LOG.info('Shelving', instance=instance)
4359         compute_utils.notify_usage_exists(self.notifier, context, instance,
4360                                           current_period=True)
4361         self._notify_about_instance_usage(context, instance, 'shelve.start')
4362         compute_utils.notify_about_instance_action(context, instance,
4363                 self.host, action=fields.NotificationAction.SHELVE,
4364                 phase=fields.NotificationPhase.START)
4365 
4366         def update_task_state(task_state, expected_state=task_states.SHELVING):
4367             shelving_state_map = {
4368                     task_states.IMAGE_PENDING_UPLOAD:
4369                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4370                     task_states.IMAGE_UPLOADING:
4371                         task_states.SHELVING_IMAGE_UPLOADING,
4372                     task_states.SHELVING: task_states.SHELVING}
4373             task_state = shelving_state_map[task_state]
4374             expected_state = shelving_state_map[expected_state]
4375             instance.task_state = task_state
4376             instance.save(expected_task_state=expected_state)
4377 
4378         self._power_off_instance(context, instance, clean_shutdown)
4379         self.driver.snapshot(context, instance, image_id, update_task_state)
4380 
4381         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4382         instance.system_metadata['shelved_image_id'] = image_id
4383         instance.system_metadata['shelved_host'] = self.host
4384         instance.vm_state = vm_states.SHELVED
4385         instance.task_state = None
4386         if CONF.shelved_offload_time == 0:
4387             instance.task_state = task_states.SHELVING_OFFLOADING
4388         instance.power_state = self._get_power_state(context, instance)
4389         instance.save(expected_task_state=[
4390                 task_states.SHELVING,
4391                 task_states.SHELVING_IMAGE_UPLOADING])
4392 
4393         self._notify_about_instance_usage(context, instance, 'shelve.end')
4394         compute_utils.notify_about_instance_action(context, instance,
4395                 self.host, action=fields.NotificationAction.SHELVE,
4396                 phase=fields.NotificationPhase.END)
4397 
4398         if CONF.shelved_offload_time == 0:
4399             self._shelve_offload_instance(context, instance,
4400                                           clean_shutdown=False)
4401 
4402     @wrap_exception()
4403     @reverts_task_state
4404     @wrap_instance_fault
4405     def shelve_offload_instance(self, context, instance, clean_shutdown):
4406         """Remove a shelved instance from the hypervisor.
4407 
4408         This frees up those resources for use by other instances, but may lead
4409         to slower unshelve times for this instance.  This method is used by
4410         volume backed instances since restoring them doesn't involve the
4411         potentially large download of an image.
4412 
4413         :param context: request context
4414         :param instance: nova.objects.instance.Instance
4415         :param clean_shutdown: give the GuestOS a chance to stop
4416         """
4417 
4418         @utils.synchronized(instance.uuid)
4419         def do_shelve_offload_instance():
4420             self._shelve_offload_instance(context, instance, clean_shutdown)
4421         do_shelve_offload_instance()
4422 
4423     def _shelve_offload_instance(self, context, instance, clean_shutdown):
4424         LOG.info('Shelve offloading', instance=instance)
4425         self._notify_about_instance_usage(context, instance,
4426                 'shelve_offload.start')
4427         compute_utils.notify_about_instance_action(context, instance,
4428                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4429                 phase=fields.NotificationPhase.START)
4430 
4431         self._power_off_instance(context, instance, clean_shutdown)
4432         current_power_state = self._get_power_state(context, instance)
4433 
4434         self.network_api.cleanup_instance_network_on_host(context, instance,
4435                                                           instance.host)
4436         network_info = self.network_api.get_instance_nw_info(context, instance)
4437         block_device_info = self._get_instance_block_device_info(context,
4438                                                                  instance)
4439         self.driver.destroy(context, instance, network_info,
4440                 block_device_info)
4441 
4442         instance.power_state = current_power_state
4443         # NOTE(mriedem): The vm_state has to be set before updating the
4444         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4445         # values cannot be nulled out until after updating the resource tracker
4446         # though.
4447         instance.vm_state = vm_states.SHELVED_OFFLOADED
4448         instance.task_state = None
4449         instance.save(expected_task_state=[task_states.SHELVING,
4450                                            task_states.SHELVING_OFFLOADING])
4451 
4452         # NOTE(ndipanov): Free resources from the resource tracker
4453         self._update_resource_tracker(context, instance)
4454 
4455         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4456         # instance, so ensure any calls result in errors
4457         self._nil_out_instance_obj_host_and_node(instance)
4458         instance.save(expected_task_state=None)
4459 
4460         self._delete_scheduler_instance_info(context, instance.uuid)
4461         self._notify_about_instance_usage(context, instance,
4462                 'shelve_offload.end')
4463         compute_utils.notify_about_instance_action(context, instance,
4464                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4465                 phase=fields.NotificationPhase.END)
4466 
4467     @wrap_exception()
4468     @reverts_task_state
4469     @wrap_instance_event(prefix='compute')
4470     @wrap_instance_fault
4471     def unshelve_instance(self, context, instance, image,
4472                           filter_properties, node):
4473         """Unshelve the instance.
4474 
4475         :param context: request context
4476         :param instance: a nova.objects.instance.Instance object
4477         :param image: an image to build from.  If None we assume a
4478             volume backed instance.
4479         :param filter_properties: dict containing limits, retry info etc.
4480         :param node: target compute node
4481         """
4482         if filter_properties is None:
4483             filter_properties = {}
4484 
4485         @utils.synchronized(instance.uuid)
4486         def do_unshelve_instance():
4487             self._unshelve_instance(context, instance, image,
4488                                     filter_properties, node)
4489         do_unshelve_instance()
4490 
4491     def _unshelve_instance_key_scrub(self, instance):
4492         """Remove data from the instance that may cause side effects."""
4493         cleaned_keys = dict(
4494                 key_data=instance.key_data,
4495                 auto_disk_config=instance.auto_disk_config)
4496         instance.key_data = None
4497         instance.auto_disk_config = False
4498         return cleaned_keys
4499 
4500     def _unshelve_instance_key_restore(self, instance, keys):
4501         """Restore previously scrubbed keys before saving the instance."""
4502         instance.update(keys)
4503 
4504     def _unshelve_instance(self, context, instance, image, filter_properties,
4505                            node):
4506         LOG.info('Unshelving', instance=instance)
4507         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4508         compute_utils.notify_about_instance_action(context, instance,
4509                 self.host, action=fields.NotificationAction.UNSHELVE,
4510                 phase=fields.NotificationPhase.START)
4511 
4512         instance.task_state = task_states.SPAWNING
4513         instance.save()
4514 
4515         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4516                 context, instance.uuid)
4517         block_device_info = self._prep_block_device(context, instance, bdms)
4518         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4519 
4520         if node is None:
4521             node = self.driver.get_available_nodes()[0]
4522             LOG.debug('No node specified, defaulting to %s', node,
4523                       instance=instance)
4524 
4525         rt = self._get_resource_tracker()
4526         limits = filter_properties.get('limits', {})
4527 
4528         shelved_image_ref = instance.image_ref
4529         if image:
4530             instance.image_ref = image['id']
4531             image_meta = objects.ImageMeta.from_dict(image)
4532         else:
4533             image_meta = objects.ImageMeta.from_dict(
4534                 utils.get_image_from_system_metadata(
4535                     instance.system_metadata))
4536 
4537         self.network_api.setup_instance_network_on_host(context, instance,
4538                                                         self.host)
4539         network_info = self.network_api.get_instance_nw_info(context, instance)
4540         try:
4541             with rt.instance_claim(context, instance, node, limits):
4542                 self.driver.spawn(context, instance, image_meta,
4543                                   injected_files=[],
4544                                   admin_password=None,
4545                                   network_info=network_info,
4546                                   block_device_info=block_device_info)
4547         except Exception:
4548             with excutils.save_and_reraise_exception():
4549                 LOG.exception('Instance failed to spawn',
4550                               instance=instance)
4551 
4552         if image:
4553             instance.image_ref = shelved_image_ref
4554             self._delete_snapshot_of_shelved_instance(context, instance,
4555                                                       image['id'])
4556 
4557         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4558         self._update_instance_after_spawn(context, instance)
4559         # Delete system_metadata for a shelved instance
4560         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4561 
4562         instance.save(expected_task_state=task_states.SPAWNING)
4563         self._update_scheduler_instance_info(context, instance)
4564         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4565         compute_utils.notify_about_instance_action(context, instance,
4566                 self.host, action=fields.NotificationAction.UNSHELVE,
4567                 phase=fields.NotificationPhase.END)
4568 
4569     @messaging.expected_exceptions(NotImplementedError)
4570     @wrap_instance_fault
4571     def reset_network(self, context, instance):
4572         """Reset networking on the given instance."""
4573         LOG.debug('Reset network', instance=instance)
4574         self.driver.reset_network(instance)
4575 
4576     def _inject_network_info(self, context, instance, network_info):
4577         """Inject network info for the given instance."""
4578         LOG.debug('Inject network info', instance=instance)
4579         LOG.debug('network_info to inject: |%s|', network_info,
4580                   instance=instance)
4581 
4582         self.driver.inject_network_info(instance,
4583                                         network_info)
4584 
4585     @wrap_instance_fault
4586     def inject_network_info(self, context, instance):
4587         """Inject network info, but don't return the info."""
4588         network_info = self.network_api.get_instance_nw_info(context, instance)
4589         self._inject_network_info(context, instance, network_info)
4590 
4591     @messaging.expected_exceptions(NotImplementedError,
4592                                    exception.ConsoleNotAvailable,
4593                                    exception.InstanceNotFound)
4594     @wrap_exception()
4595     @wrap_instance_fault
4596     def get_console_output(self, context, instance, tail_length):
4597         """Send the console output for the given instance."""
4598         context = context.elevated()
4599         LOG.info("Get console output", instance=instance)
4600         output = self.driver.get_console_output(context, instance)
4601 
4602         if type(output) is six.text_type:
4603             output = six.b(output)
4604 
4605         if tail_length is not None:
4606             output = self._tail_log(output, tail_length)
4607 
4608         return output.decode('ascii', 'replace')
4609 
4610     def _tail_log(self, log, length):
4611         try:
4612             length = int(length)
4613         except ValueError:
4614             length = 0
4615 
4616         if length == 0:
4617             return b''
4618         else:
4619             return b'\n'.join(log.split(b'\n')[-int(length):])
4620 
4621     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4622                                    exception.InstanceNotReady,
4623                                    exception.InstanceNotFound,
4624                                    exception.ConsoleTypeUnavailable,
4625                                    NotImplementedError)
4626     @wrap_exception()
4627     @wrap_instance_fault
4628     def get_vnc_console(self, context, console_type, instance):
4629         """Return connection information for a vnc console."""
4630         context = context.elevated()
4631         LOG.debug("Getting vnc console", instance=instance)
4632         token = uuidutils.generate_uuid()
4633 
4634         if not CONF.vnc.enabled:
4635             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4636 
4637         if console_type == 'novnc':
4638             # For essex, novncproxy_base_url must include the full path
4639             # including the html file (like http://myhost/vnc_auto.html)
4640             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
4641         elif console_type == 'xvpvnc':
4642             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
4643         else:
4644             raise exception.ConsoleTypeInvalid(console_type=console_type)
4645 
4646         try:
4647             # Retrieve connect info from driver, and then decorate with our
4648             # access info token
4649             console = self.driver.get_vnc_console(context, instance)
4650             connect_info = console.get_connection_info(token, access_url)
4651         except exception.InstanceNotFound:
4652             if instance.vm_state != vm_states.BUILDING:
4653                 raise
4654             raise exception.InstanceNotReady(instance_id=instance.uuid)
4655 
4656         return connect_info
4657 
4658     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4659                                    exception.InstanceNotReady,
4660                                    exception.InstanceNotFound,
4661                                    exception.ConsoleTypeUnavailable,
4662                                    NotImplementedError)
4663     @wrap_exception()
4664     @wrap_instance_fault
4665     def get_spice_console(self, context, console_type, instance):
4666         """Return connection information for a spice console."""
4667         context = context.elevated()
4668         LOG.debug("Getting spice console", instance=instance)
4669         token = uuidutils.generate_uuid()
4670 
4671         if not CONF.spice.enabled:
4672             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4673 
4674         if console_type == 'spice-html5':
4675             # For essex, spicehtml5proxy_base_url must include the full path
4676             # including the html file (like http://myhost/spice_auto.html)
4677             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
4678                                           token)
4679         else:
4680             raise exception.ConsoleTypeInvalid(console_type=console_type)
4681 
4682         try:
4683             # Retrieve connect info from driver, and then decorate with our
4684             # access info token
4685             console = self.driver.get_spice_console(context, instance)
4686             connect_info = console.get_connection_info(token, access_url)
4687         except exception.InstanceNotFound:
4688             if instance.vm_state != vm_states.BUILDING:
4689                 raise
4690             raise exception.InstanceNotReady(instance_id=instance.uuid)
4691 
4692         return connect_info
4693 
4694     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4695                                    exception.InstanceNotReady,
4696                                    exception.InstanceNotFound,
4697                                    exception.ConsoleTypeUnavailable,
4698                                    NotImplementedError)
4699     @wrap_exception()
4700     @wrap_instance_fault
4701     def get_rdp_console(self, context, console_type, instance):
4702         """Return connection information for a RDP console."""
4703         context = context.elevated()
4704         LOG.debug("Getting RDP console", instance=instance)
4705         token = uuidutils.generate_uuid()
4706 
4707         if not CONF.rdp.enabled:
4708             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4709 
4710         if console_type == 'rdp-html5':
4711             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
4712                                           token)
4713         else:
4714             raise exception.ConsoleTypeInvalid(console_type=console_type)
4715 
4716         try:
4717             # Retrieve connect info from driver, and then decorate with our
4718             # access info token
4719             console = self.driver.get_rdp_console(context, instance)
4720             connect_info = console.get_connection_info(token, access_url)
4721         except exception.InstanceNotFound:
4722             if instance.vm_state != vm_states.BUILDING:
4723                 raise
4724             raise exception.InstanceNotReady(instance_id=instance.uuid)
4725 
4726         return connect_info
4727 
4728     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4729                                    exception.InstanceNotReady,
4730                                    exception.InstanceNotFound,
4731                                    exception.ConsoleTypeUnavailable,
4732                                    NotImplementedError)
4733     @wrap_exception()
4734     @wrap_instance_fault
4735     def get_mks_console(self, context, console_type, instance):
4736         """Return connection information for a MKS console."""
4737         context = context.elevated()
4738         LOG.debug("Getting MKS console", instance=instance)
4739         token = uuidutils.generate_uuid()
4740 
4741         if not CONF.mks.enabled:
4742             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4743 
4744         if console_type == 'webmks':
4745             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
4746                                           token)
4747         else:
4748             raise exception.ConsoleTypeInvalid(console_type=console_type)
4749 
4750         try:
4751             # Retrieve connect info from driver, and then decorate with our
4752             # access info token
4753             console = self.driver.get_mks_console(context, instance)
4754             connect_info = console.get_connection_info(token, access_url)
4755         except exception.InstanceNotFound:
4756             if instance.vm_state != vm_states.BUILDING:
4757                 raise
4758             raise exception.InstanceNotReady(instance_id=instance.uuid)
4759 
4760         return connect_info
4761 
4762     @messaging.expected_exceptions(
4763         exception.ConsoleTypeInvalid,
4764         exception.InstanceNotReady,
4765         exception.InstanceNotFound,
4766         exception.ConsoleTypeUnavailable,
4767         exception.SocketPortRangeExhaustedException,
4768         exception.ImageSerialPortNumberInvalid,
4769         exception.ImageSerialPortNumberExceedFlavorValue,
4770         NotImplementedError)
4771     @wrap_exception()
4772     @wrap_instance_fault
4773     def get_serial_console(self, context, console_type, instance):
4774         """Returns connection information for a serial console."""
4775 
4776         LOG.debug("Getting serial console", instance=instance)
4777 
4778         if not CONF.serial_console.enabled:
4779             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4780 
4781         context = context.elevated()
4782 
4783         token = uuidutils.generate_uuid()
4784         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
4785 
4786         try:
4787             # Retrieve connect info from driver, and then decorate with our
4788             # access info token
4789             console = self.driver.get_serial_console(context, instance)
4790             connect_info = console.get_connection_info(token, access_url)
4791         except exception.InstanceNotFound:
4792             if instance.vm_state != vm_states.BUILDING:
4793                 raise
4794             raise exception.InstanceNotReady(instance_id=instance.uuid)
4795 
4796         return connect_info
4797 
4798     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4799                                    exception.InstanceNotReady,
4800                                    exception.InstanceNotFound)
4801     @wrap_exception()
4802     @wrap_instance_fault
4803     def validate_console_port(self, ctxt, instance, port, console_type):
4804         if console_type == "spice-html5":
4805             console_info = self.driver.get_spice_console(ctxt, instance)
4806         elif console_type == "rdp-html5":
4807             console_info = self.driver.get_rdp_console(ctxt, instance)
4808         elif console_type == "serial":
4809             console_info = self.driver.get_serial_console(ctxt, instance)
4810         elif console_type == "webmks":
4811             console_info = self.driver.get_mks_console(ctxt, instance)
4812         else:
4813             console_info = self.driver.get_vnc_console(ctxt, instance)
4814 
4815         return console_info.port == port
4816 
4817     @wrap_exception()
4818     @reverts_task_state
4819     @wrap_instance_fault
4820     def reserve_block_device_name(self, context, instance, device,
4821                                   volume_id, disk_bus, device_type):
4822         @utils.synchronized(instance.uuid)
4823         def do_reserve():
4824             bdms = (
4825                 objects.BlockDeviceMappingList.get_by_instance_uuid(
4826                     context, instance.uuid))
4827 
4828             # NOTE(ndipanov): We need to explicitly set all the fields on the
4829             #                 object so that obj_load_attr does not fail
4830             new_bdm = objects.BlockDeviceMapping(
4831                     context=context,
4832                     source_type='volume', destination_type='volume',
4833                     instance_uuid=instance.uuid, boot_index=None,
4834                     volume_id=volume_id,
4835                     device_name=device, guest_format=None,
4836                     disk_bus=disk_bus, device_type=device_type)
4837 
4838             new_bdm.device_name = self._get_device_name_for_instance(
4839                     instance, bdms, new_bdm)
4840 
4841             # NOTE(vish): create bdm here to avoid race condition
4842             new_bdm.create()
4843             return new_bdm
4844 
4845         return do_reserve()
4846 
4847     @wrap_exception()
4848     @wrap_instance_fault
4849     def attach_volume(self, context, instance, bdm):
4850         """Attach a volume to an instance."""
4851         driver_bdm = driver_block_device.convert_volume(bdm)
4852 
4853         @utils.synchronized(instance.uuid)
4854         def do_attach_volume(context, instance, driver_bdm):
4855             try:
4856                 return self._attach_volume(context, instance, driver_bdm)
4857             except Exception:
4858                 with excutils.save_and_reraise_exception():
4859                     bdm.destroy()
4860 
4861         do_attach_volume(context, instance, driver_bdm)
4862 
4863     def _attach_volume(self, context, instance, bdm):
4864         context = context.elevated()
4865         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
4866                  {'volume_id': bdm.volume_id,
4867                   'mountpoint': bdm['mount_device']},
4868                  instance=instance)
4869         compute_utils.notify_about_volume_attach_detach(
4870             context, instance, self.host,
4871             action=fields.NotificationAction.VOLUME_ATTACH,
4872             phase=fields.NotificationPhase.START,
4873             volume_id=bdm.volume_id)
4874         try:
4875             bdm.attach(context, instance, self.volume_api, self.driver,
4876                        do_driver_attach=True)
4877         except Exception as e:
4878             with excutils.save_and_reraise_exception():
4879                 LOG.exception("Failed to attach %(volume_id)s "
4880                               "at %(mountpoint)s",
4881                               {'volume_id': bdm.volume_id,
4882                                'mountpoint': bdm['mount_device']},
4883                               instance=instance)
4884                 self.volume_api.unreserve_volume(context, bdm.volume_id)
4885                 compute_utils.notify_about_volume_attach_detach(
4886                     context, instance, self.host,
4887                     action=fields.NotificationAction.VOLUME_ATTACH,
4888                     phase=fields.NotificationPhase.ERROR,
4889                     exception=e,
4890                     volume_id=bdm.volume_id)
4891 
4892         info = {'volume_id': bdm.volume_id}
4893         self._notify_about_instance_usage(
4894             context, instance, "volume.attach", extra_usage_info=info)
4895         compute_utils.notify_about_volume_attach_detach(
4896             context, instance, self.host,
4897             action=fields.NotificationAction.VOLUME_ATTACH,
4898             phase=fields.NotificationPhase.END,
4899             volume_id=bdm.volume_id)
4900 
4901     def _notify_volume_usage_detach(self, context, instance, bdm):
4902         if CONF.volume_usage_poll_interval <= 0:
4903             return
4904 
4905         vol_stats = []
4906         mp = bdm.device_name
4907         # Handle bootable volumes which will not contain /dev/
4908         if '/dev/' in mp:
4909             mp = mp[5:]
4910         try:
4911             vol_stats = self.driver.block_stats(instance, mp)
4912         except NotImplementedError:
4913             return
4914 
4915         LOG.debug("Updating volume usage cache with totals", instance=instance)
4916         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
4917         vol_usage = objects.VolumeUsage(context)
4918         vol_usage.volume_id = bdm.volume_id
4919         vol_usage.instance_uuid = instance.uuid
4920         vol_usage.project_id = instance.project_id
4921         vol_usage.user_id = instance.user_id
4922         vol_usage.availability_zone = instance.availability_zone
4923         vol_usage.curr_reads = rd_req
4924         vol_usage.curr_read_bytes = rd_bytes
4925         vol_usage.curr_writes = wr_req
4926         vol_usage.curr_write_bytes = wr_bytes
4927         vol_usage.save(update_totals=True)
4928         self.notifier.info(context, 'volume.usage',
4929                            compute_utils.usage_volume_info(vol_usage))
4930 
4931     def _detach_volume(self, context, volume_id, instance, destroy_bdm=True,
4932                        attachment_id=None):
4933         """Detach a volume from an instance.
4934 
4935         :param context: security context
4936         :param volume_id: the volume id
4937         :param instance: the Instance object to detach the volume from
4938         :param destroy_bdm: if True, the corresponding BDM entry will be marked
4939                             as deleted. Disabling this is useful for operations
4940                             like rebuild, when we don't want to destroy BDM
4941 
4942         """
4943         compute_utils.notify_about_volume_attach_detach(
4944             context, instance, self.host,
4945             action=fields.NotificationAction.VOLUME_DETACH,
4946             phase=fields.NotificationPhase.START,
4947             volume_id=volume_id)
4948         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4949                 context, volume_id, instance.uuid)
4950 
4951         self._notify_volume_usage_detach(context, instance, bdm)
4952 
4953         LOG.info('Detaching volume %(volume_id)s',
4954                  {'volume_id': volume_id}, instance=instance)
4955 
4956         driver_bdm = driver_block_device.convert_volume(bdm)
4957         driver_bdm.detach(context, instance, self.volume_api, self.driver,
4958                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
4959 
4960         info = dict(volume_id=volume_id)
4961         self._notify_about_instance_usage(
4962             context, instance, "volume.detach", extra_usage_info=info)
4963         compute_utils.notify_about_volume_attach_detach(
4964             context, instance, self.host,
4965             action=fields.NotificationAction.VOLUME_DETACH,
4966             phase=fields.NotificationPhase.END,
4967             volume_id=volume_id)
4968 
4969         if destroy_bdm:
4970             bdm.destroy()
4971 
4972     @wrap_exception()
4973     @wrap_instance_fault
4974     def detach_volume(self, context, volume_id, instance, attachment_id=None):
4975         """Detach a volume from an instance."""
4976 
4977         self._detach_volume(context, volume_id, instance,
4978                             attachment_id=attachment_id)
4979 
4980     def _init_volume_connection(self, context, new_volume_id,
4981                                 old_volume_id, connector, instance, bdm):
4982 
4983         new_cinfo = self.volume_api.initialize_connection(context,
4984                                                           new_volume_id,
4985                                                           connector)
4986         old_cinfo = jsonutils.loads(bdm['connection_info'])
4987         if old_cinfo and 'serial' not in old_cinfo:
4988             old_cinfo['serial'] = old_volume_id
4989         # NOTE(lyarwood): serial is not always present in the returned
4990         # connection_info so set it if it is missing as we do in
4991         # DriverVolumeBlockDevice.attach().
4992         if 'serial' not in new_cinfo:
4993             new_cinfo['serial'] = new_volume_id
4994         return (old_cinfo, new_cinfo)
4995 
4996     def _swap_volume(self, context, instance, bdm, connector,
4997                      old_volume_id, new_volume_id, resize_to):
4998         mountpoint = bdm['device_name']
4999         failed = False
5000         new_cinfo = None
5001         try:
5002             old_cinfo, new_cinfo = self._init_volume_connection(context,
5003                                                                 new_volume_id,
5004                                                                 old_volume_id,
5005                                                                 connector,
5006                                                                 instance,
5007                                                                 bdm)
5008             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5009             # currently implementing swap_volume, will modify the contents of
5010             # new_cinfo when connect_volume is called. This is then saved to
5011             # the BDM in swap_volume for future use outside of this flow.
5012             LOG.debug("swap_volume: Calling driver volume swap with "
5013                       "connection infos: new: %(new_cinfo)s; "
5014                       "old: %(old_cinfo)s",
5015                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo},
5016                       instance=instance)
5017             self.driver.swap_volume(old_cinfo, new_cinfo, instance, mountpoint,
5018                                     resize_to)
5019             LOG.debug("swap_volume: Driver volume swap returned, new "
5020                       "connection_info is now : %(new_cinfo)s",
5021                       {'new_cinfo': new_cinfo})
5022         except Exception as ex:
5023             failed = True
5024             with excutils.save_and_reraise_exception():
5025                 compute_utils.notify_about_volume_swap(
5026                     context, instance, self.host,
5027                     fields.NotificationAction.VOLUME_SWAP,
5028                     fields.NotificationPhase.ERROR,
5029                     old_volume_id, new_volume_id, ex)
5030                 if new_cinfo:
5031                     msg = ("Failed to swap volume %(old_volume_id)s "
5032                            "for %(new_volume_id)s")
5033                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5034                                         'new_volume_id': new_volume_id},
5035                                   instance=instance)
5036                 else:
5037                     msg = ("Failed to connect to volume %(volume_id)s "
5038                            "with volume at %(mountpoint)s")
5039                     LOG.exception(msg, {'volume_id': new_volume_id,
5040                                         'mountpoint': bdm['device_name']},
5041                                   instance=instance)
5042                 self.volume_api.roll_detaching(context, old_volume_id)
5043                 self.volume_api.unreserve_volume(context, new_volume_id)
5044         finally:
5045             conn_volume = new_volume_id if failed else old_volume_id
5046             if new_cinfo:
5047                 LOG.debug("swap_volume: calling Cinder terminate_connection "
5048                           "for %(volume)s", {'volume': conn_volume},
5049                           instance=instance)
5050                 self.volume_api.terminate_connection(context,
5051                                                      conn_volume,
5052                                                      connector)
5053             # NOTE(lyarwood): The following call to
5054             # os-migrate-volume-completion returns a dict containing
5055             # save_volume_id, this volume id has two possible values :
5056             # 1. old_volume_id if we are migrating (retyping) volumes
5057             # 2. new_volume_id if we are swapping between two existing volumes
5058             # This volume id is later used to update the volume_id and
5059             # connection_info['serial'] of the BDM.
5060             comp_ret = self.volume_api.migrate_volume_completion(
5061                                                       context,
5062                                                       old_volume_id,
5063                                                       new_volume_id,
5064                                                       error=failed)
5065             LOG.debug("swap_volume: Cinder migrate_volume_completion "
5066                       "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5067                       instance=instance)
5068 
5069         return (comp_ret, new_cinfo)
5070 
5071     @wrap_exception()
5072     @reverts_task_state
5073     @wrap_instance_fault
5074     def swap_volume(self, context, old_volume_id, new_volume_id, instance):
5075         """Swap volume for an instance."""
5076         context = context.elevated()
5077 
5078         compute_utils.notify_about_volume_swap(
5079             context, instance, self.host,
5080             fields.NotificationAction.VOLUME_SWAP,
5081             fields.NotificationPhase.START,
5082             old_volume_id, new_volume_id)
5083 
5084         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5085                 context, old_volume_id, instance.uuid)
5086         connector = self.driver.get_volume_connector(instance)
5087 
5088         resize_to = 0
5089         old_vol_size = self.volume_api.get(context, old_volume_id)['size']
5090         new_vol_size = self.volume_api.get(context, new_volume_id)['size']
5091         if new_vol_size > old_vol_size:
5092             resize_to = new_vol_size
5093 
5094         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5095                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5096                  instance=instance)
5097         comp_ret, new_cinfo = self._swap_volume(context, instance,
5098                                                          bdm,
5099                                                          connector,
5100                                                          old_volume_id,
5101                                                          new_volume_id,
5102                                                          resize_to)
5103 
5104         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5105         # correct volume_id returned by Cinder.
5106         save_volume_id = comp_ret['save_volume_id']
5107         new_cinfo['serial'] = save_volume_id
5108         values = {
5109             'connection_info': jsonutils.dumps(new_cinfo),
5110             'source_type': 'volume',
5111             'destination_type': 'volume',
5112             'snapshot_id': None,
5113             'volume_id': save_volume_id,
5114             'no_device': None}
5115 
5116         if resize_to:
5117             values['volume_size'] = resize_to
5118 
5119         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5120                   "%(updates)s", {'volume_id': bdm.volume_id,
5121                                   'updates': values},
5122                   instance=instance)
5123         bdm.update(values)
5124         bdm.save()
5125 
5126         compute_utils.notify_about_volume_swap(
5127             context, instance, self.host,
5128             fields.NotificationAction.VOLUME_SWAP,
5129             fields.NotificationPhase.END,
5130             old_volume_id, new_volume_id)
5131 
5132     @wrap_exception()
5133     def remove_volume_connection(self, context, volume_id, instance):
5134         """Remove a volume connection using the volume api."""
5135         # NOTE(vish): We don't want to actually mark the volume
5136         #             detached, or delete the bdm, just remove the
5137         #             connection from this host.
5138 
5139         try:
5140             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5141                     context, volume_id, instance.uuid)
5142             driver_bdm = driver_block_device.convert_volume(bdm)
5143             driver_bdm.driver_detach(context, instance,
5144                                      self.volume_api, self.driver)
5145             connector = self.driver.get_volume_connector(instance)
5146             self.volume_api.terminate_connection(context, volume_id, connector)
5147         except exception.NotFound:
5148             pass
5149 
5150     @wrap_exception()
5151     @wrap_instance_fault
5152     def attach_interface(self, context, instance, network_id, port_id,
5153                          requested_ip):
5154         """Use hotplug to add an network adapter to an instance."""
5155         if not self.driver.capabilities['supports_attach_interface']:
5156             raise exception.AttachInterfaceNotSupported(
5157                 instance_uuid=instance.uuid)
5158         bind_host_id = self.driver.network_binding_host_id(context, instance)
5159         network_info = self.network_api.allocate_port_for_instance(
5160             context, instance, port_id, network_id, requested_ip,
5161             bind_host_id=bind_host_id)
5162         if len(network_info) != 1:
5163             LOG.error('allocate_port_for_instance returned %(ports)s '
5164                       'ports', {'ports': len(network_info)})
5165             raise exception.InterfaceAttachFailed(
5166                     instance_uuid=instance.uuid)
5167         image_meta = objects.ImageMeta.from_instance(instance)
5168 
5169         try:
5170             self.driver.attach_interface(context, instance, image_meta,
5171                                          network_info[0])
5172         except exception.NovaException as ex:
5173             port_id = network_info[0].get('id')
5174             LOG.warning("attach interface failed , try to deallocate "
5175                         "port %(port_id)s, reason: %(msg)s",
5176                         {'port_id': port_id, 'msg': ex},
5177                         instance=instance)
5178             try:
5179                 self.network_api.deallocate_port_for_instance(
5180                     context, instance, port_id)
5181             except Exception:
5182                 LOG.warning("deallocate port %(port_id)s failed",
5183                             {'port_id': port_id}, instance=instance)
5184             raise exception.InterfaceAttachFailed(
5185                 instance_uuid=instance.uuid)
5186 
5187         return network_info[0]
5188 
5189     @wrap_exception()
5190     @wrap_instance_fault
5191     def detach_interface(self, context, instance, port_id):
5192         """Detach a network adapter from an instance."""
5193         network_info = instance.info_cache.network_info
5194         condemned = None
5195         for vif in network_info:
5196             if vif['id'] == port_id:
5197                 condemned = vif
5198                 break
5199         if condemned is None:
5200             raise exception.PortNotFound(_("Port %s is not "
5201                                            "attached") % port_id)
5202         try:
5203             self.driver.detach_interface(context, instance, condemned)
5204         except exception.NovaException as ex:
5205             LOG.warning("Detach interface failed, port_id=%(port_id)s,"
5206                         " reason: %(msg)s",
5207                         {'port_id': port_id, 'msg': ex}, instance=instance)
5208             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5209         else:
5210             try:
5211                 self.network_api.deallocate_port_for_instance(
5212                     context, instance, port_id)
5213             except Exception as ex:
5214                 with excutils.save_and_reraise_exception():
5215                     # Since this is a cast operation, log the failure for
5216                     # triage.
5217                     LOG.warning('Failed to deallocate port %(port_id)s '
5218                                 'for instance. Error: %(error)s',
5219                                 {'port_id': port_id, 'error': ex},
5220                                 instance=instance)
5221 
5222     def _get_compute_info(self, context, host):
5223         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5224             context, host)
5225 
5226     @wrap_exception()
5227     def check_instance_shared_storage(self, ctxt, instance, data):
5228         """Check if the instance files are shared
5229 
5230         :param ctxt: security context
5231         :param instance: dict of instance data
5232         :param data: result of driver.check_instance_shared_storage_local
5233 
5234         Returns True if instance disks located on shared storage and
5235         False otherwise.
5236         """
5237         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5238 
5239     @wrap_exception()
5240     @wrap_instance_event(prefix='compute')
5241     @wrap_instance_fault
5242     def check_can_live_migrate_destination(self, ctxt, instance,
5243                                            block_migration, disk_over_commit):
5244         """Check if it is possible to execute live migration.
5245 
5246         This runs checks on the destination host, and then calls
5247         back to the source host to check the results.
5248 
5249         :param context: security context
5250         :param instance: dict of instance data
5251         :param block_migration: if true, prepare for block migration
5252                                 if None, calculate it in driver
5253         :param disk_over_commit: if true, allow disk over commit
5254                                  if None, ignore disk usage checking
5255         :returns: a dict containing migration info
5256         """
5257         return self._do_check_can_live_migrate_destination(ctxt, instance,
5258                                                             block_migration,
5259                                                             disk_over_commit)
5260 
5261     def _do_check_can_live_migrate_destination(self, ctxt, instance,
5262                                                block_migration,
5263                                                disk_over_commit):
5264         src_compute_info = obj_base.obj_to_primitive(
5265             self._get_compute_info(ctxt, instance.host))
5266         dst_compute_info = obj_base.obj_to_primitive(
5267             self._get_compute_info(ctxt, CONF.host))
5268         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5269             instance, src_compute_info, dst_compute_info,
5270             block_migration, disk_over_commit)
5271         LOG.debug('destination check data is %s', dest_check_data)
5272         try:
5273             migrate_data = self.compute_rpcapi.\
5274                                 check_can_live_migrate_source(ctxt, instance,
5275                                                               dest_check_data)
5276         finally:
5277             self.driver.cleanup_live_migration_destination_check(ctxt,
5278                     dest_check_data)
5279         return migrate_data
5280 
5281     @wrap_exception()
5282     @wrap_instance_event(prefix='compute')
5283     @wrap_instance_fault
5284     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5285         """Check if it is possible to execute live migration.
5286 
5287         This checks if the live migration can succeed, based on the
5288         results from check_can_live_migrate_destination.
5289 
5290         :param ctxt: security context
5291         :param instance: dict of instance data
5292         :param dest_check_data: result of check_can_live_migrate_destination
5293         :returns: a dict containing migration info
5294         """
5295         is_volume_backed = compute_utils.is_volume_backed_instance(ctxt,
5296                                                                       instance)
5297         # TODO(tdurakov): remove dict to object conversion once RPC API version
5298         # is bumped to 5.x
5299         got_migrate_data_object = isinstance(dest_check_data,
5300                                              migrate_data_obj.LiveMigrateData)
5301         if not got_migrate_data_object:
5302             dest_check_data = \
5303                 migrate_data_obj.LiveMigrateData.detect_implementation(
5304                     dest_check_data)
5305         dest_check_data.is_volume_backed = is_volume_backed
5306         block_device_info = self._get_instance_block_device_info(
5307                             ctxt, instance, refresh_conn_info=False)
5308         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5309                                                            dest_check_data,
5310                                                            block_device_info)
5311         if not got_migrate_data_object:
5312             result = result.to_legacy_dict()
5313         LOG.debug('source check data is %s', result)
5314         return result
5315 
5316     @wrap_exception()
5317     @wrap_instance_event(prefix='compute')
5318     @wrap_instance_fault
5319     def pre_live_migration(self, context, instance, block_migration, disk,
5320                            migrate_data):
5321         """Preparations for live migration at dest host.
5322 
5323         :param context: security context
5324         :param instance: dict of instance data
5325         :param block_migration: if true, prepare for block migration
5326         :param migrate_data: A dict or LiveMigrateData object holding data
5327                              required for live migration without shared
5328                              storage.
5329 
5330         """
5331         LOG.debug('pre_live_migration data is %s', migrate_data)
5332         # TODO(tdurakov): remove dict to object conversion once RPC API version
5333         # is bumped to 5.x
5334         got_migrate_data_object = isinstance(migrate_data,
5335                                              migrate_data_obj.LiveMigrateData)
5336         if not got_migrate_data_object:
5337             migrate_data = \
5338                 migrate_data_obj.LiveMigrateData.detect_implementation(
5339                     migrate_data)
5340         block_device_info = self._get_instance_block_device_info(
5341                             context, instance, refresh_conn_info=True)
5342 
5343         network_info = self.network_api.get_instance_nw_info(context, instance)
5344         self._notify_about_instance_usage(
5345                      context, instance, "live_migration.pre.start",
5346                      network_info=network_info)
5347 
5348         migrate_data = self.driver.pre_live_migration(context,
5349                                        instance,
5350                                        block_device_info,
5351                                        network_info,
5352                                        disk,
5353                                        migrate_data)
5354         LOG.debug('driver pre_live_migration data is %s', migrate_data)
5355 
5356         # NOTE(tr3buchet): setup networks on destination host
5357         self.network_api.setup_networks_on_host(context, instance,
5358                                                          self.host)
5359 
5360         # Creating filters to hypervisors and firewalls.
5361         # An example is that nova-instance-instance-xxx,
5362         # which is written to libvirt.xml(Check "virsh nwfilter-list")
5363         # This nwfilter is necessary on the destination host.
5364         # In addition, this method is creating filtering rule
5365         # onto destination host.
5366         self.driver.ensure_filtering_rules_for_instance(instance,
5367                                             network_info)
5368 
5369         self._notify_about_instance_usage(
5370                      context, instance, "live_migration.pre.end",
5371                      network_info=network_info)
5372         # TODO(tdurakov): remove dict to object conversion once RPC API version
5373         # is bumped to 5.x
5374         if not got_migrate_data_object and migrate_data:
5375             migrate_data = migrate_data.to_legacy_dict(
5376                 pre_migration_result=True)
5377             migrate_data = migrate_data['pre_live_migration_result']
5378         LOG.debug('pre_live_migration result data is %s', migrate_data)
5379         return migrate_data
5380 
5381     def _do_live_migration(self, context, dest, instance, block_migration,
5382                            migration, migrate_data):
5383         # NOTE(danms): We should enhance the RT to account for migrations
5384         # and use the status field to denote when the accounting has been
5385         # done on source/destination. For now, this is just here for status
5386         # reporting
5387         self._set_migration_status(migration, 'preparing')
5388 
5389         got_migrate_data_object = isinstance(migrate_data,
5390                                              migrate_data_obj.LiveMigrateData)
5391         if not got_migrate_data_object:
5392             migrate_data = \
5393                 migrate_data_obj.LiveMigrateData.detect_implementation(
5394                     migrate_data)
5395 
5396         try:
5397             if ('block_migration' in migrate_data and
5398                     migrate_data.block_migration):
5399                 block_device_info = self._get_instance_block_device_info(
5400                     context, instance)
5401                 disk = self.driver.get_instance_disk_info(
5402                     instance, block_device_info=block_device_info)
5403             else:
5404                 disk = None
5405 
5406             migrate_data = self.compute_rpcapi.pre_live_migration(
5407                 context, instance,
5408                 block_migration, disk, dest, migrate_data)
5409         except Exception:
5410             with excutils.save_and_reraise_exception():
5411                 LOG.exception('Pre live migration failed at %s',
5412                               dest, instance=instance)
5413                 self._set_migration_status(migration, 'error')
5414                 self._rollback_live_migration(context, instance, dest,
5415                                               migrate_data)
5416 
5417         self._set_migration_status(migration, 'running')
5418 
5419         if migrate_data:
5420             migrate_data.migration = migration
5421         LOG.debug('live_migration data is %s', migrate_data)
5422         try:
5423             self.driver.live_migration(context, instance, dest,
5424                                        self._post_live_migration,
5425                                        self._rollback_live_migration,
5426                                        block_migration, migrate_data)
5427         except Exception:
5428             LOG.exception('Live migration failed.', instance=instance)
5429             with excutils.save_and_reraise_exception():
5430                 # Put instance and migration into error state,
5431                 # as its almost certainly too late to rollback
5432                 self._set_migration_status(migration, 'error')
5433                 # first refresh instance as it may have got updated by
5434                 # post_live_migration_at_destination
5435                 instance.refresh()
5436                 self._set_instance_obj_error_state(context, instance,
5437                                                    clean_task_state=True)
5438 
5439     @wrap_exception()
5440     @wrap_instance_event(prefix='compute')
5441     @wrap_instance_fault
5442     def live_migration(self, context, dest, instance, block_migration,
5443                        migration, migrate_data):
5444         """Executing live migration.
5445 
5446         :param context: security context
5447         :param dest: destination host
5448         :param instance: a nova.objects.instance.Instance object
5449         :param block_migration: if true, prepare for block migration
5450         :param migration: an nova.objects.Migration object
5451         :param migrate_data: implementation specific params
5452 
5453         """
5454         self._set_migration_status(migration, 'queued')
5455 
5456         def dispatch_live_migration(*args, **kwargs):
5457             with self._live_migration_semaphore:
5458                 self._do_live_migration(*args, **kwargs)
5459 
5460         # NOTE(danms): We spawn here to return the RPC worker thread back to
5461         # the pool. Since what follows could take a really long time, we don't
5462         # want to tie up RPC workers.
5463         utils.spawn_n(dispatch_live_migration,
5464                       context, dest, instance,
5465                       block_migration, migration,
5466                       migrate_data)
5467 
5468     # TODO(tdurakov): migration_id is used since 4.12 rpc api version
5469     # remove migration_id parameter when the compute RPC version
5470     # is bumped to 5.x.
5471     @wrap_exception()
5472     @wrap_instance_event(prefix='compute')
5473     @wrap_instance_fault
5474     def live_migration_force_complete(self, context, instance,
5475                                       migration_id=None):
5476         """Force live migration to complete.
5477 
5478         :param context: Security context
5479         :param instance: The instance that is being migrated
5480         :param migration_id: ID of ongoing migration; is currently not used,
5481         and isn't removed for backward compatibility
5482         """
5483 
5484         self._notify_about_instance_usage(
5485             context, instance, 'live.migration.force.complete.start')
5486         self.driver.live_migration_force_complete(instance)
5487         self._notify_about_instance_usage(
5488             context, instance, 'live.migration.force.complete.end')
5489 
5490     @wrap_exception()
5491     @wrap_instance_event(prefix='compute')
5492     @wrap_instance_fault
5493     def live_migration_abort(self, context, instance, migration_id):
5494         """Abort an in-progress live migration.
5495 
5496         :param context: Security context
5497         :param instance: The instance that is being migrated
5498         :param migration_id: ID of in-progress live migration
5499 
5500         """
5501         migration = objects.Migration.get_by_id(context, migration_id)
5502         if migration.status != 'running':
5503             raise exception.InvalidMigrationState(migration_id=migration_id,
5504                     instance_uuid=instance.uuid,
5505                     state=migration.status,
5506                     method='abort live migration')
5507 
5508         self._notify_about_instance_usage(
5509             context, instance, 'live.migration.abort.start')
5510         self.driver.live_migration_abort(instance)
5511         self._notify_about_instance_usage(
5512             context, instance, 'live.migration.abort.end')
5513 
5514     def _live_migration_cleanup_flags(self, migrate_data):
5515         """Determine whether disks or instance path need to be cleaned up after
5516         live migration (at source on success, at destination on rollback)
5517 
5518         Block migration needs empty image at destination host before migration
5519         starts, so if any failure occurs, any empty images has to be deleted.
5520 
5521         Also Volume backed live migration w/o shared storage needs to delete
5522         newly created instance-xxx dir on the destination as a part of its
5523         rollback process
5524 
5525         :param migrate_data: implementation specific data
5526         :returns: (bool, bool) -- do_cleanup, destroy_disks
5527         """
5528         # NOTE(pkoniszewski): block migration specific params are set inside
5529         # migrate_data objects for drivers that expose block live migration
5530         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
5531         # cleanup is not needed.
5532         is_shared_block_storage = True
5533         is_shared_instance_path = True
5534         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
5535             is_shared_block_storage = migrate_data.is_shared_block_storage
5536             is_shared_instance_path = migrate_data.is_shared_instance_path
5537         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
5538             is_shared_block_storage = not migrate_data.block_migration
5539             is_shared_instance_path = not migrate_data.block_migration
5540         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
5541             is_shared_instance_path = migrate_data.is_shared_instance_path
5542             is_shared_block_storage = migrate_data.is_shared_instance_path
5543 
5544         # No instance booting at source host, but instance dir
5545         # must be deleted for preparing next block migration
5546         # must be deleted for preparing next live migration w/o shared storage
5547         do_cleanup = not is_shared_instance_path
5548         destroy_disks = not is_shared_block_storage
5549 
5550         return (do_cleanup, destroy_disks)
5551 
5552     @wrap_exception()
5553     @wrap_instance_fault
5554     def _post_live_migration(self, ctxt, instance,
5555                             dest, block_migration=False, migrate_data=None):
5556         """Post operations for live migration.
5557 
5558         This method is called from live_migration
5559         and mainly updating database record.
5560 
5561         :param ctxt: security context
5562         :param instance: instance dict
5563         :param dest: destination host
5564         :param block_migration: if true, prepare for block migration
5565         :param migrate_data: if not None, it is a dict which has data
5566         required for live migration without shared storage
5567 
5568         """
5569         LOG.info('_post_live_migration() is started..',
5570                  instance=instance)
5571 
5572         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5573                 ctxt, instance.uuid)
5574 
5575         # Cleanup source host post live-migration
5576         block_device_info = self._get_instance_block_device_info(
5577                             ctxt, instance, bdms=bdms)
5578         self.driver.post_live_migration(ctxt, instance, block_device_info,
5579                                         migrate_data)
5580 
5581         # Detaching volumes.
5582         connector = self.driver.get_volume_connector(instance)
5583         for bdm in bdms:
5584             # NOTE(vish): We don't want to actually mark the volume
5585             #             detached, or delete the bdm, just remove the
5586             #             connection from this host.
5587 
5588             # remove the volume connection without detaching from hypervisor
5589             # because the instance is not running anymore on the current host
5590             if bdm.is_volume:
5591                 self.volume_api.terminate_connection(ctxt, bdm.volume_id,
5592                                                      connector)
5593 
5594         # Releasing vlan.
5595         # (not necessary in current implementation?)
5596 
5597         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
5598 
5599         self._notify_about_instance_usage(ctxt, instance,
5600                                           "live_migration._post.start",
5601                                           network_info=network_info)
5602         # Releasing security group ingress rule.
5603         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
5604                   instance=instance)
5605         self.driver.unfilter_instance(instance,
5606                                       network_info)
5607 
5608         migration = {'source_compute': self.host,
5609                      'dest_compute': dest, }
5610         self.network_api.migrate_instance_start(ctxt,
5611                                                 instance,
5612                                                 migration)
5613 
5614         destroy_vifs = False
5615         try:
5616             self.driver.post_live_migration_at_source(ctxt, instance,
5617                                                       network_info)
5618         except NotImplementedError as ex:
5619             LOG.debug(ex, instance=instance)
5620             # For all hypervisors other than libvirt, there is a possibility
5621             # they are unplugging networks from source node in the cleanup
5622             # method
5623             destroy_vifs = True
5624 
5625         # Define domain at destination host, without doing it,
5626         # pause/suspend/terminate do not work.
5627         post_at_dest_success = True
5628         try:
5629             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
5630                     instance, block_migration, dest)
5631         except Exception as error:
5632             post_at_dest_success = False
5633             # We don't want to break _post_live_migration() if
5634             # post_live_migration_at_destination() fails as it should never
5635             # affect cleaning up source node.
5636             LOG.exception("Post live migration at destination %s failed",
5637                           dest, instance=instance, error=error)
5638 
5639         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5640                 migrate_data)
5641 
5642         if do_cleanup:
5643             LOG.debug('Calling driver.cleanup from _post_live_migration',
5644                       instance=instance)
5645             self.driver.cleanup(ctxt, instance, network_info,
5646                                 destroy_disks=destroy_disks,
5647                                 migrate_data=migrate_data,
5648                                 destroy_vifs=destroy_vifs)
5649 
5650         self.instance_events.clear_events_for_instance(instance)
5651 
5652         # NOTE(timello): make sure we update available resources on source
5653         # host even before next periodic task.
5654         self.update_available_resource(ctxt)
5655 
5656         self._update_scheduler_instance_info(ctxt, instance)
5657         self._notify_about_instance_usage(ctxt, instance,
5658                                           "live_migration._post.end",
5659                                           network_info=network_info)
5660         if post_at_dest_success:
5661             LOG.info('Migrating instance to %s finished successfully.',
5662                      dest, instance=instance)
5663 
5664         if migrate_data and migrate_data.obj_attr_is_set('migration'):
5665             migrate_data.migration.status = 'completed'
5666             migrate_data.migration.save()
5667 
5668     def _consoles_enabled(self):
5669         """Returns whether a console is enable."""
5670         return (CONF.vnc.enabled or CONF.spice.enabled or
5671                 CONF.rdp.enabled or CONF.serial_console.enabled or
5672                 CONF.mks.enabled)
5673 
5674     @wrap_exception()
5675     @wrap_instance_event(prefix='compute')
5676     @wrap_instance_fault
5677     def post_live_migration_at_destination(self, context, instance,
5678                                            block_migration):
5679         """Post operations for live migration .
5680 
5681         :param context: security context
5682         :param instance: Instance dict
5683         :param block_migration: if true, prepare for block migration
5684 
5685         """
5686         LOG.info('Post operation of migration started',
5687                  instance=instance)
5688 
5689         # NOTE(tr3buchet): setup networks on destination host
5690         #                  this is called a second time because
5691         #                  multi_host does not create the bridge in
5692         #                  plug_vifs
5693         self.network_api.setup_networks_on_host(context, instance,
5694                                                          self.host)
5695         migration = {'source_compute': instance.host,
5696                      'dest_compute': self.host, }
5697         self.network_api.migrate_instance_finish(context,
5698                                                  instance,
5699                                                  migration)
5700 
5701         network_info = self.network_api.get_instance_nw_info(context, instance)
5702         self._notify_about_instance_usage(
5703                      context, instance, "live_migration.post.dest.start",
5704                      network_info=network_info)
5705         block_device_info = self._get_instance_block_device_info(context,
5706                                                                  instance)
5707 
5708         try:
5709             self.driver.post_live_migration_at_destination(
5710                 context, instance, network_info, block_migration,
5711                 block_device_info)
5712         except Exception:
5713             with excutils.save_and_reraise_exception():
5714                 instance.vm_state = vm_states.ERROR
5715                 LOG.error('Unexpected error during post live migration at '
5716                           'destination host.', instance=instance)
5717         finally:
5718             # Restore instance state and update host
5719             current_power_state = self._get_power_state(context, instance)
5720             node_name = None
5721             prev_host = instance.host
5722             try:
5723                 compute_node = self._get_compute_info(context, self.host)
5724                 node_name = compute_node.hypervisor_hostname
5725             except exception.ComputeHostNotFound:
5726                 LOG.exception('Failed to get compute_info for %s', self.host)
5727             finally:
5728                 instance.host = self.host
5729                 instance.power_state = current_power_state
5730                 instance.task_state = None
5731                 instance.node = node_name
5732                 instance.progress = 0
5733                 instance.save(expected_task_state=task_states.MIGRATING)
5734 
5735         # NOTE(tr3buchet): tear down networks on source host
5736         self.network_api.setup_networks_on_host(context, instance,
5737                                                 prev_host, teardown=True)
5738         # NOTE(vish): this is necessary to update dhcp
5739         self.network_api.setup_networks_on_host(context, instance, self.host)
5740         self._notify_about_instance_usage(
5741                      context, instance, "live_migration.post.dest.end",
5742                      network_info=network_info)
5743 
5744     @wrap_exception()
5745     @wrap_instance_fault
5746     def _rollback_live_migration(self, context, instance,
5747                                  dest, migrate_data=None,
5748                                  migration_status='error'):
5749         """Recovers Instance/volume state from migrating -> running.
5750 
5751         :param context: security context
5752         :param instance: nova.objects.instance.Instance object
5753         :param dest:
5754             This method is called from live migration src host.
5755             This param specifies destination host.
5756         :param migrate_data:
5757             if not none, contains implementation specific data.
5758         :param migration_status:
5759             Contains the status we want to set for the migration object
5760 
5761         """
5762         instance.task_state = None
5763         instance.progress = 0
5764         instance.save(expected_task_state=[task_states.MIGRATING])
5765 
5766         # TODO(tdurakov): remove dict to object conversion once RPC API version
5767         # is bumped to 5.x
5768         if isinstance(migrate_data, dict):
5769             migration = migrate_data.pop('migration', None)
5770             migrate_data = \
5771                 migrate_data_obj.LiveMigrateData.detect_implementation(
5772                     migrate_data)
5773         elif (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
5774               migrate_data.obj_attr_is_set('migration')):
5775             migration = migrate_data.migration
5776         else:
5777             migration = None
5778 
5779         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
5780         self.network_api.setup_networks_on_host(context, instance, self.host)
5781 
5782         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5783                 context, instance.uuid)
5784         for bdm in bdms:
5785             if bdm.is_volume:
5786                 self.compute_rpcapi.remove_volume_connection(
5787                         context, instance, bdm.volume_id, dest)
5788 
5789         self._notify_about_instance_usage(context, instance,
5790                                           "live_migration._rollback.start")
5791 
5792         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5793                 migrate_data)
5794 
5795         if do_cleanup:
5796             self.compute_rpcapi.rollback_live_migration_at_destination(
5797                     context, instance, dest, destroy_disks=destroy_disks,
5798                     migrate_data=migrate_data)
5799 
5800         self._notify_about_instance_usage(context, instance,
5801                                           "live_migration._rollback.end")
5802 
5803         self._set_migration_status(migration, migration_status)
5804 
5805     @wrap_exception()
5806     @wrap_instance_event(prefix='compute')
5807     @wrap_instance_fault
5808     def rollback_live_migration_at_destination(self, context, instance,
5809                                                destroy_disks,
5810                                                migrate_data):
5811         """Cleaning up image directory that is created pre_live_migration.
5812 
5813         :param context: security context
5814         :param instance: a nova.objects.instance.Instance object sent over rpc
5815         """
5816         network_info = self.network_api.get_instance_nw_info(context, instance)
5817         self._notify_about_instance_usage(
5818                       context, instance, "live_migration.rollback.dest.start",
5819                       network_info=network_info)
5820         try:
5821             # NOTE(tr3buchet): tear down networks on destination host
5822             self.network_api.setup_networks_on_host(context, instance,
5823                                                     self.host, teardown=True)
5824         except Exception:
5825             with excutils.save_and_reraise_exception():
5826                 # NOTE(tdurakov): even if teardown networks fails driver
5827                 # should try to rollback live migration on destination.
5828                 LOG.exception('An error occurred while deallocating network.',
5829                               instance=instance)
5830         finally:
5831             # always run this even if setup_networks_on_host fails
5832             # NOTE(vish): The mapping is passed in so the driver can disconnect
5833             #             from remote volumes if necessary
5834             block_device_info = self._get_instance_block_device_info(context,
5835                                                                      instance)
5836             # TODO(tdurakov): remove dict to object conversion once RPC API
5837             # version is bumped to 5.x
5838             if isinstance(migrate_data, dict):
5839                 migrate_data = \
5840                     migrate_data_obj.LiveMigrateData.detect_implementation(
5841                         migrate_data)
5842             self.driver.rollback_live_migration_at_destination(
5843                 context, instance, network_info, block_device_info,
5844                 destroy_disks=destroy_disks, migrate_data=migrate_data)
5845 
5846         self._notify_about_instance_usage(
5847                         context, instance, "live_migration.rollback.dest.end",
5848                         network_info=network_info)
5849 
5850     @periodic_task.periodic_task(
5851         spacing=CONF.heal_instance_info_cache_interval)
5852     def _heal_instance_info_cache(self, context):
5853         """Called periodically.  On every call, try to update the
5854         info_cache's network information for another instance by
5855         calling to the network manager.
5856 
5857         This is implemented by keeping a cache of uuids of instances
5858         that live on this host.  On each call, we pop one off of a
5859         list, pull the DB record, and try the call to the network API.
5860         If anything errors don't fail, as it's possible the instance
5861         has been deleted, etc.
5862         """
5863         heal_interval = CONF.heal_instance_info_cache_interval
5864         if not heal_interval:
5865             return
5866 
5867         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
5868         instance = None
5869 
5870         LOG.debug('Starting heal instance info cache')
5871 
5872         if not instance_uuids:
5873             # The list of instances to heal is empty so rebuild it
5874             LOG.debug('Rebuilding the list of instances to heal')
5875             db_instances = objects.InstanceList.get_by_host(
5876                 context, self.host, expected_attrs=[], use_slave=True)
5877             for inst in db_instances:
5878                 # We don't want to refresh the cache for instances
5879                 # which are building or deleting so don't put them
5880                 # in the list. If they are building they will get
5881                 # added to the list next time we build it.
5882                 if (inst.vm_state == vm_states.BUILDING):
5883                     LOG.debug('Skipping network cache update for instance '
5884                               'because it is Building.', instance=inst)
5885                     continue
5886                 if (inst.task_state == task_states.DELETING):
5887                     LOG.debug('Skipping network cache update for instance '
5888                               'because it is being deleted.', instance=inst)
5889                     continue
5890 
5891                 if not instance:
5892                     # Save the first one we find so we don't
5893                     # have to get it again
5894                     instance = inst
5895                 else:
5896                     instance_uuids.append(inst['uuid'])
5897 
5898             self._instance_uuids_to_heal = instance_uuids
5899         else:
5900             # Find the next valid instance on the list
5901             while instance_uuids:
5902                 try:
5903                     inst = objects.Instance.get_by_uuid(
5904                             context, instance_uuids.pop(0),
5905                             expected_attrs=['system_metadata', 'info_cache',
5906                                             'flavor'],
5907                             use_slave=True)
5908                 except exception.InstanceNotFound:
5909                     # Instance is gone.  Try to grab another.
5910                     continue
5911 
5912                 # Check the instance hasn't been migrated
5913                 if inst.host != self.host:
5914                     LOG.debug('Skipping network cache update for instance '
5915                               'because it has been migrated to another '
5916                               'host.', instance=inst)
5917                 # Check the instance isn't being deleting
5918                 elif inst.task_state == task_states.DELETING:
5919                     LOG.debug('Skipping network cache update for instance '
5920                               'because it is being deleted.', instance=inst)
5921                 else:
5922                     instance = inst
5923                     break
5924 
5925         if instance:
5926             # We have an instance now to refresh
5927             try:
5928                 # Call to network API to get instance info.. this will
5929                 # force an update to the instance's info_cache
5930                 self.network_api.get_instance_nw_info(context, instance)
5931                 LOG.debug('Updated the network info_cache for instance',
5932                           instance=instance)
5933             except exception.InstanceNotFound:
5934                 # Instance is gone.
5935                 LOG.debug('Instance no longer exists. Unable to refresh',
5936                           instance=instance)
5937                 return
5938             except exception.InstanceInfoCacheNotFound:
5939                 # InstanceInfoCache is gone.
5940                 LOG.debug('InstanceInfoCache no longer exists. '
5941                           'Unable to refresh', instance=instance)
5942             except Exception:
5943                 LOG.error('An error occurred while refreshing the network '
5944                           'cache.', instance=instance, exc_info=True)
5945         else:
5946             LOG.debug("Didn't find any instances for network info cache "
5947                       "update.")
5948 
5949     @periodic_task.periodic_task
5950     def _poll_rebooting_instances(self, context):
5951         if CONF.reboot_timeout > 0:
5952             filters = {'task_state':
5953                        [task_states.REBOOTING,
5954                         task_states.REBOOT_STARTED,
5955                         task_states.REBOOT_PENDING],
5956                        'host': self.host}
5957             rebooting = objects.InstanceList.get_by_filters(
5958                 context, filters, expected_attrs=[], use_slave=True)
5959 
5960             to_poll = []
5961             for instance in rebooting:
5962                 if timeutils.is_older_than(instance.updated_at,
5963                                            CONF.reboot_timeout):
5964                     to_poll.append(instance)
5965 
5966             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
5967 
5968     @periodic_task.periodic_task
5969     def _poll_rescued_instances(self, context):
5970         if CONF.rescue_timeout > 0:
5971             filters = {'vm_state': vm_states.RESCUED,
5972                        'host': self.host}
5973             rescued_instances = objects.InstanceList.get_by_filters(
5974                 context, filters, expected_attrs=["system_metadata"],
5975                 use_slave=True)
5976 
5977             to_unrescue = []
5978             for instance in rescued_instances:
5979                 if timeutils.is_older_than(instance.launched_at,
5980                                            CONF.rescue_timeout):
5981                     to_unrescue.append(instance)
5982 
5983             for instance in to_unrescue:
5984                 self.compute_api.unrescue(context, instance)
5985 
5986     @periodic_task.periodic_task
5987     def _poll_unconfirmed_resizes(self, context):
5988         if CONF.resize_confirm_window == 0:
5989             return
5990 
5991         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
5992                 context, CONF.resize_confirm_window, self.host,
5993                 use_slave=True)
5994 
5995         migrations_info = dict(migration_count=len(migrations),
5996                 confirm_window=CONF.resize_confirm_window)
5997 
5998         if migrations_info["migration_count"] > 0:
5999             LOG.info("Found %(migration_count)d unconfirmed migrations "
6000                      "older than %(confirm_window)d seconds",
6001                      migrations_info)
6002 
6003         def _set_migration_to_error(migration, reason, **kwargs):
6004             LOG.warning("Setting migration %(migration_id)s to error: "
6005                         "%(reason)s",
6006                         {'migration_id': migration['id'], 'reason': reason},
6007                         **kwargs)
6008             migration.status = 'error'
6009             with migration.obj_as_admin():
6010                 migration.save()
6011 
6012         for migration in migrations:
6013             instance_uuid = migration.instance_uuid
6014             LOG.info("Automatically confirming migration "
6015                      "%(migration_id)s for instance %(instance_uuid)s",
6016                      {'migration_id': migration.id,
6017                       'instance_uuid': instance_uuid})
6018             expected_attrs = ['metadata', 'system_metadata']
6019             try:
6020                 instance = objects.Instance.get_by_uuid(context,
6021                             instance_uuid, expected_attrs=expected_attrs,
6022                             use_slave=True)
6023             except exception.InstanceNotFound:
6024                 reason = (_("Instance %s not found") %
6025                           instance_uuid)
6026                 _set_migration_to_error(migration, reason)
6027                 continue
6028             if instance.vm_state == vm_states.ERROR:
6029                 reason = _("In ERROR state")
6030                 _set_migration_to_error(migration, reason,
6031                                         instance=instance)
6032                 continue
6033             # race condition: The instance in DELETING state should not be
6034             # set the migration state to error, otherwise the instance in
6035             # to be deleted which is in RESIZED state
6036             # will not be able to confirm resize
6037             if instance.task_state in [task_states.DELETING,
6038                                        task_states.SOFT_DELETING]:
6039                 msg = ("Instance being deleted or soft deleted during resize "
6040                        "confirmation. Skipping.")
6041                 LOG.debug(msg, instance=instance)
6042                 continue
6043 
6044             # race condition: This condition is hit when this method is
6045             # called between the save of the migration record with a status of
6046             # finished and the save of the instance object with a state of
6047             # RESIZED. The migration record should not be set to error.
6048             if instance.task_state == task_states.RESIZE_FINISH:
6049                 msg = ("Instance still resizing during resize "
6050                        "confirmation. Skipping.")
6051                 LOG.debug(msg, instance=instance)
6052                 continue
6053 
6054             vm_state = instance.vm_state
6055             task_state = instance.task_state
6056             if vm_state != vm_states.RESIZED or task_state is not None:
6057                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
6058                            "RESIZED/None") %
6059                           {'vm_state': vm_state,
6060                            'task_state': task_state})
6061                 _set_migration_to_error(migration, reason,
6062                                         instance=instance)
6063                 continue
6064             try:
6065                 self.compute_api.confirm_resize(context, instance,
6066                                                 migration=migration)
6067             except Exception as e:
6068                 LOG.info("Error auto-confirming resize: %s. "
6069                          "Will retry later.", e, instance=instance)
6070 
6071     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
6072     def _poll_shelved_instances(self, context):
6073 
6074         if CONF.shelved_offload_time <= 0:
6075             return
6076 
6077         filters = {'vm_state': vm_states.SHELVED,
6078                    'task_state': None,
6079                    'host': self.host}
6080         shelved_instances = objects.InstanceList.get_by_filters(
6081             context, filters=filters, expected_attrs=['system_metadata'],
6082             use_slave=True)
6083 
6084         to_gc = []
6085         for instance in shelved_instances:
6086             sys_meta = instance.system_metadata
6087             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
6088             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
6089                 to_gc.append(instance)
6090 
6091         for instance in to_gc:
6092             try:
6093                 instance.task_state = task_states.SHELVING_OFFLOADING
6094                 instance.save(expected_task_state=(None,))
6095                 self.shelve_offload_instance(context, instance,
6096                                              clean_shutdown=False)
6097             except Exception:
6098                 LOG.exception('Periodic task failed to offload instance.',
6099                               instance=instance)
6100 
6101     @periodic_task.periodic_task
6102     def _instance_usage_audit(self, context):
6103         if not CONF.instance_usage_audit:
6104             return
6105 
6106         begin, end = utils.last_completed_audit_period()
6107         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
6108                                self.host):
6109             return
6110 
6111         instances = objects.InstanceList.get_active_by_window_joined(
6112             context, begin, end, host=self.host,
6113             expected_attrs=['system_metadata', 'info_cache', 'metadata',
6114                             'flavor'],
6115             use_slave=True)
6116         num_instances = len(instances)
6117         errors = 0
6118         successes = 0
6119         LOG.info("Running instance usage audit for host %(host)s "
6120                  "from %(begin_time)s to %(end_time)s. "
6121                  "%(number_instances)s instances.",
6122                  {'host': self.host,
6123                   'begin_time': begin,
6124                   'end_time': end,
6125                   'number_instances': num_instances})
6126         start_time = time.time()
6127         task_log = objects.TaskLog(context)
6128         task_log.task_name = 'instance_usage_audit'
6129         task_log.period_beginning = begin
6130         task_log.period_ending = end
6131         task_log.host = self.host
6132         task_log.task_items = num_instances
6133         task_log.message = 'Instance usage audit started...'
6134         task_log.begin_task()
6135         for instance in instances:
6136             try:
6137                 compute_utils.notify_usage_exists(
6138                     self.notifier, context, instance,
6139                     ignore_missing_network_data=False)
6140                 successes += 1
6141             except Exception:
6142                 LOG.exception('Failed to generate usage '
6143                               'audit for instance '
6144                               'on host %s', self.host,
6145                               instance=instance)
6146                 errors += 1
6147         task_log.errors = errors
6148         task_log.message = (
6149             'Instance usage audit ran for host %s, %s instances in %s seconds.'
6150             % (self.host, num_instances, time.time() - start_time))
6151         task_log.end_task()
6152 
6153     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
6154     def _poll_bandwidth_usage(self, context):
6155 
6156         if not self._bw_usage_supported:
6157             return
6158 
6159         prev_time, start_time = utils.last_completed_audit_period()
6160 
6161         curr_time = time.time()
6162         if (curr_time - self._last_bw_usage_poll >
6163                 CONF.bandwidth_poll_interval):
6164             self._last_bw_usage_poll = curr_time
6165             LOG.info("Updating bandwidth usage cache")
6166             cells_update_interval = CONF.cells.bandwidth_update_interval
6167             if (cells_update_interval > 0 and
6168                    curr_time - self._last_bw_usage_cell_update >
6169                            cells_update_interval):
6170                 self._last_bw_usage_cell_update = curr_time
6171                 update_cells = True
6172             else:
6173                 update_cells = False
6174 
6175             instances = objects.InstanceList.get_by_host(context,
6176                                                               self.host,
6177                                                               use_slave=True)
6178             try:
6179                 bw_counters = self.driver.get_all_bw_counters(instances)
6180             except NotImplementedError:
6181                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
6182                 # implemented yet.  If they don't it doesn't break anything,
6183                 # they just don't get the info in the usage events.
6184                 # NOTE(PhilDay): Record that its not supported so we can
6185                 # skip fast on future calls rather than waste effort getting
6186                 # the list of instances.
6187                 LOG.info("Bandwidth usage not supported by hypervisor.")
6188                 self._bw_usage_supported = False
6189                 return
6190 
6191             refreshed = timeutils.utcnow()
6192             for bw_ctr in bw_counters:
6193                 # Allow switching of greenthreads between queries.
6194                 greenthread.sleep(0)
6195                 bw_in = 0
6196                 bw_out = 0
6197                 last_ctr_in = None
6198                 last_ctr_out = None
6199                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6200                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6201                     start_period=start_time, use_slave=True)
6202                 if usage:
6203                     bw_in = usage.bw_in
6204                     bw_out = usage.bw_out
6205                     last_ctr_in = usage.last_ctr_in
6206                     last_ctr_out = usage.last_ctr_out
6207                 else:
6208                     usage = (objects.BandwidthUsage.
6209                              get_by_instance_uuid_and_mac(
6210                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6211                         start_period=prev_time, use_slave=True))
6212                     if usage:
6213                         last_ctr_in = usage.last_ctr_in
6214                         last_ctr_out = usage.last_ctr_out
6215 
6216                 if last_ctr_in is not None:
6217                     if bw_ctr['bw_in'] < last_ctr_in:
6218                         # counter rollover
6219                         bw_in += bw_ctr['bw_in']
6220                     else:
6221                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6222 
6223                 if last_ctr_out is not None:
6224                     if bw_ctr['bw_out'] < last_ctr_out:
6225                         # counter rollover
6226                         bw_out += bw_ctr['bw_out']
6227                     else:
6228                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6229 
6230                 objects.BandwidthUsage(context=context).create(
6231                                               bw_ctr['uuid'],
6232                                               bw_ctr['mac_address'],
6233                                               bw_in,
6234                                               bw_out,
6235                                               bw_ctr['bw_in'],
6236                                               bw_ctr['bw_out'],
6237                                               start_period=start_time,
6238                                               last_refreshed=refreshed,
6239                                               update_cells=update_cells)
6240 
6241     def _get_host_volume_bdms(self, context, use_slave=False):
6242         """Return all block device mappings on a compute host."""
6243         compute_host_bdms = []
6244         instances = objects.InstanceList.get_by_host(context, self.host,
6245             use_slave=use_slave)
6246         for instance in instances:
6247             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6248                     context, instance.uuid, use_slave=use_slave)
6249             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6250             compute_host_bdms.append(dict(instance=instance,
6251                                           instance_bdms=instance_bdms))
6252 
6253         return compute_host_bdms
6254 
6255     def _update_volume_usage_cache(self, context, vol_usages):
6256         """Updates the volume usage cache table with a list of stats."""
6257         for usage in vol_usages:
6258             # Allow switching of greenthreads between queries.
6259             greenthread.sleep(0)
6260             vol_usage = objects.VolumeUsage(context)
6261             vol_usage.volume_id = usage['volume']
6262             vol_usage.instance_uuid = usage['instance'].uuid
6263             vol_usage.project_id = usage['instance'].project_id
6264             vol_usage.user_id = usage['instance'].user_id
6265             vol_usage.availability_zone = usage['instance'].availability_zone
6266             vol_usage.curr_reads = usage['rd_req']
6267             vol_usage.curr_read_bytes = usage['rd_bytes']
6268             vol_usage.curr_writes = usage['wr_req']
6269             vol_usage.curr_write_bytes = usage['wr_bytes']
6270             vol_usage.save()
6271             self.notifier.info(context, 'volume.usage',
6272                                compute_utils.usage_volume_info(vol_usage))
6273 
6274     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
6275     def _poll_volume_usage(self, context):
6276         if CONF.volume_usage_poll_interval == 0:
6277             return
6278 
6279         compute_host_bdms = self._get_host_volume_bdms(context,
6280                                                        use_slave=True)
6281         if not compute_host_bdms:
6282             return
6283 
6284         LOG.debug("Updating volume usage cache")
6285         try:
6286             vol_usages = self.driver.get_all_volume_usage(context,
6287                                                           compute_host_bdms)
6288         except NotImplementedError:
6289             return
6290 
6291         self._update_volume_usage_cache(context, vol_usages)
6292 
6293     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
6294                                  run_immediately=True)
6295     def _sync_power_states(self, context):
6296         """Align power states between the database and the hypervisor.
6297 
6298         To sync power state data we make a DB call to get the number of
6299         virtual machines known by the hypervisor and if the number matches the
6300         number of virtual machines known by the database, we proceed in a lazy
6301         loop, one database record at a time, checking if the hypervisor has the
6302         same power state as is in the database.
6303         """
6304         db_instances = objects.InstanceList.get_by_host(context, self.host,
6305                                                         expected_attrs=[],
6306                                                         use_slave=True)
6307 
6308         num_vm_instances = self.driver.get_num_instances()
6309         num_db_instances = len(db_instances)
6310 
6311         if num_vm_instances != num_db_instances:
6312             LOG.warning("While synchronizing instance power states, found "
6313                         "%(num_db_instances)s instances in the database "
6314                         "and %(num_vm_instances)s instances on the "
6315                         "hypervisor.",
6316                         {'num_db_instances': num_db_instances,
6317                          'num_vm_instances': num_vm_instances})
6318 
6319         def _sync(db_instance):
6320             # NOTE(melwitt): This must be synchronized as we query state from
6321             #                two separate sources, the driver and the database.
6322             #                They are set (in stop_instance) and read, in sync.
6323             @utils.synchronized(db_instance.uuid)
6324             def query_driver_power_state_and_sync():
6325                 self._query_driver_power_state_and_sync(context, db_instance)
6326 
6327             try:
6328                 query_driver_power_state_and_sync()
6329             except Exception:
6330                 LOG.exception("Periodic sync_power_state task had an "
6331                               "error while processing an instance.",
6332                               instance=db_instance)
6333 
6334             self._syncs_in_progress.pop(db_instance.uuid)
6335 
6336         for db_instance in db_instances:
6337             # process syncs asynchronously - don't want instance locking to
6338             # block entire periodic task thread
6339             uuid = db_instance.uuid
6340             if uuid in self._syncs_in_progress:
6341                 LOG.debug('Sync already in progress for %s', uuid)
6342             else:
6343                 LOG.debug('Triggering sync for uuid %s', uuid)
6344                 self._syncs_in_progress[uuid] = True
6345                 self._sync_power_pool.spawn_n(_sync, db_instance)
6346 
6347     def _query_driver_power_state_and_sync(self, context, db_instance):
6348         if db_instance.task_state is not None:
6349             LOG.info("During sync_power_state the instance has a "
6350                      "pending task (%(task)s). Skip.",
6351                      {'task': db_instance.task_state}, instance=db_instance)
6352             return
6353         # No pending tasks. Now try to figure out the real vm_power_state.
6354         try:
6355             vm_instance = self.driver.get_info(db_instance)
6356             vm_power_state = vm_instance.state
6357         except exception.InstanceNotFound:
6358             vm_power_state = power_state.NOSTATE
6359         # Note(maoy): the above get_info call might take a long time,
6360         # for example, because of a broken libvirt driver.
6361         try:
6362             self._sync_instance_power_state(context,
6363                                             db_instance,
6364                                             vm_power_state,
6365                                             use_slave=True)
6366         except exception.InstanceNotFound:
6367             # NOTE(hanlind): If the instance gets deleted during sync,
6368             # silently ignore.
6369             pass
6370 
6371     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
6372                                    use_slave=False):
6373         """Align instance power state between the database and hypervisor.
6374 
6375         If the instance is not found on the hypervisor, but is in the database,
6376         then a stop() API will be called on the instance.
6377         """
6378 
6379         # We re-query the DB to get the latest instance info to minimize
6380         # (not eliminate) race condition.
6381         db_instance.refresh(use_slave=use_slave)
6382         db_power_state = db_instance.power_state
6383         vm_state = db_instance.vm_state
6384 
6385         if self.host != db_instance.host:
6386             # on the sending end of nova-compute _sync_power_state
6387             # may have yielded to the greenthread performing a live
6388             # migration; this in turn has changed the resident-host
6389             # for the VM; However, the instance is still active, it
6390             # is just in the process of migrating to another host.
6391             # This implies that the compute source must relinquish
6392             # control to the compute destination.
6393             LOG.info("During the sync_power process the "
6394                      "instance has moved from "
6395                      "host %(src)s to host %(dst)s",
6396                      {'src': db_instance.host,
6397                       'dst': self.host},
6398                      instance=db_instance)
6399             return
6400         elif db_instance.task_state is not None:
6401             # on the receiving end of nova-compute, it could happen
6402             # that the DB instance already report the new resident
6403             # but the actual VM has not showed up on the hypervisor
6404             # yet. In this case, let's allow the loop to continue
6405             # and run the state sync in a later round
6406             LOG.info("During sync_power_state the instance has a "
6407                      "pending task (%(task)s). Skip.",
6408                      {'task': db_instance.task_state},
6409                      instance=db_instance)
6410             return
6411 
6412         orig_db_power_state = db_power_state
6413         if vm_power_state != db_power_state:
6414             LOG.info('During _sync_instance_power_state the DB '
6415                      'power_state (%(db_power_state)s) does not match '
6416                      'the vm_power_state from the hypervisor '
6417                      '(%(vm_power_state)s). Updating power_state in the '
6418                      'DB to match the hypervisor.',
6419                      {'db_power_state': db_power_state,
6420                       'vm_power_state': vm_power_state},
6421                      instance=db_instance)
6422             # power_state is always updated from hypervisor to db
6423             db_instance.power_state = vm_power_state
6424             db_instance.save()
6425             db_power_state = vm_power_state
6426 
6427         # Note(maoy): Now resolve the discrepancy between vm_state and
6428         # vm_power_state. We go through all possible vm_states.
6429         if vm_state in (vm_states.BUILDING,
6430                         vm_states.RESCUED,
6431                         vm_states.RESIZED,
6432                         vm_states.SUSPENDED,
6433                         vm_states.ERROR):
6434             # TODO(maoy): we ignore these vm_state for now.
6435             pass
6436         elif vm_state == vm_states.ACTIVE:
6437             # The only rational power state should be RUNNING
6438             if vm_power_state in (power_state.SHUTDOWN,
6439                                   power_state.CRASHED):
6440                 LOG.warning("Instance shutdown by itself. Calling the "
6441                             "stop API. Current vm_state: %(vm_state)s, "
6442                             "current task_state: %(task_state)s, "
6443                             "original DB power_state: %(db_power_state)s, "
6444                             "current VM power_state: %(vm_power_state)s",
6445                             {'vm_state': vm_state,
6446                              'task_state': db_instance.task_state,
6447                              'db_power_state': orig_db_power_state,
6448                              'vm_power_state': vm_power_state},
6449                             instance=db_instance)
6450                 try:
6451                     # Note(maoy): here we call the API instead of
6452                     # brutally updating the vm_state in the database
6453                     # to allow all the hooks and checks to be performed.
6454                     if db_instance.shutdown_terminate:
6455                         self.compute_api.delete(context, db_instance)
6456                     else:
6457                         self.compute_api.stop(context, db_instance)
6458                 except Exception:
6459                     # Note(maoy): there is no need to propagate the error
6460                     # because the same power_state will be retrieved next
6461                     # time and retried.
6462                     # For example, there might be another task scheduled.
6463                     LOG.exception("error during stop() in sync_power_state.",
6464                                   instance=db_instance)
6465             elif vm_power_state == power_state.SUSPENDED:
6466                 LOG.warning("Instance is suspended unexpectedly. Calling "
6467                             "the stop API.", instance=db_instance)
6468                 try:
6469                     self.compute_api.stop(context, db_instance)
6470                 except Exception:
6471                     LOG.exception("error during stop() in sync_power_state.",
6472                                   instance=db_instance)
6473             elif vm_power_state == power_state.PAUSED:
6474                 # Note(maoy): a VM may get into the paused state not only
6475                 # because the user request via API calls, but also
6476                 # due to (temporary) external instrumentations.
6477                 # Before the virt layer can reliably report the reason,
6478                 # we simply ignore the state discrepancy. In many cases,
6479                 # the VM state will go back to running after the external
6480                 # instrumentation is done. See bug 1097806 for details.
6481                 LOG.warning("Instance is paused unexpectedly. Ignore.",
6482                             instance=db_instance)
6483             elif vm_power_state == power_state.NOSTATE:
6484                 # Occasionally, depending on the status of the hypervisor,
6485                 # which could be restarting for example, an instance may
6486                 # not be found.  Therefore just log the condition.
6487                 LOG.warning("Instance is unexpectedly not found. Ignore.",
6488                             instance=db_instance)
6489         elif vm_state == vm_states.STOPPED:
6490             if vm_power_state not in (power_state.NOSTATE,
6491                                       power_state.SHUTDOWN,
6492                                       power_state.CRASHED):
6493                 LOG.warning("Instance is not stopped. Calling "
6494                             "the stop API. Current vm_state: %(vm_state)s,"
6495                             " current task_state: %(task_state)s, "
6496                             "original DB power_state: %(db_power_state)s, "
6497                             "current VM power_state: %(vm_power_state)s",
6498                             {'vm_state': vm_state,
6499                              'task_state': db_instance.task_state,
6500                              'db_power_state': orig_db_power_state,
6501                              'vm_power_state': vm_power_state},
6502                             instance=db_instance)
6503                 try:
6504                     # NOTE(russellb) Force the stop, because normally the
6505                     # compute API would not allow an attempt to stop a stopped
6506                     # instance.
6507                     self.compute_api.force_stop(context, db_instance)
6508                 except Exception:
6509                     LOG.exception("error during stop() in sync_power_state.",
6510                                   instance=db_instance)
6511         elif vm_state == vm_states.PAUSED:
6512             if vm_power_state in (power_state.SHUTDOWN,
6513                                   power_state.CRASHED):
6514                 LOG.warning("Paused instance shutdown by itself. Calling "
6515                             "the stop API.", instance=db_instance)
6516                 try:
6517                     self.compute_api.force_stop(context, db_instance)
6518                 except Exception:
6519                     LOG.exception("error during stop() in sync_power_state.",
6520                                   instance=db_instance)
6521         elif vm_state in (vm_states.SOFT_DELETED,
6522                           vm_states.DELETED):
6523             if vm_power_state not in (power_state.NOSTATE,
6524                                       power_state.SHUTDOWN):
6525                 # Note(maoy): this should be taken care of periodically in
6526                 # _cleanup_running_deleted_instances().
6527                 LOG.warning("Instance is not (soft-)deleted.",
6528                             instance=db_instance)
6529 
6530     @periodic_task.periodic_task
6531     def _reclaim_queued_deletes(self, context):
6532         """Reclaim instances that are queued for deletion."""
6533         interval = CONF.reclaim_instance_interval
6534         if interval <= 0:
6535             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
6536             return
6537 
6538         # TODO(comstud, jichenjc): Dummy quota object for now See bug 1296414.
6539         # The only case that the quota might be inconsistent is
6540         # the compute node died between set instance state to SOFT_DELETED
6541         # and quota commit to DB. When compute node starts again
6542         # it will have no idea the reservation is committed or not or even
6543         # expired, since it's a rare case, so marked as todo.
6544         quotas = objects.Quotas.from_reservations(context, None)
6545 
6546         filters = {'vm_state': vm_states.SOFT_DELETED,
6547                    'task_state': None,
6548                    'host': self.host}
6549         instances = objects.InstanceList.get_by_filters(
6550             context, filters,
6551             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
6552             use_slave=True)
6553         for instance in instances:
6554             if self._deleted_old_enough(instance, interval):
6555                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6556                         context, instance.uuid)
6557                 LOG.info('Reclaiming deleted instance', instance=instance)
6558                 try:
6559                     self._delete_instance(context, instance, bdms, quotas)
6560                 except Exception as e:
6561                     LOG.warning("Periodic reclaim failed to delete "
6562                                 "instance: %s",
6563                                 e, instance=instance)
6564 
6565     def update_available_resource_for_node(self, context, nodename):
6566 
6567         rt = self._get_resource_tracker()
6568         try:
6569             rt.update_available_resource(context, nodename)
6570         except exception.ComputeHostNotFound:
6571             # NOTE(comstud): We can get to this case if a node was
6572             # marked 'deleted' in the DB and then re-added with a
6573             # different auto-increment id. The cached resource
6574             # tracker tried to update a deleted record and failed.
6575             # Don't add this resource tracker to the new dict, so
6576             # that this will resolve itself on the next run.
6577             LOG.info("Compute node '%s' not found in "
6578                      "update_available_resource.", nodename)
6579             # TODO(jaypipes): Yes, this is inefficient to throw away all of the
6580             # compute nodes to force a rebuild, but this is only temporary
6581             # until Ironic baremetal node resource providers are tracked
6582             # properly in the report client and this is a tiny edge case
6583             # anyway.
6584             self._resource_tracker = None
6585             return
6586         except Exception:
6587             LOG.exception("Error updating resources for node %(node)s.",
6588                           {'node': nodename})
6589 
6590     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
6591     def update_available_resource(self, context, startup=False):
6592         """See driver.get_available_resource()
6593 
6594         Periodic process that keeps that the compute host's understanding of
6595         resource availability and usage in sync with the underlying hypervisor.
6596 
6597         :param context: security context
6598         :param startup: True if this is being called when the nova-compute
6599             service is starting, False otherwise.
6600         """
6601 
6602         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
6603                                                             use_slave=True,
6604                                                             startup=startup)
6605         nodenames = set(self.driver.get_available_nodes())
6606         for nodename in nodenames:
6607             self.update_available_resource_for_node(context, nodename)
6608 
6609         # Delete orphan compute node not reported by driver but still in db
6610         for cn in compute_nodes_in_db:
6611             if cn.hypervisor_hostname not in nodenames:
6612                 LOG.info("Deleting orphan compute node %(id)s "
6613                          "hypervisor host is %(hh)s, "
6614                          "nodes are %(nodes)s",
6615                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
6616                           'nodes': nodenames})
6617                 cn.destroy()
6618                 # Delete the corresponding resource provider in placement,
6619                 # along with any associated allocations and inventory.
6620                 # TODO(cdent): Move use of reportclient into resource tracker.
6621                 self.scheduler_client.reportclient.delete_resource_provider(
6622                     context, cn, cascade=True)
6623 
6624     def _get_compute_nodes_in_db(self, context, use_slave=False,
6625                                  startup=False):
6626         try:
6627             return objects.ComputeNodeList.get_all_by_host(context, self.host,
6628                                                            use_slave=use_slave)
6629         except exception.NotFound:
6630             if startup:
6631                 LOG.warning(
6632                     "No compute node record found for host %s. If this is "
6633                     "the first time this service is starting on this "
6634                     "host, then you can ignore this warning.", self.host)
6635             else:
6636                 LOG.error("No compute node record for host %s", self.host)
6637             return []
6638 
6639     @periodic_task.periodic_task(
6640         spacing=CONF.running_deleted_instance_poll_interval)
6641     def _cleanup_running_deleted_instances(self, context):
6642         """Cleanup any instances which are erroneously still running after
6643         having been deleted.
6644 
6645         Valid actions to take are:
6646 
6647             1. noop - do nothing
6648             2. log - log which instances are erroneously running
6649             3. reap - shutdown and cleanup any erroneously running instances
6650             4. shutdown - power off *and disable* any erroneously running
6651                           instances
6652 
6653         The use-case for this cleanup task is: for various reasons, it may be
6654         possible for the database to show an instance as deleted but for that
6655         instance to still be running on a host machine (see bug
6656         https://bugs.launchpad.net/nova/+bug/911366).
6657 
6658         This cleanup task is a cross-hypervisor utility for finding these
6659         zombied instances and either logging the discrepancy (likely what you
6660         should do in production), or automatically reaping the instances (more
6661         appropriate for dev environments).
6662         """
6663         action = CONF.running_deleted_instance_action
6664 
6665         if action == "noop":
6666             return
6667 
6668         # NOTE(sirp): admin contexts don't ordinarily return deleted records
6669         with utils.temporary_mutation(context, read_deleted="yes"):
6670             for instance in self._running_deleted_instances(context):
6671                 if action == "log":
6672                     LOG.warning("Detected instance with name label "
6673                                 "'%s' which is marked as "
6674                                 "DELETED but still present on host.",
6675                                 instance.name, instance=instance)
6676 
6677                 elif action == 'shutdown':
6678                     LOG.info("Powering off instance with name label "
6679                              "'%s' which is marked as "
6680                              "DELETED but still present on host.",
6681                              instance.name, instance=instance)
6682                     try:
6683                         try:
6684                             # disable starting the instance
6685                             self.driver.set_bootable(instance, False)
6686                         except NotImplementedError:
6687                             LOG.debug("set_bootable is not implemented "
6688                                       "for the current driver")
6689                         # and power it off
6690                         self.driver.power_off(instance)
6691                     except Exception:
6692                         LOG.warning("Failed to power off instance",
6693                                     instance=instance, exc_info=True)
6694 
6695                 elif action == 'reap':
6696                     LOG.info("Destroying instance with name label "
6697                              "'%s' which is marked as "
6698                              "DELETED but still present on host.",
6699                              instance.name, instance=instance)
6700                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6701                         context, instance.uuid, use_slave=True)
6702                     self.instance_events.clear_events_for_instance(instance)
6703                     try:
6704                         self._shutdown_instance(context, instance, bdms,
6705                                                 notify=False)
6706                         self._cleanup_volumes(context, instance.uuid, bdms)
6707                     except Exception as e:
6708                         LOG.warning("Periodic cleanup failed to delete "
6709                                     "instance: %s",
6710                                     e, instance=instance)
6711                 else:
6712                     raise Exception(_("Unrecognized value '%s'"
6713                                       " for CONF.running_deleted_"
6714                                       "instance_action") % action)
6715 
6716     def _running_deleted_instances(self, context):
6717         """Returns a list of instances nova thinks is deleted,
6718         but the hypervisor thinks is still running.
6719         """
6720         timeout = CONF.running_deleted_instance_timeout
6721         filters = {'deleted': True,
6722                    'soft_deleted': False,
6723                    'host': self.host}
6724         instances = self._get_instances_on_driver(context, filters)
6725         return [i for i in instances if self._deleted_old_enough(i, timeout)]
6726 
6727     def _deleted_old_enough(self, instance, timeout):
6728         deleted_at = instance.deleted_at
6729         if deleted_at:
6730             deleted_at = deleted_at.replace(tzinfo=None)
6731         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
6732 
6733     @contextlib.contextmanager
6734     def _error_out_instance_on_exception(self, context, instance,
6735                                          quotas=None,
6736                                          instance_state=vm_states.ACTIVE):
6737         instance_uuid = instance.uuid
6738         try:
6739             yield
6740         except NotImplementedError as error:
6741             with excutils.save_and_reraise_exception():
6742                 if quotas:
6743                     quotas.rollback()
6744                 LOG.info("Setting instance back to %(state)s after: "
6745                          "%(error)s",
6746                          {'state': instance_state, 'error': error},
6747                          instance_uuid=instance_uuid)
6748                 self._instance_update(context, instance,
6749                                       vm_state=instance_state,
6750                                       task_state=None)
6751         except exception.InstanceFaultRollback as error:
6752             if quotas:
6753                 quotas.rollback()
6754             LOG.info("Setting instance back to ACTIVE after: %s",
6755                      error, instance_uuid=instance_uuid)
6756             self._instance_update(context, instance,
6757                                   vm_state=vm_states.ACTIVE,
6758                                   task_state=None)
6759             raise error.inner_exception
6760         except Exception:
6761             LOG.exception('Setting instance vm_state to ERROR',
6762                           instance_uuid=instance_uuid)
6763             with excutils.save_and_reraise_exception():
6764                 if quotas:
6765                     quotas.rollback()
6766                 self._set_instance_obj_error_state(context, instance)
6767 
6768     @wrap_exception()
6769     def add_aggregate_host(self, context, aggregate, host, slave_info):
6770         """Notify hypervisor of change (for hypervisor pools)."""
6771         try:
6772             self.driver.add_to_aggregate(context, aggregate, host,
6773                                          slave_info=slave_info)
6774         except NotImplementedError:
6775             LOG.debug('Hypervisor driver does not support '
6776                       'add_aggregate_host')
6777         except exception.AggregateError:
6778             with excutils.save_and_reraise_exception():
6779                 self.driver.undo_aggregate_operation(
6780                                     context,
6781                                     aggregate.delete_host,
6782                                     aggregate, host)
6783 
6784     @wrap_exception()
6785     def remove_aggregate_host(self, context, host, slave_info, aggregate):
6786         """Removes a host from a physical hypervisor pool."""
6787         try:
6788             self.driver.remove_from_aggregate(context, aggregate, host,
6789                                               slave_info=slave_info)
6790         except NotImplementedError:
6791             LOG.debug('Hypervisor driver does not support '
6792                       'remove_aggregate_host')
6793         except (exception.AggregateError,
6794                 exception.InvalidAggregateAction) as e:
6795             with excutils.save_and_reraise_exception():
6796                 self.driver.undo_aggregate_operation(
6797                                     context,
6798                                     aggregate.add_host,
6799                                     aggregate, host,
6800                                     isinstance(e, exception.AggregateError))
6801 
6802     def _process_instance_event(self, instance, event):
6803         _event = self.instance_events.pop_instance_event(instance, event)
6804         if _event:
6805             LOG.debug('Processing event %(event)s',
6806                       {'event': event.key}, instance=instance)
6807             _event.send(event)
6808         else:
6809             LOG.warning('Received unexpected event %(event)s for instance',
6810                         {'event': event.key}, instance=instance)
6811 
6812     def _process_instance_vif_deleted_event(self, context, instance,
6813                                             deleted_vif_id):
6814         # If an attached port is deleted by neutron, it needs to
6815         # be detached from the instance.
6816         # And info cache needs to be updated.
6817         network_info = instance.info_cache.network_info
6818         for index, vif in enumerate(network_info):
6819             if vif['id'] == deleted_vif_id:
6820                 LOG.info('Neutron deleted interface %(intf)s; '
6821                          'detaching it from the instance and '
6822                          'deleting it from the info cache',
6823                          {'intf': vif['id']},
6824                          instance=instance)
6825                 del network_info[index]
6826                 base_net_api.update_instance_cache_with_nw_info(
6827                                  self.network_api, context,
6828                                  instance,
6829                                  nw_info=network_info)
6830                 try:
6831                     self.driver.detach_interface(context, instance, vif)
6832                 except NotImplementedError:
6833                     # Not all virt drivers support attach/detach of interfaces
6834                     # yet (like Ironic), so just ignore this.
6835                     pass
6836                 except exception.NovaException as ex:
6837                     LOG.warning("Detach interface failed, "
6838                                 "port_id=%(port_id)s, reason: %(msg)s",
6839                                 {'port_id': deleted_vif_id, 'msg': ex},
6840                                 instance=instance)
6841                 break
6842 
6843     @wrap_instance_event(prefix='compute')
6844     @wrap_instance_fault
6845     def _process_instance_volume_extended_event(self, context, instance,
6846                                                 extended_volume_id):
6847         # If an attached volume is extended by cinder, it needs to
6848         # be extended by virt driver so host can detect its new size.
6849         # And bdm needs to be updated.
6850         LOG.debug('Handling volume-extended event for volume %(vol)s',
6851                   {'vol': extended_volume_id}, instance=instance)
6852 
6853         try:
6854             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
6855                    context, extended_volume_id, instance.uuid)
6856         except exception.NotFound:
6857             LOG.warning('Extend volume failed, '
6858                         'volume %(vol)s is not attached to instance.',
6859                         {'vol': extended_volume_id},
6860                         instance=instance)
6861             return
6862 
6863         LOG.info('Cinder extended volume %(vol)s; '
6864                  'extending it to detect new size',
6865                  {'vol': extended_volume_id},
6866                  instance=instance)
6867         volume = self.volume_api.get(context, bdm.volume_id)
6868 
6869         if bdm.connection_info is None:
6870             LOG.warning('Extend volume failed, '
6871                         'attached volume %(vol)s has no connection_info',
6872                         {'vol': extended_volume_id},
6873                         instance=instance)
6874             return
6875 
6876         connection_info = jsonutils.loads(bdm.connection_info)
6877         bdm.volume_size = volume['size']
6878         bdm.save()
6879 
6880         if not self.driver.capabilities.get('supports_extend_volume'):
6881             raise exception.ExtendVolumeNotSupported(
6882                 instance_uuid=instance.uuid)
6883 
6884         try:
6885             self.driver.extend_volume(connection_info,
6886                                       instance,
6887                                       bdm.device_name)
6888         except Exception as ex:
6889             LOG.warning('Extend volume failed, '
6890                         'volume_id=%(volume_id)s, reason: %(msg)s',
6891                         {'volume_id': extended_volume_id, 'msg': ex},
6892                         instance=instance)
6893             raise
6894 
6895     @wrap_exception()
6896     def external_instance_event(self, context, instances, events):
6897         # NOTE(danms): Some event types are handled by the manager, such
6898         # as when we're asked to update the instance's info_cache. If it's
6899         # not one of those, look for some thread(s) waiting for the event and
6900         # unblock them if so.
6901         for event in events:
6902             instance = [inst for inst in instances
6903                         if inst.uuid == event.instance_uuid][0]
6904             LOG.debug('Received event %(event)s',
6905                       {'event': event.key},
6906                       instance=instance)
6907             if event.name == 'network-changed':
6908                 try:
6909                     self.network_api.get_instance_nw_info(context, instance)
6910                 except exception.NotFound as e:
6911                     LOG.info('Failed to process external instance event '
6912                              '%(event)s due to: %(error)s',
6913                              {'event': event.key, 'error': six.text_type(e)},
6914                              instance=instance)
6915             elif event.name == 'network-vif-deleted':
6916                 try:
6917                     self._process_instance_vif_deleted_event(context,
6918                                                              instance,
6919                                                              event.tag)
6920                 except exception.NotFound as e:
6921                     LOG.info('Failed to process external instance event '
6922                              '%(event)s due to: %(error)s',
6923                              {'event': event.key, 'error': six.text_type(e)},
6924                              instance=instance)
6925             elif event.name == 'volume-extended':
6926                 try:
6927                     self._process_instance_volume_extended_event(context,
6928                                                                  instance,
6929                                                                  event.tag)
6930                 except exception.NotFound as e:
6931                     LOG.info('Failed to process external instance event '
6932                              '%(event)s due to: %(error)s',
6933                              {'event': event.key, 'error': six.text_type(e)},
6934                              instance=instance)
6935             else:
6936                 self._process_instance_event(instance, event)
6937 
6938     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
6939                                  external_process_ok=True)
6940     def _run_image_cache_manager_pass(self, context):
6941         """Run a single pass of the image cache manager."""
6942 
6943         if not self.driver.capabilities["has_imagecache"]:
6944             return
6945 
6946         # Determine what other nodes use this storage
6947         storage_users.register_storage_use(CONF.instances_path, CONF.host)
6948         nodes = storage_users.get_storage_users(CONF.instances_path)
6949 
6950         # Filter all_instances to only include those nodes which share this
6951         # storage path.
6952         # TODO(mikal): this should be further refactored so that the cache
6953         # cleanup code doesn't know what those instances are, just a remote
6954         # count, and then this logic should be pushed up the stack.
6955         filters = {'deleted': False,
6956                    'soft_deleted': True,
6957                    'host': nodes}
6958         filtered_instances = objects.InstanceList.get_by_filters(context,
6959                                  filters, expected_attrs=[], use_slave=True)
6960 
6961         self.driver.manage_image_cache(context, filtered_instances)
6962 
6963     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6964     def _run_pending_deletes(self, context):
6965         """Retry any pending instance file deletes."""
6966         LOG.debug('Cleaning up deleted instances')
6967         filters = {'deleted': True,
6968                    'soft_deleted': False,
6969                    'host': CONF.host,
6970                    'cleaned': False}
6971         attrs = ['system_metadata']
6972         with utils.temporary_mutation(context, read_deleted='yes'):
6973             instances = objects.InstanceList.get_by_filters(
6974                 context, filters, expected_attrs=attrs, use_slave=True)
6975         LOG.debug('There are %d instances to clean', len(instances))
6976 
6977         # TODO(raj_singh): Remove this if condition when min value is
6978         # introduced to "maximum_instance_delete_attempts" cfg option.
6979         if CONF.maximum_instance_delete_attempts < 1:
6980             LOG.warning('Future versions of Nova will restrict the '
6981                         '"maximum_instance_delete_attempts" config option '
6982                         'to values >=1. Update your configuration file to '
6983                         'mitigate future upgrade issues.')
6984 
6985         for instance in instances:
6986             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
6987             LOG.debug('Instance has had %(attempts)s of %(max)s '
6988                       'cleanup attempts',
6989                       {'attempts': attempts,
6990                        'max': CONF.maximum_instance_delete_attempts},
6991                       instance=instance)
6992             if attempts < CONF.maximum_instance_delete_attempts:
6993                 success = self.driver.delete_instance_files(instance)
6994 
6995                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
6996                 if success:
6997                     instance.cleaned = True
6998                 with utils.temporary_mutation(context, read_deleted='yes'):
6999                     instance.save()
7000 
7001     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7002     def _cleanup_incomplete_migrations(self, context):
7003         """Delete instance files on failed resize/revert-resize operation
7004 
7005         During resize/revert-resize operation, if that instance gets deleted
7006         in-between then instance files might remain either on source or
7007         destination compute node because of race condition.
7008         """
7009         LOG.debug('Cleaning up deleted instances with incomplete migration ')
7010         migration_filters = {'host': CONF.host,
7011                              'status': 'error'}
7012         migrations = objects.MigrationList.get_by_filters(context,
7013                                                           migration_filters)
7014 
7015         if not migrations:
7016             return
7017 
7018         inst_uuid_from_migrations = set([migration.instance_uuid for migration
7019                                          in migrations])
7020 
7021         inst_filters = {'deleted': True, 'soft_deleted': False,
7022                         'uuid': inst_uuid_from_migrations}
7023         attrs = ['info_cache', 'security_groups', 'system_metadata']
7024         with utils.temporary_mutation(context, read_deleted='yes'):
7025             instances = objects.InstanceList.get_by_filters(
7026                 context, inst_filters, expected_attrs=attrs, use_slave=True)
7027 
7028         for instance in instances:
7029             if instance.host != CONF.host:
7030                 for migration in migrations:
7031                     if instance.uuid == migration.instance_uuid:
7032                         # Delete instance files if not cleanup properly either
7033                         # from the source or destination compute nodes when
7034                         # the instance is deleted during resizing.
7035                         self.driver.delete_instance_files(instance)
7036                         try:
7037                             migration.status = 'failed'
7038                             with migration.obj_as_admin():
7039                                 migration.save()
7040                         except exception.MigrationNotFound:
7041                             LOG.warning("Migration %s is not found.",
7042                                         migration.id,
7043                                         instance=instance)
7044                         break
7045 
7046     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7047                                    exception.QemuGuestAgentNotEnabled,
7048                                    exception.NovaException,
7049                                    NotImplementedError)
7050     @wrap_exception()
7051     def quiesce_instance(self, context, instance):
7052         """Quiesce an instance on this host."""
7053         context = context.elevated()
7054         image_meta = objects.ImageMeta.from_instance(instance)
7055         self.driver.quiesce(context, instance, image_meta)
7056 
7057     def _wait_for_snapshots_completion(self, context, mapping):
7058         for mapping_dict in mapping:
7059             if mapping_dict.get('source_type') == 'snapshot':
7060 
7061                 def _wait_snapshot():
7062                     snapshot = self.volume_api.get_snapshot(
7063                         context, mapping_dict['snapshot_id'])
7064                     if snapshot.get('status') != 'creating':
7065                         raise loopingcall.LoopingCallDone()
7066 
7067                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
7068                 timer.start(interval=0.5).wait()
7069 
7070     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7071                                    exception.QemuGuestAgentNotEnabled,
7072                                    exception.NovaException,
7073                                    NotImplementedError)
7074     @wrap_exception()
7075     def unquiesce_instance(self, context, instance, mapping=None):
7076         """Unquiesce an instance on this host.
7077 
7078         If snapshots' image mapping is provided, it waits until snapshots are
7079         completed before unqueiscing.
7080         """
7081         context = context.elevated()
7082         if mapping:
7083             try:
7084                 self._wait_for_snapshots_completion(context, mapping)
7085             except Exception as error:
7086                 LOG.exception("Exception while waiting completion of "
7087                               "volume snapshots: %s",
7088                               error, instance=instance)
7089         image_meta = objects.ImageMeta.from_instance(instance)
7090         self.driver.unquiesce(context, instance, image_meta)
