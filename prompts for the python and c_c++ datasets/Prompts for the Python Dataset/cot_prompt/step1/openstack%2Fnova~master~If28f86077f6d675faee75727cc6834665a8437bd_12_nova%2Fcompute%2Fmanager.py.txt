Based on the given code from a commit, please generate supplementary code files according to the commit message.
####commit message
compute: Refresh connection_info on migration rollback

Previously changes made to bdm.connection_info on the destination host
during pre_live_migration would not be reverted on the source when
rolling back. As a result future attempts to connect to the bdm could
either fail or incorrectly connect to a different volume depending on
the volume backend being used.

These changes are now reverted by calling for a refresh of
connection_info on the source host while rolling back a migration.

Closes-bug: #1419577
Change-Id: If28f86077f6d675faee75727cc6834665a8437bd

####code 
1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 import uuid
37 
38 from cinderclient import exceptions as cinder_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 from keystoneauth1 import exceptions as keystone_exception
44 from oslo_log import log as logging
45 import oslo_messaging as messaging
46 from oslo_serialization import jsonutils
47 from oslo_service import loopingcall
48 from oslo_service import periodic_task
49 from oslo_utils import excutils
50 from oslo_utils import strutils
51 from oslo_utils import timeutils
52 import six
53 from six.moves import range
54 
55 from nova import block_device
56 from nova.cells import rpcapi as cells_rpcapi
57 from nova.cloudpipe import pipelib
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova import consoleauth
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova.i18n import _LE
77 from nova.i18n import _LI
78 from nova.i18n import _LW
79 from nova import image
80 from nova.image import glance
81 from nova import manager
82 from nova import network
83 from nova.network import base_api as base_net_api
84 from nova.network import model as network_model
85 from nova.network.security_group import openstack_driver
86 from nova import objects
87 from nova.objects import base as obj_base
88 from nova.objects import fields
89 from nova.objects import instance as obj_instance
90 from nova.objects import migrate_data as migrate_data_obj
91 from nova import rpc
92 from nova import safe_utils
93 from nova.scheduler import client as scheduler_client
94 from nova import utils
95 from nova.virt import block_device as driver_block_device
96 from nova.virt import configdrive
97 from nova.virt import driver
98 from nova.virt import event as virtevent
99 from nova.virt import storage_users
100 from nova.virt import virtapi
101 from nova.volume import cinder
102 from nova.volume import encryptors
103 
104 CONF = nova.conf.CONF
105 
106 LOG = logging.getLogger(__name__)
107 
108 get_notifier = functools.partial(rpc.get_notifier, service='compute')
109 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
110                                    get_notifier=get_notifier,
111                                    binary='nova-compute')
112 
113 
114 @utils.expects_func_args('migration')
115 def errors_out_migration(function):
116     """Decorator to error out migration on failure."""
117 
118     @functools.wraps(function)
119     def decorated_function(self, context, *args, **kwargs):
120         try:
121             return function(self, context, *args, **kwargs)
122         except Exception as ex:
123             with excutils.save_and_reraise_exception():
124                 wrapped_func = safe_utils.get_wrapped_function(function)
125                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
126                                                  *args, **kwargs)
127                 migration = keyed_args['migration']
128 
129                 # NOTE(rajesht): If InstanceNotFound error is thrown from
130                 # decorated function, migration status should be set to
131                 # 'error', without checking current migration status.
132                 if not isinstance(ex, exception.InstanceNotFound):
133                     status = migration.status
134                     if status not in ['migrating', 'post-migrating']:
135                         return
136 
137                 migration.status = 'error'
138                 try:
139                     with migration.obj_as_admin():
140                         migration.save()
141                 except Exception:
142                     LOG.debug('Error setting migration status '
143                               'for instance %s.',
144                               migration.instance_uuid, exc_info=True)
145 
146     return decorated_function
147 
148 
149 @utils.expects_func_args('instance')
150 def reverts_task_state(function):
151     """Decorator to revert task_state on failure."""
152 
153     @functools.wraps(function)
154     def decorated_function(self, context, *args, **kwargs):
155         try:
156             return function(self, context, *args, **kwargs)
157         except exception.UnexpectedTaskStateError as e:
158             # Note(maoy): unexpected task state means the current
159             # task is preempted. Do not clear task state in this
160             # case.
161             with excutils.save_and_reraise_exception():
162                 LOG.info(_LI("Task possibly preempted: %s"),
163                          e.format_message())
164         except Exception:
165             with excutils.save_and_reraise_exception():
166                 wrapped_func = safe_utils.get_wrapped_function(function)
167                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
168                                                  *args, **kwargs)
169                 # NOTE(mriedem): 'instance' must be in keyed_args because we
170                 # have utils.expects_func_args('instance') decorating this
171                 # method.
172                 instance = keyed_args['instance']
173                 original_task_state = instance.task_state
174                 try:
175                     self._instance_update(context, instance, task_state=None)
176                     LOG.info(_LI("Successfully reverted task state from %s on "
177                                  "failure for instance."), original_task_state,
178                                                            instance=instance)
179                 except exception.InstanceNotFound:
180                     # We might delete an instance that failed to build shortly
181                     # after it errored out this is an expected case and we
182                     # should not trace on it.
183                     pass
184                 except Exception as e:
185                     msg = _LW("Failed to revert task state for instance. "
186                               "Error: %s")
187                     LOG.warning(msg, e, instance=instance)
188 
189     return decorated_function
190 
191 
192 @utils.expects_func_args('instance')
193 def wrap_instance_fault(function):
194     """Wraps a method to catch exceptions related to instances.
195 
196     This decorator wraps a method to catch any exceptions having to do with
197     an instance that may get thrown. It then logs an instance fault in the db.
198     """
199 
200     @functools.wraps(function)
201     def decorated_function(self, context, *args, **kwargs):
202         try:
203             return function(self, context, *args, **kwargs)
204         except exception.InstanceNotFound:
205             raise
206         except Exception as e:
207             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
208             # we will get a KeyError exception which will cover up the real
209             # exception. So, we update kwargs with the values from args first.
210             # then, we can get 'instance' from kwargs easily.
211             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
212 
213             with excutils.save_and_reraise_exception():
214                 compute_utils.add_instance_fault_from_exc(context,
215                         kwargs['instance'], e, sys.exc_info())
216 
217     return decorated_function
218 
219 
220 @utils.expects_func_args('image_id', 'instance')
221 def delete_image_on_error(function):
222     """Used for snapshot related method to ensure the image created in
223     compute.api is deleted when an error occurs.
224     """
225 
226     @functools.wraps(function)
227     def decorated_function(self, context, image_id, instance,
228                            *args, **kwargs):
229         try:
230             return function(self, context, image_id, instance,
231                             *args, **kwargs)
232         except Exception:
233             with excutils.save_and_reraise_exception():
234                 LOG.debug("Cleaning up image %s", image_id,
235                           exc_info=True, instance=instance)
236                 try:
237                     self.image_api.delete(context, image_id)
238                 except Exception:
239                     LOG.exception(_LE("Error while trying to clean up "
240                                       "image %s"), image_id,
241                                   instance=instance)
242 
243     return decorated_function
244 
245 
246 # TODO(danms): Remove me after Icehouse
247 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
248 # NOTE(mikal): if the method being decorated has more than one decorator, then
249 # put this one first. Otherwise the various exception handling decorators do
250 # not function correctly.
251 def object_compat(function):
252     """Wraps a method that expects a new-world instance
253 
254     This provides compatibility for callers passing old-style dict
255     instances.
256     """
257 
258     @functools.wraps(function)
259     def decorated_function(self, context, *args, **kwargs):
260         def _load_instance(instance_or_dict):
261             if isinstance(instance_or_dict, dict):
262                 # try to get metadata and system_metadata for most cases but
263                 # only attempt to load those if the db instance already has
264                 # those fields joined
265                 metas = [meta for meta in ('metadata', 'system_metadata')
266                          if meta in instance_or_dict]
267                 instance = objects.Instance._from_db_object(
268                     context, objects.Instance(), instance_or_dict,
269                     expected_attrs=metas)
270                 instance._context = context
271                 return instance
272             return instance_or_dict
273 
274         try:
275             kwargs['instance'] = _load_instance(kwargs['instance'])
276         except KeyError:
277             args = (_load_instance(args[0]),) + args[1:]
278 
279         migration = kwargs.get('migration')
280         if isinstance(migration, dict):
281             migration = objects.Migration._from_db_object(
282                     context.elevated(), objects.Migration(),
283                     migration)
284             kwargs['migration'] = migration
285 
286         return function(self, context, *args, **kwargs)
287 
288     return decorated_function
289 
290 
291 class InstanceEvents(object):
292     def __init__(self):
293         self._events = {}
294 
295     @staticmethod
296     def _lock_name(instance):
297         return '%s-%s' % (instance.uuid, 'events')
298 
299     def prepare_for_instance_event(self, instance, event_name):
300         """Prepare to receive an event for an instance.
301 
302         This will register an event for the given instance that we will
303         wait on later. This should be called before initiating whatever
304         action will trigger the event. The resulting eventlet.event.Event
305         object should be wait()'d on to ensure completion.
306 
307         :param instance: the instance for which the event will be generated
308         :param event_name: the name of the event we're expecting
309         :returns: an event object that should be wait()'d on
310         """
311         if self._events is None:
312             # NOTE(danms): We really should have a more specific error
313             # here, but this is what we use for our default error case
314             raise exception.NovaException('In shutdown, no new events '
315                                           'can be scheduled')
316 
317         @utils.synchronized(self._lock_name(instance))
318         def _create_or_get_event():
319             instance_events = self._events.setdefault(instance.uuid, {})
320             return instance_events.setdefault(event_name,
321                                               eventlet.event.Event())
322         LOG.debug('Preparing to wait for external event %(event)s',
323                   {'event': event_name}, instance=instance)
324         return _create_or_get_event()
325 
326     def pop_instance_event(self, instance, event):
327         """Remove a pending event from the wait list.
328 
329         This will remove a pending event from the wait list so that it
330         can be used to signal the waiters to wake up.
331 
332         :param instance: the instance for which the event was generated
333         :param event: the nova.objects.external_event.InstanceExternalEvent
334                       that describes the event
335         :returns: the eventlet.event.Event object on which the waiters
336                   are blocked
337         """
338         no_events_sentinel = object()
339         no_matching_event_sentinel = object()
340 
341         @utils.synchronized(self._lock_name(instance))
342         def _pop_event():
343             if not self._events:
344                 LOG.debug('Unexpected attempt to pop events during shutdown',
345                           instance=instance)
346                 return no_events_sentinel
347             events = self._events.get(instance.uuid)
348             if not events:
349                 return no_events_sentinel
350             _event = events.pop(event.key, None)
351             if not events:
352                 del self._events[instance.uuid]
353             if _event is None:
354                 return no_matching_event_sentinel
355             return _event
356 
357         result = _pop_event()
358         if result is no_events_sentinel:
359             LOG.debug('No waiting events found dispatching %(event)s',
360                       {'event': event.key},
361                       instance=instance)
362             return None
363         elif result is no_matching_event_sentinel:
364             LOG.debug('No event matching %(event)s in %(events)s',
365                       {'event': event.key,
366                        'events': self._events.get(instance.uuid, {}).keys()},
367                       instance=instance)
368             return None
369         else:
370             return result
371 
372     def clear_events_for_instance(self, instance):
373         """Remove all pending events for an instance.
374 
375         This will remove all events currently pending for an instance
376         and return them (indexed by event name).
377 
378         :param instance: the instance for which events should be purged
379         :returns: a dictionary of {event_name: eventlet.event.Event}
380         """
381         @utils.synchronized(self._lock_name(instance))
382         def _clear_events():
383             if self._events is None:
384                 LOG.debug('Unexpected attempt to clear events during shutdown',
385                           instance=instance)
386                 return dict()
387             return self._events.pop(instance.uuid, {})
388         return _clear_events()
389 
390     def cancel_all_events(self):
391         if self._events is None:
392             LOG.debug('Unexpected attempt to cancel events during shutdown.')
393             return
394         our_events = self._events
395         # NOTE(danms): Block new events
396         self._events = None
397 
398         for instance_uuid, events in our_events.items():
399             for event_name, eventlet_event in events.items():
400                 LOG.debug('Canceling in-flight event %(event)s for '
401                           'instance %(instance_uuid)s',
402                           {'event': event_name,
403                            'instance_uuid': instance_uuid})
404                 name, tag = event_name.rsplit('-', 1)
405                 event = objects.InstanceExternalEvent(
406                     instance_uuid=instance_uuid,
407                     name=name, status='failed',
408                     tag=tag, data={})
409                 eventlet_event.send(event)
410 
411 
412 class ComputeVirtAPI(virtapi.VirtAPI):
413     def __init__(self, compute):
414         super(ComputeVirtAPI, self).__init__()
415         self._compute = compute
416 
417     def _default_error_callback(self, event_name, instance):
418         raise exception.NovaException(_('Instance event failed'))
419 
420     @contextlib.contextmanager
421     def wait_for_instance_event(self, instance, event_names, deadline=300,
422                                 error_callback=None):
423         """Plan to wait for some events, run some code, then wait.
424 
425         This context manager will first create plans to wait for the
426         provided event_names, yield, and then wait for all the scheduled
427         events to complete.
428 
429         Note that this uses an eventlet.timeout.Timeout to bound the
430         operation, so callers should be prepared to catch that
431         failure and handle that situation appropriately.
432 
433         If the event is not received by the specified timeout deadline,
434         eventlet.timeout.Timeout is raised.
435 
436         If the event is received but did not have a 'completed'
437         status, a NovaException is raised.  If an error_callback is
438         provided, instead of raising an exception as detailed above
439         for the failure case, the callback will be called with the
440         event_name and instance, and can return True to continue
441         waiting for the rest of the events, False to stop processing,
442         or raise an exception which will bubble up to the waiter.
443 
444         :param instance: The instance for which an event is expected
445         :param event_names: A list of event names. Each element can be a
446                             string event name or tuple of strings to
447                             indicate (name, tag).
448         :param deadline: Maximum number of seconds we should wait for all
449                          of the specified events to arrive.
450         :param error_callback: A function to be called if an event arrives
451 
452         """
453 
454         if error_callback is None:
455             error_callback = self._default_error_callback
456         events = {}
457         for event_name in event_names:
458             if isinstance(event_name, tuple):
459                 name, tag = event_name
460                 event_name = objects.InstanceExternalEvent.make_key(
461                     name, tag)
462             try:
463                 events[event_name] = (
464                     self._compute.instance_events.prepare_for_instance_event(
465                         instance, event_name))
466             except exception.NovaException:
467                 error_callback(event_name, instance)
468                 # NOTE(danms): Don't wait for any of the events. They
469                 # should all be canceled and fired immediately below,
470                 # but don't stick around if not.
471                 deadline = 0
472         yield
473         with eventlet.timeout.Timeout(deadline):
474             for event_name, event in events.items():
475                 actual_event = event.wait()
476                 if actual_event.status == 'completed':
477                     continue
478                 decision = error_callback(event_name, instance)
479                 if decision is False:
480                     break
481 
482 
483 class ComputeManager(manager.Manager):
484     """Manages the running instances from creation to destruction."""
485 
486     target = messaging.Target(version='4.13')
487 
488     # How long to wait in seconds before re-issuing a shutdown
489     # signal to an instance during power off.  The overall
490     # time to wait is set by CONF.shutdown_timeout.
491     SHUTDOWN_RETRY_INTERVAL = 10
492 
493     def __init__(self, compute_driver=None, *args, **kwargs):
494         """Load configuration options and connect to the hypervisor."""
495         self.virtapi = ComputeVirtAPI(self)
496         self.network_api = network.API()
497         self.volume_api = cinder.API()
498         self.image_api = image.API()
499         self._last_host_check = 0
500         self._last_bw_usage_poll = 0
501         self._bw_usage_supported = True
502         self._last_bw_usage_cell_update = 0
503         self.compute_api = compute.API()
504         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
505         self.conductor_api = conductor.API()
506         self.compute_task_api = conductor.ComputeTaskAPI()
507         self.is_neutron_security_groups = (
508             openstack_driver.is_neutron_security_groups())
509         self.consoleauth_rpcapi = consoleauth.rpcapi.ConsoleAuthAPI()
510         self.cells_rpcapi = cells_rpcapi.CellsAPI()
511         self.scheduler_client = scheduler_client.SchedulerClient()
512         self._resource_tracker_dict = {}
513         self.instance_events = InstanceEvents()
514         self._sync_power_pool = eventlet.GreenPool()
515         self._syncs_in_progress = {}
516         self.send_instance_updates = CONF.scheduler_tracks_instance_changes
517         if CONF.max_concurrent_builds != 0:
518             self._build_semaphore = eventlet.semaphore.Semaphore(
519                 CONF.max_concurrent_builds)
520         else:
521             self._build_semaphore = compute_utils.UnlimitedSemaphore()
522         if max(CONF.max_concurrent_live_migrations, 0) != 0:
523             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
524                 CONF.max_concurrent_live_migrations)
525         else:
526             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
527 
528         super(ComputeManager, self).__init__(service_name="compute",
529                                              *args, **kwargs)
530 
531         # NOTE(russellb) Load the driver last.  It may call back into the
532         # compute manager via the virtapi, so we want it to be fully
533         # initialized before that happens.
534         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
535         self.use_legacy_block_device_info = \
536                             self.driver.need_legacy_block_device_info
537 
538     def reset(self):
539         LOG.info(_LI('Reloading compute RPC API'))
540         compute_rpcapi.LAST_VERSION = None
541         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
542 
543     def _get_resource_tracker(self, nodename):
544         rt = self._resource_tracker_dict.get(nodename)
545         if not rt:
546             if not self.driver.node_is_available(nodename):
547                 raise exception.NovaException(
548                         _("%s is not a valid node managed by this "
549                           "compute host.") % nodename)
550 
551             rt = resource_tracker.ResourceTracker(self.host,
552                                                   self.driver,
553                                                   nodename)
554             self._resource_tracker_dict[nodename] = rt
555         return rt
556 
557     def _update_resource_tracker(self, context, instance):
558         """Let the resource tracker know that an instance has changed state."""
559 
560         if (instance.host == self.host and
561                 self.driver.node_is_available(instance.node)):
562             rt = self._get_resource_tracker(instance.node)
563             rt.update_usage(context, instance)
564 
565     def _instance_update(self, context, instance, **kwargs):
566         """Update an instance in the database using kwargs as value."""
567 
568         for k, v in kwargs.items():
569             setattr(instance, k, v)
570         instance.save()
571         self._update_resource_tracker(context, instance)
572 
573     def _nil_out_instance_obj_host_and_node(self, instance):
574         # NOTE(jwcroppe): We don't do instance.save() here for performance
575         # reasons; a call to this is expected to be immediately followed by
576         # another call that does instance.save(), thus avoiding two writes
577         # to the database layer.
578         instance.host = None
579         instance.node = None
580 
581     def _set_instance_obj_error_state(self, context, instance,
582                                       clean_task_state=False):
583         try:
584             instance.vm_state = vm_states.ERROR
585             if clean_task_state:
586                 instance.task_state = None
587             instance.save()
588         except exception.InstanceNotFound:
589             LOG.debug('Instance has been destroyed from under us while '
590                       'trying to set it to ERROR', instance=instance)
591 
592     def _get_instances_on_driver(self, context, filters=None):
593         """Return a list of instance records for the instances found
594         on the hypervisor which satisfy the specified filters. If filters=None
595         return a list of instance records for all the instances found on the
596         hypervisor.
597         """
598         if not filters:
599             filters = {}
600         try:
601             driver_uuids = self.driver.list_instance_uuids()
602             if len(driver_uuids) == 0:
603                 # Short circuit, don't waste a DB call
604                 return objects.InstanceList()
605             filters['uuid'] = driver_uuids
606             local_instances = objects.InstanceList.get_by_filters(
607                 context, filters, use_slave=True)
608             return local_instances
609         except NotImplementedError:
610             pass
611 
612         # The driver doesn't support uuids listing, so we'll have
613         # to brute force.
614         driver_instances = self.driver.list_instances()
615         instances = objects.InstanceList.get_by_filters(context, filters,
616                                                         use_slave=True)
617         name_map = {instance.name: instance for instance in instances}
618         local_instances = []
619         for driver_instance in driver_instances:
620             instance = name_map.get(driver_instance)
621             if not instance:
622                 continue
623             local_instances.append(instance)
624         return local_instances
625 
626     def _destroy_evacuated_instances(self, context):
627         """Destroys evacuated instances.
628 
629         While nova-compute was down, the instances running on it could be
630         evacuated to another host. Check that the instances reported
631         by the driver are still associated with this host.  If they are
632         not, destroy them, with the exception of instances which are in
633         the MIGRATING, RESIZE_MIGRATING, RESIZE_MIGRATED, RESIZE_FINISH
634         task state or RESIZED vm state.
635         """
636         filters = {
637             'source_compute': self.host,
638             'status': ['accepted', 'done'],
639             'migration_type': 'evacuation',
640         }
641         evacuations = objects.MigrationList.get_by_filters(context, filters)
642         if not evacuations:
643             return
644         evacuations = {mig.instance_uuid: mig for mig in evacuations}
645 
646         filters = {'deleted': False}
647         local_instances = self._get_instances_on_driver(context, filters)
648         evacuated = [inst for inst in local_instances
649                      if inst.uuid in evacuations]
650         for instance in evacuated:
651             migration = evacuations[instance.uuid]
652             LOG.info(_LI('Deleting instance as it has been evacuated from '
653                          'this host'), instance=instance)
654             try:
655                 network_info = self.network_api.get_instance_nw_info(
656                     context, instance)
657                 bdi = self._get_instance_block_device_info(context,
658                                                            instance)
659                 destroy_disks = not (self._is_instance_storage_shared(
660                     context, instance))
661             except exception.InstanceNotFound:
662                 network_info = network_model.NetworkInfo()
663                 bdi = {}
664                 LOG.info(_LI('Instance has been marked deleted already, '
665                              'removing it from the hypervisor.'),
666                          instance=instance)
667                 # always destroy disks if the instance was deleted
668                 destroy_disks = True
669             self.driver.destroy(context, instance,
670                                 network_info,
671                                 bdi, destroy_disks)
672             migration.status = 'completed'
673             migration.save()
674 
675     def _is_instance_storage_shared(self, context, instance, host=None):
676         shared_storage = True
677         data = None
678         try:
679             data = self.driver.check_instance_shared_storage_local(context,
680                                                        instance)
681             if data:
682                 shared_storage = (self.compute_rpcapi.
683                                   check_instance_shared_storage(context,
684                                   instance, data, host=host))
685         except NotImplementedError:
686             LOG.debug('Hypervisor driver does not support '
687                       'instance shared storage check, '
688                       'assuming it\'s not on shared storage',
689                       instance=instance)
690             shared_storage = False
691         except Exception:
692             LOG.exception(_LE('Failed to check if instance shared'),
693                       instance=instance)
694         finally:
695             if data:
696                 self.driver.check_instance_shared_storage_cleanup(context,
697                                                                   data)
698         return shared_storage
699 
700     def _complete_partial_deletion(self, context, instance):
701         """Complete deletion for instances in DELETED status but not marked as
702         deleted in the DB
703         """
704         system_meta = instance.system_metadata
705         instance.destroy()
706         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
707                 context, instance.uuid)
708         quotas = objects.Quotas(context=context)
709         project_id, user_id = objects.quotas.ids_from_instance(context,
710                                                                instance)
711         quotas.reserve(project_id=project_id, user_id=user_id, instances=-1,
712                        cores=-instance.flavor.vcpus,
713                        ram=-instance.flavor.memory_mb)
714         self._complete_deletion(context,
715                                 instance,
716                                 bdms,
717                                 quotas,
718                                 system_meta)
719 
720     def _complete_deletion(self, context, instance, bdms,
721                            quotas, system_meta):
722         if quotas:
723             quotas.commit()
724 
725         # ensure block device mappings are not leaked
726         for bdm in bdms:
727             bdm.destroy()
728 
729         self._update_resource_tracker(context, instance)
730         self._notify_about_instance_usage(context, instance, "delete.end",
731                 system_metadata=system_meta)
732         compute_utils.notify_about_instance_action(context, instance,
733                 self.host, action=fields.NotificationAction.DELETE,
734                 phase=fields.NotificationPhase.END)
735         self._clean_instance_console_tokens(context, instance)
736         self._delete_scheduler_instance_info(context, instance.uuid)
737 
738     def _create_reservations(self, context, instance, project_id, user_id):
739         vcpus = instance.flavor.vcpus
740         mem_mb = instance.flavor.memory_mb
741 
742         quotas = objects.Quotas(context=context)
743         quotas.reserve(project_id=project_id,
744                        user_id=user_id,
745                        instances=-1,
746                        cores=-vcpus,
747                        ram=-mem_mb)
748         return quotas
749 
750     def _init_instance(self, context, instance):
751         '''Initialize this instance during service init.'''
752 
753         # NOTE(danms): If the instance appears to not be owned by this
754         # host, it may have been evacuated away, but skipped by the
755         # evacuation cleanup code due to configuration. Thus, if that
756         # is a possibility, don't touch the instance in any way, but
757         # log the concern. This will help avoid potential issues on
758         # startup due to misconfiguration.
759         if instance.host != self.host:
760             LOG.warning(_LW('Instance %(uuid)s appears to not be owned '
761                             'by this host, but by %(host)s. Startup '
762                             'processing is being skipped.'),
763                         {'uuid': instance.uuid,
764                          'host': instance.host})
765             return
766 
767         # Instances that are shut down, or in an error state can not be
768         # initialized and are not attempted to be recovered. The exception
769         # to this are instances that are in RESIZE_MIGRATING or DELETING,
770         # which are dealt with further down.
771         if (instance.vm_state == vm_states.SOFT_DELETED or
772             (instance.vm_state == vm_states.ERROR and
773             instance.task_state not in
774             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
775             LOG.debug("Instance is in %s state.",
776                       instance.vm_state, instance=instance)
777             return
778 
779         if instance.vm_state == vm_states.DELETED:
780             try:
781                 self._complete_partial_deletion(context, instance)
782             except Exception:
783                 # we don't want that an exception blocks the init_host
784                 msg = _LE('Failed to complete a deletion')
785                 LOG.exception(msg, instance=instance)
786             return
787 
788         if (instance.vm_state == vm_states.BUILDING or
789             instance.task_state in [task_states.SCHEDULING,
790                                     task_states.BLOCK_DEVICE_MAPPING,
791                                     task_states.NETWORKING,
792                                     task_states.SPAWNING]):
793             # NOTE(dave-mcnally) compute stopped before instance was fully
794             # spawned so set to ERROR state. This is safe to do as the state
795             # may be set by the api but the host is not so if we get here the
796             # instance has already been scheduled to this particular host.
797             LOG.debug("Instance failed to spawn correctly, "
798                       "setting to ERROR state", instance=instance)
799             instance.task_state = None
800             instance.vm_state = vm_states.ERROR
801             instance.save()
802             return
803 
804         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
805             instance.task_state in [task_states.REBUILDING,
806                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
807                                     task_states.REBUILD_SPAWNING]):
808             # NOTE(jichenjc) compute stopped before instance was fully
809             # spawned so set to ERROR state. This is consistent to BUILD
810             LOG.debug("Instance failed to rebuild correctly, "
811                       "setting to ERROR state", instance=instance)
812             instance.task_state = None
813             instance.vm_state = vm_states.ERROR
814             instance.save()
815             return
816 
817         if (instance.vm_state != vm_states.ERROR and
818             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
819                                     task_states.IMAGE_PENDING_UPLOAD,
820                                     task_states.IMAGE_UPLOADING,
821                                     task_states.IMAGE_SNAPSHOT]):
822             LOG.debug("Instance in transitional state %s at start-up "
823                       "clearing task state",
824                       instance.task_state, instance=instance)
825             try:
826                 self._post_interrupted_snapshot_cleanup(context, instance)
827             except Exception:
828                 # we don't want that an exception blocks the init_host
829                 msg = _LE('Failed to cleanup snapshot.')
830                 LOG.exception(msg, instance=instance)
831             instance.task_state = None
832             instance.save()
833 
834         if (instance.vm_state != vm_states.ERROR and
835             instance.task_state in [task_states.RESIZE_PREP]):
836             LOG.debug("Instance in transitional state %s at start-up "
837                       "clearing task state",
838                       instance['task_state'], instance=instance)
839             instance.task_state = None
840             instance.save()
841 
842         if instance.task_state == task_states.DELETING:
843             try:
844                 LOG.info(_LI('Service started deleting the instance during '
845                              'the previous run, but did not finish. Restarting'
846                              ' the deletion now.'), instance=instance)
847                 instance.obj_load_attr('metadata')
848                 instance.obj_load_attr('system_metadata')
849                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
850                         context, instance.uuid)
851                 project_id, user_id = objects.quotas.ids_from_instance(
852                     context, instance)
853                 quotas = self._create_reservations(context, instance,
854                                                    project_id, user_id)
855 
856                 self._delete_instance(context, instance, bdms, quotas)
857             except Exception:
858                 # we don't want that an exception blocks the init_host
859                 msg = _LE('Failed to complete a deletion')
860                 LOG.exception(msg, instance=instance)
861                 self._set_instance_obj_error_state(context, instance)
862             return
863 
864         current_power_state = self._get_power_state(context, instance)
865         try_reboot, reboot_type = self._retry_reboot(context, instance,
866                                                      current_power_state)
867 
868         if try_reboot:
869             LOG.debug("Instance in transitional state (%(task_state)s) at "
870                       "start-up and power state is (%(power_state)s), "
871                       "triggering reboot",
872                       {'task_state': instance.task_state,
873                        'power_state': current_power_state},
874                       instance=instance)
875 
876             # NOTE(mikal): if the instance was doing a soft reboot that got as
877             # far as shutting down the instance but not as far as starting it
878             # again, then we've just become a hard reboot. That means the
879             # task state for the instance needs to change so that we're in one
880             # of the expected task states for a hard reboot.
881             soft_types = [task_states.REBOOT_STARTED,
882                           task_states.REBOOT_PENDING,
883                           task_states.REBOOTING]
884             if instance.task_state in soft_types and reboot_type == 'HARD':
885                 instance.task_state = task_states.REBOOT_PENDING_HARD
886                 instance.save()
887 
888             self.reboot_instance(context, instance, block_device_info=None,
889                                  reboot_type=reboot_type)
890             return
891 
892         elif (current_power_state == power_state.RUNNING and
893               instance.task_state in [task_states.REBOOT_STARTED,
894                                       task_states.REBOOT_STARTED_HARD,
895                                       task_states.PAUSING,
896                                       task_states.UNPAUSING]):
897             LOG.warning(_LW("Instance in transitional state "
898                             "(%(task_state)s) at start-up and power state "
899                             "is (%(power_state)s), clearing task state"),
900                         {'task_state': instance.task_state,
901                          'power_state': current_power_state},
902                         instance=instance)
903             instance.task_state = None
904             instance.vm_state = vm_states.ACTIVE
905             instance.save()
906         elif (current_power_state == power_state.PAUSED and
907               instance.task_state == task_states.UNPAUSING):
908             LOG.warning(_LW("Instance in transitional state "
909                             "(%(task_state)s) at start-up and power state "
910                             "is (%(power_state)s), clearing task state "
911                             "and unpausing the instance"),
912                         {'task_state': instance.task_state,
913                          'power_state': current_power_state},
914                         instance=instance)
915             try:
916                 self.unpause_instance(context, instance)
917             except NotImplementedError:
918                 # Some virt driver didn't support pause and unpause
919                 pass
920             except Exception:
921                 LOG.exception(_LE('Failed to unpause instance'),
922                               instance=instance)
923             return
924 
925         if instance.task_state == task_states.POWERING_OFF:
926             try:
927                 LOG.debug("Instance in transitional state %s at start-up "
928                           "retrying stop request",
929                           instance.task_state, instance=instance)
930                 self.stop_instance(context, instance, True)
931             except Exception:
932                 # we don't want that an exception blocks the init_host
933                 msg = _LE('Failed to stop instance')
934                 LOG.exception(msg, instance=instance)
935             return
936 
937         if instance.task_state == task_states.POWERING_ON:
938             try:
939                 LOG.debug("Instance in transitional state %s at start-up "
940                           "retrying start request",
941                           instance.task_state, instance=instance)
942                 self.start_instance(context, instance)
943             except Exception:
944                 # we don't want that an exception blocks the init_host
945                 msg = _LE('Failed to start instance')
946                 LOG.exception(msg, instance=instance)
947             return
948 
949         net_info = compute_utils.get_nw_info_for_instance(instance)
950         try:
951             self.driver.plug_vifs(instance, net_info)
952         except NotImplementedError as e:
953             LOG.debug(e, instance=instance)
954         except exception.VirtualInterfacePlugException:
955             # we don't want an exception to block the init_host
956             LOG.exception(_LE("Vifs plug failed"), instance=instance)
957             self._set_instance_obj_error_state(context, instance)
958             return
959 
960         if instance.task_state == task_states.RESIZE_MIGRATING:
961             # We crashed during resize/migration, so roll back for safety
962             try:
963                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
964                 # not in system_metadata we default to True for backwards
965                 # compatibility
966                 power_on = (instance.system_metadata.get('old_vm_state') !=
967                             vm_states.STOPPED)
968 
969                 block_dev_info = self._get_instance_block_device_info(context,
970                                                                       instance)
971 
972                 self.driver.finish_revert_migration(context,
973                     instance, net_info, block_dev_info, power_on)
974 
975             except Exception:
976                 LOG.exception(_LE('Failed to revert crashed migration'),
977                               instance=instance)
978             finally:
979                 LOG.info(_LI('Instance found in migrating state during '
980                              'startup. Resetting task_state'),
981                          instance=instance)
982                 instance.task_state = None
983                 instance.save()
984         if instance.task_state == task_states.MIGRATING:
985             # Live migration did not complete, but instance is on this
986             # host, so reset the state.
987             instance.task_state = None
988             instance.save(expected_task_state=[task_states.MIGRATING])
989 
990         db_state = instance.power_state
991         drv_state = self._get_power_state(context, instance)
992         expect_running = (db_state == power_state.RUNNING and
993                           drv_state != db_state)
994 
995         LOG.debug('Current state is %(drv_state)s, state in DB is '
996                   '%(db_state)s.',
997                   {'drv_state': drv_state, 'db_state': db_state},
998                   instance=instance)
999 
1000         if expect_running and CONF.resume_guests_state_on_host_boot:
1001             LOG.info(_LI('Rebooting instance after nova-compute restart.'),
1002                      instance=instance)
1003 
1004             block_device_info = \
1005                 self._get_instance_block_device_info(context, instance)
1006 
1007             try:
1008                 self.driver.resume_state_on_host_boot(
1009                     context, instance, net_info, block_device_info)
1010             except NotImplementedError:
1011                 LOG.warning(_LW('Hypervisor driver does not support '
1012                                 'resume guests'), instance=instance)
1013             except Exception:
1014                 # NOTE(vish): The instance failed to resume, so we set the
1015                 #             instance to error and attempt to continue.
1016                 LOG.warning(_LW('Failed to resume instance'),
1017                             instance=instance)
1018                 self._set_instance_obj_error_state(context, instance)
1019 
1020         elif drv_state == power_state.RUNNING:
1021             # VMwareAPI drivers will raise an exception
1022             try:
1023                 self.driver.ensure_filtering_rules_for_instance(
1024                                        instance, net_info)
1025             except NotImplementedError:
1026                 LOG.debug('Hypervisor driver does not support '
1027                           'firewall rules', instance=instance)
1028 
1029     def _retry_reboot(self, context, instance, current_power_state):
1030         current_task_state = instance.task_state
1031         retry_reboot = False
1032         reboot_type = compute_utils.get_reboot_type(current_task_state,
1033                                                     current_power_state)
1034 
1035         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1036                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1037         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1038                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1039         started_not_running = (current_task_state in
1040                                [task_states.REBOOT_STARTED,
1041                                 task_states.REBOOT_STARTED_HARD] and
1042                                current_power_state != power_state.RUNNING)
1043 
1044         if pending_soft or pending_hard or started_not_running:
1045             retry_reboot = True
1046 
1047         return retry_reboot, reboot_type
1048 
1049     def handle_lifecycle_event(self, event):
1050         LOG.info(_LI("VM %(state)s (Lifecycle Event)"),
1051                  {'state': event.get_name()},
1052                  instance_uuid=event.get_instance_uuid())
1053         context = nova.context.get_admin_context(read_deleted='yes')
1054         instance = objects.Instance.get_by_uuid(context,
1055                                                 event.get_instance_uuid(),
1056                                                 expected_attrs=[])
1057         vm_power_state = None
1058         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1059             vm_power_state = power_state.SHUTDOWN
1060         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1061             vm_power_state = power_state.RUNNING
1062         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1063             vm_power_state = power_state.PAUSED
1064         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1065             vm_power_state = power_state.RUNNING
1066         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1067             vm_power_state = power_state.SUSPENDED
1068         else:
1069             LOG.warning(_LW("Unexpected power state %d"),
1070                         event.get_transition())
1071 
1072         # Note(lpetrut): The event may be delayed, thus not reflecting
1073         # the current instance power state. In that case, ignore the event.
1074         current_power_state = self._get_power_state(context, instance)
1075         if current_power_state == vm_power_state:
1076             LOG.debug('Synchronizing instance power state after lifecycle '
1077                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1078                       'current task_state: %(task_state)s, current DB '
1079                       'power_state: %(db_power_state)s, VM power_state: '
1080                       '%(vm_power_state)s',
1081                       {'event': event.get_name(),
1082                        'vm_state': instance.vm_state,
1083                        'task_state': instance.task_state,
1084                        'db_power_state': instance.power_state,
1085                        'vm_power_state': vm_power_state},
1086                       instance_uuid=instance.uuid)
1087             self._sync_instance_power_state(context,
1088                                             instance,
1089                                             vm_power_state)
1090 
1091     def handle_events(self, event):
1092         if isinstance(event, virtevent.LifecycleEvent):
1093             try:
1094                 self.handle_lifecycle_event(event)
1095             except exception.InstanceNotFound:
1096                 LOG.debug("Event %s arrived for non-existent instance. The "
1097                           "instance was probably deleted.", event)
1098         else:
1099             LOG.debug("Ignoring event %s", event)
1100 
1101     def init_virt_events(self):
1102         if CONF.workarounds.handle_virt_lifecycle_events:
1103             self.driver.register_event_listener(self.handle_events)
1104         else:
1105             # NOTE(mriedem): If the _sync_power_states periodic task is
1106             # disabled we should emit a warning in the logs.
1107             if CONF.sync_power_state_interval < 0:
1108                 LOG.warning(_LW('Instance lifecycle events from the compute '
1109                              'driver have been disabled. Note that lifecycle '
1110                              'changes to an instance outside of the compute '
1111                              'service will not be synchronized '
1112                              'automatically since the _sync_power_states '
1113                              'periodic task is also disabled.'))
1114             else:
1115                 LOG.info(_LI('Instance lifecycle events from the compute '
1116                              'driver have been disabled. Note that lifecycle '
1117                              'changes to an instance outside of the compute '
1118                              'service will only be synchronized by the '
1119                              '_sync_power_states periodic task.'))
1120 
1121     def init_host(self):
1122         """Initialization for a standalone compute service."""
1123         self.driver.init_host(host=self.host)
1124         context = nova.context.get_admin_context()
1125         instances = objects.InstanceList.get_by_host(
1126             context, self.host, expected_attrs=['info_cache', 'metadata'])
1127 
1128         if CONF.defer_iptables_apply:
1129             self.driver.filter_defer_apply_on()
1130 
1131         self.init_virt_events()
1132 
1133         try:
1134             # checking that instance was not already evacuated to other host
1135             self._destroy_evacuated_instances(context)
1136             for instance in instances:
1137                 self._init_instance(context, instance)
1138         finally:
1139             if CONF.defer_iptables_apply:
1140                 self.driver.filter_defer_apply_off()
1141             self._update_scheduler_instance_info(context, instances)
1142 
1143     def cleanup_host(self):
1144         self.driver.register_event_listener(None)
1145         self.instance_events.cancel_all_events()
1146         self.driver.cleanup_host(host=self.host)
1147 
1148     def pre_start_hook(self):
1149         """After the service is initialized, but before we fully bring
1150         the service up by listening on RPC queues, make sure to update
1151         our available resources (and indirectly our available nodes).
1152         """
1153         self.update_available_resource(nova.context.get_admin_context())
1154 
1155     def _get_power_state(self, context, instance):
1156         """Retrieve the power state for the given instance."""
1157         LOG.debug('Checking state', instance=instance)
1158         try:
1159             return self.driver.get_info(instance).state
1160         except exception.InstanceNotFound:
1161             return power_state.NOSTATE
1162 
1163     def get_console_topic(self, context):
1164         """Retrieves the console host for a project on this host.
1165 
1166         Currently this is just set in the flags for each compute host.
1167 
1168         """
1169         # TODO(mdragon): perhaps make this variable by console_type?
1170         return '%s.%s' % (CONF.console_topic, CONF.console_host)
1171 
1172     @wrap_exception()
1173     def get_console_pool_info(self, context, console_type):
1174         return self.driver.get_console_pool_info(console_type)
1175 
1176     # NOTE(hanlind): This and the virt method it calls can be removed in
1177     # version 5.0 of the RPC API
1178     @wrap_exception()
1179     def refresh_security_group_rules(self, context, security_group_id):
1180         """Tell the virtualization driver to refresh security group rules.
1181 
1182         Passes straight through to the virtualization driver.
1183 
1184         """
1185         return self.driver.refresh_security_group_rules(security_group_id)
1186 
1187     # TODO(alaski): Remove object_compat for RPC version 5.0
1188     @object_compat
1189     @wrap_exception()
1190     def refresh_instance_security_rules(self, context, instance):
1191         """Tell the virtualization driver to refresh security rules for
1192         an instance.
1193 
1194         Passes straight through to the virtualization driver.
1195 
1196         Synchronize the call because we may still be in the middle of
1197         creating the instance.
1198         """
1199         @utils.synchronized(instance.uuid)
1200         def _sync_refresh():
1201             try:
1202                 return self.driver.refresh_instance_security_rules(instance)
1203             except NotImplementedError:
1204                 LOG.debug('Hypervisor driver does not support '
1205                           'security groups.', instance=instance)
1206 
1207         return _sync_refresh()
1208 
1209     def _await_block_device_map_created(self, context, vol_id):
1210         # TODO(yamahata): creating volume simultaneously
1211         #                 reduces creation time?
1212         # TODO(yamahata): eliminate dumb polling
1213         start = time.time()
1214         retries = CONF.block_device_allocate_retries
1215         if retries < 0:
1216             LOG.warning(_LW("Treating negative config value (%(retries)s) for "
1217                             "'block_device_retries' as 0."),
1218                         {'retries': retries})
1219         # (1) treat  negative config value as 0
1220         # (2) the configured value is 0, one attempt should be made
1221         # (3) the configured value is > 0, then the total number attempts
1222         #      is (retries + 1)
1223         attempts = 1
1224         if retries >= 1:
1225             attempts = retries + 1
1226         for attempt in range(1, attempts + 1):
1227             volume = self.volume_api.get(context, vol_id)
1228             volume_status = volume['status']
1229             if volume_status not in ['creating', 'downloading']:
1230                 if volume_status == 'available':
1231                     return attempt
1232                 LOG.warning(_LW("Volume id: %(vol_id)s finished being "
1233                                 "created but its status is %(vol_status)s."),
1234                             {'vol_id': vol_id,
1235                              'vol_status': volume_status})
1236                 break
1237             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1238         raise exception.VolumeNotCreated(volume_id=vol_id,
1239                                          seconds=int(time.time() - start),
1240                                          attempts=attempt,
1241                                          volume_status=volume_status)
1242 
1243     def _decode_files(self, injected_files):
1244         """Base64 decode the list of files to inject."""
1245         if not injected_files:
1246             return []
1247 
1248         def _decode(f):
1249             path, contents = f
1250             # Py3 raises binascii.Error instead of TypeError as in Py27
1251             try:
1252                 decoded = base64.b64decode(contents)
1253                 return path, decoded
1254             except (TypeError, binascii.Error):
1255                 raise exception.Base64Exception(path=path)
1256 
1257         return [_decode(f) for f in injected_files]
1258 
1259     def _validate_instance_group_policy(self, context, instance,
1260             filter_properties):
1261         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1262         # However, there is a race condition with the enforcement of
1263         # the policy.  Since more than one instance may be scheduled at the
1264         # same time, it's possible that more than one instance with an
1265         # anti-affinity policy may end up here.  It's also possible that
1266         # multiple instances with an affinity policy could end up on different
1267         # hosts.  This is a validation step to make sure that starting the
1268         # instance here doesn't violate the policy.
1269 
1270         scheduler_hints = filter_properties.get('scheduler_hints') or {}
1271         group_hint = scheduler_hints.get('group')
1272         if not group_hint:
1273             return
1274 
1275         @utils.synchronized(group_hint)
1276         def _do_validation(context, instance, group_hint):
1277             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1278             if 'anti-affinity' in group.policies:
1279                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1280                 if self.host in group_hosts:
1281                     msg = _("Anti-affinity instance group policy "
1282                             "was violated.")
1283                     raise exception.RescheduledException(
1284                             instance_uuid=instance.uuid,
1285                             reason=msg)
1286             elif 'affinity' in group.policies:
1287                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1288                 if group_hosts and self.host not in group_hosts:
1289                     msg = _("Affinity instance group policy was violated.")
1290                     raise exception.RescheduledException(
1291                             instance_uuid=instance.uuid,
1292                             reason=msg)
1293 
1294         _do_validation(context, instance, group_hint)
1295 
1296     def _log_original_error(self, exc_info, instance_uuid):
1297         LOG.error(_LE('Error: %s'), exc_info[1], instance_uuid=instance_uuid,
1298                   exc_info=exc_info)
1299 
1300     def _reschedule(self, context, request_spec, filter_properties,
1301             instance, reschedule_method, method_args, task_state,
1302             exc_info=None):
1303         """Attempt to re-schedule a compute operation."""
1304 
1305         instance_uuid = instance.uuid
1306         retry = filter_properties.get('retry')
1307         if not retry:
1308             # no retry information, do not reschedule.
1309             LOG.debug("Retry info not present, will not reschedule",
1310                       instance_uuid=instance_uuid)
1311             return
1312 
1313         if not request_spec:
1314             LOG.debug("No request spec, will not reschedule",
1315                       instance_uuid=instance_uuid)
1316             return
1317 
1318         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1319                   {'method': reschedule_method.__name__,
1320                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1321 
1322         # reset the task state:
1323         self._instance_update(context, instance, task_state=task_state)
1324 
1325         if exc_info:
1326             # stringify to avoid circular ref problem in json serialization:
1327             retry['exc'] = traceback.format_exception_only(exc_info[0],
1328                                     exc_info[1])
1329 
1330         reschedule_method(context, *method_args)
1331         return True
1332 
1333     @periodic_task.periodic_task
1334     def _check_instance_build_time(self, context):
1335         """Ensure that instances are not stuck in build."""
1336         timeout = CONF.instance_build_timeout
1337         if timeout == 0:
1338             return
1339 
1340         filters = {'vm_state': vm_states.BUILDING,
1341                    'host': self.host}
1342 
1343         building_insts = objects.InstanceList.get_by_filters(context,
1344                            filters, expected_attrs=[], use_slave=True)
1345 
1346         for instance in building_insts:
1347             if timeutils.is_older_than(instance.created_at, timeout):
1348                 self._set_instance_obj_error_state(context, instance)
1349                 LOG.warning(_LW("Instance build timed out. Set to error "
1350                                 "state."), instance=instance)
1351 
1352     def _check_instance_exists(self, context, instance):
1353         """Ensure an instance with the same name is not already present."""
1354         if self.driver.instance_exists(instance):
1355             raise exception.InstanceExists(name=instance.name)
1356 
1357     def _allocate_network_async(self, context, instance, requested_networks,
1358                                 macs, security_groups, is_vpn, dhcp_options):
1359         """Method used to allocate networks in the background.
1360 
1361         Broken out for testing.
1362         """
1363         # First check to see if we're specifically not supposed to allocate
1364         # networks because if so, we can exit early.
1365         if requested_networks and requested_networks.no_allocate:
1366             LOG.debug("Not allocating networking since 'none' was specified.",
1367                       instance=instance)
1368             return network_model.NetworkInfo([])
1369 
1370         LOG.debug("Allocating IP information in the background.",
1371                   instance=instance)
1372         retries = CONF.network_allocate_retries
1373         if retries < 0:
1374             LOG.warning(_LW("Treating negative config value (%(retries)s) for "
1375                             "'network_allocate_retries' as 0."),
1376                         {'retries': retries})
1377             retries = 0
1378         attempts = retries + 1
1379         retry_time = 1
1380         bind_host_id = self.driver.network_binding_host_id(context, instance)
1381         for attempt in range(1, attempts + 1):
1382             try:
1383                 nwinfo = self.network_api.allocate_for_instance(
1384                         context, instance, vpn=is_vpn,
1385                         requested_networks=requested_networks,
1386                         macs=macs,
1387                         security_groups=security_groups,
1388                         dhcp_options=dhcp_options,
1389                         bind_host_id=bind_host_id)
1390                 LOG.debug('Instance network_info: |%s|', nwinfo,
1391                           instance=instance)
1392                 instance.system_metadata['network_allocated'] = 'True'
1393                 # NOTE(JoshNang) do not save the instance here, as it can cause
1394                 # races. The caller shares a reference to instance and waits
1395                 # for this async greenthread to finish before calling
1396                 # instance.save().
1397                 return nwinfo
1398             except Exception:
1399                 exc_info = sys.exc_info()
1400                 log_info = {'attempt': attempt,
1401                             'attempts': attempts}
1402                 if attempt == attempts:
1403                     LOG.exception(_LE('Instance failed network setup '
1404                                       'after %(attempts)d attempt(s)'),
1405                                   log_info)
1406                     six.reraise(*exc_info)
1407                 LOG.warning(_LW('Instance failed network setup '
1408                                 '(attempt %(attempt)d of %(attempts)d)'),
1409                             log_info, instance=instance)
1410                 time.sleep(retry_time)
1411                 retry_time *= 2
1412                 if retry_time > 30:
1413                     retry_time = 30
1414         # Not reached.
1415 
1416     def _build_networks_for_instance(self, context, instance,
1417             requested_networks, security_groups):
1418 
1419         # If we're here from a reschedule the network may already be allocated.
1420         if strutils.bool_from_string(
1421                 instance.system_metadata.get('network_allocated', 'False')):
1422             # NOTE(alex_xu): The network_allocated is True means the network
1423             # resource already allocated at previous scheduling, and the
1424             # network setup is cleanup at previous. After rescheduling, the
1425             # network resource need setup on the new host.
1426             self.network_api.setup_instance_network_on_host(
1427                 context, instance, instance.host)
1428             return self.network_api.get_instance_nw_info(context, instance)
1429 
1430         if not self.is_neutron_security_groups:
1431             security_groups = []
1432 
1433         macs = self.driver.macs_for_instance(instance)
1434         dhcp_options = self.driver.dhcp_options_for_instance(instance)
1435         network_info = self._allocate_network(context, instance,
1436                 requested_networks, macs, security_groups, dhcp_options)
1437 
1438         return network_info
1439 
1440     def _allocate_network(self, context, instance, requested_networks, macs,
1441                           security_groups, dhcp_options):
1442         """Start network allocation asynchronously.  Return an instance
1443         of NetworkInfoAsyncWrapper that can be used to retrieve the
1444         allocated networks when the operation has finished.
1445         """
1446         # NOTE(comstud): Since we're allocating networks asynchronously,
1447         # this task state has little meaning, as we won't be in this
1448         # state for very long.
1449         instance.vm_state = vm_states.BUILDING
1450         instance.task_state = task_states.NETWORKING
1451         instance.save(expected_task_state=[None])
1452         self._update_resource_tracker(context, instance)
1453 
1454         is_vpn = pipelib.is_vpn_image(instance.image_ref)
1455         return network_model.NetworkInfoAsyncWrapper(
1456                 self._allocate_network_async, context, instance,
1457                 requested_networks, macs, security_groups, is_vpn,
1458                 dhcp_options)
1459 
1460     def _default_root_device_name(self, instance, image_meta, root_bdm):
1461         try:
1462             return self.driver.default_root_device_name(instance,
1463                                                         image_meta,
1464                                                         root_bdm)
1465         except NotImplementedError:
1466             return compute_utils.get_next_device_name(instance, [])
1467 
1468     def _default_device_names_for_instance(self, instance,
1469                                            root_device_name,
1470                                            *block_device_lists):
1471         try:
1472             self.driver.default_device_names_for_instance(instance,
1473                                                           root_device_name,
1474                                                           *block_device_lists)
1475         except NotImplementedError:
1476             compute_utils.default_device_names_for_instance(
1477                 instance, root_device_name, *block_device_lists)
1478 
1479     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1480         # NOTE(ndipanov): Copy obj to avoid changing the original
1481         block_device_obj = block_device_obj.obj_clone()
1482         try:
1483             return self.driver.get_device_name_for_instance(
1484                 instance, bdms, block_device_obj)
1485         except NotImplementedError:
1486             return compute_utils.get_device_name_for_instance(
1487                 instance, bdms, block_device_obj.get("device_name"))
1488 
1489     def _default_block_device_names(self, context, instance,
1490                                     image_meta, block_devices):
1491         """Verify that all the devices have the device_name set. If not,
1492         provide a default name.
1493 
1494         It also ensures that there is a root_device_name and is set to the
1495         first block device in the boot sequence (boot_index=0).
1496         """
1497         root_bdm = block_device.get_root_bdm(block_devices)
1498         if not root_bdm:
1499             return
1500 
1501         # Get the root_device_name from the root BDM or the instance
1502         root_device_name = None
1503         update_root_bdm = False
1504 
1505         if root_bdm.device_name:
1506             root_device_name = root_bdm.device_name
1507             instance.root_device_name = root_device_name
1508         elif instance.root_device_name:
1509             root_device_name = instance.root_device_name
1510             root_bdm.device_name = root_device_name
1511             update_root_bdm = True
1512         else:
1513             root_device_name = self._default_root_device_name(instance,
1514                                                               image_meta,
1515                                                               root_bdm)
1516 
1517             instance.root_device_name = root_device_name
1518             root_bdm.device_name = root_device_name
1519             update_root_bdm = True
1520 
1521         if update_root_bdm:
1522             root_bdm.save()
1523 
1524         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1525                             block_devices))
1526         swap = list(filter(block_device.new_format_is_swap,
1527                       block_devices))
1528         block_device_mapping = list(filter(
1529               driver_block_device.is_block_device_mapping, block_devices))
1530 
1531         self._default_device_names_for_instance(instance,
1532                                                 root_device_name,
1533                                                 ephemerals,
1534                                                 swap,
1535                                                 block_device_mapping)
1536 
1537     def _block_device_info_to_legacy(self, block_device_info):
1538         """Convert BDI to the old format for drivers that need it."""
1539 
1540         if self.use_legacy_block_device_info:
1541             ephemerals = driver_block_device.legacy_block_devices(
1542                 driver.block_device_info_get_ephemerals(block_device_info))
1543             mapping = driver_block_device.legacy_block_devices(
1544                 driver.block_device_info_get_mapping(block_device_info))
1545             swap = block_device_info['swap']
1546             if swap:
1547                 swap = swap.legacy()
1548 
1549             block_device_info.update({
1550                 'ephemerals': ephemerals,
1551                 'swap': swap,
1552                 'block_device_mapping': mapping})
1553 
1554     def _check_dev_name(self, bdms, instance):
1555         bdms_no_device_name = [x for x in bdms if x.device_name is None]
1556         for bdm in bdms_no_device_name:
1557             device_name = self._get_device_name_for_instance(instance,
1558                                                              bdms,
1559                                                              bdm)
1560             values = {'device_name': device_name}
1561             bdm.update(values)
1562 
1563     def _prep_block_device(self, context, instance, bdms,
1564                            do_check_attach=True):
1565         """Set up the block device for an instance with error logging."""
1566         try:
1567             self._check_dev_name(bdms, instance)
1568             block_device_info = driver.get_block_device_info(instance, bdms)
1569             mapping = driver.block_device_info_get_mapping(block_device_info)
1570             driver_block_device.attach_block_devices(
1571                 mapping, context, instance, self.volume_api, self.driver,
1572                 do_check_attach=do_check_attach,
1573                 wait_func=self._await_block_device_map_created)
1574 
1575             self._block_device_info_to_legacy(block_device_info)
1576             return block_device_info
1577 
1578         except exception.OverQuota:
1579             msg = _LW('Failed to create block device for instance due to '
1580                       'being over volume resource quota')
1581             LOG.warning(msg, instance=instance)
1582             raise exception.VolumeLimitExceeded()
1583 
1584         except Exception:
1585             LOG.exception(_LE('Instance failed block device setup'),
1586                           instance=instance)
1587             raise exception.InvalidBDM()
1588 
1589     def _update_instance_after_spawn(self, context, instance):
1590         instance.power_state = self._get_power_state(context, instance)
1591         instance.vm_state = vm_states.ACTIVE
1592         instance.task_state = None
1593         instance.launched_at = timeutils.utcnow()
1594         configdrive.update_instance(instance)
1595 
1596     def _update_scheduler_instance_info(self, context, instance):
1597         """Sends an InstanceList with created or updated Instance objects to
1598         the Scheduler client.
1599 
1600         In the case of init_host, the value passed will already be an
1601         InstanceList. Other calls will send individual Instance objects that
1602         have been created or resized. In this case, we create an InstanceList
1603         object containing that Instance.
1604         """
1605         if not self.send_instance_updates:
1606             return
1607         if isinstance(instance, obj_instance.Instance):
1608             instance = objects.InstanceList(objects=[instance])
1609         context = context.elevated()
1610         self.scheduler_client.update_instance_info(context, self.host,
1611                                                    instance)
1612 
1613     def _delete_scheduler_instance_info(self, context, instance_uuid):
1614         """Sends the uuid of the deleted Instance to the Scheduler client."""
1615         if not self.send_instance_updates:
1616             return
1617         context = context.elevated()
1618         self.scheduler_client.delete_instance_info(context, self.host,
1619                                                    instance_uuid)
1620 
1621     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1622     def _sync_scheduler_instance_info(self, context):
1623         if not self.send_instance_updates:
1624             return
1625         context = context.elevated()
1626         instances = objects.InstanceList.get_by_host(context, self.host,
1627                                                      expected_attrs=[],
1628                                                      use_slave=True)
1629         uuids = [instance.uuid for instance in instances]
1630         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1631 
1632     def _notify_about_instance_usage(self, context, instance, event_suffix,
1633                                      network_info=None, system_metadata=None,
1634                                      extra_usage_info=None, fault=None):
1635         compute_utils.notify_about_instance_usage(
1636             self.notifier, context, instance, event_suffix,
1637             network_info=network_info,
1638             system_metadata=system_metadata,
1639             extra_usage_info=extra_usage_info, fault=fault)
1640 
1641     def _deallocate_network(self, context, instance,
1642                             requested_networks=None):
1643         # If we were told not to allocate networks let's save ourselves
1644         # the trouble of calling the network API.
1645         if requested_networks and requested_networks.no_allocate:
1646             LOG.debug("Skipping network deallocation for instance since "
1647                       "networking was not requested.", instance=instance)
1648             return
1649 
1650         LOG.debug('Deallocating network for instance', instance=instance)
1651         with timeutils.StopWatch() as timer:
1652             self.network_api.deallocate_for_instance(
1653                 context, instance, requested_networks=requested_networks)
1654         # nova-network does an rpc call so we're OK tracking time spent here
1655         LOG.info(_LI('Took %0.2f seconds to deallocate network for instance.'),
1656                  timer.elapsed(), instance=instance)
1657 
1658     def _get_instance_block_device_info(self, context, instance,
1659                                         refresh_conn_info=False,
1660                                         bdms=None):
1661         """Transform block devices to the driver block_device format."""
1662 
1663         if not bdms:
1664             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1665                     context, instance.uuid)
1666         block_device_info = driver.get_block_device_info(instance, bdms)
1667 
1668         if not refresh_conn_info:
1669             # if the block_device_mapping has no value in connection_info
1670             # (returned as None), don't include in the mapping
1671             block_device_info['block_device_mapping'] = [
1672                 bdm for bdm in driver.block_device_info_get_mapping(
1673                                     block_device_info)
1674                 if bdm.get('connection_info')]
1675         else:
1676             driver_block_device.refresh_conn_infos(
1677                 driver.block_device_info_get_mapping(block_device_info),
1678                 context, instance, self.volume_api, self.driver)
1679 
1680         self._block_device_info_to_legacy(block_device_info)
1681 
1682         return block_device_info
1683 
1684     @wrap_exception()
1685     @reverts_task_state
1686     @wrap_instance_fault
1687     def build_and_run_instance(self, context, instance, image, request_spec,
1688                      filter_properties, admin_password=None,
1689                      injected_files=None, requested_networks=None,
1690                      security_groups=None, block_device_mapping=None,
1691                      node=None, limits=None):
1692 
1693         @utils.synchronized(instance.uuid)
1694         def _locked_do_build_and_run_instance(*args, **kwargs):
1695             # NOTE(danms): We grab the semaphore with the instance uuid
1696             # locked because we could wait in line to build this instance
1697             # for a while and we want to make sure that nothing else tries
1698             # to do anything with this instance while we wait.
1699             with self._build_semaphore:
1700                 self._do_build_and_run_instance(*args, **kwargs)
1701 
1702         # NOTE(danms): We spawn here to return the RPC worker thread back to
1703         # the pool. Since what follows could take a really long time, we don't
1704         # want to tie up RPC workers.
1705         utils.spawn_n(_locked_do_build_and_run_instance,
1706                       context, instance, image, request_spec,
1707                       filter_properties, admin_password, injected_files,
1708                       requested_networks, security_groups,
1709                       block_device_mapping, node, limits)
1710 
1711     def _check_device_tagging(self, requested_networks, block_device_mapping):
1712         tagging_requested = False
1713         if requested_networks:
1714             for net in requested_networks:
1715                 if 'tag' in net and net.tag is not None:
1716                     tagging_requested = True
1717                     break
1718         if block_device_mapping and not tagging_requested:
1719             for bdm in block_device_mapping:
1720                 if 'tag' in bdm and bdm.tag is not None:
1721                     tagging_requested = True
1722                     break
1723         if (tagging_requested and
1724                 not self.driver.capabilities.get('supports_device_tagging')):
1725             raise exception.BuildAbortException('Attempt to boot guest with '
1726                                                 'tagged devices on host that '
1727                                                 'does not support tagging.')
1728 
1729     @hooks.add_hook('build_instance')
1730     @wrap_exception()
1731     @reverts_task_state
1732     @wrap_instance_event(prefix='compute')
1733     @wrap_instance_fault
1734     def _do_build_and_run_instance(self, context, instance, image,
1735             request_spec, filter_properties, admin_password, injected_files,
1736             requested_networks, security_groups, block_device_mapping,
1737             node=None, limits=None):
1738 
1739         try:
1740             LOG.debug('Starting instance...', context=context,
1741                       instance=instance)
1742             instance.vm_state = vm_states.BUILDING
1743             instance.task_state = None
1744             instance.save(expected_task_state=
1745                     (task_states.SCHEDULING, None))
1746         except exception.InstanceNotFound:
1747             msg = 'Instance disappeared before build.'
1748             LOG.debug(msg, instance=instance)
1749             return build_results.FAILED
1750         except exception.UnexpectedTaskStateError as e:
1751             LOG.debug(e.format_message(), instance=instance)
1752             return build_results.FAILED
1753 
1754         # b64 decode the files to inject:
1755         decoded_files = self._decode_files(injected_files)
1756 
1757         if limits is None:
1758             limits = {}
1759 
1760         if node is None:
1761             node = self.driver.get_available_nodes(refresh=True)[0]
1762             LOG.debug('No node specified, defaulting to %s', node,
1763                       instance=instance)
1764 
1765         try:
1766             with timeutils.StopWatch() as timer:
1767                 self._build_and_run_instance(context, instance, image,
1768                         decoded_files, admin_password, requested_networks,
1769                         security_groups, block_device_mapping, node, limits,
1770                         filter_properties)
1771             LOG.info(_LI('Took %0.2f seconds to build instance.'),
1772                      timer.elapsed(), instance=instance)
1773             return build_results.ACTIVE
1774         except exception.RescheduledException as e:
1775             retry = filter_properties.get('retry')
1776             if not retry:
1777                 # no retry information, do not reschedule.
1778                 LOG.debug("Retry info not present, will not reschedule",
1779                     instance=instance)
1780                 self._cleanup_allocated_networks(context, instance,
1781                     requested_networks)
1782                 compute_utils.add_instance_fault_from_exc(context,
1783                         instance, e, sys.exc_info(),
1784                         fault_message=e.kwargs['reason'])
1785                 self._nil_out_instance_obj_host_and_node(instance)
1786                 self._set_instance_obj_error_state(context, instance,
1787                                                    clean_task_state=True)
1788                 return build_results.FAILED
1789             LOG.debug(e.format_message(), instance=instance)
1790             # This will be used for logging the exception
1791             retry['exc'] = traceback.format_exception(*sys.exc_info())
1792             # This will be used for setting the instance fault message
1793             retry['exc_reason'] = e.kwargs['reason']
1794             # NOTE(comstud): Deallocate networks if the driver wants
1795             # us to do so.
1796             # NOTE(vladikr): SR-IOV ports should be deallocated to
1797             # allow new sriov pci devices to be allocated on a new host.
1798             # Otherwise, if devices with pci addresses are already allocated
1799             # on the destination host, the instance will fail to spawn.
1800             # info_cache.network_info should be present at this stage.
1801             if (self.driver.deallocate_networks_on_reschedule(instance) or
1802                 self.deallocate_sriov_ports_on_reschedule(instance)):
1803                 self._cleanup_allocated_networks(context, instance,
1804                         requested_networks)
1805             else:
1806                 # NOTE(alex_xu): Network already allocated and we don't
1807                 # want to deallocate them before rescheduling. But we need
1808                 # to cleanup those network resources setup on this host before
1809                 # rescheduling.
1810                 self.network_api.cleanup_instance_network_on_host(
1811                     context, instance, self.host)
1812 
1813             self._nil_out_instance_obj_host_and_node(instance)
1814             instance.task_state = task_states.SCHEDULING
1815             instance.save()
1816 
1817             self.compute_task_api.build_instances(context, [instance],
1818                     image, filter_properties, admin_password,
1819                     injected_files, requested_networks, security_groups,
1820                     block_device_mapping)
1821             return build_results.RESCHEDULED
1822         except (exception.InstanceNotFound,
1823                 exception.UnexpectedDeletingTaskStateError):
1824             msg = 'Instance disappeared during build.'
1825             LOG.debug(msg, instance=instance)
1826             self._cleanup_allocated_networks(context, instance,
1827                     requested_networks)
1828             return build_results.FAILED
1829         except exception.BuildAbortException as e:
1830             LOG.exception(e.format_message(), instance=instance)
1831             self._cleanup_allocated_networks(context, instance,
1832                     requested_networks)
1833             self._cleanup_volumes(context, instance.uuid,
1834                     block_device_mapping, raise_exc=False)
1835             compute_utils.add_instance_fault_from_exc(context, instance,
1836                     e, sys.exc_info())
1837             self._nil_out_instance_obj_host_and_node(instance)
1838             self._set_instance_obj_error_state(context, instance,
1839                                                clean_task_state=True)
1840             return build_results.FAILED
1841         except Exception as e:
1842             # Should not reach here.
1843             msg = _LE('Unexpected build failure, not rescheduling build.')
1844             LOG.exception(msg, instance=instance)
1845             self._cleanup_allocated_networks(context, instance,
1846                     requested_networks)
1847             self._cleanup_volumes(context, instance.uuid,
1848                     block_device_mapping, raise_exc=False)
1849             compute_utils.add_instance_fault_from_exc(context, instance,
1850                     e, sys.exc_info())
1851             self._nil_out_instance_obj_host_and_node(instance)
1852             self._set_instance_obj_error_state(context, instance,
1853                                                clean_task_state=True)
1854             return build_results.FAILED
1855 
1856     def deallocate_sriov_ports_on_reschedule(self, instance):
1857         """Determine if networks are needed to be deallocated before reschedule
1858 
1859         Check the cached network info for any assigned SR-IOV ports.
1860         SR-IOV ports should be deallocated prior to rescheduling
1861         in order to allow new sriov pci devices to be allocated on a new host.
1862         """
1863         info_cache = instance.info_cache
1864 
1865         def _has_sriov_port(vif):
1866             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1867 
1868         if (info_cache and info_cache.network_info):
1869             for vif in info_cache.network_info:
1870                 if _has_sriov_port(vif):
1871                     return True
1872         return False
1873 
1874     def _build_and_run_instance(self, context, instance, image, injected_files,
1875             admin_password, requested_networks, security_groups,
1876             block_device_mapping, node, limits, filter_properties):
1877 
1878         image_name = image.get('name')
1879         self._notify_about_instance_usage(context, instance, 'create.start',
1880                 extra_usage_info={'image_name': image_name})
1881 
1882         self._check_device_tagging(requested_networks, block_device_mapping)
1883 
1884         try:
1885             rt = self._get_resource_tracker(node)
1886             with rt.instance_claim(context, instance, limits):
1887                 # NOTE(russellb) It's important that this validation be done
1888                 # *after* the resource tracker instance claim, as that is where
1889                 # the host is set on the instance.
1890                 self._validate_instance_group_policy(context, instance,
1891                         filter_properties)
1892                 image_meta = objects.ImageMeta.from_dict(image)
1893                 with self._build_resources(context, instance,
1894                         requested_networks, security_groups, image_meta,
1895                         block_device_mapping) as resources:
1896                     instance.vm_state = vm_states.BUILDING
1897                     instance.task_state = task_states.SPAWNING
1898                     # NOTE(JoshNang) This also saves the changes to the
1899                     # instance from _allocate_network_async, as they aren't
1900                     # saved in that function to prevent races.
1901                     instance.save(expected_task_state=
1902                             task_states.BLOCK_DEVICE_MAPPING)
1903                     block_device_info = resources['block_device_info']
1904                     network_info = resources['network_info']
1905                     LOG.debug('Start spawning the instance on the hypervisor.',
1906                               instance=instance)
1907                     with timeutils.StopWatch() as timer:
1908                         self.driver.spawn(context, instance, image_meta,
1909                                           injected_files, admin_password,
1910                                           network_info=network_info,
1911                                           block_device_info=block_device_info)
1912                     LOG.info(_LI('Took %0.2f seconds to spawn the instance on '
1913                                  'the hypervisor.'), timer.elapsed(),
1914                              instance=instance)
1915         except (exception.InstanceNotFound,
1916                 exception.UnexpectedDeletingTaskStateError) as e:
1917             with excutils.save_and_reraise_exception():
1918                 self._notify_about_instance_usage(context, instance,
1919                     'create.end', fault=e)
1920         except exception.ComputeResourcesUnavailable as e:
1921             LOG.debug(e.format_message(), instance=instance)
1922             self._notify_about_instance_usage(context, instance,
1923                     'create.error', fault=e)
1924             raise exception.RescheduledException(
1925                     instance_uuid=instance.uuid, reason=e.format_message())
1926         except exception.BuildAbortException as e:
1927             with excutils.save_and_reraise_exception():
1928                 LOG.debug(e.format_message(), instance=instance)
1929                 self._notify_about_instance_usage(context, instance,
1930                     'create.error', fault=e)
1931         except (exception.FixedIpLimitExceeded,
1932                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
1933             LOG.warning(_LW('No more network or fixed IP to be allocated'),
1934                         instance=instance)
1935             self._notify_about_instance_usage(context, instance,
1936                     'create.error', fault=e)
1937             msg = _('Failed to allocate the network(s) with error %s, '
1938                     'not rescheduling.') % e.format_message()
1939             raise exception.BuildAbortException(instance_uuid=instance.uuid,
1940                     reason=msg)
1941         except (exception.VirtualInterfaceCreateException,
1942                 exception.VirtualInterfaceMacAddressException,
1943                 exception.UnableToAutoAllocateNetwork) as e:
1944             LOG.exception(_LE('Failed to allocate network(s)'),
1945                           instance=instance)
1946             self._notify_about_instance_usage(context, instance,
1947                     'create.error', fault=e)
1948             msg = _('Failed to allocate the network(s), not rescheduling.')
1949             raise exception.BuildAbortException(instance_uuid=instance.uuid,
1950                     reason=msg)
1951         except (exception.FlavorDiskTooSmall,
1952                 exception.FlavorMemoryTooSmall,
1953                 exception.ImageNotActive,
1954                 exception.ImageUnacceptable,
1955                 exception.InvalidDiskInfo,
1956                 exception.SignatureVerificationError) as e:
1957             self._notify_about_instance_usage(context, instance,
1958                     'create.error', fault=e)
1959             raise exception.BuildAbortException(instance_uuid=instance.uuid,
1960                     reason=e.format_message())
1961         except Exception as e:
1962             self._notify_about_instance_usage(context, instance,
1963                     'create.error', fault=e)
1964             raise exception.RescheduledException(
1965                     instance_uuid=instance.uuid, reason=six.text_type(e))
1966 
1967         # NOTE(alaski): This is only useful during reschedules, remove it now.
1968         instance.system_metadata.pop('network_allocated', None)
1969 
1970         # If CONF.default_access_ip_network_name is set, grab the
1971         # corresponding network and set the access ip values accordingly.
1972         network_name = CONF.default_access_ip_network_name
1973         if (network_name and not instance.access_ip_v4 and
1974                 not instance.access_ip_v6):
1975             # Note that when there are multiple ips to choose from, an
1976             # arbitrary one will be chosen.
1977             for vif in network_info:
1978                 if vif['network']['label'] == network_name:
1979                     for ip in vif.fixed_ips():
1980                         if not instance.access_ip_v4 and ip['version'] == 4:
1981                             instance.access_ip_v4 = ip['address']
1982                         if not instance.access_ip_v6 and ip['version'] == 6:
1983                             instance.access_ip_v6 = ip['address']
1984                     break
1985 
1986         self._update_instance_after_spawn(context, instance)
1987 
1988         try:
1989             instance.save(expected_task_state=task_states.SPAWNING)
1990         except (exception.InstanceNotFound,
1991                 exception.UnexpectedDeletingTaskStateError) as e:
1992             with excutils.save_and_reraise_exception():
1993                 self._notify_about_instance_usage(context, instance,
1994                     'create.end', fault=e)
1995 
1996         self._update_scheduler_instance_info(context, instance)
1997         self._notify_about_instance_usage(context, instance, 'create.end',
1998                 extra_usage_info={'message': _('Success')},
1999                 network_info=network_info)
2000 
2001     @contextlib.contextmanager
2002     def _build_resources(self, context, instance, requested_networks,
2003                          security_groups, image_meta, block_device_mapping):
2004         resources = {}
2005         network_info = None
2006         try:
2007             LOG.debug('Start building networks asynchronously for instance.',
2008                       instance=instance)
2009             network_info = self._build_networks_for_instance(context, instance,
2010                     requested_networks, security_groups)
2011             resources['network_info'] = network_info
2012         except (exception.InstanceNotFound,
2013                 exception.UnexpectedDeletingTaskStateError):
2014             raise
2015         except exception.UnexpectedTaskStateError as e:
2016             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2017                     reason=e.format_message())
2018         except Exception:
2019             # Because this allocation is async any failures are likely to occur
2020             # when the driver accesses network_info during spawn().
2021             LOG.exception(_LE('Failed to allocate network(s)'),
2022                           instance=instance)
2023             msg = _('Failed to allocate the network(s), not rescheduling.')
2024             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2025                     reason=msg)
2026 
2027         try:
2028             # Verify that all the BDMs have a device_name set and assign a
2029             # default to the ones missing it with the help of the driver.
2030             self._default_block_device_names(context, instance, image_meta,
2031                     block_device_mapping)
2032 
2033             LOG.debug('Start building block device mappings for instance.',
2034                       instance=instance)
2035             instance.vm_state = vm_states.BUILDING
2036             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2037             instance.save()
2038 
2039             block_device_info = self._prep_block_device(context, instance,
2040                     block_device_mapping)
2041             resources['block_device_info'] = block_device_info
2042         except (exception.InstanceNotFound,
2043                 exception.UnexpectedDeletingTaskStateError):
2044             with excutils.save_and_reraise_exception():
2045                 # Make sure the async call finishes
2046                 if network_info is not None:
2047                     network_info.wait(do_raise=False)
2048         except (exception.UnexpectedTaskStateError,
2049                 exception.VolumeLimitExceeded,
2050                 exception.InvalidBDM) as e:
2051             # Make sure the async call finishes
2052             if network_info is not None:
2053                 network_info.wait(do_raise=False)
2054             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2055                     reason=e.format_message())
2056         except Exception:
2057             LOG.exception(_LE('Failure prepping block device'),
2058                     instance=instance)
2059             # Make sure the async call finishes
2060             if network_info is not None:
2061                 network_info.wait(do_raise=False)
2062             msg = _('Failure prepping block device.')
2063             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2064                     reason=msg)
2065 
2066         try:
2067             yield resources
2068         except Exception as exc:
2069             with excutils.save_and_reraise_exception() as ctxt:
2070                 if not isinstance(exc, (exception.InstanceNotFound,
2071                     exception.UnexpectedDeletingTaskStateError)):
2072                         LOG.exception(_LE('Instance failed to spawn'),
2073                                 instance=instance)
2074                 # Make sure the async call finishes
2075                 if network_info is not None:
2076                     network_info.wait(do_raise=False)
2077                 # if network_info is empty we're likely here because of
2078                 # network allocation failure. Since nothing can be reused on
2079                 # rescheduling it's better to deallocate network to eliminate
2080                 # the chance of orphaned ports in neutron
2081                 deallocate_networks = False if network_info else True
2082                 try:
2083                     self._shutdown_instance(context, instance,
2084                             block_device_mapping, requested_networks,
2085                             try_deallocate_networks=deallocate_networks)
2086                 except Exception as exc2:
2087                     ctxt.reraise = False
2088                     LOG.warning(_LW('Could not clean up failed build,'
2089                                     ' not rescheduling. Error: %s'),
2090                                 six.text_type(exc2))
2091                     raise exception.BuildAbortException(
2092                             instance_uuid=instance.uuid,
2093                             reason=six.text_type(exc))
2094 
2095     def _cleanup_allocated_networks(self, context, instance,
2096             requested_networks):
2097         try:
2098             self._deallocate_network(context, instance, requested_networks)
2099         except Exception:
2100             msg = _LE('Failed to deallocate networks')
2101             LOG.exception(msg, instance=instance)
2102             return
2103 
2104         instance.system_metadata['network_allocated'] = 'False'
2105         try:
2106             instance.save()
2107         except exception.InstanceNotFound:
2108             # NOTE(alaski): It's possible that we're cleaning up the networks
2109             # because the instance was deleted.  If that's the case then this
2110             # exception will be raised by instance.save()
2111             pass
2112 
2113     def _try_deallocate_network(self, context, instance,
2114                                 requested_networks=None):
2115         try:
2116             # tear down allocated network structure
2117             self._deallocate_network(context, instance, requested_networks)
2118         except Exception as ex:
2119             with excutils.save_and_reraise_exception():
2120                 LOG.error(_LE('Failed to deallocate network for instance. '
2121                               'Error: %s'), ex,
2122                           instance=instance)
2123                 self._set_instance_obj_error_state(context, instance)
2124 
2125     def _get_power_off_values(self, context, instance, clean_shutdown):
2126         """Get the timing configuration for powering down this instance."""
2127         if clean_shutdown:
2128             timeout = compute_utils.get_value_from_system_metadata(instance,
2129                           key='image_os_shutdown_timeout', type=int,
2130                           default=CONF.shutdown_timeout)
2131             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2132         else:
2133             timeout = 0
2134             retry_interval = 0
2135 
2136         return timeout, retry_interval
2137 
2138     def _power_off_instance(self, context, instance, clean_shutdown=True):
2139         """Power off an instance on this host."""
2140         timeout, retry_interval = self._get_power_off_values(context,
2141                                         instance, clean_shutdown)
2142         self.driver.power_off(instance, timeout, retry_interval)
2143 
2144     def _shutdown_instance(self, context, instance,
2145                            bdms, requested_networks=None, notify=True,
2146                            try_deallocate_networks=True):
2147         """Shutdown an instance on this host.
2148 
2149         :param:context: security context
2150         :param:instance: a nova.objects.Instance object
2151         :param:bdms: the block devices for the instance to be torn
2152                      down
2153         :param:requested_networks: the networks on which the instance
2154                                    has ports
2155         :param:notify: true if a final usage notification should be
2156                        emitted
2157         :param:try_deallocate_networks: false if we should avoid
2158                                         trying to teardown networking
2159         """
2160         context = context.elevated()
2161         LOG.info(_LI('Terminating instance'),
2162                  context=context, instance=instance)
2163 
2164         if notify:
2165             self._notify_about_instance_usage(context, instance,
2166                                               "shutdown.start")
2167 
2168         network_info = compute_utils.get_nw_info_for_instance(instance)
2169 
2170         # NOTE(vish) get bdms before destroying the instance
2171         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2172         block_device_info = self._get_instance_block_device_info(
2173             context, instance, bdms=bdms)
2174 
2175         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2176         #                want to keep ip allocated for certain failures
2177         timer = timeutils.StopWatch()
2178         try:
2179             LOG.debug('Start destroying the instance on the hypervisor.',
2180                       instance=instance)
2181             timer.start()
2182             self.driver.destroy(context, instance, network_info,
2183                     block_device_info)
2184             LOG.info(_LI('Took %0.2f seconds to destroy the instance on the '
2185                          'hypervisor.'), timer.elapsed(), instance=instance)
2186         except exception.InstancePowerOffFailure:
2187             # if the instance can't power off, don't release the ip
2188             with excutils.save_and_reraise_exception():
2189                 pass
2190         except Exception:
2191             with excutils.save_and_reraise_exception():
2192                 # deallocate ip and fail without proceeding to
2193                 # volume api calls, preserving current behavior
2194                 if try_deallocate_networks:
2195                     self._try_deallocate_network(context, instance,
2196                                                  requested_networks)
2197 
2198         if try_deallocate_networks:
2199             self._try_deallocate_network(context, instance, requested_networks)
2200 
2201         timer.restart()
2202         for bdm in vol_bdms:
2203             try:
2204                 # NOTE(vish): actual driver detach done in driver.destroy, so
2205                 #             just tell cinder that we are done with it.
2206                 connector = self.driver.get_volume_connector(instance)
2207                 self.volume_api.terminate_connection(context,
2208                                                      bdm.volume_id,
2209                                                      connector)
2210                 self.volume_api.detach(context, bdm.volume_id, instance.uuid)
2211             except exception.DiskNotFound as exc:
2212                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2213                           instance=instance)
2214             except exception.VolumeNotFound as exc:
2215                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2216                           instance=instance)
2217             except (cinder_exception.EndpointNotFound,
2218                     keystone_exception.EndpointNotFound) as exc:
2219                 LOG.warning(_LW('Ignoring EndpointNotFound for '
2220                                 'volume %(volume_id)s: %(exc)s'),
2221                             {'exc': exc, 'volume_id': bdm.volume_id},
2222                             instance=instance)
2223             except cinder_exception.ClientException as exc:
2224                 LOG.warning(_LW('Ignoring unknown cinder exception for '
2225                                 'volume %(volume_id)s: %(exc)s'),
2226                             {'exc': exc, 'volume_id': bdm.volume_id},
2227                             instance=instance)
2228             except Exception as exc:
2229                 LOG.warning(_LW('Ignoring unknown exception for '
2230                                 'volume %(volume_id)s: %(exc)s'),
2231                             {'exc': exc, 'volume_id': bdm.volume_id},
2232                             instance=instance)
2233         if vol_bdms:
2234             LOG.info(_LI('Took %(time).2f seconds to detach %(num)s volumes '
2235                          'for instance.'),
2236                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2237                      instance=instance)
2238 
2239         if notify:
2240             self._notify_about_instance_usage(context, instance,
2241                                               "shutdown.end")
2242 
2243     def _cleanup_volumes(self, context, instance_uuid, bdms, raise_exc=True):
2244         exc_info = None
2245 
2246         for bdm in bdms:
2247             LOG.debug("terminating bdm %s", bdm,
2248                       instance_uuid=instance_uuid)
2249             if bdm.volume_id and bdm.delete_on_termination:
2250                 try:
2251                     self.volume_api.delete(context, bdm.volume_id)
2252                 except Exception as exc:
2253                     exc_info = sys.exc_info()
2254                     LOG.warning(_LW('Failed to delete volume: %(volume_id)s '
2255                                     'due to %(exc)s'),
2256                                 {'volume_id': bdm.volume_id, 'exc': exc})
2257         if exc_info is not None and raise_exc:
2258             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2259 
2260     @hooks.add_hook("delete_instance")
2261     def _delete_instance(self, context, instance, bdms, quotas):
2262         """Delete an instance on this host.  Commit or rollback quotas
2263         as necessary.
2264 
2265         :param context: nova request context
2266         :param instance: nova.objects.instance.Instance object
2267         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2268         :param quotas: nova.objects.quotas.Quotas object
2269         """
2270         was_soft_deleted = instance.vm_state == vm_states.SOFT_DELETED
2271         if was_soft_deleted:
2272             # Instances in SOFT_DELETED vm_state have already had quotas
2273             # decremented.
2274             try:
2275                 quotas.rollback()
2276             except Exception:
2277                 pass
2278 
2279         try:
2280             events = self.instance_events.clear_events_for_instance(instance)
2281             if events:
2282                 LOG.debug('Events pending at deletion: %(events)s',
2283                           {'events': ','.join(events.keys())},
2284                           instance=instance)
2285             self._notify_about_instance_usage(context, instance,
2286                                               "delete.start")
2287             compute_utils.notify_about_instance_action(context, instance,
2288                     self.host, action=fields.NotificationAction.DELETE,
2289                     phase=fields.NotificationPhase.START)
2290 
2291             self._shutdown_instance(context, instance, bdms)
2292             # NOTE(dims): instance.info_cache.delete() should be called after
2293             # _shutdown_instance in the compute manager as shutdown calls
2294             # deallocate_for_instance so the info_cache is still needed
2295             # at this point.
2296             if instance.info_cache is not None:
2297                 instance.info_cache.delete()
2298             else:
2299                 # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2300                 # is None. When the root cause that instance.info_cache becomes
2301                 # None is fixed, the log level should be reconsidered.
2302                 LOG.warning(_LW("Info cache for instance could not be found. "
2303                                 "Ignore."), instance=instance)
2304 
2305             # NOTE(vish): We have already deleted the instance, so we have
2306             #             to ignore problems cleaning up the volumes. It
2307             #             would be nice to let the user know somehow that
2308             #             the volume deletion failed, but it is not
2309             #             acceptable to have an instance that can not be
2310             #             deleted. Perhaps this could be reworked in the
2311             #             future to set an instance fault the first time
2312             #             and to only ignore the failure if the instance
2313             #             is already in ERROR.
2314             self._cleanup_volumes(context, instance.uuid, bdms,
2315                     raise_exc=False)
2316             # if a delete task succeeded, always update vm state and task
2317             # state without expecting task state to be DELETING
2318             instance.vm_state = vm_states.DELETED
2319             instance.task_state = None
2320             instance.power_state = power_state.NOSTATE
2321             instance.terminated_at = timeutils.utcnow()
2322             instance.save()
2323             system_meta = instance.system_metadata
2324             instance.destroy()
2325         except Exception:
2326             with excutils.save_and_reraise_exception():
2327                 quotas.rollback()
2328 
2329         self._complete_deletion(context,
2330                                 instance,
2331                                 bdms,
2332                                 quotas,
2333                                 system_meta)
2334 
2335     @wrap_exception()
2336     @reverts_task_state
2337     @wrap_instance_event(prefix='compute')
2338     @wrap_instance_fault
2339     def terminate_instance(self, context, instance, bdms, reservations):
2340         """Terminate an instance on this host."""
2341         quotas = objects.Quotas.from_reservations(context,
2342                                                   reservations,
2343                                                   instance=instance)
2344 
2345         @utils.synchronized(instance.uuid)
2346         def do_terminate_instance(instance, bdms):
2347             # NOTE(mriedem): If we are deleting the instance while it was
2348             # booting from volume, we could be racing with a database update of
2349             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2350             # to compute here, the BDMs may be stale at this point. So check
2351             # for any volume BDMs that don't have volume_id set and if we
2352             # detect that, we need to refresh the BDM list before proceeding.
2353             # TODO(mriedem): Move this into _delete_instance and make the bdms
2354             # parameter optional.
2355             for bdm in list(bdms):
2356                 if bdm.is_volume and not bdm.volume_id:
2357                     LOG.debug('There are potentially stale BDMs during '
2358                               'delete, refreshing the BlockDeviceMappingList.',
2359                               instance=instance)
2360                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2361                         context, instance.uuid)
2362                     break
2363             try:
2364                 self._delete_instance(context, instance, bdms, quotas)
2365             except exception.InstanceNotFound:
2366                 LOG.info(_LI("Instance disappeared during terminate"),
2367                          instance=instance)
2368             except Exception:
2369                 # As we're trying to delete always go to Error if something
2370                 # goes wrong that _delete_instance can't handle.
2371                 with excutils.save_and_reraise_exception():
2372                     LOG.exception(_LE('Setting instance vm_state to ERROR'),
2373                                   instance=instance)
2374                     self._set_instance_obj_error_state(context, instance)
2375 
2376         do_terminate_instance(instance, bdms)
2377 
2378     # NOTE(johannes): This is probably better named power_off_instance
2379     # so it matches the driver method, but because of other issues, we
2380     # can't use that name in grizzly.
2381     @wrap_exception()
2382     @reverts_task_state
2383     @wrap_instance_event(prefix='compute')
2384     @wrap_instance_fault
2385     def stop_instance(self, context, instance, clean_shutdown):
2386         """Stopping an instance on this host."""
2387 
2388         @utils.synchronized(instance.uuid)
2389         def do_stop_instance():
2390             current_power_state = self._get_power_state(context, instance)
2391             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2392                       'current task_state: %(task_state)s, current DB '
2393                       'power_state: %(db_power_state)s, current VM '
2394                       'power_state: %(current_power_state)s',
2395                       {'vm_state': instance.vm_state,
2396                        'task_state': instance.task_state,
2397                        'db_power_state': instance.power_state,
2398                        'current_power_state': current_power_state},
2399                       instance_uuid=instance.uuid)
2400 
2401             # NOTE(mriedem): If the instance is already powered off, we are
2402             # possibly tearing down and racing with other operations, so we can
2403             # expect the task_state to be None if something else updates the
2404             # instance and we're not locking it.
2405             expected_task_state = [task_states.POWERING_OFF]
2406             # The list of power states is from _sync_instance_power_state.
2407             if current_power_state in (power_state.NOSTATE,
2408                                        power_state.SHUTDOWN,
2409                                        power_state.CRASHED):
2410                 LOG.info(_LI('Instance is already powered off in the '
2411                              'hypervisor when stop is called.'),
2412                          instance=instance)
2413                 expected_task_state.append(None)
2414 
2415             self._notify_about_instance_usage(context, instance,
2416                                               "power_off.start")
2417             self._power_off_instance(context, instance, clean_shutdown)
2418             instance.power_state = self._get_power_state(context, instance)
2419             instance.vm_state = vm_states.STOPPED
2420             instance.task_state = None
2421             instance.save(expected_task_state=expected_task_state)
2422             self._notify_about_instance_usage(context, instance,
2423                                               "power_off.end")
2424 
2425         do_stop_instance()
2426 
2427     def _power_on(self, context, instance):
2428         network_info = self.network_api.get_instance_nw_info(context, instance)
2429         block_device_info = self._get_instance_block_device_info(context,
2430                                                                  instance)
2431         self.driver.power_on(context, instance,
2432                              network_info,
2433                              block_device_info)
2434 
2435     def _delete_snapshot_of_shelved_instance(self, context, instance,
2436                                              snapshot_id):
2437         """Delete snapshot of shelved instance."""
2438         try:
2439             self.image_api.delete(context, snapshot_id)
2440         except (exception.ImageNotFound,
2441                 exception.ImageNotAuthorized) as exc:
2442             LOG.warning(_LW("Failed to delete snapshot "
2443                             "from shelved instance (%s)."),
2444                         exc.format_message(), instance=instance)
2445         except Exception:
2446             LOG.exception(_LE("Something wrong happened when trying to "
2447                               "delete snapshot from shelved instance."),
2448                           instance=instance)
2449 
2450     # NOTE(johannes): This is probably better named power_on_instance
2451     # so it matches the driver method, but because of other issues, we
2452     # can't use that name in grizzly.
2453     @wrap_exception()
2454     @reverts_task_state
2455     @wrap_instance_event(prefix='compute')
2456     @wrap_instance_fault
2457     def start_instance(self, context, instance):
2458         """Starting an instance on this host."""
2459         self._notify_about_instance_usage(context, instance, "power_on.start")
2460         compute_utils.notify_about_instance_action(context, instance,
2461             self.host, action=fields.NotificationAction.POWER_ON,
2462             phase=fields.NotificationPhase.START)
2463         self._power_on(context, instance)
2464         instance.power_state = self._get_power_state(context, instance)
2465         instance.vm_state = vm_states.ACTIVE
2466         instance.task_state = None
2467 
2468         # Delete an image(VM snapshot) for a shelved instance
2469         snapshot_id = instance.system_metadata.get('shelved_image_id')
2470         if snapshot_id:
2471             self._delete_snapshot_of_shelved_instance(context, instance,
2472                                                       snapshot_id)
2473 
2474         # Delete system_metadata for a shelved instance
2475         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2476 
2477         instance.save(expected_task_state=task_states.POWERING_ON)
2478         self._notify_about_instance_usage(context, instance, "power_on.end")
2479         compute_utils.notify_about_instance_action(context, instance,
2480             self.host, action=fields.NotificationAction.POWER_ON,
2481             phase=fields.NotificationPhase.END)
2482 
2483     @messaging.expected_exceptions(NotImplementedError,
2484                                    exception.TriggerCrashDumpNotSupported,
2485                                    exception.InstanceNotRunning)
2486     @wrap_exception()
2487     @wrap_instance_event(prefix='compute')
2488     @wrap_instance_fault
2489     def trigger_crash_dump(self, context, instance):
2490         """Trigger crash dump in an instance."""
2491 
2492         self._notify_about_instance_usage(context, instance,
2493                                           "trigger_crash_dump.start")
2494 
2495         # This method does not change task_state and power_state because the
2496         # effect of a trigger depends on user's configuration.
2497         self.driver.trigger_crash_dump(instance)
2498 
2499         self._notify_about_instance_usage(context, instance,
2500                                           "trigger_crash_dump.end")
2501 
2502     @wrap_exception()
2503     @reverts_task_state
2504     @wrap_instance_event(prefix='compute')
2505     @wrap_instance_fault
2506     def soft_delete_instance(self, context, instance, reservations):
2507         """Soft delete an instance on this host."""
2508 
2509         quotas = objects.Quotas.from_reservations(context,
2510                                                   reservations,
2511                                                   instance=instance)
2512         try:
2513             self._notify_about_instance_usage(context, instance,
2514                                               "soft_delete.start")
2515             try:
2516                 self.driver.soft_delete(instance)
2517             except NotImplementedError:
2518                 # Fallback to just powering off the instance if the
2519                 # hypervisor doesn't implement the soft_delete method
2520                 self.driver.power_off(instance)
2521             instance.power_state = self._get_power_state(context, instance)
2522             instance.vm_state = vm_states.SOFT_DELETED
2523             instance.task_state = None
2524             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2525         except Exception:
2526             with excutils.save_and_reraise_exception():
2527                 quotas.rollback()
2528         quotas.commit()
2529         self._notify_about_instance_usage(context, instance, "soft_delete.end")
2530 
2531     @wrap_exception()
2532     @reverts_task_state
2533     @wrap_instance_event(prefix='compute')
2534     @wrap_instance_fault
2535     def restore_instance(self, context, instance):
2536         """Restore a soft-deleted instance on this host."""
2537         self._notify_about_instance_usage(context, instance, "restore.start")
2538         compute_utils.notify_about_instance_action(context, instance,
2539             self.host, action=fields.NotificationAction.RESTORE,
2540             phase=fields.NotificationPhase.START)
2541         try:
2542             self.driver.restore(instance)
2543         except NotImplementedError:
2544             # Fallback to just powering on the instance if the hypervisor
2545             # doesn't implement the restore method
2546             self._power_on(context, instance)
2547         instance.power_state = self._get_power_state(context, instance)
2548         instance.vm_state = vm_states.ACTIVE
2549         instance.task_state = None
2550         instance.save(expected_task_state=task_states.RESTORING)
2551         self._notify_about_instance_usage(context, instance, "restore.end")
2552         compute_utils.notify_about_instance_action(context, instance,
2553             self.host, action=fields.NotificationAction.RESTORE,
2554             phase=fields.NotificationPhase.END)
2555 
2556     @staticmethod
2557     def _set_migration_status(migration, status):
2558         """Set the status, and guard against a None being passed in.
2559 
2560         This is useful as some of the compute RPC calls will not pass
2561         a migration object in older versions. The check can be removed when
2562         we move past 4.x major version of the RPC API.
2563         """
2564         if migration:
2565             migration.status = status
2566             migration.save()
2567 
2568     def _rebuild_default_impl(self, context, instance, image_meta,
2569                               injected_files, admin_password, bdms,
2570                               detach_block_devices, attach_block_devices,
2571                               network_info=None,
2572                               recreate=False, block_device_info=None,
2573                               preserve_ephemeral=False):
2574         if preserve_ephemeral:
2575             # The default code path does not support preserving ephemeral
2576             # partitions.
2577             raise exception.PreserveEphemeralNotSupported()
2578 
2579         if recreate:
2580             detach_block_devices(context, bdms)
2581         else:
2582             self._power_off_instance(context, instance, clean_shutdown=True)
2583             detach_block_devices(context, bdms)
2584             self.driver.destroy(context, instance,
2585                                 network_info=network_info,
2586                                 block_device_info=block_device_info)
2587 
2588         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2589         instance.save(expected_task_state=[task_states.REBUILDING])
2590 
2591         new_block_device_info = attach_block_devices(context, instance, bdms)
2592 
2593         instance.task_state = task_states.REBUILD_SPAWNING
2594         instance.save(
2595             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2596 
2597         with instance.mutated_migration_context():
2598             self.driver.spawn(context, instance, image_meta, injected_files,
2599                               admin_password, network_info=network_info,
2600                               block_device_info=new_block_device_info)
2601 
2602     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2603     @wrap_exception()
2604     @reverts_task_state
2605     @wrap_instance_event(prefix='compute')
2606     @wrap_instance_fault
2607     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2608                          injected_files, new_pass, orig_sys_metadata,
2609                          bdms, recreate, on_shared_storage=None,
2610                          preserve_ephemeral=False, migration=None,
2611                          scheduled_node=None, limits=None):
2612         """Destroy and re-make this instance.
2613 
2614         A 'rebuild' effectively purges all existing data from the system and
2615         remakes the VM with given 'metadata' and 'personalities'.
2616 
2617         :param context: `nova.RequestContext` object
2618         :param instance: Instance object
2619         :param orig_image_ref: Original image_ref before rebuild
2620         :param image_ref: New image_ref for rebuild
2621         :param injected_files: Files to inject
2622         :param new_pass: password to set on rebuilt instance
2623         :param orig_sys_metadata: instance system metadata from pre-rebuild
2624         :param bdms: block-device-mappings to use for rebuild
2625         :param recreate: True if the instance is being recreated (e.g. the
2626             hypervisor it was on failed) - cleanup of old state will be
2627             skipped.
2628         :param on_shared_storage: True if instance files on shared storage.
2629                                   If not provided then information from the
2630                                   driver will be used to decide if the instance
2631                                   files are available or not on the target host
2632         :param preserve_ephemeral: True if the default ephemeral storage
2633                                    partition must be preserved on rebuild
2634         :param migration: a Migration object if one was created for this
2635                           rebuild operation (if it's a part of evacuate)
2636         :param scheduled_node: A node of the host chosen by the scheduler. If a
2637                                host was specified by the user, this will be
2638                                None
2639         :param limits: Overcommit limits set by the scheduler. If a host was
2640                        specified by the user, this will be None
2641         """
2642         context = context.elevated()
2643 
2644         LOG.info(_LI("Rebuilding instance"), context=context,
2645                     instance=instance)
2646         if scheduled_node is not None:
2647             rt = self._get_resource_tracker(scheduled_node)
2648             rebuild_claim = rt.rebuild_claim
2649         else:
2650             rebuild_claim = claims.NopClaim
2651 
2652         image_meta = {}
2653         if image_ref:
2654             image_meta = self.image_api.get(context, image_ref)
2655 
2656         # NOTE(mriedem): On a recreate (evacuate), we need to update
2657         # the instance's host and node properties to reflect it's
2658         # destination node for the recreate.
2659         if not scheduled_node:
2660             try:
2661                 compute_node = self._get_compute_info(context, self.host)
2662                 scheduled_node = compute_node.hypervisor_hostname
2663             except exception.ComputeHostNotFound:
2664                 LOG.exception(_LE('Failed to get compute_info for %s'),
2665                                 self.host)
2666 
2667         with self._error_out_instance_on_exception(context, instance):
2668             try:
2669                 claim_ctxt = rebuild_claim(
2670                     context, instance, limits=limits, image_meta=image_meta,
2671                     migration=migration)
2672                 self._do_rebuild_instance_with_claim(
2673                     claim_ctxt, context, instance, orig_image_ref,
2674                     image_ref, injected_files, new_pass, orig_sys_metadata,
2675                     bdms, recreate, on_shared_storage, preserve_ephemeral)
2676             except exception.ComputeResourcesUnavailable as e:
2677                 LOG.debug("Could not rebuild instance on this host, not "
2678                           "enough resources available.", instance=instance)
2679 
2680                 # NOTE(ndipanov): We just abort the build for now and leave a
2681                 # migration record for potential cleanup later
2682                 self._set_migration_status(migration, 'failed')
2683 
2684                 self._notify_about_instance_usage(context, instance,
2685                         'rebuild.error', fault=e)
2686                 raise exception.BuildAbortException(
2687                     instance_uuid=instance.uuid, reason=e.format_message())
2688             except (exception.InstanceNotFound,
2689                     exception.UnexpectedDeletingTaskStateError) as e:
2690                 LOG.debug('Instance was deleted while rebuilding',
2691                           instance=instance)
2692                 self._set_migration_status(migration, 'failed')
2693                 self._notify_about_instance_usage(context, instance,
2694                         'rebuild.error', fault=e)
2695             except Exception as e:
2696                 self._set_migration_status(migration, 'failed')
2697                 self._notify_about_instance_usage(context, instance,
2698                         'rebuild.error', fault=e)
2699                 raise
2700             else:
2701                 instance.apply_migration_context()
2702                 # NOTE (ndipanov): This save will now update the host and node
2703                 # attributes making sure that next RT pass is consistent since
2704                 # it will be based on the instance and not the migration DB
2705                 # entry.
2706                 instance.host = self.host
2707                 instance.node = scheduled_node
2708                 instance.save()
2709                 instance.drop_migration_context()
2710 
2711                 # NOTE (ndipanov): Mark the migration as done only after we
2712                 # mark the instance as belonging to this host.
2713                 self._set_migration_status(migration, 'done')
2714 
2715     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2716         """Helper to avoid deep nesting in the top-level method."""
2717 
2718         with claim_context:
2719             self._do_rebuild_instance(*args, **kwargs)
2720 
2721     @staticmethod
2722     def _get_image_name(image_meta):
2723         if image_meta.obj_attr_is_set("name"):
2724             return image_meta.name
2725         else:
2726             return ''
2727 
2728     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2729                              image_ref, injected_files, new_pass,
2730                              orig_sys_metadata, bdms, recreate,
2731                              on_shared_storage, preserve_ephemeral):
2732         orig_vm_state = instance.vm_state
2733 
2734         if recreate:
2735             if not self.driver.capabilities["supports_recreate"]:
2736                 raise exception.InstanceRecreateNotSupported
2737 
2738             self._check_instance_exists(context, instance)
2739 
2740             if on_shared_storage is None:
2741                 LOG.debug('on_shared_storage is not provided, using driver'
2742                             'information to decide if the instance needs to'
2743                             'be recreated')
2744                 on_shared_storage = self.driver.instance_on_disk(instance)
2745 
2746             elif (on_shared_storage !=
2747                     self.driver.instance_on_disk(instance)):
2748                 # To cover case when admin expects that instance files are
2749                 # on shared storage, but not accessible and vice versa
2750                 raise exception.InvalidSharedStorage(
2751                         _("Invalid state of instance files on shared"
2752                             " storage"))
2753 
2754             if on_shared_storage:
2755                 LOG.info(_LI('disk on shared storage, recreating using'
2756                                 ' existing disk'))
2757             else:
2758                 image_ref = orig_image_ref = instance.image_ref
2759                 LOG.info(_LI("disk not on shared storage, rebuilding from:"
2760                                 " '%s'"), str(image_ref))
2761 
2762         if image_ref:
2763             image_meta = objects.ImageMeta.from_image_ref(
2764                 context, self.image_api, image_ref)
2765         else:
2766             image_meta = instance.image_meta
2767 
2768         # This instance.exists message should contain the original
2769         # image_ref, not the new one.  Since the DB has been updated
2770         # to point to the new one... we have to override it.
2771         # TODO(jaypipes): Move generate_image_url() into the nova.image.api
2772         orig_image_ref_url = glance.generate_image_url(orig_image_ref)
2773         extra_usage_info = {'image_ref_url': orig_image_ref_url}
2774         compute_utils.notify_usage_exists(
2775                 self.notifier, context, instance,
2776                 current_period=True, system_metadata=orig_sys_metadata,
2777                 extra_usage_info=extra_usage_info)
2778 
2779         # This message should contain the new image_ref
2780         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
2781         self._notify_about_instance_usage(context, instance,
2782                 "rebuild.start", extra_usage_info=extra_usage_info)
2783 
2784         instance.power_state = self._get_power_state(context, instance)
2785         instance.task_state = task_states.REBUILDING
2786         instance.save(expected_task_state=[task_states.REBUILDING])
2787 
2788         if recreate:
2789             # Needed for nova-network, does nothing for neutron
2790             self.network_api.setup_networks_on_host(
2791                     context, instance, self.host)
2792             # For nova-network this is needed to move floating IPs
2793             # For neutron this updates the host in the port binding
2794             # TODO(cfriesen): this network_api call and the one above
2795             # are so similar, we should really try to unify them.
2796             self.network_api.setup_instance_network_on_host(
2797                     context, instance, self.host)
2798 
2799         network_info = compute_utils.get_nw_info_for_instance(instance)
2800         if bdms is None:
2801             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2802                     context, instance.uuid)
2803 
2804         block_device_info = \
2805             self._get_instance_block_device_info(
2806                     context, instance, bdms=bdms)
2807 
2808         def detach_block_devices(context, bdms):
2809             for bdm in bdms:
2810                 if bdm.is_volume:
2811                     self._detach_volume(context, bdm.volume_id, instance,
2812                                         destroy_bdm=False)
2813 
2814         files = self._decode_files(injected_files)
2815 
2816         kwargs = dict(
2817             context=context,
2818             instance=instance,
2819             image_meta=image_meta,
2820             injected_files=files,
2821             admin_password=new_pass,
2822             bdms=bdms,
2823             detach_block_devices=detach_block_devices,
2824             attach_block_devices=self._prep_block_device,
2825             block_device_info=block_device_info,
2826             network_info=network_info,
2827             preserve_ephemeral=preserve_ephemeral,
2828             recreate=recreate)
2829         try:
2830             with instance.mutated_migration_context():
2831                 self.driver.rebuild(**kwargs)
2832         except NotImplementedError:
2833             # NOTE(rpodolyaka): driver doesn't provide specialized version
2834             # of rebuild, fall back to the default implementation
2835             self._rebuild_default_impl(**kwargs)
2836         self._update_instance_after_spawn(context, instance)
2837         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
2838 
2839         if orig_vm_state == vm_states.STOPPED:
2840             LOG.info(_LI("bringing vm to original state: '%s'"),
2841                         orig_vm_state, instance=instance)
2842             instance.vm_state = vm_states.ACTIVE
2843             instance.task_state = task_states.POWERING_OFF
2844             instance.progress = 0
2845             instance.save()
2846             self.stop_instance(context, instance, False)
2847         self._update_scheduler_instance_info(context, instance)
2848         self._notify_about_instance_usage(
2849                 context, instance, "rebuild.end",
2850                 network_info=network_info,
2851                 extra_usage_info=extra_usage_info)
2852 
2853     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
2854                                      block_device_info):
2855         """Handle cases where the virt-layer had to detach non-working volumes
2856         in order to complete an operation.
2857         """
2858         for bdm in block_device_info['block_device_mapping']:
2859             if bdm.get('mount_device') in bad_devices:
2860                 try:
2861                     volume_id = bdm['connection_info']['data']['volume_id']
2862                 except KeyError:
2863                     continue
2864 
2865                 # NOTE(sirp): ideally we'd just call
2866                 # `compute_api.detach_volume` here but since that hits the
2867                 # DB directly, that's off limits from within the
2868                 # compute-manager.
2869                 #
2870                 # API-detach
2871                 LOG.info(_LI("Detaching from volume api: %s"), volume_id)
2872                 volume = self.volume_api.get(context, volume_id)
2873                 self.volume_api.check_detach(context, volume)
2874                 self.volume_api.begin_detaching(context, volume_id)
2875 
2876                 # Manager-detach
2877                 self.detach_volume(context, volume_id, instance)
2878 
2879     @wrap_exception()
2880     @reverts_task_state
2881     @wrap_instance_event(prefix='compute')
2882     @wrap_instance_fault
2883     def reboot_instance(self, context, instance, block_device_info,
2884                         reboot_type):
2885         """Reboot an instance on this host."""
2886         # acknowledge the request made it to the manager
2887         if reboot_type == "SOFT":
2888             instance.task_state = task_states.REBOOT_PENDING
2889             expected_states = (task_states.REBOOTING,
2890                                task_states.REBOOT_PENDING,
2891                                task_states.REBOOT_STARTED)
2892         else:
2893             instance.task_state = task_states.REBOOT_PENDING_HARD
2894             expected_states = (task_states.REBOOTING_HARD,
2895                                task_states.REBOOT_PENDING_HARD,
2896                                task_states.REBOOT_STARTED_HARD)
2897         context = context.elevated()
2898         LOG.info(_LI("Rebooting instance"), context=context, instance=instance)
2899 
2900         block_device_info = self._get_instance_block_device_info(context,
2901                                                                  instance)
2902 
2903         network_info = self.network_api.get_instance_nw_info(context, instance)
2904 
2905         self._notify_about_instance_usage(context, instance, "reboot.start")
2906 
2907         instance.power_state = self._get_power_state(context, instance)
2908         instance.save(expected_task_state=expected_states)
2909 
2910         if instance.power_state != power_state.RUNNING:
2911             state = instance.power_state
2912             running = power_state.RUNNING
2913             LOG.warning(_LW('trying to reboot a non-running instance:'
2914                             ' (state: %(state)s expected: %(running)s)'),
2915                         {'state': state, 'running': running},
2916                         context=context, instance=instance)
2917 
2918         def bad_volumes_callback(bad_devices):
2919             self._handle_bad_volumes_detached(
2920                     context, instance, bad_devices, block_device_info)
2921 
2922         try:
2923             # Don't change it out of rescue mode
2924             if instance.vm_state == vm_states.RESCUED:
2925                 new_vm_state = vm_states.RESCUED
2926             else:
2927                 new_vm_state = vm_states.ACTIVE
2928             new_power_state = None
2929             if reboot_type == "SOFT":
2930                 instance.task_state = task_states.REBOOT_STARTED
2931                 expected_state = task_states.REBOOT_PENDING
2932             else:
2933                 instance.task_state = task_states.REBOOT_STARTED_HARD
2934                 expected_state = task_states.REBOOT_PENDING_HARD
2935             instance.save(expected_task_state=expected_state)
2936             self.driver.reboot(context, instance,
2937                                network_info,
2938                                reboot_type,
2939                                block_device_info=block_device_info,
2940                                bad_volumes_callback=bad_volumes_callback)
2941 
2942         except Exception as error:
2943             with excutils.save_and_reraise_exception() as ctxt:
2944                 exc_info = sys.exc_info()
2945                 # if the reboot failed but the VM is running don't
2946                 # put it into an error state
2947                 new_power_state = self._get_power_state(context, instance)
2948                 if new_power_state == power_state.RUNNING:
2949                     LOG.warning(_LW('Reboot failed but instance is running'),
2950                                 context=context, instance=instance)
2951                     compute_utils.add_instance_fault_from_exc(context,
2952                             instance, error, exc_info)
2953                     self._notify_about_instance_usage(context, instance,
2954                             'reboot.error', fault=error)
2955                     ctxt.reraise = False
2956                 else:
2957                     LOG.error(_LE('Cannot reboot instance: %s'), error,
2958                               context=context, instance=instance)
2959                     self._set_instance_obj_error_state(context, instance)
2960 
2961         if not new_power_state:
2962             new_power_state = self._get_power_state(context, instance)
2963         try:
2964             instance.power_state = new_power_state
2965             instance.vm_state = new_vm_state
2966             instance.task_state = None
2967             instance.save()
2968         except exception.InstanceNotFound:
2969             LOG.warning(_LW("Instance disappeared during reboot"),
2970                         context=context, instance=instance)
2971 
2972         self._notify_about_instance_usage(context, instance, "reboot.end")
2973 
2974     @delete_image_on_error
2975     def _do_snapshot_instance(self, context, image_id, instance):
2976         self._snapshot_instance(context, image_id, instance,
2977                                 task_states.IMAGE_BACKUP)
2978 
2979     @wrap_exception()
2980     @reverts_task_state
2981     @wrap_instance_fault
2982     def backup_instance(self, context, image_id, instance, backup_type,
2983                         rotation):
2984         """Backup an instance on this host.
2985 
2986         :param backup_type: daily | weekly
2987         :param rotation: int representing how many backups to keep around
2988         """
2989         self._do_snapshot_instance(context, image_id, instance)
2990         self._rotate_backups(context, instance, backup_type, rotation)
2991 
2992     @wrap_exception()
2993     @reverts_task_state
2994     @wrap_instance_fault
2995     @delete_image_on_error
2996     def snapshot_instance(self, context, image_id, instance):
2997         """Snapshot an instance on this host.
2998 
2999         :param context: security context
3000         :param instance: a nova.objects.instance.Instance object
3001         :param image_id: glance.db.sqlalchemy.models.Image.Id
3002         """
3003         # NOTE(dave-mcnally) the task state will already be set by the api
3004         # but if the compute manager has crashed/been restarted prior to the
3005         # request getting here the task state may have been cleared so we set
3006         # it again and things continue normally
3007         try:
3008             instance.task_state = task_states.IMAGE_SNAPSHOT
3009             instance.save(
3010                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3011         except exception.InstanceNotFound:
3012             # possibility instance no longer exists, no point in continuing
3013             LOG.debug("Instance not found, could not set state %s "
3014                       "for instance.",
3015                       task_states.IMAGE_SNAPSHOT, instance=instance)
3016             return
3017 
3018         except exception.UnexpectedDeletingTaskStateError:
3019             LOG.debug("Instance being deleted, snapshot cannot continue",
3020                       instance=instance)
3021             return
3022 
3023         self._snapshot_instance(context, image_id, instance,
3024                                 task_states.IMAGE_SNAPSHOT)
3025 
3026     def _snapshot_instance(self, context, image_id, instance,
3027                            expected_task_state):
3028         context = context.elevated()
3029 
3030         instance.power_state = self._get_power_state(context, instance)
3031         try:
3032             instance.save()
3033 
3034             LOG.info(_LI('instance snapshotting'), context=context,
3035                   instance=instance)
3036 
3037             if instance.power_state != power_state.RUNNING:
3038                 state = instance.power_state
3039                 running = power_state.RUNNING
3040                 LOG.warning(_LW('trying to snapshot a non-running instance: '
3041                                 '(state: %(state)s expected: %(running)s)'),
3042                             {'state': state, 'running': running},
3043                             instance=instance)
3044 
3045             self._notify_about_instance_usage(
3046                 context, instance, "snapshot.start")
3047 
3048             def update_task_state(task_state,
3049                                   expected_state=expected_task_state):
3050                 instance.task_state = task_state
3051                 instance.save(expected_task_state=expected_state)
3052 
3053             self.driver.snapshot(context, instance, image_id,
3054                                  update_task_state)
3055 
3056             instance.task_state = None
3057             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3058 
3059             self._notify_about_instance_usage(context, instance,
3060                                               "snapshot.end")
3061         except (exception.InstanceNotFound,
3062                 exception.UnexpectedDeletingTaskStateError):
3063             # the instance got deleted during the snapshot
3064             # Quickly bail out of here
3065             msg = 'Instance disappeared during snapshot'
3066             LOG.debug(msg, instance=instance)
3067             try:
3068                 image_service = glance.get_default_image_service()
3069                 image = image_service.show(context, image_id)
3070                 if image['status'] != 'active':
3071                     image_service.delete(context, image_id)
3072             except Exception:
3073                 LOG.warning(_LW("Error while trying to clean up image %s"),
3074                             image_id, instance=instance)
3075         except exception.ImageNotFound:
3076             instance.task_state = None
3077             instance.save()
3078             msg = _LW("Image not found during snapshot")
3079             LOG.warning(msg, instance=instance)
3080 
3081     def _post_interrupted_snapshot_cleanup(self, context, instance):
3082         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3083 
3084     @messaging.expected_exceptions(NotImplementedError)
3085     @wrap_exception()
3086     def volume_snapshot_create(self, context, instance, volume_id,
3087                                create_info):
3088         self.driver.volume_snapshot_create(context, instance, volume_id,
3089                                            create_info)
3090 
3091     @messaging.expected_exceptions(NotImplementedError)
3092     @wrap_exception()
3093     def volume_snapshot_delete(self, context, instance, volume_id,
3094                                snapshot_id, delete_info):
3095         self.driver.volume_snapshot_delete(context, instance, volume_id,
3096                                            snapshot_id, delete_info)
3097 
3098     @wrap_instance_fault
3099     def _rotate_backups(self, context, instance, backup_type, rotation):
3100         """Delete excess backups associated to an instance.
3101 
3102         Instances are allowed a fixed number of backups (the rotation number);
3103         this method deletes the oldest backups that exceed the rotation
3104         threshold.
3105 
3106         :param context: security context
3107         :param instance: Instance dict
3108         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3109         :param rotation: int representing how many backups to keep around;
3110             None if rotation shouldn't be used (as in the case of snapshots)
3111         """
3112         filters = {'property-image_type': 'backup',
3113                    'property-backup_type': backup_type,
3114                    'property-instance_uuid': instance.uuid}
3115 
3116         images = self.image_api.get_all(context, filters=filters,
3117                                         sort_key='created_at', sort_dir='desc')
3118         num_images = len(images)
3119         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3120                   {'num_images': num_images, 'rotation': rotation},
3121                   instance=instance)
3122 
3123         if num_images > rotation:
3124             # NOTE(sirp): this deletes all backups that exceed the rotation
3125             # limit
3126             excess = len(images) - rotation
3127             LOG.debug("Rotating out %d backups", excess,
3128                       instance=instance)
3129             for i in range(excess):
3130                 image = images.pop()
3131                 image_id = image['id']
3132                 LOG.debug("Deleting image %s", image_id,
3133                           instance=instance)
3134                 self.image_api.delete(context, image_id)
3135 
3136     @wrap_exception()
3137     @reverts_task_state
3138     @wrap_instance_event(prefix='compute')
3139     @wrap_instance_fault
3140     def set_admin_password(self, context, instance, new_pass):
3141         """Set the root/admin password for an instance on this host.
3142 
3143         This is generally only called by API password resets after an
3144         image has been built.
3145 
3146         @param context: Nova auth context.
3147         @param instance: Nova instance object.
3148         @param new_pass: The admin password for the instance.
3149         """
3150 
3151         context = context.elevated()
3152         if new_pass is None:
3153             # Generate a random password
3154             new_pass = utils.generate_password()
3155 
3156         current_power_state = self._get_power_state(context, instance)
3157         expected_state = power_state.RUNNING
3158 
3159         if current_power_state != expected_state:
3160             instance.task_state = None
3161             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3162             _msg = _('instance %s is not running') % instance.uuid
3163             raise exception.InstancePasswordSetFailed(
3164                 instance=instance.uuid, reason=_msg)
3165 
3166         try:
3167             self.driver.set_admin_password(instance, new_pass)
3168             LOG.info(_LI("Root password set"), instance=instance)
3169             instance.task_state = None
3170             instance.save(
3171                 expected_task_state=task_states.UPDATING_PASSWORD)
3172         except exception.InstanceAgentNotEnabled:
3173             with excutils.save_and_reraise_exception():
3174                 LOG.debug('Guest agent is not enabled for the instance.',
3175                           instance=instance)
3176                 instance.task_state = None
3177                 instance.save(
3178                     expected_task_state=task_states.UPDATING_PASSWORD)
3179         except exception.SetAdminPasswdNotSupported:
3180             with excutils.save_and_reraise_exception():
3181                 LOG.info(_LI('set_admin_password is not supported '
3182                                 'by this driver or guest instance.'),
3183                             instance=instance)
3184                 instance.task_state = None
3185                 instance.save(
3186                     expected_task_state=task_states.UPDATING_PASSWORD)
3187         except NotImplementedError:
3188             LOG.warning(_LW('set_admin_password is not implemented '
3189                             'by this driver or guest instance.'),
3190                         instance=instance)
3191             instance.task_state = None
3192             instance.save(
3193                 expected_task_state=task_states.UPDATING_PASSWORD)
3194             raise NotImplementedError(_('set_admin_password is not '
3195                                         'implemented by this driver or guest '
3196                                         'instance.'))
3197         except exception.UnexpectedTaskStateError:
3198             # interrupted by another (most likely delete) task
3199             # do not retry
3200             raise
3201         except Exception:
3202             # Catch all here because this could be anything.
3203             LOG.exception(_LE('set_admin_password failed'),
3204                           instance=instance)
3205             self._set_instance_obj_error_state(context, instance)
3206             # We create a new exception here so that we won't
3207             # potentially reveal password information to the
3208             # API caller.  The real exception is logged above
3209             _msg = _('error setting admin password')
3210             raise exception.InstancePasswordSetFailed(
3211                 instance=instance.uuid, reason=_msg)
3212 
3213     @wrap_exception()
3214     @reverts_task_state
3215     @wrap_instance_fault
3216     def inject_file(self, context, path, file_contents, instance):
3217         """Write a file to the specified path in an instance on this host."""
3218         # NOTE(russellb) Remove this method, as well as the underlying virt
3219         # driver methods, when the compute rpc interface is bumped to 4.x
3220         # as it is no longer used.
3221         context = context.elevated()
3222         current_power_state = self._get_power_state(context, instance)
3223         expected_state = power_state.RUNNING
3224         if current_power_state != expected_state:
3225             LOG.warning(_LW('trying to inject a file into a non-running '
3226                             '(state: %(current_state)s expected: '
3227                             '%(expected_state)s)'),
3228                         {'current_state': current_power_state,
3229                          'expected_state': expected_state},
3230                         instance=instance)
3231         LOG.info(_LI('injecting file to %s'), path,
3232                     instance=instance)
3233         self.driver.inject_file(instance, path, file_contents)
3234 
3235     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3236         """Determine what image should be used to boot the rescue VM."""
3237         # 1. If rescue_image_ref is passed in, use that for rescue.
3238         # 2. Else, use the base image associated with instance's current image.
3239         #       The idea here is to provide the customer with a rescue
3240         #       environment which they are familiar with.
3241         #       So, if they built their instance off of a Debian image,
3242         #       their rescue VM will also be Debian.
3243         # 3. As a last resort, use instance's current image.
3244         if not rescue_image_ref:
3245             system_meta = utils.instance_sys_meta(instance)
3246             rescue_image_ref = system_meta.get('image_base_image_ref')
3247 
3248         if not rescue_image_ref:
3249             LOG.warning(_LW('Unable to find a different image to use for '
3250                             'rescue VM, using instance\'s current image'),
3251                         instance=instance)
3252             rescue_image_ref = instance.image_ref
3253 
3254         return objects.ImageMeta.from_image_ref(
3255             context, self.image_api, rescue_image_ref)
3256 
3257     @wrap_exception()
3258     @reverts_task_state
3259     @wrap_instance_event(prefix='compute')
3260     @wrap_instance_fault
3261     def rescue_instance(self, context, instance, rescue_password,
3262                         rescue_image_ref, clean_shutdown):
3263         context = context.elevated()
3264         LOG.info(_LI('Rescuing'), context=context, instance=instance)
3265 
3266         admin_password = (rescue_password if rescue_password else
3267                       utils.generate_password())
3268 
3269         network_info = self.network_api.get_instance_nw_info(context, instance)
3270 
3271         rescue_image_meta = self._get_rescue_image(context, instance,
3272                                                    rescue_image_ref)
3273 
3274         extra_usage_info = {'rescue_image_name':
3275                             self._get_image_name(rescue_image_meta)}
3276         self._notify_about_instance_usage(context, instance,
3277                 "rescue.start", extra_usage_info=extra_usage_info,
3278                 network_info=network_info)
3279 
3280         try:
3281             self._power_off_instance(context, instance, clean_shutdown)
3282 
3283             self.driver.rescue(context, instance,
3284                                network_info,
3285                                rescue_image_meta, admin_password)
3286         except Exception as e:
3287             LOG.exception(_LE("Error trying to Rescue Instance"),
3288                           instance=instance)
3289             self._set_instance_obj_error_state(context, instance)
3290             raise exception.InstanceNotRescuable(
3291                 instance_id=instance.uuid,
3292                 reason=_("Driver Error: %s") % e)
3293 
3294         compute_utils.notify_usage_exists(self.notifier, context, instance,
3295                                           current_period=True)
3296 
3297         instance.vm_state = vm_states.RESCUED
3298         instance.task_state = None
3299         instance.power_state = self._get_power_state(context, instance)
3300         instance.launched_at = timeutils.utcnow()
3301         instance.save(expected_task_state=task_states.RESCUING)
3302 
3303         self._notify_about_instance_usage(context, instance,
3304                 "rescue.end", extra_usage_info=extra_usage_info,
3305                 network_info=network_info)
3306 
3307     @wrap_exception()
3308     @reverts_task_state
3309     @wrap_instance_event(prefix='compute')
3310     @wrap_instance_fault
3311     def unrescue_instance(self, context, instance):
3312         context = context.elevated()
3313         LOG.info(_LI('Unrescuing'), context=context, instance=instance)
3314 
3315         network_info = self.network_api.get_instance_nw_info(context, instance)
3316         self._notify_about_instance_usage(context, instance,
3317                 "unrescue.start", network_info=network_info)
3318         with self._error_out_instance_on_exception(context, instance):
3319             self.driver.unrescue(instance,
3320                                  network_info)
3321 
3322         instance.vm_state = vm_states.ACTIVE
3323         instance.task_state = None
3324         instance.power_state = self._get_power_state(context, instance)
3325         instance.save(expected_task_state=task_states.UNRESCUING)
3326 
3327         self._notify_about_instance_usage(context,
3328                                           instance,
3329                                           "unrescue.end",
3330                                           network_info=network_info)
3331 
3332     @wrap_exception()
3333     @wrap_instance_fault
3334     def change_instance_metadata(self, context, diff, instance):
3335         """Update the metadata published to the instance."""
3336         LOG.debug("Changing instance metadata according to %r",
3337                   diff, instance=instance)
3338         self.driver.change_instance_metadata(context, instance, diff)
3339 
3340     @wrap_exception()
3341     @wrap_instance_event(prefix='compute')
3342     @wrap_instance_fault
3343     def confirm_resize(self, context, instance, reservations, migration):
3344 
3345         quotas = objects.Quotas.from_reservations(context,
3346                                                   reservations,
3347                                                   instance=instance)
3348 
3349         @utils.synchronized(instance.uuid)
3350         def do_confirm_resize(context, instance, migration_id):
3351             # NOTE(wangpan): Get the migration status from db, if it has been
3352             #                confirmed, we do nothing and return here
3353             LOG.debug("Going to confirm migration %s", migration_id,
3354                       context=context, instance=instance)
3355             try:
3356                 # TODO(russellb) Why are we sending the migration object just
3357                 # to turn around and look it up from the db again?
3358                 migration = objects.Migration.get_by_id(
3359                                     context.elevated(), migration_id)
3360             except exception.MigrationNotFound:
3361                 LOG.error(_LE("Migration %s is not found during confirmation"),
3362                           migration_id, context=context, instance=instance)
3363                 quotas.rollback()
3364                 return
3365 
3366             if migration.status == 'confirmed':
3367                 LOG.info(_LI("Migration %s is already confirmed"),
3368                          migration_id, context=context, instance=instance)
3369                 quotas.rollback()
3370                 return
3371             elif migration.status not in ('finished', 'confirming'):
3372                 LOG.warning(_LW("Unexpected confirmation status '%(status)s' "
3373                                 "of migration %(id)s, exit confirmation "
3374                                 "process"),
3375                             {"status": migration.status, "id": migration_id},
3376                             context=context, instance=instance)
3377                 quotas.rollback()
3378                 return
3379 
3380             # NOTE(wangpan): Get the instance from db, if it has been
3381             #                deleted, we do nothing and return here
3382             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3383             try:
3384                 instance = objects.Instance.get_by_uuid(
3385                         context, instance.uuid,
3386                         expected_attrs=expected_attrs)
3387             except exception.InstanceNotFound:
3388                 LOG.info(_LI("Instance is not found during confirmation"),
3389                          context=context, instance=instance)
3390                 quotas.rollback()
3391                 return
3392 
3393             self._confirm_resize(context, instance, quotas,
3394                                  migration=migration)
3395 
3396         do_confirm_resize(context, instance, migration.id)
3397 
3398     def _confirm_resize(self, context, instance, quotas,
3399                         migration=None):
3400         """Destroys the source instance."""
3401         self._notify_about_instance_usage(context, instance,
3402                                           "resize.confirm.start")
3403 
3404         with self._error_out_instance_on_exception(context, instance,
3405                                                    quotas=quotas):
3406             # NOTE(danms): delete stashed migration information
3407             old_instance_type = instance.old_flavor
3408             instance.old_flavor = None
3409             instance.new_flavor = None
3410             instance.system_metadata.pop('old_vm_state', None)
3411             instance.save()
3412 
3413             # NOTE(tr3buchet): tear down networks on source host
3414             self.network_api.setup_networks_on_host(context, instance,
3415                                migration.source_compute, teardown=True)
3416 
3417             network_info = self.network_api.get_instance_nw_info(context,
3418                                                                  instance)
3419             self.driver.confirm_migration(migration, instance,
3420                                           network_info)
3421 
3422             migration.status = 'confirmed'
3423             with migration.obj_as_admin():
3424                 migration.save()
3425 
3426             rt = self._get_resource_tracker(migration.source_node)
3427             rt.drop_move_claim(context, instance, old_instance_type,
3428                                prefix='old_')
3429 
3430             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3431             # might have manually powered up the instance to confirm the
3432             # resize/migrate, so we need to check the current power state
3433             # on the instance and set the vm_state appropriately. We default
3434             # to ACTIVE because if the power state is not SHUTDOWN, we
3435             # assume _sync_instance_power_state will clean it up.
3436             p_state = instance.power_state
3437             vm_state = None
3438             if p_state == power_state.SHUTDOWN:
3439                 vm_state = vm_states.STOPPED
3440                 LOG.debug("Resized/migrated instance is powered off. "
3441                           "Setting vm_state to '%s'.", vm_state,
3442                           instance=instance)
3443             else:
3444                 vm_state = vm_states.ACTIVE
3445 
3446             instance.vm_state = vm_state
3447             instance.task_state = None
3448             instance.save(expected_task_state=[None, task_states.DELETING])
3449 
3450             self._notify_about_instance_usage(
3451                 context, instance, "resize.confirm.end",
3452                 network_info=network_info)
3453 
3454             quotas.commit()
3455 
3456     @wrap_exception()
3457     @reverts_task_state
3458     @wrap_instance_event(prefix='compute')
3459     @errors_out_migration
3460     @wrap_instance_fault
3461     def revert_resize(self, context, instance, migration, reservations):
3462         """Destroys the new instance on the destination machine.
3463 
3464         Reverts the model changes, and powers on the old instance on the
3465         source machine.
3466 
3467         """
3468 
3469         quotas = objects.Quotas.from_reservations(context,
3470                                                   reservations,
3471                                                   instance=instance)
3472 
3473         # NOTE(comstud): A revert_resize is essentially a resize back to
3474         # the old size, so we need to send a usage event here.
3475         compute_utils.notify_usage_exists(self.notifier, context, instance,
3476                                           current_period=True)
3477 
3478         with self._error_out_instance_on_exception(context, instance,
3479                                                    quotas=quotas):
3480             # NOTE(tr3buchet): tear down networks on destination host
3481             self.network_api.setup_networks_on_host(context, instance,
3482                                                     teardown=True)
3483 
3484             migration_p = obj_base.obj_to_primitive(migration)
3485             self.network_api.migrate_instance_start(context,
3486                                                     instance,
3487                                                     migration_p)
3488 
3489             network_info = self.network_api.get_instance_nw_info(context,
3490                                                                  instance)
3491             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3492                     context, instance.uuid)
3493             block_device_info = self._get_instance_block_device_info(
3494                                 context, instance, bdms=bdms)
3495 
3496             destroy_disks = not self._is_instance_storage_shared(
3497                 context, instance, host=migration.source_compute)
3498             self.driver.destroy(context, instance, network_info,
3499                                 block_device_info, destroy_disks)
3500 
3501             self._terminate_volume_connections(context, instance, bdms)
3502 
3503             migration.status = 'reverted'
3504             with migration.obj_as_admin():
3505                 migration.save()
3506 
3507             # NOTE(ndipanov): We need to do this here because dropping the
3508             # claim means we lose the migration_context data. We really should
3509             # fix this by moving the drop_move_claim call to the
3510             # finish_revert_resize method as this is racy (revert is dropped,
3511             # but instance resources will be tracked with the new flavor until
3512             # it gets rolled back in finish_revert_resize, which is
3513             # potentially wrong for a period of time).
3514             instance.revert_migration_context()
3515             instance.save()
3516 
3517             rt = self._get_resource_tracker(instance.node)
3518             rt.drop_move_claim(context, instance)
3519 
3520             self.compute_rpcapi.finish_revert_resize(context, instance,
3521                     migration, migration.source_compute,
3522                     quotas.reservations)
3523 
3524     @wrap_exception()
3525     @reverts_task_state
3526     @wrap_instance_event(prefix='compute')
3527     @errors_out_migration
3528     @wrap_instance_fault
3529     def finish_revert_resize(self, context, instance, reservations, migration):
3530         """Finishes the second half of reverting a resize.
3531 
3532         Bring the original source instance state back (active/shutoff) and
3533         revert the resized attributes in the database.
3534 
3535         """
3536 
3537         quotas = objects.Quotas.from_reservations(context,
3538                                                   reservations,
3539                                                   instance=instance)
3540 
3541         with self._error_out_instance_on_exception(context, instance,
3542                                                    quotas=quotas):
3543             network_info = self.network_api.get_instance_nw_info(context,
3544                                                                  instance)
3545 
3546             self._notify_about_instance_usage(
3547                     context, instance, "resize.revert.start")
3548 
3549             # NOTE(mriedem): delete stashed old_vm_state information; we
3550             # default to ACTIVE for backwards compatibility if old_vm_state
3551             # is not set
3552             old_vm_state = instance.system_metadata.pop('old_vm_state',
3553                                                         vm_states.ACTIVE)
3554 
3555             self._set_instance_info(instance, instance.old_flavor)
3556             instance.old_flavor = None
3557             instance.new_flavor = None
3558             instance.host = migration.source_compute
3559             instance.node = migration.source_node
3560             instance.save()
3561 
3562             migration.dest_compute = migration.source_compute
3563             with migration.obj_as_admin():
3564                 migration.save()
3565 
3566             self.network_api.setup_networks_on_host(context, instance,
3567                                                     migration.source_compute)
3568 
3569             block_device_info = self._get_instance_block_device_info(
3570                     context, instance, refresh_conn_info=True)
3571 
3572             power_on = old_vm_state != vm_states.STOPPED
3573             self.driver.finish_revert_migration(context, instance,
3574                                        network_info,
3575                                        block_device_info, power_on)
3576 
3577             instance.launched_at = timeutils.utcnow()
3578             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
3579 
3580             migration_p = obj_base.obj_to_primitive(migration)
3581             self.network_api.migrate_instance_finish(context,
3582                                                      instance,
3583                                                      migration_p)
3584 
3585             # if the original vm state was STOPPED, set it back to STOPPED
3586             LOG.info(_LI("Updating instance to original state: '%s'"),
3587                      old_vm_state, instance=instance)
3588             if power_on:
3589                 instance.vm_state = vm_states.ACTIVE
3590                 instance.task_state = None
3591                 instance.save()
3592             else:
3593                 instance.task_state = task_states.POWERING_OFF
3594                 instance.save()
3595                 self.stop_instance(context, instance=instance,
3596                                    clean_shutdown=True)
3597 
3598             self._notify_about_instance_usage(
3599                     context, instance, "resize.revert.end")
3600             quotas.commit()
3601 
3602     def _prep_resize(self, context, image, instance, instance_type,
3603             quotas, request_spec, filter_properties, node,
3604             clean_shutdown=True):
3605 
3606         if not filter_properties:
3607             filter_properties = {}
3608 
3609         if not instance.host:
3610             self._set_instance_obj_error_state(context, instance)
3611             msg = _('Instance has no source host')
3612             raise exception.MigrationError(reason=msg)
3613 
3614         same_host = instance.host == self.host
3615         # if the flavor IDs match, it's migrate; otherwise resize
3616         if same_host and instance_type.id == instance['instance_type_id']:
3617             # check driver whether support migrate to same host
3618             if not self.driver.capabilities['supports_migrate_to_same_host']:
3619                 raise exception.UnableToMigrateToSelf(
3620                     instance_id=instance.uuid, host=self.host)
3621 
3622         # NOTE(danms): Stash the new instance_type to avoid having to
3623         # look it up in the database later
3624         instance.new_flavor = instance_type
3625         # NOTE(mriedem): Stash the old vm_state so we can set the
3626         # resized/reverted instance back to the same state later.
3627         vm_state = instance.vm_state
3628         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
3629         instance.system_metadata['old_vm_state'] = vm_state
3630         instance.save()
3631 
3632         limits = filter_properties.get('limits', {})
3633         rt = self._get_resource_tracker(node)
3634         with rt.resize_claim(context, instance, instance_type,
3635                              image_meta=image, limits=limits) as claim:
3636             LOG.info(_LI('Migrating'), context=context, instance=instance)
3637             self.compute_rpcapi.resize_instance(
3638                     context, instance, claim.migration, image,
3639                     instance_type, quotas.reservations,
3640                     clean_shutdown)
3641 
3642     @wrap_exception()
3643     @reverts_task_state
3644     @wrap_instance_event(prefix='compute')
3645     @wrap_instance_fault
3646     def prep_resize(self, context, image, instance, instance_type,
3647                     reservations, request_spec, filter_properties, node,
3648                     clean_shutdown):
3649         """Initiates the process of moving a running instance to another host.
3650 
3651         Possibly changes the RAM and disk size in the process.
3652 
3653         """
3654         if node is None:
3655             node = self.driver.get_available_nodes(refresh=True)[0]
3656             LOG.debug("No node specified, defaulting to %s", node,
3657                       instance=instance)
3658 
3659         # NOTE(melwitt): Remove this in version 5.0 of the RPC API
3660         # Code downstream may expect extra_specs to be populated since it
3661         # is receiving an object, so lookup the flavor to ensure this.
3662         if not isinstance(instance_type, objects.Flavor):
3663             instance_type = objects.Flavor.get_by_id(context,
3664                                                      instance_type['id'])
3665 
3666         quotas = objects.Quotas.from_reservations(context,
3667                                                   reservations,
3668                                                   instance=instance)
3669         with self._error_out_instance_on_exception(context, instance,
3670                                                    quotas=quotas):
3671             compute_utils.notify_usage_exists(self.notifier, context, instance,
3672                                               current_period=True)
3673             self._notify_about_instance_usage(
3674                     context, instance, "resize.prep.start")
3675             try:
3676                 self._prep_resize(context, image, instance,
3677                                   instance_type, quotas,
3678                                   request_spec, filter_properties,
3679                                   node, clean_shutdown)
3680             # NOTE(dgenin): This is thrown in LibvirtDriver when the
3681             #               instance to be migrated is backed by LVM.
3682             #               Remove when LVM migration is implemented.
3683             except exception.MigrationPreCheckError:
3684                 raise
3685             except Exception:
3686                 # try to re-schedule the resize elsewhere:
3687                 exc_info = sys.exc_info()
3688                 self._reschedule_resize_or_reraise(context, image, instance,
3689                         exc_info, instance_type, quotas, request_spec,
3690                         filter_properties)
3691             finally:
3692                 extra_usage_info = dict(
3693                         new_instance_type=instance_type.name,
3694                         new_instance_type_id=instance_type.id)
3695 
3696                 self._notify_about_instance_usage(
3697                     context, instance, "resize.prep.end",
3698                     extra_usage_info=extra_usage_info)
3699 
3700     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
3701             instance_type, quotas, request_spec, filter_properties):
3702         """Try to re-schedule the resize or re-raise the original error to
3703         error out the instance.
3704         """
3705         if not request_spec:
3706             request_spec = {}
3707         if not filter_properties:
3708             filter_properties = {}
3709 
3710         rescheduled = False
3711         instance_uuid = instance.uuid
3712 
3713         try:
3714             reschedule_method = self.compute_task_api.resize_instance
3715             scheduler_hint = dict(filter_properties=filter_properties)
3716             method_args = (instance, None, scheduler_hint, instance_type,
3717                            quotas.reservations)
3718             task_state = task_states.RESIZE_PREP
3719 
3720             rescheduled = self._reschedule(context, request_spec,
3721                     filter_properties, instance, reschedule_method,
3722                     method_args, task_state, exc_info)
3723         except Exception as error:
3724             rescheduled = False
3725             LOG.exception(_LE("Error trying to reschedule"),
3726                           instance_uuid=instance_uuid)
3727             compute_utils.add_instance_fault_from_exc(context,
3728                     instance, error,
3729                     exc_info=sys.exc_info())
3730             self._notify_about_instance_usage(context, instance,
3731                     'resize.error', fault=error)
3732 
3733         if rescheduled:
3734             self._log_original_error(exc_info, instance_uuid)
3735             compute_utils.add_instance_fault_from_exc(context,
3736                     instance, exc_info[1], exc_info=exc_info)
3737             self._notify_about_instance_usage(context, instance,
3738                     'resize.error', fault=exc_info[1])
3739         else:
3740             # not re-scheduling
3741             six.reraise(*exc_info)
3742 
3743     @wrap_exception()
3744     @reverts_task_state
3745     @wrap_instance_event(prefix='compute')
3746     @errors_out_migration
3747     @wrap_instance_fault
3748     def resize_instance(self, context, instance, image,
3749                         reservations, migration, instance_type,
3750                         clean_shutdown):
3751         """Starts the migration of a running instance to another host."""
3752 
3753         quotas = objects.Quotas.from_reservations(context,
3754                                                   reservations,
3755                                                   instance=instance)
3756         with self._error_out_instance_on_exception(context, instance,
3757                                                    quotas=quotas):
3758             # TODO(chaochin) Remove this until v5 RPC API
3759             # Code downstream may expect extra_specs to be populated since it
3760             # is receiving an object, so lookup the flavor to ensure this.
3761             if (not instance_type or
3762                 not isinstance(instance_type, objects.Flavor)):
3763                 instance_type = objects.Flavor.get_by_id(
3764                     context, migration['new_instance_type_id'])
3765 
3766             network_info = self.network_api.get_instance_nw_info(context,
3767                                                                  instance)
3768 
3769             migration.status = 'migrating'
3770             with migration.obj_as_admin():
3771                 migration.save()
3772 
3773             instance.task_state = task_states.RESIZE_MIGRATING
3774             instance.save(expected_task_state=task_states.RESIZE_PREP)
3775 
3776             self._notify_about_instance_usage(
3777                 context, instance, "resize.start", network_info=network_info)
3778 
3779             compute_utils.notify_about_instance_action(context, instance,
3780                    self.host, action=fields.NotificationAction.RESIZE,
3781                    phase=fields.NotificationPhase.START)
3782 
3783             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3784                     context, instance.uuid)
3785             block_device_info = self._get_instance_block_device_info(
3786                                 context, instance, bdms=bdms)
3787 
3788             timeout, retry_interval = self._get_power_off_values(context,
3789                                             instance, clean_shutdown)
3790             disk_info = self.driver.migrate_disk_and_power_off(
3791                     context, instance, migration.dest_host,
3792                     instance_type, network_info,
3793                     block_device_info,
3794                     timeout, retry_interval)
3795 
3796             self._terminate_volume_connections(context, instance, bdms)
3797 
3798             migration_p = obj_base.obj_to_primitive(migration)
3799             self.network_api.migrate_instance_start(context,
3800                                                     instance,
3801                                                     migration_p)
3802 
3803             migration.status = 'post-migrating'
3804             with migration.obj_as_admin():
3805                 migration.save()
3806 
3807             instance.host = migration.dest_compute
3808             instance.node = migration.dest_node
3809             instance.task_state = task_states.RESIZE_MIGRATED
3810             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
3811 
3812             self.compute_rpcapi.finish_resize(context, instance,
3813                     migration, image, disk_info,
3814                     migration.dest_compute, reservations=quotas.reservations)
3815 
3816             self._notify_about_instance_usage(context, instance, "resize.end",
3817                                               network_info=network_info)
3818 
3819             compute_utils.notify_about_instance_action(context, instance,
3820                    self.host, action=fields.NotificationAction.RESIZE,
3821                    phase=fields.NotificationPhase.END)
3822             self.instance_events.clear_events_for_instance(instance)
3823 
3824     def _terminate_volume_connections(self, context, instance, bdms):
3825         connector = self.driver.get_volume_connector(instance)
3826         for bdm in bdms:
3827             if bdm.is_volume:
3828                 self.volume_api.terminate_connection(context, bdm.volume_id,
3829                                                      connector)
3830 
3831     @staticmethod
3832     def _set_instance_info(instance, instance_type):
3833         instance.instance_type_id = instance_type.id
3834         # NOTE(danms): These are purely for any legacy code that still
3835         # looks at them.
3836         instance.memory_mb = instance_type.memory_mb
3837         instance.vcpus = instance_type.vcpus
3838         instance.root_gb = instance_type.root_gb
3839         instance.ephemeral_gb = instance_type.ephemeral_gb
3840         instance.flavor = instance_type
3841 
3842     def _finish_resize(self, context, instance, migration, disk_info,
3843                        image_meta):
3844         resize_instance = False
3845         old_instance_type_id = migration['old_instance_type_id']
3846         new_instance_type_id = migration['new_instance_type_id']
3847         old_instance_type = instance.get_flavor()
3848         # NOTE(mriedem): Get the old_vm_state so we know if we should
3849         # power on the instance. If old_vm_state is not set we need to default
3850         # to ACTIVE for backwards compatibility
3851         old_vm_state = instance.system_metadata.get('old_vm_state',
3852                                                     vm_states.ACTIVE)
3853         instance.old_flavor = old_instance_type
3854 
3855         if old_instance_type_id != new_instance_type_id:
3856             instance_type = instance.get_flavor('new')
3857             self._set_instance_info(instance, instance_type)
3858             for key in ('root_gb', 'swap', 'ephemeral_gb'):
3859                 if old_instance_type[key] != instance_type[key]:
3860                     resize_instance = True
3861                     break
3862         instance.apply_migration_context()
3863 
3864         # NOTE(tr3buchet): setup networks on destination host
3865         self.network_api.setup_networks_on_host(context, instance,
3866                                                 migration['dest_compute'])
3867 
3868         migration_p = obj_base.obj_to_primitive(migration)
3869         self.network_api.migrate_instance_finish(context,
3870                                                  instance,
3871                                                  migration_p)
3872 
3873         network_info = self.network_api.get_instance_nw_info(context, instance)
3874 
3875         instance.task_state = task_states.RESIZE_FINISH
3876         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
3877 
3878         self._notify_about_instance_usage(
3879             context, instance, "finish_resize.start",
3880             network_info=network_info)
3881 
3882         block_device_info = self._get_instance_block_device_info(
3883                             context, instance, refresh_conn_info=True)
3884 
3885         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
3886         # automatically power on the instance after it's migrated
3887         power_on = old_vm_state != vm_states.STOPPED
3888 
3889         try:
3890             self.driver.finish_migration(context, migration, instance,
3891                                          disk_info,
3892                                          network_info,
3893                                          image_meta, resize_instance,
3894                                          block_device_info, power_on)
3895         except Exception:
3896             with excutils.save_and_reraise_exception():
3897                 if old_instance_type_id != new_instance_type_id:
3898                     self._set_instance_info(instance,
3899                                             old_instance_type)
3900 
3901         migration.status = 'finished'
3902         with migration.obj_as_admin():
3903             migration.save()
3904 
3905         instance.vm_state = vm_states.RESIZED
3906         instance.task_state = None
3907         instance.launched_at = timeutils.utcnow()
3908         instance.save(expected_task_state=task_states.RESIZE_FINISH)
3909 
3910         self._update_scheduler_instance_info(context, instance)
3911         self._notify_about_instance_usage(
3912             context, instance, "finish_resize.end",
3913             network_info=network_info)
3914 
3915     @wrap_exception()
3916     @reverts_task_state
3917     @wrap_instance_event(prefix='compute')
3918     @errors_out_migration
3919     @wrap_instance_fault
3920     def finish_resize(self, context, disk_info, image, instance,
3921                       reservations, migration):
3922         """Completes the migration process.
3923 
3924         Sets up the newly transferred disk and turns on the instance at its
3925         new host machine.
3926 
3927         """
3928         quotas = objects.Quotas.from_reservations(context,
3929                                                   reservations,
3930                                                   instance=instance)
3931         try:
3932             image_meta = objects.ImageMeta.from_dict(image)
3933             self._finish_resize(context, instance, migration,
3934                                 disk_info, image_meta)
3935             quotas.commit()
3936         except Exception:
3937             LOG.exception(_LE('Setting instance vm_state to ERROR'),
3938                           instance=instance)
3939             with excutils.save_and_reraise_exception():
3940                 try:
3941                     quotas.rollback()
3942                 except Exception:
3943                     LOG.exception(_LE("Failed to rollback quota for failed "
3944                                       "finish_resize"),
3945                                   instance=instance)
3946                 self._set_instance_obj_error_state(context, instance)
3947 
3948     @wrap_exception()
3949     @wrap_instance_fault
3950     def add_fixed_ip_to_instance(self, context, network_id, instance):
3951         """Calls network_api to add new fixed_ip to instance
3952         then injects the new network info and resets instance networking.
3953 
3954         """
3955         self._notify_about_instance_usage(
3956                 context, instance, "create_ip.start")
3957 
3958         network_info = self.network_api.add_fixed_ip_to_instance(context,
3959                                                                  instance,
3960                                                                  network_id)
3961         self._inject_network_info(context, instance, network_info)
3962         self.reset_network(context, instance)
3963 
3964         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
3965         instance.updated_at = timeutils.utcnow()
3966         instance.save()
3967 
3968         self._notify_about_instance_usage(
3969             context, instance, "create_ip.end", network_info=network_info)
3970 
3971     @wrap_exception()
3972     @wrap_instance_fault
3973     def remove_fixed_ip_from_instance(self, context, address, instance):
3974         """Calls network_api to remove existing fixed_ip from instance
3975         by injecting the altered network info and resetting
3976         instance networking.
3977         """
3978         self._notify_about_instance_usage(
3979                 context, instance, "delete_ip.start")
3980 
3981         network_info = self.network_api.remove_fixed_ip_from_instance(context,
3982                                                                       instance,
3983                                                                       address)
3984         self._inject_network_info(context, instance, network_info)
3985         self.reset_network(context, instance)
3986 
3987         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
3988         instance.updated_at = timeutils.utcnow()
3989         instance.save()
3990 
3991         self._notify_about_instance_usage(
3992             context, instance, "delete_ip.end", network_info=network_info)
3993 
3994     @wrap_exception()
3995     @reverts_task_state
3996     @wrap_instance_event(prefix='compute')
3997     @wrap_instance_fault
3998     def pause_instance(self, context, instance):
3999         """Pause an instance on this host."""
4000         context = context.elevated()
4001         LOG.info(_LI('Pausing'), context=context, instance=instance)
4002         self._notify_about_instance_usage(context, instance, 'pause.start')
4003         compute_utils.notify_about_instance_action(context, instance,
4004                self.host, action=fields.NotificationAction.PAUSE,
4005                phase=fields.NotificationPhase.START)
4006         self.driver.pause(instance)
4007         instance.power_state = self._get_power_state(context, instance)
4008         instance.vm_state = vm_states.PAUSED
4009         instance.task_state = None
4010         instance.save(expected_task_state=task_states.PAUSING)
4011         self._notify_about_instance_usage(context, instance, 'pause.end')
4012         compute_utils.notify_about_instance_action(context, instance,
4013                self.host, action=fields.NotificationAction.PAUSE,
4014                phase=fields.NotificationPhase.END)
4015 
4016     @wrap_exception()
4017     @reverts_task_state
4018     @wrap_instance_event(prefix='compute')
4019     @wrap_instance_fault
4020     def unpause_instance(self, context, instance):
4021         """Unpause a paused instance on this host."""
4022         context = context.elevated()
4023         LOG.info(_LI('Unpausing'), context=context, instance=instance)
4024         self._notify_about_instance_usage(context, instance, 'unpause.start')
4025         self.driver.unpause(instance)
4026         instance.power_state = self._get_power_state(context, instance)
4027         instance.vm_state = vm_states.ACTIVE
4028         instance.task_state = None
4029         instance.save(expected_task_state=task_states.UNPAUSING)
4030         self._notify_about_instance_usage(context, instance, 'unpause.end')
4031 
4032     @wrap_exception()
4033     def host_power_action(self, context, action):
4034         """Reboots, shuts down or powers up the host."""
4035         return self.driver.host_power_action(action)
4036 
4037     @wrap_exception()
4038     def host_maintenance_mode(self, context, host, mode):
4039         """Start/Stop host maintenance window. On start, it triggers
4040         guest VMs evacuation.
4041         """
4042         return self.driver.host_maintenance_mode(host, mode)
4043 
4044     @wrap_exception()
4045     def set_host_enabled(self, context, enabled):
4046         """Sets the specified host's ability to accept new instances."""
4047         return self.driver.set_host_enabled(enabled)
4048 
4049     @wrap_exception()
4050     def get_host_uptime(self, context):
4051         """Returns the result of calling "uptime" on the target host."""
4052         return self.driver.get_host_uptime()
4053 
4054     @wrap_exception()
4055     @wrap_instance_fault
4056     def get_diagnostics(self, context, instance):
4057         """Retrieve diagnostics for an instance on this host."""
4058         current_power_state = self._get_power_state(context, instance)
4059         if current_power_state == power_state.RUNNING:
4060             LOG.info(_LI("Retrieving diagnostics"), context=context,
4061                       instance=instance)
4062             return self.driver.get_diagnostics(instance)
4063         else:
4064             raise exception.InstanceInvalidState(
4065                 attr='power state',
4066                 instance_uuid=instance.uuid,
4067                 state=power_state.STATE_MAP[instance.power_state],
4068                 method='get_diagnostics')
4069 
4070     # TODO(alaski): Remove object_compat for RPC version 5.0
4071     @object_compat
4072     @wrap_exception()
4073     @wrap_instance_fault
4074     def get_instance_diagnostics(self, context, instance):
4075         """Retrieve diagnostics for an instance on this host."""
4076         current_power_state = self._get_power_state(context, instance)
4077         if current_power_state == power_state.RUNNING:
4078             LOG.info(_LI("Retrieving diagnostics"), context=context,
4079                       instance=instance)
4080             diags = self.driver.get_instance_diagnostics(instance)
4081             return diags.serialize()
4082         else:
4083             raise exception.InstanceInvalidState(
4084                 attr='power state',
4085                 instance_uuid=instance.uuid,
4086                 state=power_state.STATE_MAP[instance.power_state],
4087                 method='get_diagnostics')
4088 
4089     @wrap_exception()
4090     @reverts_task_state
4091     @wrap_instance_event(prefix='compute')
4092     @wrap_instance_fault
4093     def suspend_instance(self, context, instance):
4094         """Suspend the given instance."""
4095         context = context.elevated()
4096 
4097         # Store the old state
4098         instance.system_metadata['old_vm_state'] = instance.vm_state
4099         self._notify_about_instance_usage(context, instance, 'suspend.start')
4100         compute_utils.notify_about_instance_action(context, instance,
4101                 self.host, action=fields.NotificationAction.SUSPEND,
4102                 phase=fields.NotificationPhase.START)
4103         with self._error_out_instance_on_exception(context, instance,
4104              instance_state=instance.vm_state):
4105             self.driver.suspend(context, instance)
4106         instance.power_state = self._get_power_state(context, instance)
4107         instance.vm_state = vm_states.SUSPENDED
4108         instance.task_state = None
4109         instance.save(expected_task_state=task_states.SUSPENDING)
4110         self._notify_about_instance_usage(context, instance, 'suspend.end')
4111         compute_utils.notify_about_instance_action(context, instance,
4112                 self.host, action=fields.NotificationAction.SUSPEND,
4113                 phase=fields.NotificationPhase.END)
4114 
4115     @wrap_exception()
4116     @reverts_task_state
4117     @wrap_instance_event(prefix='compute')
4118     @wrap_instance_fault
4119     def resume_instance(self, context, instance):
4120         """Resume the given suspended instance."""
4121         context = context.elevated()
4122         LOG.info(_LI('Resuming'), context=context, instance=instance)
4123 
4124         self._notify_about_instance_usage(context, instance, 'resume.start')
4125         network_info = self.network_api.get_instance_nw_info(context, instance)
4126         block_device_info = self._get_instance_block_device_info(
4127                             context, instance)
4128 
4129         with self._error_out_instance_on_exception(context, instance,
4130              instance_state=instance.vm_state):
4131             self.driver.resume(context, instance, network_info,
4132                                block_device_info)
4133 
4134         instance.power_state = self._get_power_state(context, instance)
4135 
4136         # We default to the ACTIVE state for backwards compatibility
4137         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4138                                                          vm_states.ACTIVE)
4139 
4140         instance.task_state = None
4141         instance.save(expected_task_state=task_states.RESUMING)
4142         self._notify_about_instance_usage(context, instance, 'resume.end')
4143 
4144     @wrap_exception()
4145     @reverts_task_state
4146     @wrap_instance_event(prefix='compute')
4147     @wrap_instance_fault
4148     def shelve_instance(self, context, instance, image_id,
4149                         clean_shutdown):
4150         """Shelve an instance.
4151 
4152         This should be used when you want to take a snapshot of the instance.
4153         It also adds system_metadata that can be used by a periodic task to
4154         offload the shelved instance after a period of time.
4155 
4156         :param context: request context
4157         :param instance: an Instance object
4158         :param image_id: an image id to snapshot to.
4159         :param clean_shutdown: give the GuestOS a chance to stop
4160         """
4161         compute_utils.notify_usage_exists(self.notifier, context, instance,
4162                                           current_period=True)
4163         self._notify_about_instance_usage(context, instance, 'shelve.start')
4164         compute_utils.notify_about_instance_action(context, instance,
4165                 self.host, action=fields.NotificationAction.SHELVE,
4166                 phase=fields.NotificationPhase.START)
4167 
4168         def update_task_state(task_state, expected_state=task_states.SHELVING):
4169             shelving_state_map = {
4170                     task_states.IMAGE_PENDING_UPLOAD:
4171                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4172                     task_states.IMAGE_UPLOADING:
4173                         task_states.SHELVING_IMAGE_UPLOADING,
4174                     task_states.SHELVING: task_states.SHELVING}
4175             task_state = shelving_state_map[task_state]
4176             expected_state = shelving_state_map[expected_state]
4177             instance.task_state = task_state
4178             instance.save(expected_task_state=expected_state)
4179 
4180         self._power_off_instance(context, instance, clean_shutdown)
4181         self.driver.snapshot(context, instance, image_id, update_task_state)
4182 
4183         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4184         instance.system_metadata['shelved_image_id'] = image_id
4185         instance.system_metadata['shelved_host'] = self.host
4186         instance.vm_state = vm_states.SHELVED
4187         instance.task_state = None
4188         if CONF.shelved_offload_time == 0:
4189             instance.task_state = task_states.SHELVING_OFFLOADING
4190         instance.power_state = self._get_power_state(context, instance)
4191         instance.save(expected_task_state=[
4192                 task_states.SHELVING,
4193                 task_states.SHELVING_IMAGE_UPLOADING])
4194 
4195         self._notify_about_instance_usage(context, instance, 'shelve.end')
4196         compute_utils.notify_about_instance_action(context, instance,
4197                 self.host, action=fields.NotificationAction.SHELVE,
4198                 phase=fields.NotificationPhase.END)
4199 
4200         if CONF.shelved_offload_time == 0:
4201             self.shelve_offload_instance(context, instance,
4202                                          clean_shutdown=False)
4203 
4204     @wrap_exception()
4205     @reverts_task_state
4206     @wrap_instance_fault
4207     def shelve_offload_instance(self, context, instance, clean_shutdown):
4208         """Remove a shelved instance from the hypervisor.
4209 
4210         This frees up those resources for use by other instances, but may lead
4211         to slower unshelve times for this instance.  This method is used by
4212         volume backed instances since restoring them doesn't involve the
4213         potentially large download of an image.
4214 
4215         :param context: request context
4216         :param instance: nova.objects.instance.Instance
4217         :param clean_shutdown: give the GuestOS a chance to stop
4218         """
4219         self._notify_about_instance_usage(context, instance,
4220                 'shelve_offload.start')
4221 
4222         self._power_off_instance(context, instance, clean_shutdown)
4223         current_power_state = self._get_power_state(context, instance)
4224 
4225         self.network_api.cleanup_instance_network_on_host(context, instance,
4226                                                           instance.host)
4227         network_info = self.network_api.get_instance_nw_info(context, instance)
4228         block_device_info = self._get_instance_block_device_info(context,
4229                                                                  instance)
4230         self.driver.destroy(context, instance, network_info,
4231                 block_device_info)
4232 
4233         instance.power_state = current_power_state
4234         instance.vm_state = vm_states.SHELVED_OFFLOADED
4235         instance.task_state = None
4236         instance.save(expected_task_state=[task_states.SHELVING,
4237                                            task_states.SHELVING_OFFLOADING])
4238 
4239         # NOTE(ndipanov): Free resources from the resource tracker
4240         self._update_resource_tracker(context, instance)
4241 
4242         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4243         # instance, so ensure any calls result in errors
4244         self._nil_out_instance_obj_host_and_node(instance)
4245         instance.save(expected_task_state=None)
4246 
4247         self._delete_scheduler_instance_info(context, instance.uuid)
4248         self._notify_about_instance_usage(context, instance,
4249                 'shelve_offload.end')
4250 
4251     @wrap_exception()
4252     @reverts_task_state
4253     @wrap_instance_event(prefix='compute')
4254     @wrap_instance_fault
4255     def unshelve_instance(self, context, instance, image,
4256                           filter_properties, node):
4257         """Unshelve the instance.
4258 
4259         :param context: request context
4260         :param instance: a nova.objects.instance.Instance object
4261         :param image: an image to build from.  If None we assume a
4262             volume backed instance.
4263         :param filter_properties: dict containing limits, retry info etc.
4264         :param node: target compute node
4265         """
4266         if filter_properties is None:
4267             filter_properties = {}
4268 
4269         @utils.synchronized(instance.uuid)
4270         def do_unshelve_instance():
4271             self._unshelve_instance(context, instance, image,
4272                                     filter_properties, node)
4273         do_unshelve_instance()
4274 
4275     def _unshelve_instance_key_scrub(self, instance):
4276         """Remove data from the instance that may cause side effects."""
4277         cleaned_keys = dict(
4278                 key_data=instance.key_data,
4279                 auto_disk_config=instance.auto_disk_config)
4280         instance.key_data = None
4281         instance.auto_disk_config = False
4282         return cleaned_keys
4283 
4284     def _unshelve_instance_key_restore(self, instance, keys):
4285         """Restore previously scrubbed keys before saving the instance."""
4286         instance.update(keys)
4287 
4288     def _unshelve_instance(self, context, instance, image, filter_properties,
4289                            node):
4290         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4291         instance.task_state = task_states.SPAWNING
4292         instance.save()
4293 
4294         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4295                 context, instance.uuid)
4296         block_device_info = self._prep_block_device(context, instance, bdms,
4297                                                     do_check_attach=False)
4298         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4299 
4300         if node is None:
4301             node = self.driver.get_available_nodes()[0]
4302             LOG.debug('No node specified, defaulting to %s', node,
4303                       instance=instance)
4304 
4305         rt = self._get_resource_tracker(node)
4306         limits = filter_properties.get('limits', {})
4307 
4308         shelved_image_ref = instance.image_ref
4309         if image:
4310             instance.image_ref = image['id']
4311             image_meta = objects.ImageMeta.from_dict(image)
4312         else:
4313             image_meta = objects.ImageMeta.from_dict(
4314                 utils.get_image_from_system_metadata(
4315                     instance.system_metadata))
4316 
4317         self.network_api.setup_instance_network_on_host(context, instance,
4318                                                         self.host)
4319         network_info = self.network_api.get_instance_nw_info(context, instance)
4320         try:
4321             with rt.instance_claim(context, instance, limits):
4322                 self.driver.spawn(context, instance, image_meta,
4323                                   injected_files=[],
4324                                   admin_password=None,
4325                                   network_info=network_info,
4326                                   block_device_info=block_device_info)
4327         except Exception:
4328             with excutils.save_and_reraise_exception():
4329                 LOG.exception(_LE('Instance failed to spawn'),
4330                               instance=instance)
4331 
4332         if image:
4333             instance.image_ref = shelved_image_ref
4334             self._delete_snapshot_of_shelved_instance(context, instance,
4335                                                       image['id'])
4336 
4337         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4338         self._update_instance_after_spawn(context, instance)
4339         # Delete system_metadata for a shelved instance
4340         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4341 
4342         instance.save(expected_task_state=task_states.SPAWNING)
4343         self._update_scheduler_instance_info(context, instance)
4344         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4345 
4346     @messaging.expected_exceptions(NotImplementedError)
4347     @wrap_instance_fault
4348     def reset_network(self, context, instance):
4349         """Reset networking on the given instance."""
4350         LOG.debug('Reset network', context=context, instance=instance)
4351         self.driver.reset_network(instance)
4352 
4353     def _inject_network_info(self, context, instance, network_info):
4354         """Inject network info for the given instance."""
4355         LOG.debug('Inject network info', context=context, instance=instance)
4356         LOG.debug('network_info to inject: |%s|', network_info,
4357                   instance=instance)
4358 
4359         self.driver.inject_network_info(instance,
4360                                         network_info)
4361 
4362     @wrap_instance_fault
4363     def inject_network_info(self, context, instance):
4364         """Inject network info, but don't return the info."""
4365         network_info = self.network_api.get_instance_nw_info(context, instance)
4366         self._inject_network_info(context, instance, network_info)
4367 
4368     @messaging.expected_exceptions(NotImplementedError,
4369                                    exception.ConsoleNotAvailable,
4370                                    exception.InstanceNotFound)
4371     @wrap_exception()
4372     @wrap_instance_fault
4373     def get_console_output(self, context, instance, tail_length):
4374         """Send the console output for the given instance."""
4375         context = context.elevated()
4376         LOG.info(_LI("Get console output"), context=context,
4377                   instance=instance)
4378         output = self.driver.get_console_output(context, instance)
4379 
4380         if type(output) is six.text_type:
4381             output = six.b(output)
4382 
4383         if tail_length is not None:
4384             output = self._tail_log(output, tail_length)
4385 
4386         return output.decode('ascii', 'replace')
4387 
4388     def _tail_log(self, log, length):
4389         try:
4390             length = int(length)
4391         except ValueError:
4392             length = 0
4393 
4394         if length == 0:
4395             return b''
4396         else:
4397             return b'\n'.join(log.split(b'\n')[-int(length):])
4398 
4399     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4400                                    exception.InstanceNotReady,
4401                                    exception.InstanceNotFound,
4402                                    exception.ConsoleTypeUnavailable,
4403                                    NotImplementedError)
4404     @wrap_exception()
4405     @wrap_instance_fault
4406     def get_vnc_console(self, context, console_type, instance):
4407         """Return connection information for a vnc console."""
4408         context = context.elevated()
4409         LOG.debug("Getting vnc console", instance=instance)
4410         token = str(uuid.uuid4())
4411 
4412         if not CONF.vnc.enabled:
4413             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4414 
4415         if console_type == 'novnc':
4416             # For essex, novncproxy_base_url must include the full path
4417             # including the html file (like http://myhost/vnc_auto.html)
4418             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
4419         elif console_type == 'xvpvnc':
4420             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
4421         else:
4422             raise exception.ConsoleTypeInvalid(console_type=console_type)
4423 
4424         try:
4425             # Retrieve connect info from driver, and then decorate with our
4426             # access info token
4427             console = self.driver.get_vnc_console(context, instance)
4428             connect_info = console.get_connection_info(token, access_url)
4429         except exception.InstanceNotFound:
4430             if instance.vm_state != vm_states.BUILDING:
4431                 raise
4432             raise exception.InstanceNotReady(instance_id=instance.uuid)
4433 
4434         return connect_info
4435 
4436     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4437                                    exception.InstanceNotReady,
4438                                    exception.InstanceNotFound,
4439                                    exception.ConsoleTypeUnavailable,
4440                                    NotImplementedError)
4441     @wrap_exception()
4442     @wrap_instance_fault
4443     def get_spice_console(self, context, console_type, instance):
4444         """Return connection information for a spice console."""
4445         context = context.elevated()
4446         LOG.debug("Getting spice console", instance=instance)
4447         token = str(uuid.uuid4())
4448 
4449         if not CONF.spice.enabled:
4450             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4451 
4452         if console_type == 'spice-html5':
4453             # For essex, spicehtml5proxy_base_url must include the full path
4454             # including the html file (like http://myhost/spice_auto.html)
4455             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
4456                                           token)
4457         else:
4458             raise exception.ConsoleTypeInvalid(console_type=console_type)
4459 
4460         try:
4461             # Retrieve connect info from driver, and then decorate with our
4462             # access info token
4463             console = self.driver.get_spice_console(context, instance)
4464             connect_info = console.get_connection_info(token, access_url)
4465         except exception.InstanceNotFound:
4466             if instance.vm_state != vm_states.BUILDING:
4467                 raise
4468             raise exception.InstanceNotReady(instance_id=instance.uuid)
4469 
4470         return connect_info
4471 
4472     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4473                                    exception.InstanceNotReady,
4474                                    exception.InstanceNotFound,
4475                                    exception.ConsoleTypeUnavailable,
4476                                    NotImplementedError)
4477     @wrap_exception()
4478     @wrap_instance_fault
4479     def get_rdp_console(self, context, console_type, instance):
4480         """Return connection information for a RDP console."""
4481         context = context.elevated()
4482         LOG.debug("Getting RDP console", instance=instance)
4483         token = str(uuid.uuid4())
4484 
4485         if not CONF.rdp.enabled:
4486             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4487 
4488         if console_type == 'rdp-html5':
4489             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
4490                                           token)
4491         else:
4492             raise exception.ConsoleTypeInvalid(console_type=console_type)
4493 
4494         try:
4495             # Retrieve connect info from driver, and then decorate with our
4496             # access info token
4497             console = self.driver.get_rdp_console(context, instance)
4498             connect_info = console.get_connection_info(token, access_url)
4499         except exception.InstanceNotFound:
4500             if instance.vm_state != vm_states.BUILDING:
4501                 raise
4502             raise exception.InstanceNotReady(instance_id=instance.uuid)
4503 
4504         return connect_info
4505 
4506     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4507                                    exception.InstanceNotReady,
4508                                    exception.InstanceNotFound,
4509                                    exception.ConsoleTypeUnavailable,
4510                                    NotImplementedError)
4511     @wrap_exception()
4512     @wrap_instance_fault
4513     def get_mks_console(self, context, console_type, instance):
4514         """Return connection information for a MKS console."""
4515         context = context.elevated()
4516         LOG.debug("Getting MKS console", instance=instance)
4517         token = str(uuid.uuid4())
4518 
4519         if not CONF.mks.enabled:
4520             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4521 
4522         if console_type == 'webmks':
4523             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
4524                                           token)
4525         else:
4526             raise exception.ConsoleTypeInvalid(console_type=console_type)
4527 
4528         try:
4529             # Retrieve connect info from driver, and then decorate with our
4530             # access info token
4531             console = self.driver.get_mks_console(context, instance)
4532             connect_info = console.get_connection_info(token, access_url)
4533         except exception.InstanceNotFound:
4534             if instance.vm_state != vm_states.BUILDING:
4535                 raise
4536             raise exception.InstanceNotReady(instance_id=instance.uuid)
4537 
4538         return connect_info
4539 
4540     @messaging.expected_exceptions(
4541         exception.ConsoleTypeInvalid,
4542         exception.InstanceNotReady,
4543         exception.InstanceNotFound,
4544         exception.ConsoleTypeUnavailable,
4545         exception.SocketPortRangeExhaustedException,
4546         exception.ImageSerialPortNumberInvalid,
4547         exception.ImageSerialPortNumberExceedFlavorValue,
4548         NotImplementedError)
4549     @wrap_exception()
4550     @wrap_instance_fault
4551     def get_serial_console(self, context, console_type, instance):
4552         """Returns connection information for a serial console."""
4553 
4554         LOG.debug("Getting serial console", instance=instance)
4555 
4556         if not CONF.serial_console.enabled:
4557             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4558 
4559         context = context.elevated()
4560 
4561         token = str(uuid.uuid4())
4562         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
4563 
4564         try:
4565             # Retrieve connect info from driver, and then decorate with our
4566             # access info token
4567             console = self.driver.get_serial_console(context, instance)
4568             connect_info = console.get_connection_info(token, access_url)
4569         except exception.InstanceNotFound:
4570             if instance.vm_state != vm_states.BUILDING:
4571                 raise
4572             raise exception.InstanceNotReady(instance_id=instance.uuid)
4573 
4574         return connect_info
4575 
4576     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4577                                    exception.InstanceNotReady,
4578                                    exception.InstanceNotFound)
4579     @wrap_exception()
4580     @wrap_instance_fault
4581     def validate_console_port(self, ctxt, instance, port, console_type):
4582         if console_type == "spice-html5":
4583             console_info = self.driver.get_spice_console(ctxt, instance)
4584         elif console_type == "rdp-html5":
4585             console_info = self.driver.get_rdp_console(ctxt, instance)
4586         elif console_type == "serial":
4587             console_info = self.driver.get_serial_console(ctxt, instance)
4588         elif console_type == "webmks":
4589             console_info = self.driver.get_mks_console(ctxt, instance)
4590         else:
4591             console_info = self.driver.get_vnc_console(ctxt, instance)
4592 
4593         return console_info.port == port
4594 
4595     @wrap_exception()
4596     @reverts_task_state
4597     @wrap_instance_fault
4598     def reserve_block_device_name(self, context, instance, device,
4599                                   volume_id, disk_bus, device_type):
4600         @utils.synchronized(instance.uuid)
4601         def do_reserve():
4602             bdms = (
4603                 objects.BlockDeviceMappingList.get_by_instance_uuid(
4604                     context, instance.uuid))
4605 
4606             # NOTE(ndipanov): We need to explicitly set all the fields on the
4607             #                 object so that obj_load_attr does not fail
4608             new_bdm = objects.BlockDeviceMapping(
4609                     context=context,
4610                     source_type='volume', destination_type='volume',
4611                     instance_uuid=instance.uuid, boot_index=None,
4612                     volume_id=volume_id,
4613                     device_name=device, guest_format=None,
4614                     disk_bus=disk_bus, device_type=device_type)
4615 
4616             new_bdm.device_name = self._get_device_name_for_instance(
4617                     instance, bdms, new_bdm)
4618 
4619             # NOTE(vish): create bdm here to avoid race condition
4620             new_bdm.create()
4621             return new_bdm
4622 
4623         return do_reserve()
4624 
4625     @wrap_exception()
4626     @wrap_instance_fault
4627     def attach_volume(self, context, instance, bdm):
4628         """Attach a volume to an instance."""
4629         driver_bdm = driver_block_device.convert_volume(bdm)
4630 
4631         @utils.synchronized(instance.uuid)
4632         def do_attach_volume(context, instance, driver_bdm):
4633             try:
4634                 return self._attach_volume(context, instance, driver_bdm)
4635             except Exception:
4636                 with excutils.save_and_reraise_exception():
4637                     bdm.destroy()
4638 
4639         do_attach_volume(context, instance, driver_bdm)
4640 
4641     def _attach_volume(self, context, instance, bdm):
4642         context = context.elevated()
4643         LOG.info(_LI('Attaching volume %(volume_id)s to %(mountpoint)s'),
4644                   {'volume_id': bdm.volume_id,
4645                   'mountpoint': bdm['mount_device']},
4646                  context=context, instance=instance)
4647         try:
4648             bdm.attach(context, instance, self.volume_api, self.driver,
4649                        do_check_attach=False, do_driver_attach=True)
4650         except Exception:
4651             with excutils.save_and_reraise_exception():
4652                 LOG.exception(_LE("Failed to attach %(volume_id)s "
4653                                   "at %(mountpoint)s"),
4654                               {'volume_id': bdm.volume_id,
4655                                'mountpoint': bdm['mount_device']},
4656                               context=context, instance=instance)
4657                 self.volume_api.unreserve_volume(context, bdm.volume_id)
4658 
4659         info = {'volume_id': bdm.volume_id}
4660         self._notify_about_instance_usage(
4661             context, instance, "volume.attach", extra_usage_info=info)
4662 
4663     def _driver_detach_volume(self, context, instance, bdm, connection_info):
4664         """Do the actual driver detach using block device mapping."""
4665         mp = bdm.device_name
4666         volume_id = bdm.volume_id
4667 
4668         LOG.info(_LI('Detach volume %(volume_id)s from mountpoint %(mp)s'),
4669                   {'volume_id': volume_id, 'mp': mp},
4670                   context=context, instance=instance)
4671 
4672         try:
4673             if not self.driver.instance_exists(instance):
4674                 LOG.warning(_LW('Detaching volume from unknown instance'),
4675                             context=context, instance=instance)
4676 
4677             encryption = encryptors.get_encryption_metadata(
4678                 context, self.volume_api, volume_id, connection_info)
4679 
4680             self.driver.detach_volume(connection_info,
4681                                       instance,
4682                                       mp,
4683                                       encryption=encryption)
4684         except exception.DiskNotFound as err:
4685             LOG.warning(_LW('Ignoring DiskNotFound exception while detaching '
4686                             'volume %(volume_id)s from %(mp)s: %(err)s'),
4687                         {'volume_id': volume_id, 'mp': mp, 'err': err},
4688                         instance=instance)
4689         except Exception:
4690             with excutils.save_and_reraise_exception():
4691                 LOG.exception(_LE('Failed to detach volume %(volume_id)s '
4692                                   'from %(mp)s'),
4693                               {'volume_id': volume_id, 'mp': mp},
4694                               context=context, instance=instance)
4695                 self.volume_api.roll_detaching(context, volume_id)
4696 
4697     def _detach_volume(self, context, volume_id, instance, destroy_bdm=True,
4698                        attachment_id=None):
4699         """Detach a volume from an instance.
4700 
4701         :param context: security context
4702         :param volume_id: the volume id
4703         :param instance: the Instance object to detach the volume from
4704         :param destroy_bdm: if True, the corresponding BDM entry will be marked
4705                             as deleted. Disabling this is useful for operations
4706                             like rebuild, when we don't want to destroy BDM
4707 
4708         """
4709 
4710         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4711                 context, volume_id, instance.uuid)
4712         if CONF.volume_usage_poll_interval > 0:
4713             vol_stats = []
4714             mp = bdm.device_name
4715             # Handle bootable volumes which will not contain /dev/
4716             if '/dev/' in mp:
4717                 mp = mp[5:]
4718             try:
4719                 vol_stats = self.driver.block_stats(instance, mp)
4720             except NotImplementedError:
4721                 pass
4722 
4723             if vol_stats:
4724                 LOG.debug("Updating volume usage cache with totals",
4725                           instance=instance)
4726                 rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
4727                 vol_usage = objects.VolumeUsage(context)
4728                 vol_usage.volume_id = volume_id
4729                 vol_usage.instance_uuid = instance.uuid
4730                 vol_usage.project_id = instance.project_id
4731                 vol_usage.user_id = instance.user_id
4732                 vol_usage.availability_zone = instance.availability_zone
4733                 vol_usage.curr_reads = rd_req
4734                 vol_usage.curr_read_bytes = rd_bytes
4735                 vol_usage.curr_writes = wr_req
4736                 vol_usage.curr_write_bytes = wr_bytes
4737                 vol_usage.save(update_totals=True)
4738                 self.notifier.info(context, 'volume.usage',
4739                                    compute_utils.usage_volume_info(vol_usage))
4740 
4741         connection_info = jsonutils.loads(bdm.connection_info)
4742         connector = self.driver.get_volume_connector(instance)
4743         if CONF.host == instance.host:
4744             # Only attempt to detach and disconnect from the volume if the
4745             # instance is currently associated with the local compute host.
4746             self._driver_detach_volume(context, instance, bdm, connection_info)
4747         elif not destroy_bdm:
4748             LOG.debug("Skipping _driver_detach_volume during remote rebuild.",
4749                       instance=instance)
4750         elif destroy_bdm:
4751             LOG.error(_LE("Unable to call for a driver detach of volume "
4752                           "%(vol_id)s due to the instance being registered to "
4753                           "the remote host %(inst_host)s."),
4754                       {'vol_id': volume_id, 'inst_host': instance.host},
4755                       instance=instance)
4756 
4757         if connection_info and not destroy_bdm and (
4758            connector.get('host') != instance.host):
4759             # If the volume is attached to another host (evacuate) then
4760             # this connector is for the wrong host. Use the connector that
4761             # was stored in connection_info instead (if we have one, and it
4762             # is for the expected host).
4763             stashed_connector = connection_info.get('connector')
4764             if not stashed_connector:
4765                 # Volume was attached before we began stashing connectors
4766                 LOG.warning(_LW("Host mismatch detected, but stashed "
4767                                 "volume connector not found. Instance host is "
4768                                 "%(ihost)s, but volume connector host is "
4769                                 "%(chost)s."),
4770                             {'ihost': instance.host,
4771                              'chost': connector.get('host')})
4772             elif stashed_connector.get('host') != instance.host:
4773                 # Unexpected error. The stashed connector is also not matching
4774                 # the needed instance host.
4775                 LOG.error(_LE("Host mismatch detected in stashed volume "
4776                               "connector. Will use local volume connector. "
4777                               "Instance host is %(ihost)s. Local volume "
4778                               "connector host is %(chost)s. Stashed volume "
4779                               "connector host is %(schost)s."),
4780                           {'ihost': instance.host,
4781                            'chost': connector.get('host'),
4782                            'schost': stashed_connector.get('host')})
4783             else:
4784                 # Fix found. Use stashed connector.
4785                 LOG.debug("Host mismatch detected. Found usable stashed "
4786                           "volume connector. Instance host is %(ihost)s. "
4787                           "Local volume connector host was %(chost)s. "
4788                           "Stashed volume connector host is %(schost)s.",
4789                           {'ihost': instance.host,
4790                            'chost': connector.get('host'),
4791                            'schost': stashed_connector.get('host')})
4792                 connector = stashed_connector
4793 
4794         self.volume_api.terminate_connection(context, volume_id, connector)
4795 
4796         if destroy_bdm:
4797             bdm.destroy()
4798 
4799         info = dict(volume_id=volume_id)
4800         self._notify_about_instance_usage(
4801             context, instance, "volume.detach", extra_usage_info=info)
4802         self.volume_api.detach(context.elevated(), volume_id, instance.uuid,
4803                                attachment_id)
4804 
4805     @wrap_exception()
4806     @wrap_instance_fault
4807     def detach_volume(self, context, volume_id, instance, attachment_id=None):
4808         """Detach a volume from an instance."""
4809 
4810         self._detach_volume(context, volume_id, instance,
4811                             attachment_id=attachment_id)
4812 
4813     def _init_volume_connection(self, context, new_volume_id,
4814                                 old_volume_id, connector, instance, bdm):
4815 
4816         new_cinfo = self.volume_api.initialize_connection(context,
4817                                                           new_volume_id,
4818                                                           connector)
4819         old_cinfo = jsonutils.loads(bdm['connection_info'])
4820         if old_cinfo and 'serial' not in old_cinfo:
4821             old_cinfo['serial'] = old_volume_id
4822         new_cinfo['serial'] = old_cinfo['serial']
4823         return (old_cinfo, new_cinfo)
4824 
4825     def _swap_volume(self, context, instance, bdm, connector,
4826                      old_volume_id, new_volume_id, resize_to):
4827         mountpoint = bdm['device_name']
4828         failed = False
4829         new_cinfo = None
4830         try:
4831             old_cinfo, new_cinfo = self._init_volume_connection(context,
4832                                                                 new_volume_id,
4833                                                                 old_volume_id,
4834                                                                 connector,
4835                                                                 instance,
4836                                                                 bdm)
4837             LOG.debug("swap_volume: Calling driver volume swap with "
4838                       "connection infos: new: %(new_cinfo)s; "
4839                       "old: %(old_cinfo)s",
4840                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo},
4841                       contex=context, instance=instance)
4842             self.driver.swap_volume(old_cinfo, new_cinfo, instance, mountpoint,
4843                                     resize_to)
4844         except Exception:
4845             failed = True
4846             with excutils.save_and_reraise_exception():
4847                 if new_cinfo:
4848                     msg = _LE("Failed to swap volume %(old_volume_id)s "
4849                               "for %(new_volume_id)s")
4850                     LOG.exception(msg, {'old_volume_id': old_volume_id,
4851                                         'new_volume_id': new_volume_id},
4852                                   context=context,
4853                                   instance=instance)
4854                 else:
4855                     msg = _LE("Failed to connect to volume %(volume_id)s "
4856                               "with volume at %(mountpoint)s")
4857                     LOG.exception(msg, {'volume_id': new_volume_id,
4858                                         'mountpoint': bdm['device_name']},
4859                                   context=context,
4860                                   instance=instance)
4861                 self.volume_api.roll_detaching(context, old_volume_id)
4862                 self.volume_api.unreserve_volume(context, new_volume_id)
4863         finally:
4864             conn_volume = new_volume_id if failed else old_volume_id
4865             if new_cinfo:
4866                 LOG.debug("swap_volume: calling Cinder terminate_connection "
4867                           "for %(volume)s", {'volume': conn_volume},
4868                           context=context, instance=instance)
4869                 self.volume_api.terminate_connection(context,
4870                                                      conn_volume,
4871                                                      connector)
4872             # If Cinder initiated the swap, it will keep
4873             # the original ID
4874             comp_ret = self.volume_api.migrate_volume_completion(
4875                                                       context,
4876                                                       old_volume_id,
4877                                                       new_volume_id,
4878                                                       error=failed)
4879             LOG.debug("swap_volume: Cinder migrate_volume_completion "
4880                       "returned: %(comp_ret)s", {'comp_ret': comp_ret},
4881                       context=context, instance=instance)
4882 
4883         return (comp_ret, new_cinfo)
4884 
4885     @wrap_exception()
4886     @reverts_task_state
4887     @wrap_instance_fault
4888     def swap_volume(self, context, old_volume_id, new_volume_id, instance):
4889         """Swap volume for an instance."""
4890         context = context.elevated()
4891 
4892         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4893                 context, old_volume_id, instance.uuid)
4894         connector = self.driver.get_volume_connector(instance)
4895 
4896         resize_to = 0
4897         old_vol_size = self.volume_api.get(context, old_volume_id)['size']
4898         new_vol_size = self.volume_api.get(context, new_volume_id)['size']
4899         if new_vol_size > old_vol_size:
4900             resize_to = new_vol_size
4901 
4902         LOG.info(_LI('Swapping volume %(old_volume)s for %(new_volume)s'),
4903                   {'old_volume': old_volume_id, 'new_volume': new_volume_id},
4904                   context=context, instance=instance)
4905         comp_ret, new_cinfo = self._swap_volume(context, instance,
4906                                                          bdm,
4907                                                          connector,
4908                                                          old_volume_id,
4909                                                          new_volume_id,
4910                                                          resize_to)
4911 
4912         save_volume_id = comp_ret['save_volume_id']
4913 
4914         # Update bdm
4915         values = {
4916             'connection_info': jsonutils.dumps(new_cinfo),
4917             'source_type': 'volume',
4918             'destination_type': 'volume',
4919             'snapshot_id': None,
4920             'volume_id': save_volume_id,
4921             'no_device': None}
4922 
4923         if resize_to:
4924             values['volume_size'] = resize_to
4925 
4926         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
4927                   "%(updates)s", {'volume_id': bdm.volume_id,
4928                                   'updates': values},
4929                   context=context, instance=instance)
4930         bdm.update(values)
4931         bdm.save()
4932 
4933     @wrap_exception()
4934     def remove_volume_connection(self, context, volume_id, instance):
4935         """Remove a volume connection using the volume api."""
4936         # NOTE(vish): We don't want to actually mark the volume
4937         #             detached, or delete the bdm, just remove the
4938         #             connection from this host.
4939 
4940         try:
4941             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4942                     context, volume_id, instance.uuid)
4943             connection_info = jsonutils.loads(bdm.connection_info)
4944             self._driver_detach_volume(context, instance, bdm, connection_info)
4945             connector = self.driver.get_volume_connector(instance)
4946             self.volume_api.terminate_connection(context, volume_id, connector)
4947         except exception.NotFound:
4948             pass
4949 
4950     @wrap_exception()
4951     @wrap_instance_fault
4952     def attach_interface(self, context, instance, network_id, port_id,
4953                          requested_ip):
4954         """Use hotplug to add an network adapter to an instance."""
4955         if not self.driver.capabilities['supports_attach_interface']:
4956             raise exception.AttachInterfaceNotSupported(
4957                 instance_id=instance.uuid)
4958         bind_host_id = self.driver.network_binding_host_id(context, instance)
4959         network_info = self.network_api.allocate_port_for_instance(
4960             context, instance, port_id, network_id, requested_ip,
4961             bind_host_id=bind_host_id)
4962         if len(network_info) != 1:
4963             LOG.error(_LE('allocate_port_for_instance returned %(ports)s '
4964                           'ports'), {'ports': len(network_info)})
4965             raise exception.InterfaceAttachFailed(
4966                     instance_uuid=instance.uuid)
4967         image_meta = objects.ImageMeta.from_instance(instance)
4968 
4969         try:
4970             self.driver.attach_interface(instance, image_meta, network_info[0])
4971         except exception.NovaException as ex:
4972             port_id = network_info[0].get('id')
4973             LOG.warning(_LW("attach interface failed , try to deallocate "
4974                          "port %(port_id)s, reason: %(msg)s"),
4975                      {'port_id': port_id, 'msg': ex},
4976                      instance=instance)
4977             try:
4978                 self.network_api.deallocate_port_for_instance(
4979                     context, instance, port_id)
4980             except Exception:
4981                 LOG.warning(_LW("deallocate port %(port_id)s failed"),
4982                              {'port_id': port_id}, instance=instance)
4983             raise exception.InterfaceAttachFailed(
4984                 instance_uuid=instance.uuid)
4985 
4986         return network_info[0]
4987 
4988     @wrap_exception()
4989     @wrap_instance_fault
4990     def detach_interface(self, context, instance, port_id):
4991         """Detach a network adapter from an instance."""
4992         network_info = instance.info_cache.network_info
4993         condemned = None
4994         for vif in network_info:
4995             if vif['id'] == port_id:
4996                 condemned = vif
4997                 break
4998         if condemned is None:
4999             raise exception.PortNotFound(_("Port %s is not "
5000                                            "attached") % port_id)
5001         try:
5002             self.driver.detach_interface(instance, condemned)
5003         except exception.NovaException as ex:
5004             LOG.warning(_LW("Detach interface failed, port_id=%(port_id)s,"
5005                             " reason: %(msg)s"),
5006                         {'port_id': port_id, 'msg': ex}, instance=instance)
5007             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5008         else:
5009             try:
5010                 self.network_api.deallocate_port_for_instance(
5011                     context, instance, port_id)
5012             except Exception as ex:
5013                 with excutils.save_and_reraise_exception():
5014                     # Since this is a cast operation, log the failure for
5015                     # triage.
5016                     LOG.warning(_LW('Failed to deallocate port %(port_id)s '
5017                                     'for instance. Error: %(error)s'),
5018                                 {'port_id': port_id, 'error': ex},
5019                                 instance=instance)
5020 
5021     def _get_compute_info(self, context, host):
5022         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5023             context, host)
5024 
5025     @wrap_exception()
5026     def check_instance_shared_storage(self, ctxt, instance, data):
5027         """Check if the instance files are shared
5028 
5029         :param ctxt: security context
5030         :param instance: dict of instance data
5031         :param data: result of driver.check_instance_shared_storage_local
5032 
5033         Returns True if instance disks located on shared storage and
5034         False otherwise.
5035         """
5036         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5037 
5038     @wrap_exception()
5039     @wrap_instance_event(prefix='compute')
5040     @wrap_instance_fault
5041     def check_can_live_migrate_destination(self, ctxt, instance,
5042                                            block_migration, disk_over_commit):
5043         """Check if it is possible to execute live migration.
5044 
5045         This runs checks on the destination host, and then calls
5046         back to the source host to check the results.
5047 
5048         :param context: security context
5049         :param instance: dict of instance data
5050         :param block_migration: if true, prepare for block migration
5051                                 if None, calculate it in driver
5052         :param disk_over_commit: if true, allow disk over commit
5053                                  if None, ignore disk usage checking
5054         :returns: a dict containing migration info
5055         """
5056         return self._do_check_can_live_migrate_destination(ctxt, instance,
5057                                                             block_migration,
5058                                                             disk_over_commit)
5059 
5060     def _do_check_can_live_migrate_destination(self, ctxt, instance,
5061                                                block_migration,
5062                                                disk_over_commit):
5063         src_compute_info = obj_base.obj_to_primitive(
5064             self._get_compute_info(ctxt, instance.host))
5065         dst_compute_info = obj_base.obj_to_primitive(
5066             self._get_compute_info(ctxt, CONF.host))
5067         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5068             instance, src_compute_info, dst_compute_info,
5069             block_migration, disk_over_commit)
5070         LOG.debug('destination check data is %s', dest_check_data)
5071         try:
5072             migrate_data = self.compute_rpcapi.\
5073                                 check_can_live_migrate_source(ctxt, instance,
5074                                                               dest_check_data)
5075         finally:
5076             self.driver.cleanup_live_migration_destination_check(ctxt,
5077                     dest_check_data)
5078         return migrate_data
5079 
5080     @wrap_exception()
5081     @wrap_instance_event(prefix='compute')
5082     @wrap_instance_fault
5083     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5084         """Check if it is possible to execute live migration.
5085 
5086         This checks if the live migration can succeed, based on the
5087         results from check_can_live_migrate_destination.
5088 
5089         :param ctxt: security context
5090         :param instance: dict of instance data
5091         :param dest_check_data: result of check_can_live_migrate_destination
5092         :returns: a dict containing migration info
5093         """
5094         is_volume_backed = compute_utils.is_volume_backed_instance(ctxt,
5095                                                                       instance)
5096         got_migrate_data_object = isinstance(dest_check_data,
5097                                              migrate_data_obj.LiveMigrateData)
5098         if not got_migrate_data_object:
5099             dest_check_data = \
5100                 migrate_data_obj.LiveMigrateData.detect_implementation(
5101                     dest_check_data)
5102         dest_check_data.is_volume_backed = is_volume_backed
5103         block_device_info = self._get_instance_block_device_info(
5104                             ctxt, instance, refresh_conn_info=False)
5105         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5106                                                            dest_check_data,
5107                                                            block_device_info)
5108         if not got_migrate_data_object:
5109             result = result.to_legacy_dict()
5110         LOG.debug('source check data is %s', result)
5111         return result
5112 
5113     @wrap_exception()
5114     @wrap_instance_event(prefix='compute')
5115     @wrap_instance_fault
5116     def pre_live_migration(self, context, instance, block_migration, disk,
5117                            migrate_data):
5118         """Preparations for live migration at dest host.
5119 
5120         :param context: security context
5121         :param instance: dict of instance data
5122         :param block_migration: if true, prepare for block migration
5123         :param migrate_data: if not None, it is a dict which holds data
5124                              required for live migration without shared
5125                              storage.
5126 
5127         """
5128         LOG.debug('pre_live_migration data is %s', migrate_data)
5129         got_migrate_data_object = isinstance(migrate_data,
5130                                              migrate_data_obj.LiveMigrateData)
5131         if not got_migrate_data_object:
5132             migrate_data = \
5133                 migrate_data_obj.LiveMigrateData.detect_implementation(
5134                     migrate_data)
5135         block_device_info = self._get_instance_block_device_info(
5136                             context, instance, refresh_conn_info=True)
5137 
5138         network_info = self.network_api.get_instance_nw_info(context, instance)
5139         self._notify_about_instance_usage(
5140                      context, instance, "live_migration.pre.start",
5141                      network_info=network_info)
5142 
5143         migrate_data = self.driver.pre_live_migration(context,
5144                                        instance,
5145                                        block_device_info,
5146                                        network_info,
5147                                        disk,
5148                                        migrate_data)
5149         LOG.debug('driver pre_live_migration data is %s' % migrate_data)
5150 
5151         # NOTE(tr3buchet): setup networks on destination host
5152         self.network_api.setup_networks_on_host(context, instance,
5153                                                          self.host)
5154 
5155         # Creating filters to hypervisors and firewalls.
5156         # An example is that nova-instance-instance-xxx,
5157         # which is written to libvirt.xml(Check "virsh nwfilter-list")
5158         # This nwfilter is necessary on the destination host.
5159         # In addition, this method is creating filtering rule
5160         # onto destination host.
5161         self.driver.ensure_filtering_rules_for_instance(instance,
5162                                             network_info)
5163 
5164         self._notify_about_instance_usage(
5165                      context, instance, "live_migration.pre.end",
5166                      network_info=network_info)
5167 
5168         if not got_migrate_data_object and migrate_data:
5169             migrate_data = migrate_data.to_legacy_dict(
5170                 pre_migration_result=True)
5171             migrate_data = migrate_data['pre_live_migration_result']
5172         LOG.debug('pre_live_migration result data is %s', migrate_data)
5173         return migrate_data
5174 
5175     def _do_live_migration(self, context, dest, instance, block_migration,
5176                            migration, migrate_data):
5177         # NOTE(danms): We should enhance the RT to account for migrations
5178         # and use the status field to denote when the accounting has been
5179         # done on source/destination. For now, this is just here for status
5180         # reporting
5181         self._set_migration_status(migration, 'preparing')
5182 
5183         got_migrate_data_object = isinstance(migrate_data,
5184                                              migrate_data_obj.LiveMigrateData)
5185         if not got_migrate_data_object:
5186             migrate_data = \
5187                 migrate_data_obj.LiveMigrateData.detect_implementation(
5188                     migrate_data)
5189 
5190         try:
5191             if ('block_migration' in migrate_data and
5192                     migrate_data.block_migration):
5193                 block_device_info = self._get_instance_block_device_info(
5194                     context, instance)
5195                 disk = self.driver.get_instance_disk_info(
5196                     instance, block_device_info=block_device_info)
5197             else:
5198                 disk = None
5199 
5200             migrate_data = self.compute_rpcapi.pre_live_migration(
5201                 context, instance,
5202                 block_migration, disk, dest, migrate_data)
5203         except Exception:
5204             with excutils.save_and_reraise_exception():
5205                 LOG.exception(_LE('Pre live migration failed at %s'),
5206                               dest, instance=instance)
5207                 self._set_migration_status(migration, 'error')
5208                 self._rollback_live_migration(context, instance, dest,
5209                                               block_migration, migrate_data)
5210 
5211         self._set_migration_status(migration, 'running')
5212 
5213         if migrate_data:
5214             migrate_data.migration = migration
5215         LOG.debug('live_migration data is %s', migrate_data)
5216         try:
5217             self.driver.live_migration(context, instance, dest,
5218                                        self._post_live_migration,
5219                                        self._rollback_live_migration,
5220                                        block_migration, migrate_data)
5221         except Exception:
5222             # Executing live migration
5223             # live_migration might raises exceptions, but
5224             # nothing must be recovered in this version.
5225             LOG.exception(_LE('Live migration failed.'), instance=instance)
5226             with excutils.save_and_reraise_exception():
5227                 self._set_migration_status(migration, 'error')
5228 
5229     @wrap_exception()
5230     @wrap_instance_event(prefix='compute')
5231     @wrap_instance_fault
5232     def live_migration(self, context, dest, instance, block_migration,
5233                        migration, migrate_data):
5234         """Executing live migration.
5235 
5236         :param context: security context
5237         :param dest: destination host
5238         :param instance: a nova.objects.instance.Instance object
5239         :param block_migration: if true, prepare for block migration
5240         :param migration: an nova.objects.Migration object
5241         :param migrate_data: implementation specific params
5242 
5243         """
5244         self._set_migration_status(migration, 'queued')
5245 
5246         def dispatch_live_migration(*args, **kwargs):
5247             with self._live_migration_semaphore:
5248                 self._do_live_migration(*args, **kwargs)
5249 
5250         # NOTE(danms): We spawn here to return the RPC worker thread back to
5251         # the pool. Since what follows could take a really long time, we don't
5252         # want to tie up RPC workers.
5253         utils.spawn_n(dispatch_live_migration,
5254                       context, dest, instance,
5255                       block_migration, migration,
5256                       migrate_data)
5257 
5258     # TODO(tdurakov): migration_id is used since 4.12 rpc api version
5259     # remove migration_id parameter when the compute RPC version
5260     # is bumped to 5.x.
5261     @wrap_exception()
5262     @wrap_instance_event(prefix='compute')
5263     @wrap_instance_fault
5264     def live_migration_force_complete(self, context, instance,
5265                                       migration_id=None):
5266         """Force live migration to complete.
5267 
5268         :param context: Security context
5269         :param instance: The instance that is being migrated
5270         :param migration_id: ID of ongoing migration; is currently not used,
5271         and isn't removed for backward compatibility
5272         """
5273 
5274         self._notify_about_instance_usage(
5275             context, instance, 'live.migration.force.complete.start')
5276         self.driver.live_migration_force_complete(instance)
5277         self._notify_about_instance_usage(
5278             context, instance, 'live.migration.force.complete.end')
5279 
5280     @wrap_exception()
5281     @wrap_instance_event(prefix='compute')
5282     @wrap_instance_fault
5283     def live_migration_abort(self, context, instance, migration_id):
5284         """Abort an in-progress live migration.
5285 
5286         :param context: Security context
5287         :param instance: The instance that is being migrated
5288         :param migration_id: ID of in-progress live migration
5289 
5290         """
5291         migration = objects.Migration.get_by_id(context, migration_id)
5292         if migration.status != 'running':
5293             raise exception.InvalidMigrationState(migration_id=migration_id,
5294                     instance_uuid=instance.uuid,
5295                     state=migration.status,
5296                     method='abort live migration')
5297 
5298         self._notify_about_instance_usage(
5299             context, instance, 'live.migration.abort.start')
5300         self.driver.live_migration_abort(instance)
5301         self._notify_about_instance_usage(
5302             context, instance, 'live.migration.abort.end')
5303 
5304     def _live_migration_cleanup_flags(self, migrate_data):
5305         """Determine whether disks or instance path need to be cleaned up after
5306         live migration (at source on success, at destination on rollback)
5307 
5308         Block migration needs empty image at destination host before migration
5309         starts, so if any failure occurs, any empty images has to be deleted.
5310 
5311         Also Volume backed live migration w/o shared storage needs to delete
5312         newly created instance-xxx dir on the destination as a part of its
5313         rollback process
5314 
5315         :param migrate_data: implementation specific data
5316         :returns: (bool, bool) -- do_cleanup, destroy_disks
5317         """
5318         # NOTE(pkoniszewski): block migration specific params are set inside
5319         # migrate_data objects for drivers that expose block live migration
5320         # information (i.e. Libvirt and Xenapi). For other drivers cleanup is
5321         # not needed.
5322         is_shared_block_storage = True
5323         is_shared_instance_path = True
5324         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
5325             is_shared_block_storage = migrate_data.is_shared_block_storage
5326             is_shared_instance_path = migrate_data.is_shared_instance_path
5327         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
5328             is_shared_block_storage = not migrate_data.block_migration
5329             is_shared_instance_path = not migrate_data.block_migration
5330 
5331         # No instance booting at source host, but instance dir
5332         # must be deleted for preparing next block migration
5333         # must be deleted for preparing next live migration w/o shared storage
5334         do_cleanup = not is_shared_instance_path
5335         destroy_disks = not is_shared_block_storage
5336 
5337         return (do_cleanup, destroy_disks)
5338 
5339     @wrap_exception()
5340     @wrap_instance_fault
5341     def _post_live_migration(self, ctxt, instance,
5342                             dest, block_migration=False, migrate_data=None):
5343         """Post operations for live migration.
5344 
5345         This method is called from live_migration
5346         and mainly updating database record.
5347 
5348         :param ctxt: security context
5349         :param instance: instance dict
5350         :param dest: destination host
5351         :param block_migration: if true, prepare for block migration
5352         :param migrate_data: if not None, it is a dict which has data
5353         required for live migration without shared storage
5354 
5355         """
5356         LOG.info(_LI('_post_live_migration() is started..'),
5357                  instance=instance)
5358 
5359         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5360                 ctxt, instance.uuid)
5361 
5362         # Cleanup source host post live-migration
5363         block_device_info = self._get_instance_block_device_info(
5364                             ctxt, instance, bdms=bdms)
5365         self.driver.post_live_migration(ctxt, instance, block_device_info,
5366                                         migrate_data)
5367 
5368         # Detaching volumes.
5369         connector = self.driver.get_volume_connector(instance)
5370         for bdm in bdms:
5371             # NOTE(vish): We don't want to actually mark the volume
5372             #             detached, or delete the bdm, just remove the
5373             #             connection from this host.
5374 
5375             # remove the volume connection without detaching from hypervisor
5376             # because the instance is not running anymore on the current host
5377             if bdm.is_volume:
5378                 self.volume_api.terminate_connection(ctxt, bdm.volume_id,
5379                                                      connector)
5380 
5381         # Releasing vlan.
5382         # (not necessary in current implementation?)
5383 
5384         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
5385 
5386         self._notify_about_instance_usage(ctxt, instance,
5387                                           "live_migration._post.start",
5388                                           network_info=network_info)
5389         # Releasing security group ingress rule.
5390         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
5391                   instance=instance)
5392         self.driver.unfilter_instance(instance,
5393                                       network_info)
5394 
5395         migration = {'source_compute': self.host,
5396                      'dest_compute': dest, }
5397         self.network_api.migrate_instance_start(ctxt,
5398                                                 instance,
5399                                                 migration)
5400 
5401         destroy_vifs = False
5402         try:
5403             self.driver.post_live_migration_at_source(ctxt, instance,
5404                                                       network_info)
5405         except NotImplementedError as ex:
5406             LOG.debug(ex, instance=instance)
5407             # For all hypervisors other than libvirt, there is a possibility
5408             # they are unplugging networks from source node in the cleanup
5409             # method
5410             destroy_vifs = True
5411 
5412         # Define domain at destination host, without doing it,
5413         # pause/suspend/terminate do not work.
5414         self.compute_rpcapi.post_live_migration_at_destination(ctxt,
5415                 instance, block_migration, dest)
5416 
5417         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5418                 migrate_data)
5419 
5420         if do_cleanup:
5421             LOG.debug('Calling driver.cleanup from _post_live_migration',
5422                       instance=instance)
5423             self.driver.cleanup(ctxt, instance, network_info,
5424                                 destroy_disks=destroy_disks,
5425                                 migrate_data=migrate_data,
5426                                 destroy_vifs=destroy_vifs)
5427 
5428         self.instance_events.clear_events_for_instance(instance)
5429 
5430         # NOTE(timello): make sure we update available resources on source
5431         # host even before next periodic task.
5432         self.update_available_resource(ctxt)
5433 
5434         self._update_scheduler_instance_info(ctxt, instance)
5435         self._notify_about_instance_usage(ctxt, instance,
5436                                           "live_migration._post.end",
5437                                           network_info=network_info)
5438         LOG.info(_LI('Migrating instance to %s finished successfully.'),
5439                  dest, instance=instance)
5440         LOG.info(_LI("You may see the error \"libvirt: QEMU error: "
5441                      "Domain not found: no domain with matching name.\" "
5442                      "This error can be safely ignored."),
5443                  instance=instance)
5444 
5445         self._clean_instance_console_tokens(ctxt, instance)
5446         if migrate_data and migrate_data.obj_attr_is_set('migration'):
5447             migrate_data.migration.status = 'completed'
5448             migrate_data.migration.save()
5449 
5450     def _consoles_enabled(self):
5451         """Returns whether a console is enable."""
5452         return (CONF.vnc.enabled or CONF.spice.enabled or
5453                 CONF.rdp.enabled or CONF.serial_console.enabled or
5454                 CONF.mks.enabled)
5455 
5456     def _clean_instance_console_tokens(self, ctxt, instance):
5457         """Clean console tokens stored for an instance."""
5458         if self._consoles_enabled():
5459             if CONF.cells.enable:
5460                 self.cells_rpcapi.consoleauth_delete_tokens(
5461                     ctxt, instance.uuid)
5462             else:
5463                 self.consoleauth_rpcapi.delete_tokens_for_instance(
5464                     ctxt, instance.uuid)
5465 
5466     @wrap_exception()
5467     @wrap_instance_event(prefix='compute')
5468     @wrap_instance_fault
5469     def post_live_migration_at_destination(self, context, instance,
5470                                            block_migration):
5471         """Post operations for live migration .
5472 
5473         :param context: security context
5474         :param instance: Instance dict
5475         :param block_migration: if true, prepare for block migration
5476 
5477         """
5478         LOG.info(_LI('Post operation of migration started'),
5479                  instance=instance)
5480 
5481         # NOTE(tr3buchet): setup networks on destination host
5482         #                  this is called a second time because
5483         #                  multi_host does not create the bridge in
5484         #                  plug_vifs
5485         self.network_api.setup_networks_on_host(context, instance,
5486                                                          self.host)
5487         migration = {'source_compute': instance.host,
5488                      'dest_compute': self.host, }
5489         self.network_api.migrate_instance_finish(context,
5490                                                  instance,
5491                                                  migration)
5492 
5493         network_info = self.network_api.get_instance_nw_info(context, instance)
5494         self._notify_about_instance_usage(
5495                      context, instance, "live_migration.post.dest.start",
5496                      network_info=network_info)
5497         block_device_info = self._get_instance_block_device_info(context,
5498                                                                  instance)
5499 
5500         try:
5501             self.driver.post_live_migration_at_destination(
5502                 context, instance, network_info, block_migration,
5503                 block_device_info)
5504         except Exception:
5505             with excutils.save_and_reraise_exception():
5506                 instance.vm_state = vm_states.ERROR
5507                 LOG.error(_LE('Unexpected error during post live migration at '
5508                               'destination host.'), instance=instance)
5509         finally:
5510             # Restore instance state and update host
5511             current_power_state = self._get_power_state(context, instance)
5512             node_name = None
5513             prev_host = instance.host
5514             try:
5515                 compute_node = self._get_compute_info(context, self.host)
5516                 node_name = compute_node.hypervisor_hostname
5517             except exception.ComputeHostNotFound:
5518                 LOG.exception(_LE('Failed to get compute_info for %s'),
5519                               self.host)
5520             finally:
5521                 instance.host = self.host
5522                 instance.power_state = current_power_state
5523                 instance.task_state = None
5524                 instance.node = node_name
5525                 instance.progress = 0
5526                 instance.save(expected_task_state=task_states.MIGRATING)
5527 
5528         # NOTE(tr3buchet): tear down networks on source host
5529         self.network_api.setup_networks_on_host(context, instance,
5530                                                 prev_host, teardown=True)
5531         # NOTE(vish): this is necessary to update dhcp
5532         self.network_api.setup_networks_on_host(context, instance, self.host)
5533         self._notify_about_instance_usage(
5534                      context, instance, "live_migration.post.dest.end",
5535                      network_info=network_info)
5536 
5537     @wrap_exception()
5538     @wrap_instance_fault
5539     def _rollback_live_migration(self, context, instance,
5540                                  dest, block_migration, migrate_data=None,
5541                                  migration_status='error'):
5542         """Recovers Instance/volume state from migrating -> running.
5543 
5544         :param context: security context
5545         :param instance: nova.objects.instance.Instance object
5546         :param dest:
5547             This method is called from live migration src host.
5548             This param specifies destination host.
5549         :param block_migration: if true, prepare for block migration
5550         :param migrate_data:
5551             if not none, contains implementation specific data.
5552         :param migration_status:
5553             Contains the status we want to set for the migration object
5554 
5555         """
5556         instance.task_state = None
5557         instance.progress = 0
5558         instance.save(expected_task_state=[task_states.MIGRATING])
5559 
5560         if isinstance(migrate_data, dict):
5561             migration = migrate_data.pop('migration', None)
5562             migrate_data = \
5563                 migrate_data_obj.LiveMigrateData.detect_implementation(
5564                     migrate_data)
5565         elif (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
5566               migrate_data.obj_attr_is_set('migration')):
5567             migration = migrate_data.migration
5568         else:
5569             migration = None
5570 
5571         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
5572         self.network_api.setup_networks_on_host(context, instance, self.host)
5573 
5574         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5575                 context, instance.uuid)
5576         for bdm in bdms:
5577             if bdm.is_volume:
5578                 self.compute_rpcapi.remove_volume_connection(
5579                         context, instance, bdm.volume_id, dest)
5580 
5581         self._notify_about_instance_usage(context, instance,
5582                                           "live_migration._rollback.start")
5583 
5584         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5585                 migrate_data)
5586 
5587         if do_cleanup:
5588             self.compute_rpcapi.rollback_live_migration_at_destination(
5589                     context, instance, dest, destroy_disks=destroy_disks,
5590                     migrate_data=migrate_data)
5591         try:
5592             # NOTE(lyarwood): Refresh connection_info on the source host to
5593             # revert any changes made during pre_live_migration.
5594             self._get_instance_block_device_info(context, instance, bdms=bdms,
5595                                                  refresh_conn_info=True)
5596         except Exception:
5597             with excutils.save_and_reraise_exception():
5598                 LOG.exception(_LE('An error occurred refreshing the '
5599                     'connection_info of attached volumes while rolling back a '
5600                     'live migration attempt'), instance=instance)
5601         finally:
5602             # NOTE(lyarwood): Always notify that the rollback has ended and
5603             # update the migration status to reflect this.
5604             self._notify_about_instance_usage(context, instance,
5605                                               "live_migration._rollback.end")
5606             self._set_migration_status(migration, migration_status)
5607 
5608     @wrap_exception()
5609     @wrap_instance_event(prefix='compute')
5610     @wrap_instance_fault
5611     def rollback_live_migration_at_destination(self, context, instance,
5612                                                destroy_disks,
5613                                                migrate_data):
5614         """Cleaning up image directory that is created pre_live_migration.
5615 
5616         :param context: security context
5617         :param instance: a nova.objects.instance.Instance object sent over rpc
5618         """
5619         network_info = self.network_api.get_instance_nw_info(context, instance)
5620         self._notify_about_instance_usage(
5621                       context, instance, "live_migration.rollback.dest.start",
5622                       network_info=network_info)
5623         try:
5624             # NOTE(tr3buchet): tear down networks on destination host
5625             self.network_api.setup_networks_on_host(context, instance,
5626                                                     self.host, teardown=True)
5627         except Exception:
5628             with excutils.save_and_reraise_exception():
5629                 # NOTE(tdurakov): even if teardown networks fails driver
5630                 # should try to rollback live migration on destination.
5631                 LOG.exception(
5632                     _LE('An error occurred while deallocating network.'),
5633                     instance=instance)
5634         finally:
5635             # always run this even if setup_networks_on_host fails
5636             # NOTE(vish): The mapping is passed in so the driver can disconnect
5637             #             from remote volumes if necessary
5638             block_device_info = self._get_instance_block_device_info(context,
5639                                                                      instance)
5640             if isinstance(migrate_data, dict):
5641                 migrate_data = \
5642                     migrate_data_obj.LiveMigrateData.detect_implementation(
5643                         migrate_data)
5644             self.driver.rollback_live_migration_at_destination(
5645                 context, instance, network_info, block_device_info,
5646                 destroy_disks=destroy_disks, migrate_data=migrate_data)
5647 
5648         self._notify_about_instance_usage(
5649                         context, instance, "live_migration.rollback.dest.end",
5650                         network_info=network_info)
5651 
5652     @periodic_task.periodic_task(
5653         spacing=CONF.heal_instance_info_cache_interval)
5654     def _heal_instance_info_cache(self, context):
5655         """Called periodically.  On every call, try to update the
5656         info_cache's network information for another instance by
5657         calling to the network manager.
5658 
5659         This is implemented by keeping a cache of uuids of instances
5660         that live on this host.  On each call, we pop one off of a
5661         list, pull the DB record, and try the call to the network API.
5662         If anything errors don't fail, as it's possible the instance
5663         has been deleted, etc.
5664         """
5665         heal_interval = CONF.heal_instance_info_cache_interval
5666         if not heal_interval:
5667             return
5668 
5669         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
5670         instance = None
5671 
5672         LOG.debug('Starting heal instance info cache')
5673 
5674         if not instance_uuids:
5675             # The list of instances to heal is empty so rebuild it
5676             LOG.debug('Rebuilding the list of instances to heal')
5677             db_instances = objects.InstanceList.get_by_host(
5678                 context, self.host, expected_attrs=[], use_slave=True)
5679             for inst in db_instances:
5680                 # We don't want to refresh the cache for instances
5681                 # which are building or deleting so don't put them
5682                 # in the list. If they are building they will get
5683                 # added to the list next time we build it.
5684                 if (inst.vm_state == vm_states.BUILDING):
5685                     LOG.debug('Skipping network cache update for instance '
5686                               'because it is Building.', instance=inst)
5687                     continue
5688                 if (inst.task_state == task_states.DELETING):
5689                     LOG.debug('Skipping network cache update for instance '
5690                               'because it is being deleted.', instance=inst)
5691                     continue
5692 
5693                 if not instance:
5694                     # Save the first one we find so we don't
5695                     # have to get it again
5696                     instance = inst
5697                 else:
5698                     instance_uuids.append(inst['uuid'])
5699 
5700             self._instance_uuids_to_heal = instance_uuids
5701         else:
5702             # Find the next valid instance on the list
5703             while instance_uuids:
5704                 try:
5705                     inst = objects.Instance.get_by_uuid(
5706                             context, instance_uuids.pop(0),
5707                             expected_attrs=['system_metadata', 'info_cache',
5708                                             'flavor'],
5709                             use_slave=True)
5710                 except exception.InstanceNotFound:
5711                     # Instance is gone.  Try to grab another.
5712                     continue
5713 
5714                 # Check the instance hasn't been migrated
5715                 if inst.host != self.host:
5716                     LOG.debug('Skipping network cache update for instance '
5717                               'because it has been migrated to another '
5718                               'host.', instance=inst)
5719                 # Check the instance isn't being deleting
5720                 elif inst.task_state == task_states.DELETING:
5721                     LOG.debug('Skipping network cache update for instance '
5722                               'because it is being deleted.', instance=inst)
5723                 else:
5724                     instance = inst
5725                     break
5726 
5727         if instance:
5728             # We have an instance now to refresh
5729             try:
5730                 # Call to network API to get instance info.. this will
5731                 # force an update to the instance's info_cache
5732                 self.network_api.get_instance_nw_info(context, instance)
5733                 LOG.debug('Updated the network info_cache for instance',
5734                           instance=instance)
5735             except exception.InstanceNotFound:
5736                 # Instance is gone.
5737                 LOG.debug('Instance no longer exists. Unable to refresh',
5738                           instance=instance)
5739                 return
5740             except exception.InstanceInfoCacheNotFound:
5741                 # InstanceInfoCache is gone.
5742                 LOG.debug('InstanceInfoCache no longer exists. '
5743                           'Unable to refresh', instance=instance)
5744             except Exception:
5745                 LOG.error(_LE('An error occurred while refreshing the network '
5746                               'cache.'), instance=instance, exc_info=True)
5747         else:
5748             LOG.debug("Didn't find any instances for network info cache "
5749                       "update.")
5750 
5751     @periodic_task.periodic_task
5752     def _poll_rebooting_instances(self, context):
5753         if CONF.reboot_timeout > 0:
5754             filters = {'task_state':
5755                        [task_states.REBOOTING,
5756                         task_states.REBOOT_STARTED,
5757                         task_states.REBOOT_PENDING],
5758                        'host': self.host}
5759             rebooting = objects.InstanceList.get_by_filters(
5760                 context, filters, expected_attrs=[], use_slave=True)
5761 
5762             to_poll = []
5763             for instance in rebooting:
5764                 if timeutils.is_older_than(instance.updated_at,
5765                                            CONF.reboot_timeout):
5766                     to_poll.append(instance)
5767 
5768             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
5769 
5770     @periodic_task.periodic_task
5771     def _poll_rescued_instances(self, context):
5772         if CONF.rescue_timeout > 0:
5773             filters = {'vm_state': vm_states.RESCUED,
5774                        'host': self.host}
5775             rescued_instances = objects.InstanceList.get_by_filters(
5776                 context, filters, expected_attrs=["system_metadata"],
5777                 use_slave=True)
5778 
5779             to_unrescue = []
5780             for instance in rescued_instances:
5781                 if timeutils.is_older_than(instance.launched_at,
5782                                            CONF.rescue_timeout):
5783                     to_unrescue.append(instance)
5784 
5785             for instance in to_unrescue:
5786                 self.compute_api.unrescue(context, instance)
5787 
5788     @periodic_task.periodic_task
5789     def _poll_unconfirmed_resizes(self, context):
5790         if CONF.resize_confirm_window == 0:
5791             return
5792 
5793         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
5794                 context, CONF.resize_confirm_window, self.host,
5795                 use_slave=True)
5796 
5797         migrations_info = dict(migration_count=len(migrations),
5798                 confirm_window=CONF.resize_confirm_window)
5799 
5800         if migrations_info["migration_count"] > 0:
5801             LOG.info(_LI("Found %(migration_count)d unconfirmed migrations "
5802                          "older than %(confirm_window)d seconds"),
5803                      migrations_info)
5804 
5805         def _set_migration_to_error(migration, reason, **kwargs):
5806             LOG.warning(_LW("Setting migration %(migration_id)s to error: "
5807                          "%(reason)s"),
5808                      {'migration_id': migration['id'], 'reason': reason},
5809                      **kwargs)
5810             migration.status = 'error'
5811             with migration.obj_as_admin():
5812                 migration.save()
5813 
5814         for migration in migrations:
5815             instance_uuid = migration.instance_uuid
5816             LOG.info(_LI("Automatically confirming migration "
5817                          "%(migration_id)s for instance %(instance_uuid)s"),
5818                      {'migration_id': migration.id,
5819                       'instance_uuid': instance_uuid})
5820             expected_attrs = ['metadata', 'system_metadata']
5821             try:
5822                 instance = objects.Instance.get_by_uuid(context,
5823                             instance_uuid, expected_attrs=expected_attrs,
5824                             use_slave=True)
5825             except exception.InstanceNotFound:
5826                 reason = (_("Instance %s not found") %
5827                           instance_uuid)
5828                 _set_migration_to_error(migration, reason)
5829                 continue
5830             if instance.vm_state == vm_states.ERROR:
5831                 reason = _("In ERROR state")
5832                 _set_migration_to_error(migration, reason,
5833                                         instance=instance)
5834                 continue
5835             # race condition: The instance in DELETING state should not be
5836             # set the migration state to error, otherwise the instance in
5837             # to be deleted which is in RESIZED state
5838             # will not be able to confirm resize
5839             if instance.task_state in [task_states.DELETING,
5840                                        task_states.SOFT_DELETING]:
5841                 msg = ("Instance being deleted or soft deleted during resize "
5842                        "confirmation. Skipping.")
5843                 LOG.debug(msg, instance=instance)
5844                 continue
5845 
5846             # race condition: This condition is hit when this method is
5847             # called between the save of the migration record with a status of
5848             # finished and the save of the instance object with a state of
5849             # RESIZED. The migration record should not be set to error.
5850             if instance.task_state == task_states.RESIZE_FINISH:
5851                 msg = ("Instance still resizing during resize "
5852                        "confirmation. Skipping.")
5853                 LOG.debug(msg, instance=instance)
5854                 continue
5855 
5856             vm_state = instance.vm_state
5857             task_state = instance.task_state
5858             if vm_state != vm_states.RESIZED or task_state is not None:
5859                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
5860                            "RESIZED/None") %
5861                           {'vm_state': vm_state,
5862                            'task_state': task_state})
5863                 _set_migration_to_error(migration, reason,
5864                                         instance=instance)
5865                 continue
5866             try:
5867                 self.compute_api.confirm_resize(context, instance,
5868                                                 migration=migration)
5869             except Exception as e:
5870                 LOG.info(_LI("Error auto-confirming resize: %s. "
5871                              "Will retry later."),
5872                          e, instance=instance)
5873 
5874     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
5875     def _poll_shelved_instances(self, context):
5876 
5877         if CONF.shelved_offload_time <= 0:
5878             return
5879 
5880         filters = {'vm_state': vm_states.SHELVED,
5881                    'task_state': None,
5882                    'host': self.host}
5883         shelved_instances = objects.InstanceList.get_by_filters(
5884             context, filters=filters, expected_attrs=['system_metadata'],
5885             use_slave=True)
5886 
5887         to_gc = []
5888         for instance in shelved_instances:
5889             sys_meta = instance.system_metadata
5890             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
5891             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
5892                 to_gc.append(instance)
5893 
5894         for instance in to_gc:
5895             try:
5896                 instance.task_state = task_states.SHELVING_OFFLOADING
5897                 instance.save(expected_task_state=(None,))
5898                 self.shelve_offload_instance(context, instance,
5899                                              clean_shutdown=False)
5900             except Exception:
5901                 LOG.exception(_LE('Periodic task failed to offload instance.'),
5902                         instance=instance)
5903 
5904     @periodic_task.periodic_task
5905     def _instance_usage_audit(self, context):
5906         if not CONF.instance_usage_audit:
5907             return
5908 
5909         begin, end = utils.last_completed_audit_period()
5910         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
5911                                self.host):
5912             return
5913 
5914         instances = objects.InstanceList.get_active_by_window_joined(
5915             context, begin, end, host=self.host,
5916             expected_attrs=['system_metadata', 'info_cache', 'metadata',
5917                             'flavor'],
5918             use_slave=True)
5919         num_instances = len(instances)
5920         errors = 0
5921         successes = 0
5922         LOG.info(_LI("Running instance usage audit for"
5923                      " host %(host)s from %(begin_time)s to "
5924                      "%(end_time)s. %(number_instances)s"
5925                      " instances."),
5926                  {'host': self.host,
5927                   'begin_time': begin,
5928                   'end_time': end,
5929                   'number_instances': num_instances})
5930         start_time = time.time()
5931         task_log = objects.TaskLog(context)
5932         task_log.task_name = 'instance_usage_audit'
5933         task_log.period_beginning = begin
5934         task_log.period_ending = end
5935         task_log.host = self.host
5936         task_log.task_items = num_instances
5937         task_log.message = 'Instance usage audit started...'
5938         task_log.begin_task()
5939         for instance in instances:
5940             try:
5941                 compute_utils.notify_usage_exists(
5942                     self.notifier, context, instance,
5943                     ignore_missing_network_data=False)
5944                 successes += 1
5945             except Exception:
5946                 LOG.exception(_LE('Failed to generate usage '
5947                                   'audit for instance '
5948                                   'on host %s'), self.host,
5949                               instance=instance)
5950                 errors += 1
5951         task_log.errors = errors
5952         task_log.message = (
5953             'Instance usage audit ran for host %s, %s instances in %s seconds.'
5954             % (self.host, num_instances, time.time() - start_time))
5955         task_log.end_task()
5956 
5957     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
5958     def _poll_bandwidth_usage(self, context):
5959 
5960         if not self._bw_usage_supported:
5961             return
5962 
5963         prev_time, start_time = utils.last_completed_audit_period()
5964 
5965         curr_time = time.time()
5966         if (curr_time - self._last_bw_usage_poll >
5967                 CONF.bandwidth_poll_interval):
5968             self._last_bw_usage_poll = curr_time
5969             LOG.info(_LI("Updating bandwidth usage cache"))
5970             cells_update_interval = CONF.cells.bandwidth_update_interval
5971             if (cells_update_interval > 0 and
5972                    curr_time - self._last_bw_usage_cell_update >
5973                            cells_update_interval):
5974                 self._last_bw_usage_cell_update = curr_time
5975                 update_cells = True
5976             else:
5977                 update_cells = False
5978 
5979             instances = objects.InstanceList.get_by_host(context,
5980                                                               self.host,
5981                                                               use_slave=True)
5982             try:
5983                 bw_counters = self.driver.get_all_bw_counters(instances)
5984             except NotImplementedError:
5985                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
5986                 # implemented yet.  If they don't it doesn't break anything,
5987                 # they just don't get the info in the usage events.
5988                 # NOTE(PhilDay): Record that its not supported so we can
5989                 # skip fast on future calls rather than waste effort getting
5990                 # the list of instances.
5991                 LOG.info(_LI("Bandwidth usage not supported by "
5992                              "hypervisor."))
5993                 self._bw_usage_supported = False
5994                 return
5995 
5996             refreshed = timeutils.utcnow()
5997             for bw_ctr in bw_counters:
5998                 # Allow switching of greenthreads between queries.
5999                 greenthread.sleep(0)
6000                 bw_in = 0
6001                 bw_out = 0
6002                 last_ctr_in = None
6003                 last_ctr_out = None
6004                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6005                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6006                     start_period=start_time, use_slave=True)
6007                 if usage:
6008                     bw_in = usage.bw_in
6009                     bw_out = usage.bw_out
6010                     last_ctr_in = usage.last_ctr_in
6011                     last_ctr_out = usage.last_ctr_out
6012                 else:
6013                     usage = (objects.BandwidthUsage.
6014                              get_by_instance_uuid_and_mac(
6015                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6016                         start_period=prev_time, use_slave=True))
6017                     if usage:
6018                         last_ctr_in = usage.last_ctr_in
6019                         last_ctr_out = usage.last_ctr_out
6020 
6021                 if last_ctr_in is not None:
6022                     if bw_ctr['bw_in'] < last_ctr_in:
6023                         # counter rollover
6024                         bw_in += bw_ctr['bw_in']
6025                     else:
6026                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6027 
6028                 if last_ctr_out is not None:
6029                     if bw_ctr['bw_out'] < last_ctr_out:
6030                         # counter rollover
6031                         bw_out += bw_ctr['bw_out']
6032                     else:
6033                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6034 
6035                 objects.BandwidthUsage(context=context).create(
6036                                               bw_ctr['uuid'],
6037                                               bw_ctr['mac_address'],
6038                                               bw_in,
6039                                               bw_out,
6040                                               bw_ctr['bw_in'],
6041                                               bw_ctr['bw_out'],
6042                                               start_period=start_time,
6043                                               last_refreshed=refreshed,
6044                                               update_cells=update_cells)
6045 
6046     def _get_host_volume_bdms(self, context, use_slave=False):
6047         """Return all block device mappings on a compute host."""
6048         compute_host_bdms = []
6049         instances = objects.InstanceList.get_by_host(context, self.host,
6050             use_slave=use_slave)
6051         for instance in instances:
6052             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6053                     context, instance.uuid, use_slave=use_slave)
6054             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6055             compute_host_bdms.append(dict(instance=instance,
6056                                           instance_bdms=instance_bdms))
6057 
6058         return compute_host_bdms
6059 
6060     def _update_volume_usage_cache(self, context, vol_usages):
6061         """Updates the volume usage cache table with a list of stats."""
6062         for usage in vol_usages:
6063             # Allow switching of greenthreads between queries.
6064             greenthread.sleep(0)
6065             vol_usage = objects.VolumeUsage(context)
6066             vol_usage.volume_id = usage['volume']
6067             vol_usage.instance_uuid = usage['instance'].uuid
6068             vol_usage.project_id = usage['instance'].project_id
6069             vol_usage.user_id = usage['instance'].user_id
6070             vol_usage.availability_zone = usage['instance'].availability_zone
6071             vol_usage.curr_reads = usage['rd_req']
6072             vol_usage.curr_read_bytes = usage['rd_bytes']
6073             vol_usage.curr_writes = usage['wr_req']
6074             vol_usage.curr_write_bytes = usage['wr_bytes']
6075             vol_usage.save()
6076             self.notifier.info(context, 'volume.usage',
6077                                compute_utils.usage_volume_info(vol_usage))
6078 
6079     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
6080     def _poll_volume_usage(self, context):
6081         if CONF.volume_usage_poll_interval == 0:
6082             return
6083 
6084         compute_host_bdms = self._get_host_volume_bdms(context,
6085                                                        use_slave=True)
6086         if not compute_host_bdms:
6087             return
6088 
6089         LOG.debug("Updating volume usage cache")
6090         try:
6091             vol_usages = self.driver.get_all_volume_usage(context,
6092                                                           compute_host_bdms)
6093         except NotImplementedError:
6094             return
6095 
6096         self._update_volume_usage_cache(context, vol_usages)
6097 
6098     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
6099                                  run_immediately=True)
6100     def _sync_power_states(self, context):
6101         """Align power states between the database and the hypervisor.
6102 
6103         To sync power state data we make a DB call to get the number of
6104         virtual machines known by the hypervisor and if the number matches the
6105         number of virtual machines known by the database, we proceed in a lazy
6106         loop, one database record at a time, checking if the hypervisor has the
6107         same power state as is in the database.
6108         """
6109         db_instances = objects.InstanceList.get_by_host(context, self.host,
6110                                                         expected_attrs=[],
6111                                                         use_slave=True)
6112 
6113         num_vm_instances = self.driver.get_num_instances()
6114         num_db_instances = len(db_instances)
6115 
6116         if num_vm_instances != num_db_instances:
6117             LOG.warning(_LW("While synchronizing instance power states, found "
6118                             "%(num_db_instances)s instances in the database "
6119                             "and %(num_vm_instances)s instances on the "
6120                             "hypervisor."),
6121                         {'num_db_instances': num_db_instances,
6122                          'num_vm_instances': num_vm_instances})
6123 
6124         def _sync(db_instance):
6125             # NOTE(melwitt): This must be synchronized as we query state from
6126             #                two separate sources, the driver and the database.
6127             #                They are set (in stop_instance) and read, in sync.
6128             @utils.synchronized(db_instance.uuid)
6129             def query_driver_power_state_and_sync():
6130                 self._query_driver_power_state_and_sync(context, db_instance)
6131 
6132             try:
6133                 query_driver_power_state_and_sync()
6134             except Exception:
6135                 LOG.exception(_LE("Periodic sync_power_state task had an "
6136                                   "error while processing an instance."),
6137                               instance=db_instance)
6138 
6139             self._syncs_in_progress.pop(db_instance.uuid)
6140 
6141         for db_instance in db_instances:
6142             # process syncs asynchronously - don't want instance locking to
6143             # block entire periodic task thread
6144             uuid = db_instance.uuid
6145             if uuid in self._syncs_in_progress:
6146                 LOG.debug('Sync already in progress for %s' % uuid)
6147             else:
6148                 LOG.debug('Triggering sync for uuid %s' % uuid)
6149                 self._syncs_in_progress[uuid] = True
6150                 self._sync_power_pool.spawn_n(_sync, db_instance)
6151 
6152     def _query_driver_power_state_and_sync(self, context, db_instance):
6153         if db_instance.task_state is not None:
6154             LOG.info(_LI("During sync_power_state the instance has a "
6155                          "pending task (%(task)s). Skip."),
6156                      {'task': db_instance.task_state}, instance=db_instance)
6157             return
6158         # No pending tasks. Now try to figure out the real vm_power_state.
6159         try:
6160             vm_instance = self.driver.get_info(db_instance)
6161             vm_power_state = vm_instance.state
6162         except exception.InstanceNotFound:
6163             vm_power_state = power_state.NOSTATE
6164         # Note(maoy): the above get_info call might take a long time,
6165         # for example, because of a broken libvirt driver.
6166         try:
6167             self._sync_instance_power_state(context,
6168                                             db_instance,
6169                                             vm_power_state,
6170                                             use_slave=True)
6171         except exception.InstanceNotFound:
6172             # NOTE(hanlind): If the instance gets deleted during sync,
6173             # silently ignore.
6174             pass
6175 
6176     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
6177                                    use_slave=False):
6178         """Align instance power state between the database and hypervisor.
6179 
6180         If the instance is not found on the hypervisor, but is in the database,
6181         then a stop() API will be called on the instance.
6182         """
6183 
6184         # We re-query the DB to get the latest instance info to minimize
6185         # (not eliminate) race condition.
6186         db_instance.refresh(use_slave=use_slave)
6187         db_power_state = db_instance.power_state
6188         vm_state = db_instance.vm_state
6189 
6190         if self.host != db_instance.host:
6191             # on the sending end of nova-compute _sync_power_state
6192             # may have yielded to the greenthread performing a live
6193             # migration; this in turn has changed the resident-host
6194             # for the VM; However, the instance is still active, it
6195             # is just in the process of migrating to another host.
6196             # This implies that the compute source must relinquish
6197             # control to the compute destination.
6198             LOG.info(_LI("During the sync_power process the "
6199                          "instance has moved from "
6200                          "host %(src)s to host %(dst)s"),
6201                      {'src': db_instance.host,
6202                       'dst': self.host},
6203                      instance=db_instance)
6204             return
6205         elif db_instance.task_state is not None:
6206             # on the receiving end of nova-compute, it could happen
6207             # that the DB instance already report the new resident
6208             # but the actual VM has not showed up on the hypervisor
6209             # yet. In this case, let's allow the loop to continue
6210             # and run the state sync in a later round
6211             LOG.info(_LI("During sync_power_state the instance has a "
6212                          "pending task (%(task)s). Skip."),
6213                      {'task': db_instance.task_state},
6214                      instance=db_instance)
6215             return
6216 
6217         orig_db_power_state = db_power_state
6218         if vm_power_state != db_power_state:
6219             LOG.info(_LI('During _sync_instance_power_state the DB '
6220                          'power_state (%(db_power_state)s) does not match '
6221                          'the vm_power_state from the hypervisor '
6222                          '(%(vm_power_state)s). Updating power_state in the '
6223                          'DB to match the hypervisor.'),
6224                      {'db_power_state': db_power_state,
6225                       'vm_power_state': vm_power_state},
6226                      instance=db_instance)
6227             # power_state is always updated from hypervisor to db
6228             db_instance.power_state = vm_power_state
6229             db_instance.save()
6230             db_power_state = vm_power_state
6231 
6232         # Note(maoy): Now resolve the discrepancy between vm_state and
6233         # vm_power_state. We go through all possible vm_states.
6234         if vm_state in (vm_states.BUILDING,
6235                         vm_states.RESCUED,
6236                         vm_states.RESIZED,
6237                         vm_states.SUSPENDED,
6238                         vm_states.ERROR):
6239             # TODO(maoy): we ignore these vm_state for now.
6240             pass
6241         elif vm_state == vm_states.ACTIVE:
6242             # The only rational power state should be RUNNING
6243             if vm_power_state in (power_state.SHUTDOWN,
6244                                   power_state.CRASHED):
6245                 LOG.warning(_LW("Instance shutdown by itself. Calling the "
6246                                 "stop API. Current vm_state: %(vm_state)s, "
6247                                 "current task_state: %(task_state)s, "
6248                                 "original DB power_state: %(db_power_state)s, "
6249                                 "current VM power_state: %(vm_power_state)s"),
6250                             {'vm_state': vm_state,
6251                              'task_state': db_instance.task_state,
6252                              'db_power_state': orig_db_power_state,
6253                              'vm_power_state': vm_power_state},
6254                             instance=db_instance)
6255                 try:
6256                     # Note(maoy): here we call the API instead of
6257                     # brutally updating the vm_state in the database
6258                     # to allow all the hooks and checks to be performed.
6259                     if db_instance.shutdown_terminate:
6260                         self.compute_api.delete(context, db_instance)
6261                     else:
6262                         self.compute_api.stop(context, db_instance)
6263                 except Exception:
6264                     # Note(maoy): there is no need to propagate the error
6265                     # because the same power_state will be retrieved next
6266                     # time and retried.
6267                     # For example, there might be another task scheduled.
6268                     LOG.exception(_LE("error during stop() in "
6269                                       "sync_power_state."),
6270                                   instance=db_instance)
6271             elif vm_power_state == power_state.SUSPENDED:
6272                 LOG.warning(_LW("Instance is suspended unexpectedly. Calling "
6273                                 "the stop API."), instance=db_instance)
6274                 try:
6275                     self.compute_api.stop(context, db_instance)
6276                 except Exception:
6277                     LOG.exception(_LE("error during stop() in "
6278                                       "sync_power_state."),
6279                                   instance=db_instance)
6280             elif vm_power_state == power_state.PAUSED:
6281                 # Note(maoy): a VM may get into the paused state not only
6282                 # because the user request via API calls, but also
6283                 # due to (temporary) external instrumentations.
6284                 # Before the virt layer can reliably report the reason,
6285                 # we simply ignore the state discrepancy. In many cases,
6286                 # the VM state will go back to running after the external
6287                 # instrumentation is done. See bug 1097806 for details.
6288                 LOG.warning(_LW("Instance is paused unexpectedly. Ignore."),
6289                             instance=db_instance)
6290             elif vm_power_state == power_state.NOSTATE:
6291                 # Occasionally, depending on the status of the hypervisor,
6292                 # which could be restarting for example, an instance may
6293                 # not be found.  Therefore just log the condition.
6294                 LOG.warning(_LW("Instance is unexpectedly not found. Ignore."),
6295                             instance=db_instance)
6296         elif vm_state == vm_states.STOPPED:
6297             if vm_power_state not in (power_state.NOSTATE,
6298                                       power_state.SHUTDOWN,
6299                                       power_state.CRASHED):
6300                 LOG.warning(_LW("Instance is not stopped. Calling "
6301                                 "the stop API. Current vm_state: %(vm_state)s,"
6302                                 " current task_state: %(task_state)s, "
6303                                 "original DB power_state: %(db_power_state)s, "
6304                                 "current VM power_state: %(vm_power_state)s"),
6305                             {'vm_state': vm_state,
6306                              'task_state': db_instance.task_state,
6307                              'db_power_state': orig_db_power_state,
6308                              'vm_power_state': vm_power_state},
6309                             instance=db_instance)
6310                 try:
6311                     # NOTE(russellb) Force the stop, because normally the
6312                     # compute API would not allow an attempt to stop a stopped
6313                     # instance.
6314                     self.compute_api.force_stop(context, db_instance)
6315                 except Exception:
6316                     LOG.exception(_LE("error during stop() in "
6317                                       "sync_power_state."),
6318                                   instance=db_instance)
6319         elif vm_state == vm_states.PAUSED:
6320             if vm_power_state in (power_state.SHUTDOWN,
6321                                   power_state.CRASHED):
6322                 LOG.warning(_LW("Paused instance shutdown by itself. Calling "
6323                                 "the stop API."), instance=db_instance)
6324                 try:
6325                     self.compute_api.force_stop(context, db_instance)
6326                 except Exception:
6327                     LOG.exception(_LE("error during stop() in "
6328                                       "sync_power_state."),
6329                                   instance=db_instance)
6330         elif vm_state in (vm_states.SOFT_DELETED,
6331                           vm_states.DELETED):
6332             if vm_power_state not in (power_state.NOSTATE,
6333                                       power_state.SHUTDOWN):
6334                 # Note(maoy): this should be taken care of periodically in
6335                 # _cleanup_running_deleted_instances().
6336                 LOG.warning(_LW("Instance is not (soft-)deleted."),
6337                             instance=db_instance)
6338 
6339     @periodic_task.periodic_task
6340     def _reclaim_queued_deletes(self, context):
6341         """Reclaim instances that are queued for deletion."""
6342         interval = CONF.reclaim_instance_interval
6343         if interval <= 0:
6344             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
6345             return
6346 
6347         # TODO(comstud, jichenjc): Dummy quota object for now See bug 1296414.
6348         # The only case that the quota might be inconsistent is
6349         # the compute node died between set instance state to SOFT_DELETED
6350         # and quota commit to DB. When compute node starts again
6351         # it will have no idea the reservation is committed or not or even
6352         # expired, since it's a rare case, so marked as todo.
6353         quotas = objects.Quotas.from_reservations(context, None)
6354 
6355         filters = {'vm_state': vm_states.SOFT_DELETED,
6356                    'task_state': None,
6357                    'host': self.host}
6358         instances = objects.InstanceList.get_by_filters(
6359             context, filters,
6360             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
6361             use_slave=True)
6362         for instance in instances:
6363             if self._deleted_old_enough(instance, interval):
6364                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6365                         context, instance.uuid)
6366                 LOG.info(_LI('Reclaiming deleted instance'), instance=instance)
6367                 try:
6368                     self._delete_instance(context, instance, bdms, quotas)
6369                 except Exception as e:
6370                     LOG.warning(_LW("Periodic reclaim failed to delete "
6371                                     "instance: %s"),
6372                                 e, instance=instance)
6373 
6374     def update_available_resource_for_node(self, context, nodename):
6375 
6376         rt = self._get_resource_tracker(nodename)
6377         try:
6378             rt.update_available_resource(context)
6379         except exception.ComputeHostNotFound:
6380             # NOTE(comstud): We can get to this case if a node was
6381             # marked 'deleted' in the DB and then re-added with a
6382             # different auto-increment id. The cached resource
6383             # tracker tried to update a deleted record and failed.
6384             # Don't add this resource tracker to the new dict, so
6385             # that this will resolve itself on the next run.
6386             LOG.info(_LI("Compute node '%s' not found in "
6387                          "update_available_resource."), nodename)
6388             self._resource_tracker_dict.pop(nodename, None)
6389             return
6390         except Exception:
6391             LOG.exception(_LE("Error updating resources for node "
6392                           "%(node)s."), {'node': nodename})
6393 
6394         # NOTE(comstud): Replace the RT cache before looping through
6395         # compute nodes to delete below, as we can end up doing greenthread
6396         # switches there. Best to have everyone using the newest cache
6397         # ASAP.
6398         self._resource_tracker_dict[nodename] = rt
6399 
6400     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
6401     def update_available_resource(self, context):
6402         """See driver.get_available_resource()
6403 
6404         Periodic process that keeps that the compute host's understanding of
6405         resource availability and usage in sync with the underlying hypervisor.
6406 
6407         :param context: security context
6408         """
6409 
6410         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
6411                                                             use_slave=True)
6412         nodenames = set(self.driver.get_available_nodes())
6413         for nodename in nodenames:
6414             self.update_available_resource_for_node(context, nodename)
6415 
6416         self._resource_tracker_dict = {
6417             k: v for k, v in self._resource_tracker_dict.items()
6418             if k in nodenames}
6419 
6420         # Delete orphan compute node not reported by driver but still in db
6421         for cn in compute_nodes_in_db:
6422             if cn.hypervisor_hostname not in nodenames:
6423                 LOG.info(_LI("Deleting orphan compute node %s"), cn.id)
6424                 cn.destroy()
6425 
6426     def _get_compute_nodes_in_db(self, context, use_slave=False):
6427         try:
6428             return objects.ComputeNodeList.get_all_by_host(context, self.host,
6429                                                            use_slave=use_slave)
6430         except exception.NotFound:
6431             LOG.error(_LE("No compute node record for host %s"), self.host)
6432             return []
6433 
6434     @periodic_task.periodic_task(
6435         spacing=CONF.running_deleted_instance_poll_interval)
6436     def _cleanup_running_deleted_instances(self, context):
6437         """Cleanup any instances which are erroneously still running after
6438         having been deleted.
6439 
6440         Valid actions to take are:
6441 
6442             1. noop - do nothing
6443             2. log - log which instances are erroneously running
6444             3. reap - shutdown and cleanup any erroneously running instances
6445             4. shutdown - power off *and disable* any erroneously running
6446                           instances
6447 
6448         The use-case for this cleanup task is: for various reasons, it may be
6449         possible for the database to show an instance as deleted but for that
6450         instance to still be running on a host machine (see bug
6451         https://bugs.launchpad.net/nova/+bug/911366).
6452 
6453         This cleanup task is a cross-hypervisor utility for finding these
6454         zombied instances and either logging the discrepancy (likely what you
6455         should do in production), or automatically reaping the instances (more
6456         appropriate for dev environments).
6457         """
6458         action = CONF.running_deleted_instance_action
6459 
6460         if action == "noop":
6461             return
6462 
6463         # NOTE(sirp): admin contexts don't ordinarily return deleted records
6464         with utils.temporary_mutation(context, read_deleted="yes"):
6465             for instance in self._running_deleted_instances(context):
6466                 if action == "log":
6467                     LOG.warning(_LW("Detected instance with name label "
6468                                     "'%s' which is marked as "
6469                                     "DELETED but still present on host."),
6470                                 instance.name, instance=instance)
6471 
6472                 elif action == 'shutdown':
6473                     LOG.info(_LI("Powering off instance with name label "
6474                                  "'%s' which is marked as "
6475                                  "DELETED but still present on host."),
6476                              instance.name, instance=instance)
6477                     try:
6478                         try:
6479                             # disable starting the instance
6480                             self.driver.set_bootable(instance, False)
6481                         except NotImplementedError:
6482                             LOG.debug("set_bootable is not implemented "
6483                                       "for the current driver")
6484                         # and power it off
6485                         self.driver.power_off(instance)
6486                     except Exception:
6487                         msg = _LW("Failed to power off instance")
6488                         LOG.warning(msg, instance=instance, exc_info=True)
6489 
6490                 elif action == 'reap':
6491                     LOG.info(_LI("Destroying instance with name label "
6492                                  "'%s' which is marked as "
6493                                  "DELETED but still present on host."),
6494                              instance.name, instance=instance)
6495                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6496                         context, instance.uuid, use_slave=True)
6497                     self.instance_events.clear_events_for_instance(instance)
6498                     try:
6499                         self._shutdown_instance(context, instance, bdms,
6500                                                 notify=False)
6501                         self._cleanup_volumes(context, instance.uuid, bdms)
6502                     except Exception as e:
6503                         LOG.warning(_LW("Periodic cleanup failed to delete "
6504                                         "instance: %s"),
6505                                     e, instance=instance)
6506                 else:
6507                     raise Exception(_("Unrecognized value '%s'"
6508                                       " for CONF.running_deleted_"
6509                                       "instance_action") % action)
6510 
6511     def _running_deleted_instances(self, context):
6512         """Returns a list of instances nova thinks is deleted,
6513         but the hypervisor thinks is still running.
6514         """
6515         timeout = CONF.running_deleted_instance_timeout
6516         filters = {'deleted': True,
6517                    'soft_deleted': False,
6518                    'host': self.host}
6519         instances = self._get_instances_on_driver(context, filters)
6520         return [i for i in instances if self._deleted_old_enough(i, timeout)]
6521 
6522     def _deleted_old_enough(self, instance, timeout):
6523         deleted_at = instance.deleted_at
6524         if deleted_at:
6525             deleted_at = deleted_at.replace(tzinfo=None)
6526         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
6527 
6528     @contextlib.contextmanager
6529     def _error_out_instance_on_exception(self, context, instance,
6530                                          quotas=None,
6531                                          instance_state=vm_states.ACTIVE):
6532         instance_uuid = instance.uuid
6533         try:
6534             yield
6535         except NotImplementedError as error:
6536             with excutils.save_and_reraise_exception():
6537                 if quotas:
6538                     quotas.rollback()
6539                 LOG.info(_LI("Setting instance back to %(state)s after: "
6540                              "%(error)s"),
6541                          {'state': instance_state, 'error': error},
6542                          instance_uuid=instance_uuid)
6543                 self._instance_update(context, instance,
6544                                       vm_state=instance_state,
6545                                       task_state=None)
6546         except exception.InstanceFaultRollback as error:
6547             if quotas:
6548                 quotas.rollback()
6549             LOG.info(_LI("Setting instance back to ACTIVE after: %s"),
6550                      error, instance_uuid=instance_uuid)
6551             self._instance_update(context, instance,
6552                                   vm_state=vm_states.ACTIVE,
6553                                   task_state=None)
6554             raise error.inner_exception
6555         except Exception:
6556             LOG.exception(_LE('Setting instance vm_state to ERROR'),
6557                           instance_uuid=instance_uuid)
6558             with excutils.save_and_reraise_exception():
6559                 if quotas:
6560                     quotas.rollback()
6561                 self._set_instance_obj_error_state(context, instance)
6562 
6563     @wrap_exception()
6564     def add_aggregate_host(self, context, aggregate, host, slave_info):
6565         """Notify hypervisor of change (for hypervisor pools)."""
6566         try:
6567             self.driver.add_to_aggregate(context, aggregate, host,
6568                                          slave_info=slave_info)
6569         except NotImplementedError:
6570             LOG.debug('Hypervisor driver does not support '
6571                       'add_aggregate_host')
6572         except exception.AggregateError:
6573             with excutils.save_and_reraise_exception():
6574                 self.driver.undo_aggregate_operation(
6575                                     context,
6576                                     aggregate.delete_host,
6577                                     aggregate, host)
6578 
6579     @wrap_exception()
6580     def remove_aggregate_host(self, context, host, slave_info, aggregate):
6581         """Removes a host from a physical hypervisor pool."""
6582         try:
6583             self.driver.remove_from_aggregate(context, aggregate, host,
6584                                               slave_info=slave_info)
6585         except NotImplementedError:
6586             LOG.debug('Hypervisor driver does not support '
6587                       'remove_aggregate_host')
6588         except (exception.AggregateError,
6589                 exception.InvalidAggregateAction) as e:
6590             with excutils.save_and_reraise_exception():
6591                 self.driver.undo_aggregate_operation(
6592                                     context,
6593                                     aggregate.add_host,
6594                                     aggregate, host,
6595                                     isinstance(e, exception.AggregateError))
6596 
6597     def _process_instance_event(self, instance, event):
6598         _event = self.instance_events.pop_instance_event(instance, event)
6599         if _event:
6600             LOG.debug('Processing event %(event)s',
6601                       {'event': event.key}, instance=instance)
6602             _event.send(event)
6603 
6604     def _process_instance_vif_deleted_event(self, context, instance,
6605                                             deleted_vif_id):
6606         # If an attached port is deleted by neutron, it needs to
6607         # be detached from the instance.
6608         # And info cache needs to be updated.
6609         network_info = instance.info_cache.network_info
6610         for index, vif in enumerate(network_info):
6611             if vif['id'] == deleted_vif_id:
6612                 LOG.info(_LI('Neutron deleted interface %(intf)s; '
6613                              'detaching it from the instance and '
6614                              'deleting it from the info cache'),
6615                          {'intf': vif['id']},
6616                          instance=instance)
6617                 del network_info[index]
6618                 base_net_api.update_instance_cache_with_nw_info(
6619                                  self.network_api, context,
6620                                  instance,
6621                                  nw_info=network_info)
6622                 try:
6623                     self.driver.detach_interface(instance, vif)
6624                 except exception.NovaException as ex:
6625                     LOG.warning(_LW("Detach interface failed, "
6626                                     "port_id=%(port_id)s, reason: %(msg)s"),
6627                                 {'port_id': deleted_vif_id, 'msg': ex},
6628                                 instance=instance)
6629                 break
6630 
6631     @wrap_exception()
6632     def external_instance_event(self, context, instances, events):
6633         # NOTE(danms): Some event types are handled by the manager, such
6634         # as when we're asked to update the instance's info_cache. If it's
6635         # not one of those, look for some thread(s) waiting for the event and
6636         # unblock them if so.
6637         for event in events:
6638             instance = [inst for inst in instances
6639                         if inst.uuid == event.instance_uuid][0]
6640             LOG.debug('Received event %(event)s',
6641                       {'event': event.key},
6642                       instance=instance)
6643             if event.name == 'network-changed':
6644                 try:
6645                     self.network_api.get_instance_nw_info(context, instance)
6646                 except exception.NotFound as e:
6647                     LOG.info(_LI('Failed to process external instance event '
6648                                  '%(event)s due to: %(error)s'),
6649                              {'event': event.key, 'error': six.text_type(e)},
6650                              instance=instance)
6651             elif event.name == 'network-vif-deleted':
6652                 self._process_instance_vif_deleted_event(context,
6653                                                          instance,
6654                                                          event.tag)
6655             else:
6656                 self._process_instance_event(instance, event)
6657 
6658     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
6659                                  external_process_ok=True)
6660     def _run_image_cache_manager_pass(self, context):
6661         """Run a single pass of the image cache manager."""
6662 
6663         if not self.driver.capabilities["has_imagecache"]:
6664             return
6665 
6666         # Determine what other nodes use this storage
6667         storage_users.register_storage_use(CONF.instances_path, CONF.host)
6668         nodes = storage_users.get_storage_users(CONF.instances_path)
6669 
6670         # Filter all_instances to only include those nodes which share this
6671         # storage path.
6672         # TODO(mikal): this should be further refactored so that the cache
6673         # cleanup code doesn't know what those instances are, just a remote
6674         # count, and then this logic should be pushed up the stack.
6675         filters = {'deleted': False,
6676                    'soft_deleted': True,
6677                    'host': nodes}
6678         filtered_instances = objects.InstanceList.get_by_filters(context,
6679                                  filters, expected_attrs=[], use_slave=True)
6680 
6681         self.driver.manage_image_cache(context, filtered_instances)
6682 
6683     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6684     def _run_pending_deletes(self, context):
6685         """Retry any pending instance file deletes."""
6686         LOG.debug('Cleaning up deleted instances')
6687         filters = {'deleted': True,
6688                    'soft_deleted': False,
6689                    'host': CONF.host,
6690                    'cleaned': False}
6691         attrs = ['info_cache', 'security_groups', 'system_metadata']
6692         with utils.temporary_mutation(context, read_deleted='yes'):
6693             instances = objects.InstanceList.get_by_filters(
6694                 context, filters, expected_attrs=attrs, use_slave=True)
6695         LOG.debug('There are %d instances to clean', len(instances))
6696 
6697         for instance in instances:
6698             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
6699             LOG.debug('Instance has had %(attempts)s of %(max)s '
6700                       'cleanup attempts',
6701                       {'attempts': attempts,
6702                        'max': CONF.maximum_instance_delete_attempts},
6703                       instance=instance)
6704             if attempts < CONF.maximum_instance_delete_attempts:
6705                 success = self.driver.delete_instance_files(instance)
6706 
6707                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
6708                 if success:
6709                     instance.cleaned = True
6710                 with utils.temporary_mutation(context, read_deleted='yes'):
6711                     instance.save()
6712 
6713     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6714     def _cleanup_incomplete_migrations(self, context):
6715         """Delete instance files on failed resize/revert-resize operation
6716 
6717         During resize/revert-resize operation, if that instance gets deleted
6718         in-between then instance files might remain either on source or
6719         destination compute node because of race condition.
6720         """
6721         LOG.debug('Cleaning up deleted instances with incomplete migration ')
6722         migration_filters = {'host': CONF.host,
6723                              'status': 'error'}
6724         migrations = objects.MigrationList.get_by_filters(context,
6725                                                           migration_filters)
6726 
6727         if not migrations:
6728             return
6729 
6730         inst_uuid_from_migrations = set([migration.instance_uuid for migration
6731                                          in migrations])
6732 
6733         inst_filters = {'deleted': True, 'soft_deleted': False,
6734                         'uuid': inst_uuid_from_migrations}
6735         attrs = ['info_cache', 'security_groups', 'system_metadata']
6736         with utils.temporary_mutation(context, read_deleted='yes'):
6737             instances = objects.InstanceList.get_by_filters(
6738                 context, inst_filters, expected_attrs=attrs, use_slave=True)
6739 
6740         for instance in instances:
6741             if instance.host != CONF.host:
6742                 for migration in migrations:
6743                     if instance.uuid == migration.instance_uuid:
6744                         # Delete instance files if not cleanup properly either
6745                         # from the source or destination compute nodes when
6746                         # the instance is deleted during resizing.
6747                         self.driver.delete_instance_files(instance)
6748                         try:
6749                             migration.status = 'failed'
6750                             with migration.obj_as_admin():
6751                                 migration.save()
6752                         except exception.MigrationNotFound:
6753                             LOG.warning(_LW("Migration %s is not found."),
6754                                         migration.id, context=context,
6755                                         instance=instance)
6756                         break
6757 
6758     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
6759                                    exception.QemuGuestAgentNotEnabled,
6760                                    exception.NovaException,
6761                                    NotImplementedError)
6762     @wrap_exception()
6763     def quiesce_instance(self, context, instance):
6764         """Quiesce an instance on this host."""
6765         context = context.elevated()
6766         image_meta = objects.ImageMeta.from_instance(instance)
6767         self.driver.quiesce(context, instance, image_meta)
6768 
6769     def _wait_for_snapshots_completion(self, context, mapping):
6770         for mapping_dict in mapping:
6771             if mapping_dict.get('source_type') == 'snapshot':
6772 
6773                 def _wait_snapshot():
6774                     snapshot = self.volume_api.get_snapshot(
6775                         context, mapping_dict['snapshot_id'])
6776                     if snapshot.get('status') != 'creating':
6777                         raise loopingcall.LoopingCallDone()
6778 
6779                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
6780                 timer.start(interval=0.5).wait()
6781 
6782     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
6783                                    exception.QemuGuestAgentNotEnabled,
6784                                    exception.NovaException,
6785                                    NotImplementedError)
6786     @wrap_exception()
6787     def unquiesce_instance(self, context, instance, mapping=None):
6788         """Unquiesce an instance on this host.
6789 
6790         If snapshots' image mapping is provided, it waits until snapshots are
6791         completed before unqueiscing.
6792         """
6793         context = context.elevated()
6794         if mapping:
6795             try:
6796                 self._wait_for_snapshots_completion(context, mapping)
6797             except Exception as error:
6798                 LOG.exception(_LE("Exception while waiting completion of "
6799                                   "volume snapshots: %s"),
6800                               error, instance=instance)
6801         image_meta = objects.ImageMeta.from_instance(instance)
6802         self.driver.unquiesce(context, instance, image_meta)
