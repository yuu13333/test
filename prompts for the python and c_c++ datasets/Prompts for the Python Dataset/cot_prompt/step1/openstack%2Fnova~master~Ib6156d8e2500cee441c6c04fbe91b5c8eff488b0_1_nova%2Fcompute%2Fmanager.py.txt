Based on the given code from a commit, please generate supplementary code files according to the commit message.
####commit message
Ensure errors_out_migration errors out migration

error_out_migration includes a check of the current migration state.
If the migration is not in either 'migrating' or 'post-migrating', the
decorator will not set it to an error state. This behaviour has been
present since the decorator was added in change Ie752e483. The change
does not describe why this restriction is present, and there is no
comment.

The list of permitted states is incomplete as it does not include
'reverting', possibly others. It is also surprising to the maintainer.

I can't come up with a good reason for this exclusion to exist,
although I suspect it was a hack to limit the scope of the decorator.
Rather than maintain a parallel list of permitted migration states, we
make the intended scope of the context explicit, and unconditionally
set an error within that scope. This is more obviously correct, and
less surprising to the maintainer.

To make the scope explicit we need both a decorator and a
contextmanager, similar to the existing
_error_out_instance_on_exception.

We explicitly limit the scope in resize_instance to before the
finish_resize cast, as a later failure should not put the migration in
an error state.

In finish_revert_resize we limit the scope to until the instance is in
the target state.

The scope is correct in revert_resize and finish_resize.

Change-Id: Ib6156d8e2500cee441c6c04fbe91b5c8eff488b0

####code 
1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 from cursive import exception as cursive_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 from keystoneauth1 import exceptions as keystone_exception
44 from oslo_log import log as logging
45 import oslo_messaging as messaging
46 from oslo_serialization import jsonutils
47 from oslo_service import loopingcall
48 from oslo_service import periodic_task
49 from oslo_utils import excutils
50 from oslo_utils import strutils
51 from oslo_utils import timeutils
52 from oslo_utils import uuidutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 import nova.context
71 from nova import exception
72 from nova import exception_wrapper
73 from nova import hooks
74 from nova.i18n import _
75 from nova import image
76 from nova.image import glance
77 from nova import manager
78 from nova import network
79 from nova.network import base_api as base_net_api
80 from nova.network import model as network_model
81 from nova.network.security_group import openstack_driver
82 from nova import objects
83 from nova.objects import base as obj_base
84 from nova.objects import fields
85 from nova.objects import instance as obj_instance
86 from nova.objects import migrate_data as migrate_data_obj
87 from nova.pci import whitelist
88 from nova import rpc
89 from nova import safe_utils
90 from nova.scheduler import client as scheduler_client
91 from nova import utils
92 from nova.virt import block_device as driver_block_device
93 from nova.virt import configdrive
94 from nova.virt import driver
95 from nova.virt import event as virtevent
96 from nova.virt import storage_users
97 from nova.virt import virtapi
98 from nova.volume import cinder
99 
100 CONF = nova.conf.CONF
101 
102 LOG = logging.getLogger(__name__)
103 
104 get_notifier = functools.partial(rpc.get_notifier, service='compute')
105 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
106                                    get_notifier=get_notifier,
107                                    binary='nova-compute')
108 
109 
110 @contextlib.contextmanager
111 def errors_out_migration_ctxt(migration):
112     """Context manager to error out migration on failure."""
113 
114     try:
115         yield
116     except Exception:
117         with excutils.save_and_reraise_exception():
118             migration.status = 'error'
119             try:
120                 with migration.obj_as_admin():
121                     migration.save()
122             except Exception:
123                 LOG.debug('Error setting migration status '
124                           'for instance %s.',
125                           migration.instance_uuid, exc_info=True)
126 
127 
128 @utils.expects_func_args('migration')
129 def errors_out_migration(function):
130     """Decorator to error out migration on failure."""
131 
132     @functools.wraps(function)
133     def decorated_function(self, context, *args, **kwargs):
134         wrapped_func = safe_utils.get_wrapped_function(function)
135         keyed_args = inspect.getcallargs(wrapped_func, self, context,
136                                          *args, **kwargs)
137         migration = keyed_args['migration']
138         with errors_out_migration_ctxt(migration):
139             return function(self, context, *args, **kwargs)
140 
141     return decorated_function
142 
143 
144 @utils.expects_func_args('instance')
145 def reverts_task_state(function):
146     """Decorator to revert task_state on failure."""
147 
148     @functools.wraps(function)
149     def decorated_function(self, context, *args, **kwargs):
150         try:
151             return function(self, context, *args, **kwargs)
152         except exception.UnexpectedTaskStateError as e:
153             # Note(maoy): unexpected task state means the current
154             # task is preempted. Do not clear task state in this
155             # case.
156             with excutils.save_and_reraise_exception():
157                 LOG.info("Task possibly preempted: %s",
158                          e.format_message())
159         except Exception:
160             with excutils.save_and_reraise_exception():
161                 wrapped_func = safe_utils.get_wrapped_function(function)
162                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
163                                                  *args, **kwargs)
164                 # NOTE(mriedem): 'instance' must be in keyed_args because we
165                 # have utils.expects_func_args('instance') decorating this
166                 # method.
167                 instance = keyed_args['instance']
168                 original_task_state = instance.task_state
169                 try:
170                     self._instance_update(context, instance, task_state=None)
171                     LOG.info("Successfully reverted task state from %s on "
172                              "failure for instance.",
173                              original_task_state, instance=instance)
174                 except exception.InstanceNotFound:
175                     # We might delete an instance that failed to build shortly
176                     # after it errored out this is an expected case and we
177                     # should not trace on it.
178                     pass
179                 except Exception as e:
180                     LOG.warning("Failed to revert task state for instance. "
181                                 "Error: %s", e, instance=instance)
182 
183     return decorated_function
184 
185 
186 @utils.expects_func_args('instance')
187 def wrap_instance_fault(function):
188     """Wraps a method to catch exceptions related to instances.
189 
190     This decorator wraps a method to catch any exceptions having to do with
191     an instance that may get thrown. It then logs an instance fault in the db.
192     """
193 
194     @functools.wraps(function)
195     def decorated_function(self, context, *args, **kwargs):
196         try:
197             return function(self, context, *args, **kwargs)
198         except exception.InstanceNotFound:
199             raise
200         except Exception as e:
201             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
202             # we will get a KeyError exception which will cover up the real
203             # exception. So, we update kwargs with the values from args first.
204             # then, we can get 'instance' from kwargs easily.
205             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
206 
207             with excutils.save_and_reraise_exception():
208                 compute_utils.add_instance_fault_from_exc(context,
209                         kwargs['instance'], e, sys.exc_info())
210 
211     return decorated_function
212 
213 
214 @utils.expects_func_args('image_id', 'instance')
215 def delete_image_on_error(function):
216     """Used for snapshot related method to ensure the image created in
217     compute.api is deleted when an error occurs.
218     """
219 
220     @functools.wraps(function)
221     def decorated_function(self, context, image_id, instance,
222                            *args, **kwargs):
223         try:
224             return function(self, context, image_id, instance,
225                             *args, **kwargs)
226         except Exception:
227             with excutils.save_and_reraise_exception():
228                 LOG.debug("Cleaning up image %s", image_id,
229                           exc_info=True, instance=instance)
230                 try:
231                     self.image_api.delete(context, image_id)
232                 except exception.ImageNotFound:
233                     # Since we're trying to cleanup an image, we don't care if
234                     # if it's already gone.
235                     pass
236                 except Exception:
237                     LOG.exception("Error while trying to clean up image %s",
238                                   image_id, instance=instance)
239 
240     return decorated_function
241 
242 
243 # TODO(danms): Remove me after Icehouse
244 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
245 # NOTE(mikal): if the method being decorated has more than one decorator, then
246 # put this one first. Otherwise the various exception handling decorators do
247 # not function correctly.
248 def object_compat(function):
249     """Wraps a method that expects a new-world instance
250 
251     This provides compatibility for callers passing old-style dict
252     instances.
253     """
254 
255     @functools.wraps(function)
256     def decorated_function(self, context, *args, **kwargs):
257         def _load_instance(instance_or_dict):
258             if isinstance(instance_or_dict, dict):
259                 # try to get metadata and system_metadata for most cases but
260                 # only attempt to load those if the db instance already has
261                 # those fields joined
262                 metas = [meta for meta in ('metadata', 'system_metadata')
263                          if meta in instance_or_dict]
264                 instance = objects.Instance._from_db_object(
265                     context, objects.Instance(), instance_or_dict,
266                     expected_attrs=metas)
267                 instance._context = context
268                 return instance
269             return instance_or_dict
270 
271         try:
272             kwargs['instance'] = _load_instance(kwargs['instance'])
273         except KeyError:
274             args = (_load_instance(args[0]),) + args[1:]
275 
276         migration = kwargs.get('migration')
277         if isinstance(migration, dict):
278             migration = objects.Migration._from_db_object(
279                     context.elevated(), objects.Migration(),
280                     migration)
281             kwargs['migration'] = migration
282 
283         return function(self, context, *args, **kwargs)
284 
285     return decorated_function
286 
287 
288 class InstanceEvents(object):
289     def __init__(self):
290         self._events = {}
291 
292     @staticmethod
293     def _lock_name(instance):
294         return '%s-%s' % (instance.uuid, 'events')
295 
296     def prepare_for_instance_event(self, instance, event_name):
297         """Prepare to receive an event for an instance.
298 
299         This will register an event for the given instance that we will
300         wait on later. This should be called before initiating whatever
301         action will trigger the event. The resulting eventlet.event.Event
302         object should be wait()'d on to ensure completion.
303 
304         :param instance: the instance for which the event will be generated
305         :param event_name: the name of the event we're expecting
306         :returns: an event object that should be wait()'d on
307         """
308         if self._events is None:
309             # NOTE(danms): We really should have a more specific error
310             # here, but this is what we use for our default error case
311             raise exception.NovaException('In shutdown, no new events '
312                                           'can be scheduled')
313 
314         @utils.synchronized(self._lock_name(instance))
315         def _create_or_get_event():
316             instance_events = self._events.setdefault(instance.uuid, {})
317             return instance_events.setdefault(event_name,
318                                               eventlet.event.Event())
319         LOG.debug('Preparing to wait for external event %(event)s',
320                   {'event': event_name}, instance=instance)
321         return _create_or_get_event()
322 
323     def pop_instance_event(self, instance, event):
324         """Remove a pending event from the wait list.
325 
326         This will remove a pending event from the wait list so that it
327         can be used to signal the waiters to wake up.
328 
329         :param instance: the instance for which the event was generated
330         :param event: the nova.objects.external_event.InstanceExternalEvent
331                       that describes the event
332         :returns: the eventlet.event.Event object on which the waiters
333                   are blocked
334         """
335         no_events_sentinel = object()
336         no_matching_event_sentinel = object()
337 
338         @utils.synchronized(self._lock_name(instance))
339         def _pop_event():
340             if not self._events:
341                 LOG.debug('Unexpected attempt to pop events during shutdown',
342                           instance=instance)
343                 return no_events_sentinel
344             events = self._events.get(instance.uuid)
345             if not events:
346                 return no_events_sentinel
347             _event = events.pop(event.key, None)
348             if not events:
349                 del self._events[instance.uuid]
350             if _event is None:
351                 return no_matching_event_sentinel
352             return _event
353 
354         result = _pop_event()
355         if result is no_events_sentinel:
356             LOG.debug('No waiting events found dispatching %(event)s',
357                       {'event': event.key},
358                       instance=instance)
359             return None
360         elif result is no_matching_event_sentinel:
361             LOG.debug('No event matching %(event)s in %(events)s',
362                       {'event': event.key,
363                        'events': self._events.get(instance.uuid, {}).keys()},
364                       instance=instance)
365             return None
366         else:
367             return result
368 
369     def clear_events_for_instance(self, instance):
370         """Remove all pending events for an instance.
371 
372         This will remove all events currently pending for an instance
373         and return them (indexed by event name).
374 
375         :param instance: the instance for which events should be purged
376         :returns: a dictionary of {event_name: eventlet.event.Event}
377         """
378         @utils.synchronized(self._lock_name(instance))
379         def _clear_events():
380             if self._events is None:
381                 LOG.debug('Unexpected attempt to clear events during shutdown',
382                           instance=instance)
383                 return dict()
384             return self._events.pop(instance.uuid, {})
385         return _clear_events()
386 
387     def cancel_all_events(self):
388         if self._events is None:
389             LOG.debug('Unexpected attempt to cancel events during shutdown.')
390             return
391         our_events = self._events
392         # NOTE(danms): Block new events
393         self._events = None
394 
395         for instance_uuid, events in our_events.items():
396             for event_name, eventlet_event in events.items():
397                 LOG.debug('Canceling in-flight event %(event)s for '
398                           'instance %(instance_uuid)s',
399                           {'event': event_name,
400                            'instance_uuid': instance_uuid})
401                 name, tag = event_name.rsplit('-', 1)
402                 event = objects.InstanceExternalEvent(
403                     instance_uuid=instance_uuid,
404                     name=name, status='failed',
405                     tag=tag, data={})
406                 eventlet_event.send(event)
407 
408 
409 class ComputeVirtAPI(virtapi.VirtAPI):
410     def __init__(self, compute):
411         super(ComputeVirtAPI, self).__init__()
412         self._compute = compute
413 
414     def _default_error_callback(self, event_name, instance):
415         raise exception.NovaException(_('Instance event failed'))
416 
417     @contextlib.contextmanager
418     def wait_for_instance_event(self, instance, event_names, deadline=300,
419                                 error_callback=None):
420         """Plan to wait for some events, run some code, then wait.
421 
422         This context manager will first create plans to wait for the
423         provided event_names, yield, and then wait for all the scheduled
424         events to complete.
425 
426         Note that this uses an eventlet.timeout.Timeout to bound the
427         operation, so callers should be prepared to catch that
428         failure and handle that situation appropriately.
429 
430         If the event is not received by the specified timeout deadline,
431         eventlet.timeout.Timeout is raised.
432 
433         If the event is received but did not have a 'completed'
434         status, a NovaException is raised.  If an error_callback is
435         provided, instead of raising an exception as detailed above
436         for the failure case, the callback will be called with the
437         event_name and instance, and can return True to continue
438         waiting for the rest of the events, False to stop processing,
439         or raise an exception which will bubble up to the waiter.
440 
441         :param instance: The instance for which an event is expected
442         :param event_names: A list of event names. Each element can be a
443                             string event name or tuple of strings to
444                             indicate (name, tag).
445         :param deadline: Maximum number of seconds we should wait for all
446                          of the specified events to arrive.
447         :param error_callback: A function to be called if an event arrives
448 
449         """
450 
451         if error_callback is None:
452             error_callback = self._default_error_callback
453         events = {}
454         for event_name in event_names:
455             if isinstance(event_name, tuple):
456                 name, tag = event_name
457                 event_name = objects.InstanceExternalEvent.make_key(
458                     name, tag)
459             try:
460                 events[event_name] = (
461                     self._compute.instance_events.prepare_for_instance_event(
462                         instance, event_name))
463             except exception.NovaException:
464                 error_callback(event_name, instance)
465                 # NOTE(danms): Don't wait for any of the events. They
466                 # should all be canceled and fired immediately below,
467                 # but don't stick around if not.
468                 deadline = 0
469         yield
470         with eventlet.timeout.Timeout(deadline):
471             for event_name, event in events.items():
472                 actual_event = event.wait()
473                 if actual_event.status == 'completed':
474                     continue
475                 decision = error_callback(event_name, instance)
476                 if decision is False:
477                     break
478 
479 
480 class ComputeManager(manager.Manager):
481     """Manages the running instances from creation to destruction."""
482 
483     target = messaging.Target(version='4.16')
484 
485     # How long to wait in seconds before re-issuing a shutdown
486     # signal to an instance during power off.  The overall
487     # time to wait is set by CONF.shutdown_timeout.
488     SHUTDOWN_RETRY_INTERVAL = 10
489 
490     def __init__(self, compute_driver=None, *args, **kwargs):
491         """Load configuration options and connect to the hypervisor."""
492         self.virtapi = ComputeVirtAPI(self)
493         self.network_api = network.API()
494         self.volume_api = cinder.API()
495         self.image_api = image.API()
496         self._last_host_check = 0
497         self._last_bw_usage_poll = 0
498         self._bw_usage_supported = True
499         self._last_bw_usage_cell_update = 0
500         self.compute_api = compute.API()
501         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
502         self.conductor_api = conductor.API()
503         self.compute_task_api = conductor.ComputeTaskAPI()
504         self.is_neutron_security_groups = (
505             openstack_driver.is_neutron_security_groups())
506         self.cells_rpcapi = cells_rpcapi.CellsAPI()
507         self.scheduler_client = scheduler_client.SchedulerClient()
508         self._resource_tracker = None
509         self.instance_events = InstanceEvents()
510         self._sync_power_pool = eventlet.GreenPool(
511             size=CONF.sync_power_state_pool_size)
512         self._syncs_in_progress = {}
513         self.send_instance_updates = (
514             CONF.filter_scheduler.track_instance_changes)
515         if CONF.max_concurrent_builds != 0:
516             self._build_semaphore = eventlet.semaphore.Semaphore(
517                 CONF.max_concurrent_builds)
518         else:
519             self._build_semaphore = compute_utils.UnlimitedSemaphore()
520         if max(CONF.max_concurrent_live_migrations, 0) != 0:
521             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
522                 CONF.max_concurrent_live_migrations)
523         else:
524             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
525         self._failed_builds = 0
526 
527         super(ComputeManager, self).__init__(service_name="compute",
528                                              *args, **kwargs)
529 
530         # NOTE(russellb) Load the driver last.  It may call back into the
531         # compute manager via the virtapi, so we want it to be fully
532         # initialized before that happens.
533         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
534         self.use_legacy_block_device_info = \
535                             self.driver.need_legacy_block_device_info
536 
537     def reset(self):
538         LOG.info('Reloading compute RPC API')
539         compute_rpcapi.LAST_VERSION = None
540         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
541 
542     def _get_resource_tracker(self):
543         if not self._resource_tracker:
544             rt = resource_tracker.ResourceTracker(self.host, self.driver)
545             self._resource_tracker = rt
546         return self._resource_tracker
547 
548     def _update_resource_tracker(self, context, instance):
549         """Let the resource tracker know that an instance has changed state."""
550 
551         if instance.host == self.host:
552             rt = self._get_resource_tracker()
553             rt.update_usage(context, instance, instance.node)
554 
555     def _instance_update(self, context, instance, **kwargs):
556         """Update an instance in the database using kwargs as value."""
557 
558         for k, v in kwargs.items():
559             setattr(instance, k, v)
560         instance.save()
561         self._update_resource_tracker(context, instance)
562 
563     def _nil_out_instance_obj_host_and_node(self, instance):
564         # NOTE(jwcroppe): We don't do instance.save() here for performance
565         # reasons; a call to this is expected to be immediately followed by
566         # another call that does instance.save(), thus avoiding two writes
567         # to the database layer.
568         instance.host = None
569         instance.node = None
570 
571     def _set_instance_obj_error_state(self, context, instance,
572                                       clean_task_state=False):
573         try:
574             instance.vm_state = vm_states.ERROR
575             if clean_task_state:
576                 instance.task_state = None
577             instance.save()
578         except exception.InstanceNotFound:
579             LOG.debug('Instance has been destroyed from under us while '
580                       'trying to set it to ERROR', instance=instance)
581 
582     def _get_instances_on_driver(self, context, filters=None):
583         """Return a list of instance records for the instances found
584         on the hypervisor which satisfy the specified filters. If filters=None
585         return a list of instance records for all the instances found on the
586         hypervisor.
587         """
588         if not filters:
589             filters = {}
590         try:
591             driver_uuids = self.driver.list_instance_uuids()
592             if len(driver_uuids) == 0:
593                 # Short circuit, don't waste a DB call
594                 return objects.InstanceList()
595             filters['uuid'] = driver_uuids
596             local_instances = objects.InstanceList.get_by_filters(
597                 context, filters, use_slave=True)
598             return local_instances
599         except NotImplementedError:
600             pass
601 
602         # The driver doesn't support uuids listing, so we'll have
603         # to brute force.
604         driver_instances = self.driver.list_instances()
605         instances = objects.InstanceList.get_by_filters(context, filters,
606                                                         use_slave=True)
607         name_map = {instance.name: instance for instance in instances}
608         local_instances = []
609         for driver_instance in driver_instances:
610             instance = name_map.get(driver_instance)
611             if not instance:
612                 continue
613             local_instances.append(instance)
614         return local_instances
615 
616     def _destroy_evacuated_instances(self, context):
617         """Destroys evacuated instances.
618 
619         While nova-compute was down, the instances running on it could be
620         evacuated to another host. Check that the instances reported
621         by the driver are still associated with this host.  If they are
622         not, destroy them, with the exception of instances which are in
623         the MIGRATING, RESIZE_MIGRATING, RESIZE_MIGRATED, RESIZE_FINISH
624         task state or RESIZED vm state.
625         """
626         filters = {
627             'source_compute': self.host,
628             'status': ['accepted', 'done'],
629             'migration_type': 'evacuation',
630         }
631         evacuations = objects.MigrationList.get_by_filters(context, filters)
632         if not evacuations:
633             return
634         evacuations = {mig.instance_uuid: mig for mig in evacuations}
635 
636         filters = {'deleted': False}
637         local_instances = self._get_instances_on_driver(context, filters)
638         evacuated = [inst for inst in local_instances
639                      if inst.uuid in evacuations]
640         for instance in evacuated:
641             migration = evacuations[instance.uuid]
642             LOG.info('Deleting instance as it has been evacuated from '
643                      'this host', instance=instance)
644             try:
645                 network_info = self.network_api.get_instance_nw_info(
646                     context, instance)
647                 bdi = self._get_instance_block_device_info(context,
648                                                            instance)
649                 destroy_disks = not (self._is_instance_storage_shared(
650                     context, instance))
651             except exception.InstanceNotFound:
652                 network_info = network_model.NetworkInfo()
653                 bdi = {}
654                 LOG.info('Instance has been marked deleted already, '
655                          'removing it from the hypervisor.',
656                          instance=instance)
657                 # always destroy disks if the instance was deleted
658                 destroy_disks = True
659             self.driver.destroy(context, instance,
660                                 network_info,
661                                 bdi, destroy_disks)
662             migration.status = 'completed'
663             migration.save()
664 
665     def _is_instance_storage_shared(self, context, instance, host=None):
666         shared_storage = True
667         data = None
668         try:
669             data = self.driver.check_instance_shared_storage_local(context,
670                                                        instance)
671             if data:
672                 shared_storage = (self.compute_rpcapi.
673                                   check_instance_shared_storage(context,
674                                   instance, data, host=host))
675         except NotImplementedError:
676             LOG.debug('Hypervisor driver does not support '
677                       'instance shared storage check, '
678                       'assuming it\'s not on shared storage',
679                       instance=instance)
680             shared_storage = False
681         except Exception:
682             LOG.exception('Failed to check if instance shared',
683                           instance=instance)
684         finally:
685             if data:
686                 self.driver.check_instance_shared_storage_cleanup(context,
687                                                                   data)
688         return shared_storage
689 
690     def _complete_partial_deletion(self, context, instance):
691         """Complete deletion for instances in DELETED status but not marked as
692         deleted in the DB
693         """
694         system_meta = instance.system_metadata
695         instance.destroy()
696         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
697                 context, instance.uuid)
698         quotas = objects.Quotas(context=context)
699         project_id, user_id = objects.quotas.ids_from_instance(context,
700                                                                instance)
701         quotas.reserve(project_id=project_id, user_id=user_id, instances=-1,
702                        cores=-instance.flavor.vcpus,
703                        ram=-instance.flavor.memory_mb)
704         self._complete_deletion(context,
705                                 instance,
706                                 bdms,
707                                 quotas,
708                                 system_meta)
709 
710     def _complete_deletion(self, context, instance, bdms,
711                            quotas, system_meta):
712         if quotas:
713             quotas.commit()
714 
715         # ensure block device mappings are not leaked
716         for bdm in bdms:
717             bdm.destroy()
718 
719         self._update_resource_tracker(context, instance)
720         self._notify_about_instance_usage(context, instance, "delete.end",
721                 system_metadata=system_meta)
722         compute_utils.notify_about_instance_action(context, instance,
723                 self.host, action=fields.NotificationAction.DELETE,
724                 phase=fields.NotificationPhase.END)
725         self._delete_scheduler_instance_info(context, instance.uuid)
726 
727     def _create_reservations(self, context, instance, project_id, user_id):
728         vcpus = instance.flavor.vcpus
729         mem_mb = instance.flavor.memory_mb
730 
731         quotas = objects.Quotas(context=context)
732         quotas.reserve(project_id=project_id,
733                        user_id=user_id,
734                        instances=-1,
735                        cores=-vcpus,
736                        ram=-mem_mb)
737         return quotas
738 
739     def _init_instance(self, context, instance):
740         '''Initialize this instance during service init.'''
741 
742         # NOTE(danms): If the instance appears to not be owned by this
743         # host, it may have been evacuated away, but skipped by the
744         # evacuation cleanup code due to configuration. Thus, if that
745         # is a possibility, don't touch the instance in any way, but
746         # log the concern. This will help avoid potential issues on
747         # startup due to misconfiguration.
748         if instance.host != self.host:
749             LOG.warning('Instance %(uuid)s appears to not be owned '
750                         'by this host, but by %(host)s. Startup '
751                         'processing is being skipped.',
752                         {'uuid': instance.uuid,
753                          'host': instance.host})
754             return
755 
756         # Instances that are shut down, or in an error state can not be
757         # initialized and are not attempted to be recovered. The exception
758         # to this are instances that are in RESIZE_MIGRATING or DELETING,
759         # which are dealt with further down.
760         if (instance.vm_state == vm_states.SOFT_DELETED or
761             (instance.vm_state == vm_states.ERROR and
762             instance.task_state not in
763             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
764             LOG.debug("Instance is in %s state.",
765                       instance.vm_state, instance=instance)
766             return
767 
768         if instance.vm_state == vm_states.DELETED:
769             try:
770                 self._complete_partial_deletion(context, instance)
771             except Exception:
772                 # we don't want that an exception blocks the init_host
773                 LOG.exception('Failed to complete a deletion',
774                               instance=instance)
775             return
776 
777         if (instance.vm_state == vm_states.BUILDING or
778             instance.task_state in [task_states.SCHEDULING,
779                                     task_states.BLOCK_DEVICE_MAPPING,
780                                     task_states.NETWORKING,
781                                     task_states.SPAWNING]):
782             # NOTE(dave-mcnally) compute stopped before instance was fully
783             # spawned so set to ERROR state. This is safe to do as the state
784             # may be set by the api but the host is not so if we get here the
785             # instance has already been scheduled to this particular host.
786             LOG.debug("Instance failed to spawn correctly, "
787                       "setting to ERROR state", instance=instance)
788             instance.task_state = None
789             instance.vm_state = vm_states.ERROR
790             instance.save()
791             return
792 
793         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
794             instance.task_state in [task_states.REBUILDING,
795                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
796                                     task_states.REBUILD_SPAWNING]):
797             # NOTE(jichenjc) compute stopped before instance was fully
798             # spawned so set to ERROR state. This is consistent to BUILD
799             LOG.debug("Instance failed to rebuild correctly, "
800                       "setting to ERROR state", instance=instance)
801             instance.task_state = None
802             instance.vm_state = vm_states.ERROR
803             instance.save()
804             return
805 
806         if (instance.vm_state != vm_states.ERROR and
807             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
808                                     task_states.IMAGE_PENDING_UPLOAD,
809                                     task_states.IMAGE_UPLOADING,
810                                     task_states.IMAGE_SNAPSHOT]):
811             LOG.debug("Instance in transitional state %s at start-up "
812                       "clearing task state",
813                       instance.task_state, instance=instance)
814             try:
815                 self._post_interrupted_snapshot_cleanup(context, instance)
816             except Exception:
817                 # we don't want that an exception blocks the init_host
818                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
819             instance.task_state = None
820             instance.save()
821 
822         if (instance.vm_state != vm_states.ERROR and
823             instance.task_state in [task_states.RESIZE_PREP]):
824             LOG.debug("Instance in transitional state %s at start-up "
825                       "clearing task state",
826                       instance['task_state'], instance=instance)
827             instance.task_state = None
828             instance.save()
829 
830         if instance.task_state == task_states.DELETING:
831             try:
832                 LOG.info('Service started deleting the instance during '
833                          'the previous run, but did not finish. Restarting'
834                          ' the deletion now.', instance=instance)
835                 instance.obj_load_attr('metadata')
836                 instance.obj_load_attr('system_metadata')
837                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
838                         context, instance.uuid)
839                 project_id, user_id = objects.quotas.ids_from_instance(
840                     context, instance)
841                 quotas = self._create_reservations(context, instance,
842                                                    project_id, user_id)
843 
844                 self._delete_instance(context, instance, bdms, quotas)
845             except Exception:
846                 # we don't want that an exception blocks the init_host
847                 LOG.exception('Failed to complete a deletion',
848                               instance=instance)
849                 self._set_instance_obj_error_state(context, instance)
850             return
851 
852         current_power_state = self._get_power_state(context, instance)
853         try_reboot, reboot_type = self._retry_reboot(context, instance,
854                                                      current_power_state)
855 
856         if try_reboot:
857             LOG.debug("Instance in transitional state (%(task_state)s) at "
858                       "start-up and power state is (%(power_state)s), "
859                       "triggering reboot",
860                       {'task_state': instance.task_state,
861                        'power_state': current_power_state},
862                       instance=instance)
863 
864             # NOTE(mikal): if the instance was doing a soft reboot that got as
865             # far as shutting down the instance but not as far as starting it
866             # again, then we've just become a hard reboot. That means the
867             # task state for the instance needs to change so that we're in one
868             # of the expected task states for a hard reboot.
869             soft_types = [task_states.REBOOT_STARTED,
870                           task_states.REBOOT_PENDING,
871                           task_states.REBOOTING]
872             if instance.task_state in soft_types and reboot_type == 'HARD':
873                 instance.task_state = task_states.REBOOT_PENDING_HARD
874                 instance.save()
875 
876             self.reboot_instance(context, instance, block_device_info=None,
877                                  reboot_type=reboot_type)
878             return
879 
880         elif (current_power_state == power_state.RUNNING and
881               instance.task_state in [task_states.REBOOT_STARTED,
882                                       task_states.REBOOT_STARTED_HARD,
883                                       task_states.PAUSING,
884                                       task_states.UNPAUSING]):
885             LOG.warning("Instance in transitional state "
886                         "(%(task_state)s) at start-up and power state "
887                         "is (%(power_state)s), clearing task state",
888                         {'task_state': instance.task_state,
889                          'power_state': current_power_state},
890                         instance=instance)
891             instance.task_state = None
892             instance.vm_state = vm_states.ACTIVE
893             instance.save()
894         elif (current_power_state == power_state.PAUSED and
895               instance.task_state == task_states.UNPAUSING):
896             LOG.warning("Instance in transitional state "
897                         "(%(task_state)s) at start-up and power state "
898                         "is (%(power_state)s), clearing task state "
899                         "and unpausing the instance",
900                         {'task_state': instance.task_state,
901                          'power_state': current_power_state},
902                         instance=instance)
903             try:
904                 self.unpause_instance(context, instance)
905             except NotImplementedError:
906                 # Some virt driver didn't support pause and unpause
907                 pass
908             except Exception:
909                 LOG.exception('Failed to unpause instance', instance=instance)
910             return
911 
912         if instance.task_state == task_states.POWERING_OFF:
913             try:
914                 LOG.debug("Instance in transitional state %s at start-up "
915                           "retrying stop request",
916                           instance.task_state, instance=instance)
917                 self.stop_instance(context, instance, True)
918             except Exception:
919                 # we don't want that an exception blocks the init_host
920                 LOG.exception('Failed to stop instance', instance=instance)
921             return
922 
923         if instance.task_state == task_states.POWERING_ON:
924             try:
925                 LOG.debug("Instance in transitional state %s at start-up "
926                           "retrying start request",
927                           instance.task_state, instance=instance)
928                 self.start_instance(context, instance)
929             except Exception:
930                 # we don't want that an exception blocks the init_host
931                 LOG.exception('Failed to start instance', instance=instance)
932             return
933 
934         net_info = instance.get_network_info()
935         try:
936             self.driver.plug_vifs(instance, net_info)
937         except NotImplementedError as e:
938             LOG.debug(e, instance=instance)
939         except exception.VirtualInterfacePlugException:
940             # we don't want an exception to block the init_host
941             LOG.exception("Vifs plug failed", instance=instance)
942             self._set_instance_obj_error_state(context, instance)
943             return
944 
945         if instance.task_state == task_states.RESIZE_MIGRATING:
946             # We crashed during resize/migration, so roll back for safety
947             try:
948                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
949                 # not in system_metadata we default to True for backwards
950                 # compatibility
951                 power_on = (instance.system_metadata.get('old_vm_state') !=
952                             vm_states.STOPPED)
953 
954                 block_dev_info = self._get_instance_block_device_info(context,
955                                                                       instance)
956 
957                 self.driver.finish_revert_migration(context,
958                     instance, net_info, block_dev_info, power_on)
959 
960             except Exception:
961                 LOG.exception('Failed to revert crashed migration',
962                               instance=instance)
963             finally:
964                 LOG.info('Instance found in migrating state during '
965                          'startup. Resetting task_state',
966                          instance=instance)
967                 instance.task_state = None
968                 instance.save()
969         if instance.task_state == task_states.MIGRATING:
970             # Live migration did not complete, but instance is on this
971             # host, so reset the state.
972             instance.task_state = None
973             instance.save(expected_task_state=[task_states.MIGRATING])
974 
975         db_state = instance.power_state
976         drv_state = self._get_power_state(context, instance)
977         expect_running = (db_state == power_state.RUNNING and
978                           drv_state != db_state)
979 
980         LOG.debug('Current state is %(drv_state)s, state in DB is '
981                   '%(db_state)s.',
982                   {'drv_state': drv_state, 'db_state': db_state},
983                   instance=instance)
984 
985         if expect_running and CONF.resume_guests_state_on_host_boot:
986             LOG.info('Rebooting instance after nova-compute restart.',
987                      instance=instance)
988 
989             block_device_info = \
990                 self._get_instance_block_device_info(context, instance)
991 
992             try:
993                 self.driver.resume_state_on_host_boot(
994                     context, instance, net_info, block_device_info)
995             except NotImplementedError:
996                 LOG.warning('Hypervisor driver does not support '
997                             'resume guests', instance=instance)
998             except Exception:
999                 # NOTE(vish): The instance failed to resume, so we set the
1000                 #             instance to error and attempt to continue.
1001                 LOG.warning('Failed to resume instance',
1002                             instance=instance)
1003                 self._set_instance_obj_error_state(context, instance)
1004 
1005         elif drv_state == power_state.RUNNING:
1006             # VMwareAPI drivers will raise an exception
1007             try:
1008                 self.driver.ensure_filtering_rules_for_instance(
1009                                        instance, net_info)
1010             except NotImplementedError:
1011                 LOG.debug('Hypervisor driver does not support '
1012                           'firewall rules', instance=instance)
1013 
1014     def _retry_reboot(self, context, instance, current_power_state):
1015         current_task_state = instance.task_state
1016         retry_reboot = False
1017         reboot_type = compute_utils.get_reboot_type(current_task_state,
1018                                                     current_power_state)
1019 
1020         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1021                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1022         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1023                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1024         started_not_running = (current_task_state in
1025                                [task_states.REBOOT_STARTED,
1026                                 task_states.REBOOT_STARTED_HARD] and
1027                                current_power_state != power_state.RUNNING)
1028 
1029         if pending_soft or pending_hard or started_not_running:
1030             retry_reboot = True
1031 
1032         return retry_reboot, reboot_type
1033 
1034     def handle_lifecycle_event(self, event):
1035         LOG.info("VM %(state)s (Lifecycle Event)",
1036                  {'state': event.get_name()},
1037                  instance_uuid=event.get_instance_uuid())
1038         context = nova.context.get_admin_context(read_deleted='yes')
1039         instance = objects.Instance.get_by_uuid(context,
1040                                                 event.get_instance_uuid(),
1041                                                 expected_attrs=[])
1042         vm_power_state = None
1043         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1044             vm_power_state = power_state.SHUTDOWN
1045         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1046             vm_power_state = power_state.RUNNING
1047         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1048             vm_power_state = power_state.PAUSED
1049         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1050             vm_power_state = power_state.RUNNING
1051         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1052             vm_power_state = power_state.SUSPENDED
1053         else:
1054             LOG.warning("Unexpected power state %d", event.get_transition())
1055 
1056         # Note(lpetrut): The event may be delayed, thus not reflecting
1057         # the current instance power state. In that case, ignore the event.
1058         current_power_state = self._get_power_state(context, instance)
1059         if current_power_state == vm_power_state:
1060             LOG.debug('Synchronizing instance power state after lifecycle '
1061                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1062                       'current task_state: %(task_state)s, current DB '
1063                       'power_state: %(db_power_state)s, VM power_state: '
1064                       '%(vm_power_state)s',
1065                       {'event': event.get_name(),
1066                        'vm_state': instance.vm_state,
1067                        'task_state': instance.task_state,
1068                        'db_power_state': instance.power_state,
1069                        'vm_power_state': vm_power_state},
1070                       instance_uuid=instance.uuid)
1071             self._sync_instance_power_state(context,
1072                                             instance,
1073                                             vm_power_state)
1074 
1075     def handle_events(self, event):
1076         if isinstance(event, virtevent.LifecycleEvent):
1077             try:
1078                 self.handle_lifecycle_event(event)
1079             except exception.InstanceNotFound:
1080                 LOG.debug("Event %s arrived for non-existent instance. The "
1081                           "instance was probably deleted.", event)
1082         else:
1083             LOG.debug("Ignoring event %s", event)
1084 
1085     def init_virt_events(self):
1086         if CONF.workarounds.handle_virt_lifecycle_events:
1087             self.driver.register_event_listener(self.handle_events)
1088         else:
1089             # NOTE(mriedem): If the _sync_power_states periodic task is
1090             # disabled we should emit a warning in the logs.
1091             if CONF.sync_power_state_interval < 0:
1092                 LOG.warning('Instance lifecycle events from the compute '
1093                             'driver have been disabled. Note that lifecycle '
1094                             'changes to an instance outside of the compute '
1095                             'service will not be synchronized '
1096                             'automatically since the _sync_power_states '
1097                             'periodic task is also disabled.')
1098             else:
1099                 LOG.info('Instance lifecycle events from the compute '
1100                          'driver have been disabled. Note that lifecycle '
1101                          'changes to an instance outside of the compute '
1102                          'service will only be synchronized by the '
1103                          '_sync_power_states periodic task.')
1104 
1105     def init_host(self):
1106         """Initialization for a standalone compute service."""
1107 
1108         if CONF.pci.passthrough_whitelist:
1109             # Simply loading the PCI passthrough whitelist will do a bunch of
1110             # validation that would otherwise wait until the PciDevTracker is
1111             # constructed when updating available resources for the compute
1112             # node(s) in the resource tracker, effectively killing that task.
1113             # So load up the whitelist when starting the compute service to
1114             # flush any invalid configuration early so we can kill the service
1115             # if the configuration is wrong.
1116             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1117 
1118         # NOTE(sbauza): We want the compute node to hard fail if it can't be
1119         # able to provide its resources to the placement API, or it would not
1120         # be able to be eligible as a destination.
1121         if CONF.placement.os_region_name is None:
1122             raise exception.PlacementNotConfigured()
1123 
1124         self.driver.init_host(host=self.host)
1125         context = nova.context.get_admin_context()
1126         instances = objects.InstanceList.get_by_host(
1127             context, self.host, expected_attrs=['info_cache', 'metadata'])
1128 
1129         if CONF.defer_iptables_apply:
1130             self.driver.filter_defer_apply_on()
1131 
1132         self.init_virt_events()
1133 
1134         try:
1135             # checking that instance was not already evacuated to other host
1136             self._destroy_evacuated_instances(context)
1137             for instance in instances:
1138                 self._init_instance(context, instance)
1139         finally:
1140             if CONF.defer_iptables_apply:
1141                 self.driver.filter_defer_apply_off()
1142             if instances:
1143                 # We only send the instance info to the scheduler on startup
1144                 # if there is anything to send, otherwise this host might
1145                 # not be mapped yet in a cell and the scheduler may have
1146                 # issues dealing with the information. Later changes to
1147                 # instances on this host will update the scheduler, or the
1148                 # _sync_scheduler_instance_info periodic task will.
1149                 self._update_scheduler_instance_info(context, instances)
1150 
1151     def cleanup_host(self):
1152         self.driver.register_event_listener(None)
1153         self.instance_events.cancel_all_events()
1154         self.driver.cleanup_host(host=self.host)
1155 
1156     def pre_start_hook(self):
1157         """After the service is initialized, but before we fully bring
1158         the service up by listening on RPC queues, make sure to update
1159         our available resources (and indirectly our available nodes).
1160         """
1161         self.update_available_resource(nova.context.get_admin_context(),
1162                                        startup=True)
1163 
1164     def _get_power_state(self, context, instance):
1165         """Retrieve the power state for the given instance."""
1166         LOG.debug('Checking state', instance=instance)
1167         try:
1168             return self.driver.get_info(instance).state
1169         except exception.InstanceNotFound:
1170             return power_state.NOSTATE
1171 
1172     def get_console_topic(self, context):
1173         """Retrieves the console host for a project on this host.
1174 
1175         Currently this is just set in the flags for each compute host.
1176 
1177         """
1178         # TODO(mdragon): perhaps make this variable by console_type?
1179         return '%s.%s' % (CONF.console_topic, CONF.console_host)
1180 
1181     @wrap_exception()
1182     def get_console_pool_info(self, context, console_type):
1183         return self.driver.get_console_pool_info(console_type)
1184 
1185     # NOTE(hanlind): This and the virt method it calls can be removed in
1186     # version 5.0 of the RPC API
1187     @wrap_exception()
1188     def refresh_security_group_rules(self, context, security_group_id):
1189         """Tell the virtualization driver to refresh security group rules.
1190 
1191         Passes straight through to the virtualization driver.
1192 
1193         """
1194         return self.driver.refresh_security_group_rules(security_group_id)
1195 
1196     # TODO(alaski): Remove object_compat for RPC version 5.0
1197     @object_compat
1198     @wrap_exception()
1199     def refresh_instance_security_rules(self, context, instance):
1200         """Tell the virtualization driver to refresh security rules for
1201         an instance.
1202 
1203         Passes straight through to the virtualization driver.
1204 
1205         Synchronize the call because we may still be in the middle of
1206         creating the instance.
1207         """
1208         @utils.synchronized(instance.uuid)
1209         def _sync_refresh():
1210             try:
1211                 return self.driver.refresh_instance_security_rules(instance)
1212             except NotImplementedError:
1213                 LOG.debug('Hypervisor driver does not support '
1214                           'security groups.', instance=instance)
1215 
1216         return _sync_refresh()
1217 
1218     def _await_block_device_map_created(self, context, vol_id):
1219         # TODO(yamahata): creating volume simultaneously
1220         #                 reduces creation time?
1221         # TODO(yamahata): eliminate dumb polling
1222         start = time.time()
1223         retries = CONF.block_device_allocate_retries
1224         if retries < 0:
1225             LOG.warning("Treating negative config value (%(retries)s) for "
1226                         "'block_device_retries' as 0.",
1227                         {'retries': retries})
1228         # (1) treat  negative config value as 0
1229         # (2) the configured value is 0, one attempt should be made
1230         # (3) the configured value is > 0, then the total number attempts
1231         #      is (retries + 1)
1232         attempts = 1
1233         if retries >= 1:
1234             attempts = retries + 1
1235         for attempt in range(1, attempts + 1):
1236             volume = self.volume_api.get(context, vol_id)
1237             volume_status = volume['status']
1238             if volume_status not in ['creating', 'downloading']:
1239                 if volume_status == 'available':
1240                     return attempt
1241                 LOG.warning("Volume id: %(vol_id)s finished being "
1242                             "created but its status is %(vol_status)s.",
1243                             {'vol_id': vol_id,
1244                              'vol_status': volume_status})
1245                 break
1246             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1247         raise exception.VolumeNotCreated(volume_id=vol_id,
1248                                          seconds=int(time.time() - start),
1249                                          attempts=attempt,
1250                                          volume_status=volume_status)
1251 
1252     def _decode_files(self, injected_files):
1253         """Base64 decode the list of files to inject."""
1254         if not injected_files:
1255             return []
1256 
1257         def _decode(f):
1258             path, contents = f
1259             # Py3 raises binascii.Error instead of TypeError as in Py27
1260             try:
1261                 decoded = base64.b64decode(contents)
1262                 return path, decoded
1263             except (TypeError, binascii.Error):
1264                 raise exception.Base64Exception(path=path)
1265 
1266         return [_decode(f) for f in injected_files]
1267 
1268     def _validate_instance_group_policy(self, context, instance,
1269             filter_properties):
1270         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1271         # However, there is a race condition with the enforcement of
1272         # the policy.  Since more than one instance may be scheduled at the
1273         # same time, it's possible that more than one instance with an
1274         # anti-affinity policy may end up here.  It's also possible that
1275         # multiple instances with an affinity policy could end up on different
1276         # hosts.  This is a validation step to make sure that starting the
1277         # instance here doesn't violate the policy.
1278 
1279         scheduler_hints = filter_properties.get('scheduler_hints') or {}
1280         group_hint = scheduler_hints.get('group')
1281         if not group_hint:
1282             return
1283 
1284         @utils.synchronized(group_hint)
1285         def _do_validation(context, instance, group_hint):
1286             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1287             if 'anti-affinity' in group.policies:
1288                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1289                 if self.host in group_hosts:
1290                     msg = _("Anti-affinity instance group policy "
1291                             "was violated.")
1292                     raise exception.RescheduledException(
1293                             instance_uuid=instance.uuid,
1294                             reason=msg)
1295             elif 'affinity' in group.policies:
1296                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1297                 if group_hosts and self.host not in group_hosts:
1298                     msg = _("Affinity instance group policy was violated.")
1299                     raise exception.RescheduledException(
1300                             instance_uuid=instance.uuid,
1301                             reason=msg)
1302 
1303         if not CONF.workarounds.disable_group_policy_check_upcall:
1304             _do_validation(context, instance, group_hint)
1305 
1306     def _log_original_error(self, exc_info, instance_uuid):
1307         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1308                   exc_info=exc_info)
1309 
1310     def _reschedule(self, context, request_spec, filter_properties,
1311             instance, reschedule_method, method_args, task_state,
1312             exc_info=None):
1313         """Attempt to re-schedule a compute operation."""
1314 
1315         instance_uuid = instance.uuid
1316         retry = filter_properties.get('retry')
1317         if not retry:
1318             # no retry information, do not reschedule.
1319             LOG.debug("Retry info not present, will not reschedule",
1320                       instance_uuid=instance_uuid)
1321             return
1322 
1323         if not request_spec:
1324             LOG.debug("No request spec, will not reschedule",
1325                       instance_uuid=instance_uuid)
1326             return
1327 
1328         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1329                   {'method': reschedule_method.__name__,
1330                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1331 
1332         # reset the task state:
1333         self._instance_update(context, instance, task_state=task_state)
1334 
1335         if exc_info:
1336             # stringify to avoid circular ref problem in json serialization:
1337             retry['exc'] = traceback.format_exception_only(exc_info[0],
1338                                     exc_info[1])
1339 
1340         reschedule_method(context, *method_args)
1341         return True
1342 
1343     @periodic_task.periodic_task
1344     def _check_instance_build_time(self, context):
1345         """Ensure that instances are not stuck in build."""
1346         timeout = CONF.instance_build_timeout
1347         if timeout == 0:
1348             return
1349 
1350         filters = {'vm_state': vm_states.BUILDING,
1351                    'host': self.host}
1352 
1353         building_insts = objects.InstanceList.get_by_filters(context,
1354                            filters, expected_attrs=[], use_slave=True)
1355 
1356         for instance in building_insts:
1357             if timeutils.is_older_than(instance.created_at, timeout):
1358                 self._set_instance_obj_error_state(context, instance)
1359                 LOG.warning("Instance build timed out. Set to error "
1360                             "state.", instance=instance)
1361 
1362     def _check_instance_exists(self, context, instance):
1363         """Ensure an instance with the same name is not already present."""
1364         if self.driver.instance_exists(instance):
1365             raise exception.InstanceExists(name=instance.name)
1366 
1367     def _allocate_network_async(self, context, instance, requested_networks,
1368                                 macs, security_groups, is_vpn, dhcp_options):
1369         """Method used to allocate networks in the background.
1370 
1371         Broken out for testing.
1372         """
1373         # First check to see if we're specifically not supposed to allocate
1374         # networks because if so, we can exit early.
1375         if requested_networks and requested_networks.no_allocate:
1376             LOG.debug("Not allocating networking since 'none' was specified.",
1377                       instance=instance)
1378             return network_model.NetworkInfo([])
1379 
1380         LOG.debug("Allocating IP information in the background.",
1381                   instance=instance)
1382         retries = CONF.network_allocate_retries
1383         attempts = retries + 1
1384         retry_time = 1
1385         bind_host_id = self.driver.network_binding_host_id(context, instance)
1386         for attempt in range(1, attempts + 1):
1387             try:
1388                 nwinfo = self.network_api.allocate_for_instance(
1389                         context, instance, vpn=is_vpn,
1390                         requested_networks=requested_networks,
1391                         macs=macs,
1392                         security_groups=security_groups,
1393                         dhcp_options=dhcp_options,
1394                         bind_host_id=bind_host_id)
1395                 LOG.debug('Instance network_info: |%s|', nwinfo,
1396                           instance=instance)
1397                 instance.system_metadata['network_allocated'] = 'True'
1398                 # NOTE(JoshNang) do not save the instance here, as it can cause
1399                 # races. The caller shares a reference to instance and waits
1400                 # for this async greenthread to finish before calling
1401                 # instance.save().
1402                 return nwinfo
1403             except Exception:
1404                 exc_info = sys.exc_info()
1405                 log_info = {'attempt': attempt,
1406                             'attempts': attempts}
1407                 if attempt == attempts:
1408                     LOG.exception('Instance failed network setup '
1409                                   'after %(attempts)d attempt(s)',
1410                                   log_info)
1411                     six.reraise(*exc_info)
1412                 LOG.warning('Instance failed network setup '
1413                             '(attempt %(attempt)d of %(attempts)d)',
1414                             log_info, instance=instance)
1415                 time.sleep(retry_time)
1416                 retry_time *= 2
1417                 if retry_time > 30:
1418                     retry_time = 30
1419         # Not reached.
1420 
1421     def _build_networks_for_instance(self, context, instance,
1422             requested_networks, security_groups):
1423 
1424         # If we're here from a reschedule the network may already be allocated.
1425         if strutils.bool_from_string(
1426                 instance.system_metadata.get('network_allocated', 'False')):
1427             # NOTE(alex_xu): The network_allocated is True means the network
1428             # resource already allocated at previous scheduling, and the
1429             # network setup is cleanup at previous. After rescheduling, the
1430             # network resource need setup on the new host.
1431             self.network_api.setup_instance_network_on_host(
1432                 context, instance, instance.host)
1433             return self.network_api.get_instance_nw_info(context, instance)
1434 
1435         if not self.is_neutron_security_groups:
1436             security_groups = []
1437 
1438         macs = self.driver.macs_for_instance(instance)
1439         dhcp_options = self.driver.dhcp_options_for_instance(instance)
1440         network_info = self._allocate_network(context, instance,
1441                 requested_networks, macs, security_groups, dhcp_options)
1442 
1443         return network_info
1444 
1445     def _allocate_network(self, context, instance, requested_networks, macs,
1446                           security_groups, dhcp_options):
1447         """Start network allocation asynchronously.  Return an instance
1448         of NetworkInfoAsyncWrapper that can be used to retrieve the
1449         allocated networks when the operation has finished.
1450         """
1451         # NOTE(comstud): Since we're allocating networks asynchronously,
1452         # this task state has little meaning, as we won't be in this
1453         # state for very long.
1454         instance.vm_state = vm_states.BUILDING
1455         instance.task_state = task_states.NETWORKING
1456         instance.save(expected_task_state=[None])
1457         self._update_resource_tracker(context, instance)
1458 
1459         is_vpn = False
1460         return network_model.NetworkInfoAsyncWrapper(
1461                 self._allocate_network_async, context, instance,
1462                 requested_networks, macs, security_groups, is_vpn,
1463                 dhcp_options)
1464 
1465     def _default_root_device_name(self, instance, image_meta, root_bdm):
1466         try:
1467             return self.driver.default_root_device_name(instance,
1468                                                         image_meta,
1469                                                         root_bdm)
1470         except NotImplementedError:
1471             return compute_utils.get_next_device_name(instance, [])
1472 
1473     def _default_device_names_for_instance(self, instance,
1474                                            root_device_name,
1475                                            *block_device_lists):
1476         try:
1477             self.driver.default_device_names_for_instance(instance,
1478                                                           root_device_name,
1479                                                           *block_device_lists)
1480         except NotImplementedError:
1481             compute_utils.default_device_names_for_instance(
1482                 instance, root_device_name, *block_device_lists)
1483 
1484     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1485         # NOTE(ndipanov): Copy obj to avoid changing the original
1486         block_device_obj = block_device_obj.obj_clone()
1487         try:
1488             return self.driver.get_device_name_for_instance(
1489                 instance, bdms, block_device_obj)
1490         except NotImplementedError:
1491             return compute_utils.get_device_name_for_instance(
1492                 instance, bdms, block_device_obj.get("device_name"))
1493 
1494     def _default_block_device_names(self, instance, image_meta, block_devices):
1495         """Verify that all the devices have the device_name set. If not,
1496         provide a default name.
1497 
1498         It also ensures that there is a root_device_name and is set to the
1499         first block device in the boot sequence (boot_index=0).
1500         """
1501         root_bdm = block_device.get_root_bdm(block_devices)
1502         if not root_bdm:
1503             return
1504 
1505         # Get the root_device_name from the root BDM or the instance
1506         root_device_name = None
1507         update_root_bdm = False
1508 
1509         if root_bdm.device_name:
1510             root_device_name = root_bdm.device_name
1511             instance.root_device_name = root_device_name
1512         elif instance.root_device_name:
1513             root_device_name = instance.root_device_name
1514             root_bdm.device_name = root_device_name
1515             update_root_bdm = True
1516         else:
1517             root_device_name = self._default_root_device_name(instance,
1518                                                               image_meta,
1519                                                               root_bdm)
1520 
1521             instance.root_device_name = root_device_name
1522             root_bdm.device_name = root_device_name
1523             update_root_bdm = True
1524 
1525         if update_root_bdm:
1526             root_bdm.save()
1527 
1528         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1529                             block_devices))
1530         swap = list(filter(block_device.new_format_is_swap,
1531                       block_devices))
1532         block_device_mapping = list(filter(
1533               driver_block_device.is_block_device_mapping, block_devices))
1534 
1535         self._default_device_names_for_instance(instance,
1536                                                 root_device_name,
1537                                                 ephemerals,
1538                                                 swap,
1539                                                 block_device_mapping)
1540 
1541     def _block_device_info_to_legacy(self, block_device_info):
1542         """Convert BDI to the old format for drivers that need it."""
1543 
1544         if self.use_legacy_block_device_info:
1545             ephemerals = driver_block_device.legacy_block_devices(
1546                 driver.block_device_info_get_ephemerals(block_device_info))
1547             mapping = driver_block_device.legacy_block_devices(
1548                 driver.block_device_info_get_mapping(block_device_info))
1549             swap = block_device_info['swap']
1550             if swap:
1551                 swap = swap.legacy()
1552 
1553             block_device_info.update({
1554                 'ephemerals': ephemerals,
1555                 'swap': swap,
1556                 'block_device_mapping': mapping})
1557 
1558     def _add_missing_dev_names(self, bdms, instance):
1559         for bdm in bdms:
1560             if bdm.device_name is not None:
1561                 continue
1562 
1563             device_name = self._get_device_name_for_instance(instance,
1564                                                              bdms, bdm)
1565             values = {'device_name': device_name}
1566             bdm.update(values)
1567             bdm.save()
1568 
1569     def _prep_block_device(self, context, instance, bdms):
1570         """Set up the block device for an instance with error logging."""
1571         try:
1572             self._add_missing_dev_names(bdms, instance)
1573             block_device_info = driver.get_block_device_info(instance, bdms)
1574             mapping = driver.block_device_info_get_mapping(block_device_info)
1575             driver_block_device.attach_block_devices(
1576                 mapping, context, instance, self.volume_api, self.driver,
1577                 wait_func=self._await_block_device_map_created)
1578 
1579             self._block_device_info_to_legacy(block_device_info)
1580             return block_device_info
1581 
1582         except exception.OverQuota as e:
1583             LOG.warning('Failed to create block device for instance due'
1584                         ' to exceeding volume related resource quota.'
1585                         ' Error: %s', e.message, instance=instance)
1586             raise
1587 
1588         except Exception:
1589             LOG.exception('Instance failed block device setup',
1590                           instance=instance)
1591             raise exception.InvalidBDM()
1592 
1593     def _update_instance_after_spawn(self, context, instance):
1594         instance.power_state = self._get_power_state(context, instance)
1595         instance.vm_state = vm_states.ACTIVE
1596         instance.task_state = None
1597         instance.launched_at = timeutils.utcnow()
1598         configdrive.update_instance(instance)
1599 
1600     def _update_scheduler_instance_info(self, context, instance):
1601         """Sends an InstanceList with created or updated Instance objects to
1602         the Scheduler client.
1603 
1604         In the case of init_host, the value passed will already be an
1605         InstanceList. Other calls will send individual Instance objects that
1606         have been created or resized. In this case, we create an InstanceList
1607         object containing that Instance.
1608         """
1609         if not self.send_instance_updates:
1610             return
1611         if isinstance(instance, obj_instance.Instance):
1612             instance = objects.InstanceList(objects=[instance])
1613         context = context.elevated()
1614         self.scheduler_client.update_instance_info(context, self.host,
1615                                                    instance)
1616 
1617     def _delete_scheduler_instance_info(self, context, instance_uuid):
1618         """Sends the uuid of the deleted Instance to the Scheduler client."""
1619         if not self.send_instance_updates:
1620             return
1621         context = context.elevated()
1622         self.scheduler_client.delete_instance_info(context, self.host,
1623                                                    instance_uuid)
1624 
1625     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1626     def _sync_scheduler_instance_info(self, context):
1627         if not self.send_instance_updates:
1628             return
1629         context = context.elevated()
1630         instances = objects.InstanceList.get_by_host(context, self.host,
1631                                                      expected_attrs=[],
1632                                                      use_slave=True)
1633         uuids = [instance.uuid for instance in instances]
1634         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1635 
1636     def _notify_about_instance_usage(self, context, instance, event_suffix,
1637                                      network_info=None, system_metadata=None,
1638                                      extra_usage_info=None, fault=None):
1639         compute_utils.notify_about_instance_usage(
1640             self.notifier, context, instance, event_suffix,
1641             network_info=network_info,
1642             system_metadata=system_metadata,
1643             extra_usage_info=extra_usage_info, fault=fault)
1644 
1645     def _deallocate_network(self, context, instance,
1646                             requested_networks=None):
1647         # If we were told not to allocate networks let's save ourselves
1648         # the trouble of calling the network API.
1649         if requested_networks and requested_networks.no_allocate:
1650             LOG.debug("Skipping network deallocation for instance since "
1651                       "networking was not requested.", instance=instance)
1652             return
1653 
1654         LOG.debug('Deallocating network for instance', instance=instance)
1655         with timeutils.StopWatch() as timer:
1656             self.network_api.deallocate_for_instance(
1657                 context, instance, requested_networks=requested_networks)
1658         # nova-network does an rpc call so we're OK tracking time spent here
1659         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1660                  timer.elapsed(), instance=instance)
1661 
1662     def _get_instance_block_device_info(self, context, instance,
1663                                         refresh_conn_info=False,
1664                                         bdms=None):
1665         """Transform block devices to the driver block_device format."""
1666 
1667         if not bdms:
1668             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1669                     context, instance.uuid)
1670         block_device_info = driver.get_block_device_info(instance, bdms)
1671 
1672         if not refresh_conn_info:
1673             # if the block_device_mapping has no value in connection_info
1674             # (returned as None), don't include in the mapping
1675             block_device_info['block_device_mapping'] = [
1676                 bdm for bdm in driver.block_device_info_get_mapping(
1677                                     block_device_info)
1678                 if bdm.get('connection_info')]
1679         else:
1680             driver_block_device.refresh_conn_infos(
1681                 driver.block_device_info_get_mapping(block_device_info),
1682                 context, instance, self.volume_api, self.driver)
1683 
1684         self._block_device_info_to_legacy(block_device_info)
1685 
1686         return block_device_info
1687 
1688     def _build_failed(self):
1689         self._failed_builds += 1
1690         limit = CONF.compute.consecutive_build_service_disable_threshold
1691         if limit and self._failed_builds >= limit:
1692             # NOTE(danms): If we're doing a bunch of parallel builds,
1693             # it is possible (although not likely) that we have already
1694             # failed N-1 builds before this and we race with a successful
1695             # build and disable ourselves here when we might've otherwise
1696             # not.
1697             LOG.error('Disabling service due to %(fails)i '
1698                       'consecutive build failures',
1699                       {'fails': self._failed_builds})
1700             ctx = nova.context.get_admin_context()
1701             service = objects.Service.get_by_compute_host(ctx, CONF.host)
1702             service.disabled = True
1703             service.disabled_reason = (
1704                 'Auto-disabled due to %i build failures' % self._failed_builds)
1705             service.save()
1706             # NOTE(danms): Reset our counter now so that when the admin
1707             # re-enables us we can start fresh
1708             self._failed_builds = 0
1709         elif self._failed_builds > 1:
1710             LOG.warning('%(fails)i consecutive build failures',
1711                         {'fails': self._failed_builds})
1712 
1713     @wrap_exception()
1714     @reverts_task_state
1715     @wrap_instance_fault
1716     def build_and_run_instance(self, context, instance, image, request_spec,
1717                      filter_properties, admin_password=None,
1718                      injected_files=None, requested_networks=None,
1719                      security_groups=None, block_device_mapping=None,
1720                      node=None, limits=None):
1721 
1722         @utils.synchronized(instance.uuid)
1723         def _locked_do_build_and_run_instance(*args, **kwargs):
1724             # NOTE(danms): We grab the semaphore with the instance uuid
1725             # locked because we could wait in line to build this instance
1726             # for a while and we want to make sure that nothing else tries
1727             # to do anything with this instance while we wait.
1728             with self._build_semaphore:
1729                 try:
1730                     result = self._do_build_and_run_instance(*args, **kwargs)
1731                 except Exception:
1732                     result = build_results.FAILED
1733                     raise
1734                 finally:
1735                     fails = (build_results.FAILED,
1736                              build_results.RESCHEDULED)
1737                     if result in fails:
1738                         self._build_failed()
1739                     else:
1740                         self._failed_builds = 0
1741 
1742         # NOTE(danms): We spawn here to return the RPC worker thread back to
1743         # the pool. Since what follows could take a really long time, we don't
1744         # want to tie up RPC workers.
1745         utils.spawn_n(_locked_do_build_and_run_instance,
1746                       context, instance, image, request_spec,
1747                       filter_properties, admin_password, injected_files,
1748                       requested_networks, security_groups,
1749                       block_device_mapping, node, limits)
1750 
1751     def _check_device_tagging(self, requested_networks, block_device_mapping):
1752         tagging_requested = False
1753         if requested_networks:
1754             for net in requested_networks:
1755                 if 'tag' in net and net.tag is not None:
1756                     tagging_requested = True
1757                     break
1758         if block_device_mapping and not tagging_requested:
1759             for bdm in block_device_mapping:
1760                 if 'tag' in bdm and bdm.tag is not None:
1761                     tagging_requested = True
1762                     break
1763         if (tagging_requested and
1764                 not self.driver.capabilities.get('supports_device_tagging')):
1765             raise exception.BuildAbortException('Attempt to boot guest with '
1766                                                 'tagged devices on host that '
1767                                                 'does not support tagging.')
1768 
1769     @hooks.add_hook('build_instance')
1770     @wrap_exception()
1771     @reverts_task_state
1772     @wrap_instance_event(prefix='compute')
1773     @wrap_instance_fault
1774     def _do_build_and_run_instance(self, context, instance, image,
1775             request_spec, filter_properties, admin_password, injected_files,
1776             requested_networks, security_groups, block_device_mapping,
1777             node=None, limits=None):
1778 
1779         try:
1780             LOG.debug('Starting instance...', instance=instance)
1781             instance.vm_state = vm_states.BUILDING
1782             instance.task_state = None
1783             instance.save(expected_task_state=
1784                     (task_states.SCHEDULING, None))
1785         except exception.InstanceNotFound:
1786             msg = 'Instance disappeared before build.'
1787             LOG.debug(msg, instance=instance)
1788             return build_results.FAILED
1789         except exception.UnexpectedTaskStateError as e:
1790             LOG.debug(e.format_message(), instance=instance)
1791             return build_results.FAILED
1792 
1793         # b64 decode the files to inject:
1794         decoded_files = self._decode_files(injected_files)
1795 
1796         if limits is None:
1797             limits = {}
1798 
1799         if node is None:
1800             node = self.driver.get_available_nodes(refresh=True)[0]
1801             LOG.debug('No node specified, defaulting to %s', node,
1802                       instance=instance)
1803 
1804         try:
1805             with timeutils.StopWatch() as timer:
1806                 self._build_and_run_instance(context, instance, image,
1807                         decoded_files, admin_password, requested_networks,
1808                         security_groups, block_device_mapping, node, limits,
1809                         filter_properties)
1810             LOG.info('Took %0.2f seconds to build instance.',
1811                      timer.elapsed(), instance=instance)
1812             return build_results.ACTIVE
1813         except exception.RescheduledException as e:
1814             retry = filter_properties.get('retry')
1815             if not retry:
1816                 # no retry information, do not reschedule.
1817                 LOG.debug("Retry info not present, will not reschedule",
1818                     instance=instance)
1819                 self._cleanup_allocated_networks(context, instance,
1820                     requested_networks)
1821                 self._cleanup_volumes(context, instance.uuid,
1822                     block_device_mapping, raise_exc=False)
1823                 compute_utils.add_instance_fault_from_exc(context,
1824                         instance, e, sys.exc_info(),
1825                         fault_message=e.kwargs['reason'])
1826                 self._nil_out_instance_obj_host_and_node(instance)
1827                 self._set_instance_obj_error_state(context, instance,
1828                                                    clean_task_state=True)
1829                 return build_results.FAILED
1830             LOG.debug(e.format_message(), instance=instance)
1831             # This will be used for logging the exception
1832             retry['exc'] = traceback.format_exception(*sys.exc_info())
1833             # This will be used for setting the instance fault message
1834             retry['exc_reason'] = e.kwargs['reason']
1835             # NOTE(comstud): Deallocate networks if the driver wants
1836             # us to do so.
1837             # NOTE(vladikr): SR-IOV ports should be deallocated to
1838             # allow new sriov pci devices to be allocated on a new host.
1839             # Otherwise, if devices with pci addresses are already allocated
1840             # on the destination host, the instance will fail to spawn.
1841             # info_cache.network_info should be present at this stage.
1842             if (self.driver.deallocate_networks_on_reschedule(instance) or
1843                 self.deallocate_sriov_ports_on_reschedule(instance)):
1844                 self._cleanup_allocated_networks(context, instance,
1845                         requested_networks)
1846             else:
1847                 # NOTE(alex_xu): Network already allocated and we don't
1848                 # want to deallocate them before rescheduling. But we need
1849                 # to cleanup those network resources setup on this host before
1850                 # rescheduling.
1851                 self.network_api.cleanup_instance_network_on_host(
1852                     context, instance, self.host)
1853 
1854             self._nil_out_instance_obj_host_and_node(instance)
1855             instance.task_state = task_states.SCHEDULING
1856             instance.save()
1857 
1858             self.compute_task_api.build_instances(context, [instance],
1859                     image, filter_properties, admin_password,
1860                     injected_files, requested_networks, security_groups,
1861                     block_device_mapping)
1862             return build_results.RESCHEDULED
1863         except (exception.InstanceNotFound,
1864                 exception.UnexpectedDeletingTaskStateError):
1865             msg = 'Instance disappeared during build.'
1866             LOG.debug(msg, instance=instance)
1867             self._cleanup_allocated_networks(context, instance,
1868                     requested_networks)
1869             return build_results.FAILED
1870         except exception.BuildAbortException as e:
1871             LOG.exception(e.format_message(), instance=instance)
1872             self._cleanup_allocated_networks(context, instance,
1873                     requested_networks)
1874             self._cleanup_volumes(context, instance.uuid,
1875                     block_device_mapping, raise_exc=False)
1876             compute_utils.add_instance_fault_from_exc(context, instance,
1877                     e, sys.exc_info())
1878             self._nil_out_instance_obj_host_and_node(instance)
1879             self._set_instance_obj_error_state(context, instance,
1880                                                clean_task_state=True)
1881             return build_results.FAILED
1882         except Exception as e:
1883             # Should not reach here.
1884             LOG.exception('Unexpected build failure, not rescheduling build.',
1885                           instance=instance)
1886             self._cleanup_allocated_networks(context, instance,
1887                     requested_networks)
1888             self._cleanup_volumes(context, instance.uuid,
1889                     block_device_mapping, raise_exc=False)
1890             compute_utils.add_instance_fault_from_exc(context, instance,
1891                     e, sys.exc_info())
1892             self._nil_out_instance_obj_host_and_node(instance)
1893             self._set_instance_obj_error_state(context, instance,
1894                                                clean_task_state=True)
1895             return build_results.FAILED
1896 
1897     def deallocate_sriov_ports_on_reschedule(self, instance):
1898         """Determine if networks are needed to be deallocated before reschedule
1899 
1900         Check the cached network info for any assigned SR-IOV ports.
1901         SR-IOV ports should be deallocated prior to rescheduling
1902         in order to allow new sriov pci devices to be allocated on a new host.
1903         """
1904         info_cache = instance.info_cache
1905 
1906         def _has_sriov_port(vif):
1907             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1908 
1909         if (info_cache and info_cache.network_info):
1910             for vif in info_cache.network_info:
1911                 if _has_sriov_port(vif):
1912                     return True
1913         return False
1914 
1915     def _build_and_run_instance(self, context, instance, image, injected_files,
1916             admin_password, requested_networks, security_groups,
1917             block_device_mapping, node, limits, filter_properties):
1918 
1919         image_name = image.get('name')
1920         self._notify_about_instance_usage(context, instance, 'create.start',
1921                 extra_usage_info={'image_name': image_name})
1922         compute_utils.notify_about_instance_create(
1923             context, instance, self.host,
1924             phase=fields.NotificationPhase.START)
1925 
1926         # NOTE(mikal): cache the keystone roles associated with the instance
1927         # at boot time for later reference
1928         instance.system_metadata.update(
1929             {'boot_roles': ','.join(context.roles)})
1930 
1931         self._check_device_tagging(requested_networks, block_device_mapping)
1932 
1933         try:
1934             rt = self._get_resource_tracker()
1935             with rt.instance_claim(context, instance, node, limits):
1936                 # NOTE(russellb) It's important that this validation be done
1937                 # *after* the resource tracker instance claim, as that is where
1938                 # the host is set on the instance.
1939                 self._validate_instance_group_policy(context, instance,
1940                         filter_properties)
1941                 image_meta = objects.ImageMeta.from_dict(image)
1942                 with self._build_resources(context, instance,
1943                         requested_networks, security_groups, image_meta,
1944                         block_device_mapping) as resources:
1945                     instance.vm_state = vm_states.BUILDING
1946                     instance.task_state = task_states.SPAWNING
1947                     # NOTE(JoshNang) This also saves the changes to the
1948                     # instance from _allocate_network_async, as they aren't
1949                     # saved in that function to prevent races.
1950                     instance.save(expected_task_state=
1951                             task_states.BLOCK_DEVICE_MAPPING)
1952                     block_device_info = resources['block_device_info']
1953                     network_info = resources['network_info']
1954                     LOG.debug('Start spawning the instance on the hypervisor.',
1955                               instance=instance)
1956                     with timeutils.StopWatch() as timer:
1957                         self.driver.spawn(context, instance, image_meta,
1958                                           injected_files, admin_password,
1959                                           network_info=network_info,
1960                                           block_device_info=block_device_info)
1961                     LOG.info('Took %0.2f seconds to spawn the instance on '
1962                              'the hypervisor.', timer.elapsed(),
1963                              instance=instance)
1964         except (exception.InstanceNotFound,
1965                 exception.UnexpectedDeletingTaskStateError) as e:
1966             with excutils.save_and_reraise_exception():
1967                 self._notify_about_instance_usage(context, instance,
1968                     'create.error', fault=e)
1969                 compute_utils.notify_about_instance_create(
1970                     context, instance, self.host,
1971                     phase=fields.NotificationPhase.ERROR, exception=e)
1972         except exception.ComputeResourcesUnavailable as e:
1973             LOG.debug(e.format_message(), instance=instance)
1974             self._notify_about_instance_usage(context, instance,
1975                     'create.error', fault=e)
1976             compute_utils.notify_about_instance_create(
1977                     context, instance, self.host,
1978                     phase=fields.NotificationPhase.ERROR, exception=e)
1979             raise exception.RescheduledException(
1980                     instance_uuid=instance.uuid, reason=e.format_message())
1981         except exception.BuildAbortException as e:
1982             with excutils.save_and_reraise_exception():
1983                 LOG.debug(e.format_message(), instance=instance)
1984                 self._notify_about_instance_usage(context, instance,
1985                     'create.error', fault=e)
1986                 compute_utils.notify_about_instance_create(
1987                     context, instance, self.host,
1988                     phase=fields.NotificationPhase.ERROR, exception=e)
1989         except (exception.FixedIpLimitExceeded,
1990                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
1991             LOG.warning('No more network or fixed IP to be allocated',
1992                         instance=instance)
1993             self._notify_about_instance_usage(context, instance,
1994                     'create.error', fault=e)
1995             compute_utils.notify_about_instance_create(
1996                     context, instance, self.host,
1997                     phase=fields.NotificationPhase.ERROR, exception=e)
1998             msg = _('Failed to allocate the network(s) with error %s, '
1999                     'not rescheduling.') % e.format_message()
2000             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2001                     reason=msg)
2002         except (exception.VirtualInterfaceCreateException,
2003                 exception.VirtualInterfaceMacAddressException,
2004                 exception.FixedIpInvalidOnHost,
2005                 exception.UnableToAutoAllocateNetwork) as e:
2006             LOG.exception('Failed to allocate network(s)',
2007                           instance=instance)
2008             self._notify_about_instance_usage(context, instance,
2009                     'create.error', fault=e)
2010             compute_utils.notify_about_instance_create(
2011                     context, instance, self.host,
2012                     phase=fields.NotificationPhase.ERROR, exception=e)
2013             msg = _('Failed to allocate the network(s), not rescheduling.')
2014             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2015                     reason=msg)
2016         except (exception.FlavorDiskTooSmall,
2017                 exception.FlavorMemoryTooSmall,
2018                 exception.ImageNotActive,
2019                 exception.ImageUnacceptable,
2020                 exception.InvalidDiskInfo,
2021                 exception.InvalidDiskFormat,
2022                 cursive_exception.SignatureVerificationError,
2023                 exception.VolumeEncryptionNotSupported,
2024                 exception.InvalidInput) as e:
2025             self._notify_about_instance_usage(context, instance,
2026                     'create.error', fault=e)
2027             compute_utils.notify_about_instance_create(
2028                     context, instance, self.host,
2029                     phase=fields.NotificationPhase.ERROR, exception=e)
2030             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2031                     reason=e.format_message())
2032         except Exception as e:
2033             self._notify_about_instance_usage(context, instance,
2034                     'create.error', fault=e)
2035             compute_utils.notify_about_instance_create(
2036                     context, instance, self.host,
2037                     phase=fields.NotificationPhase.ERROR, exception=e)
2038             raise exception.RescheduledException(
2039                     instance_uuid=instance.uuid, reason=six.text_type(e))
2040 
2041         # NOTE(alaski): This is only useful during reschedules, remove it now.
2042         instance.system_metadata.pop('network_allocated', None)
2043 
2044         # If CONF.default_access_ip_network_name is set, grab the
2045         # corresponding network and set the access ip values accordingly.
2046         network_name = CONF.default_access_ip_network_name
2047         if (network_name and not instance.access_ip_v4 and
2048                 not instance.access_ip_v6):
2049             # Note that when there are multiple ips to choose from, an
2050             # arbitrary one will be chosen.
2051             for vif in network_info:
2052                 if vif['network']['label'] == network_name:
2053                     for ip in vif.fixed_ips():
2054                         if not instance.access_ip_v4 and ip['version'] == 4:
2055                             instance.access_ip_v4 = ip['address']
2056                         if not instance.access_ip_v6 and ip['version'] == 6:
2057                             instance.access_ip_v6 = ip['address']
2058                     break
2059 
2060         self._update_instance_after_spawn(context, instance)
2061 
2062         try:
2063             instance.save(expected_task_state=task_states.SPAWNING)
2064         except (exception.InstanceNotFound,
2065                 exception.UnexpectedDeletingTaskStateError) as e:
2066             with excutils.save_and_reraise_exception():
2067                 self._notify_about_instance_usage(context, instance,
2068                     'create.error', fault=e)
2069                 compute_utils.notify_about_instance_create(
2070                     context, instance, self.host,
2071                     phase=fields.NotificationPhase.ERROR, exception=e)
2072 
2073         self._update_scheduler_instance_info(context, instance)
2074         self._notify_about_instance_usage(context, instance, 'create.end',
2075                 extra_usage_info={'message': _('Success')},
2076                 network_info=network_info)
2077         compute_utils.notify_about_instance_create(context, instance,
2078                 self.host, phase=fields.NotificationPhase.END)
2079 
2080     @contextlib.contextmanager
2081     def _build_resources(self, context, instance, requested_networks,
2082                          security_groups, image_meta, block_device_mapping):
2083         resources = {}
2084         network_info = None
2085         try:
2086             LOG.debug('Start building networks asynchronously for instance.',
2087                       instance=instance)
2088             network_info = self._build_networks_for_instance(context, instance,
2089                     requested_networks, security_groups)
2090             resources['network_info'] = network_info
2091         except (exception.InstanceNotFound,
2092                 exception.UnexpectedDeletingTaskStateError):
2093             raise
2094         except exception.UnexpectedTaskStateError as e:
2095             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2096                     reason=e.format_message())
2097         except Exception:
2098             # Because this allocation is async any failures are likely to occur
2099             # when the driver accesses network_info during spawn().
2100             LOG.exception('Failed to allocate network(s)',
2101                           instance=instance)
2102             msg = _('Failed to allocate the network(s), not rescheduling.')
2103             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2104                     reason=msg)
2105 
2106         try:
2107             # Verify that all the BDMs have a device_name set and assign a
2108             # default to the ones missing it with the help of the driver.
2109             self._default_block_device_names(instance, image_meta,
2110                                              block_device_mapping)
2111 
2112             LOG.debug('Start building block device mappings for instance.',
2113                       instance=instance)
2114             instance.vm_state = vm_states.BUILDING
2115             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2116             instance.save()
2117 
2118             block_device_info = self._prep_block_device(context, instance,
2119                     block_device_mapping)
2120             resources['block_device_info'] = block_device_info
2121         except (exception.InstanceNotFound,
2122                 exception.UnexpectedDeletingTaskStateError):
2123             with excutils.save_and_reraise_exception():
2124                 # Make sure the async call finishes
2125                 if network_info is not None:
2126                     network_info.wait(do_raise=False)
2127         except (exception.UnexpectedTaskStateError,
2128                 exception.OverQuota, exception.InvalidBDM) as e:
2129             # Make sure the async call finishes
2130             if network_info is not None:
2131                 network_info.wait(do_raise=False)
2132             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2133                     reason=e.format_message())
2134         except Exception:
2135             LOG.exception('Failure prepping block device',
2136                           instance=instance)
2137             # Make sure the async call finishes
2138             if network_info is not None:
2139                 network_info.wait(do_raise=False)
2140             msg = _('Failure prepping block device.')
2141             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2142                     reason=msg)
2143 
2144         try:
2145             yield resources
2146         except Exception as exc:
2147             with excutils.save_and_reraise_exception() as ctxt:
2148                 if not isinstance(exc, (
2149                         exception.InstanceNotFound,
2150                         exception.UnexpectedDeletingTaskStateError)):
2151                     LOG.exception('Instance failed to spawn',
2152                                   instance=instance)
2153                 # Make sure the async call finishes
2154                 if network_info is not None:
2155                     network_info.wait(do_raise=False)
2156                 # if network_info is empty we're likely here because of
2157                 # network allocation failure. Since nothing can be reused on
2158                 # rescheduling it's better to deallocate network to eliminate
2159                 # the chance of orphaned ports in neutron
2160                 deallocate_networks = False if network_info else True
2161                 try:
2162                     self._shutdown_instance(context, instance,
2163                             block_device_mapping, requested_networks,
2164                             try_deallocate_networks=deallocate_networks)
2165                 except Exception as exc2:
2166                     ctxt.reraise = False
2167                     LOG.warning('Could not clean up failed build,'
2168                                 ' not rescheduling. Error: %s',
2169                                 six.text_type(exc2))
2170                     raise exception.BuildAbortException(
2171                             instance_uuid=instance.uuid,
2172                             reason=six.text_type(exc))
2173 
2174     def _cleanup_allocated_networks(self, context, instance,
2175             requested_networks):
2176         try:
2177             self._deallocate_network(context, instance, requested_networks)
2178         except Exception:
2179             LOG.exception('Failed to deallocate networks', instance=instance)
2180             return
2181 
2182         instance.system_metadata['network_allocated'] = 'False'
2183         try:
2184             instance.save()
2185         except exception.InstanceNotFound:
2186             # NOTE(alaski): It's possible that we're cleaning up the networks
2187             # because the instance was deleted.  If that's the case then this
2188             # exception will be raised by instance.save()
2189             pass
2190 
2191     def _try_deallocate_network(self, context, instance,
2192                                 requested_networks=None):
2193         try:
2194             # tear down allocated network structure
2195             self._deallocate_network(context, instance, requested_networks)
2196         except Exception as ex:
2197             with excutils.save_and_reraise_exception():
2198                 LOG.error('Failed to deallocate network for instance. '
2199                           'Error: %s', ex, instance=instance)
2200                 self._set_instance_obj_error_state(context, instance)
2201 
2202     def _get_power_off_values(self, context, instance, clean_shutdown):
2203         """Get the timing configuration for powering down this instance."""
2204         if clean_shutdown:
2205             timeout = compute_utils.get_value_from_system_metadata(instance,
2206                           key='image_os_shutdown_timeout', type=int,
2207                           default=CONF.shutdown_timeout)
2208             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2209         else:
2210             timeout = 0
2211             retry_interval = 0
2212 
2213         return timeout, retry_interval
2214 
2215     def _power_off_instance(self, context, instance, clean_shutdown=True):
2216         """Power off an instance on this host."""
2217         timeout, retry_interval = self._get_power_off_values(context,
2218                                         instance, clean_shutdown)
2219         self.driver.power_off(instance, timeout, retry_interval)
2220 
2221     def _shutdown_instance(self, context, instance,
2222                            bdms, requested_networks=None, notify=True,
2223                            try_deallocate_networks=True):
2224         """Shutdown an instance on this host.
2225 
2226         :param:context: security context
2227         :param:instance: a nova.objects.Instance object
2228         :param:bdms: the block devices for the instance to be torn
2229                      down
2230         :param:requested_networks: the networks on which the instance
2231                                    has ports
2232         :param:notify: true if a final usage notification should be
2233                        emitted
2234         :param:try_deallocate_networks: false if we should avoid
2235                                         trying to teardown networking
2236         """
2237         context = context.elevated()
2238         LOG.info('Terminating instance', instance=instance)
2239 
2240         if notify:
2241             self._notify_about_instance_usage(context, instance,
2242                                               "shutdown.start")
2243             compute_utils.notify_about_instance_action(context, instance,
2244                     self.host, action=fields.NotificationAction.SHUTDOWN,
2245                     phase=fields.NotificationPhase.START)
2246 
2247         network_info = instance.get_network_info()
2248 
2249         # NOTE(vish) get bdms before destroying the instance
2250         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2251         block_device_info = self._get_instance_block_device_info(
2252             context, instance, bdms=bdms)
2253 
2254         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2255         #                want to keep ip allocated for certain failures
2256         timer = timeutils.StopWatch()
2257         try:
2258             LOG.debug('Start destroying the instance on the hypervisor.',
2259                       instance=instance)
2260             timer.start()
2261             self.driver.destroy(context, instance, network_info,
2262                     block_device_info)
2263             LOG.info('Took %0.2f seconds to destroy the instance on the '
2264                      'hypervisor.', timer.elapsed(), instance=instance)
2265         except exception.InstancePowerOffFailure:
2266             # if the instance can't power off, don't release the ip
2267             with excutils.save_and_reraise_exception():
2268                 pass
2269         except Exception:
2270             with excutils.save_and_reraise_exception():
2271                 # deallocate ip and fail without proceeding to
2272                 # volume api calls, preserving current behavior
2273                 if try_deallocate_networks:
2274                     self._try_deallocate_network(context, instance,
2275                                                  requested_networks)
2276 
2277         if try_deallocate_networks:
2278             self._try_deallocate_network(context, instance, requested_networks)
2279 
2280         timer.restart()
2281         for bdm in vol_bdms:
2282             try:
2283                 if bdm.attachment_id:
2284                     self.volume_api.attachment_delete(context,
2285                                                       bdm.attachment_id)
2286                 else:
2287                     # NOTE(vish): actual driver detach done in driver.destroy,
2288                     #             so just tell cinder that we are done with it.
2289                     connector = self.driver.get_volume_connector(instance)
2290                     self.volume_api.terminate_connection(context,
2291                                                          bdm.volume_id,
2292                                                          connector)
2293                     self.volume_api.detach(context, bdm.volume_id,
2294                                            instance.uuid)
2295 
2296             except exception.VolumeAttachmentNotFound as exc:
2297                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2298                           instance=instance)
2299             except exception.DiskNotFound as exc:
2300                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2301                           instance=instance)
2302             except exception.VolumeNotFound as exc:
2303                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2304                           instance=instance)
2305             except (cinder_exception.EndpointNotFound,
2306                     keystone_exception.EndpointNotFound) as exc:
2307                 LOG.warning('Ignoring EndpointNotFound for '
2308                             'volume %(volume_id)s: %(exc)s',
2309                             {'exc': exc, 'volume_id': bdm.volume_id},
2310                             instance=instance)
2311             except cinder_exception.ClientException as exc:
2312                 LOG.warning('Ignoring unknown cinder exception for '
2313                             'volume %(volume_id)s: %(exc)s',
2314                             {'exc': exc, 'volume_id': bdm.volume_id},
2315                             instance=instance)
2316             except Exception as exc:
2317                 LOG.warning('Ignoring unknown exception for '
2318                             'volume %(volume_id)s: %(exc)s',
2319                             {'exc': exc, 'volume_id': bdm.volume_id},
2320                             instance=instance)
2321         if vol_bdms:
2322             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2323                      'for instance.',
2324                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2325                      instance=instance)
2326 
2327         if notify:
2328             self._notify_about_instance_usage(context, instance,
2329                                               "shutdown.end")
2330             compute_utils.notify_about_instance_action(context, instance,
2331                     self.host, action=fields.NotificationAction.SHUTDOWN,
2332                     phase=fields.NotificationPhase.END)
2333 
2334     def _cleanup_volumes(self, context, instance_uuid, bdms, raise_exc=True):
2335         exc_info = None
2336 
2337         for bdm in bdms:
2338             LOG.debug("terminating bdm %s", bdm,
2339                       instance_uuid=instance_uuid)
2340             if bdm.volume_id and bdm.delete_on_termination:
2341                 try:
2342                     self.volume_api.delete(context, bdm.volume_id)
2343                 except Exception as exc:
2344                     exc_info = sys.exc_info()
2345                     LOG.warning('Failed to delete volume: %(volume_id)s '
2346                                 'due to %(exc)s',
2347                                 {'volume_id': bdm.volume_id, 'exc': exc})
2348         if exc_info is not None and raise_exc:
2349             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2350 
2351     @hooks.add_hook("delete_instance")
2352     def _delete_instance(self, context, instance, bdms, quotas):
2353         """Delete an instance on this host.  Commit or rollback quotas
2354         as necessary.
2355 
2356         :param context: nova request context
2357         :param instance: nova.objects.instance.Instance object
2358         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2359         :param quotas: nova.objects.quotas.Quotas object
2360         """
2361         was_soft_deleted = instance.vm_state == vm_states.SOFT_DELETED
2362         if was_soft_deleted:
2363             # Instances in SOFT_DELETED vm_state have already had quotas
2364             # decremented.
2365             try:
2366                 quotas.rollback()
2367             except Exception:
2368                 pass
2369 
2370         try:
2371             events = self.instance_events.clear_events_for_instance(instance)
2372             if events:
2373                 LOG.debug('Events pending at deletion: %(events)s',
2374                           {'events': ','.join(events.keys())},
2375                           instance=instance)
2376             self._notify_about_instance_usage(context, instance,
2377                                               "delete.start")
2378             compute_utils.notify_about_instance_action(context, instance,
2379                     self.host, action=fields.NotificationAction.DELETE,
2380                     phase=fields.NotificationPhase.START)
2381 
2382             self._shutdown_instance(context, instance, bdms)
2383             # NOTE(dims): instance.info_cache.delete() should be called after
2384             # _shutdown_instance in the compute manager as shutdown calls
2385             # deallocate_for_instance so the info_cache is still needed
2386             # at this point.
2387             if instance.info_cache is not None:
2388                 instance.info_cache.delete()
2389             else:
2390                 # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2391                 # is None. When the root cause that instance.info_cache becomes
2392                 # None is fixed, the log level should be reconsidered.
2393                 LOG.warning("Info cache for instance could not be found. "
2394                             "Ignore.", instance=instance)
2395 
2396             # NOTE(vish): We have already deleted the instance, so we have
2397             #             to ignore problems cleaning up the volumes. It
2398             #             would be nice to let the user know somehow that
2399             #             the volume deletion failed, but it is not
2400             #             acceptable to have an instance that can not be
2401             #             deleted. Perhaps this could be reworked in the
2402             #             future to set an instance fault the first time
2403             #             and to only ignore the failure if the instance
2404             #             is already in ERROR.
2405             self._cleanup_volumes(context, instance.uuid, bdms,
2406                     raise_exc=False)
2407             # if a delete task succeeded, always update vm state and task
2408             # state without expecting task state to be DELETING
2409             instance.vm_state = vm_states.DELETED
2410             instance.task_state = None
2411             instance.power_state = power_state.NOSTATE
2412             instance.terminated_at = timeutils.utcnow()
2413             instance.save()
2414             system_meta = instance.system_metadata
2415             instance.destroy()
2416         except Exception:
2417             with excutils.save_and_reraise_exception():
2418                 quotas.rollback()
2419 
2420         self._complete_deletion(context,
2421                                 instance,
2422                                 bdms,
2423                                 quotas,
2424                                 system_meta)
2425 
2426     @wrap_exception()
2427     @reverts_task_state
2428     @wrap_instance_event(prefix='compute')
2429     @wrap_instance_fault
2430     def terminate_instance(self, context, instance, bdms, reservations):
2431         """Terminate an instance on this host."""
2432         quotas = objects.Quotas.from_reservations(context,
2433                                                   reservations,
2434                                                   instance=instance)
2435 
2436         @utils.synchronized(instance.uuid)
2437         def do_terminate_instance(instance, bdms):
2438             # NOTE(mriedem): If we are deleting the instance while it was
2439             # booting from volume, we could be racing with a database update of
2440             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2441             # to compute here, the BDMs may be stale at this point. So check
2442             # for any volume BDMs that don't have volume_id set and if we
2443             # detect that, we need to refresh the BDM list before proceeding.
2444             # TODO(mriedem): Move this into _delete_instance and make the bdms
2445             # parameter optional.
2446             for bdm in list(bdms):
2447                 if bdm.is_volume and not bdm.volume_id:
2448                     LOG.debug('There are potentially stale BDMs during '
2449                               'delete, refreshing the BlockDeviceMappingList.',
2450                               instance=instance)
2451                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2452                         context, instance.uuid)
2453                     break
2454             try:
2455                 self._delete_instance(context, instance, bdms, quotas)
2456             except exception.InstanceNotFound:
2457                 LOG.info("Instance disappeared during terminate",
2458                          instance=instance)
2459             except Exception:
2460                 # As we're trying to delete always go to Error if something
2461                 # goes wrong that _delete_instance can't handle.
2462                 with excutils.save_and_reraise_exception():
2463                     LOG.exception('Setting instance vm_state to ERROR',
2464                                   instance=instance)
2465                     self._set_instance_obj_error_state(context, instance)
2466 
2467         do_terminate_instance(instance, bdms)
2468 
2469     # NOTE(johannes): This is probably better named power_off_instance
2470     # so it matches the driver method, but because of other issues, we
2471     # can't use that name in grizzly.
2472     @wrap_exception()
2473     @reverts_task_state
2474     @wrap_instance_event(prefix='compute')
2475     @wrap_instance_fault
2476     def stop_instance(self, context, instance, clean_shutdown):
2477         """Stopping an instance on this host."""
2478 
2479         @utils.synchronized(instance.uuid)
2480         def do_stop_instance():
2481             current_power_state = self._get_power_state(context, instance)
2482             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2483                       'current task_state: %(task_state)s, current DB '
2484                       'power_state: %(db_power_state)s, current VM '
2485                       'power_state: %(current_power_state)s',
2486                       {'vm_state': instance.vm_state,
2487                        'task_state': instance.task_state,
2488                        'db_power_state': instance.power_state,
2489                        'current_power_state': current_power_state},
2490                       instance_uuid=instance.uuid)
2491 
2492             # NOTE(mriedem): If the instance is already powered off, we are
2493             # possibly tearing down and racing with other operations, so we can
2494             # expect the task_state to be None if something else updates the
2495             # instance and we're not locking it.
2496             expected_task_state = [task_states.POWERING_OFF]
2497             # The list of power states is from _sync_instance_power_state.
2498             if current_power_state in (power_state.NOSTATE,
2499                                        power_state.SHUTDOWN,
2500                                        power_state.CRASHED):
2501                 LOG.info('Instance is already powered off in the '
2502                          'hypervisor when stop is called.',
2503                          instance=instance)
2504                 expected_task_state.append(None)
2505 
2506             self._notify_about_instance_usage(context, instance,
2507                                               "power_off.start")
2508 
2509             compute_utils.notify_about_instance_action(context, instance,
2510                         self.host, action=fields.NotificationAction.POWER_OFF,
2511                         phase=fields.NotificationPhase.START)
2512 
2513             self._power_off_instance(context, instance, clean_shutdown)
2514             instance.power_state = self._get_power_state(context, instance)
2515             instance.vm_state = vm_states.STOPPED
2516             instance.task_state = None
2517             instance.save(expected_task_state=expected_task_state)
2518             self._notify_about_instance_usage(context, instance,
2519                                               "power_off.end")
2520 
2521             compute_utils.notify_about_instance_action(context, instance,
2522                         self.host, action=fields.NotificationAction.POWER_OFF,
2523                         phase=fields.NotificationPhase.END)
2524 
2525         do_stop_instance()
2526 
2527     def _power_on(self, context, instance):
2528         network_info = self.network_api.get_instance_nw_info(context, instance)
2529         block_device_info = self._get_instance_block_device_info(context,
2530                                                                  instance)
2531         self.driver.power_on(context, instance,
2532                              network_info,
2533                              block_device_info)
2534 
2535     def _delete_snapshot_of_shelved_instance(self, context, instance,
2536                                              snapshot_id):
2537         """Delete snapshot of shelved instance."""
2538         try:
2539             self.image_api.delete(context, snapshot_id)
2540         except (exception.ImageNotFound,
2541                 exception.ImageNotAuthorized) as exc:
2542             LOG.warning("Failed to delete snapshot "
2543                         "from shelved instance (%s).",
2544                         exc.format_message(), instance=instance)
2545         except Exception:
2546             LOG.exception("Something wrong happened when trying to "
2547                           "delete snapshot from shelved instance.",
2548                           instance=instance)
2549 
2550     # NOTE(johannes): This is probably better named power_on_instance
2551     # so it matches the driver method, but because of other issues, we
2552     # can't use that name in grizzly.
2553     @wrap_exception()
2554     @reverts_task_state
2555     @wrap_instance_event(prefix='compute')
2556     @wrap_instance_fault
2557     def start_instance(self, context, instance):
2558         """Starting an instance on this host."""
2559         self._notify_about_instance_usage(context, instance, "power_on.start")
2560         compute_utils.notify_about_instance_action(context, instance,
2561             self.host, action=fields.NotificationAction.POWER_ON,
2562             phase=fields.NotificationPhase.START)
2563         self._power_on(context, instance)
2564         instance.power_state = self._get_power_state(context, instance)
2565         instance.vm_state = vm_states.ACTIVE
2566         instance.task_state = None
2567 
2568         # Delete an image(VM snapshot) for a shelved instance
2569         snapshot_id = instance.system_metadata.get('shelved_image_id')
2570         if snapshot_id:
2571             self._delete_snapshot_of_shelved_instance(context, instance,
2572                                                       snapshot_id)
2573 
2574         # Delete system_metadata for a shelved instance
2575         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2576 
2577         instance.save(expected_task_state=task_states.POWERING_ON)
2578         self._notify_about_instance_usage(context, instance, "power_on.end")
2579         compute_utils.notify_about_instance_action(context, instance,
2580             self.host, action=fields.NotificationAction.POWER_ON,
2581             phase=fields.NotificationPhase.END)
2582 
2583     @messaging.expected_exceptions(NotImplementedError,
2584                                    exception.TriggerCrashDumpNotSupported,
2585                                    exception.InstanceNotRunning)
2586     @wrap_exception()
2587     @wrap_instance_event(prefix='compute')
2588     @wrap_instance_fault
2589     def trigger_crash_dump(self, context, instance):
2590         """Trigger crash dump in an instance."""
2591 
2592         self._notify_about_instance_usage(context, instance,
2593                                           "trigger_crash_dump.start")
2594 
2595         # This method does not change task_state and power_state because the
2596         # effect of a trigger depends on user's configuration.
2597         self.driver.trigger_crash_dump(instance)
2598 
2599         self._notify_about_instance_usage(context, instance,
2600                                           "trigger_crash_dump.end")
2601 
2602     @wrap_exception()
2603     @reverts_task_state
2604     @wrap_instance_event(prefix='compute')
2605     @wrap_instance_fault
2606     def soft_delete_instance(self, context, instance, reservations):
2607         """Soft delete an instance on this host."""
2608 
2609         quotas = objects.Quotas.from_reservations(context,
2610                                                   reservations,
2611                                                   instance=instance)
2612         try:
2613             self._notify_about_instance_usage(context, instance,
2614                                               "soft_delete.start")
2615             compute_utils.notify_about_instance_action(context, instance,
2616                 self.host, action=fields.NotificationAction.SOFT_DELETE,
2617                 phase=fields.NotificationPhase.START)
2618             try:
2619                 self.driver.soft_delete(instance)
2620             except NotImplementedError:
2621                 # Fallback to just powering off the instance if the
2622                 # hypervisor doesn't implement the soft_delete method
2623                 self.driver.power_off(instance)
2624             instance.power_state = self._get_power_state(context, instance)
2625             instance.vm_state = vm_states.SOFT_DELETED
2626             instance.task_state = None
2627             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2628         except Exception:
2629             with excutils.save_and_reraise_exception():
2630                 quotas.rollback()
2631         quotas.commit()
2632         self._notify_about_instance_usage(context, instance, "soft_delete.end")
2633         compute_utils.notify_about_instance_action(context, instance,
2634             self.host, action=fields.NotificationAction.SOFT_DELETE,
2635             phase=fields.NotificationPhase.END)
2636 
2637     @wrap_exception()
2638     @reverts_task_state
2639     @wrap_instance_event(prefix='compute')
2640     @wrap_instance_fault
2641     def restore_instance(self, context, instance):
2642         """Restore a soft-deleted instance on this host."""
2643         self._notify_about_instance_usage(context, instance, "restore.start")
2644         compute_utils.notify_about_instance_action(context, instance,
2645             self.host, action=fields.NotificationAction.RESTORE,
2646             phase=fields.NotificationPhase.START)
2647         try:
2648             self.driver.restore(instance)
2649         except NotImplementedError:
2650             # Fallback to just powering on the instance if the hypervisor
2651             # doesn't implement the restore method
2652             self._power_on(context, instance)
2653         instance.power_state = self._get_power_state(context, instance)
2654         instance.vm_state = vm_states.ACTIVE
2655         instance.task_state = None
2656         instance.save(expected_task_state=task_states.RESTORING)
2657         self._notify_about_instance_usage(context, instance, "restore.end")
2658         compute_utils.notify_about_instance_action(context, instance,
2659             self.host, action=fields.NotificationAction.RESTORE,
2660             phase=fields.NotificationPhase.END)
2661 
2662     @staticmethod
2663     def _set_migration_status(migration, status):
2664         """Set the status, and guard against a None being passed in.
2665 
2666         This is useful as some of the compute RPC calls will not pass
2667         a migration object in older versions. The check can be removed when
2668         we move past 4.x major version of the RPC API.
2669         """
2670         if migration:
2671             migration.status = status
2672             migration.save()
2673 
2674     def _rebuild_default_impl(self, context, instance, image_meta,
2675                               injected_files, admin_password, bdms,
2676                               detach_block_devices, attach_block_devices,
2677                               network_info=None,
2678                               recreate=False, block_device_info=None,
2679                               preserve_ephemeral=False):
2680         if preserve_ephemeral:
2681             # The default code path does not support preserving ephemeral
2682             # partitions.
2683             raise exception.PreserveEphemeralNotSupported()
2684 
2685         if recreate:
2686             detach_block_devices(context, bdms)
2687         else:
2688             self._power_off_instance(context, instance, clean_shutdown=True)
2689             detach_block_devices(context, bdms)
2690             self.driver.destroy(context, instance,
2691                                 network_info=network_info,
2692                                 block_device_info=block_device_info)
2693 
2694         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2695         instance.save(expected_task_state=[task_states.REBUILDING])
2696 
2697         new_block_device_info = attach_block_devices(context, instance, bdms)
2698 
2699         instance.task_state = task_states.REBUILD_SPAWNING
2700         instance.save(
2701             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2702 
2703         with instance.mutated_migration_context():
2704             self.driver.spawn(context, instance, image_meta, injected_files,
2705                               admin_password, network_info=network_info,
2706                               block_device_info=new_block_device_info)
2707 
2708     def _notify_instance_rebuild_error(self, context, instance, error):
2709         self._notify_about_instance_usage(context, instance,
2710                                           'rebuild.error', fault=error)
2711         compute_utils.notify_about_instance_action(
2712             context, instance, self.host,
2713             action=fields.NotificationAction.REBUILD,
2714             phase=fields.NotificationPhase.ERROR, exception=error)
2715 
2716     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2717     @wrap_exception()
2718     @reverts_task_state
2719     @wrap_instance_event(prefix='compute')
2720     @wrap_instance_fault
2721     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2722                          injected_files, new_pass, orig_sys_metadata,
2723                          bdms, recreate, on_shared_storage=None,
2724                          preserve_ephemeral=False, migration=None,
2725                          scheduled_node=None, limits=None):
2726         """Destroy and re-make this instance.
2727 
2728         A 'rebuild' effectively purges all existing data from the system and
2729         remakes the VM with given 'metadata' and 'personalities'.
2730 
2731         :param context: `nova.RequestContext` object
2732         :param instance: Instance object
2733         :param orig_image_ref: Original image_ref before rebuild
2734         :param image_ref: New image_ref for rebuild
2735         :param injected_files: Files to inject
2736         :param new_pass: password to set on rebuilt instance
2737         :param orig_sys_metadata: instance system metadata from pre-rebuild
2738         :param bdms: block-device-mappings to use for rebuild
2739         :param recreate: True if the instance is being recreated (e.g. the
2740             hypervisor it was on failed) - cleanup of old state will be
2741             skipped.
2742         :param on_shared_storage: True if instance files on shared storage.
2743                                   If not provided then information from the
2744                                   driver will be used to decide if the instance
2745                                   files are available or not on the target host
2746         :param preserve_ephemeral: True if the default ephemeral storage
2747                                    partition must be preserved on rebuild
2748         :param migration: a Migration object if one was created for this
2749                           rebuild operation (if it's a part of evacuate)
2750         :param scheduled_node: A node of the host chosen by the scheduler. If a
2751                                host was specified by the user, this will be
2752                                None
2753         :param limits: Overcommit limits set by the scheduler. If a host was
2754                        specified by the user, this will be None
2755         """
2756         context = context.elevated()
2757 
2758         LOG.info("Rebuilding instance", instance=instance)
2759 
2760         # NOTE(gyee): there are three possible scenarios.
2761         #
2762         #   1. instance is being rebuilt on the same node. In this case,
2763         #      recreate should be False and scheduled_node should be None.
2764         #   2. instance is being rebuilt on a node chosen by the
2765         #      scheduler (i.e. evacuate). In this case, scheduled_node should
2766         #      be specified and recreate should be True.
2767         #   3. instance is being rebuilt on a node chosen by the user. (i.e.
2768         #      force evacuate). In this case, scheduled_node is not specified
2769         #      and recreate is set to True.
2770         #
2771         # For scenarios #2 and #3, we must do rebuild claim as server is
2772         # being evacuated to a different node.
2773         if recreate or scheduled_node is not None:
2774             rt = self._get_resource_tracker()
2775             rebuild_claim = rt.rebuild_claim
2776         else:
2777             rebuild_claim = claims.NopClaim
2778 
2779         image_meta = {}
2780         if image_ref:
2781             image_meta = self.image_api.get(context, image_ref)
2782 
2783         # NOTE(mriedem): On a recreate (evacuate), we need to update
2784         # the instance's host and node properties to reflect it's
2785         # destination node for the recreate.
2786         if not scheduled_node:
2787             if recreate:
2788                 try:
2789                     compute_node = self._get_compute_info(context, self.host)
2790                     scheduled_node = compute_node.hypervisor_hostname
2791                 except exception.ComputeHostNotFound:
2792                     LOG.exception('Failed to get compute_info for %s',
2793                                   self.host)
2794             else:
2795                 scheduled_node = instance.node
2796 
2797         with self._error_out_instance_on_exception(context, instance):
2798             try:
2799                 claim_ctxt = rebuild_claim(
2800                     context, instance, scheduled_node,
2801                     limits=limits, image_meta=image_meta,
2802                     migration=migration)
2803                 self._do_rebuild_instance_with_claim(
2804                     claim_ctxt, context, instance, orig_image_ref,
2805                     image_ref, injected_files, new_pass, orig_sys_metadata,
2806                     bdms, recreate, on_shared_storage, preserve_ephemeral)
2807             except exception.ComputeResourcesUnavailable as e:
2808                 LOG.debug("Could not rebuild instance on this host, not "
2809                           "enough resources available.", instance=instance)
2810 
2811                 # NOTE(ndipanov): We just abort the build for now and leave a
2812                 # migration record for potential cleanup later
2813                 self._set_migration_status(migration, 'failed')
2814                 self._notify_instance_rebuild_error(context, instance, e)
2815 
2816                 raise exception.BuildAbortException(
2817                     instance_uuid=instance.uuid, reason=e.format_message())
2818             except (exception.InstanceNotFound,
2819                     exception.UnexpectedDeletingTaskStateError) as e:
2820                 LOG.debug('Instance was deleted while rebuilding',
2821                           instance=instance)
2822                 self._set_migration_status(migration, 'failed')
2823                 self._notify_instance_rebuild_error(context, instance, e)
2824             except Exception as e:
2825                 self._set_migration_status(migration, 'failed')
2826                 self._notify_instance_rebuild_error(context, instance, e)
2827                 raise
2828             else:
2829                 instance.apply_migration_context()
2830                 # NOTE (ndipanov): This save will now update the host and node
2831                 # attributes making sure that next RT pass is consistent since
2832                 # it will be based on the instance and not the migration DB
2833                 # entry.
2834                 instance.host = self.host
2835                 instance.node = scheduled_node
2836                 instance.save()
2837                 instance.drop_migration_context()
2838 
2839                 # NOTE (ndipanov): Mark the migration as done only after we
2840                 # mark the instance as belonging to this host.
2841                 self._set_migration_status(migration, 'done')
2842 
2843     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2844         """Helper to avoid deep nesting in the top-level method."""
2845 
2846         with claim_context:
2847             self._do_rebuild_instance(*args, **kwargs)
2848 
2849     @staticmethod
2850     def _get_image_name(image_meta):
2851         if image_meta.obj_attr_is_set("name"):
2852             return image_meta.name
2853         else:
2854             return ''
2855 
2856     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2857                              image_ref, injected_files, new_pass,
2858                              orig_sys_metadata, bdms, recreate,
2859                              on_shared_storage, preserve_ephemeral):
2860         orig_vm_state = instance.vm_state
2861 
2862         if recreate:
2863             if not self.driver.capabilities["supports_recreate"]:
2864                 raise exception.InstanceRecreateNotSupported
2865 
2866             self._check_instance_exists(context, instance)
2867 
2868             if on_shared_storage is None:
2869                 LOG.debug('on_shared_storage is not provided, using driver'
2870                             'information to decide if the instance needs to'
2871                             'be recreated')
2872                 on_shared_storage = self.driver.instance_on_disk(instance)
2873 
2874             elif (on_shared_storage !=
2875                     self.driver.instance_on_disk(instance)):
2876                 # To cover case when admin expects that instance files are
2877                 # on shared storage, but not accessible and vice versa
2878                 raise exception.InvalidSharedStorage(
2879                         _("Invalid state of instance files on shared"
2880                             " storage"))
2881 
2882             if on_shared_storage:
2883                 LOG.info('disk on shared storage, recreating using'
2884                          ' existing disk')
2885             else:
2886                 image_ref = orig_image_ref = instance.image_ref
2887                 LOG.info("disk not on shared storage, rebuilding from:"
2888                          " '%s'", str(image_ref))
2889 
2890         if image_ref:
2891             image_meta = objects.ImageMeta.from_image_ref(
2892                 context, self.image_api, image_ref)
2893         else:
2894             image_meta = instance.image_meta
2895 
2896         # This instance.exists message should contain the original
2897         # image_ref, not the new one.  Since the DB has been updated
2898         # to point to the new one... we have to override it.
2899         # TODO(jaypipes): Move generate_image_url() into the nova.image.api
2900         orig_image_ref_url = glance.generate_image_url(orig_image_ref)
2901         extra_usage_info = {'image_ref_url': orig_image_ref_url}
2902         compute_utils.notify_usage_exists(
2903                 self.notifier, context, instance,
2904                 current_period=True, system_metadata=orig_sys_metadata,
2905                 extra_usage_info=extra_usage_info)
2906 
2907         # This message should contain the new image_ref
2908         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
2909         self._notify_about_instance_usage(context, instance,
2910                 "rebuild.start", extra_usage_info=extra_usage_info)
2911         # NOTE: image_name is not included in the versioned notification
2912         # because we already provide the image_uuid in the notification
2913         # payload and the image details can be looked up via the uuid.
2914         compute_utils.notify_about_instance_action(
2915             context, instance, self.host,
2916             action=fields.NotificationAction.REBUILD,
2917             phase=fields.NotificationPhase.START)
2918 
2919         instance.power_state = self._get_power_state(context, instance)
2920         instance.task_state = task_states.REBUILDING
2921         instance.save(expected_task_state=[task_states.REBUILDING])
2922 
2923         if recreate:
2924             self.network_api.setup_networks_on_host(
2925                     context, instance, self.host)
2926             # For nova-network this is needed to move floating IPs
2927             # For neutron this updates the host in the port binding
2928             # TODO(cfriesen): this network_api call and the one above
2929             # are so similar, we should really try to unify them.
2930             self.network_api.setup_instance_network_on_host(
2931                     context, instance, self.host)
2932 
2933         network_info = instance.get_network_info()
2934         if bdms is None:
2935             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2936                     context, instance.uuid)
2937 
2938         block_device_info = \
2939             self._get_instance_block_device_info(
2940                     context, instance, bdms=bdms)
2941 
2942         def detach_block_devices(context, bdms):
2943             for bdm in bdms:
2944                 if bdm.is_volume:
2945                     self._detach_volume(context, bdm, instance,
2946                                         destroy_bdm=False)
2947 
2948         files = self._decode_files(injected_files)
2949 
2950         kwargs = dict(
2951             context=context,
2952             instance=instance,
2953             image_meta=image_meta,
2954             injected_files=files,
2955             admin_password=new_pass,
2956             bdms=bdms,
2957             detach_block_devices=detach_block_devices,
2958             attach_block_devices=self._prep_block_device,
2959             block_device_info=block_device_info,
2960             network_info=network_info,
2961             preserve_ephemeral=preserve_ephemeral,
2962             recreate=recreate)
2963         try:
2964             with instance.mutated_migration_context():
2965                 self.driver.rebuild(**kwargs)
2966         except NotImplementedError:
2967             # NOTE(rpodolyaka): driver doesn't provide specialized version
2968             # of rebuild, fall back to the default implementation
2969             self._rebuild_default_impl(**kwargs)
2970         self._update_instance_after_spawn(context, instance)
2971         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
2972 
2973         if orig_vm_state == vm_states.STOPPED:
2974             LOG.info("bringing vm to original state: '%s'",
2975                      orig_vm_state, instance=instance)
2976             instance.vm_state = vm_states.ACTIVE
2977             instance.task_state = task_states.POWERING_OFF
2978             instance.progress = 0
2979             instance.save()
2980             self.stop_instance(context, instance, False)
2981         self._update_scheduler_instance_info(context, instance)
2982         self._notify_about_instance_usage(
2983                 context, instance, "rebuild.end",
2984                 network_info=network_info,
2985                 extra_usage_info=extra_usage_info)
2986         compute_utils.notify_about_instance_action(
2987             context, instance, self.host,
2988             action=fields.NotificationAction.REBUILD,
2989             phase=fields.NotificationPhase.END)
2990 
2991     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
2992                                      block_device_info):
2993         """Handle cases where the virt-layer had to detach non-working volumes
2994         in order to complete an operation.
2995         """
2996         for bdm in block_device_info['block_device_mapping']:
2997             if bdm.get('mount_device') in bad_devices:
2998                 try:
2999                     volume_id = bdm['connection_info']['data']['volume_id']
3000                 except KeyError:
3001                     continue
3002 
3003                 # NOTE(sirp): ideally we'd just call
3004                 # `compute_api.detach_volume` here but since that hits the
3005                 # DB directly, that's off limits from within the
3006                 # compute-manager.
3007                 #
3008                 # API-detach
3009                 LOG.info("Detaching from volume api: %s", volume_id)
3010                 volume = self.volume_api.get(context, volume_id)
3011                 self.volume_api.check_detach(context, volume)
3012                 self.volume_api.begin_detaching(context, volume_id)
3013 
3014                 # Manager-detach
3015                 self.detach_volume(context, volume_id, instance)
3016 
3017     @wrap_exception()
3018     @reverts_task_state
3019     @wrap_instance_event(prefix='compute')
3020     @wrap_instance_fault
3021     def reboot_instance(self, context, instance, block_device_info,
3022                         reboot_type):
3023         """Reboot an instance on this host."""
3024         # acknowledge the request made it to the manager
3025         if reboot_type == "SOFT":
3026             instance.task_state = task_states.REBOOT_PENDING
3027             expected_states = (task_states.REBOOTING,
3028                                task_states.REBOOT_PENDING,
3029                                task_states.REBOOT_STARTED)
3030         else:
3031             instance.task_state = task_states.REBOOT_PENDING_HARD
3032             expected_states = (task_states.REBOOTING_HARD,
3033                                task_states.REBOOT_PENDING_HARD,
3034                                task_states.REBOOT_STARTED_HARD)
3035         context = context.elevated()
3036         LOG.info("Rebooting instance", instance=instance)
3037 
3038         block_device_info = self._get_instance_block_device_info(context,
3039                                                                  instance)
3040 
3041         network_info = self.network_api.get_instance_nw_info(context, instance)
3042 
3043         self._notify_about_instance_usage(context, instance, "reboot.start")
3044         compute_utils.notify_about_instance_action(
3045             context, instance, self.host,
3046             action=fields.NotificationAction.REBOOT,
3047             phase=fields.NotificationPhase.START
3048         )
3049 
3050         instance.power_state = self._get_power_state(context, instance)
3051         instance.save(expected_task_state=expected_states)
3052 
3053         if instance.power_state != power_state.RUNNING:
3054             state = instance.power_state
3055             running = power_state.RUNNING
3056             LOG.warning('trying to reboot a non-running instance:'
3057                         ' (state: %(state)s expected: %(running)s)',
3058                         {'state': state, 'running': running},
3059                         instance=instance)
3060 
3061         def bad_volumes_callback(bad_devices):
3062             self._handle_bad_volumes_detached(
3063                     context, instance, bad_devices, block_device_info)
3064 
3065         try:
3066             # Don't change it out of rescue mode
3067             if instance.vm_state == vm_states.RESCUED:
3068                 new_vm_state = vm_states.RESCUED
3069             else:
3070                 new_vm_state = vm_states.ACTIVE
3071             new_power_state = None
3072             if reboot_type == "SOFT":
3073                 instance.task_state = task_states.REBOOT_STARTED
3074                 expected_state = task_states.REBOOT_PENDING
3075             else:
3076                 instance.task_state = task_states.REBOOT_STARTED_HARD
3077                 expected_state = task_states.REBOOT_PENDING_HARD
3078             instance.save(expected_task_state=expected_state)
3079             self.driver.reboot(context, instance,
3080                                network_info,
3081                                reboot_type,
3082                                block_device_info=block_device_info,
3083                                bad_volumes_callback=bad_volumes_callback)
3084 
3085         except Exception as error:
3086             with excutils.save_and_reraise_exception() as ctxt:
3087                 exc_info = sys.exc_info()
3088                 # if the reboot failed but the VM is running don't
3089                 # put it into an error state
3090                 new_power_state = self._get_power_state(context, instance)
3091                 if new_power_state == power_state.RUNNING:
3092                     LOG.warning('Reboot failed but instance is running',
3093                                 instance=instance)
3094                     compute_utils.add_instance_fault_from_exc(context,
3095                             instance, error, exc_info)
3096                     self._notify_about_instance_usage(context, instance,
3097                             'reboot.error', fault=error)
3098                     compute_utils.notify_about_instance_action(
3099                         context, instance, self.host,
3100                         action=fields.NotificationAction.REBOOT,
3101                         phase=fields.NotificationPhase.ERROR,
3102                         exception=error
3103                     )
3104                     ctxt.reraise = False
3105                 else:
3106                     LOG.error('Cannot reboot instance: %s', error,
3107                               instance=instance)
3108                     self._set_instance_obj_error_state(context, instance)
3109 
3110         if not new_power_state:
3111             new_power_state = self._get_power_state(context, instance)
3112         try:
3113             instance.power_state = new_power_state
3114             instance.vm_state = new_vm_state
3115             instance.task_state = None
3116             instance.save()
3117         except exception.InstanceNotFound:
3118             LOG.warning("Instance disappeared during reboot",
3119                         instance=instance)
3120 
3121         self._notify_about_instance_usage(context, instance, "reboot.end")
3122         compute_utils.notify_about_instance_action(
3123             context, instance, self.host,
3124             action=fields.NotificationAction.REBOOT,
3125             phase=fields.NotificationPhase.END
3126         )
3127 
3128     @delete_image_on_error
3129     def _do_snapshot_instance(self, context, image_id, instance):
3130         self._snapshot_instance(context, image_id, instance,
3131                                 task_states.IMAGE_BACKUP)
3132 
3133     @wrap_exception()
3134     @reverts_task_state
3135     @wrap_instance_fault
3136     def backup_instance(self, context, image_id, instance, backup_type,
3137                         rotation):
3138         """Backup an instance on this host.
3139 
3140         :param backup_type: daily | weekly
3141         :param rotation: int representing how many backups to keep around
3142         """
3143         self._do_snapshot_instance(context, image_id, instance)
3144         self._rotate_backups(context, instance, backup_type, rotation)
3145 
3146     @wrap_exception()
3147     @reverts_task_state
3148     @wrap_instance_fault
3149     @delete_image_on_error
3150     def snapshot_instance(self, context, image_id, instance):
3151         """Snapshot an instance on this host.
3152 
3153         :param context: security context
3154         :param image_id: glance.db.sqlalchemy.models.Image.Id
3155         :param instance: a nova.objects.instance.Instance object
3156         """
3157         # NOTE(dave-mcnally) the task state will already be set by the api
3158         # but if the compute manager has crashed/been restarted prior to the
3159         # request getting here the task state may have been cleared so we set
3160         # it again and things continue normally
3161         try:
3162             instance.task_state = task_states.IMAGE_SNAPSHOT
3163             instance.save(
3164                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3165         except exception.InstanceNotFound:
3166             # possibility instance no longer exists, no point in continuing
3167             LOG.debug("Instance not found, could not set state %s "
3168                       "for instance.",
3169                       task_states.IMAGE_SNAPSHOT, instance=instance)
3170             return
3171 
3172         except exception.UnexpectedDeletingTaskStateError:
3173             LOG.debug("Instance being deleted, snapshot cannot continue",
3174                       instance=instance)
3175             return
3176 
3177         self._snapshot_instance(context, image_id, instance,
3178                                 task_states.IMAGE_SNAPSHOT)
3179 
3180     def _snapshot_instance(self, context, image_id, instance,
3181                            expected_task_state):
3182         context = context.elevated()
3183 
3184         instance.power_state = self._get_power_state(context, instance)
3185         try:
3186             instance.save()
3187 
3188             LOG.info('instance snapshotting', instance=instance)
3189 
3190             if instance.power_state != power_state.RUNNING:
3191                 state = instance.power_state
3192                 running = power_state.RUNNING
3193                 LOG.warning('trying to snapshot a non-running instance: '
3194                             '(state: %(state)s expected: %(running)s)',
3195                             {'state': state, 'running': running},
3196                             instance=instance)
3197 
3198             self._notify_about_instance_usage(
3199                 context, instance, "snapshot.start")
3200             compute_utils.notify_about_instance_action(context, instance,
3201                 self.host, action=fields.NotificationAction.SNAPSHOT,
3202                 phase=fields.NotificationPhase.START)
3203 
3204             def update_task_state(task_state,
3205                                   expected_state=expected_task_state):
3206                 instance.task_state = task_state
3207                 instance.save(expected_task_state=expected_state)
3208 
3209             self.driver.snapshot(context, instance, image_id,
3210                                  update_task_state)
3211 
3212             instance.task_state = None
3213             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3214 
3215             self._notify_about_instance_usage(context, instance,
3216                                               "snapshot.end")
3217             compute_utils.notify_about_instance_action(context, instance,
3218                 self.host, action=fields.NotificationAction.SNAPSHOT,
3219                 phase=fields.NotificationPhase.END)
3220         except (exception.InstanceNotFound,
3221                 exception.UnexpectedDeletingTaskStateError):
3222             # the instance got deleted during the snapshot
3223             # Quickly bail out of here
3224             msg = 'Instance disappeared during snapshot'
3225             LOG.debug(msg, instance=instance)
3226             try:
3227                 image_service = glance.get_default_image_service()
3228                 image = image_service.show(context, image_id)
3229                 if image['status'] != 'active':
3230                     image_service.delete(context, image_id)
3231             except Exception:
3232                 LOG.warning("Error while trying to clean up image %s",
3233                             image_id, instance=instance)
3234         except exception.ImageNotFound:
3235             instance.task_state = None
3236             instance.save()
3237             LOG.warning("Image not found during snapshot", instance=instance)
3238 
3239     def _post_interrupted_snapshot_cleanup(self, context, instance):
3240         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3241 
3242     @messaging.expected_exceptions(NotImplementedError)
3243     @wrap_exception()
3244     def volume_snapshot_create(self, context, instance, volume_id,
3245                                create_info):
3246         self.driver.volume_snapshot_create(context, instance, volume_id,
3247                                            create_info)
3248 
3249     @messaging.expected_exceptions(NotImplementedError)
3250     @wrap_exception()
3251     def volume_snapshot_delete(self, context, instance, volume_id,
3252                                snapshot_id, delete_info):
3253         self.driver.volume_snapshot_delete(context, instance, volume_id,
3254                                            snapshot_id, delete_info)
3255 
3256     @wrap_instance_fault
3257     def _rotate_backups(self, context, instance, backup_type, rotation):
3258         """Delete excess backups associated to an instance.
3259 
3260         Instances are allowed a fixed number of backups (the rotation number);
3261         this method deletes the oldest backups that exceed the rotation
3262         threshold.
3263 
3264         :param context: security context
3265         :param instance: Instance dict
3266         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3267         :param rotation: int representing how many backups to keep around;
3268             None if rotation shouldn't be used (as in the case of snapshots)
3269         """
3270         filters = {'property-image_type': 'backup',
3271                    'property-backup_type': backup_type,
3272                    'property-instance_uuid': instance.uuid}
3273 
3274         images = self.image_api.get_all(context, filters=filters,
3275                                         sort_key='created_at', sort_dir='desc')
3276         num_images = len(images)
3277         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3278                   {'num_images': num_images, 'rotation': rotation},
3279                   instance=instance)
3280 
3281         if num_images > rotation:
3282             # NOTE(sirp): this deletes all backups that exceed the rotation
3283             # limit
3284             excess = len(images) - rotation
3285             LOG.debug("Rotating out %d backups", excess,
3286                       instance=instance)
3287             for i in range(excess):
3288                 image = images.pop()
3289                 image_id = image['id']
3290                 LOG.debug("Deleting image %s", image_id,
3291                           instance=instance)
3292                 try:
3293                     self.image_api.delete(context, image_id)
3294                 except exception.ImageNotFound:
3295                     LOG.info("Failed to find image %(image_id)s to "
3296                              "delete", {'image_id': image_id},
3297                              instance=instance)
3298 
3299     @wrap_exception()
3300     @reverts_task_state
3301     @wrap_instance_event(prefix='compute')
3302     @wrap_instance_fault
3303     def set_admin_password(self, context, instance, new_pass):
3304         """Set the root/admin password for an instance on this host.
3305 
3306         This is generally only called by API password resets after an
3307         image has been built.
3308 
3309         @param context: Nova auth context.
3310         @param instance: Nova instance object.
3311         @param new_pass: The admin password for the instance.
3312         """
3313 
3314         context = context.elevated()
3315         if new_pass is None:
3316             # Generate a random password
3317             new_pass = utils.generate_password()
3318 
3319         current_power_state = self._get_power_state(context, instance)
3320         expected_state = power_state.RUNNING
3321 
3322         if current_power_state != expected_state:
3323             instance.task_state = None
3324             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3325             _msg = _('instance %s is not running') % instance.uuid
3326             raise exception.InstancePasswordSetFailed(
3327                 instance=instance.uuid, reason=_msg)
3328 
3329         try:
3330             self.driver.set_admin_password(instance, new_pass)
3331             LOG.info("Root password set", instance=instance)
3332             instance.task_state = None
3333             instance.save(
3334                 expected_task_state=task_states.UPDATING_PASSWORD)
3335         except exception.InstanceAgentNotEnabled:
3336             with excutils.save_and_reraise_exception():
3337                 LOG.debug('Guest agent is not enabled for the instance.',
3338                           instance=instance)
3339                 instance.task_state = None
3340                 instance.save(
3341                     expected_task_state=task_states.UPDATING_PASSWORD)
3342         except exception.SetAdminPasswdNotSupported:
3343             with excutils.save_and_reraise_exception():
3344                 LOG.info('set_admin_password is not supported '
3345                          'by this driver or guest instance.',
3346                          instance=instance)
3347                 instance.task_state = None
3348                 instance.save(
3349                     expected_task_state=task_states.UPDATING_PASSWORD)
3350         except NotImplementedError:
3351             LOG.warning('set_admin_password is not implemented '
3352                         'by this driver or guest instance.',
3353                         instance=instance)
3354             instance.task_state = None
3355             instance.save(
3356                 expected_task_state=task_states.UPDATING_PASSWORD)
3357             raise NotImplementedError(_('set_admin_password is not '
3358                                         'implemented by this driver or guest '
3359                                         'instance.'))
3360         except exception.UnexpectedTaskStateError:
3361             # interrupted by another (most likely delete) task
3362             # do not retry
3363             raise
3364         except Exception:
3365             # Catch all here because this could be anything.
3366             LOG.exception('set_admin_password failed', instance=instance)
3367             self._set_instance_obj_error_state(context, instance)
3368             # We create a new exception here so that we won't
3369             # potentially reveal password information to the
3370             # API caller.  The real exception is logged above
3371             _msg = _('error setting admin password')
3372             raise exception.InstancePasswordSetFailed(
3373                 instance=instance.uuid, reason=_msg)
3374 
3375     @wrap_exception()
3376     @reverts_task_state
3377     @wrap_instance_fault
3378     def inject_file(self, context, path, file_contents, instance):
3379         """Write a file to the specified path in an instance on this host."""
3380         # NOTE(russellb) Remove this method, as well as the underlying virt
3381         # driver methods, when the compute rpc interface is bumped to 4.x
3382         # as it is no longer used.
3383         context = context.elevated()
3384         current_power_state = self._get_power_state(context, instance)
3385         expected_state = power_state.RUNNING
3386         if current_power_state != expected_state:
3387             LOG.warning('trying to inject a file into a non-running '
3388                         '(state: %(current_state)s expected: '
3389                         '%(expected_state)s)',
3390                         {'current_state': current_power_state,
3391                          'expected_state': expected_state},
3392                         instance=instance)
3393         LOG.info('injecting file to %s', path, instance=instance)
3394         self.driver.inject_file(instance, path, file_contents)
3395 
3396     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3397         """Determine what image should be used to boot the rescue VM."""
3398         # 1. If rescue_image_ref is passed in, use that for rescue.
3399         # 2. Else, use the base image associated with instance's current image.
3400         #       The idea here is to provide the customer with a rescue
3401         #       environment which they are familiar with.
3402         #       So, if they built their instance off of a Debian image,
3403         #       their rescue VM will also be Debian.
3404         # 3. As a last resort, use instance's current image.
3405         if not rescue_image_ref:
3406             system_meta = utils.instance_sys_meta(instance)
3407             rescue_image_ref = system_meta.get('image_base_image_ref')
3408 
3409         if not rescue_image_ref:
3410             LOG.warning('Unable to find a different image to use for '
3411                         'rescue VM, using instance\'s current image',
3412                         instance=instance)
3413             rescue_image_ref = instance.image_ref
3414 
3415         return objects.ImageMeta.from_image_ref(
3416             context, self.image_api, rescue_image_ref)
3417 
3418     @wrap_exception()
3419     @reverts_task_state
3420     @wrap_instance_event(prefix='compute')
3421     @wrap_instance_fault
3422     def rescue_instance(self, context, instance, rescue_password,
3423                         rescue_image_ref, clean_shutdown):
3424         context = context.elevated()
3425         LOG.info('Rescuing', instance=instance)
3426 
3427         admin_password = (rescue_password if rescue_password else
3428                       utils.generate_password())
3429 
3430         network_info = self.network_api.get_instance_nw_info(context, instance)
3431 
3432         rescue_image_meta = self._get_rescue_image(context, instance,
3433                                                    rescue_image_ref)
3434 
3435         extra_usage_info = {'rescue_image_name':
3436                             self._get_image_name(rescue_image_meta)}
3437         self._notify_about_instance_usage(context, instance,
3438                 "rescue.start", extra_usage_info=extra_usage_info,
3439                 network_info=network_info)
3440 
3441         try:
3442             self._power_off_instance(context, instance, clean_shutdown)
3443 
3444             self.driver.rescue(context, instance,
3445                                network_info,
3446                                rescue_image_meta, admin_password)
3447         except Exception as e:
3448             LOG.exception("Error trying to Rescue Instance",
3449                           instance=instance)
3450             self._set_instance_obj_error_state(context, instance)
3451             raise exception.InstanceNotRescuable(
3452                 instance_id=instance.uuid,
3453                 reason=_("Driver Error: %s") % e)
3454 
3455         compute_utils.notify_usage_exists(self.notifier, context, instance,
3456                                           current_period=True)
3457 
3458         instance.vm_state = vm_states.RESCUED
3459         instance.task_state = None
3460         instance.power_state = self._get_power_state(context, instance)
3461         instance.launched_at = timeutils.utcnow()
3462         instance.save(expected_task_state=task_states.RESCUING)
3463 
3464         self._notify_about_instance_usage(context, instance,
3465                 "rescue.end", extra_usage_info=extra_usage_info,
3466                 network_info=network_info)
3467 
3468     @wrap_exception()
3469     @reverts_task_state
3470     @wrap_instance_event(prefix='compute')
3471     @wrap_instance_fault
3472     def unrescue_instance(self, context, instance):
3473         context = context.elevated()
3474         LOG.info('Unrescuing', instance=instance)
3475 
3476         network_info = self.network_api.get_instance_nw_info(context, instance)
3477         self._notify_about_instance_usage(context, instance,
3478                 "unrescue.start", network_info=network_info)
3479         with self._error_out_instance_on_exception(context, instance):
3480             self.driver.unrescue(instance,
3481                                  network_info)
3482 
3483         instance.vm_state = vm_states.ACTIVE
3484         instance.task_state = None
3485         instance.power_state = self._get_power_state(context, instance)
3486         instance.save(expected_task_state=task_states.UNRESCUING)
3487 
3488         self._notify_about_instance_usage(context,
3489                                           instance,
3490                                           "unrescue.end",
3491                                           network_info=network_info)
3492 
3493     @wrap_exception()
3494     @wrap_instance_fault
3495     def change_instance_metadata(self, context, diff, instance):
3496         """Update the metadata published to the instance."""
3497         LOG.debug("Changing instance metadata according to %r",
3498                   diff, instance=instance)
3499         self.driver.change_instance_metadata(context, instance, diff)
3500 
3501     @wrap_exception()
3502     @wrap_instance_event(prefix='compute')
3503     @wrap_instance_fault
3504     def confirm_resize(self, context, instance, reservations, migration):
3505 
3506         quotas = objects.Quotas.from_reservations(context,
3507                                                   reservations,
3508                                                   instance=instance)
3509 
3510         @utils.synchronized(instance.uuid)
3511         def do_confirm_resize(context, instance, migration_id):
3512             # NOTE(wangpan): Get the migration status from db, if it has been
3513             #                confirmed, we do nothing and return here
3514             LOG.debug("Going to confirm migration %s", migration_id,
3515                       instance=instance)
3516             try:
3517                 # TODO(russellb) Why are we sending the migration object just
3518                 # to turn around and look it up from the db again?
3519                 migration = objects.Migration.get_by_id(
3520                                     context.elevated(), migration_id)
3521             except exception.MigrationNotFound:
3522                 LOG.error("Migration %s is not found during confirmation",
3523                           migration_id, instance=instance)
3524                 quotas.rollback()
3525                 return
3526 
3527             if migration.status == 'confirmed':
3528                 LOG.info("Migration %s is already confirmed",
3529                          migration_id, instance=instance)
3530                 quotas.rollback()
3531                 return
3532             elif migration.status not in ('finished', 'confirming'):
3533                 LOG.warning("Unexpected confirmation status '%(status)s' "
3534                             "of migration %(id)s, exit confirmation process",
3535                             {"status": migration.status, "id": migration_id},
3536                             instance=instance)
3537                 quotas.rollback()
3538                 return
3539 
3540             # NOTE(wangpan): Get the instance from db, if it has been
3541             #                deleted, we do nothing and return here
3542             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3543             try:
3544                 instance = objects.Instance.get_by_uuid(
3545                         context, instance.uuid,
3546                         expected_attrs=expected_attrs)
3547             except exception.InstanceNotFound:
3548                 LOG.info("Instance is not found during confirmation",
3549                          instance=instance)
3550                 quotas.rollback()
3551                 return
3552 
3553             self._confirm_resize(context, instance, quotas,
3554                                  migration=migration)
3555 
3556         do_confirm_resize(context, instance, migration.id)
3557 
3558     def _confirm_resize(self, context, instance, quotas,
3559                         migration=None):
3560         """Destroys the source instance."""
3561         self._notify_about_instance_usage(context, instance,
3562                                           "resize.confirm.start")
3563 
3564         with self._error_out_instance_on_exception(context, instance,
3565                                                    quotas=quotas):
3566             # NOTE(danms): delete stashed migration information
3567             old_instance_type = instance.old_flavor
3568             instance.old_flavor = None
3569             instance.new_flavor = None
3570             instance.system_metadata.pop('old_vm_state', None)
3571             instance.save()
3572 
3573             # NOTE(tr3buchet): tear down networks on source host
3574             self.network_api.setup_networks_on_host(context, instance,
3575                                migration.source_compute, teardown=True)
3576 
3577             network_info = self.network_api.get_instance_nw_info(context,
3578                                                                  instance)
3579             self.driver.confirm_migration(context, migration, instance,
3580                                           network_info)
3581 
3582             migration.status = 'confirmed'
3583             with migration.obj_as_admin():
3584                 migration.save()
3585 
3586             rt = self._get_resource_tracker()
3587             rt.drop_move_claim(context, instance, migration.source_node,
3588                                old_instance_type, prefix='old_')
3589             instance.drop_migration_context()
3590 
3591             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3592             # might have manually powered up the instance to confirm the
3593             # resize/migrate, so we need to check the current power state
3594             # on the instance and set the vm_state appropriately. We default
3595             # to ACTIVE because if the power state is not SHUTDOWN, we
3596             # assume _sync_instance_power_state will clean it up.
3597             p_state = instance.power_state
3598             vm_state = None
3599             if p_state == power_state.SHUTDOWN:
3600                 vm_state = vm_states.STOPPED
3601                 LOG.debug("Resized/migrated instance is powered off. "
3602                           "Setting vm_state to '%s'.", vm_state,
3603                           instance=instance)
3604             else:
3605                 vm_state = vm_states.ACTIVE
3606 
3607             instance.vm_state = vm_state
3608             instance.task_state = None
3609             instance.save(expected_task_state=[None, task_states.DELETING])
3610 
3611             self._notify_about_instance_usage(
3612                 context, instance, "resize.confirm.end",
3613                 network_info=network_info)
3614 
3615             quotas.commit()
3616 
3617     @wrap_exception()
3618     @reverts_task_state
3619     @wrap_instance_event(prefix='compute')
3620     @errors_out_migration
3621     @wrap_instance_fault
3622     def revert_resize(self, context, instance, migration, reservations):
3623         """Destroys the new instance on the destination machine.
3624 
3625         Reverts the model changes, and powers on the old instance on the
3626         source machine.
3627 
3628         """
3629 
3630         quotas = objects.Quotas.from_reservations(context,
3631                                                   reservations,
3632                                                   instance=instance)
3633 
3634         # NOTE(comstud): A revert_resize is essentially a resize back to
3635         # the old size, so we need to send a usage event here.
3636         compute_utils.notify_usage_exists(self.notifier, context, instance,
3637                                           current_period=True)
3638 
3639         with self._error_out_instance_on_exception(context, instance,
3640                                                    quotas=quotas):
3641             # NOTE(tr3buchet): tear down networks on destination host
3642             self.network_api.setup_networks_on_host(context, instance,
3643                                                     teardown=True)
3644 
3645             migration_p = obj_base.obj_to_primitive(migration)
3646             self.network_api.migrate_instance_start(context,
3647                                                     instance,
3648                                                     migration_p)
3649 
3650             network_info = self.network_api.get_instance_nw_info(context,
3651                                                                  instance)
3652             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3653                     context, instance.uuid)
3654             block_device_info = self._get_instance_block_device_info(
3655                                 context, instance, bdms=bdms)
3656 
3657             destroy_disks = not self._is_instance_storage_shared(
3658                 context, instance, host=migration.source_compute)
3659             self.driver.destroy(context, instance, network_info,
3660                                 block_device_info, destroy_disks)
3661 
3662             self._terminate_volume_connections(context, instance, bdms)
3663 
3664             migration.status = 'reverted'
3665             with migration.obj_as_admin():
3666                 migration.save()
3667 
3668             # NOTE(ndipanov): We need to do this here because dropping the
3669             # claim means we lose the migration_context data. We really should
3670             # fix this by moving the drop_move_claim call to the
3671             # finish_revert_resize method as this is racy (revert is dropped,
3672             # but instance resources will be tracked with the new flavor until
3673             # it gets rolled back in finish_revert_resize, which is
3674             # potentially wrong for a period of time).
3675             instance.revert_migration_context()
3676             instance.save()
3677 
3678             rt = self._get_resource_tracker()
3679             rt.drop_move_claim(context, instance, instance.node)
3680 
3681             self.compute_rpcapi.finish_revert_resize(context, instance,
3682                     migration, migration.source_compute,
3683                     quotas.reservations)
3684 
3685     @wrap_exception()
3686     @reverts_task_state
3687     @wrap_instance_event(prefix='compute')
3688     @wrap_instance_fault
3689     def finish_revert_resize(self, context, instance, reservations, migration):
3690         """Finishes the second half of reverting a resize.
3691 
3692         Bring the original source instance state back (active/shutoff) and
3693         revert the resized attributes in the database.
3694 
3695         """
3696 
3697         quotas = objects.Quotas.from_reservations(context, reservations,
3698                                                   instance=instance)
3699 
3700         with errors_out_migration_ctxt(migration), \
3701              self._error_out_instance_on_exception(context, instance,
3702                                                    quotas=quotas):
3703 
3704             self._notify_about_instance_usage(
3705                     context, instance, "resize.revert.start")
3706 
3707             # NOTE(mriedem): delete stashed old_vm_state information; we
3708             # default to ACTIVE for backwards compatibility if old_vm_state
3709             # is not set
3710             old_vm_state = instance.system_metadata.pop('old_vm_state',
3711                                                         vm_states.ACTIVE)
3712 
3713             self._set_instance_info(instance, instance.old_flavor)
3714             instance.old_flavor = None
3715             instance.new_flavor = None
3716             instance.host = migration.source_compute
3717             instance.node = migration.source_node
3718             instance.save()
3719 
3720             self.network_api.setup_networks_on_host(context, instance,
3721                                                     migration.source_compute)
3722             migration_p = obj_base.obj_to_primitive(migration)
3723             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
3724             # source host temporarily. "network_api.migrate_instance_finish"
3725             # will setup the network for the instance on the destination host.
3726             # For revert resize, the instance will back to the source host, the
3727             # setup of the network for instance should be on the source host.
3728             # So set the migration_p['dest_compute'] to source host at here.
3729             migration_p['dest_compute'] = migration.source_compute
3730             self.network_api.migrate_instance_finish(context,
3731                                                      instance,
3732                                                      migration_p)
3733             network_info = self.network_api.get_instance_nw_info(context,
3734                                                                  instance)
3735 
3736             block_device_info = self._get_instance_block_device_info(
3737                     context, instance, refresh_conn_info=True)
3738 
3739             power_on = old_vm_state != vm_states.STOPPED
3740             self.driver.finish_revert_migration(context, instance,
3741                                        network_info,
3742                                        block_device_info, power_on)
3743 
3744             instance.drop_migration_context()
3745             instance.launched_at = timeutils.utcnow()
3746             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
3747 
3748             # if the original vm state was STOPPED, set it back to STOPPED
3749             LOG.info("Updating instance to original state: '%s'",
3750                      old_vm_state, instance=instance)
3751             if power_on:
3752                 instance.vm_state = vm_states.ACTIVE
3753                 instance.task_state = None
3754                 instance.save()
3755             else:
3756                 instance.task_state = task_states.POWERING_OFF
3757                 instance.save()
3758                 self.stop_instance(context, instance=instance,
3759                                    clean_shutdown=True)
3760 
3761         self._notify_about_instance_usage(
3762                 context, instance, "resize.revert.end")
3763         quotas.commit()
3764 
3765     def _prep_resize(self, context, image, instance, instance_type,
3766             quotas, request_spec, filter_properties, node,
3767             clean_shutdown=True):
3768 
3769         if not filter_properties:
3770             filter_properties = {}
3771 
3772         if not instance.host:
3773             self._set_instance_obj_error_state(context, instance)
3774             msg = _('Instance has no source host')
3775             raise exception.MigrationError(reason=msg)
3776 
3777         same_host = instance.host == self.host
3778         # if the flavor IDs match, it's migrate; otherwise resize
3779         if same_host and instance_type.id == instance['instance_type_id']:
3780             # check driver whether support migrate to same host
3781             if not self.driver.capabilities['supports_migrate_to_same_host']:
3782                 raise exception.UnableToMigrateToSelf(
3783                     instance_id=instance.uuid, host=self.host)
3784 
3785         # NOTE(danms): Stash the new instance_type to avoid having to
3786         # look it up in the database later
3787         instance.new_flavor = instance_type
3788         # NOTE(mriedem): Stash the old vm_state so we can set the
3789         # resized/reverted instance back to the same state later.
3790         vm_state = instance.vm_state
3791         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
3792         instance.system_metadata['old_vm_state'] = vm_state
3793         instance.save()
3794 
3795         limits = filter_properties.get('limits', {})
3796         rt = self._get_resource_tracker()
3797         with rt.resize_claim(context, instance, instance_type, node,
3798                              image_meta=image, limits=limits) as claim:
3799             LOG.info('Migrating', instance=instance)
3800             self.compute_rpcapi.resize_instance(
3801                     context, instance, claim.migration, image,
3802                     instance_type, quotas.reservations,
3803                     clean_shutdown)
3804 
3805     @wrap_exception()
3806     @reverts_task_state
3807     @wrap_instance_event(prefix='compute')
3808     @wrap_instance_fault
3809     def prep_resize(self, context, image, instance, instance_type,
3810                     reservations, request_spec, filter_properties, node,
3811                     clean_shutdown):
3812         """Initiates the process of moving a running instance to another host.
3813 
3814         Possibly changes the RAM and disk size in the process.
3815 
3816         """
3817         if node is None:
3818             node = self.driver.get_available_nodes(refresh=True)[0]
3819             LOG.debug("No node specified, defaulting to %s", node,
3820                       instance=instance)
3821 
3822         # NOTE(melwitt): Remove this in version 5.0 of the RPC API
3823         # Code downstream may expect extra_specs to be populated since it
3824         # is receiving an object, so lookup the flavor to ensure this.
3825         if not isinstance(instance_type, objects.Flavor):
3826             instance_type = objects.Flavor.get_by_id(context,
3827                                                      instance_type['id'])
3828 
3829         quotas = objects.Quotas.from_reservations(context,
3830                                                   reservations,
3831                                                   instance=instance)
3832         with self._error_out_instance_on_exception(context, instance,
3833                                                    quotas=quotas):
3834             compute_utils.notify_usage_exists(self.notifier, context, instance,
3835                                               current_period=True)
3836             self._notify_about_instance_usage(
3837                     context, instance, "resize.prep.start")
3838             try:
3839                 self._prep_resize(context, image, instance,
3840                                   instance_type, quotas,
3841                                   request_spec, filter_properties,
3842                                   node, clean_shutdown)
3843             # NOTE(dgenin): This is thrown in LibvirtDriver when the
3844             #               instance to be migrated is backed by LVM.
3845             #               Remove when LVM migration is implemented.
3846             except exception.MigrationPreCheckError:
3847                 raise
3848             except Exception:
3849                 # try to re-schedule the resize elsewhere:
3850                 exc_info = sys.exc_info()
3851                 self._reschedule_resize_or_reraise(context, image, instance,
3852                         exc_info, instance_type, quotas, request_spec,
3853                         filter_properties)
3854             finally:
3855                 extra_usage_info = dict(
3856                         new_instance_type=instance_type.name,
3857                         new_instance_type_id=instance_type.id)
3858 
3859                 self._notify_about_instance_usage(
3860                     context, instance, "resize.prep.end",
3861                     extra_usage_info=extra_usage_info)
3862 
3863     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
3864             instance_type, quotas, request_spec, filter_properties):
3865         """Try to re-schedule the resize or re-raise the original error to
3866         error out the instance.
3867         """
3868         if not request_spec:
3869             request_spec = {}
3870         if not filter_properties:
3871             filter_properties = {}
3872 
3873         rescheduled = False
3874         instance_uuid = instance.uuid
3875 
3876         try:
3877             reschedule_method = self.compute_task_api.resize_instance
3878             scheduler_hint = dict(filter_properties=filter_properties)
3879             method_args = (instance, None, scheduler_hint, instance_type,
3880                            quotas.reservations)
3881             task_state = task_states.RESIZE_PREP
3882 
3883             rescheduled = self._reschedule(context, request_spec,
3884                     filter_properties, instance, reschedule_method,
3885                     method_args, task_state, exc_info)
3886         except Exception as error:
3887             rescheduled = False
3888             LOG.exception("Error trying to reschedule",
3889                           instance_uuid=instance_uuid)
3890             compute_utils.add_instance_fault_from_exc(context,
3891                     instance, error,
3892                     exc_info=sys.exc_info())
3893             self._notify_about_instance_usage(context, instance,
3894                     'resize.error', fault=error)
3895 
3896         if rescheduled:
3897             self._log_original_error(exc_info, instance_uuid)
3898             compute_utils.add_instance_fault_from_exc(context,
3899                     instance, exc_info[1], exc_info=exc_info)
3900             self._notify_about_instance_usage(context, instance,
3901                     'resize.error', fault=exc_info[1])
3902         else:
3903             # not re-scheduling
3904             six.reraise(*exc_info)
3905 
3906     @wrap_exception()
3907     @reverts_task_state
3908     @wrap_instance_event(prefix='compute')
3909     @wrap_instance_fault
3910     def resize_instance(self, context, instance, image,
3911                         reservations, migration, instance_type,
3912                         clean_shutdown):
3913         """Starts the migration of a running instance to another host."""
3914 
3915         quotas = objects.Quotas.from_reservations(context, reservations,
3916                                                   instance=instance)
3917 
3918         with errors_out_migration_ctxt(migration), \
3919              self._error_out_instance_on_exception(context, instance,
3920                                                    quotas=quotas):
3921 
3922             # TODO(chaochin) Remove this until v5 RPC API
3923             # Code downstream may expect extra_specs to be populated since it
3924             # is receiving an object, so lookup the flavor to ensure this.
3925             if (not instance_type or
3926                 not isinstance(instance_type, objects.Flavor)):
3927                 instance_type = objects.Flavor.get_by_id(
3928                     context, migration['new_instance_type_id'])
3929 
3930             network_info = self.network_api.get_instance_nw_info(context,
3931                                                                  instance)
3932 
3933             migration.status = 'migrating'
3934             with migration.obj_as_admin():
3935                 migration.save()
3936 
3937             instance.task_state = task_states.RESIZE_MIGRATING
3938             instance.save(expected_task_state=task_states.RESIZE_PREP)
3939 
3940             self._notify_about_instance_usage(
3941                 context, instance, "resize.start", network_info=network_info)
3942 
3943             compute_utils.notify_about_instance_action(context, instance,
3944                    self.host, action=fields.NotificationAction.RESIZE,
3945                    phase=fields.NotificationPhase.START)
3946 
3947             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3948                     context, instance.uuid)
3949             block_device_info = self._get_instance_block_device_info(
3950                                 context, instance, bdms=bdms)
3951 
3952             timeout, retry_interval = self._get_power_off_values(context,
3953                                             instance, clean_shutdown)
3954             disk_info = self.driver.migrate_disk_and_power_off(
3955                     context, instance, migration.dest_host,
3956                     instance_type, network_info,
3957                     block_device_info,
3958                     timeout, retry_interval)
3959 
3960             self._terminate_volume_connections(context, instance, bdms)
3961 
3962             migration_p = obj_base.obj_to_primitive(migration)
3963             self.network_api.migrate_instance_start(context,
3964                                                     instance,
3965                                                     migration_p)
3966 
3967             migration.status = 'post-migrating'
3968             with migration.obj_as_admin():
3969                 migration.save()
3970 
3971             instance.host = migration.dest_compute
3972             instance.node = migration.dest_node
3973             instance.task_state = task_states.RESIZE_MIGRATED
3974             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
3975 
3976             self.compute_rpcapi.finish_resize(context, instance,
3977                     migration, image, disk_info,
3978                     migration.dest_compute, reservations=quotas.reservations)
3979 
3980         self._notify_about_instance_usage(context, instance, "resize.end",
3981                                           network_info=network_info)
3982 
3983         compute_utils.notify_about_instance_action(context, instance,
3984                self.host, action=fields.NotificationAction.RESIZE,
3985                phase=fields.NotificationPhase.END)
3986         self.instance_events.clear_events_for_instance(instance)
3987 
3988     def _terminate_volume_connections(self, context, instance, bdms):
3989         connector = None
3990         for bdm in bdms:
3991             if bdm.is_volume:
3992                 if bdm.attachment_id:
3993                     self.volume_api.attachment_delete(context,
3994                                                       bdm.attachment_id)
3995                 else:
3996                     if connector is None:
3997                         connector = self.driver.get_volume_connector(instance)
3998                     self.volume_api.terminate_connection(context,
3999                                                          bdm.volume_id,
4000                                                          connector)
4001 
4002     @staticmethod
4003     def _set_instance_info(instance, instance_type):
4004         instance.instance_type_id = instance_type.id
4005         # NOTE(danms): These are purely for any legacy code that still
4006         # looks at them.
4007         instance.memory_mb = instance_type.memory_mb
4008         instance.vcpus = instance_type.vcpus
4009         instance.root_gb = instance_type.root_gb
4010         instance.ephemeral_gb = instance_type.ephemeral_gb
4011         instance.flavor = instance_type
4012 
4013     def _finish_resize(self, context, instance, migration, disk_info,
4014                        image_meta):
4015         resize_instance = False
4016         old_instance_type_id = migration['old_instance_type_id']
4017         new_instance_type_id = migration['new_instance_type_id']
4018         old_instance_type = instance.get_flavor()
4019         # NOTE(mriedem): Get the old_vm_state so we know if we should
4020         # power on the instance. If old_vm_state is not set we need to default
4021         # to ACTIVE for backwards compatibility
4022         old_vm_state = instance.system_metadata.get('old_vm_state',
4023                                                     vm_states.ACTIVE)
4024         instance.old_flavor = old_instance_type
4025 
4026         if old_instance_type_id != new_instance_type_id:
4027             instance_type = instance.get_flavor('new')
4028             self._set_instance_info(instance, instance_type)
4029             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4030                 if old_instance_type[key] != instance_type[key]:
4031                     resize_instance = True
4032                     break
4033         instance.apply_migration_context()
4034 
4035         # NOTE(tr3buchet): setup networks on destination host
4036         self.network_api.setup_networks_on_host(context, instance,
4037                                                 migration['dest_compute'])
4038 
4039         migration_p = obj_base.obj_to_primitive(migration)
4040         self.network_api.migrate_instance_finish(context,
4041                                                  instance,
4042                                                  migration_p)
4043 
4044         network_info = self.network_api.get_instance_nw_info(context, instance)
4045 
4046         instance.task_state = task_states.RESIZE_FINISH
4047         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4048 
4049         self._notify_about_instance_usage(
4050             context, instance, "finish_resize.start",
4051             network_info=network_info)
4052         compute_utils.notify_about_instance_action(context, instance,
4053                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4054                phase=fields.NotificationPhase.START)
4055 
4056         block_device_info = self._get_instance_block_device_info(
4057                             context, instance, refresh_conn_info=True)
4058 
4059         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4060         # automatically power on the instance after it's migrated
4061         power_on = old_vm_state != vm_states.STOPPED
4062 
4063         try:
4064             self.driver.finish_migration(context, migration, instance,
4065                                          disk_info,
4066                                          network_info,
4067                                          image_meta, resize_instance,
4068                                          block_device_info, power_on)
4069         except Exception:
4070             with excutils.save_and_reraise_exception():
4071                 if old_instance_type_id != new_instance_type_id:
4072                     self._set_instance_info(instance,
4073                                             old_instance_type)
4074 
4075         migration.status = 'finished'
4076         with migration.obj_as_admin():
4077             migration.save()
4078 
4079         instance.vm_state = vm_states.RESIZED
4080         instance.task_state = None
4081         instance.launched_at = timeutils.utcnow()
4082         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4083 
4084         self._update_scheduler_instance_info(context, instance)
4085         self._notify_about_instance_usage(
4086             context, instance, "finish_resize.end",
4087             network_info=network_info)
4088         compute_utils.notify_about_instance_action(context, instance,
4089                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4090                phase=fields.NotificationPhase.END)
4091 
4092     @wrap_exception()
4093     @reverts_task_state
4094     @wrap_instance_event(prefix='compute')
4095     @errors_out_migration
4096     @wrap_instance_fault
4097     def finish_resize(self, context, disk_info, image, instance,
4098                       reservations, migration):
4099         """Completes the migration process.
4100 
4101         Sets up the newly transferred disk and turns on the instance at its
4102         new host machine.
4103 
4104         """
4105         quotas = objects.Quotas.from_reservations(context,
4106                                                   reservations,
4107                                                   instance=instance)
4108         try:
4109             image_meta = objects.ImageMeta.from_dict(image)
4110             self._finish_resize(context, instance, migration,
4111                                 disk_info, image_meta)
4112             quotas.commit()
4113         except Exception:
4114             LOG.exception('Setting instance vm_state to ERROR',
4115                           instance=instance)
4116             with excutils.save_and_reraise_exception():
4117                 try:
4118                     quotas.rollback()
4119                 except Exception:
4120                     LOG.exception("Failed to rollback quota for failed "
4121                                   "finish_resize",
4122                                   instance=instance)
4123                 self._set_instance_obj_error_state(context, instance)
4124 
4125     @wrap_exception()
4126     @wrap_instance_fault
4127     def add_fixed_ip_to_instance(self, context, network_id, instance):
4128         """Calls network_api to add new fixed_ip to instance
4129         then injects the new network info and resets instance networking.
4130 
4131         """
4132         self._notify_about_instance_usage(
4133                 context, instance, "create_ip.start")
4134 
4135         network_info = self.network_api.add_fixed_ip_to_instance(context,
4136                                                                  instance,
4137                                                                  network_id)
4138         self._inject_network_info(context, instance, network_info)
4139         self.reset_network(context, instance)
4140 
4141         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4142         instance.updated_at = timeutils.utcnow()
4143         instance.save()
4144 
4145         self._notify_about_instance_usage(
4146             context, instance, "create_ip.end", network_info=network_info)
4147 
4148     @wrap_exception()
4149     @wrap_instance_fault
4150     def remove_fixed_ip_from_instance(self, context, address, instance):
4151         """Calls network_api to remove existing fixed_ip from instance
4152         by injecting the altered network info and resetting
4153         instance networking.
4154         """
4155         self._notify_about_instance_usage(
4156                 context, instance, "delete_ip.start")
4157 
4158         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4159                                                                       instance,
4160                                                                       address)
4161         self._inject_network_info(context, instance, network_info)
4162         self.reset_network(context, instance)
4163 
4164         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4165         instance.updated_at = timeutils.utcnow()
4166         instance.save()
4167 
4168         self._notify_about_instance_usage(
4169             context, instance, "delete_ip.end", network_info=network_info)
4170 
4171     @wrap_exception()
4172     @reverts_task_state
4173     @wrap_instance_event(prefix='compute')
4174     @wrap_instance_fault
4175     def pause_instance(self, context, instance):
4176         """Pause an instance on this host."""
4177         context = context.elevated()
4178         LOG.info('Pausing', instance=instance)
4179         self._notify_about_instance_usage(context, instance, 'pause.start')
4180         compute_utils.notify_about_instance_action(context, instance,
4181                self.host, action=fields.NotificationAction.PAUSE,
4182                phase=fields.NotificationPhase.START)
4183         self.driver.pause(instance)
4184         instance.power_state = self._get_power_state(context, instance)
4185         instance.vm_state = vm_states.PAUSED
4186         instance.task_state = None
4187         instance.save(expected_task_state=task_states.PAUSING)
4188         self._notify_about_instance_usage(context, instance, 'pause.end')
4189         compute_utils.notify_about_instance_action(context, instance,
4190                self.host, action=fields.NotificationAction.PAUSE,
4191                phase=fields.NotificationPhase.END)
4192 
4193     @wrap_exception()
4194     @reverts_task_state
4195     @wrap_instance_event(prefix='compute')
4196     @wrap_instance_fault
4197     def unpause_instance(self, context, instance):
4198         """Unpause a paused instance on this host."""
4199         context = context.elevated()
4200         LOG.info('Unpausing', instance=instance)
4201         self._notify_about_instance_usage(context, instance, 'unpause.start')
4202         compute_utils.notify_about_instance_action(context, instance,
4203             self.host, action=fields.NotificationAction.UNPAUSE,
4204             phase=fields.NotificationPhase.START)
4205         self.driver.unpause(instance)
4206         instance.power_state = self._get_power_state(context, instance)
4207         instance.vm_state = vm_states.ACTIVE
4208         instance.task_state = None
4209         instance.save(expected_task_state=task_states.UNPAUSING)
4210         self._notify_about_instance_usage(context, instance, 'unpause.end')
4211         compute_utils.notify_about_instance_action(context, instance,
4212             self.host, action=fields.NotificationAction.UNPAUSE,
4213             phase=fields.NotificationPhase.END)
4214 
4215     @wrap_exception()
4216     def host_power_action(self, context, action):
4217         """Reboots, shuts down or powers up the host."""
4218         return self.driver.host_power_action(action)
4219 
4220     @wrap_exception()
4221     def host_maintenance_mode(self, context, host, mode):
4222         """Start/Stop host maintenance window. On start, it triggers
4223         guest VMs evacuation.
4224         """
4225         return self.driver.host_maintenance_mode(host, mode)
4226 
4227     @wrap_exception()
4228     def set_host_enabled(self, context, enabled):
4229         """Sets the specified host's ability to accept new instances."""
4230         return self.driver.set_host_enabled(enabled)
4231 
4232     @wrap_exception()
4233     def get_host_uptime(self, context):
4234         """Returns the result of calling "uptime" on the target host."""
4235         return self.driver.get_host_uptime()
4236 
4237     @wrap_exception()
4238     @wrap_instance_fault
4239     def get_diagnostics(self, context, instance):
4240         """Retrieve diagnostics for an instance on this host."""
4241         current_power_state = self._get_power_state(context, instance)
4242         if current_power_state == power_state.RUNNING:
4243             LOG.info("Retrieving diagnostics", instance=instance)
4244             return self.driver.get_diagnostics(instance)
4245         else:
4246             raise exception.InstanceInvalidState(
4247                 attr='power state',
4248                 instance_uuid=instance.uuid,
4249                 state=power_state.STATE_MAP[instance.power_state],
4250                 method='get_diagnostics')
4251 
4252     # TODO(alaski): Remove object_compat for RPC version 5.0
4253     @object_compat
4254     @wrap_exception()
4255     @wrap_instance_fault
4256     def get_instance_diagnostics(self, context, instance):
4257         """Retrieve diagnostics for an instance on this host."""
4258         current_power_state = self._get_power_state(context, instance)
4259         if current_power_state == power_state.RUNNING:
4260             LOG.info("Retrieving diagnostics", instance=instance)
4261             return self.driver.get_instance_diagnostics(instance)
4262         else:
4263             raise exception.InstanceInvalidState(
4264                 attr='power state',
4265                 instance_uuid=instance.uuid,
4266                 state=power_state.STATE_MAP[instance.power_state],
4267                 method='get_diagnostics')
4268 
4269     @wrap_exception()
4270     @reverts_task_state
4271     @wrap_instance_event(prefix='compute')
4272     @wrap_instance_fault
4273     def suspend_instance(self, context, instance):
4274         """Suspend the given instance."""
4275         context = context.elevated()
4276 
4277         # Store the old state
4278         instance.system_metadata['old_vm_state'] = instance.vm_state
4279         self._notify_about_instance_usage(context, instance, 'suspend.start')
4280         compute_utils.notify_about_instance_action(context, instance,
4281                 self.host, action=fields.NotificationAction.SUSPEND,
4282                 phase=fields.NotificationPhase.START)
4283         with self._error_out_instance_on_exception(context, instance,
4284              instance_state=instance.vm_state):
4285             self.driver.suspend(context, instance)
4286         instance.power_state = self._get_power_state(context, instance)
4287         instance.vm_state = vm_states.SUSPENDED
4288         instance.task_state = None
4289         instance.save(expected_task_state=task_states.SUSPENDING)
4290         self._notify_about_instance_usage(context, instance, 'suspend.end')
4291         compute_utils.notify_about_instance_action(context, instance,
4292                 self.host, action=fields.NotificationAction.SUSPEND,
4293                 phase=fields.NotificationPhase.END)
4294 
4295     @wrap_exception()
4296     @reverts_task_state
4297     @wrap_instance_event(prefix='compute')
4298     @wrap_instance_fault
4299     def resume_instance(self, context, instance):
4300         """Resume the given suspended instance."""
4301         context = context.elevated()
4302         LOG.info('Resuming', instance=instance)
4303 
4304         self._notify_about_instance_usage(context, instance, 'resume.start')
4305         compute_utils.notify_about_instance_action(context, instance,
4306             self.host, action=fields.NotificationAction.RESUME,
4307             phase=fields.NotificationPhase.START)
4308 
4309         network_info = self.network_api.get_instance_nw_info(context, instance)
4310         block_device_info = self._get_instance_block_device_info(
4311                             context, instance)
4312 
4313         with self._error_out_instance_on_exception(context, instance,
4314              instance_state=instance.vm_state):
4315             self.driver.resume(context, instance, network_info,
4316                                block_device_info)
4317 
4318         instance.power_state = self._get_power_state(context, instance)
4319 
4320         # We default to the ACTIVE state for backwards compatibility
4321         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4322                                                          vm_states.ACTIVE)
4323 
4324         instance.task_state = None
4325         instance.save(expected_task_state=task_states.RESUMING)
4326         self._notify_about_instance_usage(context, instance, 'resume.end')
4327         compute_utils.notify_about_instance_action(context, instance,
4328             self.host, action=fields.NotificationAction.RESUME,
4329             phase=fields.NotificationPhase.END)
4330 
4331     @wrap_exception()
4332     @reverts_task_state
4333     @wrap_instance_event(prefix='compute')
4334     @wrap_instance_fault
4335     def shelve_instance(self, context, instance, image_id,
4336                         clean_shutdown):
4337         """Shelve an instance.
4338 
4339         This should be used when you want to take a snapshot of the instance.
4340         It also adds system_metadata that can be used by a periodic task to
4341         offload the shelved instance after a period of time.
4342 
4343         :param context: request context
4344         :param instance: an Instance object
4345         :param image_id: an image id to snapshot to.
4346         :param clean_shutdown: give the GuestOS a chance to stop
4347         """
4348 
4349         @utils.synchronized(instance.uuid)
4350         def do_shelve_instance():
4351             self._shelve_instance(context, instance, image_id, clean_shutdown)
4352         do_shelve_instance()
4353 
4354     def _shelve_instance(self, context, instance, image_id,
4355                          clean_shutdown):
4356         LOG.info('Shelving', instance=instance)
4357         compute_utils.notify_usage_exists(self.notifier, context, instance,
4358                                           current_period=True)
4359         self._notify_about_instance_usage(context, instance, 'shelve.start')
4360         compute_utils.notify_about_instance_action(context, instance,
4361                 self.host, action=fields.NotificationAction.SHELVE,
4362                 phase=fields.NotificationPhase.START)
4363 
4364         def update_task_state(task_state, expected_state=task_states.SHELVING):
4365             shelving_state_map = {
4366                     task_states.IMAGE_PENDING_UPLOAD:
4367                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4368                     task_states.IMAGE_UPLOADING:
4369                         task_states.SHELVING_IMAGE_UPLOADING,
4370                     task_states.SHELVING: task_states.SHELVING}
4371             task_state = shelving_state_map[task_state]
4372             expected_state = shelving_state_map[expected_state]
4373             instance.task_state = task_state
4374             instance.save(expected_task_state=expected_state)
4375 
4376         self._power_off_instance(context, instance, clean_shutdown)
4377         self.driver.snapshot(context, instance, image_id, update_task_state)
4378 
4379         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4380         instance.system_metadata['shelved_image_id'] = image_id
4381         instance.system_metadata['shelved_host'] = self.host
4382         instance.vm_state = vm_states.SHELVED
4383         instance.task_state = None
4384         if CONF.shelved_offload_time == 0:
4385             instance.task_state = task_states.SHELVING_OFFLOADING
4386         instance.power_state = self._get_power_state(context, instance)
4387         instance.save(expected_task_state=[
4388                 task_states.SHELVING,
4389                 task_states.SHELVING_IMAGE_UPLOADING])
4390 
4391         self._notify_about_instance_usage(context, instance, 'shelve.end')
4392         compute_utils.notify_about_instance_action(context, instance,
4393                 self.host, action=fields.NotificationAction.SHELVE,
4394                 phase=fields.NotificationPhase.END)
4395 
4396         if CONF.shelved_offload_time == 0:
4397             self._shelve_offload_instance(context, instance,
4398                                           clean_shutdown=False)
4399 
4400     @wrap_exception()
4401     @reverts_task_state
4402     @wrap_instance_fault
4403     def shelve_offload_instance(self, context, instance, clean_shutdown):
4404         """Remove a shelved instance from the hypervisor.
4405 
4406         This frees up those resources for use by other instances, but may lead
4407         to slower unshelve times for this instance.  This method is used by
4408         volume backed instances since restoring them doesn't involve the
4409         potentially large download of an image.
4410 
4411         :param context: request context
4412         :param instance: nova.objects.instance.Instance
4413         :param clean_shutdown: give the GuestOS a chance to stop
4414         """
4415 
4416         @utils.synchronized(instance.uuid)
4417         def do_shelve_offload_instance():
4418             self._shelve_offload_instance(context, instance, clean_shutdown)
4419         do_shelve_offload_instance()
4420 
4421     def _shelve_offload_instance(self, context, instance, clean_shutdown):
4422         LOG.info('Shelve offloading', instance=instance)
4423         self._notify_about_instance_usage(context, instance,
4424                 'shelve_offload.start')
4425         compute_utils.notify_about_instance_action(context, instance,
4426                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4427                 phase=fields.NotificationPhase.START)
4428 
4429         self._power_off_instance(context, instance, clean_shutdown)
4430         current_power_state = self._get_power_state(context, instance)
4431 
4432         self.network_api.cleanup_instance_network_on_host(context, instance,
4433                                                           instance.host)
4434         network_info = self.network_api.get_instance_nw_info(context, instance)
4435         block_device_info = self._get_instance_block_device_info(context,
4436                                                                  instance)
4437         self.driver.destroy(context, instance, network_info,
4438                 block_device_info)
4439 
4440         instance.power_state = current_power_state
4441         # NOTE(mriedem): The vm_state has to be set before updating the
4442         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4443         # values cannot be nulled out until after updating the resource tracker
4444         # though.
4445         instance.vm_state = vm_states.SHELVED_OFFLOADED
4446         instance.task_state = None
4447         instance.save(expected_task_state=[task_states.SHELVING,
4448                                            task_states.SHELVING_OFFLOADING])
4449 
4450         # NOTE(ndipanov): Free resources from the resource tracker
4451         self._update_resource_tracker(context, instance)
4452 
4453         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4454         # instance, so ensure any calls result in errors
4455         self._nil_out_instance_obj_host_and_node(instance)
4456         instance.save(expected_task_state=None)
4457 
4458         self._delete_scheduler_instance_info(context, instance.uuid)
4459         self._notify_about_instance_usage(context, instance,
4460                 'shelve_offload.end')
4461         compute_utils.notify_about_instance_action(context, instance,
4462                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4463                 phase=fields.NotificationPhase.END)
4464 
4465     @wrap_exception()
4466     @reverts_task_state
4467     @wrap_instance_event(prefix='compute')
4468     @wrap_instance_fault
4469     def unshelve_instance(self, context, instance, image,
4470                           filter_properties, node):
4471         """Unshelve the instance.
4472 
4473         :param context: request context
4474         :param instance: a nova.objects.instance.Instance object
4475         :param image: an image to build from.  If None we assume a
4476             volume backed instance.
4477         :param filter_properties: dict containing limits, retry info etc.
4478         :param node: target compute node
4479         """
4480         if filter_properties is None:
4481             filter_properties = {}
4482 
4483         @utils.synchronized(instance.uuid)
4484         def do_unshelve_instance():
4485             self._unshelve_instance(context, instance, image,
4486                                     filter_properties, node)
4487         do_unshelve_instance()
4488 
4489     def _unshelve_instance_key_scrub(self, instance):
4490         """Remove data from the instance that may cause side effects."""
4491         cleaned_keys = dict(
4492                 key_data=instance.key_data,
4493                 auto_disk_config=instance.auto_disk_config)
4494         instance.key_data = None
4495         instance.auto_disk_config = False
4496         return cleaned_keys
4497 
4498     def _unshelve_instance_key_restore(self, instance, keys):
4499         """Restore previously scrubbed keys before saving the instance."""
4500         instance.update(keys)
4501 
4502     def _unshelve_instance(self, context, instance, image, filter_properties,
4503                            node):
4504         LOG.info('Unshelving', instance=instance)
4505         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4506         compute_utils.notify_about_instance_action(context, instance,
4507                 self.host, action=fields.NotificationAction.UNSHELVE,
4508                 phase=fields.NotificationPhase.START)
4509 
4510         instance.task_state = task_states.SPAWNING
4511         instance.save()
4512 
4513         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4514                 context, instance.uuid)
4515         block_device_info = self._prep_block_device(context, instance, bdms)
4516         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4517 
4518         if node is None:
4519             node = self.driver.get_available_nodes()[0]
4520             LOG.debug('No node specified, defaulting to %s', node,
4521                       instance=instance)
4522 
4523         rt = self._get_resource_tracker()
4524         limits = filter_properties.get('limits', {})
4525 
4526         shelved_image_ref = instance.image_ref
4527         if image:
4528             instance.image_ref = image['id']
4529             image_meta = objects.ImageMeta.from_dict(image)
4530         else:
4531             image_meta = objects.ImageMeta.from_dict(
4532                 utils.get_image_from_system_metadata(
4533                     instance.system_metadata))
4534 
4535         self.network_api.setup_instance_network_on_host(context, instance,
4536                                                         self.host)
4537         network_info = self.network_api.get_instance_nw_info(context, instance)
4538         try:
4539             with rt.instance_claim(context, instance, node, limits):
4540                 self.driver.spawn(context, instance, image_meta,
4541                                   injected_files=[],
4542                                   admin_password=None,
4543                                   network_info=network_info,
4544                                   block_device_info=block_device_info)
4545         except Exception:
4546             with excutils.save_and_reraise_exception():
4547                 LOG.exception('Instance failed to spawn',
4548                               instance=instance)
4549 
4550         if image:
4551             instance.image_ref = shelved_image_ref
4552             self._delete_snapshot_of_shelved_instance(context, instance,
4553                                                       image['id'])
4554 
4555         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4556         self._update_instance_after_spawn(context, instance)
4557         # Delete system_metadata for a shelved instance
4558         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4559 
4560         instance.save(expected_task_state=task_states.SPAWNING)
4561         self._update_scheduler_instance_info(context, instance)
4562         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4563         compute_utils.notify_about_instance_action(context, instance,
4564                 self.host, action=fields.NotificationAction.UNSHELVE,
4565                 phase=fields.NotificationPhase.END)
4566 
4567     @messaging.expected_exceptions(NotImplementedError)
4568     @wrap_instance_fault
4569     def reset_network(self, context, instance):
4570         """Reset networking on the given instance."""
4571         LOG.debug('Reset network', instance=instance)
4572         self.driver.reset_network(instance)
4573 
4574     def _inject_network_info(self, context, instance, network_info):
4575         """Inject network info for the given instance."""
4576         LOG.debug('Inject network info', instance=instance)
4577         LOG.debug('network_info to inject: |%s|', network_info,
4578                   instance=instance)
4579 
4580         self.driver.inject_network_info(instance,
4581                                         network_info)
4582 
4583     @wrap_instance_fault
4584     def inject_network_info(self, context, instance):
4585         """Inject network info, but don't return the info."""
4586         network_info = self.network_api.get_instance_nw_info(context, instance)
4587         self._inject_network_info(context, instance, network_info)
4588 
4589     @messaging.expected_exceptions(NotImplementedError,
4590                                    exception.ConsoleNotAvailable,
4591                                    exception.InstanceNotFound)
4592     @wrap_exception()
4593     @wrap_instance_fault
4594     def get_console_output(self, context, instance, tail_length):
4595         """Send the console output for the given instance."""
4596         context = context.elevated()
4597         LOG.info("Get console output", instance=instance)
4598         output = self.driver.get_console_output(context, instance)
4599 
4600         if type(output) is six.text_type:
4601             output = six.b(output)
4602 
4603         if tail_length is not None:
4604             output = self._tail_log(output, tail_length)
4605 
4606         return output.decode('ascii', 'replace')
4607 
4608     def _tail_log(self, log, length):
4609         try:
4610             length = int(length)
4611         except ValueError:
4612             length = 0
4613 
4614         if length == 0:
4615             return b''
4616         else:
4617             return b'\n'.join(log.split(b'\n')[-int(length):])
4618 
4619     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4620                                    exception.InstanceNotReady,
4621                                    exception.InstanceNotFound,
4622                                    exception.ConsoleTypeUnavailable,
4623                                    NotImplementedError)
4624     @wrap_exception()
4625     @wrap_instance_fault
4626     def get_vnc_console(self, context, console_type, instance):
4627         """Return connection information for a vnc console."""
4628         context = context.elevated()
4629         LOG.debug("Getting vnc console", instance=instance)
4630         token = uuidutils.generate_uuid()
4631 
4632         if not CONF.vnc.enabled:
4633             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4634 
4635         if console_type == 'novnc':
4636             # For essex, novncproxy_base_url must include the full path
4637             # including the html file (like http://myhost/vnc_auto.html)
4638             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
4639         elif console_type == 'xvpvnc':
4640             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
4641         else:
4642             raise exception.ConsoleTypeInvalid(console_type=console_type)
4643 
4644         try:
4645             # Retrieve connect info from driver, and then decorate with our
4646             # access info token
4647             console = self.driver.get_vnc_console(context, instance)
4648             connect_info = console.get_connection_info(token, access_url)
4649         except exception.InstanceNotFound:
4650             if instance.vm_state != vm_states.BUILDING:
4651                 raise
4652             raise exception.InstanceNotReady(instance_id=instance.uuid)
4653 
4654         return connect_info
4655 
4656     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4657                                    exception.InstanceNotReady,
4658                                    exception.InstanceNotFound,
4659                                    exception.ConsoleTypeUnavailable,
4660                                    NotImplementedError)
4661     @wrap_exception()
4662     @wrap_instance_fault
4663     def get_spice_console(self, context, console_type, instance):
4664         """Return connection information for a spice console."""
4665         context = context.elevated()
4666         LOG.debug("Getting spice console", instance=instance)
4667         token = uuidutils.generate_uuid()
4668 
4669         if not CONF.spice.enabled:
4670             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4671 
4672         if console_type == 'spice-html5':
4673             # For essex, spicehtml5proxy_base_url must include the full path
4674             # including the html file (like http://myhost/spice_auto.html)
4675             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
4676                                           token)
4677         else:
4678             raise exception.ConsoleTypeInvalid(console_type=console_type)
4679 
4680         try:
4681             # Retrieve connect info from driver, and then decorate with our
4682             # access info token
4683             console = self.driver.get_spice_console(context, instance)
4684             connect_info = console.get_connection_info(token, access_url)
4685         except exception.InstanceNotFound:
4686             if instance.vm_state != vm_states.BUILDING:
4687                 raise
4688             raise exception.InstanceNotReady(instance_id=instance.uuid)
4689 
4690         return connect_info
4691 
4692     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4693                                    exception.InstanceNotReady,
4694                                    exception.InstanceNotFound,
4695                                    exception.ConsoleTypeUnavailable,
4696                                    NotImplementedError)
4697     @wrap_exception()
4698     @wrap_instance_fault
4699     def get_rdp_console(self, context, console_type, instance):
4700         """Return connection information for a RDP console."""
4701         context = context.elevated()
4702         LOG.debug("Getting RDP console", instance=instance)
4703         token = uuidutils.generate_uuid()
4704 
4705         if not CONF.rdp.enabled:
4706             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4707 
4708         if console_type == 'rdp-html5':
4709             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
4710                                           token)
4711         else:
4712             raise exception.ConsoleTypeInvalid(console_type=console_type)
4713 
4714         try:
4715             # Retrieve connect info from driver, and then decorate with our
4716             # access info token
4717             console = self.driver.get_rdp_console(context, instance)
4718             connect_info = console.get_connection_info(token, access_url)
4719         except exception.InstanceNotFound:
4720             if instance.vm_state != vm_states.BUILDING:
4721                 raise
4722             raise exception.InstanceNotReady(instance_id=instance.uuid)
4723 
4724         return connect_info
4725 
4726     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4727                                    exception.InstanceNotReady,
4728                                    exception.InstanceNotFound,
4729                                    exception.ConsoleTypeUnavailable,
4730                                    NotImplementedError)
4731     @wrap_exception()
4732     @wrap_instance_fault
4733     def get_mks_console(self, context, console_type, instance):
4734         """Return connection information for a MKS console."""
4735         context = context.elevated()
4736         LOG.debug("Getting MKS console", instance=instance)
4737         token = uuidutils.generate_uuid()
4738 
4739         if not CONF.mks.enabled:
4740             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4741 
4742         if console_type == 'webmks':
4743             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
4744                                           token)
4745         else:
4746             raise exception.ConsoleTypeInvalid(console_type=console_type)
4747 
4748         try:
4749             # Retrieve connect info from driver, and then decorate with our
4750             # access info token
4751             console = self.driver.get_mks_console(context, instance)
4752             connect_info = console.get_connection_info(token, access_url)
4753         except exception.InstanceNotFound:
4754             if instance.vm_state != vm_states.BUILDING:
4755                 raise
4756             raise exception.InstanceNotReady(instance_id=instance.uuid)
4757 
4758         return connect_info
4759 
4760     @messaging.expected_exceptions(
4761         exception.ConsoleTypeInvalid,
4762         exception.InstanceNotReady,
4763         exception.InstanceNotFound,
4764         exception.ConsoleTypeUnavailable,
4765         exception.SocketPortRangeExhaustedException,
4766         exception.ImageSerialPortNumberInvalid,
4767         exception.ImageSerialPortNumberExceedFlavorValue,
4768         NotImplementedError)
4769     @wrap_exception()
4770     @wrap_instance_fault
4771     def get_serial_console(self, context, console_type, instance):
4772         """Returns connection information for a serial console."""
4773 
4774         LOG.debug("Getting serial console", instance=instance)
4775 
4776         if not CONF.serial_console.enabled:
4777             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4778 
4779         context = context.elevated()
4780 
4781         token = uuidutils.generate_uuid()
4782         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
4783 
4784         try:
4785             # Retrieve connect info from driver, and then decorate with our
4786             # access info token
4787             console = self.driver.get_serial_console(context, instance)
4788             connect_info = console.get_connection_info(token, access_url)
4789         except exception.InstanceNotFound:
4790             if instance.vm_state != vm_states.BUILDING:
4791                 raise
4792             raise exception.InstanceNotReady(instance_id=instance.uuid)
4793 
4794         return connect_info
4795 
4796     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4797                                    exception.InstanceNotReady,
4798                                    exception.InstanceNotFound)
4799     @wrap_exception()
4800     @wrap_instance_fault
4801     def validate_console_port(self, ctxt, instance, port, console_type):
4802         if console_type == "spice-html5":
4803             console_info = self.driver.get_spice_console(ctxt, instance)
4804         elif console_type == "rdp-html5":
4805             console_info = self.driver.get_rdp_console(ctxt, instance)
4806         elif console_type == "serial":
4807             console_info = self.driver.get_serial_console(ctxt, instance)
4808         elif console_type == "webmks":
4809             console_info = self.driver.get_mks_console(ctxt, instance)
4810         else:
4811             console_info = self.driver.get_vnc_console(ctxt, instance)
4812 
4813         return console_info.port == port
4814 
4815     @wrap_exception()
4816     @reverts_task_state
4817     @wrap_instance_fault
4818     def reserve_block_device_name(self, context, instance, device,
4819                                   volume_id, disk_bus, device_type, tag=None):
4820         if (tag and not
4821                 self.driver.capabilities.get('supports_tagged_attach_volume',
4822                                              False)):
4823             raise exception.VolumeTaggedAttachNotSupported()
4824 
4825         @utils.synchronized(instance.uuid)
4826         def do_reserve():
4827             bdms = (
4828                 objects.BlockDeviceMappingList.get_by_instance_uuid(
4829                     context, instance.uuid))
4830 
4831             # NOTE(ndipanov): We need to explicitly set all the fields on the
4832             #                 object so that obj_load_attr does not fail
4833             new_bdm = objects.BlockDeviceMapping(
4834                     context=context,
4835                     source_type='volume', destination_type='volume',
4836                     instance_uuid=instance.uuid, boot_index=None,
4837                     volume_id=volume_id,
4838                     device_name=device, guest_format=None,
4839                     disk_bus=disk_bus, device_type=device_type, tag=tag)
4840 
4841             new_bdm.device_name = self._get_device_name_for_instance(
4842                     instance, bdms, new_bdm)
4843 
4844             # NOTE(vish): create bdm here to avoid race condition
4845             new_bdm.create()
4846             return new_bdm
4847 
4848         return do_reserve()
4849 
4850     @wrap_exception()
4851     @wrap_instance_fault
4852     def attach_volume(self, context, instance, bdm):
4853         """Attach a volume to an instance."""
4854         driver_bdm = driver_block_device.convert_volume(bdm)
4855 
4856         @utils.synchronized(instance.uuid)
4857         def do_attach_volume(context, instance, driver_bdm):
4858             try:
4859                 return self._attach_volume(context, instance, driver_bdm)
4860             except Exception:
4861                 with excutils.save_and_reraise_exception():
4862                     bdm.destroy()
4863 
4864         do_attach_volume(context, instance, driver_bdm)
4865 
4866     def _attach_volume(self, context, instance, bdm):
4867         context = context.elevated()
4868         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
4869                  {'volume_id': bdm.volume_id,
4870                   'mountpoint': bdm['mount_device']},
4871                  instance=instance)
4872         compute_utils.notify_about_volume_attach_detach(
4873             context, instance, self.host,
4874             action=fields.NotificationAction.VOLUME_ATTACH,
4875             phase=fields.NotificationPhase.START,
4876             volume_id=bdm.volume_id)
4877         try:
4878             bdm.attach(context, instance, self.volume_api, self.driver,
4879                        do_driver_attach=True)
4880         except Exception as e:
4881             with excutils.save_and_reraise_exception():
4882                 LOG.exception("Failed to attach %(volume_id)s "
4883                               "at %(mountpoint)s",
4884                               {'volume_id': bdm.volume_id,
4885                                'mountpoint': bdm['mount_device']},
4886                               instance=instance)
4887                 self.volume_api.unreserve_volume(context, bdm.volume_id)
4888                 compute_utils.notify_about_volume_attach_detach(
4889                     context, instance, self.host,
4890                     action=fields.NotificationAction.VOLUME_ATTACH,
4891                     phase=fields.NotificationPhase.ERROR,
4892                     exception=e,
4893                     volume_id=bdm.volume_id)
4894 
4895         info = {'volume_id': bdm.volume_id}
4896         self._notify_about_instance_usage(
4897             context, instance, "volume.attach", extra_usage_info=info)
4898         compute_utils.notify_about_volume_attach_detach(
4899             context, instance, self.host,
4900             action=fields.NotificationAction.VOLUME_ATTACH,
4901             phase=fields.NotificationPhase.END,
4902             volume_id=bdm.volume_id)
4903 
4904     def _notify_volume_usage_detach(self, context, instance, bdm):
4905         if CONF.volume_usage_poll_interval <= 0:
4906             return
4907 
4908         vol_stats = []
4909         mp = bdm.device_name
4910         # Handle bootable volumes which will not contain /dev/
4911         if '/dev/' in mp:
4912             mp = mp[5:]
4913         try:
4914             vol_stats = self.driver.block_stats(instance, mp)
4915         except NotImplementedError:
4916             return
4917 
4918         LOG.debug("Updating volume usage cache with totals", instance=instance)
4919         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
4920         vol_usage = objects.VolumeUsage(context)
4921         vol_usage.volume_id = bdm.volume_id
4922         vol_usage.instance_uuid = instance.uuid
4923         vol_usage.project_id = instance.project_id
4924         vol_usage.user_id = instance.user_id
4925         vol_usage.availability_zone = instance.availability_zone
4926         vol_usage.curr_reads = rd_req
4927         vol_usage.curr_read_bytes = rd_bytes
4928         vol_usage.curr_writes = wr_req
4929         vol_usage.curr_write_bytes = wr_bytes
4930         vol_usage.save(update_totals=True)
4931         self.notifier.info(context, 'volume.usage',
4932                            compute_utils.usage_volume_info(vol_usage))
4933 
4934     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
4935                        attachment_id=None):
4936         """Detach a volume from an instance.
4937 
4938         :param context: security context
4939         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
4940         :param instance: the Instance object to detach the volume from
4941         :param destroy_bdm: if True, the corresponding BDM entry will be marked
4942                             as deleted. Disabling this is useful for operations
4943                             like rebuild, when we don't want to destroy BDM
4944         :param attachment_id: The volume attachment_id for the given instance
4945                               and volume.
4946         """
4947         volume_id = bdm.volume_id
4948         compute_utils.notify_about_volume_attach_detach(
4949             context, instance, self.host,
4950             action=fields.NotificationAction.VOLUME_DETACH,
4951             phase=fields.NotificationPhase.START,
4952             volume_id=volume_id)
4953 
4954         self._notify_volume_usage_detach(context, instance, bdm)
4955 
4956         LOG.info('Detaching volume %(volume_id)s',
4957                  {'volume_id': volume_id}, instance=instance)
4958 
4959         driver_bdm = driver_block_device.convert_volume(bdm)
4960         driver_bdm.detach(context, instance, self.volume_api, self.driver,
4961                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
4962 
4963         info = dict(volume_id=volume_id)
4964         self._notify_about_instance_usage(
4965             context, instance, "volume.detach", extra_usage_info=info)
4966         compute_utils.notify_about_volume_attach_detach(
4967             context, instance, self.host,
4968             action=fields.NotificationAction.VOLUME_DETACH,
4969             phase=fields.NotificationPhase.END,
4970             volume_id=volume_id)
4971 
4972         if 'tag' in bdm and bdm.tag:
4973             self._delete_disk_metadata(instance, bdm)
4974         if destroy_bdm:
4975             bdm.destroy()
4976 
4977     def _delete_disk_metadata(self, instance, bdm):
4978         for device in instance.device_metadata.devices:
4979             if isinstance(device, objects.DiskMetadata):
4980                 if 'serial' in device:
4981                     if device.serial == bdm.volume_id:
4982                         instance.device_metadata.devices.remove(device)
4983                         instance.save()
4984                         break
4985                 else:
4986                     # NOTE(artom) We log the entire device object because all
4987                     # fields are nullable and may not be set
4988                     LOG.warning('Unable to determine whether to clean up '
4989                                 'device metadata for disk %s', device,
4990                                 instance=instance)
4991 
4992     @wrap_exception()
4993     @wrap_instance_fault
4994     def detach_volume(self, context, volume_id, instance, attachment_id=None):
4995         """Detach a volume from an instance.
4996 
4997         :param context: security context
4998         :param volume_id: the volume id
4999         :param instance: the Instance object to detach the volume from
5000         :param attachment_id: The volume attachment_id for the given instance
5001                               and volume.
5002 
5003         """
5004         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5005                 context, volume_id, instance.uuid)
5006         self._detach_volume(context, bdm, instance,
5007                             attachment_id=attachment_id)
5008 
5009     def _init_volume_connection(self, context, new_volume_id,
5010                                 old_volume_id, connector, instance, bdm):
5011 
5012         new_cinfo = self.volume_api.initialize_connection(context,
5013                                                           new_volume_id,
5014                                                           connector)
5015         old_cinfo = jsonutils.loads(bdm['connection_info'])
5016         if old_cinfo and 'serial' not in old_cinfo:
5017             old_cinfo['serial'] = old_volume_id
5018         # NOTE(lyarwood): serial is not always present in the returned
5019         # connection_info so set it if it is missing as we do in
5020         # DriverVolumeBlockDevice.attach().
5021         if 'serial' not in new_cinfo:
5022             new_cinfo['serial'] = new_volume_id
5023         return (old_cinfo, new_cinfo)
5024 
5025     def _swap_volume(self, context, instance, bdm, connector,
5026                      old_volume_id, new_volume_id, resize_to):
5027         mountpoint = bdm['device_name']
5028         failed = False
5029         new_cinfo = None
5030         try:
5031             old_cinfo, new_cinfo = self._init_volume_connection(context,
5032                                                                 new_volume_id,
5033                                                                 old_volume_id,
5034                                                                 connector,
5035                                                                 instance,
5036                                                                 bdm)
5037             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5038             # currently implementing swap_volume, will modify the contents of
5039             # new_cinfo when connect_volume is called. This is then saved to
5040             # the BDM in swap_volume for future use outside of this flow.
5041             LOG.debug("swap_volume: Calling driver volume swap with "
5042                       "connection infos: new: %(new_cinfo)s; "
5043                       "old: %(old_cinfo)s",
5044                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo},
5045                       instance=instance)
5046             self.driver.swap_volume(old_cinfo, new_cinfo, instance, mountpoint,
5047                                     resize_to)
5048             LOG.debug("swap_volume: Driver volume swap returned, new "
5049                       "connection_info is now : %(new_cinfo)s",
5050                       {'new_cinfo': new_cinfo})
5051         except Exception as ex:
5052             failed = True
5053             with excutils.save_and_reraise_exception():
5054                 compute_utils.notify_about_volume_swap(
5055                     context, instance, self.host,
5056                     fields.NotificationAction.VOLUME_SWAP,
5057                     fields.NotificationPhase.ERROR,
5058                     old_volume_id, new_volume_id, ex)
5059                 if new_cinfo:
5060                     msg = ("Failed to swap volume %(old_volume_id)s "
5061                            "for %(new_volume_id)s")
5062                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5063                                         'new_volume_id': new_volume_id},
5064                                   instance=instance)
5065                 else:
5066                     msg = ("Failed to connect to volume %(volume_id)s "
5067                            "with volume at %(mountpoint)s")
5068                     LOG.exception(msg, {'volume_id': new_volume_id,
5069                                         'mountpoint': bdm['device_name']},
5070                                   instance=instance)
5071                 self.volume_api.roll_detaching(context, old_volume_id)
5072                 self.volume_api.unreserve_volume(context, new_volume_id)
5073         finally:
5074             conn_volume = new_volume_id if failed else old_volume_id
5075             if new_cinfo:
5076                 LOG.debug("swap_volume: calling Cinder terminate_connection "
5077                           "for %(volume)s", {'volume': conn_volume},
5078                           instance=instance)
5079                 self.volume_api.terminate_connection(context,
5080                                                      conn_volume,
5081                                                      connector)
5082             # NOTE(lyarwood): The following call to
5083             # os-migrate-volume-completion returns a dict containing
5084             # save_volume_id, this volume id has two possible values :
5085             # 1. old_volume_id if we are migrating (retyping) volumes
5086             # 2. new_volume_id if we are swapping between two existing volumes
5087             # This volume id is later used to update the volume_id and
5088             # connection_info['serial'] of the BDM.
5089             comp_ret = self.volume_api.migrate_volume_completion(
5090                                                       context,
5091                                                       old_volume_id,
5092                                                       new_volume_id,
5093                                                       error=failed)
5094             LOG.debug("swap_volume: Cinder migrate_volume_completion "
5095                       "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5096                       instance=instance)
5097 
5098         return (comp_ret, new_cinfo)
5099 
5100     @wrap_exception()
5101     @reverts_task_state
5102     @wrap_instance_fault
5103     def swap_volume(self, context, old_volume_id, new_volume_id, instance):
5104         """Swap volume for an instance."""
5105         context = context.elevated()
5106 
5107         compute_utils.notify_about_volume_swap(
5108             context, instance, self.host,
5109             fields.NotificationAction.VOLUME_SWAP,
5110             fields.NotificationPhase.START,
5111             old_volume_id, new_volume_id)
5112 
5113         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5114                 context, old_volume_id, instance.uuid)
5115         connector = self.driver.get_volume_connector(instance)
5116 
5117         resize_to = 0
5118         old_vol_size = self.volume_api.get(context, old_volume_id)['size']
5119         new_vol_size = self.volume_api.get(context, new_volume_id)['size']
5120         if new_vol_size > old_vol_size:
5121             resize_to = new_vol_size
5122 
5123         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5124                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5125                  instance=instance)
5126         comp_ret, new_cinfo = self._swap_volume(context, instance,
5127                                                          bdm,
5128                                                          connector,
5129                                                          old_volume_id,
5130                                                          new_volume_id,
5131                                                          resize_to)
5132 
5133         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5134         # correct volume_id returned by Cinder.
5135         save_volume_id = comp_ret['save_volume_id']
5136         new_cinfo['serial'] = save_volume_id
5137         values = {
5138             'connection_info': jsonutils.dumps(new_cinfo),
5139             'source_type': 'volume',
5140             'destination_type': 'volume',
5141             'snapshot_id': None,
5142             'volume_id': save_volume_id,
5143             'no_device': None}
5144 
5145         if resize_to:
5146             values['volume_size'] = resize_to
5147 
5148         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5149                   "%(updates)s", {'volume_id': bdm.volume_id,
5150                                   'updates': values},
5151                   instance=instance)
5152         bdm.update(values)
5153         bdm.save()
5154 
5155         compute_utils.notify_about_volume_swap(
5156             context, instance, self.host,
5157             fields.NotificationAction.VOLUME_SWAP,
5158             fields.NotificationPhase.END,
5159             old_volume_id, new_volume_id)
5160 
5161     @wrap_exception()
5162     def remove_volume_connection(self, context, volume_id, instance):
5163         """Remove a volume connection using the volume api."""
5164         # NOTE(vish): We don't want to actually mark the volume
5165         #             detached, or delete the bdm, just remove the
5166         #             connection from this host.
5167 
5168         try:
5169             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5170                     context, volume_id, instance.uuid)
5171             driver_bdm = driver_block_device.convert_volume(bdm)
5172             driver_bdm.driver_detach(context, instance,
5173                                      self.volume_api, self.driver)
5174             connector = self.driver.get_volume_connector(instance)
5175             self.volume_api.terminate_connection(context, volume_id, connector)
5176         except exception.NotFound:
5177             pass
5178 
5179     @wrap_exception()
5180     @wrap_instance_fault
5181     def attach_interface(self, context, instance, network_id, port_id,
5182                          requested_ip, tag=None):
5183         """Use hotplug to add an network adapter to an instance."""
5184         if not self.driver.capabilities['supports_attach_interface']:
5185             raise exception.AttachInterfaceNotSupported(
5186                 instance_uuid=instance.uuid)
5187         if (tag and not
5188             self.driver.capabilities.get('supports_tagged_attach_interface',
5189                                          False)):
5190             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5191         bind_host_id = self.driver.network_binding_host_id(context, instance)
5192         network_info = self.network_api.allocate_port_for_instance(
5193             context, instance, port_id, network_id, requested_ip,
5194             bind_host_id=bind_host_id, tag=tag)
5195         if len(network_info) != 1:
5196             LOG.error('allocate_port_for_instance returned %(ports)s '
5197                       'ports', {'ports': len(network_info)})
5198             raise exception.InterfaceAttachFailed(
5199                     instance_uuid=instance.uuid)
5200         image_meta = objects.ImageMeta.from_instance(instance)
5201 
5202         try:
5203             self.driver.attach_interface(context, instance, image_meta,
5204                                          network_info[0])
5205         except exception.NovaException as ex:
5206             port_id = network_info[0].get('id')
5207             LOG.warning("attach interface failed , try to deallocate "
5208                         "port %(port_id)s, reason: %(msg)s",
5209                         {'port_id': port_id, 'msg': ex},
5210                         instance=instance)
5211             try:
5212                 self.network_api.deallocate_port_for_instance(
5213                     context, instance, port_id)
5214             except Exception:
5215                 LOG.warning("deallocate port %(port_id)s failed",
5216                             {'port_id': port_id}, instance=instance)
5217             raise exception.InterfaceAttachFailed(
5218                 instance_uuid=instance.uuid)
5219 
5220         return network_info[0]
5221 
5222     @wrap_exception()
5223     @wrap_instance_fault
5224     def detach_interface(self, context, instance, port_id):
5225         """Detach a network adapter from an instance."""
5226         network_info = instance.info_cache.network_info
5227         condemned = None
5228         for vif in network_info:
5229             if vif['id'] == port_id:
5230                 condemned = vif
5231                 break
5232         if condemned is None:
5233             raise exception.PortNotFound(_("Port %s is not "
5234                                            "attached") % port_id)
5235         try:
5236             self.driver.detach_interface(context, instance, condemned)
5237         except exception.NovaException as ex:
5238             LOG.warning("Detach interface failed, port_id=%(port_id)s,"
5239                         " reason: %(msg)s",
5240                         {'port_id': port_id, 'msg': ex}, instance=instance)
5241             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5242         else:
5243             try:
5244                 self.network_api.deallocate_port_for_instance(
5245                     context, instance, port_id)
5246             except Exception as ex:
5247                 with excutils.save_and_reraise_exception():
5248                     # Since this is a cast operation, log the failure for
5249                     # triage.
5250                     LOG.warning('Failed to deallocate port %(port_id)s '
5251                                 'for instance. Error: %(error)s',
5252                                 {'port_id': port_id, 'error': ex},
5253                                 instance=instance)
5254 
5255     def _get_compute_info(self, context, host):
5256         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5257             context, host)
5258 
5259     @wrap_exception()
5260     def check_instance_shared_storage(self, ctxt, instance, data):
5261         """Check if the instance files are shared
5262 
5263         :param ctxt: security context
5264         :param instance: dict of instance data
5265         :param data: result of driver.check_instance_shared_storage_local
5266 
5267         Returns True if instance disks located on shared storage and
5268         False otherwise.
5269         """
5270         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5271 
5272     @wrap_exception()
5273     @wrap_instance_event(prefix='compute')
5274     @wrap_instance_fault
5275     def check_can_live_migrate_destination(self, ctxt, instance,
5276                                            block_migration, disk_over_commit):
5277         """Check if it is possible to execute live migration.
5278 
5279         This runs checks on the destination host, and then calls
5280         back to the source host to check the results.
5281 
5282         :param context: security context
5283         :param instance: dict of instance data
5284         :param block_migration: if true, prepare for block migration
5285                                 if None, calculate it in driver
5286         :param disk_over_commit: if true, allow disk over commit
5287                                  if None, ignore disk usage checking
5288         :returns: a dict containing migration info
5289         """
5290         return self._do_check_can_live_migrate_destination(ctxt, instance,
5291                                                             block_migration,
5292                                                             disk_over_commit)
5293 
5294     def _do_check_can_live_migrate_destination(self, ctxt, instance,
5295                                                block_migration,
5296                                                disk_over_commit):
5297         src_compute_info = obj_base.obj_to_primitive(
5298             self._get_compute_info(ctxt, instance.host))
5299         dst_compute_info = obj_base.obj_to_primitive(
5300             self._get_compute_info(ctxt, CONF.host))
5301         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5302             instance, src_compute_info, dst_compute_info,
5303             block_migration, disk_over_commit)
5304         LOG.debug('destination check data is %s', dest_check_data)
5305         try:
5306             migrate_data = self.compute_rpcapi.\
5307                                 check_can_live_migrate_source(ctxt, instance,
5308                                                               dest_check_data)
5309         finally:
5310             self.driver.cleanup_live_migration_destination_check(ctxt,
5311                     dest_check_data)
5312         return migrate_data
5313 
5314     @wrap_exception()
5315     @wrap_instance_event(prefix='compute')
5316     @wrap_instance_fault
5317     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5318         """Check if it is possible to execute live migration.
5319 
5320         This checks if the live migration can succeed, based on the
5321         results from check_can_live_migrate_destination.
5322 
5323         :param ctxt: security context
5324         :param instance: dict of instance data
5325         :param dest_check_data: result of check_can_live_migrate_destination
5326         :returns: a dict containing migration info
5327         """
5328         is_volume_backed = compute_utils.is_volume_backed_instance(ctxt,
5329                                                                       instance)
5330         # TODO(tdurakov): remove dict to object conversion once RPC API version
5331         # is bumped to 5.x
5332         got_migrate_data_object = isinstance(dest_check_data,
5333                                              migrate_data_obj.LiveMigrateData)
5334         if not got_migrate_data_object:
5335             dest_check_data = \
5336                 migrate_data_obj.LiveMigrateData.detect_implementation(
5337                     dest_check_data)
5338         dest_check_data.is_volume_backed = is_volume_backed
5339         block_device_info = self._get_instance_block_device_info(
5340                             ctxt, instance, refresh_conn_info=False)
5341         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5342                                                            dest_check_data,
5343                                                            block_device_info)
5344         if not got_migrate_data_object:
5345             result = result.to_legacy_dict()
5346         LOG.debug('source check data is %s', result)
5347         return result
5348 
5349     @wrap_exception()
5350     @wrap_instance_event(prefix='compute')
5351     @wrap_instance_fault
5352     def pre_live_migration(self, context, instance, block_migration, disk,
5353                            migrate_data):
5354         """Preparations for live migration at dest host.
5355 
5356         :param context: security context
5357         :param instance: dict of instance data
5358         :param block_migration: if true, prepare for block migration
5359         :param migrate_data: A dict or LiveMigrateData object holding data
5360                              required for live migration without shared
5361                              storage.
5362 
5363         """
5364         LOG.debug('pre_live_migration data is %s', migrate_data)
5365         # TODO(tdurakov): remove dict to object conversion once RPC API version
5366         # is bumped to 5.x
5367         got_migrate_data_object = isinstance(migrate_data,
5368                                              migrate_data_obj.LiveMigrateData)
5369         if not got_migrate_data_object:
5370             migrate_data = \
5371                 migrate_data_obj.LiveMigrateData.detect_implementation(
5372                     migrate_data)
5373         block_device_info = self._get_instance_block_device_info(
5374                             context, instance, refresh_conn_info=True)
5375 
5376         network_info = self.network_api.get_instance_nw_info(context, instance)
5377         self._notify_about_instance_usage(
5378                      context, instance, "live_migration.pre.start",
5379                      network_info=network_info)
5380 
5381         migrate_data = self.driver.pre_live_migration(context,
5382                                        instance,
5383                                        block_device_info,
5384                                        network_info,
5385                                        disk,
5386                                        migrate_data)
5387         LOG.debug('driver pre_live_migration data is %s', migrate_data)
5388 
5389         # NOTE(tr3buchet): setup networks on destination host
5390         self.network_api.setup_networks_on_host(context, instance,
5391                                                          self.host)
5392 
5393         # Creating filters to hypervisors and firewalls.
5394         # An example is that nova-instance-instance-xxx,
5395         # which is written to libvirt.xml(Check "virsh nwfilter-list")
5396         # This nwfilter is necessary on the destination host.
5397         # In addition, this method is creating filtering rule
5398         # onto destination host.
5399         self.driver.ensure_filtering_rules_for_instance(instance,
5400                                             network_info)
5401 
5402         self._notify_about_instance_usage(
5403                      context, instance, "live_migration.pre.end",
5404                      network_info=network_info)
5405         # TODO(tdurakov): remove dict to object conversion once RPC API version
5406         # is bumped to 5.x
5407         if not got_migrate_data_object and migrate_data:
5408             migrate_data = migrate_data.to_legacy_dict(
5409                 pre_migration_result=True)
5410             migrate_data = migrate_data['pre_live_migration_result']
5411         LOG.debug('pre_live_migration result data is %s', migrate_data)
5412         return migrate_data
5413 
5414     def _do_live_migration(self, context, dest, instance, block_migration,
5415                            migration, migrate_data):
5416         # NOTE(danms): We should enhance the RT to account for migrations
5417         # and use the status field to denote when the accounting has been
5418         # done on source/destination. For now, this is just here for status
5419         # reporting
5420         self._set_migration_status(migration, 'preparing')
5421 
5422         got_migrate_data_object = isinstance(migrate_data,
5423                                              migrate_data_obj.LiveMigrateData)
5424         if not got_migrate_data_object:
5425             migrate_data = \
5426                 migrate_data_obj.LiveMigrateData.detect_implementation(
5427                     migrate_data)
5428 
5429         try:
5430             if ('block_migration' in migrate_data and
5431                     migrate_data.block_migration):
5432                 block_device_info = self._get_instance_block_device_info(
5433                     context, instance)
5434                 disk = self.driver.get_instance_disk_info(
5435                     instance, block_device_info=block_device_info)
5436             else:
5437                 disk = None
5438 
5439             migrate_data = self.compute_rpcapi.pre_live_migration(
5440                 context, instance,
5441                 block_migration, disk, dest, migrate_data)
5442         except Exception:
5443             with excutils.save_and_reraise_exception():
5444                 LOG.exception('Pre live migration failed at %s',
5445                               dest, instance=instance)
5446                 self._set_migration_status(migration, 'error')
5447                 self._rollback_live_migration(context, instance, dest,
5448                                               migrate_data)
5449 
5450         self._set_migration_status(migration, 'running')
5451 
5452         if migrate_data:
5453             migrate_data.migration = migration
5454         LOG.debug('live_migration data is %s', migrate_data)
5455         try:
5456             self.driver.live_migration(context, instance, dest,
5457                                        self._post_live_migration,
5458                                        self._rollback_live_migration,
5459                                        block_migration, migrate_data)
5460         except Exception:
5461             LOG.exception('Live migration failed.', instance=instance)
5462             with excutils.save_and_reraise_exception():
5463                 # Put instance and migration into error state,
5464                 # as its almost certainly too late to rollback
5465                 self._set_migration_status(migration, 'error')
5466                 # first refresh instance as it may have got updated by
5467                 # post_live_migration_at_destination
5468                 instance.refresh()
5469                 self._set_instance_obj_error_state(context, instance,
5470                                                    clean_task_state=True)
5471 
5472     @wrap_exception()
5473     @wrap_instance_event(prefix='compute')
5474     @wrap_instance_fault
5475     def live_migration(self, context, dest, instance, block_migration,
5476                        migration, migrate_data):
5477         """Executing live migration.
5478 
5479         :param context: security context
5480         :param dest: destination host
5481         :param instance: a nova.objects.instance.Instance object
5482         :param block_migration: if true, prepare for block migration
5483         :param migration: an nova.objects.Migration object
5484         :param migrate_data: implementation specific params
5485 
5486         """
5487         self._set_migration_status(migration, 'queued')
5488 
5489         def dispatch_live_migration(*args, **kwargs):
5490             with self._live_migration_semaphore:
5491                 self._do_live_migration(*args, **kwargs)
5492 
5493         # NOTE(danms): We spawn here to return the RPC worker thread back to
5494         # the pool. Since what follows could take a really long time, we don't
5495         # want to tie up RPC workers.
5496         utils.spawn_n(dispatch_live_migration,
5497                       context, dest, instance,
5498                       block_migration, migration,
5499                       migrate_data)
5500 
5501     # TODO(tdurakov): migration_id is used since 4.12 rpc api version
5502     # remove migration_id parameter when the compute RPC version
5503     # is bumped to 5.x.
5504     @wrap_exception()
5505     @wrap_instance_event(prefix='compute')
5506     @wrap_instance_fault
5507     def live_migration_force_complete(self, context, instance,
5508                                       migration_id=None):
5509         """Force live migration to complete.
5510 
5511         :param context: Security context
5512         :param instance: The instance that is being migrated
5513         :param migration_id: ID of ongoing migration; is currently not used,
5514         and isn't removed for backward compatibility
5515         """
5516 
5517         self._notify_about_instance_usage(
5518             context, instance, 'live.migration.force.complete.start')
5519         self.driver.live_migration_force_complete(instance)
5520         self._notify_about_instance_usage(
5521             context, instance, 'live.migration.force.complete.end')
5522 
5523     @wrap_exception()
5524     @wrap_instance_event(prefix='compute')
5525     @wrap_instance_fault
5526     def live_migration_abort(self, context, instance, migration_id):
5527         """Abort an in-progress live migration.
5528 
5529         :param context: Security context
5530         :param instance: The instance that is being migrated
5531         :param migration_id: ID of in-progress live migration
5532 
5533         """
5534         migration = objects.Migration.get_by_id(context, migration_id)
5535         if migration.status != 'running':
5536             raise exception.InvalidMigrationState(migration_id=migration_id,
5537                     instance_uuid=instance.uuid,
5538                     state=migration.status,
5539                     method='abort live migration')
5540 
5541         self._notify_about_instance_usage(
5542             context, instance, 'live.migration.abort.start')
5543         self.driver.live_migration_abort(instance)
5544         self._notify_about_instance_usage(
5545             context, instance, 'live.migration.abort.end')
5546 
5547     def _live_migration_cleanup_flags(self, migrate_data):
5548         """Determine whether disks or instance path need to be cleaned up after
5549         live migration (at source on success, at destination on rollback)
5550 
5551         Block migration needs empty image at destination host before migration
5552         starts, so if any failure occurs, any empty images has to be deleted.
5553 
5554         Also Volume backed live migration w/o shared storage needs to delete
5555         newly created instance-xxx dir on the destination as a part of its
5556         rollback process
5557 
5558         :param migrate_data: implementation specific data
5559         :returns: (bool, bool) -- do_cleanup, destroy_disks
5560         """
5561         # NOTE(pkoniszewski): block migration specific params are set inside
5562         # migrate_data objects for drivers that expose block live migration
5563         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
5564         # cleanup is not needed.
5565         is_shared_block_storage = True
5566         is_shared_instance_path = True
5567         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
5568             is_shared_block_storage = migrate_data.is_shared_block_storage
5569             is_shared_instance_path = migrate_data.is_shared_instance_path
5570         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
5571             is_shared_block_storage = not migrate_data.block_migration
5572             is_shared_instance_path = not migrate_data.block_migration
5573         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
5574             is_shared_instance_path = migrate_data.is_shared_instance_path
5575             is_shared_block_storage = migrate_data.is_shared_instance_path
5576 
5577         # No instance booting at source host, but instance dir
5578         # must be deleted for preparing next block migration
5579         # must be deleted for preparing next live migration w/o shared storage
5580         do_cleanup = not is_shared_instance_path
5581         destroy_disks = not is_shared_block_storage
5582 
5583         return (do_cleanup, destroy_disks)
5584 
5585     @wrap_exception()
5586     @wrap_instance_fault
5587     def _post_live_migration(self, ctxt, instance,
5588                             dest, block_migration=False, migrate_data=None):
5589         """Post operations for live migration.
5590 
5591         This method is called from live_migration
5592         and mainly updating database record.
5593 
5594         :param ctxt: security context
5595         :param instance: instance dict
5596         :param dest: destination host
5597         :param block_migration: if true, prepare for block migration
5598         :param migrate_data: if not None, it is a dict which has data
5599         required for live migration without shared storage
5600 
5601         """
5602         LOG.info('_post_live_migration() is started..',
5603                  instance=instance)
5604 
5605         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5606                 ctxt, instance.uuid)
5607 
5608         # Cleanup source host post live-migration
5609         block_device_info = self._get_instance_block_device_info(
5610                             ctxt, instance, bdms=bdms)
5611         self.driver.post_live_migration(ctxt, instance, block_device_info,
5612                                         migrate_data)
5613 
5614         # Detaching volumes.
5615         connector = self.driver.get_volume_connector(instance)
5616         for bdm in bdms:
5617             # NOTE(vish): We don't want to actually mark the volume
5618             #             detached, or delete the bdm, just remove the
5619             #             connection from this host.
5620 
5621             # remove the volume connection without detaching from hypervisor
5622             # because the instance is not running anymore on the current host
5623             if bdm.is_volume:
5624                 self.volume_api.terminate_connection(ctxt, bdm.volume_id,
5625                                                      connector)
5626 
5627         # Releasing vlan.
5628         # (not necessary in current implementation?)
5629 
5630         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
5631 
5632         self._notify_about_instance_usage(ctxt, instance,
5633                                           "live_migration._post.start",
5634                                           network_info=network_info)
5635         # Releasing security group ingress rule.
5636         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
5637                   instance=instance)
5638         self.driver.unfilter_instance(instance,
5639                                       network_info)
5640 
5641         migration = {'source_compute': self.host,
5642                      'dest_compute': dest, }
5643         self.network_api.migrate_instance_start(ctxt,
5644                                                 instance,
5645                                                 migration)
5646 
5647         destroy_vifs = False
5648         try:
5649             self.driver.post_live_migration_at_source(ctxt, instance,
5650                                                       network_info)
5651         except NotImplementedError as ex:
5652             LOG.debug(ex, instance=instance)
5653             # For all hypervisors other than libvirt, there is a possibility
5654             # they are unplugging networks from source node in the cleanup
5655             # method
5656             destroy_vifs = True
5657 
5658         # Define domain at destination host, without doing it,
5659         # pause/suspend/terminate do not work.
5660         post_at_dest_success = True
5661         try:
5662             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
5663                     instance, block_migration, dest)
5664         except Exception as error:
5665             post_at_dest_success = False
5666             # We don't want to break _post_live_migration() if
5667             # post_live_migration_at_destination() fails as it should never
5668             # affect cleaning up source node.
5669             LOG.exception("Post live migration at destination %s failed",
5670                           dest, instance=instance, error=error)
5671 
5672         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5673                 migrate_data)
5674 
5675         if do_cleanup:
5676             LOG.debug('Calling driver.cleanup from _post_live_migration',
5677                       instance=instance)
5678             self.driver.cleanup(ctxt, instance, network_info,
5679                                 destroy_disks=destroy_disks,
5680                                 migrate_data=migrate_data,
5681                                 destroy_vifs=destroy_vifs)
5682 
5683         self.instance_events.clear_events_for_instance(instance)
5684 
5685         # NOTE(timello): make sure we update available resources on source
5686         # host even before next periodic task.
5687         self.update_available_resource(ctxt)
5688 
5689         self._update_scheduler_instance_info(ctxt, instance)
5690         self._notify_about_instance_usage(ctxt, instance,
5691                                           "live_migration._post.end",
5692                                           network_info=network_info)
5693         if post_at_dest_success:
5694             LOG.info('Migrating instance to %s finished successfully.',
5695                      dest, instance=instance)
5696 
5697         if migrate_data and migrate_data.obj_attr_is_set('migration'):
5698             migrate_data.migration.status = 'completed'
5699             migrate_data.migration.save()
5700 
5701     def _consoles_enabled(self):
5702         """Returns whether a console is enable."""
5703         return (CONF.vnc.enabled or CONF.spice.enabled or
5704                 CONF.rdp.enabled or CONF.serial_console.enabled or
5705                 CONF.mks.enabled)
5706 
5707     @wrap_exception()
5708     @wrap_instance_event(prefix='compute')
5709     @wrap_instance_fault
5710     def post_live_migration_at_destination(self, context, instance,
5711                                            block_migration):
5712         """Post operations for live migration .
5713 
5714         :param context: security context
5715         :param instance: Instance dict
5716         :param block_migration: if true, prepare for block migration
5717 
5718         """
5719         LOG.info('Post operation of migration started',
5720                  instance=instance)
5721 
5722         # NOTE(tr3buchet): setup networks on destination host
5723         #                  this is called a second time because
5724         #                  multi_host does not create the bridge in
5725         #                  plug_vifs
5726         self.network_api.setup_networks_on_host(context, instance,
5727                                                          self.host)
5728         migration = {'source_compute': instance.host,
5729                      'dest_compute': self.host, }
5730         self.network_api.migrate_instance_finish(context,
5731                                                  instance,
5732                                                  migration)
5733 
5734         network_info = self.network_api.get_instance_nw_info(context, instance)
5735         self._notify_about_instance_usage(
5736                      context, instance, "live_migration.post.dest.start",
5737                      network_info=network_info)
5738         block_device_info = self._get_instance_block_device_info(context,
5739                                                                  instance)
5740 
5741         try:
5742             self.driver.post_live_migration_at_destination(
5743                 context, instance, network_info, block_migration,
5744                 block_device_info)
5745         except Exception:
5746             with excutils.save_and_reraise_exception():
5747                 instance.vm_state = vm_states.ERROR
5748                 LOG.error('Unexpected error during post live migration at '
5749                           'destination host.', instance=instance)
5750         finally:
5751             # Restore instance state and update host
5752             current_power_state = self._get_power_state(context, instance)
5753             node_name = None
5754             prev_host = instance.host
5755             try:
5756                 compute_node = self._get_compute_info(context, self.host)
5757                 node_name = compute_node.hypervisor_hostname
5758             except exception.ComputeHostNotFound:
5759                 LOG.exception('Failed to get compute_info for %s', self.host)
5760             finally:
5761                 instance.host = self.host
5762                 instance.power_state = current_power_state
5763                 instance.task_state = None
5764                 instance.node = node_name
5765                 instance.progress = 0
5766                 instance.save(expected_task_state=task_states.MIGRATING)
5767 
5768         # NOTE(tr3buchet): tear down networks on source host
5769         self.network_api.setup_networks_on_host(context, instance,
5770                                                 prev_host, teardown=True)
5771         # NOTE(vish): this is necessary to update dhcp
5772         self.network_api.setup_networks_on_host(context, instance, self.host)
5773         self._notify_about_instance_usage(
5774                      context, instance, "live_migration.post.dest.end",
5775                      network_info=network_info)
5776 
5777     @wrap_exception()
5778     @wrap_instance_fault
5779     def _rollback_live_migration(self, context, instance,
5780                                  dest, migrate_data=None,
5781                                  migration_status='error'):
5782         """Recovers Instance/volume state from migrating -> running.
5783 
5784         :param context: security context
5785         :param instance: nova.objects.instance.Instance object
5786         :param dest:
5787             This method is called from live migration src host.
5788             This param specifies destination host.
5789         :param migrate_data:
5790             if not none, contains implementation specific data.
5791         :param migration_status:
5792             Contains the status we want to set for the migration object
5793 
5794         """
5795         instance.task_state = None
5796         instance.progress = 0
5797         instance.save(expected_task_state=[task_states.MIGRATING])
5798 
5799         # TODO(tdurakov): remove dict to object conversion once RPC API version
5800         # is bumped to 5.x
5801         if isinstance(migrate_data, dict):
5802             migration = migrate_data.pop('migration', None)
5803             migrate_data = \
5804                 migrate_data_obj.LiveMigrateData.detect_implementation(
5805                     migrate_data)
5806         elif (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
5807               migrate_data.obj_attr_is_set('migration')):
5808             migration = migrate_data.migration
5809         else:
5810             migration = None
5811 
5812         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
5813         self.network_api.setup_networks_on_host(context, instance, self.host)
5814 
5815         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5816                 context, instance.uuid)
5817         for bdm in bdms:
5818             if bdm.is_volume:
5819                 self.compute_rpcapi.remove_volume_connection(
5820                         context, instance, bdm.volume_id, dest)
5821 
5822         self._notify_about_instance_usage(context, instance,
5823                                           "live_migration._rollback.start")
5824         compute_utils.notify_about_instance_action(context, instance,
5825                 self.host,
5826                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
5827                 phase=fields.NotificationPhase.START)
5828 
5829         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5830                 migrate_data)
5831 
5832         if do_cleanup:
5833             self.compute_rpcapi.rollback_live_migration_at_destination(
5834                     context, instance, dest, destroy_disks=destroy_disks,
5835                     migrate_data=migrate_data)
5836 
5837         self._notify_about_instance_usage(context, instance,
5838                                           "live_migration._rollback.end")
5839         compute_utils.notify_about_instance_action(context, instance,
5840                 self.host,
5841                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
5842                 phase=fields.NotificationPhase.END)
5843 
5844         self._set_migration_status(migration, migration_status)
5845 
5846     @wrap_exception()
5847     @wrap_instance_event(prefix='compute')
5848     @wrap_instance_fault
5849     def rollback_live_migration_at_destination(self, context, instance,
5850                                                destroy_disks,
5851                                                migrate_data):
5852         """Cleaning up image directory that is created pre_live_migration.
5853 
5854         :param context: security context
5855         :param instance: a nova.objects.instance.Instance object sent over rpc
5856         """
5857         network_info = self.network_api.get_instance_nw_info(context, instance)
5858         self._notify_about_instance_usage(
5859                       context, instance, "live_migration.rollback.dest.start",
5860                       network_info=network_info)
5861         try:
5862             # NOTE(tr3buchet): tear down networks on destination host
5863             self.network_api.setup_networks_on_host(context, instance,
5864                                                     self.host, teardown=True)
5865         except Exception:
5866             with excutils.save_and_reraise_exception():
5867                 # NOTE(tdurakov): even if teardown networks fails driver
5868                 # should try to rollback live migration on destination.
5869                 LOG.exception('An error occurred while deallocating network.',
5870                               instance=instance)
5871         finally:
5872             # always run this even if setup_networks_on_host fails
5873             # NOTE(vish): The mapping is passed in so the driver can disconnect
5874             #             from remote volumes if necessary
5875             block_device_info = self._get_instance_block_device_info(context,
5876                                                                      instance)
5877             # TODO(tdurakov): remove dict to object conversion once RPC API
5878             # version is bumped to 5.x
5879             if isinstance(migrate_data, dict):
5880                 migrate_data = \
5881                     migrate_data_obj.LiveMigrateData.detect_implementation(
5882                         migrate_data)
5883             self.driver.rollback_live_migration_at_destination(
5884                 context, instance, network_info, block_device_info,
5885                 destroy_disks=destroy_disks, migrate_data=migrate_data)
5886 
5887         self._notify_about_instance_usage(
5888                         context, instance, "live_migration.rollback.dest.end",
5889                         network_info=network_info)
5890 
5891     @periodic_task.periodic_task(
5892         spacing=CONF.heal_instance_info_cache_interval)
5893     def _heal_instance_info_cache(self, context):
5894         """Called periodically.  On every call, try to update the
5895         info_cache's network information for another instance by
5896         calling to the network manager.
5897 
5898         This is implemented by keeping a cache of uuids of instances
5899         that live on this host.  On each call, we pop one off of a
5900         list, pull the DB record, and try the call to the network API.
5901         If anything errors don't fail, as it's possible the instance
5902         has been deleted, etc.
5903         """
5904         heal_interval = CONF.heal_instance_info_cache_interval
5905         if not heal_interval:
5906             return
5907 
5908         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
5909         instance = None
5910 
5911         LOG.debug('Starting heal instance info cache')
5912 
5913         if not instance_uuids:
5914             # The list of instances to heal is empty so rebuild it
5915             LOG.debug('Rebuilding the list of instances to heal')
5916             db_instances = objects.InstanceList.get_by_host(
5917                 context, self.host, expected_attrs=[], use_slave=True)
5918             for inst in db_instances:
5919                 # We don't want to refresh the cache for instances
5920                 # which are building or deleting so don't put them
5921                 # in the list. If they are building they will get
5922                 # added to the list next time we build it.
5923                 if (inst.vm_state == vm_states.BUILDING):
5924                     LOG.debug('Skipping network cache update for instance '
5925                               'because it is Building.', instance=inst)
5926                     continue
5927                 if (inst.task_state == task_states.DELETING):
5928                     LOG.debug('Skipping network cache update for instance '
5929                               'because it is being deleted.', instance=inst)
5930                     continue
5931 
5932                 if not instance:
5933                     # Save the first one we find so we don't
5934                     # have to get it again
5935                     instance = inst
5936                 else:
5937                     instance_uuids.append(inst['uuid'])
5938 
5939             self._instance_uuids_to_heal = instance_uuids
5940         else:
5941             # Find the next valid instance on the list
5942             while instance_uuids:
5943                 try:
5944                     inst = objects.Instance.get_by_uuid(
5945                             context, instance_uuids.pop(0),
5946                             expected_attrs=['system_metadata', 'info_cache',
5947                                             'flavor'],
5948                             use_slave=True)
5949                 except exception.InstanceNotFound:
5950                     # Instance is gone.  Try to grab another.
5951                     continue
5952 
5953                 # Check the instance hasn't been migrated
5954                 if inst.host != self.host:
5955                     LOG.debug('Skipping network cache update for instance '
5956                               'because it has been migrated to another '
5957                               'host.', instance=inst)
5958                 # Check the instance isn't being deleting
5959                 elif inst.task_state == task_states.DELETING:
5960                     LOG.debug('Skipping network cache update for instance '
5961                               'because it is being deleted.', instance=inst)
5962                 else:
5963                     instance = inst
5964                     break
5965 
5966         if instance:
5967             # We have an instance now to refresh
5968             try:
5969                 # Call to network API to get instance info.. this will
5970                 # force an update to the instance's info_cache
5971                 self.network_api.get_instance_nw_info(context, instance)
5972                 LOG.debug('Updated the network info_cache for instance',
5973                           instance=instance)
5974             except exception.InstanceNotFound:
5975                 # Instance is gone.
5976                 LOG.debug('Instance no longer exists. Unable to refresh',
5977                           instance=instance)
5978                 return
5979             except exception.InstanceInfoCacheNotFound:
5980                 # InstanceInfoCache is gone.
5981                 LOG.debug('InstanceInfoCache no longer exists. '
5982                           'Unable to refresh', instance=instance)
5983             except Exception:
5984                 LOG.error('An error occurred while refreshing the network '
5985                           'cache.', instance=instance, exc_info=True)
5986         else:
5987             LOG.debug("Didn't find any instances for network info cache "
5988                       "update.")
5989 
5990     @periodic_task.periodic_task
5991     def _poll_rebooting_instances(self, context):
5992         if CONF.reboot_timeout > 0:
5993             filters = {'task_state':
5994                        [task_states.REBOOTING,
5995                         task_states.REBOOT_STARTED,
5996                         task_states.REBOOT_PENDING],
5997                        'host': self.host}
5998             rebooting = objects.InstanceList.get_by_filters(
5999                 context, filters, expected_attrs=[], use_slave=True)
6000 
6001             to_poll = []
6002             for instance in rebooting:
6003                 if timeutils.is_older_than(instance.updated_at,
6004                                            CONF.reboot_timeout):
6005                     to_poll.append(instance)
6006 
6007             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
6008 
6009     @periodic_task.periodic_task
6010     def _poll_rescued_instances(self, context):
6011         if CONF.rescue_timeout > 0:
6012             filters = {'vm_state': vm_states.RESCUED,
6013                        'host': self.host}
6014             rescued_instances = objects.InstanceList.get_by_filters(
6015                 context, filters, expected_attrs=["system_metadata"],
6016                 use_slave=True)
6017 
6018             to_unrescue = []
6019             for instance in rescued_instances:
6020                 if timeutils.is_older_than(instance.launched_at,
6021                                            CONF.rescue_timeout):
6022                     to_unrescue.append(instance)
6023 
6024             for instance in to_unrescue:
6025                 self.compute_api.unrescue(context, instance)
6026 
6027     @periodic_task.periodic_task
6028     def _poll_unconfirmed_resizes(self, context):
6029         if CONF.resize_confirm_window == 0:
6030             return
6031 
6032         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
6033                 context, CONF.resize_confirm_window, self.host,
6034                 use_slave=True)
6035 
6036         migrations_info = dict(migration_count=len(migrations),
6037                 confirm_window=CONF.resize_confirm_window)
6038 
6039         if migrations_info["migration_count"] > 0:
6040             LOG.info("Found %(migration_count)d unconfirmed migrations "
6041                      "older than %(confirm_window)d seconds",
6042                      migrations_info)
6043 
6044         def _set_migration_to_error(migration, reason, **kwargs):
6045             LOG.warning("Setting migration %(migration_id)s to error: "
6046                         "%(reason)s",
6047                         {'migration_id': migration['id'], 'reason': reason},
6048                         **kwargs)
6049             migration.status = 'error'
6050             with migration.obj_as_admin():
6051                 migration.save()
6052 
6053         for migration in migrations:
6054             instance_uuid = migration.instance_uuid
6055             LOG.info("Automatically confirming migration "
6056                      "%(migration_id)s for instance %(instance_uuid)s",
6057                      {'migration_id': migration.id,
6058                       'instance_uuid': instance_uuid})
6059             expected_attrs = ['metadata', 'system_metadata']
6060             try:
6061                 instance = objects.Instance.get_by_uuid(context,
6062                             instance_uuid, expected_attrs=expected_attrs,
6063                             use_slave=True)
6064             except exception.InstanceNotFound:
6065                 reason = (_("Instance %s not found") %
6066                           instance_uuid)
6067                 _set_migration_to_error(migration, reason)
6068                 continue
6069             if instance.vm_state == vm_states.ERROR:
6070                 reason = _("In ERROR state")
6071                 _set_migration_to_error(migration, reason,
6072                                         instance=instance)
6073                 continue
6074             # race condition: The instance in DELETING state should not be
6075             # set the migration state to error, otherwise the instance in
6076             # to be deleted which is in RESIZED state
6077             # will not be able to confirm resize
6078             if instance.task_state in [task_states.DELETING,
6079                                        task_states.SOFT_DELETING]:
6080                 msg = ("Instance being deleted or soft deleted during resize "
6081                        "confirmation. Skipping.")
6082                 LOG.debug(msg, instance=instance)
6083                 continue
6084 
6085             # race condition: This condition is hit when this method is
6086             # called between the save of the migration record with a status of
6087             # finished and the save of the instance object with a state of
6088             # RESIZED. The migration record should not be set to error.
6089             if instance.task_state == task_states.RESIZE_FINISH:
6090                 msg = ("Instance still resizing during resize "
6091                        "confirmation. Skipping.")
6092                 LOG.debug(msg, instance=instance)
6093                 continue
6094 
6095             vm_state = instance.vm_state
6096             task_state = instance.task_state
6097             if vm_state != vm_states.RESIZED or task_state is not None:
6098                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
6099                            "RESIZED/None") %
6100                           {'vm_state': vm_state,
6101                            'task_state': task_state})
6102                 _set_migration_to_error(migration, reason,
6103                                         instance=instance)
6104                 continue
6105             try:
6106                 self.compute_api.confirm_resize(context, instance,
6107                                                 migration=migration)
6108             except Exception as e:
6109                 LOG.info("Error auto-confirming resize: %s. "
6110                          "Will retry later.", e, instance=instance)
6111 
6112     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
6113     def _poll_shelved_instances(self, context):
6114 
6115         if CONF.shelved_offload_time <= 0:
6116             return
6117 
6118         filters = {'vm_state': vm_states.SHELVED,
6119                    'task_state': None,
6120                    'host': self.host}
6121         shelved_instances = objects.InstanceList.get_by_filters(
6122             context, filters=filters, expected_attrs=['system_metadata'],
6123             use_slave=True)
6124 
6125         to_gc = []
6126         for instance in shelved_instances:
6127             sys_meta = instance.system_metadata
6128             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
6129             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
6130                 to_gc.append(instance)
6131 
6132         for instance in to_gc:
6133             try:
6134                 instance.task_state = task_states.SHELVING_OFFLOADING
6135                 instance.save(expected_task_state=(None,))
6136                 self.shelve_offload_instance(context, instance,
6137                                              clean_shutdown=False)
6138             except Exception:
6139                 LOG.exception('Periodic task failed to offload instance.',
6140                               instance=instance)
6141 
6142     @periodic_task.periodic_task
6143     def _instance_usage_audit(self, context):
6144         if not CONF.instance_usage_audit:
6145             return
6146 
6147         begin, end = utils.last_completed_audit_period()
6148         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
6149                                self.host):
6150             return
6151 
6152         instances = objects.InstanceList.get_active_by_window_joined(
6153             context, begin, end, host=self.host,
6154             expected_attrs=['system_metadata', 'info_cache', 'metadata',
6155                             'flavor'],
6156             use_slave=True)
6157         num_instances = len(instances)
6158         errors = 0
6159         successes = 0
6160         LOG.info("Running instance usage audit for host %(host)s "
6161                  "from %(begin_time)s to %(end_time)s. "
6162                  "%(number_instances)s instances.",
6163                  {'host': self.host,
6164                   'begin_time': begin,
6165                   'end_time': end,
6166                   'number_instances': num_instances})
6167         start_time = time.time()
6168         task_log = objects.TaskLog(context)
6169         task_log.task_name = 'instance_usage_audit'
6170         task_log.period_beginning = begin
6171         task_log.period_ending = end
6172         task_log.host = self.host
6173         task_log.task_items = num_instances
6174         task_log.message = 'Instance usage audit started...'
6175         task_log.begin_task()
6176         for instance in instances:
6177             try:
6178                 compute_utils.notify_usage_exists(
6179                     self.notifier, context, instance,
6180                     ignore_missing_network_data=False)
6181                 successes += 1
6182             except Exception:
6183                 LOG.exception('Failed to generate usage '
6184                               'audit for instance '
6185                               'on host %s', self.host,
6186                               instance=instance)
6187                 errors += 1
6188         task_log.errors = errors
6189         task_log.message = (
6190             'Instance usage audit ran for host %s, %s instances in %s seconds.'
6191             % (self.host, num_instances, time.time() - start_time))
6192         task_log.end_task()
6193 
6194     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
6195     def _poll_bandwidth_usage(self, context):
6196 
6197         if not self._bw_usage_supported:
6198             return
6199 
6200         prev_time, start_time = utils.last_completed_audit_period()
6201 
6202         curr_time = time.time()
6203         if (curr_time - self._last_bw_usage_poll >
6204                 CONF.bandwidth_poll_interval):
6205             self._last_bw_usage_poll = curr_time
6206             LOG.info("Updating bandwidth usage cache")
6207             cells_update_interval = CONF.cells.bandwidth_update_interval
6208             if (cells_update_interval > 0 and
6209                    curr_time - self._last_bw_usage_cell_update >
6210                            cells_update_interval):
6211                 self._last_bw_usage_cell_update = curr_time
6212                 update_cells = True
6213             else:
6214                 update_cells = False
6215 
6216             instances = objects.InstanceList.get_by_host(context,
6217                                                               self.host,
6218                                                               use_slave=True)
6219             try:
6220                 bw_counters = self.driver.get_all_bw_counters(instances)
6221             except NotImplementedError:
6222                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
6223                 # implemented yet.  If they don't it doesn't break anything,
6224                 # they just don't get the info in the usage events.
6225                 # NOTE(PhilDay): Record that its not supported so we can
6226                 # skip fast on future calls rather than waste effort getting
6227                 # the list of instances.
6228                 LOG.info("Bandwidth usage not supported by hypervisor.")
6229                 self._bw_usage_supported = False
6230                 return
6231 
6232             refreshed = timeutils.utcnow()
6233             for bw_ctr in bw_counters:
6234                 # Allow switching of greenthreads between queries.
6235                 greenthread.sleep(0)
6236                 bw_in = 0
6237                 bw_out = 0
6238                 last_ctr_in = None
6239                 last_ctr_out = None
6240                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6241                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6242                     start_period=start_time, use_slave=True)
6243                 if usage:
6244                     bw_in = usage.bw_in
6245                     bw_out = usage.bw_out
6246                     last_ctr_in = usage.last_ctr_in
6247                     last_ctr_out = usage.last_ctr_out
6248                 else:
6249                     usage = (objects.BandwidthUsage.
6250                              get_by_instance_uuid_and_mac(
6251                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6252                         start_period=prev_time, use_slave=True))
6253                     if usage:
6254                         last_ctr_in = usage.last_ctr_in
6255                         last_ctr_out = usage.last_ctr_out
6256 
6257                 if last_ctr_in is not None:
6258                     if bw_ctr['bw_in'] < last_ctr_in:
6259                         # counter rollover
6260                         bw_in += bw_ctr['bw_in']
6261                     else:
6262                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6263 
6264                 if last_ctr_out is not None:
6265                     if bw_ctr['bw_out'] < last_ctr_out:
6266                         # counter rollover
6267                         bw_out += bw_ctr['bw_out']
6268                     else:
6269                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6270 
6271                 objects.BandwidthUsage(context=context).create(
6272                                               bw_ctr['uuid'],
6273                                               bw_ctr['mac_address'],
6274                                               bw_in,
6275                                               bw_out,
6276                                               bw_ctr['bw_in'],
6277                                               bw_ctr['bw_out'],
6278                                               start_period=start_time,
6279                                               last_refreshed=refreshed,
6280                                               update_cells=update_cells)
6281 
6282     def _get_host_volume_bdms(self, context, use_slave=False):
6283         """Return all block device mappings on a compute host."""
6284         compute_host_bdms = []
6285         instances = objects.InstanceList.get_by_host(context, self.host,
6286             use_slave=use_slave)
6287         for instance in instances:
6288             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6289                     context, instance.uuid, use_slave=use_slave)
6290             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6291             compute_host_bdms.append(dict(instance=instance,
6292                                           instance_bdms=instance_bdms))
6293 
6294         return compute_host_bdms
6295 
6296     def _update_volume_usage_cache(self, context, vol_usages):
6297         """Updates the volume usage cache table with a list of stats."""
6298         for usage in vol_usages:
6299             # Allow switching of greenthreads between queries.
6300             greenthread.sleep(0)
6301             vol_usage = objects.VolumeUsage(context)
6302             vol_usage.volume_id = usage['volume']
6303             vol_usage.instance_uuid = usage['instance'].uuid
6304             vol_usage.project_id = usage['instance'].project_id
6305             vol_usage.user_id = usage['instance'].user_id
6306             vol_usage.availability_zone = usage['instance'].availability_zone
6307             vol_usage.curr_reads = usage['rd_req']
6308             vol_usage.curr_read_bytes = usage['rd_bytes']
6309             vol_usage.curr_writes = usage['wr_req']
6310             vol_usage.curr_write_bytes = usage['wr_bytes']
6311             vol_usage.save()
6312             self.notifier.info(context, 'volume.usage',
6313                                compute_utils.usage_volume_info(vol_usage))
6314 
6315     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
6316     def _poll_volume_usage(self, context):
6317         if CONF.volume_usage_poll_interval == 0:
6318             return
6319 
6320         compute_host_bdms = self._get_host_volume_bdms(context,
6321                                                        use_slave=True)
6322         if not compute_host_bdms:
6323             return
6324 
6325         LOG.debug("Updating volume usage cache")
6326         try:
6327             vol_usages = self.driver.get_all_volume_usage(context,
6328                                                           compute_host_bdms)
6329         except NotImplementedError:
6330             return
6331 
6332         self._update_volume_usage_cache(context, vol_usages)
6333 
6334     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
6335                                  run_immediately=True)
6336     def _sync_power_states(self, context):
6337         """Align power states between the database and the hypervisor.
6338 
6339         To sync power state data we make a DB call to get the number of
6340         virtual machines known by the hypervisor and if the number matches the
6341         number of virtual machines known by the database, we proceed in a lazy
6342         loop, one database record at a time, checking if the hypervisor has the
6343         same power state as is in the database.
6344         """
6345         db_instances = objects.InstanceList.get_by_host(context, self.host,
6346                                                         expected_attrs=[],
6347                                                         use_slave=True)
6348 
6349         num_vm_instances = self.driver.get_num_instances()
6350         num_db_instances = len(db_instances)
6351 
6352         if num_vm_instances != num_db_instances:
6353             LOG.warning("While synchronizing instance power states, found "
6354                         "%(num_db_instances)s instances in the database "
6355                         "and %(num_vm_instances)s instances on the "
6356                         "hypervisor.",
6357                         {'num_db_instances': num_db_instances,
6358                          'num_vm_instances': num_vm_instances})
6359 
6360         def _sync(db_instance):
6361             # NOTE(melwitt): This must be synchronized as we query state from
6362             #                two separate sources, the driver and the database.
6363             #                They are set (in stop_instance) and read, in sync.
6364             @utils.synchronized(db_instance.uuid)
6365             def query_driver_power_state_and_sync():
6366                 self._query_driver_power_state_and_sync(context, db_instance)
6367 
6368             try:
6369                 query_driver_power_state_and_sync()
6370             except Exception:
6371                 LOG.exception("Periodic sync_power_state task had an "
6372                               "error while processing an instance.",
6373                               instance=db_instance)
6374 
6375             self._syncs_in_progress.pop(db_instance.uuid)
6376 
6377         for db_instance in db_instances:
6378             # process syncs asynchronously - don't want instance locking to
6379             # block entire periodic task thread
6380             uuid = db_instance.uuid
6381             if uuid in self._syncs_in_progress:
6382                 LOG.debug('Sync already in progress for %s', uuid)
6383             else:
6384                 LOG.debug('Triggering sync for uuid %s', uuid)
6385                 self._syncs_in_progress[uuid] = True
6386                 self._sync_power_pool.spawn_n(_sync, db_instance)
6387 
6388     def _query_driver_power_state_and_sync(self, context, db_instance):
6389         if db_instance.task_state is not None:
6390             LOG.info("During sync_power_state the instance has a "
6391                      "pending task (%(task)s). Skip.",
6392                      {'task': db_instance.task_state}, instance=db_instance)
6393             return
6394         # No pending tasks. Now try to figure out the real vm_power_state.
6395         try:
6396             vm_instance = self.driver.get_info(db_instance)
6397             vm_power_state = vm_instance.state
6398         except exception.InstanceNotFound:
6399             vm_power_state = power_state.NOSTATE
6400         # Note(maoy): the above get_info call might take a long time,
6401         # for example, because of a broken libvirt driver.
6402         try:
6403             self._sync_instance_power_state(context,
6404                                             db_instance,
6405                                             vm_power_state,
6406                                             use_slave=True)
6407         except exception.InstanceNotFound:
6408             # NOTE(hanlind): If the instance gets deleted during sync,
6409             # silently ignore.
6410             pass
6411 
6412     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
6413                                    use_slave=False):
6414         """Align instance power state between the database and hypervisor.
6415 
6416         If the instance is not found on the hypervisor, but is in the database,
6417         then a stop() API will be called on the instance.
6418         """
6419 
6420         # We re-query the DB to get the latest instance info to minimize
6421         # (not eliminate) race condition.
6422         db_instance.refresh(use_slave=use_slave)
6423         db_power_state = db_instance.power_state
6424         vm_state = db_instance.vm_state
6425 
6426         if self.host != db_instance.host:
6427             # on the sending end of nova-compute _sync_power_state
6428             # may have yielded to the greenthread performing a live
6429             # migration; this in turn has changed the resident-host
6430             # for the VM; However, the instance is still active, it
6431             # is just in the process of migrating to another host.
6432             # This implies that the compute source must relinquish
6433             # control to the compute destination.
6434             LOG.info("During the sync_power process the "
6435                      "instance has moved from "
6436                      "host %(src)s to host %(dst)s",
6437                      {'src': db_instance.host,
6438                       'dst': self.host},
6439                      instance=db_instance)
6440             return
6441         elif db_instance.task_state is not None:
6442             # on the receiving end of nova-compute, it could happen
6443             # that the DB instance already report the new resident
6444             # but the actual VM has not showed up on the hypervisor
6445             # yet. In this case, let's allow the loop to continue
6446             # and run the state sync in a later round
6447             LOG.info("During sync_power_state the instance has a "
6448                      "pending task (%(task)s). Skip.",
6449                      {'task': db_instance.task_state},
6450                      instance=db_instance)
6451             return
6452 
6453         orig_db_power_state = db_power_state
6454         if vm_power_state != db_power_state:
6455             LOG.info('During _sync_instance_power_state the DB '
6456                      'power_state (%(db_power_state)s) does not match '
6457                      'the vm_power_state from the hypervisor '
6458                      '(%(vm_power_state)s). Updating power_state in the '
6459                      'DB to match the hypervisor.',
6460                      {'db_power_state': db_power_state,
6461                       'vm_power_state': vm_power_state},
6462                      instance=db_instance)
6463             # power_state is always updated from hypervisor to db
6464             db_instance.power_state = vm_power_state
6465             db_instance.save()
6466             db_power_state = vm_power_state
6467 
6468         # Note(maoy): Now resolve the discrepancy between vm_state and
6469         # vm_power_state. We go through all possible vm_states.
6470         if vm_state in (vm_states.BUILDING,
6471                         vm_states.RESCUED,
6472                         vm_states.RESIZED,
6473                         vm_states.SUSPENDED,
6474                         vm_states.ERROR):
6475             # TODO(maoy): we ignore these vm_state for now.
6476             pass
6477         elif vm_state == vm_states.ACTIVE:
6478             # The only rational power state should be RUNNING
6479             if vm_power_state in (power_state.SHUTDOWN,
6480                                   power_state.CRASHED):
6481                 LOG.warning("Instance shutdown by itself. Calling the "
6482                             "stop API. Current vm_state: %(vm_state)s, "
6483                             "current task_state: %(task_state)s, "
6484                             "original DB power_state: %(db_power_state)s, "
6485                             "current VM power_state: %(vm_power_state)s",
6486                             {'vm_state': vm_state,
6487                              'task_state': db_instance.task_state,
6488                              'db_power_state': orig_db_power_state,
6489                              'vm_power_state': vm_power_state},
6490                             instance=db_instance)
6491                 try:
6492                     # Note(maoy): here we call the API instead of
6493                     # brutally updating the vm_state in the database
6494                     # to allow all the hooks and checks to be performed.
6495                     if db_instance.shutdown_terminate:
6496                         self.compute_api.delete(context, db_instance)
6497                     else:
6498                         self.compute_api.stop(context, db_instance)
6499                 except Exception:
6500                     # Note(maoy): there is no need to propagate the error
6501                     # because the same power_state will be retrieved next
6502                     # time and retried.
6503                     # For example, there might be another task scheduled.
6504                     LOG.exception("error during stop() in sync_power_state.",
6505                                   instance=db_instance)
6506             elif vm_power_state == power_state.SUSPENDED:
6507                 LOG.warning("Instance is suspended unexpectedly. Calling "
6508                             "the stop API.", instance=db_instance)
6509                 try:
6510                     self.compute_api.stop(context, db_instance)
6511                 except Exception:
6512                     LOG.exception("error during stop() in sync_power_state.",
6513                                   instance=db_instance)
6514             elif vm_power_state == power_state.PAUSED:
6515                 # Note(maoy): a VM may get into the paused state not only
6516                 # because the user request via API calls, but also
6517                 # due to (temporary) external instrumentations.
6518                 # Before the virt layer can reliably report the reason,
6519                 # we simply ignore the state discrepancy. In many cases,
6520                 # the VM state will go back to running after the external
6521                 # instrumentation is done. See bug 1097806 for details.
6522                 LOG.warning("Instance is paused unexpectedly. Ignore.",
6523                             instance=db_instance)
6524             elif vm_power_state == power_state.NOSTATE:
6525                 # Occasionally, depending on the status of the hypervisor,
6526                 # which could be restarting for example, an instance may
6527                 # not be found.  Therefore just log the condition.
6528                 LOG.warning("Instance is unexpectedly not found. Ignore.",
6529                             instance=db_instance)
6530         elif vm_state == vm_states.STOPPED:
6531             if vm_power_state not in (power_state.NOSTATE,
6532                                       power_state.SHUTDOWN,
6533                                       power_state.CRASHED):
6534                 LOG.warning("Instance is not stopped. Calling "
6535                             "the stop API. Current vm_state: %(vm_state)s,"
6536                             " current task_state: %(task_state)s, "
6537                             "original DB power_state: %(db_power_state)s, "
6538                             "current VM power_state: %(vm_power_state)s",
6539                             {'vm_state': vm_state,
6540                              'task_state': db_instance.task_state,
6541                              'db_power_state': orig_db_power_state,
6542                              'vm_power_state': vm_power_state},
6543                             instance=db_instance)
6544                 try:
6545                     # NOTE(russellb) Force the stop, because normally the
6546                     # compute API would not allow an attempt to stop a stopped
6547                     # instance.
6548                     self.compute_api.force_stop(context, db_instance)
6549                 except Exception:
6550                     LOG.exception("error during stop() in sync_power_state.",
6551                                   instance=db_instance)
6552         elif vm_state == vm_states.PAUSED:
6553             if vm_power_state in (power_state.SHUTDOWN,
6554                                   power_state.CRASHED):
6555                 LOG.warning("Paused instance shutdown by itself. Calling "
6556                             "the stop API.", instance=db_instance)
6557                 try:
6558                     self.compute_api.force_stop(context, db_instance)
6559                 except Exception:
6560                     LOG.exception("error during stop() in sync_power_state.",
6561                                   instance=db_instance)
6562         elif vm_state in (vm_states.SOFT_DELETED,
6563                           vm_states.DELETED):
6564             if vm_power_state not in (power_state.NOSTATE,
6565                                       power_state.SHUTDOWN):
6566                 # Note(maoy): this should be taken care of periodically in
6567                 # _cleanup_running_deleted_instances().
6568                 LOG.warning("Instance is not (soft-)deleted.",
6569                             instance=db_instance)
6570 
6571     @periodic_task.periodic_task
6572     def _reclaim_queued_deletes(self, context):
6573         """Reclaim instances that are queued for deletion."""
6574         interval = CONF.reclaim_instance_interval
6575         if interval <= 0:
6576             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
6577             return
6578 
6579         # TODO(comstud, jichenjc): Dummy quota object for now See bug 1296414.
6580         # The only case that the quota might be inconsistent is
6581         # the compute node died between set instance state to SOFT_DELETED
6582         # and quota commit to DB. When compute node starts again
6583         # it will have no idea the reservation is committed or not or even
6584         # expired, since it's a rare case, so marked as todo.
6585         quotas = objects.Quotas.from_reservations(context, None)
6586 
6587         filters = {'vm_state': vm_states.SOFT_DELETED,
6588                    'task_state': None,
6589                    'host': self.host}
6590         instances = objects.InstanceList.get_by_filters(
6591             context, filters,
6592             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
6593             use_slave=True)
6594         for instance in instances:
6595             if self._deleted_old_enough(instance, interval):
6596                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6597                         context, instance.uuid)
6598                 LOG.info('Reclaiming deleted instance', instance=instance)
6599                 try:
6600                     self._delete_instance(context, instance, bdms, quotas)
6601                 except Exception as e:
6602                     LOG.warning("Periodic reclaim failed to delete "
6603                                 "instance: %s",
6604                                 e, instance=instance)
6605 
6606     def update_available_resource_for_node(self, context, nodename):
6607 
6608         rt = self._get_resource_tracker()
6609         try:
6610             rt.update_available_resource(context, nodename)
6611         except exception.ComputeHostNotFound:
6612             # NOTE(comstud): We can get to this case if a node was
6613             # marked 'deleted' in the DB and then re-added with a
6614             # different auto-increment id. The cached resource
6615             # tracker tried to update a deleted record and failed.
6616             # Don't add this resource tracker to the new dict, so
6617             # that this will resolve itself on the next run.
6618             LOG.info("Compute node '%s' not found in "
6619                      "update_available_resource.", nodename)
6620             # TODO(jaypipes): Yes, this is inefficient to throw away all of the
6621             # compute nodes to force a rebuild, but this is only temporary
6622             # until Ironic baremetal node resource providers are tracked
6623             # properly in the report client and this is a tiny edge case
6624             # anyway.
6625             self._resource_tracker = None
6626             return
6627         except Exception:
6628             LOG.exception("Error updating resources for node %(node)s.",
6629                           {'node': nodename})
6630 
6631     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
6632     def update_available_resource(self, context, startup=False):
6633         """See driver.get_available_resource()
6634 
6635         Periodic process that keeps that the compute host's understanding of
6636         resource availability and usage in sync with the underlying hypervisor.
6637 
6638         :param context: security context
6639         :param startup: True if this is being called when the nova-compute
6640             service is starting, False otherwise.
6641         """
6642 
6643         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
6644                                                             use_slave=True,
6645                                                             startup=startup)
6646         nodenames = set(self.driver.get_available_nodes())
6647         for nodename in nodenames:
6648             self.update_available_resource_for_node(context, nodename)
6649 
6650         # Delete orphan compute node not reported by driver but still in db
6651         for cn in compute_nodes_in_db:
6652             if cn.hypervisor_hostname not in nodenames:
6653                 LOG.info("Deleting orphan compute node %(id)s "
6654                          "hypervisor host is %(hh)s, "
6655                          "nodes are %(nodes)s",
6656                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
6657                           'nodes': nodenames})
6658                 cn.destroy()
6659                 # Delete the corresponding resource provider in placement,
6660                 # along with any associated allocations and inventory.
6661                 # TODO(cdent): Move use of reportclient into resource tracker.
6662                 self.scheduler_client.reportclient.delete_resource_provider(
6663                     context, cn, cascade=True)
6664 
6665     def _get_compute_nodes_in_db(self, context, use_slave=False,
6666                                  startup=False):
6667         try:
6668             return objects.ComputeNodeList.get_all_by_host(context, self.host,
6669                                                            use_slave=use_slave)
6670         except exception.NotFound:
6671             if startup:
6672                 LOG.warning(
6673                     "No compute node record found for host %s. If this is "
6674                     "the first time this service is starting on this "
6675                     "host, then you can ignore this warning.", self.host)
6676             else:
6677                 LOG.error("No compute node record for host %s", self.host)
6678             return []
6679 
6680     @periodic_task.periodic_task(
6681         spacing=CONF.running_deleted_instance_poll_interval)
6682     def _cleanup_running_deleted_instances(self, context):
6683         """Cleanup any instances which are erroneously still running after
6684         having been deleted.
6685 
6686         Valid actions to take are:
6687 
6688             1. noop - do nothing
6689             2. log - log which instances are erroneously running
6690             3. reap - shutdown and cleanup any erroneously running instances
6691             4. shutdown - power off *and disable* any erroneously running
6692                           instances
6693 
6694         The use-case for this cleanup task is: for various reasons, it may be
6695         possible for the database to show an instance as deleted but for that
6696         instance to still be running on a host machine (see bug
6697         https://bugs.launchpad.net/nova/+bug/911366).
6698 
6699         This cleanup task is a cross-hypervisor utility for finding these
6700         zombied instances and either logging the discrepancy (likely what you
6701         should do in production), or automatically reaping the instances (more
6702         appropriate for dev environments).
6703         """
6704         action = CONF.running_deleted_instance_action
6705 
6706         if action == "noop":
6707             return
6708 
6709         # NOTE(sirp): admin contexts don't ordinarily return deleted records
6710         with utils.temporary_mutation(context, read_deleted="yes"):
6711             for instance in self._running_deleted_instances(context):
6712                 if action == "log":
6713                     LOG.warning("Detected instance with name label "
6714                                 "'%s' which is marked as "
6715                                 "DELETED but still present on host.",
6716                                 instance.name, instance=instance)
6717 
6718                 elif action == 'shutdown':
6719                     LOG.info("Powering off instance with name label "
6720                              "'%s' which is marked as "
6721                              "DELETED but still present on host.",
6722                              instance.name, instance=instance)
6723                     try:
6724                         try:
6725                             # disable starting the instance
6726                             self.driver.set_bootable(instance, False)
6727                         except NotImplementedError:
6728                             LOG.debug("set_bootable is not implemented "
6729                                       "for the current driver")
6730                         # and power it off
6731                         self.driver.power_off(instance)
6732                     except Exception:
6733                         LOG.warning("Failed to power off instance",
6734                                     instance=instance, exc_info=True)
6735 
6736                 elif action == 'reap':
6737                     LOG.info("Destroying instance with name label "
6738                              "'%s' which is marked as "
6739                              "DELETED but still present on host.",
6740                              instance.name, instance=instance)
6741                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6742                         context, instance.uuid, use_slave=True)
6743                     self.instance_events.clear_events_for_instance(instance)
6744                     try:
6745                         self._shutdown_instance(context, instance, bdms,
6746                                                 notify=False)
6747                         self._cleanup_volumes(context, instance.uuid, bdms)
6748                     except Exception as e:
6749                         LOG.warning("Periodic cleanup failed to delete "
6750                                     "instance: %s",
6751                                     e, instance=instance)
6752                 else:
6753                     raise Exception(_("Unrecognized value '%s'"
6754                                       " for CONF.running_deleted_"
6755                                       "instance_action") % action)
6756 
6757     def _running_deleted_instances(self, context):
6758         """Returns a list of instances nova thinks is deleted,
6759         but the hypervisor thinks is still running.
6760         """
6761         timeout = CONF.running_deleted_instance_timeout
6762         filters = {'deleted': True,
6763                    'soft_deleted': False,
6764                    'host': self.host}
6765         instances = self._get_instances_on_driver(context, filters)
6766         return [i for i in instances if self._deleted_old_enough(i, timeout)]
6767 
6768     def _deleted_old_enough(self, instance, timeout):
6769         deleted_at = instance.deleted_at
6770         if deleted_at:
6771             deleted_at = deleted_at.replace(tzinfo=None)
6772         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
6773 
6774     @contextlib.contextmanager
6775     def _error_out_instance_on_exception(self, context, instance,
6776                                          quotas=None,
6777                                          instance_state=vm_states.ACTIVE):
6778         instance_uuid = instance.uuid
6779         try:
6780             yield
6781         except NotImplementedError as error:
6782             with excutils.save_and_reraise_exception():
6783                 if quotas:
6784                     quotas.rollback()
6785                 LOG.info("Setting instance back to %(state)s after: "
6786                          "%(error)s",
6787                          {'state': instance_state, 'error': error},
6788                          instance_uuid=instance_uuid)
6789                 self._instance_update(context, instance,
6790                                       vm_state=instance_state,
6791                                       task_state=None)
6792         except exception.InstanceFaultRollback as error:
6793             if quotas:
6794                 quotas.rollback()
6795             LOG.info("Setting instance back to ACTIVE after: %s",
6796                      error, instance_uuid=instance_uuid)
6797             self._instance_update(context, instance,
6798                                   vm_state=vm_states.ACTIVE,
6799                                   task_state=None)
6800             raise error.inner_exception
6801         except Exception:
6802             LOG.exception('Setting instance vm_state to ERROR',
6803                           instance_uuid=instance_uuid)
6804             with excutils.save_and_reraise_exception():
6805                 if quotas:
6806                     quotas.rollback()
6807                 self._set_instance_obj_error_state(context, instance)
6808 
6809     @wrap_exception()
6810     def add_aggregate_host(self, context, aggregate, host, slave_info):
6811         """Notify hypervisor of change (for hypervisor pools)."""
6812         try:
6813             self.driver.add_to_aggregate(context, aggregate, host,
6814                                          slave_info=slave_info)
6815         except NotImplementedError:
6816             LOG.debug('Hypervisor driver does not support '
6817                       'add_aggregate_host')
6818         except exception.AggregateError:
6819             with excutils.save_and_reraise_exception():
6820                 self.driver.undo_aggregate_operation(
6821                                     context,
6822                                     aggregate.delete_host,
6823                                     aggregate, host)
6824 
6825     @wrap_exception()
6826     def remove_aggregate_host(self, context, host, slave_info, aggregate):
6827         """Removes a host from a physical hypervisor pool."""
6828         try:
6829             self.driver.remove_from_aggregate(context, aggregate, host,
6830                                               slave_info=slave_info)
6831         except NotImplementedError:
6832             LOG.debug('Hypervisor driver does not support '
6833                       'remove_aggregate_host')
6834         except (exception.AggregateError,
6835                 exception.InvalidAggregateAction) as e:
6836             with excutils.save_and_reraise_exception():
6837                 self.driver.undo_aggregate_operation(
6838                                     context,
6839                                     aggregate.add_host,
6840                                     aggregate, host,
6841                                     isinstance(e, exception.AggregateError))
6842 
6843     def _process_instance_event(self, instance, event):
6844         _event = self.instance_events.pop_instance_event(instance, event)
6845         if _event:
6846             LOG.debug('Processing event %(event)s',
6847                       {'event': event.key}, instance=instance)
6848             _event.send(event)
6849         else:
6850             LOG.warning('Received unexpected event %(event)s for instance',
6851                         {'event': event.key}, instance=instance)
6852 
6853     def _process_instance_vif_deleted_event(self, context, instance,
6854                                             deleted_vif_id):
6855         # If an attached port is deleted by neutron, it needs to
6856         # be detached from the instance.
6857         # And info cache needs to be updated.
6858         network_info = instance.info_cache.network_info
6859         for index, vif in enumerate(network_info):
6860             if vif['id'] == deleted_vif_id:
6861                 LOG.info('Neutron deleted interface %(intf)s; '
6862                          'detaching it from the instance and '
6863                          'deleting it from the info cache',
6864                          {'intf': vif['id']},
6865                          instance=instance)
6866                 del network_info[index]
6867                 base_net_api.update_instance_cache_with_nw_info(
6868                                  self.network_api, context,
6869                                  instance,
6870                                  nw_info=network_info)
6871                 try:
6872                     self.driver.detach_interface(context, instance, vif)
6873                 except NotImplementedError:
6874                     # Not all virt drivers support attach/detach of interfaces
6875                     # yet (like Ironic), so just ignore this.
6876                     pass
6877                 except exception.NovaException as ex:
6878                     LOG.warning("Detach interface failed, "
6879                                 "port_id=%(port_id)s, reason: %(msg)s",
6880                                 {'port_id': deleted_vif_id, 'msg': ex},
6881                                 instance=instance)
6882                 break
6883 
6884     @wrap_exception()
6885     def external_instance_event(self, context, instances, events):
6886         # NOTE(danms): Some event types are handled by the manager, such
6887         # as when we're asked to update the instance's info_cache. If it's
6888         # not one of those, look for some thread(s) waiting for the event and
6889         # unblock them if so.
6890         for event in events:
6891             instance = [inst for inst in instances
6892                         if inst.uuid == event.instance_uuid][0]
6893             LOG.debug('Received event %(event)s',
6894                       {'event': event.key},
6895                       instance=instance)
6896             if event.name == 'network-changed':
6897                 try:
6898                     self.network_api.get_instance_nw_info(context, instance)
6899                 except exception.NotFound as e:
6900                     LOG.info('Failed to process external instance event '
6901                              '%(event)s due to: %(error)s',
6902                              {'event': event.key, 'error': six.text_type(e)},
6903                              instance=instance)
6904             elif event.name == 'network-vif-deleted':
6905                 try:
6906                     self._process_instance_vif_deleted_event(context,
6907                                                              instance,
6908                                                              event.tag)
6909                 except exception.NotFound as e:
6910                     LOG.info('Failed to process external instance event '
6911                              '%(event)s due to: %(error)s',
6912                              {'event': event.key, 'error': six.text_type(e)},
6913                              instance=instance)
6914             else:
6915                 self._process_instance_event(instance, event)
6916 
6917     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
6918                                  external_process_ok=True)
6919     def _run_image_cache_manager_pass(self, context):
6920         """Run a single pass of the image cache manager."""
6921 
6922         if not self.driver.capabilities["has_imagecache"]:
6923             return
6924 
6925         # Determine what other nodes use this storage
6926         storage_users.register_storage_use(CONF.instances_path, CONF.host)
6927         nodes = storage_users.get_storage_users(CONF.instances_path)
6928 
6929         # Filter all_instances to only include those nodes which share this
6930         # storage path.
6931         # TODO(mikal): this should be further refactored so that the cache
6932         # cleanup code doesn't know what those instances are, just a remote
6933         # count, and then this logic should be pushed up the stack.
6934         filters = {'deleted': False,
6935                    'soft_deleted': True,
6936                    'host': nodes}
6937         filtered_instances = objects.InstanceList.get_by_filters(context,
6938                                  filters, expected_attrs=[], use_slave=True)
6939 
6940         self.driver.manage_image_cache(context, filtered_instances)
6941 
6942     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6943     def _run_pending_deletes(self, context):
6944         """Retry any pending instance file deletes."""
6945         LOG.debug('Cleaning up deleted instances')
6946         filters = {'deleted': True,
6947                    'soft_deleted': False,
6948                    'host': CONF.host,
6949                    'cleaned': False}
6950         attrs = ['system_metadata']
6951         with utils.temporary_mutation(context, read_deleted='yes'):
6952             instances = objects.InstanceList.get_by_filters(
6953                 context, filters, expected_attrs=attrs, use_slave=True)
6954         LOG.debug('There are %d instances to clean', len(instances))
6955 
6956         # TODO(raj_singh): Remove this if condition when min value is
6957         # introduced to "maximum_instance_delete_attempts" cfg option.
6958         if CONF.maximum_instance_delete_attempts < 1:
6959             LOG.warning('Future versions of Nova will restrict the '
6960                         '"maximum_instance_delete_attempts" config option '
6961                         'to values >=1. Update your configuration file to '
6962                         'mitigate future upgrade issues.')
6963 
6964         for instance in instances:
6965             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
6966             LOG.debug('Instance has had %(attempts)s of %(max)s '
6967                       'cleanup attempts',
6968                       {'attempts': attempts,
6969                        'max': CONF.maximum_instance_delete_attempts},
6970                       instance=instance)
6971             if attempts < CONF.maximum_instance_delete_attempts:
6972                 success = self.driver.delete_instance_files(instance)
6973 
6974                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
6975                 if success:
6976                     instance.cleaned = True
6977                 with utils.temporary_mutation(context, read_deleted='yes'):
6978                     instance.save()
6979 
6980     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6981     def _cleanup_incomplete_migrations(self, context):
6982         """Delete instance files on failed resize/revert-resize operation
6983 
6984         During resize/revert-resize operation, if that instance gets deleted
6985         in-between then instance files might remain either on source or
6986         destination compute node because of race condition.
6987         """
6988         LOG.debug('Cleaning up deleted instances with incomplete migration ')
6989         migration_filters = {'host': CONF.host,
6990                              'status': 'error'}
6991         migrations = objects.MigrationList.get_by_filters(context,
6992                                                           migration_filters)
6993 
6994         if not migrations:
6995             return
6996 
6997         inst_uuid_from_migrations = set([migration.instance_uuid for migration
6998                                          in migrations])
6999 
7000         inst_filters = {'deleted': True, 'soft_deleted': False,
7001                         'uuid': inst_uuid_from_migrations}
7002         attrs = ['info_cache', 'security_groups', 'system_metadata']
7003         with utils.temporary_mutation(context, read_deleted='yes'):
7004             instances = objects.InstanceList.get_by_filters(
7005                 context, inst_filters, expected_attrs=attrs, use_slave=True)
7006 
7007         for instance in instances:
7008             if instance.host != CONF.host:
7009                 for migration in migrations:
7010                     if instance.uuid == migration.instance_uuid:
7011                         # Delete instance files if not cleanup properly either
7012                         # from the source or destination compute nodes when
7013                         # the instance is deleted during resizing.
7014                         self.driver.delete_instance_files(instance)
7015                         try:
7016                             migration.status = 'failed'
7017                             with migration.obj_as_admin():
7018                                 migration.save()
7019                         except exception.MigrationNotFound:
7020                             LOG.warning("Migration %s is not found.",
7021                                         migration.id,
7022                                         instance=instance)
7023                         break
7024 
7025     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7026                                    exception.QemuGuestAgentNotEnabled,
7027                                    exception.NovaException,
7028                                    NotImplementedError)
7029     @wrap_exception()
7030     def quiesce_instance(self, context, instance):
7031         """Quiesce an instance on this host."""
7032         context = context.elevated()
7033         image_meta = objects.ImageMeta.from_instance(instance)
7034         self.driver.quiesce(context, instance, image_meta)
7035 
7036     def _wait_for_snapshots_completion(self, context, mapping):
7037         for mapping_dict in mapping:
7038             if mapping_dict.get('source_type') == 'snapshot':
7039 
7040                 def _wait_snapshot():
7041                     snapshot = self.volume_api.get_snapshot(
7042                         context, mapping_dict['snapshot_id'])
7043                     if snapshot.get('status') != 'creating':
7044                         raise loopingcall.LoopingCallDone()
7045 
7046                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
7047                 timer.start(interval=0.5).wait()
7048 
7049     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7050                                    exception.QemuGuestAgentNotEnabled,
7051                                    exception.NovaException,
7052                                    NotImplementedError)
7053     @wrap_exception()
7054     def unquiesce_instance(self, context, instance, mapping=None):
7055         """Unquiesce an instance on this host.
7056 
7057         If snapshots' image mapping is provided, it waits until snapshots are
7058         completed before unqueiscing.
7059         """
7060         context = context.elevated()
7061         if mapping:
7062             try:
7063                 self._wait_for_snapshots_completion(context, mapping)
7064             except Exception as error:
7065                 LOG.exception("Exception while waiting completion of "
7066                               "volume snapshots: %s",
7067                               error, instance=instance)
7068         image_meta = objects.ImageMeta.from_instance(instance)
7069         self.driver.unquiesce(context, instance, image_meta)
