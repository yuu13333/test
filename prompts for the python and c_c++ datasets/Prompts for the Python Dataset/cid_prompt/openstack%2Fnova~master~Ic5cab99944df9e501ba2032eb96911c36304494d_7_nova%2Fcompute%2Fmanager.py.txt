Please review the code below for security defects. You can consider defect types in terms of:
1.CWE-284 (Improper Access Control)
2.CWE-435 (Improper Interaction Between Multiple Entities)
3.CWE-664 (Improper Control of a Resource Through its Lifetime)
4.CWE-682 (Incorrect Calculation)
5.CWE-691 (Insufficient Control Flow Management)
6.CWE-693 (Protection Mechanism Failure)
7.CWE-697 (Incorrect Comparison)
8.CWE-703 (Improper Check or Handling of Exceptional Conditions)
9.CWE-707 (Improper Neutralization)
10.CWE-710 (Improper Adherence to Coding Standards)
If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are detected, states: 'No security defects are detected in the code'.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 import eventlet.event
39 from eventlet import greenthread
40 import eventlet.semaphore
41 import eventlet.timeout
42 from keystoneauth1 import exceptions as keystone_exception
43 from oslo_log import log as logging
44 import oslo_messaging as messaging
45 from oslo_serialization import jsonutils
46 from oslo_service import loopingcall
47 from oslo_service import periodic_task
48 from oslo_utils import excutils
49 from oslo_utils import strutils
50 from oslo_utils import timeutils
51 from oslo_utils import uuidutils
52 import six
53 from six.moves import range
54 
55 from nova import block_device
56 from nova.cells import rpcapi as cells_rpcapi
57 from nova.cloudpipe import pipelib
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova import consoleauth
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova.i18n import _LE
77 from nova.i18n import _LI
78 from nova.i18n import _LW
79 from nova import image
80 from nova.image import glance
81 from nova import manager
82 from nova import network
83 from nova.network import base_api as base_net_api
84 from nova.network import model as network_model
85 from nova.network.security_group import openstack_driver
86 from nova import objects
87 from nova.objects import base as obj_base
88 from nova.objects import fields
89 from nova.objects import instance as obj_instance
90 from nova.objects import migrate_data as migrate_data_obj
91 from nova.pci import whitelist
92 from nova import rpc
93 from nova import safe_utils
94 from nova.scheduler import client as scheduler_client
95 from nova import utils
96 from nova.virt import block_device as driver_block_device
97 from nova.virt import configdrive
98 from nova.virt import driver
99 from nova.virt import event as virtevent
100 from nova.virt import storage_users
101 from nova.virt import virtapi
102 from nova.volume import cinder
103 from nova.volume import encryptors
104 
105 CONF = nova.conf.CONF
106 
107 LOG = logging.getLogger(__name__)
108 
109 get_notifier = functools.partial(rpc.get_notifier, service='compute')
110 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
111                                    get_notifier=get_notifier,
112                                    binary='nova-compute')
113 
114 
115 @utils.expects_func_args('migration')
116 def errors_out_migration(function):
117     """Decorator to error out migration on failure."""
118 
119     @functools.wraps(function)
120     def decorated_function(self, context, *args, **kwargs):
121         try:
122             return function(self, context, *args, **kwargs)
123         except Exception as ex:
124             with excutils.save_and_reraise_exception():
125                 wrapped_func = safe_utils.get_wrapped_function(function)
126                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
127                                                  *args, **kwargs)
128                 migration = keyed_args['migration']
129 
130                 # NOTE(rajesht): If InstanceNotFound error is thrown from
131                 # decorated function, migration status should be set to
132                 # 'error', without checking current migration status.
133                 if not isinstance(ex, exception.InstanceNotFound):
134                     status = migration.status
135                     if status not in ['migrating', 'post-migrating']:
136                         return
137 
138                 migration.status = 'error'
139                 try:
140                     with migration.obj_as_admin():
141                         migration.save()
142                 except Exception:
143                     LOG.debug('Error setting migration status '
144                               'for instance %s.',
145                               migration.instance_uuid, exc_info=True)
146 
147     return decorated_function
148 
149 
150 @utils.expects_func_args('instance')
151 def reverts_task_state(function):
152     """Decorator to revert task_state on failure."""
153 
154     @functools.wraps(function)
155     def decorated_function(self, context, *args, **kwargs):
156         try:
157             return function(self, context, *args, **kwargs)
158         except exception.UnexpectedTaskStateError as e:
159             # Note(maoy): unexpected task state means the current
160             # task is preempted. Do not clear task state in this
161             # case.
162             with excutils.save_and_reraise_exception():
163                 LOG.info(_LI("Task possibly preempted: %s"),
164                          e.format_message())
165         except Exception:
166             with excutils.save_and_reraise_exception():
167                 wrapped_func = safe_utils.get_wrapped_function(function)
168                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
169                                                  *args, **kwargs)
170                 # NOTE(mriedem): 'instance' must be in keyed_args because we
171                 # have utils.expects_func_args('instance') decorating this
172                 # method.
173                 instance = keyed_args['instance']
174                 original_task_state = instance.task_state
175                 try:
176                     self._instance_update(context, instance, task_state=None)
177                     LOG.info(_LI("Successfully reverted task state from %s on "
178                                  "failure for instance."), original_task_state,
179                                                            instance=instance)
180                 except exception.InstanceNotFound:
181                     # We might delete an instance that failed to build shortly
182                     # after it errored out this is an expected case and we
183                     # should not trace on it.
184                     pass
185                 except Exception as e:
186                     msg = _LW("Failed to revert task state for instance. "
187                               "Error: %s")
188                     LOG.warning(msg, e, instance=instance)
189 
190     return decorated_function
191 
192 
193 @utils.expects_func_args('instance')
194 def wrap_instance_fault(function):
195     """Wraps a method to catch exceptions related to instances.
196 
197     This decorator wraps a method to catch any exceptions having to do with
198     an instance that may get thrown. It then logs an instance fault in the db.
199     """
200 
201     @functools.wraps(function)
202     def decorated_function(self, context, *args, **kwargs):
203         try:
204             return function(self, context, *args, **kwargs)
205         except exception.InstanceNotFound:
206             raise
207         except Exception as e:
208             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
209             # we will get a KeyError exception which will cover up the real
210             # exception. So, we update kwargs with the values from args first.
211             # then, we can get 'instance' from kwargs easily.
212             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
213 
214             with excutils.save_and_reraise_exception():
215                 compute_utils.add_instance_fault_from_exc(context,
216                         kwargs['instance'], e, sys.exc_info())
217 
218     return decorated_function
219 
220 
221 @utils.expects_func_args('image_id', 'instance')
222 def delete_image_on_error(function):
223     """Used for snapshot related method to ensure the image created in
224     compute.api is deleted when an error occurs.
225     """
226 
227     @functools.wraps(function)
228     def decorated_function(self, context, image_id, instance,
229                            *args, **kwargs):
230         try:
231             return function(self, context, image_id, instance,
232                             *args, **kwargs)
233         except Exception:
234             with excutils.save_and_reraise_exception():
235                 LOG.debug("Cleaning up image %s", image_id,
236                           exc_info=True, instance=instance)
237                 try:
238                     self.image_api.delete(context, image_id)
239                 except exception.ImageNotFound:
240                     # Since we're trying to cleanup an image, we don't care if
241                     # if it's already gone.
242                     pass
243                 except Exception:
244                     LOG.exception(_LE("Error while trying to clean up "
245                                       "image %s"), image_id,
246                                   instance=instance)
247 
248     return decorated_function
249 
250 
251 # TODO(danms): Remove me after Icehouse
252 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
253 # NOTE(mikal): if the method being decorated has more than one decorator, then
254 # put this one first. Otherwise the various exception handling decorators do
255 # not function correctly.
256 def object_compat(function):
257     """Wraps a method that expects a new-world instance
258 
259     This provides compatibility for callers passing old-style dict
260     instances.
261     """
262 
263     @functools.wraps(function)
264     def decorated_function(self, context, *args, **kwargs):
265         def _load_instance(instance_or_dict):
266             if isinstance(instance_or_dict, dict):
267                 # try to get metadata and system_metadata for most cases but
268                 # only attempt to load those if the db instance already has
269                 # those fields joined
270                 metas = [meta for meta in ('metadata', 'system_metadata')
271                          if meta in instance_or_dict]
272                 instance = objects.Instance._from_db_object(
273                     context, objects.Instance(), instance_or_dict,
274                     expected_attrs=metas)
275                 instance._context = context
276                 return instance
277             return instance_or_dict
278 
279         try:
280             kwargs['instance'] = _load_instance(kwargs['instance'])
281         except KeyError:
282             args = (_load_instance(args[0]),) + args[1:]
283 
284         migration = kwargs.get('migration')
285         if isinstance(migration, dict):
286             migration = objects.Migration._from_db_object(
287                     context.elevated(), objects.Migration(),
288                     migration)
289             kwargs['migration'] = migration
290 
291         return function(self, context, *args, **kwargs)
292 
293     return decorated_function
294 
295 
296 class InstanceEvents(object):
297     def __init__(self):
298         self._events = {}
299 
300     @staticmethod
301     def _lock_name(instance):
302         return '%s-%s' % (instance.uuid, 'events')
303 
304     def prepare_for_instance_event(self, instance, event_name):
305         """Prepare to receive an event for an instance.
306 
307         This will register an event for the given instance that we will
308         wait on later. This should be called before initiating whatever
309         action will trigger the event. The resulting eventlet.event.Event
310         object should be wait()'d on to ensure completion.
311 
312         :param instance: the instance for which the event will be generated
313         :param event_name: the name of the event we're expecting
314         :returns: an event object that should be wait()'d on
315         """
316         if self._events is None:
317             # NOTE(danms): We really should have a more specific error
318             # here, but this is what we use for our default error case
319             raise exception.NovaException('In shutdown, no new events '
320                                           'can be scheduled')
321 
322         @utils.synchronized(self._lock_name(instance))
323         def _create_or_get_event():
324             instance_events = self._events.setdefault(instance.uuid, {})
325             return instance_events.setdefault(event_name,
326                                               eventlet.event.Event())
327         LOG.debug('Preparing to wait for external event %(event)s',
328                   {'event': event_name}, instance=instance)
329         return _create_or_get_event()
330 
331     def pop_instance_event(self, instance, event):
332         """Remove a pending event from the wait list.
333 
334         This will remove a pending event from the wait list so that it
335         can be used to signal the waiters to wake up.
336 
337         :param instance: the instance for which the event was generated
338         :param event: the nova.objects.external_event.InstanceExternalEvent
339                       that describes the event
340         :returns: the eventlet.event.Event object on which the waiters
341                   are blocked
342         """
343         no_events_sentinel = object()
344         no_matching_event_sentinel = object()
345 
346         @utils.synchronized(self._lock_name(instance))
347         def _pop_event():
348             if not self._events:
349                 LOG.debug('Unexpected attempt to pop events during shutdown',
350                           instance=instance)
351                 return no_events_sentinel
352             events = self._events.get(instance.uuid)
353             if not events:
354                 return no_events_sentinel
355             _event = events.pop(event.key, None)
356             if not events:
357                 del self._events[instance.uuid]
358             if _event is None:
359                 return no_matching_event_sentinel
360             return _event
361 
362         result = _pop_event()
363         if result is no_events_sentinel:
364             LOG.debug('No waiting events found dispatching %(event)s',
365                       {'event': event.key},
366                       instance=instance)
367             return None
368         elif result is no_matching_event_sentinel:
369             LOG.debug('No event matching %(event)s in %(events)s',
370                       {'event': event.key,
371                        'events': self._events.get(instance.uuid, {}).keys()},
372                       instance=instance)
373             return None
374         else:
375             return result
376 
377     def clear_events_for_instance(self, instance):
378         """Remove all pending events for an instance.
379 
380         This will remove all events currently pending for an instance
381         and return them (indexed by event name).
382 
383         :param instance: the instance for which events should be purged
384         :returns: a dictionary of {event_name: eventlet.event.Event}
385         """
386         @utils.synchronized(self._lock_name(instance))
387         def _clear_events():
388             if self._events is None:
389                 LOG.debug('Unexpected attempt to clear events during shutdown',
390                           instance=instance)
391                 return dict()
392             return self._events.pop(instance.uuid, {})
393         return _clear_events()
394 
395     def cancel_all_events(self):
396         if self._events is None:
397             LOG.debug('Unexpected attempt to cancel events during shutdown.')
398             return
399         our_events = self._events
400         # NOTE(danms): Block new events
401         self._events = None
402 
403         for instance_uuid, events in our_events.items():
404             for event_name, eventlet_event in events.items():
405                 LOG.debug('Canceling in-flight event %(event)s for '
406                           'instance %(instance_uuid)s',
407                           {'event': event_name,
408                            'instance_uuid': instance_uuid})
409                 name, tag = event_name.rsplit('-', 1)
410                 event = objects.InstanceExternalEvent(
411                     instance_uuid=instance_uuid,
412                     name=name, status='failed',
413                     tag=tag, data={})
414                 eventlet_event.send(event)
415 
416 
417 class ComputeVirtAPI(virtapi.VirtAPI):
418     def __init__(self, compute):
419         super(ComputeVirtAPI, self).__init__()
420         self._compute = compute
421 
422     def _default_error_callback(self, event_name, instance):
423         raise exception.NovaException(_('Instance event failed'))
424 
425     @contextlib.contextmanager
426     def wait_for_instance_event(self, instance, event_names, deadline=300,
427                                 error_callback=None):
428         """Plan to wait for some events, run some code, then wait.
429 
430         This context manager will first create plans to wait for the
431         provided event_names, yield, and then wait for all the scheduled
432         events to complete.
433 
434         Note that this uses an eventlet.timeout.Timeout to bound the
435         operation, so callers should be prepared to catch that
436         failure and handle that situation appropriately.
437 
438         If the event is not received by the specified timeout deadline,
439         eventlet.timeout.Timeout is raised.
440 
441         If the event is received but did not have a 'completed'
442         status, a NovaException is raised.  If an error_callback is
443         provided, instead of raising an exception as detailed above
444         for the failure case, the callback will be called with the
445         event_name and instance, and can return True to continue
446         waiting for the rest of the events, False to stop processing,
447         or raise an exception which will bubble up to the waiter.
448 
449         :param instance: The instance for which an event is expected
450         :param event_names: A list of event names. Each element can be a
451                             string event name or tuple of strings to
452                             indicate (name, tag).
453         :param deadline: Maximum number of seconds we should wait for all
454                          of the specified events to arrive.
455         :param error_callback: A function to be called if an event arrives
456 
457         """
458 
459         if error_callback is None:
460             error_callback = self._default_error_callback
461         events = {}
462         for event_name in event_names:
463             if isinstance(event_name, tuple):
464                 name, tag = event_name
465                 event_name = objects.InstanceExternalEvent.make_key(
466                     name, tag)
467             try:
468                 events[event_name] = (
469                     self._compute.instance_events.prepare_for_instance_event(
470                         instance, event_name))
471             except exception.NovaException:
472                 error_callback(event_name, instance)
473                 # NOTE(danms): Don't wait for any of the events. They
474                 # should all be canceled and fired immediately below,
475                 # but don't stick around if not.
476                 deadline = 0
477         yield
478         with eventlet.timeout.Timeout(deadline):
479             for event_name, event in events.items():
480                 actual_event = event.wait()
481                 if actual_event.status == 'completed':
482                     continue
483                 decision = error_callback(event_name, instance)
484                 if decision is False:
485                     break
486 
487 
488 class ComputeManager(manager.Manager):
489     """Manages the running instances from creation to destruction."""
490 
491     target = messaging.Target(version='4.13')
492 
493     # How long to wait in seconds before re-issuing a shutdown
494     # signal to an instance during power off.  The overall
495     # time to wait is set by CONF.shutdown_timeout.
496     SHUTDOWN_RETRY_INTERVAL = 10
497 
498     def __init__(self, compute_driver=None, *args, **kwargs):
499         """Load configuration options and connect to the hypervisor."""
500         self.virtapi = ComputeVirtAPI(self)
501         self.network_api = network.API()
502         self.volume_api = cinder.API()
503         self.image_api = image.API()
504         self._last_host_check = 0
505         self._last_bw_usage_poll = 0
506         self._bw_usage_supported = True
507         self._last_bw_usage_cell_update = 0
508         self.compute_api = compute.API()
509         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
510         self.conductor_api = conductor.API()
511         self.compute_task_api = conductor.ComputeTaskAPI()
512         self.is_neutron_security_groups = (
513             openstack_driver.is_neutron_security_groups())
514         self.consoleauth_rpcapi = consoleauth.rpcapi.ConsoleAuthAPI()
515         self.cells_rpcapi = cells_rpcapi.CellsAPI()
516         self.scheduler_client = scheduler_client.SchedulerClient()
517         self._resource_tracker = None
518         self.instance_events = InstanceEvents()
519         self._sync_power_pool = eventlet.GreenPool(
520             size=CONF.sync_power_state_pool_size)
521         self._syncs_in_progress = {}
522         self.send_instance_updates = (
523             CONF.filter_scheduler.track_instance_changes)
524         if CONF.max_concurrent_builds != 0:
525             self._build_semaphore = eventlet.semaphore.Semaphore(
526                 CONF.max_concurrent_builds)
527         else:
528             self._build_semaphore = compute_utils.UnlimitedSemaphore()
529         if max(CONF.max_concurrent_live_migrations, 0) != 0:
530             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
531                 CONF.max_concurrent_live_migrations)
532         else:
533             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
534 
535         super(ComputeManager, self).__init__(service_name="compute",
536                                              *args, **kwargs)
537 
538         # NOTE(russellb) Load the driver last.  It may call back into the
539         # compute manager via the virtapi, so we want it to be fully
540         # initialized before that happens.
541         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
542         self.use_legacy_block_device_info = \
543                             self.driver.need_legacy_block_device_info
544 
545     def reset(self):
546         LOG.info(_LI('Reloading compute RPC API'))
547         compute_rpcapi.LAST_VERSION = None
548         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
549 
550     def _get_resource_tracker(self):
551         if not self._resource_tracker:
552             rt = resource_tracker.ResourceTracker(self.host, self.driver)
553             self._resource_tracker = rt
554         return self._resource_tracker
555 
556     def _update_resource_tracker(self, context, instance):
557         """Let the resource tracker know that an instance has changed state."""
558 
559         if instance.host == self.host:
560             rt = self._get_resource_tracker()
561             rt.update_usage(context, instance, instance.node)
562 
563     def _instance_update(self, context, instance, **kwargs):
564         """Update an instance in the database using kwargs as value."""
565 
566         for k, v in kwargs.items():
567             setattr(instance, k, v)
568         instance.save()
569         self._update_resource_tracker(context, instance)
570 
571     def _nil_out_instance_obj_host_and_node(self, instance):
572         # NOTE(jwcroppe): We don't do instance.save() here for performance
573         # reasons; a call to this is expected to be immediately followed by
574         # another call that does instance.save(), thus avoiding two writes
575         # to the database layer.
576         instance.host = None
577         instance.node = None
578 
579     def _set_instance_obj_error_state(self, context, instance,
580                                       clean_task_state=False):
581         try:
582             instance.vm_state = vm_states.ERROR
583             if clean_task_state:
584                 instance.task_state = None
585             instance.save()
586         except exception.InstanceNotFound:
587             LOG.debug('Instance has been destroyed from under us while '
588                       'trying to set it to ERROR', instance=instance)
589 
590     def _get_instances_on_driver(self, context, filters=None):
591         """Return a list of instance records for the instances found
592         on the hypervisor which satisfy the specified filters. If filters=None
593         return a list of instance records for all the instances found on the
594         hypervisor.
595         """
596         if not filters:
597             filters = {}
598         try:
599             driver_uuids = self.driver.list_instance_uuids()
600             if len(driver_uuids) == 0:
601                 # Short circuit, don't waste a DB call
602                 return objects.InstanceList()
603             filters['uuid'] = driver_uuids
604             local_instances = objects.InstanceList.get_by_filters(
605                 context, filters, use_slave=True)
606             return local_instances
607         except NotImplementedError:
608             pass
609 
610         # The driver doesn't support uuids listing, so we'll have
611         # to brute force.
612         driver_instances = self.driver.list_instances()
613         instances = objects.InstanceList.get_by_filters(context, filters,
614                                                         use_slave=True)
615         name_map = {instance.name: instance for instance in instances}
616         local_instances = []
617         for driver_instance in driver_instances:
618             instance = name_map.get(driver_instance)
619             if not instance:
620                 continue
621             local_instances.append(instance)
622         return local_instances
623 
624     def _destroy_evacuated_instances(self, context):
625         """Destroys evacuated instances.
626 
627         While nova-compute was down, the instances running on it could be
628         evacuated to another host. Check that the instances reported
629         by the driver are still associated with this host.  If they are
630         not, destroy them, with the exception of instances which are in
631         the MIGRATING, RESIZE_MIGRATING, RESIZE_MIGRATED, RESIZE_FINISH
632         task state or RESIZED vm state.
633         """
634         filters = {
635             'source_compute': self.host,
636             'status': ['accepted', 'done'],
637             'migration_type': 'evacuation',
638         }
639         evacuations = objects.MigrationList.get_by_filters(context, filters)
640         if not evacuations:
641             return
642         evacuations = {mig.instance_uuid: mig for mig in evacuations}
643 
644         filters = {'deleted': False}
645         local_instances = self._get_instances_on_driver(context, filters)
646         evacuated = [inst for inst in local_instances
647                      if inst.uuid in evacuations]
648         for instance in evacuated:
649             migration = evacuations[instance.uuid]
650             LOG.info(_LI('Deleting instance as it has been evacuated from '
651                          'this host'), instance=instance)
652             try:
653                 network_info = self.network_api.get_instance_nw_info(
654                     context, instance)
655                 bdi = self._get_instance_block_device_info(context,
656                                                            instance)
657                 destroy_disks = not (self._is_instance_storage_shared(
658                     context, instance))
659             except exception.InstanceNotFound:
660                 network_info = network_model.NetworkInfo()
661                 bdi = {}
662                 LOG.info(_LI('Instance has been marked deleted already, '
663                              'removing it from the hypervisor.'),
664                          instance=instance)
665                 # always destroy disks if the instance was deleted
666                 destroy_disks = True
667             self.driver.destroy(context, instance,
668                                 network_info,
669                                 bdi, destroy_disks)
670             migration.status = 'completed'
671             migration.save()
672 
673     def _is_instance_storage_shared(self, context, instance, host=None):
674         shared_storage = True
675         data = None
676         try:
677             data = self.driver.check_instance_shared_storage_local(context,
678                                                        instance)
679             if data:
680                 shared_storage = (self.compute_rpcapi.
681                                   check_instance_shared_storage(context,
682                                   instance, data, host=host))
683         except NotImplementedError:
684             LOG.debug('Hypervisor driver does not support '
685                       'instance shared storage check, '
686                       'assuming it\'s not on shared storage',
687                       instance=instance)
688             shared_storage = False
689         except Exception:
690             LOG.exception(_LE('Failed to check if instance shared'),
691                       instance=instance)
692         finally:
693             if data:
694                 self.driver.check_instance_shared_storage_cleanup(context,
695                                                                   data)
696         return shared_storage
697 
698     def _complete_partial_deletion(self, context, instance):
699         """Complete deletion for instances in DELETED status but not marked as
700         deleted in the DB
701         """
702         system_meta = instance.system_metadata
703         instance.destroy()
704         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
705                 context, instance.uuid)
706         quotas = objects.Quotas(context=context)
707         project_id, user_id = objects.quotas.ids_from_instance(context,
708                                                                instance)
709         quotas.reserve(project_id=project_id, user_id=user_id, instances=-1,
710                        cores=-instance.flavor.vcpus,
711                        ram=-instance.flavor.memory_mb)
712         self._complete_deletion(context,
713                                 instance,
714                                 bdms,
715                                 quotas,
716                                 system_meta)
717 
718     def _complete_deletion(self, context, instance, bdms,
719                            quotas, system_meta):
720         if quotas:
721             quotas.commit()
722 
723         # ensure block device mappings are not leaked
724         for bdm in bdms:
725             bdm.destroy()
726 
727         self._update_resource_tracker(context, instance)
728         self._notify_about_instance_usage(context, instance, "delete.end",
729                 system_metadata=system_meta)
730         compute_utils.notify_about_instance_action(context, instance,
731                 self.host, action=fields.NotificationAction.DELETE,
732                 phase=fields.NotificationPhase.END)
733         self._clean_instance_console_tokens(context, instance)
734         self._delete_scheduler_instance_info(context, instance.uuid)
735 
736     def _create_reservations(self, context, instance, project_id, user_id):
737         vcpus = instance.flavor.vcpus
738         mem_mb = instance.flavor.memory_mb
739 
740         quotas = objects.Quotas(context=context)
741         quotas.reserve(project_id=project_id,
742                        user_id=user_id,
743                        instances=-1,
744                        cores=-vcpus,
745                        ram=-mem_mb)
746         return quotas
747 
748     def _init_instance(self, context, instance):
749         '''Initialize this instance during service init.'''
750 
751         # NOTE(danms): If the instance appears to not be owned by this
752         # host, it may have been evacuated away, but skipped by the
753         # evacuation cleanup code due to configuration. Thus, if that
754         # is a possibility, don't touch the instance in any way, but
755         # log the concern. This will help avoid potential issues on
756         # startup due to misconfiguration.
757         if instance.host != self.host:
758             LOG.warning(_LW('Instance %(uuid)s appears to not be owned '
759                             'by this host, but by %(host)s. Startup '
760                             'processing is being skipped.'),
761                         {'uuid': instance.uuid,
762                          'host': instance.host})
763             return
764 
765         # Instances that are shut down, or in an error state can not be
766         # initialized and are not attempted to be recovered. The exception
767         # to this are instances that are in RESIZE_MIGRATING or DELETING,
768         # which are dealt with further down.
769         if (instance.vm_state == vm_states.SOFT_DELETED or
770             (instance.vm_state == vm_states.ERROR and
771             instance.task_state not in
772             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
773             LOG.debug("Instance is in %s state.",
774                       instance.vm_state, instance=instance)
775             return
776 
777         if instance.vm_state == vm_states.DELETED:
778             try:
779                 self._complete_partial_deletion(context, instance)
780             except Exception:
781                 # we don't want that an exception blocks the init_host
782                 msg = _LE('Failed to complete a deletion')
783                 LOG.exception(msg, instance=instance)
784             return
785 
786         if (instance.vm_state == vm_states.BUILDING or
787             instance.task_state in [task_states.SCHEDULING,
788                                     task_states.BLOCK_DEVICE_MAPPING,
789                                     task_states.NETWORKING,
790                                     task_states.SPAWNING]):
791             # NOTE(dave-mcnally) compute stopped before instance was fully
792             # spawned so set to ERROR state. This is safe to do as the state
793             # may be set by the api but the host is not so if we get here the
794             # instance has already been scheduled to this particular host.
795             LOG.debug("Instance failed to spawn correctly, "
796                       "setting to ERROR state", instance=instance)
797             instance.task_state = None
798             instance.vm_state = vm_states.ERROR
799             instance.save()
800             return
801 
802         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
803             instance.task_state in [task_states.REBUILDING,
804                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
805                                     task_states.REBUILD_SPAWNING]):
806             # NOTE(jichenjc) compute stopped before instance was fully
807             # spawned so set to ERROR state. This is consistent to BUILD
808             LOG.debug("Instance failed to rebuild correctly, "
809                       "setting to ERROR state", instance=instance)
810             instance.task_state = None
811             instance.vm_state = vm_states.ERROR
812             instance.save()
813             return
814 
815         if (instance.vm_state != vm_states.ERROR and
816             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
817                                     task_states.IMAGE_PENDING_UPLOAD,
818                                     task_states.IMAGE_UPLOADING,
819                                     task_states.IMAGE_SNAPSHOT]):
820             LOG.debug("Instance in transitional state %s at start-up "
821                       "clearing task state",
822                       instance.task_state, instance=instance)
823             try:
824                 self._post_interrupted_snapshot_cleanup(context, instance)
825             except Exception:
826                 # we don't want that an exception blocks the init_host
827                 msg = _LE('Failed to cleanup snapshot.')
828                 LOG.exception(msg, instance=instance)
829             instance.task_state = None
830             instance.save()
831 
832         if (instance.vm_state != vm_states.ERROR and
833             instance.task_state in [task_states.RESIZE_PREP]):
834             LOG.debug("Instance in transitional state %s at start-up "
835                       "clearing task state",
836                       instance['task_state'], instance=instance)
837             instance.task_state = None
838             instance.save()
839 
840         if instance.task_state == task_states.DELETING:
841             try:
842                 LOG.info(_LI('Service started deleting the instance during '
843                              'the previous run, but did not finish. Restarting'
844                              ' the deletion now.'), instance=instance)
845                 instance.obj_load_attr('metadata')
846                 instance.obj_load_attr('system_metadata')
847                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
848                         context, instance.uuid)
849                 project_id, user_id = objects.quotas.ids_from_instance(
850                     context, instance)
851                 quotas = self._create_reservations(context, instance,
852                                                    project_id, user_id)
853 
854                 self._delete_instance(context, instance, bdms, quotas)
855             except Exception:
856                 # we don't want that an exception blocks the init_host
857                 msg = _LE('Failed to complete a deletion')
858                 LOG.exception(msg, instance=instance)
859                 self._set_instance_obj_error_state(context, instance)
860             return
861 
862         current_power_state = self._get_power_state(context, instance)
863         try_reboot, reboot_type = self._retry_reboot(context, instance,
864                                                      current_power_state)
865 
866         if try_reboot:
867             LOG.debug("Instance in transitional state (%(task_state)s) at "
868                       "start-up and power state is (%(power_state)s), "
869                       "triggering reboot",
870                       {'task_state': instance.task_state,
871                        'power_state': current_power_state},
872                       instance=instance)
873 
874             # NOTE(mikal): if the instance was doing a soft reboot that got as
875             # far as shutting down the instance but not as far as starting it
876             # again, then we've just become a hard reboot. That means the
877             # task state for the instance needs to change so that we're in one
878             # of the expected task states for a hard reboot.
879             soft_types = [task_states.REBOOT_STARTED,
880                           task_states.REBOOT_PENDING,
881                           task_states.REBOOTING]
882             if instance.task_state in soft_types and reboot_type == 'HARD':
883                 instance.task_state = task_states.REBOOT_PENDING_HARD
884                 instance.save()
885 
886             self.reboot_instance(context, instance, block_device_info=None,
887                                  reboot_type=reboot_type)
888             return
889 
890         elif (current_power_state == power_state.RUNNING and
891               instance.task_state in [task_states.REBOOT_STARTED,
892                                       task_states.REBOOT_STARTED_HARD,
893                                       task_states.PAUSING,
894                                       task_states.UNPAUSING]):
895             LOG.warning(_LW("Instance in transitional state "
896                             "(%(task_state)s) at start-up and power state "
897                             "is (%(power_state)s), clearing task state"),
898                         {'task_state': instance.task_state,
899                          'power_state': current_power_state},
900                         instance=instance)
901             instance.task_state = None
902             instance.vm_state = vm_states.ACTIVE
903             instance.save()
904         elif (current_power_state == power_state.PAUSED and
905               instance.task_state == task_states.UNPAUSING):
906             LOG.warning(_LW("Instance in transitional state "
907                             "(%(task_state)s) at start-up and power state "
908                             "is (%(power_state)s), clearing task state "
909                             "and unpausing the instance"),
910                         {'task_state': instance.task_state,
911                          'power_state': current_power_state},
912                         instance=instance)
913             try:
914                 self.unpause_instance(context, instance)
915             except NotImplementedError:
916                 # Some virt driver didn't support pause and unpause
917                 pass
918             except Exception:
919                 LOG.exception(_LE('Failed to unpause instance'),
920                               instance=instance)
921             return
922 
923         if instance.task_state == task_states.POWERING_OFF:
924             try:
925                 LOG.debug("Instance in transitional state %s at start-up "
926                           "retrying stop request",
927                           instance.task_state, instance=instance)
928                 self.stop_instance(context, instance, True)
929             except Exception:
930                 # we don't want that an exception blocks the init_host
931                 msg = _LE('Failed to stop instance')
932                 LOG.exception(msg, instance=instance)
933             return
934 
935         if instance.task_state == task_states.POWERING_ON:
936             try:
937                 LOG.debug("Instance in transitional state %s at start-up "
938                           "retrying start request",
939                           instance.task_state, instance=instance)
940                 self.start_instance(context, instance)
941             except Exception:
942                 # we don't want that an exception blocks the init_host
943                 msg = _LE('Failed to start instance')
944                 LOG.exception(msg, instance=instance)
945             return
946 
947         net_info = compute_utils.get_nw_info_for_instance(instance)
948         try:
949             self.driver.plug_vifs(instance, net_info)
950         except NotImplementedError as e:
951             LOG.debug(e, instance=instance)
952         except exception.VirtualInterfacePlugException:
953             # we don't want an exception to block the init_host
954             LOG.exception(_LE("Vifs plug failed"), instance=instance)
955             self._set_instance_obj_error_state(context, instance)
956             return
957 
958         if instance.task_state == task_states.RESIZE_MIGRATING:
959             # We crashed during resize/migration, so roll back for safety
960             try:
961                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
962                 # not in system_metadata we default to True for backwards
963                 # compatibility
964                 power_on = (instance.system_metadata.get('old_vm_state') !=
965                             vm_states.STOPPED)
966 
967                 block_dev_info = self._get_instance_block_device_info(context,
968                                                                       instance)
969 
970                 self.driver.finish_revert_migration(context,
971                     instance, net_info, block_dev_info, power_on)
972 
973             except Exception:
974                 LOG.exception(_LE('Failed to revert crashed migration'),
975                               instance=instance)
976             finally:
977                 LOG.info(_LI('Instance found in migrating state during '
978                              'startup. Resetting task_state'),
979                          instance=instance)
980                 instance.task_state = None
981                 instance.save()
982         if instance.task_state == task_states.MIGRATING:
983             # Live migration did not complete, but instance is on this
984             # host, so reset the state.
985             instance.task_state = None
986             instance.save(expected_task_state=[task_states.MIGRATING])
987 
988         db_state = instance.power_state
989         drv_state = self._get_power_state(context, instance)
990         expect_running = (db_state == power_state.RUNNING and
991                           drv_state != db_state)
992 
993         LOG.debug('Current state is %(drv_state)s, state in DB is '
994                   '%(db_state)s.',
995                   {'drv_state': drv_state, 'db_state': db_state},
996                   instance=instance)
997 
998         if expect_running and CONF.resume_guests_state_on_host_boot:
999             LOG.info(_LI('Rebooting instance after nova-compute restart.'),
1000                      instance=instance)
1001 
1002             block_device_info = \
1003                 self._get_instance_block_device_info(context, instance)
1004 
1005             try:
1006                 self.driver.resume_state_on_host_boot(
1007                     context, instance, net_info, block_device_info)
1008             except NotImplementedError:
1009                 LOG.warning(_LW('Hypervisor driver does not support '
1010                                 'resume guests'), instance=instance)
1011             except Exception:
1012                 # NOTE(vish): The instance failed to resume, so we set the
1013                 #             instance to error and attempt to continue.
1014                 LOG.warning(_LW('Failed to resume instance'),
1015                             instance=instance)
1016                 self._set_instance_obj_error_state(context, instance)
1017 
1018         elif drv_state == power_state.RUNNING:
1019             # VMwareAPI drivers will raise an exception
1020             try:
1021                 self.driver.ensure_filtering_rules_for_instance(
1022                                        instance, net_info)
1023             except NotImplementedError:
1024                 LOG.debug('Hypervisor driver does not support '
1025                           'firewall rules', instance=instance)
1026 
1027     def _retry_reboot(self, context, instance, current_power_state):
1028         current_task_state = instance.task_state
1029         retry_reboot = False
1030         reboot_type = compute_utils.get_reboot_type(current_task_state,
1031                                                     current_power_state)
1032 
1033         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1034                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1035         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1036                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1037         started_not_running = (current_task_state in
1038                                [task_states.REBOOT_STARTED,
1039                                 task_states.REBOOT_STARTED_HARD] and
1040                                current_power_state != power_state.RUNNING)
1041 
1042         if pending_soft or pending_hard or started_not_running:
1043             retry_reboot = True
1044 
1045         return retry_reboot, reboot_type
1046 
1047     def handle_lifecycle_event(self, event):
1048         LOG.info(_LI("VM %(state)s (Lifecycle Event)"),
1049                  {'state': event.get_name()},
1050                  instance_uuid=event.get_instance_uuid())
1051         context = nova.context.get_admin_context(read_deleted='yes')
1052         instance = objects.Instance.get_by_uuid(context,
1053                                                 event.get_instance_uuid(),
1054                                                 expected_attrs=[])
1055         vm_power_state = None
1056         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1057             vm_power_state = power_state.SHUTDOWN
1058         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1059             vm_power_state = power_state.RUNNING
1060         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1061             vm_power_state = power_state.PAUSED
1062         elif (event.get_transition() == virtevent.
1063                 EVENT_LIFECYCLE_POSTCOPY_STARTED):
1064             vm_power_state = power_state.PAUSED
1065         elif (event.get_transition() == virtevent.
1066                 EVENT_LIFECYCLE_MIGRATION_COMPLETED):
1067             vm_power_state = power_state.PAUSED
1068         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1069             vm_power_state = power_state.RUNNING
1070         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1071             vm_power_state = power_state.SUSPENDED
1072         else:
1073             LOG.warning(_LW("Unexpected power state %d"),
1074                         event.get_transition())
1075 
1076         # Note(lpetrut): The event may be delayed, thus not reflecting
1077         # the current instance power state. In that case, ignore the event.
1078         current_power_state = self._get_power_state(context, instance)
1079         if current_power_state == vm_power_state:
1080             LOG.debug('Synchronizing instance power state after lifecycle '
1081                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1082                       'current task_state: %(task_state)s, current DB '
1083                       'power_state: %(db_power_state)s, VM power_state: '
1084                       '%(vm_power_state)s',
1085                       {'event': event.get_name(),
1086                        'vm_state': instance.vm_state,
1087                        'task_state': instance.task_state,
1088                        'db_power_state': instance.power_state,
1089                        'vm_power_state': vm_power_state},
1090                       instance_uuid=instance.uuid)
1091             self._sync_instance_power_state(context,
1092                                             instance,
1093                                             vm_power_state)
1094         event_transition = event.get_transition()
1095         if instance.task_state == task_states.MIGRATING and (
1096             event_transition == virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED or
1097             event_transition == virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED):
1098             status = 'running'
1099             if (event_transition ==
1100                     virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED):
1101                 status = 'running (post-copy)'
1102             LOG.debug('Updating port binding of the instance',
1103                       instance=instance)
1104             migration = objects.Migration.get_by_instance_and_status(
1105                         context, instance.uuid, status)
1106             self.network_api.migrate_instance_finish(context, instance,
1107                                                      migration)
1108 
1109     def handle_events(self, event):
1110         if isinstance(event, virtevent.LifecycleEvent):
1111             try:
1112                 self.handle_lifecycle_event(event)
1113             except exception.InstanceNotFound:
1114                 LOG.debug("Event %s arrived for non-existent instance. The "
1115                           "instance was probably deleted.", event)
1116         else:
1117             LOG.debug("Ignoring event %s", event)
1118 
1119     def init_virt_events(self):
1120         if CONF.workarounds.handle_virt_lifecycle_events:
1121             self.driver.register_event_listener(self.handle_events)
1122         else:
1123             # NOTE(mriedem): If the _sync_power_states periodic task is
1124             # disabled we should emit a warning in the logs.
1125             if CONF.sync_power_state_interval < 0:
1126                 LOG.warning(_LW('Instance lifecycle events from the compute '
1127                              'driver have been disabled. Note that lifecycle '
1128                              'changes to an instance outside of the compute '
1129                              'service will not be synchronized '
1130                              'automatically since the _sync_power_states '
1131                              'periodic task is also disabled.'))
1132             else:
1133                 LOG.info(_LI('Instance lifecycle events from the compute '
1134                              'driver have been disabled. Note that lifecycle '
1135                              'changes to an instance outside of the compute '
1136                              'service will only be synchronized by the '
1137                              '_sync_power_states periodic task.'))
1138 
1139     def init_host(self):
1140         """Initialization for a standalone compute service."""
1141 
1142         if CONF.pci.passthrough_whitelist:
1143             # Simply loading the PCI passthrough whitelist will do a bunch of
1144             # validation that would otherwise wait until the PciDevTracker is
1145             # constructed when updating available resources for the compute
1146             # node(s) in the resource tracker, effectively killing that task.
1147             # So load up the whitelist when starting the compute service to
1148             # flush any invalid configuration early so we can kill the service
1149             # if the configuration is wrong.
1150             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1151 
1152         # NOTE(sbauza): We want the compute node to hard fail if it can't be
1153         # able to provide its resources to the placement API, or it would not
1154         # be able to be eligible as a destination.
1155         if CONF.placement.os_region_name is None:
1156             raise exception.PlacementNotConfigured()
1157 
1158         self.driver.init_host(host=self.host)
1159         context = nova.context.get_admin_context()
1160         instances = objects.InstanceList.get_by_host(
1161             context, self.host, expected_attrs=['info_cache', 'metadata'])
1162 
1163         if CONF.defer_iptables_apply:
1164             self.driver.filter_defer_apply_on()
1165 
1166         self.init_virt_events()
1167 
1168         try:
1169             # checking that instance was not already evacuated to other host
1170             self._destroy_evacuated_instances(context)
1171             for instance in instances:
1172                 self._init_instance(context, instance)
1173         finally:
1174             if CONF.defer_iptables_apply:
1175                 self.driver.filter_defer_apply_off()
1176             self._update_scheduler_instance_info(context, instances)
1177 
1178     def cleanup_host(self):
1179         self.driver.register_event_listener(None)
1180         self.instance_events.cancel_all_events()
1181         self.driver.cleanup_host(host=self.host)
1182 
1183     def pre_start_hook(self):
1184         """After the service is initialized, but before we fully bring
1185         the service up by listening on RPC queues, make sure to update
1186         our available resources (and indirectly our available nodes).
1187         """
1188         self.update_available_resource(nova.context.get_admin_context(),
1189                                        startup=True)
1190 
1191     def _get_power_state(self, context, instance):
1192         """Retrieve the power state for the given instance."""
1193         LOG.debug('Checking state', instance=instance)
1194         try:
1195             return self.driver.get_info(instance).state
1196         except exception.InstanceNotFound:
1197             return power_state.NOSTATE
1198 
1199     def get_console_topic(self, context):
1200         """Retrieves the console host for a project on this host.
1201 
1202         Currently this is just set in the flags for each compute host.
1203 
1204         """
1205         # TODO(mdragon): perhaps make this variable by console_type?
1206         return '%s.%s' % (CONF.console_topic, CONF.console_host)
1207 
1208     @wrap_exception()
1209     def get_console_pool_info(self, context, console_type):
1210         return self.driver.get_console_pool_info(console_type)
1211 
1212     # NOTE(hanlind): This and the virt method it calls can be removed in
1213     # version 5.0 of the RPC API
1214     @wrap_exception()
1215     def refresh_security_group_rules(self, context, security_group_id):
1216         """Tell the virtualization driver to refresh security group rules.
1217 
1218         Passes straight through to the virtualization driver.
1219 
1220         """
1221         return self.driver.refresh_security_group_rules(security_group_id)
1222 
1223     # TODO(alaski): Remove object_compat for RPC version 5.0
1224     @object_compat
1225     @wrap_exception()
1226     def refresh_instance_security_rules(self, context, instance):
1227         """Tell the virtualization driver to refresh security rules for
1228         an instance.
1229 
1230         Passes straight through to the virtualization driver.
1231 
1232         Synchronize the call because we may still be in the middle of
1233         creating the instance.
1234         """
1235         @utils.synchronized(instance.uuid)
1236         def _sync_refresh():
1237             try:
1238                 return self.driver.refresh_instance_security_rules(instance)
1239             except NotImplementedError:
1240                 LOG.debug('Hypervisor driver does not support '
1241                           'security groups.', instance=instance)
1242 
1243         return _sync_refresh()
1244 
1245     def _await_block_device_map_created(self, context, vol_id):
1246         # TODO(yamahata): creating volume simultaneously
1247         #                 reduces creation time?
1248         # TODO(yamahata): eliminate dumb polling
1249         start = time.time()
1250         retries = CONF.block_device_allocate_retries
1251         if retries < 0:
1252             LOG.warning(_LW("Treating negative config value (%(retries)s) for "
1253                             "'block_device_retries' as 0."),
1254                         {'retries': retries})
1255         # (1) treat  negative config value as 0
1256         # (2) the configured value is 0, one attempt should be made
1257         # (3) the configured value is > 0, then the total number attempts
1258         #      is (retries + 1)
1259         attempts = 1
1260         if retries >= 1:
1261             attempts = retries + 1
1262         for attempt in range(1, attempts + 1):
1263             volume = self.volume_api.get(context, vol_id)
1264             volume_status = volume['status']
1265             if volume_status not in ['creating', 'downloading']:
1266                 if volume_status == 'available':
1267                     return attempt
1268                 LOG.warning(_LW("Volume id: %(vol_id)s finished being "
1269                                 "created but its status is %(vol_status)s."),
1270                             {'vol_id': vol_id,
1271                              'vol_status': volume_status})
1272                 break
1273             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1274         raise exception.VolumeNotCreated(volume_id=vol_id,
1275                                          seconds=int(time.time() - start),
1276                                          attempts=attempt,
1277                                          volume_status=volume_status)
1278 
1279     def _decode_files(self, injected_files):
1280         """Base64 decode the list of files to inject."""
1281         if not injected_files:
1282             return []
1283 
1284         def _decode(f):
1285             path, contents = f
1286             # Py3 raises binascii.Error instead of TypeError as in Py27
1287             try:
1288                 decoded = base64.b64decode(contents)
1289                 return path, decoded
1290             except (TypeError, binascii.Error):
1291                 raise exception.Base64Exception(path=path)
1292 
1293         return [_decode(f) for f in injected_files]
1294 
1295     def _validate_instance_group_policy(self, context, instance,
1296             filter_properties):
1297         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1298         # However, there is a race condition with the enforcement of
1299         # the policy.  Since more than one instance may be scheduled at the
1300         # same time, it's possible that more than one instance with an
1301         # anti-affinity policy may end up here.  It's also possible that
1302         # multiple instances with an affinity policy could end up on different
1303         # hosts.  This is a validation step to make sure that starting the
1304         # instance here doesn't violate the policy.
1305 
1306         scheduler_hints = filter_properties.get('scheduler_hints') or {}
1307         group_hint = scheduler_hints.get('group')
1308         if not group_hint:
1309             return
1310 
1311         @utils.synchronized(group_hint)
1312         def _do_validation(context, instance, group_hint):
1313             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1314             if 'anti-affinity' in group.policies:
1315                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1316                 if self.host in group_hosts:
1317                     msg = _("Anti-affinity instance group policy "
1318                             "was violated.")
1319                     raise exception.RescheduledException(
1320                             instance_uuid=instance.uuid,
1321                             reason=msg)
1322             elif 'affinity' in group.policies:
1323                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1324                 if group_hosts and self.host not in group_hosts:
1325                     msg = _("Affinity instance group policy was violated.")
1326                     raise exception.RescheduledException(
1327                             instance_uuid=instance.uuid,
1328                             reason=msg)
1329 
1330         _do_validation(context, instance, group_hint)
1331 
1332     def _log_original_error(self, exc_info, instance_uuid):
1333         LOG.error(_LE('Error: %s'), exc_info[1], instance_uuid=instance_uuid,
1334                   exc_info=exc_info)
1335 
1336     def _reschedule(self, context, request_spec, filter_properties,
1337             instance, reschedule_method, method_args, task_state,
1338             exc_info=None):
1339         """Attempt to re-schedule a compute operation."""
1340 
1341         instance_uuid = instance.uuid
1342         retry = filter_properties.get('retry')
1343         if not retry:
1344             # no retry information, do not reschedule.
1345             LOG.debug("Retry info not present, will not reschedule",
1346                       instance_uuid=instance_uuid)
1347             return
1348 
1349         if not request_spec:
1350             LOG.debug("No request spec, will not reschedule",
1351                       instance_uuid=instance_uuid)
1352             return
1353 
1354         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1355                   {'method': reschedule_method.__name__,
1356                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1357 
1358         # reset the task state:
1359         self._instance_update(context, instance, task_state=task_state)
1360 
1361         if exc_info:
1362             # stringify to avoid circular ref problem in json serialization:
1363             retry['exc'] = traceback.format_exception_only(exc_info[0],
1364                                     exc_info[1])
1365 
1366         reschedule_method(context, *method_args)
1367         return True
1368 
1369     @periodic_task.periodic_task
1370     def _check_instance_build_time(self, context):
1371         """Ensure that instances are not stuck in build."""
1372         timeout = CONF.instance_build_timeout
1373         if timeout == 0:
1374             return
1375 
1376         filters = {'vm_state': vm_states.BUILDING,
1377                    'host': self.host}
1378 
1379         building_insts = objects.InstanceList.get_by_filters(context,
1380                            filters, expected_attrs=[], use_slave=True)
1381 
1382         for instance in building_insts:
1383             if timeutils.is_older_than(instance.created_at, timeout):
1384                 self._set_instance_obj_error_state(context, instance)
1385                 LOG.warning(_LW("Instance build timed out. Set to error "
1386                                 "state."), instance=instance)
1387 
1388     def _check_instance_exists(self, context, instance):
1389         """Ensure an instance with the same name is not already present."""
1390         if self.driver.instance_exists(instance):
1391             raise exception.InstanceExists(name=instance.name)
1392 
1393     def _allocate_network_async(self, context, instance, requested_networks,
1394                                 macs, security_groups, is_vpn, dhcp_options):
1395         """Method used to allocate networks in the background.
1396 
1397         Broken out for testing.
1398         """
1399         # First check to see if we're specifically not supposed to allocate
1400         # networks because if so, we can exit early.
1401         if requested_networks and requested_networks.no_allocate:
1402             LOG.debug("Not allocating networking since 'none' was specified.",
1403                       instance=instance)
1404             return network_model.NetworkInfo([])
1405 
1406         LOG.debug("Allocating IP information in the background.",
1407                   instance=instance)
1408         retries = CONF.network_allocate_retries
1409         attempts = retries + 1
1410         retry_time = 1
1411         bind_host_id = self.driver.network_binding_host_id(context, instance)
1412         for attempt in range(1, attempts + 1):
1413             try:
1414                 nwinfo = self.network_api.allocate_for_instance(
1415                         context, instance, vpn=is_vpn,
1416                         requested_networks=requested_networks,
1417                         macs=macs,
1418                         security_groups=security_groups,
1419                         dhcp_options=dhcp_options,
1420                         bind_host_id=bind_host_id)
1421                 LOG.debug('Instance network_info: |%s|', nwinfo,
1422                           instance=instance)
1423                 instance.system_metadata['network_allocated'] = 'True'
1424                 # NOTE(JoshNang) do not save the instance here, as it can cause
1425                 # races. The caller shares a reference to instance and waits
1426                 # for this async greenthread to finish before calling
1427                 # instance.save().
1428                 return nwinfo
1429             except Exception:
1430                 exc_info = sys.exc_info()
1431                 log_info = {'attempt': attempt,
1432                             'attempts': attempts}
1433                 if attempt == attempts:
1434                     LOG.exception(_LE('Instance failed network setup '
1435                                       'after %(attempts)d attempt(s)'),
1436                                   log_info)
1437                     six.reraise(*exc_info)
1438                 LOG.warning(_LW('Instance failed network setup '
1439                                 '(attempt %(attempt)d of %(attempts)d)'),
1440                             log_info, instance=instance)
1441                 time.sleep(retry_time)
1442                 retry_time *= 2
1443                 if retry_time > 30:
1444                     retry_time = 30
1445         # Not reached.
1446 
1447     def _build_networks_for_instance(self, context, instance,
1448             requested_networks, security_groups):
1449 
1450         # If we're here from a reschedule the network may already be allocated.
1451         if strutils.bool_from_string(
1452                 instance.system_metadata.get('network_allocated', 'False')):
1453             # NOTE(alex_xu): The network_allocated is True means the network
1454             # resource already allocated at previous scheduling, and the
1455             # network setup is cleanup at previous. After rescheduling, the
1456             # network resource need setup on the new host.
1457             self.network_api.setup_instance_network_on_host(
1458                 context, instance, instance.host)
1459             return self.network_api.get_instance_nw_info(context, instance)
1460 
1461         if not self.is_neutron_security_groups:
1462             security_groups = []
1463 
1464         macs = self.driver.macs_for_instance(instance)
1465         dhcp_options = self.driver.dhcp_options_for_instance(instance)
1466         network_info = self._allocate_network(context, instance,
1467                 requested_networks, macs, security_groups, dhcp_options)
1468 
1469         return network_info
1470 
1471     def _allocate_network(self, context, instance, requested_networks, macs,
1472                           security_groups, dhcp_options):
1473         """Start network allocation asynchronously.  Return an instance
1474         of NetworkInfoAsyncWrapper that can be used to retrieve the
1475         allocated networks when the operation has finished.
1476         """
1477         # NOTE(comstud): Since we're allocating networks asynchronously,
1478         # this task state has little meaning, as we won't be in this
1479         # state for very long.
1480         instance.vm_state = vm_states.BUILDING
1481         instance.task_state = task_states.NETWORKING
1482         instance.save(expected_task_state=[None])
1483         self._update_resource_tracker(context, instance)
1484 
1485         is_vpn = pipelib.is_vpn_image(instance.image_ref)
1486         return network_model.NetworkInfoAsyncWrapper(
1487                 self._allocate_network_async, context, instance,
1488                 requested_networks, macs, security_groups, is_vpn,
1489                 dhcp_options)
1490 
1491     def _default_root_device_name(self, instance, image_meta, root_bdm):
1492         try:
1493             return self.driver.default_root_device_name(instance,
1494                                                         image_meta,
1495                                                         root_bdm)
1496         except NotImplementedError:
1497             return compute_utils.get_next_device_name(instance, [])
1498 
1499     def _default_device_names_for_instance(self, instance,
1500                                            root_device_name,
1501                                            *block_device_lists):
1502         try:
1503             self.driver.default_device_names_for_instance(instance,
1504                                                           root_device_name,
1505                                                           *block_device_lists)
1506         except NotImplementedError:
1507             compute_utils.default_device_names_for_instance(
1508                 instance, root_device_name, *block_device_lists)
1509 
1510     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1511         # NOTE(ndipanov): Copy obj to avoid changing the original
1512         block_device_obj = block_device_obj.obj_clone()
1513         try:
1514             return self.driver.get_device_name_for_instance(
1515                 instance, bdms, block_device_obj)
1516         except NotImplementedError:
1517             return compute_utils.get_device_name_for_instance(
1518                 instance, bdms, block_device_obj.get("device_name"))
1519 
1520     def _default_block_device_names(self, instance, image_meta, block_devices):
1521         """Verify that all the devices have the device_name set. If not,
1522         provide a default name.
1523 
1524         It also ensures that there is a root_device_name and is set to the
1525         first block device in the boot sequence (boot_index=0).
1526         """
1527         root_bdm = block_device.get_root_bdm(block_devices)
1528         if not root_bdm:
1529             return
1530 
1531         # Get the root_device_name from the root BDM or the instance
1532         root_device_name = None
1533         update_root_bdm = False
1534 
1535         if root_bdm.device_name:
1536             root_device_name = root_bdm.device_name
1537             instance.root_device_name = root_device_name
1538         elif instance.root_device_name:
1539             root_device_name = instance.root_device_name
1540             root_bdm.device_name = root_device_name
1541             update_root_bdm = True
1542         else:
1543             root_device_name = self._default_root_device_name(instance,
1544                                                               image_meta,
1545                                                               root_bdm)
1546 
1547             instance.root_device_name = root_device_name
1548             root_bdm.device_name = root_device_name
1549             update_root_bdm = True
1550 
1551         if update_root_bdm:
1552             root_bdm.save()
1553 
1554         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1555                             block_devices))
1556         swap = list(filter(block_device.new_format_is_swap,
1557                       block_devices))
1558         block_device_mapping = list(filter(
1559               driver_block_device.is_block_device_mapping, block_devices))
1560 
1561         self._default_device_names_for_instance(instance,
1562                                                 root_device_name,
1563                                                 ephemerals,
1564                                                 swap,
1565                                                 block_device_mapping)
1566 
1567     def _block_device_info_to_legacy(self, block_device_info):
1568         """Convert BDI to the old format for drivers that need it."""
1569 
1570         if self.use_legacy_block_device_info:
1571             ephemerals = driver_block_device.legacy_block_devices(
1572                 driver.block_device_info_get_ephemerals(block_device_info))
1573             mapping = driver_block_device.legacy_block_devices(
1574                 driver.block_device_info_get_mapping(block_device_info))
1575             swap = block_device_info['swap']
1576             if swap:
1577                 swap = swap.legacy()
1578 
1579             block_device_info.update({
1580                 'ephemerals': ephemerals,
1581                 'swap': swap,
1582                 'block_device_mapping': mapping})
1583 
1584     def _add_missing_dev_names(self, bdms, instance):
1585         for bdm in bdms:
1586             if bdm.device_name is not None:
1587                 continue
1588 
1589             device_name = self._get_device_name_for_instance(instance,
1590                                                              bdms, bdm)
1591             values = {'device_name': device_name}
1592             bdm.update(values)
1593             bdm.save()
1594 
1595     def _prep_block_device(self, context, instance, bdms):
1596         """Set up the block device for an instance with error logging."""
1597         try:
1598             self._add_missing_dev_names(bdms, instance)
1599             block_device_info = driver.get_block_device_info(instance, bdms)
1600             mapping = driver.block_device_info_get_mapping(block_device_info)
1601             driver_block_device.attach_block_devices(
1602                 mapping, context, instance, self.volume_api, self.driver,
1603                 wait_func=self._await_block_device_map_created)
1604 
1605             self._block_device_info_to_legacy(block_device_info)
1606             return block_device_info
1607 
1608         except exception.OverQuota:
1609             msg = _LW('Failed to create block device for instance due to '
1610                       'being over volume resource quota')
1611             LOG.warning(msg, instance=instance)
1612             raise exception.VolumeLimitExceeded()
1613 
1614         except Exception:
1615             LOG.exception(_LE('Instance failed block device setup'),
1616                           instance=instance)
1617             raise exception.InvalidBDM()
1618 
1619     def _update_instance_after_spawn(self, context, instance):
1620         instance.power_state = self._get_power_state(context, instance)
1621         instance.vm_state = vm_states.ACTIVE
1622         instance.task_state = None
1623         instance.launched_at = timeutils.utcnow()
1624         configdrive.update_instance(instance)
1625 
1626     def _update_scheduler_instance_info(self, context, instance):
1627         """Sends an InstanceList with created or updated Instance objects to
1628         the Scheduler client.
1629 
1630         In the case of init_host, the value passed will already be an
1631         InstanceList. Other calls will send individual Instance objects that
1632         have been created or resized. In this case, we create an InstanceList
1633         object containing that Instance.
1634         """
1635         if not self.send_instance_updates:
1636             return
1637         if isinstance(instance, obj_instance.Instance):
1638             instance = objects.InstanceList(objects=[instance])
1639         context = context.elevated()
1640         self.scheduler_client.update_instance_info(context, self.host,
1641                                                    instance)
1642 
1643     def _delete_scheduler_instance_info(self, context, instance_uuid):
1644         """Sends the uuid of the deleted Instance to the Scheduler client."""
1645         if not self.send_instance_updates:
1646             return
1647         context = context.elevated()
1648         self.scheduler_client.delete_instance_info(context, self.host,
1649                                                    instance_uuid)
1650 
1651     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1652     def _sync_scheduler_instance_info(self, context):
1653         if not self.send_instance_updates:
1654             return
1655         context = context.elevated()
1656         instances = objects.InstanceList.get_by_host(context, self.host,
1657                                                      expected_attrs=[],
1658                                                      use_slave=True)
1659         uuids = [instance.uuid for instance in instances]
1660         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1661 
1662     def _notify_about_instance_usage(self, context, instance, event_suffix,
1663                                      network_info=None, system_metadata=None,
1664                                      extra_usage_info=None, fault=None):
1665         compute_utils.notify_about_instance_usage(
1666             self.notifier, context, instance, event_suffix,
1667             network_info=network_info,
1668             system_metadata=system_metadata,
1669             extra_usage_info=extra_usage_info, fault=fault)
1670 
1671     def _deallocate_network(self, context, instance,
1672                             requested_networks=None):
1673         # If we were told not to allocate networks let's save ourselves
1674         # the trouble of calling the network API.
1675         if requested_networks and requested_networks.no_allocate:
1676             LOG.debug("Skipping network deallocation for instance since "
1677                       "networking was not requested.", instance=instance)
1678             return
1679 
1680         LOG.debug('Deallocating network for instance', instance=instance)
1681         with timeutils.StopWatch() as timer:
1682             self.network_api.deallocate_for_instance(
1683                 context, instance, requested_networks=requested_networks)
1684         # nova-network does an rpc call so we're OK tracking time spent here
1685         LOG.info(_LI('Took %0.2f seconds to deallocate network for instance.'),
1686                  timer.elapsed(), instance=instance)
1687 
1688     def _get_instance_block_device_info(self, context, instance,
1689                                         refresh_conn_info=False,
1690                                         bdms=None):
1691         """Transform block devices to the driver block_device format."""
1692 
1693         if not bdms:
1694             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1695                     context, instance.uuid)
1696         block_device_info = driver.get_block_device_info(instance, bdms)
1697 
1698         if not refresh_conn_info:
1699             # if the block_device_mapping has no value in connection_info
1700             # (returned as None), don't include in the mapping
1701             block_device_info['block_device_mapping'] = [
1702                 bdm for bdm in driver.block_device_info_get_mapping(
1703                                     block_device_info)
1704                 if bdm.get('connection_info')]
1705         else:
1706             driver_block_device.refresh_conn_infos(
1707                 driver.block_device_info_get_mapping(block_device_info),
1708                 context, instance, self.volume_api, self.driver)
1709 
1710         self._block_device_info_to_legacy(block_device_info)
1711 
1712         return block_device_info
1713 
1714     @wrap_exception()
1715     @reverts_task_state
1716     @wrap_instance_fault
1717     def build_and_run_instance(self, context, instance, image, request_spec,
1718                      filter_properties, admin_password=None,
1719                      injected_files=None, requested_networks=None,
1720                      security_groups=None, block_device_mapping=None,
1721                      node=None, limits=None):
1722 
1723         @utils.synchronized(instance.uuid)
1724         def _locked_do_build_and_run_instance(*args, **kwargs):
1725             # NOTE(danms): We grab the semaphore with the instance uuid
1726             # locked because we could wait in line to build this instance
1727             # for a while and we want to make sure that nothing else tries
1728             # to do anything with this instance while we wait.
1729             with self._build_semaphore:
1730                 self._do_build_and_run_instance(*args, **kwargs)
1731 
1732         # NOTE(danms): We spawn here to return the RPC worker thread back to
1733         # the pool. Since what follows could take a really long time, we don't
1734         # want to tie up RPC workers.
1735         utils.spawn_n(_locked_do_build_and_run_instance,
1736                       context, instance, image, request_spec,
1737                       filter_properties, admin_password, injected_files,
1738                       requested_networks, security_groups,
1739                       block_device_mapping, node, limits)
1740 
1741     def _check_device_tagging(self, requested_networks, block_device_mapping):
1742         tagging_requested = False
1743         if requested_networks:
1744             for net in requested_networks:
1745                 if 'tag' in net and net.tag is not None:
1746                     tagging_requested = True
1747                     break
1748         if block_device_mapping and not tagging_requested:
1749             for bdm in block_device_mapping:
1750                 if 'tag' in bdm and bdm.tag is not None:
1751                     tagging_requested = True
1752                     break
1753         if (tagging_requested and
1754                 not self.driver.capabilities.get('supports_device_tagging')):
1755             raise exception.BuildAbortException('Attempt to boot guest with '
1756                                                 'tagged devices on host that '
1757                                                 'does not support tagging.')
1758 
1759     @hooks.add_hook('build_instance')
1760     @wrap_exception()
1761     @reverts_task_state
1762     @wrap_instance_event(prefix='compute')
1763     @wrap_instance_fault
1764     def _do_build_and_run_instance(self, context, instance, image,
1765             request_spec, filter_properties, admin_password, injected_files,
1766             requested_networks, security_groups, block_device_mapping,
1767             node=None, limits=None):
1768 
1769         try:
1770             LOG.debug('Starting instance...', instance=instance)
1771             instance.vm_state = vm_states.BUILDING
1772             instance.task_state = None
1773             instance.save(expected_task_state=
1774                     (task_states.SCHEDULING, None))
1775         except exception.InstanceNotFound:
1776             msg = 'Instance disappeared before build.'
1777             LOG.debug(msg, instance=instance)
1778             return build_results.FAILED
1779         except exception.UnexpectedTaskStateError as e:
1780             LOG.debug(e.format_message(), instance=instance)
1781             return build_results.FAILED
1782 
1783         # b64 decode the files to inject:
1784         decoded_files = self._decode_files(injected_files)
1785 
1786         if limits is None:
1787             limits = {}
1788 
1789         if node is None:
1790             node = self.driver.get_available_nodes(refresh=True)[0]
1791             LOG.debug('No node specified, defaulting to %s', node,
1792                       instance=instance)
1793 
1794         try:
1795             with timeutils.StopWatch() as timer:
1796                 self._build_and_run_instance(context, instance, image,
1797                         decoded_files, admin_password, requested_networks,
1798                         security_groups, block_device_mapping, node, limits,
1799                         filter_properties)
1800             LOG.info(_LI('Took %0.2f seconds to build instance.'),
1801                      timer.elapsed(), instance=instance)
1802             return build_results.ACTIVE
1803         except exception.RescheduledException as e:
1804             retry = filter_properties.get('retry')
1805             if not retry:
1806                 # no retry information, do not reschedule.
1807                 LOG.debug("Retry info not present, will not reschedule",
1808                     instance=instance)
1809                 self._cleanup_allocated_networks(context, instance,
1810                     requested_networks)
1811                 compute_utils.add_instance_fault_from_exc(context,
1812                         instance, e, sys.exc_info(),
1813                         fault_message=e.kwargs['reason'])
1814                 self._nil_out_instance_obj_host_and_node(instance)
1815                 self._set_instance_obj_error_state(context, instance,
1816                                                    clean_task_state=True)
1817                 return build_results.FAILED
1818             LOG.debug(e.format_message(), instance=instance)
1819             # This will be used for logging the exception
1820             retry['exc'] = traceback.format_exception(*sys.exc_info())
1821             # This will be used for setting the instance fault message
1822             retry['exc_reason'] = e.kwargs['reason']
1823             # NOTE(comstud): Deallocate networks if the driver wants
1824             # us to do so.
1825             # NOTE(vladikr): SR-IOV ports should be deallocated to
1826             # allow new sriov pci devices to be allocated on a new host.
1827             # Otherwise, if devices with pci addresses are already allocated
1828             # on the destination host, the instance will fail to spawn.
1829             # info_cache.network_info should be present at this stage.
1830             if (self.driver.deallocate_networks_on_reschedule(instance) or
1831                 self.deallocate_sriov_ports_on_reschedule(instance)):
1832                 self._cleanup_allocated_networks(context, instance,
1833                         requested_networks)
1834             else:
1835                 # NOTE(alex_xu): Network already allocated and we don't
1836                 # want to deallocate them before rescheduling. But we need
1837                 # to cleanup those network resources setup on this host before
1838                 # rescheduling.
1839                 self.network_api.cleanup_instance_network_on_host(
1840                     context, instance, self.host)
1841 
1842             self._nil_out_instance_obj_host_and_node(instance)
1843             instance.task_state = task_states.SCHEDULING
1844             instance.save()
1845 
1846             self.compute_task_api.build_instances(context, [instance],
1847                     image, filter_properties, admin_password,
1848                     injected_files, requested_networks, security_groups,
1849                     block_device_mapping)
1850             return build_results.RESCHEDULED
1851         except (exception.InstanceNotFound,
1852                 exception.UnexpectedDeletingTaskStateError):
1853             msg = 'Instance disappeared during build.'
1854             LOG.debug(msg, instance=instance)
1855             self._cleanup_allocated_networks(context, instance,
1856                     requested_networks)
1857             return build_results.FAILED
1858         except exception.BuildAbortException as e:
1859             LOG.exception(e.format_message(), instance=instance)
1860             self._cleanup_allocated_networks(context, instance,
1861                     requested_networks)
1862             self._cleanup_volumes(context, instance.uuid,
1863                     block_device_mapping, raise_exc=False)
1864             compute_utils.add_instance_fault_from_exc(context, instance,
1865                     e, sys.exc_info())
1866             self._nil_out_instance_obj_host_and_node(instance)
1867             self._set_instance_obj_error_state(context, instance,
1868                                                clean_task_state=True)
1869             return build_results.FAILED
1870         except Exception as e:
1871             # Should not reach here.
1872             msg = _LE('Unexpected build failure, not rescheduling build.')
1873             LOG.exception(msg, instance=instance)
1874             self._cleanup_allocated_networks(context, instance,
1875                     requested_networks)
1876             self._cleanup_volumes(context, instance.uuid,
1877                     block_device_mapping, raise_exc=False)
1878             compute_utils.add_instance_fault_from_exc(context, instance,
1879                     e, sys.exc_info())
1880             self._nil_out_instance_obj_host_and_node(instance)
1881             self._set_instance_obj_error_state(context, instance,
1882                                                clean_task_state=True)
1883             return build_results.FAILED
1884 
1885     def deallocate_sriov_ports_on_reschedule(self, instance):
1886         """Determine if networks are needed to be deallocated before reschedule
1887 
1888         Check the cached network info for any assigned SR-IOV ports.
1889         SR-IOV ports should be deallocated prior to rescheduling
1890         in order to allow new sriov pci devices to be allocated on a new host.
1891         """
1892         info_cache = instance.info_cache
1893 
1894         def _has_sriov_port(vif):
1895             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1896 
1897         if (info_cache and info_cache.network_info):
1898             for vif in info_cache.network_info:
1899                 if _has_sriov_port(vif):
1900                     return True
1901         return False
1902 
1903     def _build_and_run_instance(self, context, instance, image, injected_files,
1904             admin_password, requested_networks, security_groups,
1905             block_device_mapping, node, limits, filter_properties):
1906 
1907         image_name = image.get('name')
1908         self._notify_about_instance_usage(context, instance, 'create.start',
1909                 extra_usage_info={'image_name': image_name})
1910         compute_utils.notify_about_instance_action(
1911             context, instance, self.host,
1912             action=fields.NotificationAction.CREATE,
1913             phase=fields.NotificationPhase.START)
1914 
1915         # NOTE(mikal): cache the keystone roles associated with the instance
1916         # at boot time for later reference
1917         instance.system_metadata.update(
1918             {'boot_roles': ','.join(context.roles)})
1919 
1920         self._check_device_tagging(requested_networks, block_device_mapping)
1921 
1922         try:
1923             rt = self._get_resource_tracker()
1924             with rt.instance_claim(context, instance, node, limits):
1925                 # NOTE(russellb) It's important that this validation be done
1926                 # *after* the resource tracker instance claim, as that is where
1927                 # the host is set on the instance.
1928                 self._validate_instance_group_policy(context, instance,
1929                         filter_properties)
1930                 image_meta = objects.ImageMeta.from_dict(image)
1931                 with self._build_resources(context, instance,
1932                         requested_networks, security_groups, image_meta,
1933                         block_device_mapping) as resources:
1934                     instance.vm_state = vm_states.BUILDING
1935                     instance.task_state = task_states.SPAWNING
1936                     # NOTE(JoshNang) This also saves the changes to the
1937                     # instance from _allocate_network_async, as they aren't
1938                     # saved in that function to prevent races.
1939                     instance.save(expected_task_state=
1940                             task_states.BLOCK_DEVICE_MAPPING)
1941                     block_device_info = resources['block_device_info']
1942                     network_info = resources['network_info']
1943                     LOG.debug('Start spawning the instance on the hypervisor.',
1944                               instance=instance)
1945                     with timeutils.StopWatch() as timer:
1946                         self.driver.spawn(context, instance, image_meta,
1947                                           injected_files, admin_password,
1948                                           network_info=network_info,
1949                                           block_device_info=block_device_info)
1950                     LOG.info(_LI('Took %0.2f seconds to spawn the instance on '
1951                                  'the hypervisor.'), timer.elapsed(),
1952                              instance=instance)
1953         except (exception.InstanceNotFound,
1954                 exception.UnexpectedDeletingTaskStateError) as e:
1955             with excutils.save_and_reraise_exception():
1956                 self._notify_about_instance_usage(context, instance,
1957                     'create.error', fault=e)
1958                 compute_utils.notify_about_instance_action(
1959                     context, instance, self.host,
1960                     action=fields.NotificationAction.CREATE,
1961                     phase=fields.NotificationPhase.ERROR, exception=e)
1962         except exception.ComputeResourcesUnavailable as e:
1963             LOG.debug(e.format_message(), instance=instance)
1964             self._notify_about_instance_usage(context, instance,
1965                     'create.error', fault=e)
1966             compute_utils.notify_about_instance_action(
1967                     context, instance, self.host,
1968                     action=fields.NotificationAction.CREATE,
1969                     phase=fields.NotificationPhase.ERROR, exception=e)
1970             raise exception.RescheduledException(
1971                     instance_uuid=instance.uuid, reason=e.format_message())
1972         except exception.BuildAbortException as e:
1973             with excutils.save_and_reraise_exception():
1974                 LOG.debug(e.format_message(), instance=instance)
1975                 self._notify_about_instance_usage(context, instance,
1976                     'create.error', fault=e)
1977                 compute_utils.notify_about_instance_action(
1978                     context, instance, self.host,
1979                     action=fields.NotificationAction.CREATE,
1980                     phase=fields.NotificationPhase.ERROR, exception=e)
1981         except (exception.FixedIpLimitExceeded,
1982                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
1983             LOG.warning(_LW('No more network or fixed IP to be allocated'),
1984                         instance=instance)
1985             self._notify_about_instance_usage(context, instance,
1986                     'create.error', fault=e)
1987             compute_utils.notify_about_instance_action(
1988                     context, instance, self.host,
1989                     action=fields.NotificationAction.CREATE,
1990                     phase=fields.NotificationPhase.ERROR, exception=e)
1991             msg = _('Failed to allocate the network(s) with error %s, '
1992                     'not rescheduling.') % e.format_message()
1993             raise exception.BuildAbortException(instance_uuid=instance.uuid,
1994                     reason=msg)
1995         except (exception.VirtualInterfaceCreateException,
1996                 exception.VirtualInterfaceMacAddressException,
1997                 exception.FixedIpInvalidOnHost,
1998                 exception.UnableToAutoAllocateNetwork) as e:
1999             LOG.exception(_LE('Failed to allocate network(s)'),
2000                           instance=instance)
2001             self._notify_about_instance_usage(context, instance,
2002                     'create.error', fault=e)
2003             compute_utils.notify_about_instance_action(
2004                     context, instance, self.host,
2005                     action=fields.NotificationAction.CREATE,
2006                     phase=fields.NotificationPhase.ERROR, exception=e)
2007             msg = _('Failed to allocate the network(s), not rescheduling.')
2008             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2009                     reason=msg)
2010         except (exception.FlavorDiskTooSmall,
2011                 exception.FlavorMemoryTooSmall,
2012                 exception.ImageNotActive,
2013                 exception.ImageUnacceptable,
2014                 exception.InvalidDiskInfo,
2015                 exception.InvalidDiskFormat,
2016                 exception.SignatureVerificationError,
2017                 exception.VolumeEncryptionNotSupported,
2018                 exception.InvalidInput) as e:
2019             self._notify_about_instance_usage(context, instance,
2020                     'create.error', fault=e)
2021             compute_utils.notify_about_instance_action(
2022                     context, instance, self.host,
2023                     action=fields.NotificationAction.CREATE,
2024                     phase=fields.NotificationPhase.ERROR, exception=e)
2025             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2026                     reason=e.format_message())
2027         except Exception as e:
2028             self._notify_about_instance_usage(context, instance,
2029                     'create.error', fault=e)
2030             compute_utils.notify_about_instance_action(
2031                     context, instance, self.host,
2032                     action=fields.NotificationAction.CREATE,
2033                     phase=fields.NotificationPhase.ERROR, exception=e)
2034             raise exception.RescheduledException(
2035                     instance_uuid=instance.uuid, reason=six.text_type(e))
2036 
2037         # NOTE(alaski): This is only useful during reschedules, remove it now.
2038         instance.system_metadata.pop('network_allocated', None)
2039 
2040         # If CONF.default_access_ip_network_name is set, grab the
2041         # corresponding network and set the access ip values accordingly.
2042         network_name = CONF.default_access_ip_network_name
2043         if (network_name and not instance.access_ip_v4 and
2044                 not instance.access_ip_v6):
2045             # Note that when there are multiple ips to choose from, an
2046             # arbitrary one will be chosen.
2047             for vif in network_info:
2048                 if vif['network']['label'] == network_name:
2049                     for ip in vif.fixed_ips():
2050                         if not instance.access_ip_v4 and ip['version'] == 4:
2051                             instance.access_ip_v4 = ip['address']
2052                         if not instance.access_ip_v6 and ip['version'] == 6:
2053                             instance.access_ip_v6 = ip['address']
2054                     break
2055 
2056         self._update_instance_after_spawn(context, instance)
2057 
2058         try:
2059             instance.save(expected_task_state=task_states.SPAWNING)
2060         except (exception.InstanceNotFound,
2061                 exception.UnexpectedDeletingTaskStateError) as e:
2062             with excutils.save_and_reraise_exception():
2063                 self._notify_about_instance_usage(context, instance,
2064                     'create.error', fault=e)
2065                 compute_utils.notify_about_instance_action(
2066                     context, instance, self.host,
2067                     action=fields.NotificationAction.CREATE,
2068                     phase=fields.NotificationPhase.ERROR, exception=e)
2069 
2070         self._update_scheduler_instance_info(context, instance)
2071         self._notify_about_instance_usage(context, instance, 'create.end',
2072                 extra_usage_info={'message': _('Success')},
2073                 network_info=network_info)
2074         compute_utils.notify_about_instance_action(context, instance,
2075                 self.host, action=fields.NotificationAction.CREATE,
2076                 phase=fields.NotificationPhase.END)
2077 
2078     @contextlib.contextmanager
2079     def _build_resources(self, context, instance, requested_networks,
2080                          security_groups, image_meta, block_device_mapping):
2081         resources = {}
2082         network_info = None
2083         try:
2084             LOG.debug('Start building networks asynchronously for instance.',
2085                       instance=instance)
2086             network_info = self._build_networks_for_instance(context, instance,
2087                     requested_networks, security_groups)
2088             resources['network_info'] = network_info
2089         except (exception.InstanceNotFound,
2090                 exception.UnexpectedDeletingTaskStateError):
2091             raise
2092         except exception.UnexpectedTaskStateError as e:
2093             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2094                     reason=e.format_message())
2095         except Exception:
2096             # Because this allocation is async any failures are likely to occur
2097             # when the driver accesses network_info during spawn().
2098             LOG.exception(_LE('Failed to allocate network(s)'),
2099                           instance=instance)
2100             msg = _('Failed to allocate the network(s), not rescheduling.')
2101             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2102                     reason=msg)
2103 
2104         try:
2105             # Verify that all the BDMs have a device_name set and assign a
2106             # default to the ones missing it with the help of the driver.
2107             self._default_block_device_names(instance, image_meta,
2108                                              block_device_mapping)
2109 
2110             LOG.debug('Start building block device mappings for instance.',
2111                       instance=instance)
2112             instance.vm_state = vm_states.BUILDING
2113             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2114             instance.save()
2115 
2116             block_device_info = self._prep_block_device(context, instance,
2117                     block_device_mapping)
2118             resources['block_device_info'] = block_device_info
2119         except (exception.InstanceNotFound,
2120                 exception.UnexpectedDeletingTaskStateError):
2121             with excutils.save_and_reraise_exception():
2122                 # Make sure the async call finishes
2123                 if network_info is not None:
2124                     network_info.wait(do_raise=False)
2125         except (exception.UnexpectedTaskStateError,
2126                 exception.VolumeLimitExceeded,
2127                 exception.InvalidBDM) as e:
2128             # Make sure the async call finishes
2129             if network_info is not None:
2130                 network_info.wait(do_raise=False)
2131             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2132                     reason=e.format_message())
2133         except Exception:
2134             LOG.exception(_LE('Failure prepping block device'),
2135                     instance=instance)
2136             # Make sure the async call finishes
2137             if network_info is not None:
2138                 network_info.wait(do_raise=False)
2139             msg = _('Failure prepping block device.')
2140             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2141                     reason=msg)
2142 
2143         try:
2144             yield resources
2145         except Exception as exc:
2146             with excutils.save_and_reraise_exception() as ctxt:
2147                 if not isinstance(exc, (
2148                         exception.InstanceNotFound,
2149                         exception.UnexpectedDeletingTaskStateError)):
2150                     LOG.exception(_LE('Instance failed to spawn'),
2151                                   instance=instance)
2152                 # Make sure the async call finishes
2153                 if network_info is not None:
2154                     network_info.wait(do_raise=False)
2155                 # if network_info is empty we're likely here because of
2156                 # network allocation failure. Since nothing can be reused on
2157                 # rescheduling it's better to deallocate network to eliminate
2158                 # the chance of orphaned ports in neutron
2159                 deallocate_networks = False if network_info else True
2160                 try:
2161                     self._shutdown_instance(context, instance,
2162                             block_device_mapping, requested_networks,
2163                             try_deallocate_networks=deallocate_networks)
2164                 except Exception as exc2:
2165                     ctxt.reraise = False
2166                     LOG.warning(_LW('Could not clean up failed build,'
2167                                     ' not rescheduling. Error: %s'),
2168                                 six.text_type(exc2))
2169                     raise exception.BuildAbortException(
2170                             instance_uuid=instance.uuid,
2171                             reason=six.text_type(exc))
2172 
2173     def _cleanup_allocated_networks(self, context, instance,
2174             requested_networks):
2175         try:
2176             self._deallocate_network(context, instance, requested_networks)
2177         except Exception:
2178             msg = _LE('Failed to deallocate networks')
2179             LOG.exception(msg, instance=instance)
2180             return
2181 
2182         instance.system_metadata['network_allocated'] = 'False'
2183         try:
2184             instance.save()
2185         except exception.InstanceNotFound:
2186             # NOTE(alaski): It's possible that we're cleaning up the networks
2187             # because the instance was deleted.  If that's the case then this
2188             # exception will be raised by instance.save()
2189             pass
2190 
2191     def _try_deallocate_network(self, context, instance,
2192                                 requested_networks=None):
2193         try:
2194             # tear down allocated network structure
2195             self._deallocate_network(context, instance, requested_networks)
2196         except Exception as ex:
2197             with excutils.save_and_reraise_exception():
2198                 LOG.error(_LE('Failed to deallocate network for instance. '
2199                               'Error: %s'), ex,
2200                           instance=instance)
2201                 self._set_instance_obj_error_state(context, instance)
2202 
2203     def _get_power_off_values(self, context, instance, clean_shutdown):
2204         """Get the timing configuration for powering down this instance."""
2205         if clean_shutdown:
2206             timeout = compute_utils.get_value_from_system_metadata(instance,
2207                           key='image_os_shutdown_timeout', type=int,
2208                           default=CONF.shutdown_timeout)
2209             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2210         else:
2211             timeout = 0
2212             retry_interval = 0
2213 
2214         return timeout, retry_interval
2215 
2216     def _power_off_instance(self, context, instance, clean_shutdown=True):
2217         """Power off an instance on this host."""
2218         timeout, retry_interval = self._get_power_off_values(context,
2219                                         instance, clean_shutdown)
2220         self.driver.power_off(instance, timeout, retry_interval)
2221 
2222     def _shutdown_instance(self, context, instance,
2223                            bdms, requested_networks=None, notify=True,
2224                            try_deallocate_networks=True):
2225         """Shutdown an instance on this host.
2226 
2227         :param:context: security context
2228         :param:instance: a nova.objects.Instance object
2229         :param:bdms: the block devices for the instance to be torn
2230                      down
2231         :param:requested_networks: the networks on which the instance
2232                                    has ports
2233         :param:notify: true if a final usage notification should be
2234                        emitted
2235         :param:try_deallocate_networks: false if we should avoid
2236                                         trying to teardown networking
2237         """
2238         context = context.elevated()
2239         LOG.info(_LI('Terminating instance'), instance=instance)
2240 
2241         if notify:
2242             self._notify_about_instance_usage(context, instance,
2243                                               "shutdown.start")
2244             compute_utils.notify_about_instance_action(context, instance,
2245                     self.host, action=fields.NotificationAction.SHUTDOWN,
2246                     phase=fields.NotificationPhase.START)
2247 
2248         network_info = compute_utils.get_nw_info_for_instance(instance)
2249 
2250         # NOTE(vish) get bdms before destroying the instance
2251         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2252         block_device_info = self._get_instance_block_device_info(
2253             context, instance, bdms=bdms)
2254 
2255         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2256         #                want to keep ip allocated for certain failures
2257         timer = timeutils.StopWatch()
2258         try:
2259             LOG.debug('Start destroying the instance on the hypervisor.',
2260                       instance=instance)
2261             timer.start()
2262             self.driver.destroy(context, instance, network_info,
2263                     block_device_info)
2264             LOG.info(_LI('Took %0.2f seconds to destroy the instance on the '
2265                          'hypervisor.'), timer.elapsed(), instance=instance)
2266         except exception.InstancePowerOffFailure:
2267             # if the instance can't power off, don't release the ip
2268             with excutils.save_and_reraise_exception():
2269                 pass
2270         except Exception:
2271             with excutils.save_and_reraise_exception():
2272                 # deallocate ip and fail without proceeding to
2273                 # volume api calls, preserving current behavior
2274                 if try_deallocate_networks:
2275                     self._try_deallocate_network(context, instance,
2276                                                  requested_networks)
2277 
2278         if try_deallocate_networks:
2279             self._try_deallocate_network(context, instance, requested_networks)
2280 
2281         timer.restart()
2282         for bdm in vol_bdms:
2283             try:
2284                 # NOTE(vish): actual driver detach done in driver.destroy, so
2285                 #             just tell cinder that we are done with it.
2286                 connector = self.driver.get_volume_connector(instance)
2287                 self.volume_api.terminate_connection(context,
2288                                                      bdm.volume_id,
2289                                                      connector)
2290                 self.volume_api.detach(context, bdm.volume_id, instance.uuid)
2291             except exception.DiskNotFound as exc:
2292                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2293                           instance=instance)
2294             except exception.VolumeNotFound as exc:
2295                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2296                           instance=instance)
2297             except (cinder_exception.EndpointNotFound,
2298                     keystone_exception.EndpointNotFound) as exc:
2299                 LOG.warning(_LW('Ignoring EndpointNotFound for '
2300                                 'volume %(volume_id)s: %(exc)s'),
2301                             {'exc': exc, 'volume_id': bdm.volume_id},
2302                             instance=instance)
2303             except cinder_exception.ClientException as exc:
2304                 LOG.warning(_LW('Ignoring unknown cinder exception for '
2305                                 'volume %(volume_id)s: %(exc)s'),
2306                             {'exc': exc, 'volume_id': bdm.volume_id},
2307                             instance=instance)
2308             except Exception as exc:
2309                 LOG.warning(_LW('Ignoring unknown exception for '
2310                                 'volume %(volume_id)s: %(exc)s'),
2311                             {'exc': exc, 'volume_id': bdm.volume_id},
2312                             instance=instance)
2313         if vol_bdms:
2314             LOG.info(_LI('Took %(time).2f seconds to detach %(num)s volumes '
2315                          'for instance.'),
2316                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2317                      instance=instance)
2318 
2319         if notify:
2320             self._notify_about_instance_usage(context, instance,
2321                                               "shutdown.end")
2322             compute_utils.notify_about_instance_action(context, instance,
2323                     self.host, action=fields.NotificationAction.SHUTDOWN,
2324                     phase=fields.NotificationPhase.END)
2325 
2326     def _cleanup_volumes(self, context, instance_uuid, bdms, raise_exc=True):
2327         exc_info = None
2328 
2329         for bdm in bdms:
2330             LOG.debug("terminating bdm %s", bdm,
2331                       instance_uuid=instance_uuid)
2332             if bdm.volume_id and bdm.delete_on_termination:
2333                 try:
2334                     self.volume_api.delete(context, bdm.volume_id)
2335                 except Exception as exc:
2336                     exc_info = sys.exc_info()
2337                     LOG.warning(_LW('Failed to delete volume: %(volume_id)s '
2338                                     'due to %(exc)s'),
2339                                 {'volume_id': bdm.volume_id, 'exc': exc})
2340         if exc_info is not None and raise_exc:
2341             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2342 
2343     @hooks.add_hook("delete_instance")
2344     def _delete_instance(self, context, instance, bdms, quotas):
2345         """Delete an instance on this host.  Commit or rollback quotas
2346         as necessary.
2347 
2348         :param context: nova request context
2349         :param instance: nova.objects.instance.Instance object
2350         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2351         :param quotas: nova.objects.quotas.Quotas object
2352         """
2353         was_soft_deleted = instance.vm_state == vm_states.SOFT_DELETED
2354         if was_soft_deleted:
2355             # Instances in SOFT_DELETED vm_state have already had quotas
2356             # decremented.
2357             try:
2358                 quotas.rollback()
2359             except Exception:
2360                 pass
2361 
2362         try:
2363             events = self.instance_events.clear_events_for_instance(instance)
2364             if events:
2365                 LOG.debug('Events pending at deletion: %(events)s',
2366                           {'events': ','.join(events.keys())},
2367                           instance=instance)
2368             self._notify_about_instance_usage(context, instance,
2369                                               "delete.start")
2370             compute_utils.notify_about_instance_action(context, instance,
2371                     self.host, action=fields.NotificationAction.DELETE,
2372                     phase=fields.NotificationPhase.START)
2373 
2374             self._shutdown_instance(context, instance, bdms)
2375             # NOTE(dims): instance.info_cache.delete() should be called after
2376             # _shutdown_instance in the compute manager as shutdown calls
2377             # deallocate_for_instance so the info_cache is still needed
2378             # at this point.
2379             if instance.info_cache is not None:
2380                 instance.info_cache.delete()
2381             else:
2382                 # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2383                 # is None. When the root cause that instance.info_cache becomes
2384                 # None is fixed, the log level should be reconsidered.
2385                 LOG.warning(_LW("Info cache for instance could not be found. "
2386                                 "Ignore."), instance=instance)
2387 
2388             # NOTE(vish): We have already deleted the instance, so we have
2389             #             to ignore problems cleaning up the volumes. It
2390             #             would be nice to let the user know somehow that
2391             #             the volume deletion failed, but it is not
2392             #             acceptable to have an instance that can not be
2393             #             deleted. Perhaps this could be reworked in the
2394             #             future to set an instance fault the first time
2395             #             and to only ignore the failure if the instance
2396             #             is already in ERROR.
2397             self._cleanup_volumes(context, instance.uuid, bdms,
2398                     raise_exc=False)
2399             # if a delete task succeeded, always update vm state and task
2400             # state without expecting task state to be DELETING
2401             instance.vm_state = vm_states.DELETED
2402             instance.task_state = None
2403             instance.power_state = power_state.NOSTATE
2404             instance.terminated_at = timeutils.utcnow()
2405             instance.save()
2406             system_meta = instance.system_metadata
2407             instance.destroy()
2408         except Exception:
2409             with excutils.save_and_reraise_exception():
2410                 quotas.rollback()
2411 
2412         self._complete_deletion(context,
2413                                 instance,
2414                                 bdms,
2415                                 quotas,
2416                                 system_meta)
2417 
2418     @wrap_exception()
2419     @reverts_task_state
2420     @wrap_instance_event(prefix='compute')
2421     @wrap_instance_fault
2422     def terminate_instance(self, context, instance, bdms, reservations):
2423         """Terminate an instance on this host."""
2424         quotas = objects.Quotas.from_reservations(context,
2425                                                   reservations,
2426                                                   instance=instance)
2427 
2428         @utils.synchronized(instance.uuid)
2429         def do_terminate_instance(instance, bdms):
2430             # NOTE(mriedem): If we are deleting the instance while it was
2431             # booting from volume, we could be racing with a database update of
2432             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2433             # to compute here, the BDMs may be stale at this point. So check
2434             # for any volume BDMs that don't have volume_id set and if we
2435             # detect that, we need to refresh the BDM list before proceeding.
2436             # TODO(mriedem): Move this into _delete_instance and make the bdms
2437             # parameter optional.
2438             for bdm in list(bdms):
2439                 if bdm.is_volume and not bdm.volume_id:
2440                     LOG.debug('There are potentially stale BDMs during '
2441                               'delete, refreshing the BlockDeviceMappingList.',
2442                               instance=instance)
2443                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2444                         context, instance.uuid)
2445                     break
2446             try:
2447                 self._delete_instance(context, instance, bdms, quotas)
2448             except exception.InstanceNotFound:
2449                 LOG.info(_LI("Instance disappeared during terminate"),
2450                          instance=instance)
2451             except Exception:
2452                 # As we're trying to delete always go to Error if something
2453                 # goes wrong that _delete_instance can't handle.
2454                 with excutils.save_and_reraise_exception():
2455                     LOG.exception(_LE('Setting instance vm_state to ERROR'),
2456                                   instance=instance)
2457                     self._set_instance_obj_error_state(context, instance)
2458 
2459         do_terminate_instance(instance, bdms)
2460 
2461     # NOTE(johannes): This is probably better named power_off_instance
2462     # so it matches the driver method, but because of other issues, we
2463     # can't use that name in grizzly.
2464     @wrap_exception()
2465     @reverts_task_state
2466     @wrap_instance_event(prefix='compute')
2467     @wrap_instance_fault
2468     def stop_instance(self, context, instance, clean_shutdown):
2469         """Stopping an instance on this host."""
2470 
2471         @utils.synchronized(instance.uuid)
2472         def do_stop_instance():
2473             current_power_state = self._get_power_state(context, instance)
2474             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2475                       'current task_state: %(task_state)s, current DB '
2476                       'power_state: %(db_power_state)s, current VM '
2477                       'power_state: %(current_power_state)s',
2478                       {'vm_state': instance.vm_state,
2479                        'task_state': instance.task_state,
2480                        'db_power_state': instance.power_state,
2481                        'current_power_state': current_power_state},
2482                       instance_uuid=instance.uuid)
2483 
2484             # NOTE(mriedem): If the instance is already powered off, we are
2485             # possibly tearing down and racing with other operations, so we can
2486             # expect the task_state to be None if something else updates the
2487             # instance and we're not locking it.
2488             expected_task_state = [task_states.POWERING_OFF]
2489             # The list of power states is from _sync_instance_power_state.
2490             if current_power_state in (power_state.NOSTATE,
2491                                        power_state.SHUTDOWN,
2492                                        power_state.CRASHED):
2493                 LOG.info(_LI('Instance is already powered off in the '
2494                              'hypervisor when stop is called.'),
2495                          instance=instance)
2496                 expected_task_state.append(None)
2497 
2498             self._notify_about_instance_usage(context, instance,
2499                                               "power_off.start")
2500 
2501             compute_utils.notify_about_instance_action(context, instance,
2502                         self.host, action=fields.NotificationAction.POWER_OFF,
2503                         phase=fields.NotificationPhase.START)
2504 
2505             self._power_off_instance(context, instance, clean_shutdown)
2506             instance.power_state = self._get_power_state(context, instance)
2507             instance.vm_state = vm_states.STOPPED
2508             instance.task_state = None
2509             instance.save(expected_task_state=expected_task_state)
2510             self._notify_about_instance_usage(context, instance,
2511                                               "power_off.end")
2512 
2513             compute_utils.notify_about_instance_action(context, instance,
2514                         self.host, action=fields.NotificationAction.POWER_OFF,
2515                         phase=fields.NotificationPhase.END)
2516 
2517         do_stop_instance()
2518 
2519     def _power_on(self, context, instance):
2520         network_info = self.network_api.get_instance_nw_info(context, instance)
2521         block_device_info = self._get_instance_block_device_info(context,
2522                                                                  instance)
2523         self.driver.power_on(context, instance,
2524                              network_info,
2525                              block_device_info)
2526 
2527     def _delete_snapshot_of_shelved_instance(self, context, instance,
2528                                              snapshot_id):
2529         """Delete snapshot of shelved instance."""
2530         try:
2531             self.image_api.delete(context, snapshot_id)
2532         except (exception.ImageNotFound,
2533                 exception.ImageNotAuthorized) as exc:
2534             LOG.warning(_LW("Failed to delete snapshot "
2535                             "from shelved instance (%s)."),
2536                         exc.format_message(), instance=instance)
2537         except Exception:
2538             LOG.exception(_LE("Something wrong happened when trying to "
2539                               "delete snapshot from shelved instance."),
2540                           instance=instance)
2541 
2542     # NOTE(johannes): This is probably better named power_on_instance
2543     # so it matches the driver method, but because of other issues, we
2544     # can't use that name in grizzly.
2545     @wrap_exception()
2546     @reverts_task_state
2547     @wrap_instance_event(prefix='compute')
2548     @wrap_instance_fault
2549     def start_instance(self, context, instance):
2550         """Starting an instance on this host."""
2551         self._notify_about_instance_usage(context, instance, "power_on.start")
2552         compute_utils.notify_about_instance_action(context, instance,
2553             self.host, action=fields.NotificationAction.POWER_ON,
2554             phase=fields.NotificationPhase.START)
2555         self._power_on(context, instance)
2556         instance.power_state = self._get_power_state(context, instance)
2557         instance.vm_state = vm_states.ACTIVE
2558         instance.task_state = None
2559 
2560         # Delete an image(VM snapshot) for a shelved instance
2561         snapshot_id = instance.system_metadata.get('shelved_image_id')
2562         if snapshot_id:
2563             self._delete_snapshot_of_shelved_instance(context, instance,
2564                                                       snapshot_id)
2565 
2566         # Delete system_metadata for a shelved instance
2567         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2568 
2569         instance.save(expected_task_state=task_states.POWERING_ON)
2570         self._notify_about_instance_usage(context, instance, "power_on.end")
2571         compute_utils.notify_about_instance_action(context, instance,
2572             self.host, action=fields.NotificationAction.POWER_ON,
2573             phase=fields.NotificationPhase.END)
2574 
2575     @messaging.expected_exceptions(NotImplementedError,
2576                                    exception.TriggerCrashDumpNotSupported,
2577                                    exception.InstanceNotRunning)
2578     @wrap_exception()
2579     @wrap_instance_event(prefix='compute')
2580     @wrap_instance_fault
2581     def trigger_crash_dump(self, context, instance):
2582         """Trigger crash dump in an instance."""
2583 
2584         self._notify_about_instance_usage(context, instance,
2585                                           "trigger_crash_dump.start")
2586 
2587         # This method does not change task_state and power_state because the
2588         # effect of a trigger depends on user's configuration.
2589         self.driver.trigger_crash_dump(instance)
2590 
2591         self._notify_about_instance_usage(context, instance,
2592                                           "trigger_crash_dump.end")
2593 
2594     @wrap_exception()
2595     @reverts_task_state
2596     @wrap_instance_event(prefix='compute')
2597     @wrap_instance_fault
2598     def soft_delete_instance(self, context, instance, reservations):
2599         """Soft delete an instance on this host."""
2600 
2601         quotas = objects.Quotas.from_reservations(context,
2602                                                   reservations,
2603                                                   instance=instance)
2604         try:
2605             self._notify_about_instance_usage(context, instance,
2606                                               "soft_delete.start")
2607             try:
2608                 self.driver.soft_delete(instance)
2609             except NotImplementedError:
2610                 # Fallback to just powering off the instance if the
2611                 # hypervisor doesn't implement the soft_delete method
2612                 self.driver.power_off(instance)
2613             instance.power_state = self._get_power_state(context, instance)
2614             instance.vm_state = vm_states.SOFT_DELETED
2615             instance.task_state = None
2616             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2617         except Exception:
2618             with excutils.save_and_reraise_exception():
2619                 quotas.rollback()
2620         quotas.commit()
2621         self._notify_about_instance_usage(context, instance, "soft_delete.end")
2622 
2623     @wrap_exception()
2624     @reverts_task_state
2625     @wrap_instance_event(prefix='compute')
2626     @wrap_instance_fault
2627     def restore_instance(self, context, instance):
2628         """Restore a soft-deleted instance on this host."""
2629         self._notify_about_instance_usage(context, instance, "restore.start")
2630         compute_utils.notify_about_instance_action(context, instance,
2631             self.host, action=fields.NotificationAction.RESTORE,
2632             phase=fields.NotificationPhase.START)
2633         try:
2634             self.driver.restore(instance)
2635         except NotImplementedError:
2636             # Fallback to just powering on the instance if the hypervisor
2637             # doesn't implement the restore method
2638             self._power_on(context, instance)
2639         instance.power_state = self._get_power_state(context, instance)
2640         instance.vm_state = vm_states.ACTIVE
2641         instance.task_state = None
2642         instance.save(expected_task_state=task_states.RESTORING)
2643         self._notify_about_instance_usage(context, instance, "restore.end")
2644         compute_utils.notify_about_instance_action(context, instance,
2645             self.host, action=fields.NotificationAction.RESTORE,
2646             phase=fields.NotificationPhase.END)
2647 
2648     @staticmethod
2649     def _set_migration_status(migration, status):
2650         """Set the status, and guard against a None being passed in.
2651 
2652         This is useful as some of the compute RPC calls will not pass
2653         a migration object in older versions. The check can be removed when
2654         we move past 4.x major version of the RPC API.
2655         """
2656         if migration:
2657             migration.status = status
2658             migration.save()
2659 
2660     def _rebuild_default_impl(self, context, instance, image_meta,
2661                               injected_files, admin_password, bdms,
2662                               detach_block_devices, attach_block_devices,
2663                               network_info=None,
2664                               recreate=False, block_device_info=None,
2665                               preserve_ephemeral=False):
2666         if preserve_ephemeral:
2667             # The default code path does not support preserving ephemeral
2668             # partitions.
2669             raise exception.PreserveEphemeralNotSupported()
2670 
2671         if recreate:
2672             detach_block_devices(context, bdms)
2673         else:
2674             self._power_off_instance(context, instance, clean_shutdown=True)
2675             detach_block_devices(context, bdms)
2676             self.driver.destroy(context, instance,
2677                                 network_info=network_info,
2678                                 block_device_info=block_device_info)
2679 
2680         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2681         instance.save(expected_task_state=[task_states.REBUILDING])
2682 
2683         new_block_device_info = attach_block_devices(context, instance, bdms)
2684 
2685         instance.task_state = task_states.REBUILD_SPAWNING
2686         instance.save(
2687             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2688 
2689         with instance.mutated_migration_context():
2690             self.driver.spawn(context, instance, image_meta, injected_files,
2691                               admin_password, network_info=network_info,
2692                               block_device_info=new_block_device_info)
2693 
2694     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2695     @wrap_exception()
2696     @reverts_task_state
2697     @wrap_instance_event(prefix='compute')
2698     @wrap_instance_fault
2699     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2700                          injected_files, new_pass, orig_sys_metadata,
2701                          bdms, recreate, on_shared_storage=None,
2702                          preserve_ephemeral=False, migration=None,
2703                          scheduled_node=None, limits=None):
2704         """Destroy and re-make this instance.
2705 
2706         A 'rebuild' effectively purges all existing data from the system and
2707         remakes the VM with given 'metadata' and 'personalities'.
2708 
2709         :param context: `nova.RequestContext` object
2710         :param instance: Instance object
2711         :param orig_image_ref: Original image_ref before rebuild
2712         :param image_ref: New image_ref for rebuild
2713         :param injected_files: Files to inject
2714         :param new_pass: password to set on rebuilt instance
2715         :param orig_sys_metadata: instance system metadata from pre-rebuild
2716         :param bdms: block-device-mappings to use for rebuild
2717         :param recreate: True if the instance is being recreated (e.g. the
2718             hypervisor it was on failed) - cleanup of old state will be
2719             skipped.
2720         :param on_shared_storage: True if instance files on shared storage.
2721                                   If not provided then information from the
2722                                   driver will be used to decide if the instance
2723                                   files are available or not on the target host
2724         :param preserve_ephemeral: True if the default ephemeral storage
2725                                    partition must be preserved on rebuild
2726         :param migration: a Migration object if one was created for this
2727                           rebuild operation (if it's a part of evacuate)
2728         :param scheduled_node: A node of the host chosen by the scheduler. If a
2729                                host was specified by the user, this will be
2730                                None
2731         :param limits: Overcommit limits set by the scheduler. If a host was
2732                        specified by the user, this will be None
2733         """
2734         context = context.elevated()
2735 
2736         LOG.info(_LI("Rebuilding instance"), instance=instance)
2737         if scheduled_node is not None:
2738             rt = self._get_resource_tracker()
2739             rebuild_claim = rt.rebuild_claim
2740         else:
2741             rebuild_claim = claims.NopClaim
2742 
2743         image_meta = {}
2744         if image_ref:
2745             image_meta = self.image_api.get(context, image_ref)
2746 
2747         # NOTE(mriedem): On a recreate (evacuate), we need to update
2748         # the instance's host and node properties to reflect it's
2749         # destination node for the recreate.
2750         if not scheduled_node:
2751             if recreate:
2752                 try:
2753                     compute_node = self._get_compute_info(context, self.host)
2754                     scheduled_node = compute_node.hypervisor_hostname
2755                 except exception.ComputeHostNotFound:
2756                     LOG.exception(_LE('Failed to get compute_info for %s'),
2757                                   self.host)
2758             else:
2759                 scheduled_node = instance.node
2760 
2761         with self._error_out_instance_on_exception(context, instance):
2762             try:
2763                 claim_ctxt = rebuild_claim(
2764                     context, instance, scheduled_node,
2765                     limits=limits, image_meta=image_meta,
2766                     migration=migration)
2767                 self._do_rebuild_instance_with_claim(
2768                     claim_ctxt, context, instance, orig_image_ref,
2769                     image_ref, injected_files, new_pass, orig_sys_metadata,
2770                     bdms, recreate, on_shared_storage, preserve_ephemeral)
2771             except exception.ComputeResourcesUnavailable as e:
2772                 LOG.debug("Could not rebuild instance on this host, not "
2773                           "enough resources available.", instance=instance)
2774 
2775                 # NOTE(ndipanov): We just abort the build for now and leave a
2776                 # migration record for potential cleanup later
2777                 self._set_migration_status(migration, 'failed')
2778 
2779                 self._notify_about_instance_usage(context, instance,
2780                         'rebuild.error', fault=e)
2781                 raise exception.BuildAbortException(
2782                     instance_uuid=instance.uuid, reason=e.format_message())
2783             except (exception.InstanceNotFound,
2784                     exception.UnexpectedDeletingTaskStateError) as e:
2785                 LOG.debug('Instance was deleted while rebuilding',
2786                           instance=instance)
2787                 self._set_migration_status(migration, 'failed')
2788                 self._notify_about_instance_usage(context, instance,
2789                         'rebuild.error', fault=e)
2790             except Exception as e:
2791                 self._set_migration_status(migration, 'failed')
2792                 self._notify_about_instance_usage(context, instance,
2793                         'rebuild.error', fault=e)
2794                 raise
2795             else:
2796                 instance.apply_migration_context()
2797                 # NOTE (ndipanov): This save will now update the host and node
2798                 # attributes making sure that next RT pass is consistent since
2799                 # it will be based on the instance and not the migration DB
2800                 # entry.
2801                 instance.host = self.host
2802                 instance.node = scheduled_node
2803                 instance.save()
2804                 instance.drop_migration_context()
2805 
2806                 # NOTE (ndipanov): Mark the migration as done only after we
2807                 # mark the instance as belonging to this host.
2808                 self._set_migration_status(migration, 'done')
2809 
2810     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2811         """Helper to avoid deep nesting in the top-level method."""
2812 
2813         with claim_context:
2814             self._do_rebuild_instance(*args, **kwargs)
2815 
2816     @staticmethod
2817     def _get_image_name(image_meta):
2818         if image_meta.obj_attr_is_set("name"):
2819             return image_meta.name
2820         else:
2821             return ''
2822 
2823     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2824                              image_ref, injected_files, new_pass,
2825                              orig_sys_metadata, bdms, recreate,
2826                              on_shared_storage, preserve_ephemeral):
2827         orig_vm_state = instance.vm_state
2828 
2829         if recreate:
2830             if not self.driver.capabilities["supports_recreate"]:
2831                 raise exception.InstanceRecreateNotSupported
2832 
2833             self._check_instance_exists(context, instance)
2834 
2835             if on_shared_storage is None:
2836                 LOG.debug('on_shared_storage is not provided, using driver'
2837                             'information to decide if the instance needs to'
2838                             'be recreated')
2839                 on_shared_storage = self.driver.instance_on_disk(instance)
2840 
2841             elif (on_shared_storage !=
2842                     self.driver.instance_on_disk(instance)):
2843                 # To cover case when admin expects that instance files are
2844                 # on shared storage, but not accessible and vice versa
2845                 raise exception.InvalidSharedStorage(
2846                         _("Invalid state of instance files on shared"
2847                             " storage"))
2848 
2849             if on_shared_storage:
2850                 LOG.info(_LI('disk on shared storage, recreating using'
2851                                 ' existing disk'))
2852             else:
2853                 image_ref = orig_image_ref = instance.image_ref
2854                 LOG.info(_LI("disk not on shared storage, rebuilding from:"
2855                                 " '%s'"), str(image_ref))
2856 
2857         if image_ref:
2858             image_meta = objects.ImageMeta.from_image_ref(
2859                 context, self.image_api, image_ref)
2860         else:
2861             image_meta = instance.image_meta
2862 
2863         # This instance.exists message should contain the original
2864         # image_ref, not the new one.  Since the DB has been updated
2865         # to point to the new one... we have to override it.
2866         # TODO(jaypipes): Move generate_image_url() into the nova.image.api
2867         orig_image_ref_url = glance.generate_image_url(orig_image_ref)
2868         extra_usage_info = {'image_ref_url': orig_image_ref_url}
2869         compute_utils.notify_usage_exists(
2870                 self.notifier, context, instance,
2871                 current_period=True, system_metadata=orig_sys_metadata,
2872                 extra_usage_info=extra_usage_info)
2873 
2874         # This message should contain the new image_ref
2875         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
2876         self._notify_about_instance_usage(context, instance,
2877                 "rebuild.start", extra_usage_info=extra_usage_info)
2878 
2879         instance.power_state = self._get_power_state(context, instance)
2880         instance.task_state = task_states.REBUILDING
2881         instance.save(expected_task_state=[task_states.REBUILDING])
2882 
2883         if recreate:
2884             self.network_api.setup_networks_on_host(
2885                     context, instance, self.host)
2886             # For nova-network this is needed to move floating IPs
2887             # For neutron this updates the host in the port binding
2888             # TODO(cfriesen): this network_api call and the one above
2889             # are so similar, we should really try to unify them.
2890             self.network_api.setup_instance_network_on_host(
2891                     context, instance, self.host)
2892 
2893         network_info = compute_utils.get_nw_info_for_instance(instance)
2894         if bdms is None:
2895             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2896                     context, instance.uuid)
2897 
2898         block_device_info = \
2899             self._get_instance_block_device_info(
2900                     context, instance, bdms=bdms)
2901 
2902         def detach_block_devices(context, bdms):
2903             for bdm in bdms:
2904                 if bdm.is_volume:
2905                     self._detach_volume(context, bdm.volume_id, instance,
2906                                         destroy_bdm=False)
2907 
2908         files = self._decode_files(injected_files)
2909 
2910         kwargs = dict(
2911             context=context,
2912             instance=instance,
2913             image_meta=image_meta,
2914             injected_files=files,
2915             admin_password=new_pass,
2916             bdms=bdms,
2917             detach_block_devices=detach_block_devices,
2918             attach_block_devices=self._prep_block_device,
2919             block_device_info=block_device_info,
2920             network_info=network_info,
2921             preserve_ephemeral=preserve_ephemeral,
2922             recreate=recreate)
2923         try:
2924             with instance.mutated_migration_context():
2925                 self.driver.rebuild(**kwargs)
2926         except NotImplementedError:
2927             # NOTE(rpodolyaka): driver doesn't provide specialized version
2928             # of rebuild, fall back to the default implementation
2929             self._rebuild_default_impl(**kwargs)
2930         self._update_instance_after_spawn(context, instance)
2931         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
2932 
2933         if orig_vm_state == vm_states.STOPPED:
2934             LOG.info(_LI("bringing vm to original state: '%s'"),
2935                         orig_vm_state, instance=instance)
2936             instance.vm_state = vm_states.ACTIVE
2937             instance.task_state = task_states.POWERING_OFF
2938             instance.progress = 0
2939             instance.save()
2940             self.stop_instance(context, instance, False)
2941         self._update_scheduler_instance_info(context, instance)
2942         self._notify_about_instance_usage(
2943                 context, instance, "rebuild.end",
2944                 network_info=network_info,
2945                 extra_usage_info=extra_usage_info)
2946 
2947     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
2948                                      block_device_info):
2949         """Handle cases where the virt-layer had to detach non-working volumes
2950         in order to complete an operation.
2951         """
2952         for bdm in block_device_info['block_device_mapping']:
2953             if bdm.get('mount_device') in bad_devices:
2954                 try:
2955                     volume_id = bdm['connection_info']['data']['volume_id']
2956                 except KeyError:
2957                     continue
2958 
2959                 # NOTE(sirp): ideally we'd just call
2960                 # `compute_api.detach_volume` here but since that hits the
2961                 # DB directly, that's off limits from within the
2962                 # compute-manager.
2963                 #
2964                 # API-detach
2965                 LOG.info(_LI("Detaching from volume api: %s"), volume_id)
2966                 volume = self.volume_api.get(context, volume_id)
2967                 self.volume_api.check_detach(context, volume)
2968                 self.volume_api.begin_detaching(context, volume_id)
2969 
2970                 # Manager-detach
2971                 self.detach_volume(context, volume_id, instance)
2972 
2973     @wrap_exception()
2974     @reverts_task_state
2975     @wrap_instance_event(prefix='compute')
2976     @wrap_instance_fault
2977     def reboot_instance(self, context, instance, block_device_info,
2978                         reboot_type):
2979         """Reboot an instance on this host."""
2980         # acknowledge the request made it to the manager
2981         if reboot_type == "SOFT":
2982             instance.task_state = task_states.REBOOT_PENDING
2983             expected_states = (task_states.REBOOTING,
2984                                task_states.REBOOT_PENDING,
2985                                task_states.REBOOT_STARTED)
2986         else:
2987             instance.task_state = task_states.REBOOT_PENDING_HARD
2988             expected_states = (task_states.REBOOTING_HARD,
2989                                task_states.REBOOT_PENDING_HARD,
2990                                task_states.REBOOT_STARTED_HARD)
2991         context = context.elevated()
2992         LOG.info(_LI("Rebooting instance"), instance=instance)
2993 
2994         block_device_info = self._get_instance_block_device_info(context,
2995                                                                  instance)
2996 
2997         network_info = self.network_api.get_instance_nw_info(context, instance)
2998 
2999         self._notify_about_instance_usage(context, instance, "reboot.start")
3000 
3001         instance.power_state = self._get_power_state(context, instance)
3002         instance.save(expected_task_state=expected_states)
3003 
3004         if instance.power_state != power_state.RUNNING:
3005             state = instance.power_state
3006             running = power_state.RUNNING
3007             LOG.warning(_LW('trying to reboot a non-running instance:'
3008                             ' (state: %(state)s expected: %(running)s)'),
3009                         {'state': state, 'running': running},
3010                         instance=instance)
3011 
3012         def bad_volumes_callback(bad_devices):
3013             self._handle_bad_volumes_detached(
3014                     context, instance, bad_devices, block_device_info)
3015 
3016         try:
3017             # Don't change it out of rescue mode
3018             if instance.vm_state == vm_states.RESCUED:
3019                 new_vm_state = vm_states.RESCUED
3020             else:
3021                 new_vm_state = vm_states.ACTIVE
3022             new_power_state = None
3023             if reboot_type == "SOFT":
3024                 instance.task_state = task_states.REBOOT_STARTED
3025                 expected_state = task_states.REBOOT_PENDING
3026             else:
3027                 instance.task_state = task_states.REBOOT_STARTED_HARD
3028                 expected_state = task_states.REBOOT_PENDING_HARD
3029             instance.save(expected_task_state=expected_state)
3030             self.driver.reboot(context, instance,
3031                                network_info,
3032                                reboot_type,
3033                                block_device_info=block_device_info,
3034                                bad_volumes_callback=bad_volumes_callback)
3035 
3036         except Exception as error:
3037             with excutils.save_and_reraise_exception() as ctxt:
3038                 exc_info = sys.exc_info()
3039                 # if the reboot failed but the VM is running don't
3040                 # put it into an error state
3041                 new_power_state = self._get_power_state(context, instance)
3042                 if new_power_state == power_state.RUNNING:
3043                     LOG.warning(_LW('Reboot failed but instance is running'),
3044                                 instance=instance)
3045                     compute_utils.add_instance_fault_from_exc(context,
3046                             instance, error, exc_info)
3047                     self._notify_about_instance_usage(context, instance,
3048                             'reboot.error', fault=error)
3049                     ctxt.reraise = False
3050                 else:
3051                     LOG.error(_LE('Cannot reboot instance: %s'), error,
3052                               instance=instance)
3053                     self._set_instance_obj_error_state(context, instance)
3054 
3055         if not new_power_state:
3056             new_power_state = self._get_power_state(context, instance)
3057         try:
3058             instance.power_state = new_power_state
3059             instance.vm_state = new_vm_state
3060             instance.task_state = None
3061             instance.save()
3062         except exception.InstanceNotFound:
3063             LOG.warning(_LW("Instance disappeared during reboot"),
3064                         instance=instance)
3065 
3066         self._notify_about_instance_usage(context, instance, "reboot.end")
3067 
3068     @delete_image_on_error
3069     def _do_snapshot_instance(self, context, image_id, instance):
3070         self._snapshot_instance(context, image_id, instance,
3071                                 task_states.IMAGE_BACKUP)
3072 
3073     @wrap_exception()
3074     @reverts_task_state
3075     @wrap_instance_fault
3076     def backup_instance(self, context, image_id, instance, backup_type,
3077                         rotation):
3078         """Backup an instance on this host.
3079 
3080         :param backup_type: daily | weekly
3081         :param rotation: int representing how many backups to keep around
3082         """
3083         self._do_snapshot_instance(context, image_id, instance)
3084         self._rotate_backups(context, instance, backup_type, rotation)
3085 
3086     @wrap_exception()
3087     @reverts_task_state
3088     @wrap_instance_fault
3089     @delete_image_on_error
3090     def snapshot_instance(self, context, image_id, instance):
3091         """Snapshot an instance on this host.
3092 
3093         :param context: security context
3094         :param image_id: glance.db.sqlalchemy.models.Image.Id
3095         :param instance: a nova.objects.instance.Instance object
3096         """
3097         # NOTE(dave-mcnally) the task state will already be set by the api
3098         # but if the compute manager has crashed/been restarted prior to the
3099         # request getting here the task state may have been cleared so we set
3100         # it again and things continue normally
3101         try:
3102             instance.task_state = task_states.IMAGE_SNAPSHOT
3103             instance.save(
3104                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3105         except exception.InstanceNotFound:
3106             # possibility instance no longer exists, no point in continuing
3107             LOG.debug("Instance not found, could not set state %s "
3108                       "for instance.",
3109                       task_states.IMAGE_SNAPSHOT, instance=instance)
3110             return
3111 
3112         except exception.UnexpectedDeletingTaskStateError:
3113             LOG.debug("Instance being deleted, snapshot cannot continue",
3114                       instance=instance)
3115             return
3116 
3117         self._snapshot_instance(context, image_id, instance,
3118                                 task_states.IMAGE_SNAPSHOT)
3119 
3120     def _snapshot_instance(self, context, image_id, instance,
3121                            expected_task_state):
3122         context = context.elevated()
3123 
3124         instance.power_state = self._get_power_state(context, instance)
3125         try:
3126             instance.save()
3127 
3128             LOG.info(_LI('instance snapshotting'), instance=instance)
3129 
3130             if instance.power_state != power_state.RUNNING:
3131                 state = instance.power_state
3132                 running = power_state.RUNNING
3133                 LOG.warning(_LW('trying to snapshot a non-running instance: '
3134                                 '(state: %(state)s expected: %(running)s)'),
3135                             {'state': state, 'running': running},
3136                             instance=instance)
3137 
3138             self._notify_about_instance_usage(
3139                 context, instance, "snapshot.start")
3140             compute_utils.notify_about_instance_action(context, instance,
3141                 self.host, action=fields.NotificationAction.SNAPSHOT,
3142                 phase=fields.NotificationPhase.START)
3143 
3144             def update_task_state(task_state,
3145                                   expected_state=expected_task_state):
3146                 instance.task_state = task_state
3147                 instance.save(expected_task_state=expected_state)
3148 
3149             self.driver.snapshot(context, instance, image_id,
3150                                  update_task_state)
3151 
3152             instance.task_state = None
3153             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3154 
3155             self._notify_about_instance_usage(context, instance,
3156                                               "snapshot.end")
3157             compute_utils.notify_about_instance_action(context, instance,
3158                 self.host, action=fields.NotificationAction.SNAPSHOT,
3159                 phase=fields.NotificationPhase.END)
3160         except (exception.InstanceNotFound,
3161                 exception.UnexpectedDeletingTaskStateError):
3162             # the instance got deleted during the snapshot
3163             # Quickly bail out of here
3164             msg = 'Instance disappeared during snapshot'
3165             LOG.debug(msg, instance=instance)
3166             try:
3167                 image_service = glance.get_default_image_service()
3168                 image = image_service.show(context, image_id)
3169                 if image['status'] != 'active':
3170                     image_service.delete(context, image_id)
3171             except Exception:
3172                 LOG.warning(_LW("Error while trying to clean up image %s"),
3173                             image_id, instance=instance)
3174         except exception.ImageNotFound:
3175             instance.task_state = None
3176             instance.save()
3177             msg = _LW("Image not found during snapshot")
3178             LOG.warning(msg, instance=instance)
3179 
3180     def _post_interrupted_snapshot_cleanup(self, context, instance):
3181         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3182 
3183     @messaging.expected_exceptions(NotImplementedError)
3184     @wrap_exception()
3185     def volume_snapshot_create(self, context, instance, volume_id,
3186                                create_info):
3187         self.driver.volume_snapshot_create(context, instance, volume_id,
3188                                            create_info)
3189 
3190     @messaging.expected_exceptions(NotImplementedError)
3191     @wrap_exception()
3192     def volume_snapshot_delete(self, context, instance, volume_id,
3193                                snapshot_id, delete_info):
3194         self.driver.volume_snapshot_delete(context, instance, volume_id,
3195                                            snapshot_id, delete_info)
3196 
3197     @wrap_instance_fault
3198     def _rotate_backups(self, context, instance, backup_type, rotation):
3199         """Delete excess backups associated to an instance.
3200 
3201         Instances are allowed a fixed number of backups (the rotation number);
3202         this method deletes the oldest backups that exceed the rotation
3203         threshold.
3204 
3205         :param context: security context
3206         :param instance: Instance dict
3207         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3208         :param rotation: int representing how many backups to keep around;
3209             None if rotation shouldn't be used (as in the case of snapshots)
3210         """
3211         filters = {'property-image_type': 'backup',
3212                    'property-backup_type': backup_type,
3213                    'property-instance_uuid': instance.uuid}
3214 
3215         images = self.image_api.get_all(context, filters=filters,
3216                                         sort_key='created_at', sort_dir='desc')
3217         num_images = len(images)
3218         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3219                   {'num_images': num_images, 'rotation': rotation},
3220                   instance=instance)
3221 
3222         if num_images > rotation:
3223             # NOTE(sirp): this deletes all backups that exceed the rotation
3224             # limit
3225             excess = len(images) - rotation
3226             LOG.debug("Rotating out %d backups", excess,
3227                       instance=instance)
3228             for i in range(excess):
3229                 image = images.pop()
3230                 image_id = image['id']
3231                 LOG.debug("Deleting image %s", image_id,
3232                           instance=instance)
3233                 try:
3234                     self.image_api.delete(context, image_id)
3235                 except exception.ImageNotFound:
3236                     LOG.info(_LI("Failed to find image %(image_id)s to "
3237                                  "delete"), {'image_id': image_id},
3238                              instance=instance)
3239 
3240     @wrap_exception()
3241     @reverts_task_state
3242     @wrap_instance_event(prefix='compute')
3243     @wrap_instance_fault
3244     def set_admin_password(self, context, instance, new_pass):
3245         """Set the root/admin password for an instance on this host.
3246 
3247         This is generally only called by API password resets after an
3248         image has been built.
3249 
3250         @param context: Nova auth context.
3251         @param instance: Nova instance object.
3252         @param new_pass: The admin password for the instance.
3253         """
3254 
3255         context = context.elevated()
3256         if new_pass is None:
3257             # Generate a random password
3258             new_pass = utils.generate_password()
3259 
3260         current_power_state = self._get_power_state(context, instance)
3261         expected_state = power_state.RUNNING
3262 
3263         if current_power_state != expected_state:
3264             instance.task_state = None
3265             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3266             _msg = _('instance %s is not running') % instance.uuid
3267             raise exception.InstancePasswordSetFailed(
3268                 instance=instance.uuid, reason=_msg)
3269 
3270         try:
3271             self.driver.set_admin_password(instance, new_pass)
3272             LOG.info(_LI("Root password set"), instance=instance)
3273             instance.task_state = None
3274             instance.save(
3275                 expected_task_state=task_states.UPDATING_PASSWORD)
3276         except exception.InstanceAgentNotEnabled:
3277             with excutils.save_and_reraise_exception():
3278                 LOG.debug('Guest agent is not enabled for the instance.',
3279                           instance=instance)
3280                 instance.task_state = None
3281                 instance.save(
3282                     expected_task_state=task_states.UPDATING_PASSWORD)
3283         except exception.SetAdminPasswdNotSupported:
3284             with excutils.save_and_reraise_exception():
3285                 LOG.info(_LI('set_admin_password is not supported '
3286                                 'by this driver or guest instance.'),
3287                             instance=instance)
3288                 instance.task_state = None
3289                 instance.save(
3290                     expected_task_state=task_states.UPDATING_PASSWORD)
3291         except NotImplementedError:
3292             LOG.warning(_LW('set_admin_password is not implemented '
3293                             'by this driver or guest instance.'),
3294                         instance=instance)
3295             instance.task_state = None
3296             instance.save(
3297                 expected_task_state=task_states.UPDATING_PASSWORD)
3298             raise NotImplementedError(_('set_admin_password is not '
3299                                         'implemented by this driver or guest '
3300                                         'instance.'))
3301         except exception.UnexpectedTaskStateError:
3302             # interrupted by another (most likely delete) task
3303             # do not retry
3304             raise
3305         except Exception:
3306             # Catch all here because this could be anything.
3307             LOG.exception(_LE('set_admin_password failed'),
3308                           instance=instance)
3309             self._set_instance_obj_error_state(context, instance)
3310             # We create a new exception here so that we won't
3311             # potentially reveal password information to the
3312             # API caller.  The real exception is logged above
3313             _msg = _('error setting admin password')
3314             raise exception.InstancePasswordSetFailed(
3315                 instance=instance.uuid, reason=_msg)
3316 
3317     @wrap_exception()
3318     @reverts_task_state
3319     @wrap_instance_fault
3320     def inject_file(self, context, path, file_contents, instance):
3321         """Write a file to the specified path in an instance on this host."""
3322         # NOTE(russellb) Remove this method, as well as the underlying virt
3323         # driver methods, when the compute rpc interface is bumped to 4.x
3324         # as it is no longer used.
3325         context = context.elevated()
3326         current_power_state = self._get_power_state(context, instance)
3327         expected_state = power_state.RUNNING
3328         if current_power_state != expected_state:
3329             LOG.warning(_LW('trying to inject a file into a non-running '
3330                             '(state: %(current_state)s expected: '
3331                             '%(expected_state)s)'),
3332                         {'current_state': current_power_state,
3333                          'expected_state': expected_state},
3334                         instance=instance)
3335         LOG.info(_LI('injecting file to %s'), path,
3336                     instance=instance)
3337         self.driver.inject_file(instance, path, file_contents)
3338 
3339     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3340         """Determine what image should be used to boot the rescue VM."""
3341         # 1. If rescue_image_ref is passed in, use that for rescue.
3342         # 2. Else, use the base image associated with instance's current image.
3343         #       The idea here is to provide the customer with a rescue
3344         #       environment which they are familiar with.
3345         #       So, if they built their instance off of a Debian image,
3346         #       their rescue VM will also be Debian.
3347         # 3. As a last resort, use instance's current image.
3348         if not rescue_image_ref:
3349             system_meta = utils.instance_sys_meta(instance)
3350             rescue_image_ref = system_meta.get('image_base_image_ref')
3351 
3352         if not rescue_image_ref:
3353             LOG.warning(_LW('Unable to find a different image to use for '
3354                             'rescue VM, using instance\'s current image'),
3355                         instance=instance)
3356             rescue_image_ref = instance.image_ref
3357 
3358         return objects.ImageMeta.from_image_ref(
3359             context, self.image_api, rescue_image_ref)
3360 
3361     @wrap_exception()
3362     @reverts_task_state
3363     @wrap_instance_event(prefix='compute')
3364     @wrap_instance_fault
3365     def rescue_instance(self, context, instance, rescue_password,
3366                         rescue_image_ref, clean_shutdown):
3367         context = context.elevated()
3368         LOG.info(_LI('Rescuing'), instance=instance)
3369 
3370         admin_password = (rescue_password if rescue_password else
3371                       utils.generate_password())
3372 
3373         network_info = self.network_api.get_instance_nw_info(context, instance)
3374 
3375         rescue_image_meta = self._get_rescue_image(context, instance,
3376                                                    rescue_image_ref)
3377 
3378         extra_usage_info = {'rescue_image_name':
3379                             self._get_image_name(rescue_image_meta)}
3380         self._notify_about_instance_usage(context, instance,
3381                 "rescue.start", extra_usage_info=extra_usage_info,
3382                 network_info=network_info)
3383 
3384         try:
3385             self._power_off_instance(context, instance, clean_shutdown)
3386 
3387             self.driver.rescue(context, instance,
3388                                network_info,
3389                                rescue_image_meta, admin_password)
3390         except Exception as e:
3391             LOG.exception(_LE("Error trying to Rescue Instance"),
3392                           instance=instance)
3393             self._set_instance_obj_error_state(context, instance)
3394             raise exception.InstanceNotRescuable(
3395                 instance_id=instance.uuid,
3396                 reason=_("Driver Error: %s") % e)
3397 
3398         compute_utils.notify_usage_exists(self.notifier, context, instance,
3399                                           current_period=True)
3400 
3401         instance.vm_state = vm_states.RESCUED
3402         instance.task_state = None
3403         instance.power_state = self._get_power_state(context, instance)
3404         instance.launched_at = timeutils.utcnow()
3405         instance.save(expected_task_state=task_states.RESCUING)
3406 
3407         self._notify_about_instance_usage(context, instance,
3408                 "rescue.end", extra_usage_info=extra_usage_info,
3409                 network_info=network_info)
3410 
3411     @wrap_exception()
3412     @reverts_task_state
3413     @wrap_instance_event(prefix='compute')
3414     @wrap_instance_fault
3415     def unrescue_instance(self, context, instance):
3416         context = context.elevated()
3417         LOG.info(_LI('Unrescuing'), instance=instance)
3418 
3419         network_info = self.network_api.get_instance_nw_info(context, instance)
3420         self._notify_about_instance_usage(context, instance,
3421                 "unrescue.start", network_info=network_info)
3422         with self._error_out_instance_on_exception(context, instance):
3423             self.driver.unrescue(instance,
3424                                  network_info)
3425 
3426         instance.vm_state = vm_states.ACTIVE
3427         instance.task_state = None
3428         instance.power_state = self._get_power_state(context, instance)
3429         instance.save(expected_task_state=task_states.UNRESCUING)
3430 
3431         self._notify_about_instance_usage(context,
3432                                           instance,
3433                                           "unrescue.end",
3434                                           network_info=network_info)
3435 
3436     @wrap_exception()
3437     @wrap_instance_fault
3438     def change_instance_metadata(self, context, diff, instance):
3439         """Update the metadata published to the instance."""
3440         LOG.debug("Changing instance metadata according to %r",
3441                   diff, instance=instance)
3442         self.driver.change_instance_metadata(context, instance, diff)
3443 
3444     @wrap_exception()
3445     @wrap_instance_event(prefix='compute')
3446     @wrap_instance_fault
3447     def confirm_resize(self, context, instance, reservations, migration):
3448 
3449         quotas = objects.Quotas.from_reservations(context,
3450                                                   reservations,
3451                                                   instance=instance)
3452 
3453         @utils.synchronized(instance.uuid)
3454         def do_confirm_resize(context, instance, migration_id):
3455             # NOTE(wangpan): Get the migration status from db, if it has been
3456             #                confirmed, we do nothing and return here
3457             LOG.debug("Going to confirm migration %s", migration_id,
3458                       instance=instance)
3459             try:
3460                 # TODO(russellb) Why are we sending the migration object just
3461                 # to turn around and look it up from the db again?
3462                 migration = objects.Migration.get_by_id(
3463                                     context.elevated(), migration_id)
3464             except exception.MigrationNotFound:
3465                 LOG.error(_LE("Migration %s is not found during confirmation"),
3466                           migration_id, instance=instance)
3467                 quotas.rollback()
3468                 return
3469 
3470             if migration.status == 'confirmed':
3471                 LOG.info(_LI("Migration %s is already confirmed"),
3472                          migration_id, instance=instance)
3473                 quotas.rollback()
3474                 return
3475             elif migration.status not in ('finished', 'confirming'):
3476                 LOG.warning(_LW("Unexpected confirmation status '%(status)s' "
3477                                 "of migration %(id)s, exit confirmation "
3478                                 "process"),
3479                             {"status": migration.status, "id": migration_id},
3480                             instance=instance)
3481                 quotas.rollback()
3482                 return
3483 
3484             # NOTE(wangpan): Get the instance from db, if it has been
3485             #                deleted, we do nothing and return here
3486             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3487             try:
3488                 instance = objects.Instance.get_by_uuid(
3489                         context, instance.uuid,
3490                         expected_attrs=expected_attrs)
3491             except exception.InstanceNotFound:
3492                 LOG.info(_LI("Instance is not found during confirmation"),
3493                          instance=instance)
3494                 quotas.rollback()
3495                 return
3496 
3497             self._confirm_resize(context, instance, quotas,
3498                                  migration=migration)
3499 
3500         do_confirm_resize(context, instance, migration.id)
3501 
3502     def _confirm_resize(self, context, instance, quotas,
3503                         migration=None):
3504         """Destroys the source instance."""
3505         self._notify_about_instance_usage(context, instance,
3506                                           "resize.confirm.start")
3507 
3508         with self._error_out_instance_on_exception(context, instance,
3509                                                    quotas=quotas):
3510             # NOTE(danms): delete stashed migration information
3511             old_instance_type = instance.old_flavor
3512             instance.old_flavor = None
3513             instance.new_flavor = None
3514             instance.system_metadata.pop('old_vm_state', None)
3515             instance.save()
3516 
3517             # NOTE(tr3buchet): tear down networks on source host
3518             self.network_api.setup_networks_on_host(context, instance,
3519                                migration.source_compute, teardown=True)
3520 
3521             network_info = self.network_api.get_instance_nw_info(context,
3522                                                                  instance)
3523             self.driver.confirm_migration(context, migration, instance,
3524                                           network_info)
3525 
3526             migration.status = 'confirmed'
3527             with migration.obj_as_admin():
3528                 migration.save()
3529 
3530             rt = self._get_resource_tracker()
3531             rt.drop_move_claim(context, instance, migration.source_node,
3532                                old_instance_type, prefix='old_')
3533             instance.drop_migration_context()
3534 
3535             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3536             # might have manually powered up the instance to confirm the
3537             # resize/migrate, so we need to check the current power state
3538             # on the instance and set the vm_state appropriately. We default
3539             # to ACTIVE because if the power state is not SHUTDOWN, we
3540             # assume _sync_instance_power_state will clean it up.
3541             p_state = instance.power_state
3542             vm_state = None
3543             if p_state == power_state.SHUTDOWN:
3544                 vm_state = vm_states.STOPPED
3545                 LOG.debug("Resized/migrated instance is powered off. "
3546                           "Setting vm_state to '%s'.", vm_state,
3547                           instance=instance)
3548             else:
3549                 vm_state = vm_states.ACTIVE
3550 
3551             instance.vm_state = vm_state
3552             instance.task_state = None
3553             instance.save(expected_task_state=[None, task_states.DELETING])
3554 
3555             self._notify_about_instance_usage(
3556                 context, instance, "resize.confirm.end",
3557                 network_info=network_info)
3558 
3559             quotas.commit()
3560 
3561     @wrap_exception()
3562     @reverts_task_state
3563     @wrap_instance_event(prefix='compute')
3564     @errors_out_migration
3565     @wrap_instance_fault
3566     def revert_resize(self, context, instance, migration, reservations):
3567         """Destroys the new instance on the destination machine.
3568 
3569         Reverts the model changes, and powers on the old instance on the
3570         source machine.
3571 
3572         """
3573 
3574         quotas = objects.Quotas.from_reservations(context,
3575                                                   reservations,
3576                                                   instance=instance)
3577 
3578         # NOTE(comstud): A revert_resize is essentially a resize back to
3579         # the old size, so we need to send a usage event here.
3580         compute_utils.notify_usage_exists(self.notifier, context, instance,
3581                                           current_period=True)
3582 
3583         with self._error_out_instance_on_exception(context, instance,
3584                                                    quotas=quotas):
3585             # NOTE(tr3buchet): tear down networks on destination host
3586             self.network_api.setup_networks_on_host(context, instance,
3587                                                     teardown=True)
3588 
3589             migration_p = obj_base.obj_to_primitive(migration)
3590             self.network_api.migrate_instance_start(context,
3591                                                     instance,
3592                                                     migration_p)
3593 
3594             network_info = self.network_api.get_instance_nw_info(context,
3595                                                                  instance)
3596             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3597                     context, instance.uuid)
3598             block_device_info = self._get_instance_block_device_info(
3599                                 context, instance, bdms=bdms)
3600 
3601             destroy_disks = not self._is_instance_storage_shared(
3602                 context, instance, host=migration.source_compute)
3603             self.driver.destroy(context, instance, network_info,
3604                                 block_device_info, destroy_disks)
3605 
3606             self._terminate_volume_connections(context, instance, bdms)
3607 
3608             migration.status = 'reverted'
3609             with migration.obj_as_admin():
3610                 migration.save()
3611 
3612             # NOTE(ndipanov): We need to do this here because dropping the
3613             # claim means we lose the migration_context data. We really should
3614             # fix this by moving the drop_move_claim call to the
3615             # finish_revert_resize method as this is racy (revert is dropped,
3616             # but instance resources will be tracked with the new flavor until
3617             # it gets rolled back in finish_revert_resize, which is
3618             # potentially wrong for a period of time).
3619             instance.revert_migration_context()
3620             instance.save()
3621 
3622             rt = self._get_resource_tracker()
3623             rt.drop_move_claim(context, instance, instance.node)
3624 
3625             self.compute_rpcapi.finish_revert_resize(context, instance,
3626                     migration, migration.source_compute,
3627                     quotas.reservations)
3628 
3629     @wrap_exception()
3630     @reverts_task_state
3631     @wrap_instance_event(prefix='compute')
3632     @errors_out_migration
3633     @wrap_instance_fault
3634     def finish_revert_resize(self, context, instance, reservations, migration):
3635         """Finishes the second half of reverting a resize.
3636 
3637         Bring the original source instance state back (active/shutoff) and
3638         revert the resized attributes in the database.
3639 
3640         """
3641 
3642         quotas = objects.Quotas.from_reservations(context,
3643                                                   reservations,
3644                                                   instance=instance)
3645 
3646         with self._error_out_instance_on_exception(context, instance,
3647                                                    quotas=quotas):
3648             self._notify_about_instance_usage(
3649                     context, instance, "resize.revert.start")
3650 
3651             # NOTE(mriedem): delete stashed old_vm_state information; we
3652             # default to ACTIVE for backwards compatibility if old_vm_state
3653             # is not set
3654             old_vm_state = instance.system_metadata.pop('old_vm_state',
3655                                                         vm_states.ACTIVE)
3656 
3657             self._set_instance_info(instance, instance.old_flavor)
3658             instance.old_flavor = None
3659             instance.new_flavor = None
3660             instance.host = migration.source_compute
3661             instance.node = migration.source_node
3662             instance.save()
3663 
3664             self.network_api.setup_networks_on_host(context, instance,
3665                                                     migration.source_compute)
3666             migration_p = obj_base.obj_to_primitive(migration)
3667             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
3668             # source host temporarily. "network_api.migrate_instance_finish"
3669             # will setup the network for the instance on the destination host.
3670             # For revert resize, the instance will back to the source host, the
3671             # setup of the network for instance should be on the source host.
3672             # So set the migration_p['dest_compute'] to source host at here.
3673             migration_p['dest_compute'] = migration.source_compute
3674             self.network_api.migrate_instance_finish(context,
3675                                                      instance,
3676                                                      migration_p)
3677             network_info = self.network_api.get_instance_nw_info(context,
3678                                                                  instance)
3679 
3680             block_device_info = self._get_instance_block_device_info(
3681                     context, instance, refresh_conn_info=True)
3682 
3683             power_on = old_vm_state != vm_states.STOPPED
3684             self.driver.finish_revert_migration(context, instance,
3685                                        network_info,
3686                                        block_device_info, power_on)
3687 
3688             instance.drop_migration_context()
3689             instance.launched_at = timeutils.utcnow()
3690             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
3691 
3692             # if the original vm state was STOPPED, set it back to STOPPED
3693             LOG.info(_LI("Updating instance to original state: '%s'"),
3694                      old_vm_state, instance=instance)
3695             if power_on:
3696                 instance.vm_state = vm_states.ACTIVE
3697                 instance.task_state = None
3698                 instance.save()
3699             else:
3700                 instance.task_state = task_states.POWERING_OFF
3701                 instance.save()
3702                 self.stop_instance(context, instance=instance,
3703                                    clean_shutdown=True)
3704 
3705             self._notify_about_instance_usage(
3706                     context, instance, "resize.revert.end")
3707             quotas.commit()
3708 
3709     def _prep_resize(self, context, image, instance, instance_type,
3710             quotas, request_spec, filter_properties, node,
3711             clean_shutdown=True):
3712 
3713         if not filter_properties:
3714             filter_properties = {}
3715 
3716         if not instance.host:
3717             self._set_instance_obj_error_state(context, instance)
3718             msg = _('Instance has no source host')
3719             raise exception.MigrationError(reason=msg)
3720 
3721         same_host = instance.host == self.host
3722         # if the flavor IDs match, it's migrate; otherwise resize
3723         if same_host and instance_type.id == instance['instance_type_id']:
3724             # check driver whether support migrate to same host
3725             if not self.driver.capabilities['supports_migrate_to_same_host']:
3726                 raise exception.UnableToMigrateToSelf(
3727                     instance_id=instance.uuid, host=self.host)
3728 
3729         # NOTE(danms): Stash the new instance_type to avoid having to
3730         # look it up in the database later
3731         instance.new_flavor = instance_type
3732         # NOTE(mriedem): Stash the old vm_state so we can set the
3733         # resized/reverted instance back to the same state later.
3734         vm_state = instance.vm_state
3735         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
3736         instance.system_metadata['old_vm_state'] = vm_state
3737         instance.save()
3738 
3739         limits = filter_properties.get('limits', {})
3740         rt = self._get_resource_tracker()
3741         with rt.resize_claim(context, instance, instance_type, node,
3742                              image_meta=image, limits=limits) as claim:
3743             LOG.info(_LI('Migrating'), instance=instance)
3744             self.compute_rpcapi.resize_instance(
3745                     context, instance, claim.migration, image,
3746                     instance_type, quotas.reservations,
3747                     clean_shutdown)
3748 
3749     @wrap_exception()
3750     @reverts_task_state
3751     @wrap_instance_event(prefix='compute')
3752     @wrap_instance_fault
3753     def prep_resize(self, context, image, instance, instance_type,
3754                     reservations, request_spec, filter_properties, node,
3755                     clean_shutdown):
3756         """Initiates the process of moving a running instance to another host.
3757 
3758         Possibly changes the RAM and disk size in the process.
3759 
3760         """
3761         if node is None:
3762             node = self.driver.get_available_nodes(refresh=True)[0]
3763             LOG.debug("No node specified, defaulting to %s", node,
3764                       instance=instance)
3765 
3766         # NOTE(melwitt): Remove this in version 5.0 of the RPC API
3767         # Code downstream may expect extra_specs to be populated since it
3768         # is receiving an object, so lookup the flavor to ensure this.
3769         if not isinstance(instance_type, objects.Flavor):
3770             instance_type = objects.Flavor.get_by_id(context,
3771                                                      instance_type['id'])
3772 
3773         quotas = objects.Quotas.from_reservations(context,
3774                                                   reservations,
3775                                                   instance=instance)
3776         with self._error_out_instance_on_exception(context, instance,
3777                                                    quotas=quotas):
3778             compute_utils.notify_usage_exists(self.notifier, context, instance,
3779                                               current_period=True)
3780             self._notify_about_instance_usage(
3781                     context, instance, "resize.prep.start")
3782             try:
3783                 self._prep_resize(context, image, instance,
3784                                   instance_type, quotas,
3785                                   request_spec, filter_properties,
3786                                   node, clean_shutdown)
3787             # NOTE(dgenin): This is thrown in LibvirtDriver when the
3788             #               instance to be migrated is backed by LVM.
3789             #               Remove when LVM migration is implemented.
3790             except exception.MigrationPreCheckError:
3791                 raise
3792             except Exception:
3793                 # try to re-schedule the resize elsewhere:
3794                 exc_info = sys.exc_info()
3795                 self._reschedule_resize_or_reraise(context, image, instance,
3796                         exc_info, instance_type, quotas, request_spec,
3797                         filter_properties)
3798             finally:
3799                 extra_usage_info = dict(
3800                         new_instance_type=instance_type.name,
3801                         new_instance_type_id=instance_type.id)
3802 
3803                 self._notify_about_instance_usage(
3804                     context, instance, "resize.prep.end",
3805                     extra_usage_info=extra_usage_info)
3806 
3807     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
3808             instance_type, quotas, request_spec, filter_properties):
3809         """Try to re-schedule the resize or re-raise the original error to
3810         error out the instance.
3811         """
3812         if not request_spec:
3813             request_spec = {}
3814         if not filter_properties:
3815             filter_properties = {}
3816 
3817         rescheduled = False
3818         instance_uuid = instance.uuid
3819 
3820         try:
3821             reschedule_method = self.compute_task_api.resize_instance
3822             scheduler_hint = dict(filter_properties=filter_properties)
3823             method_args = (instance, None, scheduler_hint, instance_type,
3824                            quotas.reservations)
3825             task_state = task_states.RESIZE_PREP
3826 
3827             rescheduled = self._reschedule(context, request_spec,
3828                     filter_properties, instance, reschedule_method,
3829                     method_args, task_state, exc_info)
3830         except Exception as error:
3831             rescheduled = False
3832             LOG.exception(_LE("Error trying to reschedule"),
3833                           instance_uuid=instance_uuid)
3834             compute_utils.add_instance_fault_from_exc(context,
3835                     instance, error,
3836                     exc_info=sys.exc_info())
3837             self._notify_about_instance_usage(context, instance,
3838                     'resize.error', fault=error)
3839 
3840         if rescheduled:
3841             self._log_original_error(exc_info, instance_uuid)
3842             compute_utils.add_instance_fault_from_exc(context,
3843                     instance, exc_info[1], exc_info=exc_info)
3844             self._notify_about_instance_usage(context, instance,
3845                     'resize.error', fault=exc_info[1])
3846         else:
3847             # not re-scheduling
3848             six.reraise(*exc_info)
3849 
3850     @wrap_exception()
3851     @reverts_task_state
3852     @wrap_instance_event(prefix='compute')
3853     @errors_out_migration
3854     @wrap_instance_fault
3855     def resize_instance(self, context, instance, image,
3856                         reservations, migration, instance_type,
3857                         clean_shutdown):
3858         """Starts the migration of a running instance to another host."""
3859 
3860         quotas = objects.Quotas.from_reservations(context,
3861                                                   reservations,
3862                                                   instance=instance)
3863         with self._error_out_instance_on_exception(context, instance,
3864                                                    quotas=quotas):
3865             # TODO(chaochin) Remove this until v5 RPC API
3866             # Code downstream may expect extra_specs to be populated since it
3867             # is receiving an object, so lookup the flavor to ensure this.
3868             if (not instance_type or
3869                 not isinstance(instance_type, objects.Flavor)):
3870                 instance_type = objects.Flavor.get_by_id(
3871                     context, migration['new_instance_type_id'])
3872 
3873             network_info = self.network_api.get_instance_nw_info(context,
3874                                                                  instance)
3875 
3876             migration.status = 'migrating'
3877             with migration.obj_as_admin():
3878                 migration.save()
3879 
3880             instance.task_state = task_states.RESIZE_MIGRATING
3881             instance.save(expected_task_state=task_states.RESIZE_PREP)
3882 
3883             self._notify_about_instance_usage(
3884                 context, instance, "resize.start", network_info=network_info)
3885 
3886             compute_utils.notify_about_instance_action(context, instance,
3887                    self.host, action=fields.NotificationAction.RESIZE,
3888                    phase=fields.NotificationPhase.START)
3889 
3890             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3891                     context, instance.uuid)
3892             block_device_info = self._get_instance_block_device_info(
3893                                 context, instance, bdms=bdms)
3894 
3895             timeout, retry_interval = self._get_power_off_values(context,
3896                                             instance, clean_shutdown)
3897             disk_info = self.driver.migrate_disk_and_power_off(
3898                     context, instance, migration.dest_host,
3899                     instance_type, network_info,
3900                     block_device_info,
3901                     timeout, retry_interval)
3902 
3903             self._terminate_volume_connections(context, instance, bdms)
3904 
3905             migration_p = obj_base.obj_to_primitive(migration)
3906             self.network_api.migrate_instance_start(context,
3907                                                     instance,
3908                                                     migration_p)
3909 
3910             migration.status = 'post-migrating'
3911             with migration.obj_as_admin():
3912                 migration.save()
3913 
3914             instance.host = migration.dest_compute
3915             instance.node = migration.dest_node
3916             instance.task_state = task_states.RESIZE_MIGRATED
3917             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
3918 
3919             self.compute_rpcapi.finish_resize(context, instance,
3920                     migration, image, disk_info,
3921                     migration.dest_compute, reservations=quotas.reservations)
3922 
3923             self._notify_about_instance_usage(context, instance, "resize.end",
3924                                               network_info=network_info)
3925 
3926             compute_utils.notify_about_instance_action(context, instance,
3927                    self.host, action=fields.NotificationAction.RESIZE,
3928                    phase=fields.NotificationPhase.END)
3929             self.instance_events.clear_events_for_instance(instance)
3930 
3931     def _terminate_volume_connections(self, context, instance, bdms):
3932         connector = self.driver.get_volume_connector(instance)
3933         for bdm in bdms:
3934             if bdm.is_volume:
3935                 self.volume_api.terminate_connection(context, bdm.volume_id,
3936                                                      connector)
3937 
3938     @staticmethod
3939     def _set_instance_info(instance, instance_type):
3940         instance.instance_type_id = instance_type.id
3941         # NOTE(danms): These are purely for any legacy code that still
3942         # looks at them.
3943         instance.memory_mb = instance_type.memory_mb
3944         instance.vcpus = instance_type.vcpus
3945         instance.root_gb = instance_type.root_gb
3946         instance.ephemeral_gb = instance_type.ephemeral_gb
3947         instance.flavor = instance_type
3948 
3949     def _finish_resize(self, context, instance, migration, disk_info,
3950                        image_meta):
3951         resize_instance = False
3952         old_instance_type_id = migration['old_instance_type_id']
3953         new_instance_type_id = migration['new_instance_type_id']
3954         old_instance_type = instance.get_flavor()
3955         # NOTE(mriedem): Get the old_vm_state so we know if we should
3956         # power on the instance. If old_vm_state is not set we need to default
3957         # to ACTIVE for backwards compatibility
3958         old_vm_state = instance.system_metadata.get('old_vm_state',
3959                                                     vm_states.ACTIVE)
3960         instance.old_flavor = old_instance_type
3961 
3962         if old_instance_type_id != new_instance_type_id:
3963             instance_type = instance.get_flavor('new')
3964             self._set_instance_info(instance, instance_type)
3965             for key in ('root_gb', 'swap', 'ephemeral_gb'):
3966                 if old_instance_type[key] != instance_type[key]:
3967                     resize_instance = True
3968                     break
3969         instance.apply_migration_context()
3970 
3971         # NOTE(tr3buchet): setup networks on destination host
3972         self.network_api.setup_networks_on_host(context, instance,
3973                                                 migration['dest_compute'])
3974 
3975         migration_p = obj_base.obj_to_primitive(migration)
3976         self.network_api.migrate_instance_finish(context,
3977                                                  instance,
3978                                                  migration_p)
3979 
3980         network_info = self.network_api.get_instance_nw_info(context, instance)
3981 
3982         instance.task_state = task_states.RESIZE_FINISH
3983         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
3984 
3985         self._notify_about_instance_usage(
3986             context, instance, "finish_resize.start",
3987             network_info=network_info)
3988         compute_utils.notify_about_instance_action(context, instance,
3989                self.host, action=fields.NotificationAction.RESIZE_FINISH,
3990                phase=fields.NotificationPhase.START)
3991 
3992         block_device_info = self._get_instance_block_device_info(
3993                             context, instance, refresh_conn_info=True)
3994 
3995         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
3996         # automatically power on the instance after it's migrated
3997         power_on = old_vm_state != vm_states.STOPPED
3998 
3999         try:
4000             self.driver.finish_migration(context, migration, instance,
4001                                          disk_info,
4002                                          network_info,
4003                                          image_meta, resize_instance,
4004                                          block_device_info, power_on)
4005         except Exception:
4006             with excutils.save_and_reraise_exception():
4007                 if old_instance_type_id != new_instance_type_id:
4008                     self._set_instance_info(instance,
4009                                             old_instance_type)
4010 
4011         migration.status = 'finished'
4012         with migration.obj_as_admin():
4013             migration.save()
4014 
4015         instance.vm_state = vm_states.RESIZED
4016         instance.task_state = None
4017         instance.launched_at = timeutils.utcnow()
4018         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4019 
4020         self._update_scheduler_instance_info(context, instance)
4021         self._notify_about_instance_usage(
4022             context, instance, "finish_resize.end",
4023             network_info=network_info)
4024         compute_utils.notify_about_instance_action(context, instance,
4025                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4026                phase=fields.NotificationPhase.END)
4027 
4028     @wrap_exception()
4029     @reverts_task_state
4030     @wrap_instance_event(prefix='compute')
4031     @errors_out_migration
4032     @wrap_instance_fault
4033     def finish_resize(self, context, disk_info, image, instance,
4034                       reservations, migration):
4035         """Completes the migration process.
4036 
4037         Sets up the newly transferred disk and turns on the instance at its
4038         new host machine.
4039 
4040         """
4041         quotas = objects.Quotas.from_reservations(context,
4042                                                   reservations,
4043                                                   instance=instance)
4044         try:
4045             image_meta = objects.ImageMeta.from_dict(image)
4046             self._finish_resize(context, instance, migration,
4047                                 disk_info, image_meta)
4048             quotas.commit()
4049         except Exception:
4050             LOG.exception(_LE('Setting instance vm_state to ERROR'),
4051                           instance=instance)
4052             with excutils.save_and_reraise_exception():
4053                 try:
4054                     quotas.rollback()
4055                 except Exception:
4056                     LOG.exception(_LE("Failed to rollback quota for failed "
4057                                       "finish_resize"),
4058                                   instance=instance)
4059                 self._set_instance_obj_error_state(context, instance)
4060 
4061     @wrap_exception()
4062     @wrap_instance_fault
4063     def add_fixed_ip_to_instance(self, context, network_id, instance):
4064         """Calls network_api to add new fixed_ip to instance
4065         then injects the new network info and resets instance networking.
4066 
4067         """
4068         self._notify_about_instance_usage(
4069                 context, instance, "create_ip.start")
4070 
4071         network_info = self.network_api.add_fixed_ip_to_instance(context,
4072                                                                  instance,
4073                                                                  network_id)
4074         self._inject_network_info(context, instance, network_info)
4075         self.reset_network(context, instance)
4076 
4077         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4078         instance.updated_at = timeutils.utcnow()
4079         instance.save()
4080 
4081         self._notify_about_instance_usage(
4082             context, instance, "create_ip.end", network_info=network_info)
4083 
4084     @wrap_exception()
4085     @wrap_instance_fault
4086     def remove_fixed_ip_from_instance(self, context, address, instance):
4087         """Calls network_api to remove existing fixed_ip from instance
4088         by injecting the altered network info and resetting
4089         instance networking.
4090         """
4091         self._notify_about_instance_usage(
4092                 context, instance, "delete_ip.start")
4093 
4094         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4095                                                                       instance,
4096                                                                       address)
4097         self._inject_network_info(context, instance, network_info)
4098         self.reset_network(context, instance)
4099 
4100         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4101         instance.updated_at = timeutils.utcnow()
4102         instance.save()
4103 
4104         self._notify_about_instance_usage(
4105             context, instance, "delete_ip.end", network_info=network_info)
4106 
4107     @wrap_exception()
4108     @reverts_task_state
4109     @wrap_instance_event(prefix='compute')
4110     @wrap_instance_fault
4111     def pause_instance(self, context, instance):
4112         """Pause an instance on this host."""
4113         context = context.elevated()
4114         LOG.info(_LI('Pausing'), instance=instance)
4115         self._notify_about_instance_usage(context, instance, 'pause.start')
4116         compute_utils.notify_about_instance_action(context, instance,
4117                self.host, action=fields.NotificationAction.PAUSE,
4118                phase=fields.NotificationPhase.START)
4119         self.driver.pause(instance)
4120         instance.power_state = self._get_power_state(context, instance)
4121         instance.vm_state = vm_states.PAUSED
4122         instance.task_state = None
4123         instance.save(expected_task_state=task_states.PAUSING)
4124         self._notify_about_instance_usage(context, instance, 'pause.end')
4125         compute_utils.notify_about_instance_action(context, instance,
4126                self.host, action=fields.NotificationAction.PAUSE,
4127                phase=fields.NotificationPhase.END)
4128 
4129     @wrap_exception()
4130     @reverts_task_state
4131     @wrap_instance_event(prefix='compute')
4132     @wrap_instance_fault
4133     def unpause_instance(self, context, instance):
4134         """Unpause a paused instance on this host."""
4135         context = context.elevated()
4136         LOG.info(_LI('Unpausing'), instance=instance)
4137         self._notify_about_instance_usage(context, instance, 'unpause.start')
4138         compute_utils.notify_about_instance_action(context, instance,
4139             self.host, action=fields.NotificationAction.UNPAUSE,
4140             phase=fields.NotificationPhase.START)
4141         self.driver.unpause(instance)
4142         instance.power_state = self._get_power_state(context, instance)
4143         instance.vm_state = vm_states.ACTIVE
4144         instance.task_state = None
4145         instance.save(expected_task_state=task_states.UNPAUSING)
4146         self._notify_about_instance_usage(context, instance, 'unpause.end')
4147         compute_utils.notify_about_instance_action(context, instance,
4148             self.host, action=fields.NotificationAction.UNPAUSE,
4149             phase=fields.NotificationPhase.END)
4150 
4151     @wrap_exception()
4152     def host_power_action(self, context, action):
4153         """Reboots, shuts down or powers up the host."""
4154         return self.driver.host_power_action(action)
4155 
4156     @wrap_exception()
4157     def host_maintenance_mode(self, context, host, mode):
4158         """Start/Stop host maintenance window. On start, it triggers
4159         guest VMs evacuation.
4160         """
4161         return self.driver.host_maintenance_mode(host, mode)
4162 
4163     @wrap_exception()
4164     def set_host_enabled(self, context, enabled):
4165         """Sets the specified host's ability to accept new instances."""
4166         return self.driver.set_host_enabled(enabled)
4167 
4168     @wrap_exception()
4169     def get_host_uptime(self, context):
4170         """Returns the result of calling "uptime" on the target host."""
4171         return self.driver.get_host_uptime()
4172 
4173     @wrap_exception()
4174     @wrap_instance_fault
4175     def get_diagnostics(self, context, instance):
4176         """Retrieve diagnostics for an instance on this host."""
4177         current_power_state = self._get_power_state(context, instance)
4178         if current_power_state == power_state.RUNNING:
4179             LOG.info(_LI("Retrieving diagnostics"), instance=instance)
4180             return self.driver.get_diagnostics(instance)
4181         else:
4182             raise exception.InstanceInvalidState(
4183                 attr='power state',
4184                 instance_uuid=instance.uuid,
4185                 state=power_state.STATE_MAP[instance.power_state],
4186                 method='get_diagnostics')
4187 
4188     # TODO(alaski): Remove object_compat for RPC version 5.0
4189     @object_compat
4190     @wrap_exception()
4191     @wrap_instance_fault
4192     def get_instance_diagnostics(self, context, instance):
4193         """Retrieve diagnostics for an instance on this host."""
4194         current_power_state = self._get_power_state(context, instance)
4195         if current_power_state == power_state.RUNNING:
4196             LOG.info(_LI("Retrieving diagnostics"), instance=instance)
4197             diags = self.driver.get_instance_diagnostics(instance)
4198             return diags.serialize()
4199         else:
4200             raise exception.InstanceInvalidState(
4201                 attr='power state',
4202                 instance_uuid=instance.uuid,
4203                 state=power_state.STATE_MAP[instance.power_state],
4204                 method='get_diagnostics')
4205 
4206     @wrap_exception()
4207     @reverts_task_state
4208     @wrap_instance_event(prefix='compute')
4209     @wrap_instance_fault
4210     def suspend_instance(self, context, instance):
4211         """Suspend the given instance."""
4212         context = context.elevated()
4213 
4214         # Store the old state
4215         instance.system_metadata['old_vm_state'] = instance.vm_state
4216         self._notify_about_instance_usage(context, instance, 'suspend.start')
4217         compute_utils.notify_about_instance_action(context, instance,
4218                 self.host, action=fields.NotificationAction.SUSPEND,
4219                 phase=fields.NotificationPhase.START)
4220         with self._error_out_instance_on_exception(context, instance,
4221              instance_state=instance.vm_state):
4222             self.driver.suspend(context, instance)
4223         instance.power_state = self._get_power_state(context, instance)
4224         instance.vm_state = vm_states.SUSPENDED
4225         instance.task_state = None
4226         instance.save(expected_task_state=task_states.SUSPENDING)
4227         self._notify_about_instance_usage(context, instance, 'suspend.end')
4228         compute_utils.notify_about_instance_action(context, instance,
4229                 self.host, action=fields.NotificationAction.SUSPEND,
4230                 phase=fields.NotificationPhase.END)
4231 
4232     @wrap_exception()
4233     @reverts_task_state
4234     @wrap_instance_event(prefix='compute')
4235     @wrap_instance_fault
4236     def resume_instance(self, context, instance):
4237         """Resume the given suspended instance."""
4238         context = context.elevated()
4239         LOG.info(_LI('Resuming'), instance=instance)
4240 
4241         self._notify_about_instance_usage(context, instance, 'resume.start')
4242         compute_utils.notify_about_instance_action(context, instance,
4243             self.host, action=fields.NotificationAction.RESUME,
4244             phase=fields.NotificationPhase.START)
4245 
4246         network_info = self.network_api.get_instance_nw_info(context, instance)
4247         block_device_info = self._get_instance_block_device_info(
4248                             context, instance)
4249 
4250         with self._error_out_instance_on_exception(context, instance,
4251              instance_state=instance.vm_state):
4252             self.driver.resume(context, instance, network_info,
4253                                block_device_info)
4254 
4255         instance.power_state = self._get_power_state(context, instance)
4256 
4257         # We default to the ACTIVE state for backwards compatibility
4258         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4259                                                          vm_states.ACTIVE)
4260 
4261         instance.task_state = None
4262         instance.save(expected_task_state=task_states.RESUMING)
4263         self._notify_about_instance_usage(context, instance, 'resume.end')
4264         compute_utils.notify_about_instance_action(context, instance,
4265             self.host, action=fields.NotificationAction.RESUME,
4266             phase=fields.NotificationPhase.END)
4267 
4268     @wrap_exception()
4269     @reverts_task_state
4270     @wrap_instance_event(prefix='compute')
4271     @wrap_instance_fault
4272     def shelve_instance(self, context, instance, image_id,
4273                         clean_shutdown):
4274         """Shelve an instance.
4275 
4276         This should be used when you want to take a snapshot of the instance.
4277         It also adds system_metadata that can be used by a periodic task to
4278         offload the shelved instance after a period of time.
4279 
4280         :param context: request context
4281         :param instance: an Instance object
4282         :param image_id: an image id to snapshot to.
4283         :param clean_shutdown: give the GuestOS a chance to stop
4284         """
4285 
4286         @utils.synchronized(instance.uuid)
4287         def do_shelve_instance():
4288             self._shelve_instance(context, instance, image_id, clean_shutdown)
4289         do_shelve_instance()
4290 
4291     def _shelve_instance(self, context, instance, image_id,
4292                          clean_shutdown):
4293         LOG.info(_LI('Shelving'), instance=instance)
4294         compute_utils.notify_usage_exists(self.notifier, context, instance,
4295                                           current_period=True)
4296         self._notify_about_instance_usage(context, instance, 'shelve.start')
4297         compute_utils.notify_about_instance_action(context, instance,
4298                 self.host, action=fields.NotificationAction.SHELVE,
4299                 phase=fields.NotificationPhase.START)
4300 
4301         def update_task_state(task_state, expected_state=task_states.SHELVING):
4302             shelving_state_map = {
4303                     task_states.IMAGE_PENDING_UPLOAD:
4304                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4305                     task_states.IMAGE_UPLOADING:
4306                         task_states.SHELVING_IMAGE_UPLOADING,
4307                     task_states.SHELVING: task_states.SHELVING}
4308             task_state = shelving_state_map[task_state]
4309             expected_state = shelving_state_map[expected_state]
4310             instance.task_state = task_state
4311             instance.save(expected_task_state=expected_state)
4312 
4313         self._power_off_instance(context, instance, clean_shutdown)
4314         self.driver.snapshot(context, instance, image_id, update_task_state)
4315 
4316         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4317         instance.system_metadata['shelved_image_id'] = image_id
4318         instance.system_metadata['shelved_host'] = self.host
4319         instance.vm_state = vm_states.SHELVED
4320         instance.task_state = None
4321         if CONF.shelved_offload_time == 0:
4322             instance.task_state = task_states.SHELVING_OFFLOADING
4323         instance.power_state = self._get_power_state(context, instance)
4324         instance.save(expected_task_state=[
4325                 task_states.SHELVING,
4326                 task_states.SHELVING_IMAGE_UPLOADING])
4327 
4328         self._notify_about_instance_usage(context, instance, 'shelve.end')
4329         compute_utils.notify_about_instance_action(context, instance,
4330                 self.host, action=fields.NotificationAction.SHELVE,
4331                 phase=fields.NotificationPhase.END)
4332 
4333         if CONF.shelved_offload_time == 0:
4334             self._shelve_offload_instance(context, instance,
4335                                           clean_shutdown=False)
4336 
4337     @wrap_exception()
4338     @reverts_task_state
4339     @wrap_instance_fault
4340     def shelve_offload_instance(self, context, instance, clean_shutdown):
4341         """Remove a shelved instance from the hypervisor.
4342 
4343         This frees up those resources for use by other instances, but may lead
4344         to slower unshelve times for this instance.  This method is used by
4345         volume backed instances since restoring them doesn't involve the
4346         potentially large download of an image.
4347 
4348         :param context: request context
4349         :param instance: nova.objects.instance.Instance
4350         :param clean_shutdown: give the GuestOS a chance to stop
4351         """
4352 
4353         @utils.synchronized(instance.uuid)
4354         def do_shelve_offload_instance():
4355             self._shelve_offload_instance(context, instance, clean_shutdown)
4356         do_shelve_offload_instance()
4357 
4358     def _shelve_offload_instance(self, context, instance, clean_shutdown):
4359         LOG.info(_LI('Shelve offloading'), instance=instance)
4360         self._notify_about_instance_usage(context, instance,
4361                 'shelve_offload.start')
4362         compute_utils.notify_about_instance_action(context, instance,
4363                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4364                 phase=fields.NotificationPhase.START)
4365 
4366         self._power_off_instance(context, instance, clean_shutdown)
4367         current_power_state = self._get_power_state(context, instance)
4368 
4369         self.network_api.cleanup_instance_network_on_host(context, instance,
4370                                                           instance.host)
4371         network_info = self.network_api.get_instance_nw_info(context, instance)
4372         block_device_info = self._get_instance_block_device_info(context,
4373                                                                  instance)
4374         self.driver.destroy(context, instance, network_info,
4375                 block_device_info)
4376 
4377         instance.power_state = current_power_state
4378         # NOTE(mriedem): The vm_state has to be set before updating the
4379         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4380         # values cannot be nulled out until after updating the resource tracker
4381         # though.
4382         instance.vm_state = vm_states.SHELVED_OFFLOADED
4383         instance.task_state = None
4384         instance.save(expected_task_state=[task_states.SHELVING,
4385                                            task_states.SHELVING_OFFLOADING])
4386 
4387         # NOTE(ndipanov): Free resources from the resource tracker
4388         self._update_resource_tracker(context, instance)
4389 
4390         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4391         # instance, so ensure any calls result in errors
4392         self._nil_out_instance_obj_host_and_node(instance)
4393         instance.save(expected_task_state=None)
4394 
4395         self._delete_scheduler_instance_info(context, instance.uuid)
4396         self._notify_about_instance_usage(context, instance,
4397                 'shelve_offload.end')
4398         compute_utils.notify_about_instance_action(context, instance,
4399                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4400                 phase=fields.NotificationPhase.END)
4401 
4402     @wrap_exception()
4403     @reverts_task_state
4404     @wrap_instance_event(prefix='compute')
4405     @wrap_instance_fault
4406     def unshelve_instance(self, context, instance, image,
4407                           filter_properties, node):
4408         """Unshelve the instance.
4409 
4410         :param context: request context
4411         :param instance: a nova.objects.instance.Instance object
4412         :param image: an image to build from.  If None we assume a
4413             volume backed instance.
4414         :param filter_properties: dict containing limits, retry info etc.
4415         :param node: target compute node
4416         """
4417         if filter_properties is None:
4418             filter_properties = {}
4419 
4420         @utils.synchronized(instance.uuid)
4421         def do_unshelve_instance():
4422             self._unshelve_instance(context, instance, image,
4423                                     filter_properties, node)
4424         do_unshelve_instance()
4425 
4426     def _unshelve_instance_key_scrub(self, instance):
4427         """Remove data from the instance that may cause side effects."""
4428         cleaned_keys = dict(
4429                 key_data=instance.key_data,
4430                 auto_disk_config=instance.auto_disk_config)
4431         instance.key_data = None
4432         instance.auto_disk_config = False
4433         return cleaned_keys
4434 
4435     def _unshelve_instance_key_restore(self, instance, keys):
4436         """Restore previously scrubbed keys before saving the instance."""
4437         instance.update(keys)
4438 
4439     def _unshelve_instance(self, context, instance, image, filter_properties,
4440                            node):
4441         LOG.info(_LI('Unshelving'), instance=instance)
4442         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4443         compute_utils.notify_about_instance_action(context, instance,
4444                 self.host, action=fields.NotificationAction.UNSHELVE,
4445                 phase=fields.NotificationPhase.START)
4446 
4447         instance.task_state = task_states.SPAWNING
4448         instance.save()
4449 
4450         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4451                 context, instance.uuid)
4452         block_device_info = self._prep_block_device(context, instance, bdms)
4453         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4454 
4455         if node is None:
4456             node = self.driver.get_available_nodes()[0]
4457             LOG.debug('No node specified, defaulting to %s', node,
4458                       instance=instance)
4459 
4460         rt = self._get_resource_tracker()
4461         limits = filter_properties.get('limits', {})
4462 
4463         shelved_image_ref = instance.image_ref
4464         if image:
4465             instance.image_ref = image['id']
4466             image_meta = objects.ImageMeta.from_dict(image)
4467         else:
4468             image_meta = objects.ImageMeta.from_dict(
4469                 utils.get_image_from_system_metadata(
4470                     instance.system_metadata))
4471 
4472         self.network_api.setup_instance_network_on_host(context, instance,
4473                                                         self.host)
4474         network_info = self.network_api.get_instance_nw_info(context, instance)
4475         try:
4476             with rt.instance_claim(context, instance, node, limits):
4477                 self.driver.spawn(context, instance, image_meta,
4478                                   injected_files=[],
4479                                   admin_password=None,
4480                                   network_info=network_info,
4481                                   block_device_info=block_device_info)
4482         except Exception:
4483             with excutils.save_and_reraise_exception():
4484                 LOG.exception(_LE('Instance failed to spawn'),
4485                               instance=instance)
4486 
4487         if image:
4488             instance.image_ref = shelved_image_ref
4489             self._delete_snapshot_of_shelved_instance(context, instance,
4490                                                       image['id'])
4491 
4492         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4493         self._update_instance_after_spawn(context, instance)
4494         # Delete system_metadata for a shelved instance
4495         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4496 
4497         instance.save(expected_task_state=task_states.SPAWNING)
4498         self._update_scheduler_instance_info(context, instance)
4499         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4500         compute_utils.notify_about_instance_action(context, instance,
4501                 self.host, action=fields.NotificationAction.UNSHELVE,
4502                 phase=fields.NotificationPhase.END)
4503 
4504     @messaging.expected_exceptions(NotImplementedError)
4505     @wrap_instance_fault
4506     def reset_network(self, context, instance):
4507         """Reset networking on the given instance."""
4508         LOG.debug('Reset network', instance=instance)
4509         self.driver.reset_network(instance)
4510 
4511     def _inject_network_info(self, context, instance, network_info):
4512         """Inject network info for the given instance."""
4513         LOG.debug('Inject network info', instance=instance)
4514         LOG.debug('network_info to inject: |%s|', network_info,
4515                   instance=instance)
4516 
4517         self.driver.inject_network_info(instance,
4518                                         network_info)
4519 
4520     @wrap_instance_fault
4521     def inject_network_info(self, context, instance):
4522         """Inject network info, but don't return the info."""
4523         network_info = self.network_api.get_instance_nw_info(context, instance)
4524         self._inject_network_info(context, instance, network_info)
4525 
4526     @messaging.expected_exceptions(NotImplementedError,
4527                                    exception.ConsoleNotAvailable,
4528                                    exception.InstanceNotFound)
4529     @wrap_exception()
4530     @wrap_instance_fault
4531     def get_console_output(self, context, instance, tail_length):
4532         """Send the console output for the given instance."""
4533         context = context.elevated()
4534         LOG.info(_LI("Get console output"), instance=instance)
4535         output = self.driver.get_console_output(context, instance)
4536 
4537         if type(output) is six.text_type:
4538             output = six.b(output)
4539 
4540         if tail_length is not None:
4541             output = self._tail_log(output, tail_length)
4542 
4543         return output.decode('ascii', 'replace')
4544 
4545     def _tail_log(self, log, length):
4546         try:
4547             length = int(length)
4548         except ValueError:
4549             length = 0
4550 
4551         if length == 0:
4552             return b''
4553         else:
4554             return b'\n'.join(log.split(b'\n')[-int(length):])
4555 
4556     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4557                                    exception.InstanceNotReady,
4558                                    exception.InstanceNotFound,
4559                                    exception.ConsoleTypeUnavailable,
4560                                    NotImplementedError)
4561     @wrap_exception()
4562     @wrap_instance_fault
4563     def get_vnc_console(self, context, console_type, instance):
4564         """Return connection information for a vnc console."""
4565         context = context.elevated()
4566         LOG.debug("Getting vnc console", instance=instance)
4567         token = uuidutils.generate_uuid()
4568 
4569         if not CONF.vnc.enabled:
4570             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4571 
4572         if console_type == 'novnc':
4573             # For essex, novncproxy_base_url must include the full path
4574             # including the html file (like http://myhost/vnc_auto.html)
4575             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
4576         elif console_type == 'xvpvnc':
4577             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
4578         else:
4579             raise exception.ConsoleTypeInvalid(console_type=console_type)
4580 
4581         try:
4582             # Retrieve connect info from driver, and then decorate with our
4583             # access info token
4584             console = self.driver.get_vnc_console(context, instance)
4585             connect_info = console.get_connection_info(token, access_url)
4586         except exception.InstanceNotFound:
4587             if instance.vm_state != vm_states.BUILDING:
4588                 raise
4589             raise exception.InstanceNotReady(instance_id=instance.uuid)
4590 
4591         return connect_info
4592 
4593     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4594                                    exception.InstanceNotReady,
4595                                    exception.InstanceNotFound,
4596                                    exception.ConsoleTypeUnavailable,
4597                                    NotImplementedError)
4598     @wrap_exception()
4599     @wrap_instance_fault
4600     def get_spice_console(self, context, console_type, instance):
4601         """Return connection information for a spice console."""
4602         context = context.elevated()
4603         LOG.debug("Getting spice console", instance=instance)
4604         token = uuidutils.generate_uuid()
4605 
4606         if not CONF.spice.enabled:
4607             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4608 
4609         if console_type == 'spice-html5':
4610             # For essex, spicehtml5proxy_base_url must include the full path
4611             # including the html file (like http://myhost/spice_auto.html)
4612             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
4613                                           token)
4614         else:
4615             raise exception.ConsoleTypeInvalid(console_type=console_type)
4616 
4617         try:
4618             # Retrieve connect info from driver, and then decorate with our
4619             # access info token
4620             console = self.driver.get_spice_console(context, instance)
4621             connect_info = console.get_connection_info(token, access_url)
4622         except exception.InstanceNotFound:
4623             if instance.vm_state != vm_states.BUILDING:
4624                 raise
4625             raise exception.InstanceNotReady(instance_id=instance.uuid)
4626 
4627         return connect_info
4628 
4629     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4630                                    exception.InstanceNotReady,
4631                                    exception.InstanceNotFound,
4632                                    exception.ConsoleTypeUnavailable,
4633                                    NotImplementedError)
4634     @wrap_exception()
4635     @wrap_instance_fault
4636     def get_rdp_console(self, context, console_type, instance):
4637         """Return connection information for a RDP console."""
4638         context = context.elevated()
4639         LOG.debug("Getting RDP console", instance=instance)
4640         token = uuidutils.generate_uuid()
4641 
4642         if not CONF.rdp.enabled:
4643             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4644 
4645         if console_type == 'rdp-html5':
4646             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
4647                                           token)
4648         else:
4649             raise exception.ConsoleTypeInvalid(console_type=console_type)
4650 
4651         try:
4652             # Retrieve connect info from driver, and then decorate with our
4653             # access info token
4654             console = self.driver.get_rdp_console(context, instance)
4655             connect_info = console.get_connection_info(token, access_url)
4656         except exception.InstanceNotFound:
4657             if instance.vm_state != vm_states.BUILDING:
4658                 raise
4659             raise exception.InstanceNotReady(instance_id=instance.uuid)
4660 
4661         return connect_info
4662 
4663     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4664                                    exception.InstanceNotReady,
4665                                    exception.InstanceNotFound,
4666                                    exception.ConsoleTypeUnavailable,
4667                                    NotImplementedError)
4668     @wrap_exception()
4669     @wrap_instance_fault
4670     def get_mks_console(self, context, console_type, instance):
4671         """Return connection information for a MKS console."""
4672         context = context.elevated()
4673         LOG.debug("Getting MKS console", instance=instance)
4674         token = uuidutils.generate_uuid()
4675 
4676         if not CONF.mks.enabled:
4677             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4678 
4679         if console_type == 'webmks':
4680             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
4681                                           token)
4682         else:
4683             raise exception.ConsoleTypeInvalid(console_type=console_type)
4684 
4685         try:
4686             # Retrieve connect info from driver, and then decorate with our
4687             # access info token
4688             console = self.driver.get_mks_console(context, instance)
4689             connect_info = console.get_connection_info(token, access_url)
4690         except exception.InstanceNotFound:
4691             if instance.vm_state != vm_states.BUILDING:
4692                 raise
4693             raise exception.InstanceNotReady(instance_id=instance.uuid)
4694 
4695         return connect_info
4696 
4697     @messaging.expected_exceptions(
4698         exception.ConsoleTypeInvalid,
4699         exception.InstanceNotReady,
4700         exception.InstanceNotFound,
4701         exception.ConsoleTypeUnavailable,
4702         exception.SocketPortRangeExhaustedException,
4703         exception.ImageSerialPortNumberInvalid,
4704         exception.ImageSerialPortNumberExceedFlavorValue,
4705         NotImplementedError)
4706     @wrap_exception()
4707     @wrap_instance_fault
4708     def get_serial_console(self, context, console_type, instance):
4709         """Returns connection information for a serial console."""
4710 
4711         LOG.debug("Getting serial console", instance=instance)
4712 
4713         if not CONF.serial_console.enabled:
4714             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4715 
4716         context = context.elevated()
4717 
4718         token = uuidutils.generate_uuid()
4719         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
4720 
4721         try:
4722             # Retrieve connect info from driver, and then decorate with our
4723             # access info token
4724             console = self.driver.get_serial_console(context, instance)
4725             connect_info = console.get_connection_info(token, access_url)
4726         except exception.InstanceNotFound:
4727             if instance.vm_state != vm_states.BUILDING:
4728                 raise
4729             raise exception.InstanceNotReady(instance_id=instance.uuid)
4730 
4731         return connect_info
4732 
4733     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4734                                    exception.InstanceNotReady,
4735                                    exception.InstanceNotFound)
4736     @wrap_exception()
4737     @wrap_instance_fault
4738     def validate_console_port(self, ctxt, instance, port, console_type):
4739         if console_type == "spice-html5":
4740             console_info = self.driver.get_spice_console(ctxt, instance)
4741         elif console_type == "rdp-html5":
4742             console_info = self.driver.get_rdp_console(ctxt, instance)
4743         elif console_type == "serial":
4744             console_info = self.driver.get_serial_console(ctxt, instance)
4745         elif console_type == "webmks":
4746             console_info = self.driver.get_mks_console(ctxt, instance)
4747         else:
4748             console_info = self.driver.get_vnc_console(ctxt, instance)
4749 
4750         return console_info.port == port
4751 
4752     @wrap_exception()
4753     @reverts_task_state
4754     @wrap_instance_fault
4755     def reserve_block_device_name(self, context, instance, device,
4756                                   volume_id, disk_bus, device_type):
4757         @utils.synchronized(instance.uuid)
4758         def do_reserve():
4759             bdms = (
4760                 objects.BlockDeviceMappingList.get_by_instance_uuid(
4761                     context, instance.uuid))
4762 
4763             # NOTE(ndipanov): We need to explicitly set all the fields on the
4764             #                 object so that obj_load_attr does not fail
4765             new_bdm = objects.BlockDeviceMapping(
4766                     context=context,
4767                     source_type='volume', destination_type='volume',
4768                     instance_uuid=instance.uuid, boot_index=None,
4769                     volume_id=volume_id,
4770                     device_name=device, guest_format=None,
4771                     disk_bus=disk_bus, device_type=device_type)
4772 
4773             new_bdm.device_name = self._get_device_name_for_instance(
4774                     instance, bdms, new_bdm)
4775 
4776             # NOTE(vish): create bdm here to avoid race condition
4777             new_bdm.create()
4778             return new_bdm
4779 
4780         return do_reserve()
4781 
4782     @wrap_exception()
4783     @wrap_instance_fault
4784     def attach_volume(self, context, instance, bdm):
4785         """Attach a volume to an instance."""
4786         driver_bdm = driver_block_device.convert_volume(bdm)
4787 
4788         @utils.synchronized(instance.uuid)
4789         def do_attach_volume(context, instance, driver_bdm):
4790             try:
4791                 return self._attach_volume(context, instance, driver_bdm)
4792             except Exception:
4793                 with excutils.save_and_reraise_exception():
4794                     bdm.destroy()
4795 
4796         do_attach_volume(context, instance, driver_bdm)
4797 
4798     def _attach_volume(self, context, instance, bdm):
4799         context = context.elevated()
4800         LOG.info(_LI('Attaching volume %(volume_id)s to %(mountpoint)s'),
4801                   {'volume_id': bdm.volume_id,
4802                   'mountpoint': bdm['mount_device']},
4803                  instance=instance)
4804         try:
4805             bdm.attach(context, instance, self.volume_api, self.driver,
4806                        do_driver_attach=True)
4807         except Exception:
4808             with excutils.save_and_reraise_exception():
4809                 LOG.exception(_LE("Failed to attach %(volume_id)s "
4810                                   "at %(mountpoint)s"),
4811                               {'volume_id': bdm.volume_id,
4812                                'mountpoint': bdm['mount_device']},
4813                               instance=instance)
4814                 self.volume_api.unreserve_volume(context, bdm.volume_id)
4815 
4816         info = {'volume_id': bdm.volume_id}
4817         self._notify_about_instance_usage(
4818             context, instance, "volume.attach", extra_usage_info=info)
4819 
4820     def _driver_detach_volume(self, context, instance, bdm, connection_info):
4821         """Do the actual driver detach using block device mapping."""
4822         mp = bdm.device_name
4823         volume_id = bdm.volume_id
4824 
4825         LOG.info(_LI('Detach volume %(volume_id)s from mountpoint %(mp)s'),
4826                   {'volume_id': volume_id, 'mp': mp},
4827                   instance=instance)
4828 
4829         try:
4830             if not self.driver.instance_exists(instance):
4831                 LOG.warning(_LW('Detaching volume from unknown instance'),
4832                             instance=instance)
4833 
4834             encryption = encryptors.get_encryption_metadata(
4835                 context, self.volume_api, volume_id, connection_info)
4836 
4837             self.driver.detach_volume(connection_info,
4838                                       instance,
4839                                       mp,
4840                                       encryption=encryption)
4841         except exception.DiskNotFound as err:
4842             LOG.warning(_LW('Ignoring DiskNotFound exception while detaching '
4843                             'volume %(volume_id)s from %(mp)s: %(err)s'),
4844                         {'volume_id': volume_id, 'mp': mp, 'err': err},
4845                         instance=instance)
4846         except Exception:
4847             with excutils.save_and_reraise_exception():
4848                 LOG.exception(_LE('Failed to detach volume %(volume_id)s '
4849                                   'from %(mp)s'),
4850                               {'volume_id': volume_id, 'mp': mp},
4851                               instance=instance)
4852                 self.volume_api.roll_detaching(context, volume_id)
4853 
4854     def _detach_volume(self, context, volume_id, instance, destroy_bdm=True,
4855                        attachment_id=None):
4856         """Detach a volume from an instance.
4857 
4858         :param context: security context
4859         :param volume_id: the volume id
4860         :param instance: the Instance object to detach the volume from
4861         :param destroy_bdm: if True, the corresponding BDM entry will be marked
4862                             as deleted. Disabling this is useful for operations
4863                             like rebuild, when we don't want to destroy BDM
4864 
4865         """
4866 
4867         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4868                 context, volume_id, instance.uuid)
4869         if CONF.volume_usage_poll_interval > 0:
4870             vol_stats = []
4871             mp = bdm.device_name
4872             # Handle bootable volumes which will not contain /dev/
4873             if '/dev/' in mp:
4874                 mp = mp[5:]
4875             try:
4876                 vol_stats = self.driver.block_stats(instance, mp)
4877             except NotImplementedError:
4878                 pass
4879 
4880             if vol_stats:
4881                 LOG.debug("Updating volume usage cache with totals",
4882                           instance=instance)
4883                 rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
4884                 vol_usage = objects.VolumeUsage(context)
4885                 vol_usage.volume_id = volume_id
4886                 vol_usage.instance_uuid = instance.uuid
4887                 vol_usage.project_id = instance.project_id
4888                 vol_usage.user_id = instance.user_id
4889                 vol_usage.availability_zone = instance.availability_zone
4890                 vol_usage.curr_reads = rd_req
4891                 vol_usage.curr_read_bytes = rd_bytes
4892                 vol_usage.curr_writes = wr_req
4893                 vol_usage.curr_write_bytes = wr_bytes
4894                 vol_usage.save(update_totals=True)
4895                 self.notifier.info(context, 'volume.usage',
4896                                    compute_utils.usage_volume_info(vol_usage))
4897 
4898         connection_info = jsonutils.loads(bdm.connection_info)
4899         connector = self.driver.get_volume_connector(instance)
4900         if CONF.host == instance.host:
4901             # Only attempt to detach and disconnect from the volume if the
4902             # instance is currently associated with the local compute host.
4903             self._driver_detach_volume(context, instance, bdm, connection_info)
4904         elif not destroy_bdm:
4905             LOG.debug("Skipping _driver_detach_volume during remote rebuild.",
4906                       instance=instance)
4907         elif destroy_bdm:
4908             LOG.error(_LE("Unable to call for a driver detach of volume "
4909                           "%(vol_id)s due to the instance being registered to "
4910                           "the remote host %(inst_host)s."),
4911                       {'vol_id': volume_id, 'inst_host': instance.host},
4912                       instance=instance)
4913 
4914         if connection_info and not destroy_bdm and (
4915            connector.get('host') != instance.host):
4916             # If the volume is attached to another host (evacuate) then
4917             # this connector is for the wrong host. Use the connector that
4918             # was stored in connection_info instead (if we have one, and it
4919             # is for the expected host).
4920             stashed_connector = connection_info.get('connector')
4921             if not stashed_connector:
4922                 # Volume was attached before we began stashing connectors
4923                 LOG.warning(_LW("Host mismatch detected, but stashed "
4924                                 "volume connector not found. Instance host is "
4925                                 "%(ihost)s, but volume connector host is "
4926                                 "%(chost)s."),
4927                             {'ihost': instance.host,
4928                              'chost': connector.get('host')})
4929             elif stashed_connector.get('host') != instance.host:
4930                 # Unexpected error. The stashed connector is also not matching
4931                 # the needed instance host.
4932                 LOG.error(_LE("Host mismatch detected in stashed volume "
4933                               "connector. Will use local volume connector. "
4934                               "Instance host is %(ihost)s. Local volume "
4935                               "connector host is %(chost)s. Stashed volume "
4936                               "connector host is %(schost)s."),
4937                           {'ihost': instance.host,
4938                            'chost': connector.get('host'),
4939                            'schost': stashed_connector.get('host')})
4940             else:
4941                 # Fix found. Use stashed connector.
4942                 LOG.debug("Host mismatch detected. Found usable stashed "
4943                           "volume connector. Instance host is %(ihost)s. "
4944                           "Local volume connector host was %(chost)s. "
4945                           "Stashed volume connector host is %(schost)s.",
4946                           {'ihost': instance.host,
4947                            'chost': connector.get('host'),
4948                            'schost': stashed_connector.get('host')})
4949                 connector = stashed_connector
4950 
4951         self.volume_api.terminate_connection(context, volume_id, connector)
4952 
4953         if destroy_bdm:
4954             bdm.destroy()
4955 
4956         info = dict(volume_id=volume_id)
4957         self._notify_about_instance_usage(
4958             context, instance, "volume.detach", extra_usage_info=info)
4959         self.volume_api.detach(context.elevated(), volume_id, instance.uuid,
4960                                attachment_id)
4961 
4962     @wrap_exception()
4963     @wrap_instance_fault
4964     def detach_volume(self, context, volume_id, instance, attachment_id=None):
4965         """Detach a volume from an instance."""
4966 
4967         self._detach_volume(context, volume_id, instance,
4968                             attachment_id=attachment_id)
4969 
4970     def _init_volume_connection(self, context, new_volume_id,
4971                                 old_volume_id, connector, instance, bdm):
4972 
4973         new_cinfo = self.volume_api.initialize_connection(context,
4974                                                           new_volume_id,
4975                                                           connector)
4976         old_cinfo = jsonutils.loads(bdm['connection_info'])
4977         if old_cinfo and 'serial' not in old_cinfo:
4978             old_cinfo['serial'] = old_volume_id
4979         # NOTE(lyarwood): serial is not always present in the returned
4980         # connection_info so set it if it is missing as we do in
4981         # DriverVolumeBlockDevice.attach().
4982         if 'serial' not in new_cinfo:
4983             new_cinfo['serial'] = new_volume_id
4984         return (old_cinfo, new_cinfo)
4985 
4986     def _swap_volume(self, context, instance, bdm, connector,
4987                      old_volume_id, new_volume_id, resize_to):
4988         mountpoint = bdm['device_name']
4989         failed = False
4990         new_cinfo = None
4991         try:
4992             old_cinfo, new_cinfo = self._init_volume_connection(context,
4993                                                                 new_volume_id,
4994                                                                 old_volume_id,
4995                                                                 connector,
4996                                                                 instance,
4997                                                                 bdm)
4998             # NOTE(lyarwood): The Libvirt driver, the only virt driver
4999             # currently implementing swap_volume, will modify the contents of
5000             # new_cinfo when connect_volume is called. This is then saved to
5001             # the BDM in swap_volume for future use outside of this flow.
5002             LOG.debug("swap_volume: Calling driver volume swap with "
5003                       "connection infos: new: %(new_cinfo)s; "
5004                       "old: %(old_cinfo)s",
5005                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo},
5006                       instance=instance)
5007             self.driver.swap_volume(old_cinfo, new_cinfo, instance, mountpoint,
5008                                     resize_to)
5009             LOG.debug("swap_volume: Driver volume swap returned, new "
5010                       "connection_info is now : %(new_cinfo)s",
5011                       {'new_cinfo': new_cinfo})
5012         except Exception as ex:
5013             failed = True
5014             with excutils.save_and_reraise_exception():
5015                 compute_utils.notify_about_volume_swap(
5016                     context, instance, self.host,
5017                     fields.NotificationAction.VOLUME_SWAP,
5018                     fields.NotificationPhase.ERROR,
5019                     old_volume_id, new_volume_id, ex)
5020                 if new_cinfo:
5021                     msg = _LE("Failed to swap volume %(old_volume_id)s "
5022                               "for %(new_volume_id)s")
5023                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5024                                         'new_volume_id': new_volume_id},
5025                                   instance=instance)
5026                 else:
5027                     msg = _LE("Failed to connect to volume %(volume_id)s "
5028                               "with volume at %(mountpoint)s")
5029                     LOG.exception(msg, {'volume_id': new_volume_id,
5030                                         'mountpoint': bdm['device_name']},
5031                                   instance=instance)
5032                 self.volume_api.roll_detaching(context, old_volume_id)
5033                 self.volume_api.unreserve_volume(context, new_volume_id)
5034         finally:
5035             conn_volume = new_volume_id if failed else old_volume_id
5036             if new_cinfo:
5037                 LOG.debug("swap_volume: calling Cinder terminate_connection "
5038                           "for %(volume)s", {'volume': conn_volume},
5039                           instance=instance)
5040                 self.volume_api.terminate_connection(context,
5041                                                      conn_volume,
5042                                                      connector)
5043             # NOTE(lyarwood): The following call to
5044             # os-migrate-volume-completion returns a dict containing
5045             # save_volume_id, this volume id has two possible values :
5046             # 1. old_volume_id if we are migrating (retyping) volumes
5047             # 2. new_volume_id if we are swapping between two existing volumes
5048             # This volume id is later used to update the volume_id and
5049             # connection_info['serial'] of the BDM.
5050             comp_ret = self.volume_api.migrate_volume_completion(
5051                                                       context,
5052                                                       old_volume_id,
5053                                                       new_volume_id,
5054                                                       error=failed)
5055             LOG.debug("swap_volume: Cinder migrate_volume_completion "
5056                       "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5057                       instance=instance)
5058 
5059         return (comp_ret, new_cinfo)
5060 
5061     @wrap_exception()
5062     @reverts_task_state
5063     @wrap_instance_fault
5064     def swap_volume(self, context, old_volume_id, new_volume_id, instance):
5065         """Swap volume for an instance."""
5066         context = context.elevated()
5067 
5068         compute_utils.notify_about_volume_swap(
5069             context, instance, self.host,
5070             fields.NotificationAction.VOLUME_SWAP,
5071             fields.NotificationPhase.START,
5072             old_volume_id, new_volume_id)
5073 
5074         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5075                 context, old_volume_id, instance.uuid)
5076         connector = self.driver.get_volume_connector(instance)
5077 
5078         resize_to = 0
5079         old_vol_size = self.volume_api.get(context, old_volume_id)['size']
5080         new_vol_size = self.volume_api.get(context, new_volume_id)['size']
5081         if new_vol_size > old_vol_size:
5082             resize_to = new_vol_size
5083 
5084         LOG.info(_LI('Swapping volume %(old_volume)s for %(new_volume)s'),
5085                   {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5086                  instance=instance)
5087         comp_ret, new_cinfo = self._swap_volume(context, instance,
5088                                                          bdm,
5089                                                          connector,
5090                                                          old_volume_id,
5091                                                          new_volume_id,
5092                                                          resize_to)
5093 
5094         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5095         # correct volume_id returned by Cinder.
5096         save_volume_id = comp_ret['save_volume_id']
5097         new_cinfo['serial'] = save_volume_id
5098         values = {
5099             'connection_info': jsonutils.dumps(new_cinfo),
5100             'source_type': 'volume',
5101             'destination_type': 'volume',
5102             'snapshot_id': None,
5103             'volume_id': save_volume_id,
5104             'no_device': None}
5105 
5106         if resize_to:
5107             values['volume_size'] = resize_to
5108 
5109         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5110                   "%(updates)s", {'volume_id': bdm.volume_id,
5111                                   'updates': values},
5112                   instance=instance)
5113         bdm.update(values)
5114         bdm.save()
5115 
5116         compute_utils.notify_about_volume_swap(
5117             context, instance, self.host,
5118             fields.NotificationAction.VOLUME_SWAP,
5119             fields.NotificationPhase.END,
5120             old_volume_id, new_volume_id)
5121 
5122     @wrap_exception()
5123     def remove_volume_connection(self, context, volume_id, instance):
5124         """Remove a volume connection using the volume api."""
5125         # NOTE(vish): We don't want to actually mark the volume
5126         #             detached, or delete the bdm, just remove the
5127         #             connection from this host.
5128 
5129         try:
5130             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5131                     context, volume_id, instance.uuid)
5132             connection_info = jsonutils.loads(bdm.connection_info)
5133             self._driver_detach_volume(context, instance, bdm, connection_info)
5134             connector = self.driver.get_volume_connector(instance)
5135             self.volume_api.terminate_connection(context, volume_id, connector)
5136         except exception.NotFound:
5137             pass
5138 
5139     @wrap_exception()
5140     @wrap_instance_fault
5141     def attach_interface(self, context, instance, network_id, port_id,
5142                          requested_ip):
5143         """Use hotplug to add an network adapter to an instance."""
5144         if not self.driver.capabilities['supports_attach_interface']:
5145             raise exception.AttachInterfaceNotSupported(
5146                 instance_id=instance.uuid)
5147         bind_host_id = self.driver.network_binding_host_id(context, instance)
5148         network_info = self.network_api.allocate_port_for_instance(
5149             context, instance, port_id, network_id, requested_ip,
5150             bind_host_id=bind_host_id)
5151         if len(network_info) != 1:
5152             LOG.error(_LE('allocate_port_for_instance returned %(ports)s '
5153                           'ports'), {'ports': len(network_info)})
5154             raise exception.InterfaceAttachFailed(
5155                     instance_uuid=instance.uuid)
5156         image_meta = objects.ImageMeta.from_instance(instance)
5157 
5158         try:
5159             self.driver.attach_interface(context, instance, image_meta,
5160                                          network_info[0])
5161         except exception.NovaException as ex:
5162             port_id = network_info[0].get('id')
5163             LOG.warning(_LW("attach interface failed , try to deallocate "
5164                          "port %(port_id)s, reason: %(msg)s"),
5165                      {'port_id': port_id, 'msg': ex},
5166                      instance=instance)
5167             try:
5168                 self.network_api.deallocate_port_for_instance(
5169                     context, instance, port_id)
5170             except Exception:
5171                 LOG.warning(_LW("deallocate port %(port_id)s failed"),
5172                              {'port_id': port_id}, instance=instance)
5173             raise exception.InterfaceAttachFailed(
5174                 instance_uuid=instance.uuid)
5175 
5176         return network_info[0]
5177 
5178     @wrap_exception()
5179     @wrap_instance_fault
5180     def detach_interface(self, context, instance, port_id):
5181         """Detach a network adapter from an instance."""
5182         network_info = instance.info_cache.network_info
5183         condemned = None
5184         for vif in network_info:
5185             if vif['id'] == port_id:
5186                 condemned = vif
5187                 break
5188         if condemned is None:
5189             raise exception.PortNotFound(_("Port %s is not "
5190                                            "attached") % port_id)
5191         try:
5192             self.driver.detach_interface(context, instance, condemned)
5193         except exception.NovaException as ex:
5194             LOG.warning(_LW("Detach interface failed, port_id=%(port_id)s,"
5195                             " reason: %(msg)s"),
5196                         {'port_id': port_id, 'msg': ex}, instance=instance)
5197             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5198         else:
5199             try:
5200                 self.network_api.deallocate_port_for_instance(
5201                     context, instance, port_id)
5202             except Exception as ex:
5203                 with excutils.save_and_reraise_exception():
5204                     # Since this is a cast operation, log the failure for
5205                     # triage.
5206                     LOG.warning(_LW('Failed to deallocate port %(port_id)s '
5207                                     'for instance. Error: %(error)s'),
5208                                 {'port_id': port_id, 'error': ex},
5209                                 instance=instance)
5210 
5211     def _get_compute_info(self, context, host):
5212         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5213             context, host)
5214 
5215     @wrap_exception()
5216     def check_instance_shared_storage(self, ctxt, instance, data):
5217         """Check if the instance files are shared
5218 
5219         :param ctxt: security context
5220         :param instance: dict of instance data
5221         :param data: result of driver.check_instance_shared_storage_local
5222 
5223         Returns True if instance disks located on shared storage and
5224         False otherwise.
5225         """
5226         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5227 
5228     @wrap_exception()
5229     @wrap_instance_event(prefix='compute')
5230     @wrap_instance_fault
5231     def check_can_live_migrate_destination(self, ctxt, instance,
5232                                            block_migration, disk_over_commit):
5233         """Check if it is possible to execute live migration.
5234 
5235         This runs checks on the destination host, and then calls
5236         back to the source host to check the results.
5237 
5238         :param context: security context
5239         :param instance: dict of instance data
5240         :param block_migration: if true, prepare for block migration
5241                                 if None, calculate it in driver
5242         :param disk_over_commit: if true, allow disk over commit
5243                                  if None, ignore disk usage checking
5244         :returns: a dict containing migration info
5245         """
5246         return self._do_check_can_live_migrate_destination(ctxt, instance,
5247                                                             block_migration,
5248                                                             disk_over_commit)
5249 
5250     def _do_check_can_live_migrate_destination(self, ctxt, instance,
5251                                                block_migration,
5252                                                disk_over_commit):
5253         src_compute_info = obj_base.obj_to_primitive(
5254             self._get_compute_info(ctxt, instance.host))
5255         dst_compute_info = obj_base.obj_to_primitive(
5256             self._get_compute_info(ctxt, CONF.host))
5257         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5258             instance, src_compute_info, dst_compute_info,
5259             block_migration, disk_over_commit)
5260         LOG.debug('destination check data is %s', dest_check_data)
5261         try:
5262             migrate_data = self.compute_rpcapi.\
5263                                 check_can_live_migrate_source(ctxt, instance,
5264                                                               dest_check_data)
5265         finally:
5266             self.driver.cleanup_live_migration_destination_check(ctxt,
5267                     dest_check_data)
5268         return migrate_data
5269 
5270     @wrap_exception()
5271     @wrap_instance_event(prefix='compute')
5272     @wrap_instance_fault
5273     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5274         """Check if it is possible to execute live migration.
5275 
5276         This checks if the live migration can succeed, based on the
5277         results from check_can_live_migrate_destination.
5278 
5279         :param ctxt: security context
5280         :param instance: dict of instance data
5281         :param dest_check_data: result of check_can_live_migrate_destination
5282         :returns: a dict containing migration info
5283         """
5284         is_volume_backed = compute_utils.is_volume_backed_instance(ctxt,
5285                                                                       instance)
5286         # TODO(tdurakov): remove dict to object conversion once RPC API version
5287         # is bumped to 5.x
5288         got_migrate_data_object = isinstance(dest_check_data,
5289                                              migrate_data_obj.LiveMigrateData)
5290         if not got_migrate_data_object:
5291             dest_check_data = \
5292                 migrate_data_obj.LiveMigrateData.detect_implementation(
5293                     dest_check_data)
5294         dest_check_data.is_volume_backed = is_volume_backed
5295         block_device_info = self._get_instance_block_device_info(
5296                             ctxt, instance, refresh_conn_info=False)
5297         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5298                                                            dest_check_data,
5299                                                            block_device_info)
5300         if not got_migrate_data_object:
5301             result = result.to_legacy_dict()
5302         LOG.debug('source check data is %s', result)
5303         return result
5304 
5305     @wrap_exception()
5306     @wrap_instance_event(prefix='compute')
5307     @wrap_instance_fault
5308     def pre_live_migration(self, context, instance, block_migration, disk,
5309                            migrate_data):
5310         """Preparations for live migration at dest host.
5311 
5312         :param context: security context
5313         :param instance: dict of instance data
5314         :param block_migration: if true, prepare for block migration
5315         :param migrate_data: A dict or LiveMigrateData object holding data
5316                              required for live migration without shared
5317                              storage.
5318 
5319         """
5320         LOG.debug('pre_live_migration data is %s', migrate_data)
5321         # TODO(tdurakov): remove dict to object conversion once RPC API version
5322         # is bumped to 5.x
5323         got_migrate_data_object = isinstance(migrate_data,
5324                                              migrate_data_obj.LiveMigrateData)
5325         if not got_migrate_data_object:
5326             migrate_data = \
5327                 migrate_data_obj.LiveMigrateData.detect_implementation(
5328                     migrate_data)
5329         block_device_info = self._get_instance_block_device_info(
5330                             context, instance, refresh_conn_info=True)
5331 
5332         network_info = self.network_api.get_instance_nw_info(context, instance)
5333         self._notify_about_instance_usage(
5334                      context, instance, "live_migration.pre.start",
5335                      network_info=network_info)
5336 
5337         migrate_data = self.driver.pre_live_migration(context,
5338                                        instance,
5339                                        block_device_info,
5340                                        network_info,
5341                                        disk,
5342                                        migrate_data)
5343         LOG.debug('driver pre_live_migration data is %s', migrate_data)
5344 
5345         # NOTE(tr3buchet): setup networks on destination host
5346         self.network_api.setup_networks_on_host(context, instance,
5347                                                          self.host)
5348 
5349         # Creating filters to hypervisors and firewalls.
5350         # An example is that nova-instance-instance-xxx,
5351         # which is written to libvirt.xml(Check "virsh nwfilter-list")
5352         # This nwfilter is necessary on the destination host.
5353         # In addition, this method is creating filtering rule
5354         # onto destination host.
5355         self.driver.ensure_filtering_rules_for_instance(instance,
5356                                             network_info)
5357 
5358         self._notify_about_instance_usage(
5359                      context, instance, "live_migration.pre.end",
5360                      network_info=network_info)
5361         # TODO(tdurakov): remove dict to object conversion once RPC API version
5362         # is bumped to 5.x
5363         if not got_migrate_data_object and migrate_data:
5364             migrate_data = migrate_data.to_legacy_dict(
5365                 pre_migration_result=True)
5366             migrate_data = migrate_data['pre_live_migration_result']
5367         LOG.debug('pre_live_migration result data is %s', migrate_data)
5368         return migrate_data
5369 
5370     def _do_live_migration(self, context, dest, instance, block_migration,
5371                            migration, migrate_data):
5372         # NOTE(danms): We should enhance the RT to account for migrations
5373         # and use the status field to denote when the accounting has been
5374         # done on source/destination. For now, this is just here for status
5375         # reporting
5376         self._set_migration_status(migration, 'preparing')
5377 
5378         got_migrate_data_object = isinstance(migrate_data,
5379                                              migrate_data_obj.LiveMigrateData)
5380         if not got_migrate_data_object:
5381             migrate_data = \
5382                 migrate_data_obj.LiveMigrateData.detect_implementation(
5383                     migrate_data)
5384 
5385         try:
5386             if ('block_migration' in migrate_data and
5387                     migrate_data.block_migration):
5388                 block_device_info = self._get_instance_block_device_info(
5389                     context, instance)
5390                 disk = self.driver.get_instance_disk_info(
5391                     instance, block_device_info=block_device_info)
5392             else:
5393                 disk = None
5394 
5395             migrate_data = self.compute_rpcapi.pre_live_migration(
5396                 context, instance,
5397                 block_migration, disk, dest, migrate_data)
5398         except Exception:
5399             with excutils.save_and_reraise_exception():
5400                 LOG.exception(_LE('Pre live migration failed at %s'),
5401                               dest, instance=instance)
5402                 self._set_migration_status(migration, 'error')
5403                 self._rollback_live_migration(context, instance, dest,
5404                                               migrate_data)
5405 
5406         self._set_migration_status(migration, 'running')
5407 
5408         if migrate_data:
5409             migrate_data.migration = migration
5410         LOG.debug('live_migration data is %s', migrate_data)
5411         try:
5412             self.driver.live_migration(context, instance, dest,
5413                                        self._post_live_migration,
5414                                        self._rollback_live_migration,
5415                                        block_migration, migrate_data)
5416         except Exception:
5417             # Executing live migration
5418             # live_migration might raises exceptions, but
5419             # nothing must be recovered in this version.
5420             LOG.exception(_LE('Live migration failed.'), instance=instance)
5421             with excutils.save_and_reraise_exception():
5422                 self._set_migration_status(migration, 'error')
5423 
5424     @wrap_exception()
5425     @wrap_instance_event(prefix='compute')
5426     @wrap_instance_fault
5427     def live_migration(self, context, dest, instance, block_migration,
5428                        migration, migrate_data):
5429         """Executing live migration.
5430 
5431         :param context: security context
5432         :param dest: destination host
5433         :param instance: a nova.objects.instance.Instance object
5434         :param block_migration: if true, prepare for block migration
5435         :param migration: an nova.objects.Migration object
5436         :param migrate_data: implementation specific params
5437 
5438         """
5439         self._set_migration_status(migration, 'queued')
5440 
5441         def dispatch_live_migration(*args, **kwargs):
5442             with self._live_migration_semaphore:
5443                 self._do_live_migration(*args, **kwargs)
5444 
5445         # NOTE(danms): We spawn here to return the RPC worker thread back to
5446         # the pool. Since what follows could take a really long time, we don't
5447         # want to tie up RPC workers.
5448         utils.spawn_n(dispatch_live_migration,
5449                       context, dest, instance,
5450                       block_migration, migration,
5451                       migrate_data)
5452 
5453     # TODO(tdurakov): migration_id is used since 4.12 rpc api version
5454     # remove migration_id parameter when the compute RPC version
5455     # is bumped to 5.x.
5456     @wrap_exception()
5457     @wrap_instance_event(prefix='compute')
5458     @wrap_instance_fault
5459     def live_migration_force_complete(self, context, instance,
5460                                       migration_id=None):
5461         """Force live migration to complete.
5462 
5463         :param context: Security context
5464         :param instance: The instance that is being migrated
5465         :param migration_id: ID of ongoing migration; is currently not used,
5466         and isn't removed for backward compatibility
5467         """
5468 
5469         self._notify_about_instance_usage(
5470             context, instance, 'live.migration.force.complete.start')
5471         self.driver.live_migration_force_complete(instance)
5472         self._notify_about_instance_usage(
5473             context, instance, 'live.migration.force.complete.end')
5474 
5475     @wrap_exception()
5476     @wrap_instance_event(prefix='compute')
5477     @wrap_instance_fault
5478     def live_migration_abort(self, context, instance, migration_id):
5479         """Abort an in-progress live migration.
5480 
5481         :param context: Security context
5482         :param instance: The instance that is being migrated
5483         :param migration_id: ID of in-progress live migration
5484 
5485         """
5486         migration = objects.Migration.get_by_id(context, migration_id)
5487         if migration.status != 'running':
5488             raise exception.InvalidMigrationState(migration_id=migration_id,
5489                     instance_uuid=instance.uuid,
5490                     state=migration.status,
5491                     method='abort live migration')
5492 
5493         self._notify_about_instance_usage(
5494             context, instance, 'live.migration.abort.start')
5495         self.driver.live_migration_abort(instance)
5496         self._notify_about_instance_usage(
5497             context, instance, 'live.migration.abort.end')
5498 
5499     def _live_migration_cleanup_flags(self, migrate_data):
5500         """Determine whether disks or instance path need to be cleaned up after
5501         live migration (at source on success, at destination on rollback)
5502 
5503         Block migration needs empty image at destination host before migration
5504         starts, so if any failure occurs, any empty images has to be deleted.
5505 
5506         Also Volume backed live migration w/o shared storage needs to delete
5507         newly created instance-xxx dir on the destination as a part of its
5508         rollback process
5509 
5510         :param migrate_data: implementation specific data
5511         :returns: (bool, bool) -- do_cleanup, destroy_disks
5512         """
5513         # NOTE(pkoniszewski): block migration specific params are set inside
5514         # migrate_data objects for drivers that expose block live migration
5515         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
5516         # cleanup is not needed.
5517         is_shared_block_storage = True
5518         is_shared_instance_path = True
5519         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
5520             is_shared_block_storage = migrate_data.is_shared_block_storage
5521             is_shared_instance_path = migrate_data.is_shared_instance_path
5522         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
5523             is_shared_block_storage = not migrate_data.block_migration
5524             is_shared_instance_path = not migrate_data.block_migration
5525         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
5526             is_shared_instance_path = migrate_data.is_shared_instance_path
5527             is_shared_block_storage = migrate_data.is_shared_instance_path
5528 
5529         # No instance booting at source host, but instance dir
5530         # must be deleted for preparing next block migration
5531         # must be deleted for preparing next live migration w/o shared storage
5532         do_cleanup = not is_shared_instance_path
5533         destroy_disks = not is_shared_block_storage
5534 
5535         return (do_cleanup, destroy_disks)
5536 
5537     @wrap_exception()
5538     @wrap_instance_fault
5539     def _post_live_migration(self, ctxt, instance,
5540                             dest, block_migration=False, migrate_data=None):
5541         """Post operations for live migration.
5542 
5543         This method is called from live_migration
5544         and mainly updating database record.
5545 
5546         :param ctxt: security context
5547         :param instance: instance dict
5548         :param dest: destination host
5549         :param block_migration: if true, prepare for block migration
5550         :param migrate_data: if not None, it is a dict which has data
5551         required for live migration without shared storage
5552 
5553         """
5554         LOG.info(_LI('_post_live_migration() is started..'),
5555                  instance=instance)
5556 
5557         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5558                 ctxt, instance.uuid)
5559 
5560         # Cleanup source host post live-migration
5561         block_device_info = self._get_instance_block_device_info(
5562                             ctxt, instance, bdms=bdms)
5563         self.driver.post_live_migration(ctxt, instance, block_device_info,
5564                                         migrate_data)
5565 
5566         # Detaching volumes.
5567         connector = self.driver.get_volume_connector(instance)
5568         for bdm in bdms:
5569             # NOTE(vish): We don't want to actually mark the volume
5570             #             detached, or delete the bdm, just remove the
5571             #             connection from this host.
5572 
5573             # remove the volume connection without detaching from hypervisor
5574             # because the instance is not running anymore on the current host
5575             if bdm.is_volume:
5576                 self.volume_api.terminate_connection(ctxt, bdm.volume_id,
5577                                                      connector)
5578 
5579         # Releasing vlan.
5580         # (not necessary in current implementation?)
5581 
5582         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
5583 
5584         self._notify_about_instance_usage(ctxt, instance,
5585                                           "live_migration._post.start",
5586                                           network_info=network_info)
5587         # Releasing security group ingress rule.
5588         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
5589                   instance=instance)
5590         self.driver.unfilter_instance(instance,
5591                                       network_info)
5592 
5593         migration = {'source_compute': self.host,
5594                      'dest_compute': dest, }
5595         self.network_api.migrate_instance_start(ctxt,
5596                                                 instance,
5597                                                 migration)
5598 
5599         destroy_vifs = False
5600         try:
5601             self.driver.post_live_migration_at_source(ctxt, instance,
5602                                                       network_info)
5603         except NotImplementedError as ex:
5604             LOG.debug(ex, instance=instance)
5605             # For all hypervisors other than libvirt, there is a possibility
5606             # they are unplugging networks from source node in the cleanup
5607             # method
5608             destroy_vifs = True
5609 
5610         # Define domain at destination host, without doing it,
5611         # pause/suspend/terminate do not work.
5612         try:
5613             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
5614                     instance, block_migration, dest)
5615         except Exception as error:
5616             # We don't want to break _post_live_migration() if
5617             # post_live_migration_at_destination() fails as it should never
5618             # affect cleaning up source node.
5619             LOG.exception(_LE("Post live migration at destination %s failed"),
5620                     dest, instance=instance, error=error)
5621 
5622         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5623                 migrate_data)
5624 
5625         if do_cleanup:
5626             LOG.debug('Calling driver.cleanup from _post_live_migration',
5627                       instance=instance)
5628             self.driver.cleanup(ctxt, instance, network_info,
5629                                 destroy_disks=destroy_disks,
5630                                 migrate_data=migrate_data,
5631                                 destroy_vifs=destroy_vifs)
5632 
5633         self.instance_events.clear_events_for_instance(instance)
5634 
5635         # NOTE(timello): make sure we update available resources on source
5636         # host even before next periodic task.
5637         self.update_available_resource(ctxt)
5638 
5639         self._update_scheduler_instance_info(ctxt, instance)
5640         self._notify_about_instance_usage(ctxt, instance,
5641                                           "live_migration._post.end",
5642                                           network_info=network_info)
5643         LOG.info(_LI('Migrating instance to %s finished successfully.'),
5644                  dest, instance=instance)
5645         LOG.info(_LI("You may see the error \"libvirt: QEMU error: "
5646                      "Domain not found: no domain with matching name.\" "
5647                      "This error can be safely ignored."),
5648                  instance=instance)
5649 
5650         self._clean_instance_console_tokens(ctxt, instance)
5651         if migrate_data and migrate_data.obj_attr_is_set('migration'):
5652             migrate_data.migration.status = 'completed'
5653             migrate_data.migration.save()
5654 
5655     def _consoles_enabled(self):
5656         """Returns whether a console is enable."""
5657         return (CONF.vnc.enabled or CONF.spice.enabled or
5658                 CONF.rdp.enabled or CONF.serial_console.enabled or
5659                 CONF.mks.enabled)
5660 
5661     def _clean_instance_console_tokens(self, ctxt, instance):
5662         """Clean console tokens stored for an instance."""
5663         if self._consoles_enabled():
5664             if CONF.cells.enable:
5665                 self.cells_rpcapi.consoleauth_delete_tokens(
5666                     ctxt, instance.uuid)
5667             else:
5668                 self.consoleauth_rpcapi.delete_tokens_for_instance(
5669                     ctxt, instance.uuid)
5670 
5671     @wrap_exception()
5672     @wrap_instance_event(prefix='compute')
5673     @wrap_instance_fault
5674     def post_live_migration_at_destination(self, context, instance,
5675                                            block_migration):
5676         """Post operations for live migration .
5677 
5678         :param context: security context
5679         :param instance: Instance dict
5680         :param block_migration: if true, prepare for block migration
5681 
5682         """
5683         LOG.info(_LI('Post operation of migration started'),
5684                  instance=instance)
5685 
5686         # NOTE(tr3buchet): setup networks on destination host
5687         #                  this is called a second time because
5688         #                  multi_host does not create the bridge in
5689         #                  plug_vifs
5690         self.network_api.setup_networks_on_host(context, instance,
5691                                                          self.host)
5692         migration = {'source_compute': instance.host,
5693                      'dest_compute': self.host, }
5694         self.network_api.migrate_instance_finish(context,
5695                                                  instance,
5696                                                  migration)
5697 
5698         network_info = self.network_api.get_instance_nw_info(context, instance)
5699         self._notify_about_instance_usage(
5700                      context, instance, "live_migration.post.dest.start",
5701                      network_info=network_info)
5702         block_device_info = self._get_instance_block_device_info(context,
5703                                                                  instance)
5704 
5705         try:
5706             self.driver.post_live_migration_at_destination(
5707                 context, instance, network_info, block_migration,
5708                 block_device_info)
5709         except Exception:
5710             with excutils.save_and_reraise_exception():
5711                 instance.vm_state = vm_states.ERROR
5712                 LOG.error(_LE('Unexpected error during post live migration at '
5713                               'destination host.'), instance=instance)
5714         finally:
5715             # Restore instance state and update host
5716             current_power_state = self._get_power_state(context, instance)
5717             node_name = None
5718             prev_host = instance.host
5719             try:
5720                 compute_node = self._get_compute_info(context, self.host)
5721                 node_name = compute_node.hypervisor_hostname
5722             except exception.ComputeHostNotFound:
5723                 LOG.exception(_LE('Failed to get compute_info for %s'),
5724                               self.host)
5725             finally:
5726                 instance.host = self.host
5727                 instance.power_state = current_power_state
5728                 instance.task_state = None
5729                 instance.node = node_name
5730                 instance.progress = 0
5731                 instance.save(expected_task_state=task_states.MIGRATING)
5732 
5733         # NOTE(tr3buchet): tear down networks on source host
5734         self.network_api.setup_networks_on_host(context, instance,
5735                                                 prev_host, teardown=True)
5736         # NOTE(vish): this is necessary to update dhcp
5737         self.network_api.setup_networks_on_host(context, instance, self.host)
5738         self._notify_about_instance_usage(
5739                      context, instance, "live_migration.post.dest.end",
5740                      network_info=network_info)
5741 
5742     @wrap_exception()
5743     @wrap_instance_fault
5744     def _rollback_live_migration(self, context, instance,
5745                                  dest, migrate_data=None,
5746                                  migration_status='error'):
5747         """Recovers Instance/volume state from migrating -> running.
5748 
5749         :param context: security context
5750         :param instance: nova.objects.instance.Instance object
5751         :param dest:
5752             This method is called from live migration src host.
5753             This param specifies destination host.
5754         :param migrate_data:
5755             if not none, contains implementation specific data.
5756         :param migration_status:
5757             Contains the status we want to set for the migration object
5758 
5759         """
5760         instance.task_state = None
5761         instance.progress = 0
5762         instance.save(expected_task_state=[task_states.MIGRATING])
5763 
5764         # TODO(tdurakov): remove dict to object conversion once RPC API version
5765         # is bumped to 5.x
5766         if isinstance(migrate_data, dict):
5767             migration = migrate_data.pop('migration', None)
5768             migrate_data = \
5769                 migrate_data_obj.LiveMigrateData.detect_implementation(
5770                     migrate_data)
5771         elif (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
5772               migrate_data.obj_attr_is_set('migration')):
5773             migration = migrate_data.migration
5774         else:
5775             migration = None
5776 
5777         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
5778         self.network_api.setup_networks_on_host(context, instance, self.host)
5779 
5780         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5781                 context, instance.uuid)
5782         for bdm in bdms:
5783             if bdm.is_volume:
5784                 self.compute_rpcapi.remove_volume_connection(
5785                         context, instance, bdm.volume_id, dest)
5786 
5787         self._notify_about_instance_usage(context, instance,
5788                                           "live_migration._rollback.start")
5789 
5790         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5791                 migrate_data)
5792 
5793         if do_cleanup:
5794             self.compute_rpcapi.rollback_live_migration_at_destination(
5795                     context, instance, dest, destroy_disks=destroy_disks,
5796                     migrate_data=migrate_data)
5797 
5798         self._notify_about_instance_usage(context, instance,
5799                                           "live_migration._rollback.end")
5800 
5801         self._set_migration_status(migration, migration_status)
5802 
5803     @wrap_exception()
5804     @wrap_instance_event(prefix='compute')
5805     @wrap_instance_fault
5806     def rollback_live_migration_at_destination(self, context, instance,
5807                                                destroy_disks,
5808                                                migrate_data):
5809         """Cleaning up image directory that is created pre_live_migration.
5810 
5811         :param context: security context
5812         :param instance: a nova.objects.instance.Instance object sent over rpc
5813         """
5814         network_info = self.network_api.get_instance_nw_info(context, instance)
5815         self._notify_about_instance_usage(
5816                       context, instance, "live_migration.rollback.dest.start",
5817                       network_info=network_info)
5818         try:
5819             # NOTE(tr3buchet): tear down networks on destination host
5820             self.network_api.setup_networks_on_host(context, instance,
5821                                                     self.host, teardown=True)
5822         except Exception:
5823             with excutils.save_and_reraise_exception():
5824                 # NOTE(tdurakov): even if teardown networks fails driver
5825                 # should try to rollback live migration on destination.
5826                 LOG.exception(
5827                     _LE('An error occurred while deallocating network.'),
5828                     instance=instance)
5829         finally:
5830             # always run this even if setup_networks_on_host fails
5831             # NOTE(vish): The mapping is passed in so the driver can disconnect
5832             #             from remote volumes if necessary
5833             block_device_info = self._get_instance_block_device_info(context,
5834                                                                      instance)
5835             # TODO(tdurakov): remove dict to object conversion once RPC API
5836             # version is bumped to 5.x
5837             if isinstance(migrate_data, dict):
5838                 migrate_data = \
5839                     migrate_data_obj.LiveMigrateData.detect_implementation(
5840                         migrate_data)
5841             self.driver.rollback_live_migration_at_destination(
5842                 context, instance, network_info, block_device_info,
5843                 destroy_disks=destroy_disks, migrate_data=migrate_data)
5844 
5845         self._notify_about_instance_usage(
5846                         context, instance, "live_migration.rollback.dest.end",
5847                         network_info=network_info)
5848 
5849     @periodic_task.periodic_task(
5850         spacing=CONF.heal_instance_info_cache_interval)
5851     def _heal_instance_info_cache(self, context):
5852         """Called periodically.  On every call, try to update the
5853         info_cache's network information for another instance by
5854         calling to the network manager.
5855 
5856         This is implemented by keeping a cache of uuids of instances
5857         that live on this host.  On each call, we pop one off of a
5858         list, pull the DB record, and try the call to the network API.
5859         If anything errors don't fail, as it's possible the instance
5860         has been deleted, etc.
5861         """
5862         heal_interval = CONF.heal_instance_info_cache_interval
5863         if not heal_interval:
5864             return
5865 
5866         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
5867         instance = None
5868 
5869         LOG.debug('Starting heal instance info cache')
5870 
5871         if not instance_uuids:
5872             # The list of instances to heal is empty so rebuild it
5873             LOG.debug('Rebuilding the list of instances to heal')
5874             db_instances = objects.InstanceList.get_by_host(
5875                 context, self.host, expected_attrs=[], use_slave=True)
5876             for inst in db_instances:
5877                 # We don't want to refresh the cache for instances
5878                 # which are building or deleting so don't put them
5879                 # in the list. If they are building they will get
5880                 # added to the list next time we build it.
5881                 if (inst.vm_state == vm_states.BUILDING):
5882                     LOG.debug('Skipping network cache update for instance '
5883                               'because it is Building.', instance=inst)
5884                     continue
5885                 if (inst.task_state == task_states.DELETING):
5886                     LOG.debug('Skipping network cache update for instance '
5887                               'because it is being deleted.', instance=inst)
5888                     continue
5889 
5890                 if not instance:
5891                     # Save the first one we find so we don't
5892                     # have to get it again
5893                     instance = inst
5894                 else:
5895                     instance_uuids.append(inst['uuid'])
5896 
5897             self._instance_uuids_to_heal = instance_uuids
5898         else:
5899             # Find the next valid instance on the list
5900             while instance_uuids:
5901                 try:
5902                     inst = objects.Instance.get_by_uuid(
5903                             context, instance_uuids.pop(0),
5904                             expected_attrs=['system_metadata', 'info_cache',
5905                                             'flavor'],
5906                             use_slave=True)
5907                 except exception.InstanceNotFound:
5908                     # Instance is gone.  Try to grab another.
5909                     continue
5910 
5911                 # Check the instance hasn't been migrated
5912                 if inst.host != self.host:
5913                     LOG.debug('Skipping network cache update for instance '
5914                               'because it has been migrated to another '
5915                               'host.', instance=inst)
5916                 # Check the instance isn't being deleting
5917                 elif inst.task_state == task_states.DELETING:
5918                     LOG.debug('Skipping network cache update for instance '
5919                               'because it is being deleted.', instance=inst)
5920                 else:
5921                     instance = inst
5922                     break
5923 
5924         if instance:
5925             # We have an instance now to refresh
5926             try:
5927                 # Call to network API to get instance info.. this will
5928                 # force an update to the instance's info_cache
5929                 self.network_api.get_instance_nw_info(context, instance)
5930                 LOG.debug('Updated the network info_cache for instance',
5931                           instance=instance)
5932             except exception.InstanceNotFound:
5933                 # Instance is gone.
5934                 LOG.debug('Instance no longer exists. Unable to refresh',
5935                           instance=instance)
5936                 return
5937             except exception.InstanceInfoCacheNotFound:
5938                 # InstanceInfoCache is gone.
5939                 LOG.debug('InstanceInfoCache no longer exists. '
5940                           'Unable to refresh', instance=instance)
5941             except Exception:
5942                 LOG.error(_LE('An error occurred while refreshing the network '
5943                               'cache.'), instance=instance, exc_info=True)
5944         else:
5945             LOG.debug("Didn't find any instances for network info cache "
5946                       "update.")
5947 
5948     @periodic_task.periodic_task
5949     def _poll_rebooting_instances(self, context):
5950         if CONF.reboot_timeout > 0:
5951             filters = {'task_state':
5952                        [task_states.REBOOTING,
5953                         task_states.REBOOT_STARTED,
5954                         task_states.REBOOT_PENDING],
5955                        'host': self.host}
5956             rebooting = objects.InstanceList.get_by_filters(
5957                 context, filters, expected_attrs=[], use_slave=True)
5958 
5959             to_poll = []
5960             for instance in rebooting:
5961                 if timeutils.is_older_than(instance.updated_at,
5962                                            CONF.reboot_timeout):
5963                     to_poll.append(instance)
5964 
5965             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
5966 
5967     @periodic_task.periodic_task
5968     def _poll_rescued_instances(self, context):
5969         if CONF.rescue_timeout > 0:
5970             filters = {'vm_state': vm_states.RESCUED,
5971                        'host': self.host}
5972             rescued_instances = objects.InstanceList.get_by_filters(
5973                 context, filters, expected_attrs=["system_metadata"],
5974                 use_slave=True)
5975 
5976             to_unrescue = []
5977             for instance in rescued_instances:
5978                 if timeutils.is_older_than(instance.launched_at,
5979                                            CONF.rescue_timeout):
5980                     to_unrescue.append(instance)
5981 
5982             for instance in to_unrescue:
5983                 self.compute_api.unrescue(context, instance)
5984 
5985     @periodic_task.periodic_task
5986     def _poll_unconfirmed_resizes(self, context):
5987         if CONF.resize_confirm_window == 0:
5988             return
5989 
5990         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
5991                 context, CONF.resize_confirm_window, self.host,
5992                 use_slave=True)
5993 
5994         migrations_info = dict(migration_count=len(migrations),
5995                 confirm_window=CONF.resize_confirm_window)
5996 
5997         if migrations_info["migration_count"] > 0:
5998             LOG.info(_LI("Found %(migration_count)d unconfirmed migrations "
5999                          "older than %(confirm_window)d seconds"),
6000                      migrations_info)
6001 
6002         def _set_migration_to_error(migration, reason, **kwargs):
6003             LOG.warning(_LW("Setting migration %(migration_id)s to error: "
6004                          "%(reason)s"),
6005                      {'migration_id': migration['id'], 'reason': reason},
6006                      **kwargs)
6007             migration.status = 'error'
6008             with migration.obj_as_admin():
6009                 migration.save()
6010 
6011         for migration in migrations:
6012             instance_uuid = migration.instance_uuid
6013             LOG.info(_LI("Automatically confirming migration "
6014                          "%(migration_id)s for instance %(instance_uuid)s"),
6015                      {'migration_id': migration.id,
6016                       'instance_uuid': instance_uuid})
6017             expected_attrs = ['metadata', 'system_metadata']
6018             try:
6019                 instance = objects.Instance.get_by_uuid(context,
6020                             instance_uuid, expected_attrs=expected_attrs,
6021                             use_slave=True)
6022             except exception.InstanceNotFound:
6023                 reason = (_("Instance %s not found") %
6024                           instance_uuid)
6025                 _set_migration_to_error(migration, reason)
6026                 continue
6027             if instance.vm_state == vm_states.ERROR:
6028                 reason = _("In ERROR state")
6029                 _set_migration_to_error(migration, reason,
6030                                         instance=instance)
6031                 continue
6032             # race condition: The instance in DELETING state should not be
6033             # set the migration state to error, otherwise the instance in
6034             # to be deleted which is in RESIZED state
6035             # will not be able to confirm resize
6036             if instance.task_state in [task_states.DELETING,
6037                                        task_states.SOFT_DELETING]:
6038                 msg = ("Instance being deleted or soft deleted during resize "
6039                        "confirmation. Skipping.")
6040                 LOG.debug(msg, instance=instance)
6041                 continue
6042 
6043             # race condition: This condition is hit when this method is
6044             # called between the save of the migration record with a status of
6045             # finished and the save of the instance object with a state of
6046             # RESIZED. The migration record should not be set to error.
6047             if instance.task_state == task_states.RESIZE_FINISH:
6048                 msg = ("Instance still resizing during resize "
6049                        "confirmation. Skipping.")
6050                 LOG.debug(msg, instance=instance)
6051                 continue
6052 
6053             vm_state = instance.vm_state
6054             task_state = instance.task_state
6055             if vm_state != vm_states.RESIZED or task_state is not None:
6056                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
6057                            "RESIZED/None") %
6058                           {'vm_state': vm_state,
6059                            'task_state': task_state})
6060                 _set_migration_to_error(migration, reason,
6061                                         instance=instance)
6062                 continue
6063             try:
6064                 self.compute_api.confirm_resize(context, instance,
6065                                                 migration=migration)
6066             except Exception as e:
6067                 LOG.info(_LI("Error auto-confirming resize: %s. "
6068                              "Will retry later."),
6069                          e, instance=instance)
6070 
6071     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
6072     def _poll_shelved_instances(self, context):
6073 
6074         if CONF.shelved_offload_time <= 0:
6075             return
6076 
6077         filters = {'vm_state': vm_states.SHELVED,
6078                    'task_state': None,
6079                    'host': self.host}
6080         shelved_instances = objects.InstanceList.get_by_filters(
6081             context, filters=filters, expected_attrs=['system_metadata'],
6082             use_slave=True)
6083 
6084         to_gc = []
6085         for instance in shelved_instances:
6086             sys_meta = instance.system_metadata
6087             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
6088             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
6089                 to_gc.append(instance)
6090 
6091         for instance in to_gc:
6092             try:
6093                 instance.task_state = task_states.SHELVING_OFFLOADING
6094                 instance.save(expected_task_state=(None,))
6095                 self.shelve_offload_instance(context, instance,
6096                                              clean_shutdown=False)
6097             except Exception:
6098                 LOG.exception(_LE('Periodic task failed to offload instance.'),
6099                         instance=instance)
6100 
6101     @periodic_task.periodic_task
6102     def _instance_usage_audit(self, context):
6103         if not CONF.instance_usage_audit:
6104             return
6105 
6106         begin, end = utils.last_completed_audit_period()
6107         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
6108                                self.host):
6109             return
6110 
6111         instances = objects.InstanceList.get_active_by_window_joined(
6112             context, begin, end, host=self.host,
6113             expected_attrs=['system_metadata', 'info_cache', 'metadata',
6114                             'flavor'],
6115             use_slave=True)
6116         num_instances = len(instances)
6117         errors = 0
6118         successes = 0
6119         LOG.info(_LI("Running instance usage audit for"
6120                      " host %(host)s from %(begin_time)s to "
6121                      "%(end_time)s. %(number_instances)s"
6122                      " instances."),
6123                  {'host': self.host,
6124                   'begin_time': begin,
6125                   'end_time': end,
6126                   'number_instances': num_instances})
6127         start_time = time.time()
6128         task_log = objects.TaskLog(context)
6129         task_log.task_name = 'instance_usage_audit'
6130         task_log.period_beginning = begin
6131         task_log.period_ending = end
6132         task_log.host = self.host
6133         task_log.task_items = num_instances
6134         task_log.message = 'Instance usage audit started...'
6135         task_log.begin_task()
6136         for instance in instances:
6137             try:
6138                 compute_utils.notify_usage_exists(
6139                     self.notifier, context, instance,
6140                     ignore_missing_network_data=False)
6141                 successes += 1
6142             except Exception:
6143                 LOG.exception(_LE('Failed to generate usage '
6144                                   'audit for instance '
6145                                   'on host %s'), self.host,
6146                               instance=instance)
6147                 errors += 1
6148         task_log.errors = errors
6149         task_log.message = (
6150             'Instance usage audit ran for host %s, %s instances in %s seconds.'
6151             % (self.host, num_instances, time.time() - start_time))
6152         task_log.end_task()
6153 
6154     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
6155     def _poll_bandwidth_usage(self, context):
6156 
6157         if not self._bw_usage_supported:
6158             return
6159 
6160         prev_time, start_time = utils.last_completed_audit_period()
6161 
6162         curr_time = time.time()
6163         if (curr_time - self._last_bw_usage_poll >
6164                 CONF.bandwidth_poll_interval):
6165             self._last_bw_usage_poll = curr_time
6166             LOG.info(_LI("Updating bandwidth usage cache"))
6167             cells_update_interval = CONF.cells.bandwidth_update_interval
6168             if (cells_update_interval > 0 and
6169                    curr_time - self._last_bw_usage_cell_update >
6170                            cells_update_interval):
6171                 self._last_bw_usage_cell_update = curr_time
6172                 update_cells = True
6173             else:
6174                 update_cells = False
6175 
6176             instances = objects.InstanceList.get_by_host(context,
6177                                                               self.host,
6178                                                               use_slave=True)
6179             try:
6180                 bw_counters = self.driver.get_all_bw_counters(instances)
6181             except NotImplementedError:
6182                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
6183                 # implemented yet.  If they don't it doesn't break anything,
6184                 # they just don't get the info in the usage events.
6185                 # NOTE(PhilDay): Record that its not supported so we can
6186                 # skip fast on future calls rather than waste effort getting
6187                 # the list of instances.
6188                 LOG.info(_LI("Bandwidth usage not supported by "
6189                              "hypervisor."))
6190                 self._bw_usage_supported = False
6191                 return
6192 
6193             refreshed = timeutils.utcnow()
6194             for bw_ctr in bw_counters:
6195                 # Allow switching of greenthreads between queries.
6196                 greenthread.sleep(0)
6197                 bw_in = 0
6198                 bw_out = 0
6199                 last_ctr_in = None
6200                 last_ctr_out = None
6201                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6202                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6203                     start_period=start_time, use_slave=True)
6204                 if usage:
6205                     bw_in = usage.bw_in
6206                     bw_out = usage.bw_out
6207                     last_ctr_in = usage.last_ctr_in
6208                     last_ctr_out = usage.last_ctr_out
6209                 else:
6210                     usage = (objects.BandwidthUsage.
6211                              get_by_instance_uuid_and_mac(
6212                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6213                         start_period=prev_time, use_slave=True))
6214                     if usage:
6215                         last_ctr_in = usage.last_ctr_in
6216                         last_ctr_out = usage.last_ctr_out
6217 
6218                 if last_ctr_in is not None:
6219                     if bw_ctr['bw_in'] < last_ctr_in:
6220                         # counter rollover
6221                         bw_in += bw_ctr['bw_in']
6222                     else:
6223                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6224 
6225                 if last_ctr_out is not None:
6226                     if bw_ctr['bw_out'] < last_ctr_out:
6227                         # counter rollover
6228                         bw_out += bw_ctr['bw_out']
6229                     else:
6230                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6231 
6232                 objects.BandwidthUsage(context=context).create(
6233                                               bw_ctr['uuid'],
6234                                               bw_ctr['mac_address'],
6235                                               bw_in,
6236                                               bw_out,
6237                                               bw_ctr['bw_in'],
6238                                               bw_ctr['bw_out'],
6239                                               start_period=start_time,
6240                                               last_refreshed=refreshed,
6241                                               update_cells=update_cells)
6242 
6243     def _get_host_volume_bdms(self, context, use_slave=False):
6244         """Return all block device mappings on a compute host."""
6245         compute_host_bdms = []
6246         instances = objects.InstanceList.get_by_host(context, self.host,
6247             use_slave=use_slave)
6248         for instance in instances:
6249             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6250                     context, instance.uuid, use_slave=use_slave)
6251             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6252             compute_host_bdms.append(dict(instance=instance,
6253                                           instance_bdms=instance_bdms))
6254 
6255         return compute_host_bdms
6256 
6257     def _update_volume_usage_cache(self, context, vol_usages):
6258         """Updates the volume usage cache table with a list of stats."""
6259         for usage in vol_usages:
6260             # Allow switching of greenthreads between queries.
6261             greenthread.sleep(0)
6262             vol_usage = objects.VolumeUsage(context)
6263             vol_usage.volume_id = usage['volume']
6264             vol_usage.instance_uuid = usage['instance'].uuid
6265             vol_usage.project_id = usage['instance'].project_id
6266             vol_usage.user_id = usage['instance'].user_id
6267             vol_usage.availability_zone = usage['instance'].availability_zone
6268             vol_usage.curr_reads = usage['rd_req']
6269             vol_usage.curr_read_bytes = usage['rd_bytes']
6270             vol_usage.curr_writes = usage['wr_req']
6271             vol_usage.curr_write_bytes = usage['wr_bytes']
6272             vol_usage.save()
6273             self.notifier.info(context, 'volume.usage',
6274                                compute_utils.usage_volume_info(vol_usage))
6275 
6276     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
6277     def _poll_volume_usage(self, context):
6278         if CONF.volume_usage_poll_interval == 0:
6279             return
6280 
6281         compute_host_bdms = self._get_host_volume_bdms(context,
6282                                                        use_slave=True)
6283         if not compute_host_bdms:
6284             return
6285 
6286         LOG.debug("Updating volume usage cache")
6287         try:
6288             vol_usages = self.driver.get_all_volume_usage(context,
6289                                                           compute_host_bdms)
6290         except NotImplementedError:
6291             return
6292 
6293         self._update_volume_usage_cache(context, vol_usages)
6294 
6295     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
6296                                  run_immediately=True)
6297     def _sync_power_states(self, context):
6298         """Align power states between the database and the hypervisor.
6299 
6300         To sync power state data we make a DB call to get the number of
6301         virtual machines known by the hypervisor and if the number matches the
6302         number of virtual machines known by the database, we proceed in a lazy
6303         loop, one database record at a time, checking if the hypervisor has the
6304         same power state as is in the database.
6305         """
6306         db_instances = objects.InstanceList.get_by_host(context, self.host,
6307                                                         expected_attrs=[],
6308                                                         use_slave=True)
6309 
6310         num_vm_instances = self.driver.get_num_instances()
6311         num_db_instances = len(db_instances)
6312 
6313         if num_vm_instances != num_db_instances:
6314             LOG.warning(_LW("While synchronizing instance power states, found "
6315                             "%(num_db_instances)s instances in the database "
6316                             "and %(num_vm_instances)s instances on the "
6317                             "hypervisor."),
6318                         {'num_db_instances': num_db_instances,
6319                          'num_vm_instances': num_vm_instances})
6320 
6321         def _sync(db_instance):
6322             # NOTE(melwitt): This must be synchronized as we query state from
6323             #                two separate sources, the driver and the database.
6324             #                They are set (in stop_instance) and read, in sync.
6325             @utils.synchronized(db_instance.uuid)
6326             def query_driver_power_state_and_sync():
6327                 self._query_driver_power_state_and_sync(context, db_instance)
6328 
6329             try:
6330                 query_driver_power_state_and_sync()
6331             except Exception:
6332                 LOG.exception(_LE("Periodic sync_power_state task had an "
6333                                   "error while processing an instance."),
6334                               instance=db_instance)
6335 
6336             self._syncs_in_progress.pop(db_instance.uuid)
6337 
6338         for db_instance in db_instances:
6339             # process syncs asynchronously - don't want instance locking to
6340             # block entire periodic task thread
6341             uuid = db_instance.uuid
6342             if uuid in self._syncs_in_progress:
6343                 LOG.debug('Sync already in progress for %s', uuid)
6344             else:
6345                 LOG.debug('Triggering sync for uuid %s', uuid)
6346                 self._syncs_in_progress[uuid] = True
6347                 self._sync_power_pool.spawn_n(_sync, db_instance)
6348 
6349     def _query_driver_power_state_and_sync(self, context, db_instance):
6350         if db_instance.task_state is not None:
6351             LOG.info(_LI("During sync_power_state the instance has a "
6352                          "pending task (%(task)s). Skip."),
6353                      {'task': db_instance.task_state}, instance=db_instance)
6354             return
6355         # No pending tasks. Now try to figure out the real vm_power_state.
6356         try:
6357             vm_instance = self.driver.get_info(db_instance)
6358             vm_power_state = vm_instance.state
6359         except exception.InstanceNotFound:
6360             vm_power_state = power_state.NOSTATE
6361         # Note(maoy): the above get_info call might take a long time,
6362         # for example, because of a broken libvirt driver.
6363         try:
6364             self._sync_instance_power_state(context,
6365                                             db_instance,
6366                                             vm_power_state,
6367                                             use_slave=True)
6368         except exception.InstanceNotFound:
6369             # NOTE(hanlind): If the instance gets deleted during sync,
6370             # silently ignore.
6371             pass
6372 
6373     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
6374                                    use_slave=False):
6375         """Align instance power state between the database and hypervisor.
6376 
6377         If the instance is not found on the hypervisor, but is in the database,
6378         then a stop() API will be called on the instance.
6379         """
6380 
6381         # We re-query the DB to get the latest instance info to minimize
6382         # (not eliminate) race condition.
6383         db_instance.refresh(use_slave=use_slave)
6384         db_power_state = db_instance.power_state
6385         vm_state = db_instance.vm_state
6386 
6387         if self.host != db_instance.host:
6388             # on the sending end of nova-compute _sync_power_state
6389             # may have yielded to the greenthread performing a live
6390             # migration; this in turn has changed the resident-host
6391             # for the VM; However, the instance is still active, it
6392             # is just in the process of migrating to another host.
6393             # This implies that the compute source must relinquish
6394             # control to the compute destination.
6395             LOG.info(_LI("During the sync_power process the "
6396                          "instance has moved from "
6397                          "host %(src)s to host %(dst)s"),
6398                      {'src': db_instance.host,
6399                       'dst': self.host},
6400                      instance=db_instance)
6401             return
6402         elif db_instance.task_state is not None:
6403             # on the receiving end of nova-compute, it could happen
6404             # that the DB instance already report the new resident
6405             # but the actual VM has not showed up on the hypervisor
6406             # yet. In this case, let's allow the loop to continue
6407             # and run the state sync in a later round
6408             LOG.info(_LI("During sync_power_state the instance has a "
6409                          "pending task (%(task)s). Skip."),
6410                      {'task': db_instance.task_state},
6411                      instance=db_instance)
6412             return
6413 
6414         orig_db_power_state = db_power_state
6415         if vm_power_state != db_power_state:
6416             LOG.info(_LI('During _sync_instance_power_state the DB '
6417                          'power_state (%(db_power_state)s) does not match '
6418                          'the vm_power_state from the hypervisor '
6419                          '(%(vm_power_state)s). Updating power_state in the '
6420                          'DB to match the hypervisor.'),
6421                      {'db_power_state': db_power_state,
6422                       'vm_power_state': vm_power_state},
6423                      instance=db_instance)
6424             # power_state is always updated from hypervisor to db
6425             db_instance.power_state = vm_power_state
6426             db_instance.save()
6427             db_power_state = vm_power_state
6428 
6429         # Note(maoy): Now resolve the discrepancy between vm_state and
6430         # vm_power_state. We go through all possible vm_states.
6431         if vm_state in (vm_states.BUILDING,
6432                         vm_states.RESCUED,
6433                         vm_states.RESIZED,
6434                         vm_states.SUSPENDED,
6435                         vm_states.ERROR):
6436             # TODO(maoy): we ignore these vm_state for now.
6437             pass
6438         elif vm_state == vm_states.ACTIVE:
6439             # The only rational power state should be RUNNING
6440             if vm_power_state in (power_state.SHUTDOWN,
6441                                   power_state.CRASHED):
6442                 LOG.warning(_LW("Instance shutdown by itself. Calling the "
6443                                 "stop API. Current vm_state: %(vm_state)s, "
6444                                 "current task_state: %(task_state)s, "
6445                                 "original DB power_state: %(db_power_state)s, "
6446                                 "current VM power_state: %(vm_power_state)s"),
6447                             {'vm_state': vm_state,
6448                              'task_state': db_instance.task_state,
6449                              'db_power_state': orig_db_power_state,
6450                              'vm_power_state': vm_power_state},
6451                             instance=db_instance)
6452                 try:
6453                     # Note(maoy): here we call the API instead of
6454                     # brutally updating the vm_state in the database
6455                     # to allow all the hooks and checks to be performed.
6456                     if db_instance.shutdown_terminate:
6457                         self.compute_api.delete(context, db_instance)
6458                     else:
6459                         self.compute_api.stop(context, db_instance)
6460                 except Exception:
6461                     # Note(maoy): there is no need to propagate the error
6462                     # because the same power_state will be retrieved next
6463                     # time and retried.
6464                     # For example, there might be another task scheduled.
6465                     LOG.exception(_LE("error during stop() in "
6466                                       "sync_power_state."),
6467                                   instance=db_instance)
6468             elif vm_power_state == power_state.SUSPENDED:
6469                 LOG.warning(_LW("Instance is suspended unexpectedly. Calling "
6470                                 "the stop API."), instance=db_instance)
6471                 try:
6472                     self.compute_api.stop(context, db_instance)
6473                 except Exception:
6474                     LOG.exception(_LE("error during stop() in "
6475                                       "sync_power_state."),
6476                                   instance=db_instance)
6477             elif vm_power_state == power_state.PAUSED:
6478                 # Note(maoy): a VM may get into the paused state not only
6479                 # because the user request via API calls, but also
6480                 # due to (temporary) external instrumentations.
6481                 # Before the virt layer can reliably report the reason,
6482                 # we simply ignore the state discrepancy. In many cases,
6483                 # the VM state will go back to running after the external
6484                 # instrumentation is done. See bug 1097806 for details.
6485                 LOG.warning(_LW("Instance is paused unexpectedly. Ignore."),
6486                             instance=db_instance)
6487             elif vm_power_state == power_state.NOSTATE:
6488                 # Occasionally, depending on the status of the hypervisor,
6489                 # which could be restarting for example, an instance may
6490                 # not be found.  Therefore just log the condition.
6491                 LOG.warning(_LW("Instance is unexpectedly not found. Ignore."),
6492                             instance=db_instance)
6493         elif vm_state == vm_states.STOPPED:
6494             if vm_power_state not in (power_state.NOSTATE,
6495                                       power_state.SHUTDOWN,
6496                                       power_state.CRASHED):
6497                 LOG.warning(_LW("Instance is not stopped. Calling "
6498                                 "the stop API. Current vm_state: %(vm_state)s,"
6499                                 " current task_state: %(task_state)s, "
6500                                 "original DB power_state: %(db_power_state)s, "
6501                                 "current VM power_state: %(vm_power_state)s"),
6502                             {'vm_state': vm_state,
6503                              'task_state': db_instance.task_state,
6504                              'db_power_state': orig_db_power_state,
6505                              'vm_power_state': vm_power_state},
6506                             instance=db_instance)
6507                 try:
6508                     # NOTE(russellb) Force the stop, because normally the
6509                     # compute API would not allow an attempt to stop a stopped
6510                     # instance.
6511                     self.compute_api.force_stop(context, db_instance)
6512                 except Exception:
6513                     LOG.exception(_LE("error during stop() in "
6514                                       "sync_power_state."),
6515                                   instance=db_instance)
6516         elif vm_state == vm_states.PAUSED:
6517             if vm_power_state in (power_state.SHUTDOWN,
6518                                   power_state.CRASHED):
6519                 LOG.warning(_LW("Paused instance shutdown by itself. Calling "
6520                                 "the stop API."), instance=db_instance)
6521                 try:
6522                     self.compute_api.force_stop(context, db_instance)
6523                 except Exception:
6524                     LOG.exception(_LE("error during stop() in "
6525                                       "sync_power_state."),
6526                                   instance=db_instance)
6527         elif vm_state in (vm_states.SOFT_DELETED,
6528                           vm_states.DELETED):
6529             if vm_power_state not in (power_state.NOSTATE,
6530                                       power_state.SHUTDOWN):
6531                 # Note(maoy): this should be taken care of periodically in
6532                 # _cleanup_running_deleted_instances().
6533                 LOG.warning(_LW("Instance is not (soft-)deleted."),
6534                             instance=db_instance)
6535 
6536     @periodic_task.periodic_task
6537     def _reclaim_queued_deletes(self, context):
6538         """Reclaim instances that are queued for deletion."""
6539         interval = CONF.reclaim_instance_interval
6540         if interval <= 0:
6541             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
6542             return
6543 
6544         # TODO(comstud, jichenjc): Dummy quota object for now See bug 1296414.
6545         # The only case that the quota might be inconsistent is
6546         # the compute node died between set instance state to SOFT_DELETED
6547         # and quota commit to DB. When compute node starts again
6548         # it will have no idea the reservation is committed or not or even
6549         # expired, since it's a rare case, so marked as todo.
6550         quotas = objects.Quotas.from_reservations(context, None)
6551 
6552         filters = {'vm_state': vm_states.SOFT_DELETED,
6553                    'task_state': None,
6554                    'host': self.host}
6555         instances = objects.InstanceList.get_by_filters(
6556             context, filters,
6557             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
6558             use_slave=True)
6559         for instance in instances:
6560             if self._deleted_old_enough(instance, interval):
6561                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6562                         context, instance.uuid)
6563                 LOG.info(_LI('Reclaiming deleted instance'), instance=instance)
6564                 try:
6565                     self._delete_instance(context, instance, bdms, quotas)
6566                 except Exception as e:
6567                     LOG.warning(_LW("Periodic reclaim failed to delete "
6568                                     "instance: %s"),
6569                                 e, instance=instance)
6570 
6571     def update_available_resource_for_node(self, context, nodename):
6572 
6573         rt = self._get_resource_tracker()
6574         try:
6575             rt.update_available_resource(context, nodename)
6576         except exception.ComputeHostNotFound:
6577             # NOTE(comstud): We can get to this case if a node was
6578             # marked 'deleted' in the DB and then re-added with a
6579             # different auto-increment id. The cached resource
6580             # tracker tried to update a deleted record and failed.
6581             # Don't add this resource tracker to the new dict, so
6582             # that this will resolve itself on the next run.
6583             LOG.info(_LI("Compute node '%s' not found in "
6584                          "update_available_resource."), nodename)
6585             # TODO(jaypipes): Yes, this is inefficient to throw away all of the
6586             # compute nodes to force a rebuild, but this is only temporary
6587             # until Ironic baremetal node resource providers are tracked
6588             # properly in the report client and this is a tiny edge case
6589             # anyway.
6590             self._resource_tracker = None
6591             return
6592         except Exception:
6593             LOG.exception(_LE("Error updating resources for node "
6594                           "%(node)s."), {'node': nodename})
6595 
6596     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
6597     def update_available_resource(self, context, startup=False):
6598         """See driver.get_available_resource()
6599 
6600         Periodic process that keeps that the compute host's understanding of
6601         resource availability and usage in sync with the underlying hypervisor.
6602 
6603         :param context: security context
6604         :param startup: True if this is being called when the nova-compute
6605             service is starting, False otherwise.
6606         """
6607 
6608         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
6609                                                             use_slave=True,
6610                                                             startup=startup)
6611         nodenames = set(self.driver.get_available_nodes())
6612         for nodename in nodenames:
6613             self.update_available_resource_for_node(context, nodename)
6614 
6615         # Delete orphan compute node not reported by driver but still in db
6616         for cn in compute_nodes_in_db:
6617             if cn.hypervisor_hostname not in nodenames:
6618                 LOG.info(_LI("Deleting orphan compute node %(id)s "
6619                              "hypervisor host is %(hh)s, "
6620                              "nodes are %(nodes)s"),
6621                              {'id': cn.id, 'hh': cn.hypervisor_hostname,
6622                               'nodes': nodenames})
6623                 cn.destroy()
6624                 # Delete the corresponding resource provider in placement,
6625                 # along with any associated allocations and inventory.
6626                 # TODO(cdent): Move use of reportclient into resource tracker.
6627                 self.scheduler_client.reportclient.delete_resource_provider(
6628                     context, cn, cascade=True)
6629 
6630     def _get_compute_nodes_in_db(self, context, use_slave=False,
6631                                  startup=False):
6632         try:
6633             return objects.ComputeNodeList.get_all_by_host(context, self.host,
6634                                                            use_slave=use_slave)
6635         except exception.NotFound:
6636             if startup:
6637                 LOG.warning(
6638                     _LW("No compute node record found for host %s. If this is "
6639                         "the first time this service is starting on this "
6640                         "host, then you can ignore this warning."), self.host)
6641             else:
6642                 LOG.error(_LE("No compute node record for host %s"), self.host)
6643             return []
6644 
6645     @periodic_task.periodic_task(
6646         spacing=CONF.running_deleted_instance_poll_interval)
6647     def _cleanup_running_deleted_instances(self, context):
6648         """Cleanup any instances which are erroneously still running after
6649         having been deleted.
6650 
6651         Valid actions to take are:
6652 
6653             1. noop - do nothing
6654             2. log - log which instances are erroneously running
6655             3. reap - shutdown and cleanup any erroneously running instances
6656             4. shutdown - power off *and disable* any erroneously running
6657                           instances
6658 
6659         The use-case for this cleanup task is: for various reasons, it may be
6660         possible for the database to show an instance as deleted but for that
6661         instance to still be running on a host machine (see bug
6662         https://bugs.launchpad.net/nova/+bug/911366).
6663 
6664         This cleanup task is a cross-hypervisor utility for finding these
6665         zombied instances and either logging the discrepancy (likely what you
6666         should do in production), or automatically reaping the instances (more
6667         appropriate for dev environments).
6668         """
6669         action = CONF.running_deleted_instance_action
6670 
6671         if action == "noop":
6672             return
6673 
6674         # NOTE(sirp): admin contexts don't ordinarily return deleted records
6675         with utils.temporary_mutation(context, read_deleted="yes"):
6676             for instance in self._running_deleted_instances(context):
6677                 if action == "log":
6678                     LOG.warning(_LW("Detected instance with name label "
6679                                     "'%s' which is marked as "
6680                                     "DELETED but still present on host."),
6681                                 instance.name, instance=instance)
6682 
6683                 elif action == 'shutdown':
6684                     LOG.info(_LI("Powering off instance with name label "
6685                                  "'%s' which is marked as "
6686                                  "DELETED but still present on host."),
6687                              instance.name, instance=instance)
6688                     try:
6689                         try:
6690                             # disable starting the instance
6691                             self.driver.set_bootable(instance, False)
6692                         except NotImplementedError:
6693                             LOG.debug("set_bootable is not implemented "
6694                                       "for the current driver")
6695                         # and power it off
6696                         self.driver.power_off(instance)
6697                     except Exception:
6698                         msg = _LW("Failed to power off instance")
6699                         LOG.warning(msg, instance=instance, exc_info=True)
6700 
6701                 elif action == 'reap':
6702                     LOG.info(_LI("Destroying instance with name label "
6703                                  "'%s' which is marked as "
6704                                  "DELETED but still present on host."),
6705                              instance.name, instance=instance)
6706                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6707                         context, instance.uuid, use_slave=True)
6708                     self.instance_events.clear_events_for_instance(instance)
6709                     try:
6710                         self._shutdown_instance(context, instance, bdms,
6711                                                 notify=False)
6712                         self._cleanup_volumes(context, instance.uuid, bdms)
6713                     except Exception as e:
6714                         LOG.warning(_LW("Periodic cleanup failed to delete "
6715                                         "instance: %s"),
6716                                     e, instance=instance)
6717                 else:
6718                     raise Exception(_("Unrecognized value '%s'"
6719                                       " for CONF.running_deleted_"
6720                                       "instance_action") % action)
6721 
6722     def _running_deleted_instances(self, context):
6723         """Returns a list of instances nova thinks is deleted,
6724         but the hypervisor thinks is still running.
6725         """
6726         timeout = CONF.running_deleted_instance_timeout
6727         filters = {'deleted': True,
6728                    'soft_deleted': False,
6729                    'host': self.host}
6730         instances = self._get_instances_on_driver(context, filters)
6731         return [i for i in instances if self._deleted_old_enough(i, timeout)]
6732 
6733     def _deleted_old_enough(self, instance, timeout):
6734         deleted_at = instance.deleted_at
6735         if deleted_at:
6736             deleted_at = deleted_at.replace(tzinfo=None)
6737         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
6738 
6739     @contextlib.contextmanager
6740     def _error_out_instance_on_exception(self, context, instance,
6741                                          quotas=None,
6742                                          instance_state=vm_states.ACTIVE):
6743         instance_uuid = instance.uuid
6744         try:
6745             yield
6746         except NotImplementedError as error:
6747             with excutils.save_and_reraise_exception():
6748                 if quotas:
6749                     quotas.rollback()
6750                 LOG.info(_LI("Setting instance back to %(state)s after: "
6751                              "%(error)s"),
6752                          {'state': instance_state, 'error': error},
6753                          instance_uuid=instance_uuid)
6754                 self._instance_update(context, instance,
6755                                       vm_state=instance_state,
6756                                       task_state=None)
6757         except exception.InstanceFaultRollback as error:
6758             if quotas:
6759                 quotas.rollback()
6760             LOG.info(_LI("Setting instance back to ACTIVE after: %s"),
6761                      error, instance_uuid=instance_uuid)
6762             self._instance_update(context, instance,
6763                                   vm_state=vm_states.ACTIVE,
6764                                   task_state=None)
6765             raise error.inner_exception
6766         except Exception:
6767             LOG.exception(_LE('Setting instance vm_state to ERROR'),
6768                           instance_uuid=instance_uuid)
6769             with excutils.save_and_reraise_exception():
6770                 if quotas:
6771                     quotas.rollback()
6772                 self._set_instance_obj_error_state(context, instance)
6773 
6774     @wrap_exception()
6775     def add_aggregate_host(self, context, aggregate, host, slave_info):
6776         """Notify hypervisor of change (for hypervisor pools)."""
6777         try:
6778             self.driver.add_to_aggregate(context, aggregate, host,
6779                                          slave_info=slave_info)
6780         except NotImplementedError:
6781             LOG.debug('Hypervisor driver does not support '
6782                       'add_aggregate_host')
6783         except exception.AggregateError:
6784             with excutils.save_and_reraise_exception():
6785                 self.driver.undo_aggregate_operation(
6786                                     context,
6787                                     aggregate.delete_host,
6788                                     aggregate, host)
6789 
6790     @wrap_exception()
6791     def remove_aggregate_host(self, context, host, slave_info, aggregate):
6792         """Removes a host from a physical hypervisor pool."""
6793         try:
6794             self.driver.remove_from_aggregate(context, aggregate, host,
6795                                               slave_info=slave_info)
6796         except NotImplementedError:
6797             LOG.debug('Hypervisor driver does not support '
6798                       'remove_aggregate_host')
6799         except (exception.AggregateError,
6800                 exception.InvalidAggregateAction) as e:
6801             with excutils.save_and_reraise_exception():
6802                 self.driver.undo_aggregate_operation(
6803                                     context,
6804                                     aggregate.add_host,
6805                                     aggregate, host,
6806                                     isinstance(e, exception.AggregateError))
6807 
6808     def _process_instance_event(self, instance, event):
6809         _event = self.instance_events.pop_instance_event(instance, event)
6810         if _event:
6811             LOG.debug('Processing event %(event)s',
6812                       {'event': event.key}, instance=instance)
6813             _event.send(event)
6814         else:
6815             LOG.warning(_LW('Received unexpected event %(event)s for '
6816                             'instance'),
6817                         {'event': event.key}, instance=instance)
6818 
6819     def _process_instance_vif_deleted_event(self, context, instance,
6820                                             deleted_vif_id):
6821         # If an attached port is deleted by neutron, it needs to
6822         # be detached from the instance.
6823         # And info cache needs to be updated.
6824         network_info = instance.info_cache.network_info
6825         for index, vif in enumerate(network_info):
6826             if vif['id'] == deleted_vif_id:
6827                 LOG.info(_LI('Neutron deleted interface %(intf)s; '
6828                              'detaching it from the instance and '
6829                              'deleting it from the info cache'),
6830                          {'intf': vif['id']},
6831                          instance=instance)
6832                 del network_info[index]
6833                 base_net_api.update_instance_cache_with_nw_info(
6834                                  self.network_api, context,
6835                                  instance,
6836                                  nw_info=network_info)
6837                 try:
6838                     self.driver.detach_interface(context, instance, vif)
6839                 except NotImplementedError:
6840                     # Not all virt drivers support attach/detach of interfaces
6841                     # yet (like Ironic), so just ignore this.
6842                     pass
6843                 except exception.NovaException as ex:
6844                     LOG.warning(_LW("Detach interface failed, "
6845                                     "port_id=%(port_id)s, reason: %(msg)s"),
6846                                 {'port_id': deleted_vif_id, 'msg': ex},
6847                                 instance=instance)
6848                 break
6849 
6850     @wrap_exception()
6851     def external_instance_event(self, context, instances, events):
6852         # NOTE(danms): Some event types are handled by the manager, such
6853         # as when we're asked to update the instance's info_cache. If it's
6854         # not one of those, look for some thread(s) waiting for the event and
6855         # unblock them if so.
6856         for event in events:
6857             instance = [inst for inst in instances
6858                         if inst.uuid == event.instance_uuid][0]
6859             LOG.debug('Received event %(event)s',
6860                       {'event': event.key},
6861                       instance=instance)
6862             if event.name == 'network-changed':
6863                 try:
6864                     self.network_api.get_instance_nw_info(context, instance)
6865                 except exception.NotFound as e:
6866                     LOG.info(_LI('Failed to process external instance event '
6867                                  '%(event)s due to: %(error)s'),
6868                              {'event': event.key, 'error': six.text_type(e)},
6869                              instance=instance)
6870             elif event.name == 'network-vif-deleted':
6871                 try:
6872                     self._process_instance_vif_deleted_event(context,
6873                                                              instance,
6874                                                              event.tag)
6875                 except exception.NotFound as e:
6876                     LOG.info(_LI('Failed to process external instance event '
6877                                  '%(event)s due to: %(error)s'),
6878                              {'event': event.key, 'error': six.text_type(e)},
6879                              instance=instance)
6880             else:
6881                 self._process_instance_event(instance, event)
6882 
6883     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
6884                                  external_process_ok=True)
6885     def _run_image_cache_manager_pass(self, context):
6886         """Run a single pass of the image cache manager."""
6887 
6888         if not self.driver.capabilities["has_imagecache"]:
6889             return
6890 
6891         # Determine what other nodes use this storage
6892         storage_users.register_storage_use(CONF.instances_path, CONF.host)
6893         nodes = storage_users.get_storage_users(CONF.instances_path)
6894 
6895         # Filter all_instances to only include those nodes which share this
6896         # storage path.
6897         # TODO(mikal): this should be further refactored so that the cache
6898         # cleanup code doesn't know what those instances are, just a remote
6899         # count, and then this logic should be pushed up the stack.
6900         filters = {'deleted': False,
6901                    'soft_deleted': True,
6902                    'host': nodes}
6903         filtered_instances = objects.InstanceList.get_by_filters(context,
6904                                  filters, expected_attrs=[], use_slave=True)
6905 
6906         self.driver.manage_image_cache(context, filtered_instances)
6907 
6908     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6909     def _run_pending_deletes(self, context):
6910         """Retry any pending instance file deletes."""
6911         LOG.debug('Cleaning up deleted instances')
6912         filters = {'deleted': True,
6913                    'soft_deleted': False,
6914                    'host': CONF.host,
6915                    'cleaned': False}
6916         attrs = ['system_metadata']
6917         with utils.temporary_mutation(context, read_deleted='yes'):
6918             instances = objects.InstanceList.get_by_filters(
6919                 context, filters, expected_attrs=attrs, use_slave=True)
6920         LOG.debug('There are %d instances to clean', len(instances))
6921 
6922         # TODO(raj_singh): Remove this if condition when min value is
6923         # introduced to "maximum_instance_delete_attempts" cfg option.
6924         if CONF.maximum_instance_delete_attempts < 1:
6925             LOG.warning(_LW('Future versions of Nova will restrict the '
6926                             '"maximum_instance_delete_attempts" config option '
6927                             'to values >=1. Update your configuration file to '
6928                             'mitigate future upgrade issues.'))
6929 
6930         for instance in instances:
6931             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
6932             LOG.debug('Instance has had %(attempts)s of %(max)s '
6933                       'cleanup attempts',
6934                       {'attempts': attempts,
6935                        'max': CONF.maximum_instance_delete_attempts},
6936                       instance=instance)
6937             if attempts < CONF.maximum_instance_delete_attempts:
6938                 success = self.driver.delete_instance_files(instance)
6939 
6940                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
6941                 if success:
6942                     instance.cleaned = True
6943                 with utils.temporary_mutation(context, read_deleted='yes'):
6944                     instance.save()
6945 
6946     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6947     def _cleanup_incomplete_migrations(self, context):
6948         """Delete instance files on failed resize/revert-resize operation
6949 
6950         During resize/revert-resize operation, if that instance gets deleted
6951         in-between then instance files might remain either on source or
6952         destination compute node because of race condition.
6953         """
6954         LOG.debug('Cleaning up deleted instances with incomplete migration ')
6955         migration_filters = {'host': CONF.host,
6956                              'status': 'error'}
6957         migrations = objects.MigrationList.get_by_filters(context,
6958                                                           migration_filters)
6959 
6960         if not migrations:
6961             return
6962 
6963         inst_uuid_from_migrations = set([migration.instance_uuid for migration
6964                                          in migrations])
6965 
6966         inst_filters = {'deleted': True, 'soft_deleted': False,
6967                         'uuid': inst_uuid_from_migrations}
6968         attrs = ['info_cache', 'security_groups', 'system_metadata']
6969         with utils.temporary_mutation(context, read_deleted='yes'):
6970             instances = objects.InstanceList.get_by_filters(
6971                 context, inst_filters, expected_attrs=attrs, use_slave=True)
6972 
6973         for instance in instances:
6974             if instance.host != CONF.host:
6975                 for migration in migrations:
6976                     if instance.uuid == migration.instance_uuid:
6977                         # Delete instance files if not cleanup properly either
6978                         # from the source or destination compute nodes when
6979                         # the instance is deleted during resizing.
6980                         self.driver.delete_instance_files(instance)
6981                         try:
6982                             migration.status = 'failed'
6983                             with migration.obj_as_admin():
6984                                 migration.save()
6985                         except exception.MigrationNotFound:
6986                             LOG.warning(_LW("Migration %s is not found."),
6987                                         migration.id,
6988                                         instance=instance)
6989                         break
6990 
6991     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
6992                                    exception.QemuGuestAgentNotEnabled,
6993                                    exception.NovaException,
6994                                    NotImplementedError)
6995     @wrap_exception()
6996     def quiesce_instance(self, context, instance):
6997         """Quiesce an instance on this host."""
6998         context = context.elevated()
6999         image_meta = objects.ImageMeta.from_instance(instance)
7000         self.driver.quiesce(context, instance, image_meta)
7001 
7002     def _wait_for_snapshots_completion(self, context, mapping):
7003         for mapping_dict in mapping:
7004             if mapping_dict.get('source_type') == 'snapshot':
7005 
7006                 def _wait_snapshot():
7007                     snapshot = self.volume_api.get_snapshot(
7008                         context, mapping_dict['snapshot_id'])
7009                     if snapshot.get('status') != 'creating':
7010                         raise loopingcall.LoopingCallDone()
7011 
7012                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
7013                 timer.start(interval=0.5).wait()
7014 
7015     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7016                                    exception.QemuGuestAgentNotEnabled,
7017                                    exception.NovaException,
7018                                    NotImplementedError)
7019     @wrap_exception()
7020     def unquiesce_instance(self, context, instance, mapping=None):
7021         """Unquiesce an instance on this host.
7022 
7023         If snapshots' image mapping is provided, it waits until snapshots are
7024         completed before unqueiscing.
7025         """
7026         context = context.elevated()
7027         if mapping:
7028             try:
7029                 self._wait_for_snapshots_completion(context, mapping)
7030             except Exception as error:
7031                 LOG.exception(_LE("Exception while waiting completion of "
7032                                   "volume snapshots: %s"),
7033                               error, instance=instance)
7034         image_meta = objects.ImageMeta.from_instance(instance)
7035         self.driver.unquiesce(context, instance, image_meta)
