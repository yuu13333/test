Please review the code below for security defects. You can consider defect types in terms of:
1.CWE-284 (Improper Access Control)
2.CWE-435 (Improper Interaction Between Multiple Entities)
3.CWE-664 (Improper Control of a Resource Through its Lifetime)
4.CWE-682 (Incorrect Calculation)
5.CWE-691 (Insufficient Control Flow Management)
6.CWE-693 (Protection Mechanism Failure)
7.CWE-697 (Incorrect Comparison)
8.CWE-703 (Improper Check or Handling of Exceptional Conditions)
9.CWE-707 (Improper Neutralization)
10.CWE-710 (Improper Adherence to Coding Standards)
If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are detected, states: 'No security defects are detected in the code'.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 from cursive import exception as cursive_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 import futurist
44 from keystoneauth1 import exceptions as keystone_exception
45 from oslo_log import log as logging
46 import oslo_messaging as messaging
47 from oslo_serialization import jsonutils
48 from oslo_service import loopingcall
49 from oslo_service import periodic_task
50 from oslo_utils import excutils
51 from oslo_utils import strutils
52 from oslo_utils import timeutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova.console import rpcapi as console_rpcapi
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova import image
77 from nova import manager
78 from nova import network
79 from nova.network import base_api as base_net_api
80 from nova.network import model as network_model
81 from nova.network.security_group import openstack_driver
82 from nova import objects
83 from nova.objects import base as obj_base
84 from nova.objects import fields
85 from nova.objects import instance as obj_instance
86 from nova.objects import migrate_data as migrate_data_obj
87 from nova.pci import whitelist
88 from nova import rpc
89 from nova import safe_utils
90 from nova.scheduler.client import query
91 from nova import utils
92 from nova.virt import block_device as driver_block_device
93 from nova.virt import configdrive
94 from nova.virt import driver
95 from nova.virt import event as virtevent
96 from nova.virt import storage_users
97 from nova.virt import virtapi
98 from nova.volume import cinder
99 
100 CONF = nova.conf.CONF
101 
102 LOG = logging.getLogger(__name__)
103 
104 get_notifier = functools.partial(rpc.get_notifier, service='compute')
105 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
106                                    get_notifier=get_notifier,
107                                    binary='nova-compute')
108 
109 
110 @contextlib.contextmanager
111 def errors_out_migration_ctxt(migration):
112     """Context manager to error out migration on failure."""
113 
114     try:
115         yield
116     except Exception:
117         with excutils.save_and_reraise_exception():
118             if migration:
119                 # We may have been passed None for our migration if we're
120                 # receiving from an older client. The migration will be
121                 # errored via the legacy path.
122                 migration.status = 'error'
123                 try:
124                     with migration.obj_as_admin():
125                         migration.save()
126                 except Exception:
127                     LOG.debug(
128                         'Error setting migration status for instance %s.',
129                         migration.instance_uuid, exc_info=True)
130 
131 
132 @utils.expects_func_args('migration')
133 def errors_out_migration(function):
134     """Decorator to error out migration on failure."""
135 
136     @functools.wraps(function)
137     def decorated_function(self, context, *args, **kwargs):
138         wrapped_func = safe_utils.get_wrapped_function(function)
139         keyed_args = inspect.getcallargs(wrapped_func, self, context,
140                                          *args, **kwargs)
141         migration = keyed_args['migration']
142         with errors_out_migration_ctxt(migration):
143             return function(self, context, *args, **kwargs)
144 
145     return decorated_function
146 
147 
148 @utils.expects_func_args('instance')
149 def reverts_task_state(function):
150     """Decorator to revert task_state on failure."""
151 
152     @functools.wraps(function)
153     def decorated_function(self, context, *args, **kwargs):
154         try:
155             return function(self, context, *args, **kwargs)
156         except exception.UnexpectedTaskStateError as e:
157             # Note(maoy): unexpected task state means the current
158             # task is preempted. Do not clear task state in this
159             # case.
160             with excutils.save_and_reraise_exception():
161                 LOG.info("Task possibly preempted: %s",
162                          e.format_message())
163         except Exception:
164             with excutils.save_and_reraise_exception():
165                 wrapped_func = safe_utils.get_wrapped_function(function)
166                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
167                                                  *args, **kwargs)
168                 # NOTE(mriedem): 'instance' must be in keyed_args because we
169                 # have utils.expects_func_args('instance') decorating this
170                 # method.
171                 instance = keyed_args['instance']
172                 original_task_state = instance.task_state
173                 try:
174                     self._instance_update(context, instance, task_state=None)
175                     LOG.info("Successfully reverted task state from %s on "
176                              "failure for instance.",
177                              original_task_state, instance=instance)
178                 except exception.InstanceNotFound:
179                     # We might delete an instance that failed to build shortly
180                     # after it errored out this is an expected case and we
181                     # should not trace on it.
182                     pass
183                 except Exception as e:
184                     LOG.warning("Failed to revert task state for instance. "
185                                 "Error: %s", e, instance=instance)
186 
187     return decorated_function
188 
189 
190 @utils.expects_func_args('instance')
191 def wrap_instance_fault(function):
192     """Wraps a method to catch exceptions related to instances.
193 
194     This decorator wraps a method to catch any exceptions having to do with
195     an instance that may get thrown. It then logs an instance fault in the db.
196     """
197 
198     @functools.wraps(function)
199     def decorated_function(self, context, *args, **kwargs):
200         try:
201             return function(self, context, *args, **kwargs)
202         except exception.InstanceNotFound:
203             raise
204         except Exception as e:
205             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
206             # we will get a KeyError exception which will cover up the real
207             # exception. So, we update kwargs with the values from args first.
208             # then, we can get 'instance' from kwargs easily.
209             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
210 
211             with excutils.save_and_reraise_exception():
212                 compute_utils.add_instance_fault_from_exc(context,
213                         kwargs['instance'], e, sys.exc_info())
214 
215     return decorated_function
216 
217 
218 @utils.expects_func_args('image_id', 'instance')
219 def delete_image_on_error(function):
220     """Used for snapshot related method to ensure the image created in
221     compute.api is deleted when an error occurs.
222     """
223 
224     @functools.wraps(function)
225     def decorated_function(self, context, image_id, instance,
226                            *args, **kwargs):
227         try:
228             return function(self, context, image_id, instance,
229                             *args, **kwargs)
230         except Exception:
231             with excutils.save_and_reraise_exception():
232                 LOG.debug("Cleaning up image %s", image_id,
233                           exc_info=True, instance=instance)
234                 try:
235                     self.image_api.delete(context, image_id)
236                 except exception.ImageNotFound:
237                     # Since we're trying to cleanup an image, we don't care if
238                     # if it's already gone.
239                     pass
240                 except Exception:
241                     LOG.exception("Error while trying to clean up image %s",
242                                   image_id, instance=instance)
243 
244     return decorated_function
245 
246 
247 # TODO(danms): Remove me after Icehouse
248 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
249 # NOTE(mikal): if the method being decorated has more than one decorator, then
250 # put this one first. Otherwise the various exception handling decorators do
251 # not function correctly.
252 def object_compat(function):
253     """Wraps a method that expects a new-world instance
254 
255     This provides compatibility for callers passing old-style dict
256     instances.
257     """
258 
259     @functools.wraps(function)
260     def decorated_function(self, context, *args, **kwargs):
261         def _load_instance(instance_or_dict):
262             if isinstance(instance_or_dict, dict):
263                 # try to get metadata and system_metadata for most cases but
264                 # only attempt to load those if the db instance already has
265                 # those fields joined
266                 metas = [meta for meta in ('metadata', 'system_metadata')
267                          if meta in instance_or_dict]
268                 instance = objects.Instance._from_db_object(
269                     context, objects.Instance(), instance_or_dict,
270                     expected_attrs=metas)
271                 instance._context = context
272                 return instance
273             return instance_or_dict
274 
275         try:
276             kwargs['instance'] = _load_instance(kwargs['instance'])
277         except KeyError:
278             args = (_load_instance(args[0]),) + args[1:]
279 
280         migration = kwargs.get('migration')
281         if isinstance(migration, dict):
282             migration = objects.Migration._from_db_object(
283                     context.elevated(), objects.Migration(),
284                     migration)
285             kwargs['migration'] = migration
286 
287         return function(self, context, *args, **kwargs)
288 
289     return decorated_function
290 
291 
292 class InstanceEvents(object):
293     def __init__(self):
294         self._events = {}
295 
296     @staticmethod
297     def _lock_name(instance):
298         return '%s-%s' % (instance.uuid, 'events')
299 
300     def prepare_for_instance_event(self, instance, name, tag):
301         """Prepare to receive an event for an instance.
302 
303         This will register an event for the given instance that we will
304         wait on later. This should be called before initiating whatever
305         action will trigger the event. The resulting eventlet.event.Event
306         object should be wait()'d on to ensure completion.
307 
308         :param instance: the instance for which the event will be generated
309         :param name: the name of the event we're expecting
310         :param tag: the tag associated with the event we're expecting
311         :returns: an event object that should be wait()'d on
312         """
313         if self._events is None:
314             # NOTE(danms): We really should have a more specific error
315             # here, but this is what we use for our default error case
316             raise exception.NovaException('In shutdown, no new events '
317                                           'can be scheduled')
318 
319         @utils.synchronized(self._lock_name(instance))
320         def _create_or_get_event():
321             instance_events = self._events.setdefault(instance.uuid, {})
322             return instance_events.setdefault((name, tag),
323                                               eventlet.event.Event())
324         LOG.debug('Preparing to wait for external event %(name)s-%(tag)s',
325                   {'name': name, 'tag': tag}, instance=instance)
326         return _create_or_get_event()
327 
328     def pop_instance_event(self, instance, event):
329         """Remove a pending event from the wait list.
330 
331         This will remove a pending event from the wait list so that it
332         can be used to signal the waiters to wake up.
333 
334         :param instance: the instance for which the event was generated
335         :param event: the nova.objects.external_event.InstanceExternalEvent
336                       that describes the event
337         :returns: the eventlet.event.Event object on which the waiters
338                   are blocked
339         """
340         no_events_sentinel = object()
341         no_matching_event_sentinel = object()
342 
343         @utils.synchronized(self._lock_name(instance))
344         def _pop_event():
345             if self._events is None:
346                 LOG.debug('Unexpected attempt to pop events during shutdown',
347                           instance=instance)
348                 return no_events_sentinel
349             events = self._events.get(instance.uuid)
350             if not events:
351                 return no_events_sentinel
352             _event = events.pop((event.name, event.tag), None)
353             if not events:
354                 del self._events[instance.uuid]
355             if _event is None:
356                 return no_matching_event_sentinel
357             return _event
358 
359         result = _pop_event()
360         if result is no_events_sentinel:
361             LOG.debug('No waiting events found dispatching %(event)s',
362                       {'event': event.key},
363                       instance=instance)
364             return None
365         elif result is no_matching_event_sentinel:
366             LOG.debug('No event matching %(event)s in %(events)s',
367                       {'event': event.key,
368                        'events': self._events.get(instance.uuid, {}).keys()},
369                       instance=instance)
370             return None
371         else:
372             return result
373 
374     def clear_events_for_instance(self, instance):
375         """Remove all pending events for an instance.
376 
377         This will remove all events currently pending for an instance
378         and return them (indexed by event name).
379 
380         :param instance: the instance for which events should be purged
381         :returns: a dictionary of {event_name: eventlet.event.Event}
382         """
383         @utils.synchronized(self._lock_name(instance))
384         def _clear_events():
385             if self._events is None:
386                 LOG.debug('Unexpected attempt to clear events during shutdown',
387                           instance=instance)
388                 return dict()
389             # NOTE(danms): We have historically returned the raw internal
390             # format here, which is {event.key: [events, ...])} so just
391             # trivially convert it here.
392             return {'%s-%s' % k: e
393                     for k, e in self._events.pop(instance.uuid, {}).items()}
394         return _clear_events()
395 
396     def cancel_all_events(self):
397         if self._events is None:
398             LOG.debug('Unexpected attempt to cancel events during shutdown.')
399             return
400         our_events = self._events
401         # NOTE(danms): Block new events
402         self._events = None
403 
404         for instance_uuid, events in our_events.items():
405             for (name, tag), eventlet_event in events.items():
406                 LOG.debug('Canceling in-flight event %(name)s-%(tag)s for '
407                           'instance %(instance_uuid)s',
408                           {'name': name,
409                            'tag': tag,
410                            'instance_uuid': instance_uuid})
411                 event = objects.InstanceExternalEvent(
412                     instance_uuid=instance_uuid,
413                     name=name, status='failed',
414                     tag=tag, data={})
415                 eventlet_event.send(event)
416 
417 
418 class ComputeVirtAPI(virtapi.VirtAPI):
419     def __init__(self, compute):
420         super(ComputeVirtAPI, self).__init__()
421         self._compute = compute
422 
423     def _default_error_callback(self, event_name, instance):
424         raise exception.NovaException(_('Instance event failed'))
425 
426     @contextlib.contextmanager
427     def wait_for_instance_event(self, instance, event_names, deadline=300,
428                                 error_callback=None):
429         """Plan to wait for some events, run some code, then wait.
430 
431         This context manager will first create plans to wait for the
432         provided event_names, yield, and then wait for all the scheduled
433         events to complete.
434 
435         Note that this uses an eventlet.timeout.Timeout to bound the
436         operation, so callers should be prepared to catch that
437         failure and handle that situation appropriately.
438 
439         If the event is not received by the specified timeout deadline,
440         eventlet.timeout.Timeout is raised.
441 
442         If the event is received but did not have a 'completed'
443         status, a NovaException is raised.  If an error_callback is
444         provided, instead of raising an exception as detailed above
445         for the failure case, the callback will be called with the
446         event_name and instance, and can return True to continue
447         waiting for the rest of the events, False to stop processing,
448         or raise an exception which will bubble up to the waiter.
449 
450         :param instance: The instance for which an event is expected
451         :param event_names: A list of event names. Each element is a
452                             tuple of strings to indicate (name, tag),
453                             where name is required, but tag may be None.
454         :param deadline: Maximum number of seconds we should wait for all
455                          of the specified events to arrive.
456         :param error_callback: A function to be called if an event arrives
457 
458         """
459 
460         if error_callback is None:
461             error_callback = self._default_error_callback
462         events = {}
463         for event_name in event_names:
464             name, tag = event_name
465             event_name = objects.InstanceExternalEvent.make_key(name, tag)
466             try:
467                 events[event_name] = (
468                     self._compute.instance_events.prepare_for_instance_event(
469                         instance, name, tag))
470             except exception.NovaException:
471                 error_callback(event_name, instance)
472                 # NOTE(danms): Don't wait for any of the events. They
473                 # should all be canceled and fired immediately below,
474                 # but don't stick around if not.
475                 deadline = 0
476         yield
477         with eventlet.timeout.Timeout(deadline):
478             for event_name, event in events.items():
479                 actual_event = event.wait()
480                 if actual_event.status == 'completed':
481                     continue
482                 decision = error_callback(event_name, instance)
483                 if decision is False:
484                     break
485 
486 
487 class ComputeManager(manager.Manager):
488     """Manages the running instances from creation to destruction."""
489 
490     target = messaging.Target(version='5.2')
491 
492     def __init__(self, compute_driver=None, *args, **kwargs):
493         """Load configuration options and connect to the hypervisor."""
494         self.virtapi = ComputeVirtAPI(self)
495         self.network_api = network.API()
496         self.volume_api = cinder.API()
497         self.image_api = image.API()
498         self._last_host_check = 0
499         self._last_bw_usage_poll = 0
500         self._bw_usage_supported = True
501         self._last_bw_usage_cell_update = 0
502         self.compute_api = compute.API()
503         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
504         self.conductor_api = conductor.API()
505         self.compute_task_api = conductor.ComputeTaskAPI()
506         self.is_neutron_security_groups = (
507             openstack_driver.is_neutron_security_groups())
508         self.cells_rpcapi = cells_rpcapi.CellsAPI()
509         self.query_client = query.SchedulerQueryClient()
510         self.instance_events = InstanceEvents()
511         self._sync_power_pool = eventlet.GreenPool(
512             size=CONF.sync_power_state_pool_size)
513         self._syncs_in_progress = {}
514         self.send_instance_updates = (
515             CONF.filter_scheduler.track_instance_changes)
516         if CONF.max_concurrent_builds != 0:
517             self._build_semaphore = eventlet.semaphore.Semaphore(
518                 CONF.max_concurrent_builds)
519         else:
520             self._build_semaphore = compute_utils.UnlimitedSemaphore()
521         if max(CONF.max_concurrent_live_migrations, 0) != 0:
522             self._live_migration_executor = futurist.GreenThreadPoolExecutor(
523                 max_workers=CONF.max_concurrent_live_migrations)
524         else:
525             if CONF.max_concurrent_live_migrations < 0:
526                 LOG.warning('The value of the max_concurrent_live_migrations '
527                             'config option is less than 0. '
528                             'It is treated as 0 and will raise ValueError '
529                             'in a future release.')
530             self._live_migration_executor = futurist.GreenThreadPoolExecutor()
531         # This is a dict, keyed by instance uuid, to a two-item tuple of
532         # migration object and Future for the queued live migration.
533         self._waiting_live_migrations = {}
534 
535         super(ComputeManager, self).__init__(service_name="compute",
536                                              *args, **kwargs)
537 
538         # NOTE(russellb) Load the driver last.  It may call back into the
539         # compute manager via the virtapi, so we want it to be fully
540         # initialized before that happens.
541         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
542         self.use_legacy_block_device_info = \
543                             self.driver.need_legacy_block_device_info
544         self.rt = resource_tracker.ResourceTracker(self.host, self.driver)
545         self.reportclient = self.rt.reportclient
546 
547     def reset(self):
548         LOG.info('Reloading compute RPC API')
549         compute_rpcapi.LAST_VERSION = None
550         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
551         self.reportclient.clear_provider_cache()
552 
553     def _update_resource_tracker(self, context, instance):
554         """Let the resource tracker know that an instance has changed state."""
555 
556         if instance.host == self.host:
557             self.rt.update_usage(context, instance, instance.node)
558 
559     def _instance_update(self, context, instance, **kwargs):
560         """Update an instance in the database using kwargs as value."""
561 
562         for k, v in kwargs.items():
563             setattr(instance, k, v)
564         instance.save()
565         self._update_resource_tracker(context, instance)
566 
567     def _nil_out_instance_obj_host_and_node(self, instance):
568         # NOTE(jwcroppe): We don't do instance.save() here for performance
569         # reasons; a call to this is expected to be immediately followed by
570         # another call that does instance.save(), thus avoiding two writes
571         # to the database layer.
572         instance.host = None
573         instance.node = None
574         # If the instance is not on a host, it's not in an aggregate and
575         # therefore is not in an availability zone.
576         instance.availability_zone = None
577 
578     def _set_instance_obj_error_state(self, context, instance,
579                                       clean_task_state=False):
580         try:
581             instance.vm_state = vm_states.ERROR
582             if clean_task_state:
583                 instance.task_state = None
584             instance.save()
585         except exception.InstanceNotFound:
586             LOG.debug('Instance has been destroyed from under us while '
587                       'trying to set it to ERROR', instance=instance)
588 
589     def _get_instances_on_driver(self, context, filters=None):
590         """Return a list of instance records for the instances found
591         on the hypervisor which satisfy the specified filters. If filters=None
592         return a list of instance records for all the instances found on the
593         hypervisor.
594         """
595         if not filters:
596             filters = {}
597         try:
598             driver_uuids = self.driver.list_instance_uuids()
599             if len(driver_uuids) == 0:
600                 # Short circuit, don't waste a DB call
601                 return objects.InstanceList()
602             filters['uuid'] = driver_uuids
603             local_instances = objects.InstanceList.get_by_filters(
604                 context, filters, use_slave=True)
605             return local_instances
606         except NotImplementedError:
607             pass
608 
609         # The driver doesn't support uuids listing, so we'll have
610         # to brute force.
611         driver_instances = self.driver.list_instances()
612         # NOTE(mjozefcz): In this case we need to apply host filter.
613         # Without this all instance data would be fetched from db.
614         filters['host'] = self.host
615         instances = objects.InstanceList.get_by_filters(context, filters,
616                                                         use_slave=True)
617         name_map = {instance.name: instance for instance in instances}
618         local_instances = []
619         for driver_instance in driver_instances:
620             instance = name_map.get(driver_instance)
621             if not instance:
622                 continue
623             local_instances.append(instance)
624         return local_instances
625 
626     def _destroy_evacuated_instances(self, context):
627         """Destroys evacuated instances.
628 
629         While nova-compute was down, the instances running on it could be
630         evacuated to another host. This method looks for evacuation migration
631         records where this is the source host and which were either started
632         (accepted), in-progress (pre-migrating) or migrated (done). From those
633         migration records, local instances reported by the hypervisor are
634         compared to the instances for the migration records and those local
635         guests are destroyed, along with instance allocation records in
636         Placement for this node.
637         """
638         filters = {
639             'source_compute': self.host,
640             # NOTE(mriedem): Migration records that have been accepted are
641             # included in case the source node comes back up while instances
642             # are being evacuated to another host. We don't want the same
643             # instance being reported from multiple hosts.
644             # NOTE(lyarwood): pre-migrating is also included here as the
645             # source compute can come back online shortly after the RT
646             # claims on the destination that in-turn moves the migration to
647             # pre-migrating. If the evacuate fails on the destination host,
648             # the user can rebuild the instance (in ERROR state) on the source
649             # host.
650             'status': ['accepted', 'pre-migrating', 'done'],
651             'migration_type': 'evacuation',
652         }
653         with utils.temporary_mutation(context, read_deleted='yes'):
654             evacuations = objects.MigrationList.get_by_filters(context,
655                                                                filters)
656         if not evacuations:
657             return
658         evacuations = {mig.instance_uuid: mig for mig in evacuations}
659 
660         # TODO(mriedem): We could optimize by pre-loading the joined fields
661         # we know we'll use, like info_cache and flavor.
662         local_instances = self._get_instances_on_driver(context)
663         evacuated = [inst for inst in local_instances
664                      if inst.uuid in evacuations]
665 
666         # NOTE(gibi): We are called from init_host and at this point the
667         # compute_nodes of the resource tracker has not been populated yet so
668         # we cannot rely on the resource tracker here.
669         compute_nodes = {}
670 
671         for instance in evacuated:
672             migration = evacuations[instance.uuid]
673             LOG.info('Deleting instance as it has been evacuated from '
674                      'this host', instance=instance)
675             try:
676                 network_info = self.network_api.get_instance_nw_info(
677                     context, instance)
678                 bdi = self._get_instance_block_device_info(context,
679                                                            instance)
680                 destroy_disks = not (self._is_instance_storage_shared(
681                     context, instance))
682             except exception.InstanceNotFound:
683                 network_info = network_model.NetworkInfo()
684                 bdi = {}
685                 LOG.info('Instance has been marked deleted already, '
686                          'removing it from the hypervisor.',
687                          instance=instance)
688                 # always destroy disks if the instance was deleted
689                 destroy_disks = True
690             self.driver.destroy(context, instance,
691                                 network_info,
692                                 bdi, destroy_disks)
693 
694             # delete the allocation of the evacuated instance from this host
695             if migration.source_node not in compute_nodes:
696                 try:
697                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
698                         context, self.host, migration.source_node).uuid
699                     compute_nodes[migration.source_node] = cn_uuid
700                 except exception.ComputeHostNotFound:
701                     LOG.error("Failed to clean allocation of evacuated "
702                               "instance as the source node %s is not found",
703                               migration.source_node, instance=instance)
704                     continue
705             cn_uuid = compute_nodes[migration.source_node]
706 
707             # If the instance was deleted in the interim, assume its
708             # allocations were properly cleaned up (either by its hosting
709             # compute service or the API).
710             if (not instance.deleted and
711                     not self.reportclient.
712                         remove_provider_tree_from_instance_allocation(
713                             context, instance.uuid, cn_uuid)):
714                 LOG.error("Failed to clean allocation of evacuated instance "
715                           "on the source node %s",
716                           cn_uuid, instance=instance)
717 
718             migration.status = 'completed'
719             migration.save()
720         return evacuations
721 
722     def _is_instance_storage_shared(self, context, instance, host=None):
723         shared_storage = True
724         data = None
725         try:
726             data = self.driver.check_instance_shared_storage_local(context,
727                                                        instance)
728             if data:
729                 shared_storage = (self.compute_rpcapi.
730                                   check_instance_shared_storage(context,
731                                   instance, data, host=host))
732         except NotImplementedError:
733             LOG.debug('Hypervisor driver does not support '
734                       'instance shared storage check, '
735                       'assuming it\'s not on shared storage',
736                       instance=instance)
737             shared_storage = False
738         except Exception:
739             LOG.exception('Failed to check if instance shared',
740                           instance=instance)
741         finally:
742             if data:
743                 self.driver.check_instance_shared_storage_cleanup(context,
744                                                                   data)
745         return shared_storage
746 
747     def _complete_partial_deletion(self, context, instance):
748         """Complete deletion for instances in DELETED status but not marked as
749         deleted in the DB
750         """
751         instance.destroy()
752         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
753                 context, instance.uuid)
754         self._complete_deletion(context,
755                                 instance)
756         self._notify_about_instance_usage(context, instance, "delete.end")
757         compute_utils.notify_about_instance_action(context, instance,
758                 self.host, action=fields.NotificationAction.DELETE,
759                 phase=fields.NotificationPhase.END, bdms=bdms)
760 
761     def _complete_deletion(self, context, instance):
762         self._update_resource_tracker(context, instance)
763 
764         self.reportclient.delete_allocation_for_instance(context,
765                                                          instance.uuid)
766 
767         self._clean_instance_console_tokens(context, instance)
768         self._delete_scheduler_instance_info(context, instance.uuid)
769 
770     def _init_instance(self, context, instance):
771         """Initialize this instance during service init."""
772 
773         # NOTE(danms): If the instance appears to not be owned by this
774         # host, it may have been evacuated away, but skipped by the
775         # evacuation cleanup code due to configuration. Thus, if that
776         # is a possibility, don't touch the instance in any way, but
777         # log the concern. This will help avoid potential issues on
778         # startup due to misconfiguration.
779         if instance.host != self.host:
780             LOG.warning('Instance %(uuid)s appears to not be owned '
781                         'by this host, but by %(host)s. Startup '
782                         'processing is being skipped.',
783                         {'uuid': instance.uuid,
784                          'host': instance.host})
785             return
786 
787         # Instances that are shut down, or in an error state can not be
788         # initialized and are not attempted to be recovered. The exception
789         # to this are instances that are in RESIZE_MIGRATING or DELETING,
790         # which are dealt with further down.
791         if (instance.vm_state == vm_states.SOFT_DELETED or
792             (instance.vm_state == vm_states.ERROR and
793             instance.task_state not in
794             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
795             LOG.debug("Instance is in %s state.",
796                       instance.vm_state, instance=instance)
797             return
798 
799         if instance.vm_state == vm_states.DELETED:
800             try:
801                 self._complete_partial_deletion(context, instance)
802             except Exception:
803                 # we don't want that an exception blocks the init_host
804                 LOG.exception('Failed to complete a deletion',
805                               instance=instance)
806             return
807 
808         if (instance.vm_state == vm_states.BUILDING or
809             instance.task_state in [task_states.SCHEDULING,
810                                     task_states.BLOCK_DEVICE_MAPPING,
811                                     task_states.NETWORKING,
812                                     task_states.SPAWNING]):
813             # NOTE(dave-mcnally) compute stopped before instance was fully
814             # spawned so set to ERROR state. This is safe to do as the state
815             # may be set by the api but the host is not so if we get here the
816             # instance has already been scheduled to this particular host.
817             LOG.debug("Instance failed to spawn correctly, "
818                       "setting to ERROR state", instance=instance)
819             instance.task_state = None
820             instance.vm_state = vm_states.ERROR
821             instance.save()
822             return
823 
824         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
825             instance.task_state in [task_states.REBUILDING,
826                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
827                                     task_states.REBUILD_SPAWNING]):
828             # NOTE(jichenjc) compute stopped before instance was fully
829             # spawned so set to ERROR state. This is consistent to BUILD
830             LOG.debug("Instance failed to rebuild correctly, "
831                       "setting to ERROR state", instance=instance)
832             instance.task_state = None
833             instance.vm_state = vm_states.ERROR
834             instance.save()
835             return
836 
837         if (instance.vm_state != vm_states.ERROR and
838             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
839                                     task_states.IMAGE_PENDING_UPLOAD,
840                                     task_states.IMAGE_UPLOADING,
841                                     task_states.IMAGE_SNAPSHOT]):
842             LOG.debug("Instance in transitional state %s at start-up "
843                       "clearing task state",
844                       instance.task_state, instance=instance)
845             try:
846                 self._post_interrupted_snapshot_cleanup(context, instance)
847             except Exception:
848                 # we don't want that an exception blocks the init_host
849                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
850             instance.task_state = None
851             instance.save()
852 
853         if (instance.vm_state != vm_states.ERROR and
854             instance.task_state in [task_states.RESIZE_PREP]):
855             LOG.debug("Instance in transitional state %s at start-up "
856                       "clearing task state",
857                       instance['task_state'], instance=instance)
858             instance.task_state = None
859             instance.save()
860 
861         if instance.task_state == task_states.DELETING:
862             try:
863                 LOG.info('Service started deleting the instance during '
864                          'the previous run, but did not finish. Restarting'
865                          ' the deletion now.', instance=instance)
866                 instance.obj_load_attr('metadata')
867                 instance.obj_load_attr('system_metadata')
868                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
869                         context, instance.uuid)
870                 self._delete_instance(context, instance, bdms)
871             except Exception:
872                 # we don't want that an exception blocks the init_host
873                 LOG.exception('Failed to complete a deletion',
874                               instance=instance)
875                 self._set_instance_obj_error_state(context, instance)
876             return
877 
878         current_power_state = self._get_power_state(context, instance)
879         try_reboot, reboot_type = self._retry_reboot(context, instance,
880                                                      current_power_state)
881 
882         if try_reboot:
883             LOG.debug("Instance in transitional state (%(task_state)s) at "
884                       "start-up and power state is (%(power_state)s), "
885                       "triggering reboot",
886                       {'task_state': instance.task_state,
887                        'power_state': current_power_state},
888                       instance=instance)
889 
890             # NOTE(mikal): if the instance was doing a soft reboot that got as
891             # far as shutting down the instance but not as far as starting it
892             # again, then we've just become a hard reboot. That means the
893             # task state for the instance needs to change so that we're in one
894             # of the expected task states for a hard reboot.
895             if (instance.task_state in task_states.soft_reboot_states and
896                 reboot_type == 'HARD'):
897                 instance.task_state = task_states.REBOOT_PENDING_HARD
898                 instance.save()
899 
900             self.reboot_instance(context, instance, block_device_info=None,
901                                  reboot_type=reboot_type)
902             return
903 
904         elif (current_power_state == power_state.RUNNING and
905               instance.task_state in [task_states.REBOOT_STARTED,
906                                       task_states.REBOOT_STARTED_HARD,
907                                       task_states.PAUSING,
908                                       task_states.UNPAUSING]):
909             LOG.warning("Instance in transitional state "
910                         "(%(task_state)s) at start-up and power state "
911                         "is (%(power_state)s), clearing task state",
912                         {'task_state': instance.task_state,
913                          'power_state': current_power_state},
914                         instance=instance)
915             instance.task_state = None
916             instance.vm_state = vm_states.ACTIVE
917             instance.save()
918         elif (current_power_state == power_state.PAUSED and
919               instance.task_state == task_states.UNPAUSING):
920             LOG.warning("Instance in transitional state "
921                         "(%(task_state)s) at start-up and power state "
922                         "is (%(power_state)s), clearing task state "
923                         "and unpausing the instance",
924                         {'task_state': instance.task_state,
925                          'power_state': current_power_state},
926                         instance=instance)
927             try:
928                 self.unpause_instance(context, instance)
929             except NotImplementedError:
930                 # Some virt driver didn't support pause and unpause
931                 pass
932             except Exception:
933                 LOG.exception('Failed to unpause instance', instance=instance)
934             return
935 
936         if instance.task_state == task_states.POWERING_OFF:
937             try:
938                 LOG.debug("Instance in transitional state %s at start-up "
939                           "retrying stop request",
940                           instance.task_state, instance=instance)
941                 self.stop_instance(context, instance, True)
942             except Exception:
943                 # we don't want that an exception blocks the init_host
944                 LOG.exception('Failed to stop instance', instance=instance)
945             return
946 
947         if instance.task_state == task_states.POWERING_ON:
948             try:
949                 LOG.debug("Instance in transitional state %s at start-up "
950                           "retrying start request",
951                           instance.task_state, instance=instance)
952                 self.start_instance(context, instance)
953             except Exception:
954                 # we don't want that an exception blocks the init_host
955                 LOG.exception('Failed to start instance', instance=instance)
956             return
957 
958         net_info = instance.get_network_info()
959         try:
960             self.driver.plug_vifs(instance, net_info)
961         except NotImplementedError as e:
962             LOG.debug(e, instance=instance)
963         except exception.VirtualInterfacePlugException:
964             # NOTE(mriedem): If we get here, it could be because the vif_type
965             # in the cache is "binding_failed" or "unbound".  The only way to
966             # fix this is to try and bind the ports again, which would be
967             # expensive here on host startup. We could add a check to
968             # _heal_instance_info_cache to handle this, but probably only if
969             # the instance task_state is None.
970             LOG.exception('Virtual interface plugging failed for instance. '
971                           'The port binding:host_id may need to be manually '
972                           'updated.', instance=instance)
973             self._set_instance_obj_error_state(context, instance)
974             return
975 
976         if instance.task_state == task_states.RESIZE_MIGRATING:
977             # We crashed during resize/migration, so roll back for safety
978             try:
979                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
980                 # not in system_metadata we default to True for backwards
981                 # compatibility
982                 power_on = (instance.system_metadata.get('old_vm_state') !=
983                             vm_states.STOPPED)
984 
985                 block_dev_info = self._get_instance_block_device_info(context,
986                                                                       instance)
987 
988                 self.driver.finish_revert_migration(context,
989                     instance, net_info, block_dev_info, power_on)
990 
991             except Exception:
992                 LOG.exception('Failed to revert crashed migration',
993                               instance=instance)
994             finally:
995                 LOG.info('Instance found in migrating state during '
996                          'startup. Resetting task_state',
997                          instance=instance)
998                 instance.task_state = None
999                 instance.save()
1000         if instance.task_state == task_states.MIGRATING:
1001             # Live migration did not complete, but instance is on this
1002             # host, so reset the state.
1003             instance.task_state = None
1004             instance.save(expected_task_state=[task_states.MIGRATING])
1005 
1006         db_state = instance.power_state
1007         drv_state = self._get_power_state(context, instance)
1008         expect_running = (db_state == power_state.RUNNING and
1009                           drv_state != db_state)
1010 
1011         LOG.debug('Current state is %(drv_state)s, state in DB is '
1012                   '%(db_state)s.',
1013                   {'drv_state': drv_state, 'db_state': db_state},
1014                   instance=instance)
1015 
1016         if expect_running and CONF.resume_guests_state_on_host_boot:
1017             self._resume_guests_state(context, instance, net_info)
1018         elif drv_state == power_state.RUNNING:
1019             # VMwareAPI drivers will raise an exception
1020             try:
1021                 self.driver.ensure_filtering_rules_for_instance(
1022                                        instance, net_info)
1023             except NotImplementedError:
1024                 LOG.debug('Hypervisor driver does not support '
1025                           'firewall rules', instance=instance)
1026 
1027     def _resume_guests_state(self, context, instance, net_info):
1028         LOG.info('Rebooting instance after nova-compute restart.',
1029                  instance=instance)
1030         block_device_info = \
1031             self._get_instance_block_device_info(context, instance)
1032 
1033         try:
1034             self.driver.resume_state_on_host_boot(
1035                 context, instance, net_info, block_device_info)
1036         except NotImplementedError:
1037             LOG.warning('Hypervisor driver does not support '
1038                         'resume guests', instance=instance)
1039         except Exception:
1040             # NOTE(vish): The instance failed to resume, so we set the
1041             #             instance to error and attempt to continue.
1042             LOG.warning('Failed to resume instance',
1043                         instance=instance)
1044             self._set_instance_obj_error_state(context, instance)
1045 
1046     def _retry_reboot(self, context, instance, current_power_state):
1047         current_task_state = instance.task_state
1048         retry_reboot = False
1049         reboot_type = compute_utils.get_reboot_type(current_task_state,
1050                                                     current_power_state)
1051 
1052         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1053                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1054         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1055                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1056         started_not_running = (current_task_state in
1057                                [task_states.REBOOT_STARTED,
1058                                 task_states.REBOOT_STARTED_HARD] and
1059                                current_power_state != power_state.RUNNING)
1060 
1061         if pending_soft or pending_hard or started_not_running:
1062             retry_reboot = True
1063 
1064         return retry_reboot, reboot_type
1065 
1066     def handle_lifecycle_event(self, event):
1067         LOG.info("VM %(state)s (Lifecycle Event)",
1068                  {'state': event.get_name()},
1069                  instance_uuid=event.get_instance_uuid())
1070         context = nova.context.get_admin_context(read_deleted='yes')
1071         vm_power_state = None
1072         event_transition = event.get_transition()
1073         if event_transition == virtevent.EVENT_LIFECYCLE_STOPPED:
1074             vm_power_state = power_state.SHUTDOWN
1075         elif event_transition == virtevent.EVENT_LIFECYCLE_STARTED:
1076             vm_power_state = power_state.RUNNING
1077         elif event_transition in (
1078                 virtevent.EVENT_LIFECYCLE_PAUSED,
1079                 virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED,
1080                 virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED):
1081             vm_power_state = power_state.PAUSED
1082         elif event_transition == virtevent.EVENT_LIFECYCLE_RESUMED:
1083             vm_power_state = power_state.RUNNING
1084         elif event_transition == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1085             vm_power_state = power_state.SUSPENDED
1086         else:
1087             LOG.warning("Unexpected lifecycle event: %d", event_transition)
1088 
1089         migrate_finish_statuses = {
1090             # This happens on the source node and indicates live migration
1091             # entered post-copy mode.
1092             virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED: 'running (post-copy)',
1093             # Suspended for offline migration.
1094             virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED: 'running'
1095         }
1096 
1097         expected_attrs = []
1098         if event_transition in migrate_finish_statuses:
1099             # Join on info_cache since that's needed in migrate_instance_start.
1100             expected_attrs.append('info_cache')
1101         instance = objects.Instance.get_by_uuid(context,
1102                                                 event.get_instance_uuid(),
1103                                                 expected_attrs=expected_attrs)
1104 
1105         # Note(lpetrut): The event may be delayed, thus not reflecting
1106         # the current instance power state. In that case, ignore the event.
1107         current_power_state = self._get_power_state(context, instance)
1108         if current_power_state == vm_power_state:
1109             LOG.debug('Synchronizing instance power state after lifecycle '
1110                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1111                       'current task_state: %(task_state)s, current DB '
1112                       'power_state: %(db_power_state)s, VM power_state: '
1113                       '%(vm_power_state)s',
1114                       {'event': event.get_name(),
1115                        'vm_state': instance.vm_state,
1116                        'task_state': instance.task_state,
1117                        'db_power_state': instance.power_state,
1118                        'vm_power_state': vm_power_state},
1119                       instance_uuid=instance.uuid)
1120             self._sync_instance_power_state(context,
1121                                             instance,
1122                                             vm_power_state)
1123 
1124         # The following checks are for live migration. We want to activate
1125         # the port binding for the destination host before the live migration
1126         # is resumed on the destination host in order to reduce network
1127         # downtime. Otherwise the ports are bound to the destination host
1128         # in post_live_migration_at_destination.
1129         # TODO(danms): Explore options for using a different live migration
1130         # specific callback for this instead of piggy-backing on the
1131         # handle_lifecycle_event callback.
1132         if (instance.task_state == task_states.MIGRATING and
1133                 event_transition in migrate_finish_statuses):
1134             status = migrate_finish_statuses[event_transition]
1135             try:
1136                 migration = objects.Migration.get_by_instance_and_status(
1137                             context, instance.uuid, status)
1138                 LOG.debug('Binding ports to destination host: %s',
1139                           migration.dest_compute, instance=instance)
1140                 # For neutron, migrate_instance_start will activate the
1141                 # destination host port bindings, if there are any created by
1142                 # conductor before live migration started.
1143                 self.network_api.migrate_instance_start(
1144                     context, instance, migration)
1145             except exception.MigrationNotFoundByStatus:
1146                 LOG.warning("Unable to find migration record with status "
1147                             "'%s' for instance. Port binding will happen in "
1148                             "post live migration.", status, instance=instance)
1149 
1150     def handle_events(self, event):
1151         if isinstance(event, virtevent.LifecycleEvent):
1152             try:
1153                 self.handle_lifecycle_event(event)
1154             except exception.InstanceNotFound:
1155                 LOG.debug("Event %s arrived for non-existent instance. The "
1156                           "instance was probably deleted.", event)
1157         else:
1158             LOG.debug("Ignoring event %s", event)
1159 
1160     def init_virt_events(self):
1161         if CONF.workarounds.handle_virt_lifecycle_events:
1162             self.driver.register_event_listener(self.handle_events)
1163         else:
1164             # NOTE(mriedem): If the _sync_power_states periodic task is
1165             # disabled we should emit a warning in the logs.
1166             if CONF.sync_power_state_interval < 0:
1167                 LOG.warning('Instance lifecycle events from the compute '
1168                             'driver have been disabled. Note that lifecycle '
1169                             'changes to an instance outside of the compute '
1170                             'service will not be synchronized '
1171                             'automatically since the _sync_power_states '
1172                             'periodic task is also disabled.')
1173             else:
1174                 LOG.info('Instance lifecycle events from the compute '
1175                          'driver have been disabled. Note that lifecycle '
1176                          'changes to an instance outside of the compute '
1177                          'service will only be synchronized by the '
1178                          '_sync_power_states periodic task.')
1179 
1180     def init_host(self):
1181         """Initialization for a standalone compute service."""
1182 
1183         if CONF.pci.passthrough_whitelist:
1184             # Simply loading the PCI passthrough whitelist will do a bunch of
1185             # validation that would otherwise wait until the PciDevTracker is
1186             # constructed when updating available resources for the compute
1187             # node(s) in the resource tracker, effectively killing that task.
1188             # So load up the whitelist when starting the compute service to
1189             # flush any invalid configuration early so we can kill the service
1190             # if the configuration is wrong.
1191             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1192 
1193         nova.conf.neutron.register_dynamic_opts(CONF)
1194 
1195         # Override the number of concurrent disk operations allowed if the
1196         # user has specified a limit.
1197         if CONF.compute.max_concurrent_disk_ops != 0:
1198             compute_utils.disk_ops_semaphore = \
1199                 eventlet.semaphore.BoundedSemaphore(
1200                     CONF.compute.max_concurrent_disk_ops)
1201 
1202         self.driver.init_host(host=self.host)
1203         context = nova.context.get_admin_context()
1204         instances = objects.InstanceList.get_by_host(
1205             context, self.host, expected_attrs=['info_cache', 'metadata'])
1206 
1207         if CONF.defer_iptables_apply:
1208             self.driver.filter_defer_apply_on()
1209 
1210         self.init_virt_events()
1211 
1212         try:
1213             # checking that instance was not already evacuated to other host
1214             evacuated_instances = self._destroy_evacuated_instances(context)
1215 
1216             # Initialise instances on the host that are not evacuating
1217             for instance in instances:
1218                 if (not evacuated_instances or
1219                         instance.uuid not in evacuated_instances):
1220                     self._init_instance(context, instance)
1221 
1222         finally:
1223             if CONF.defer_iptables_apply:
1224                 self.driver.filter_defer_apply_off()
1225             if instances:
1226                 # We only send the instance info to the scheduler on startup
1227                 # if there is anything to send, otherwise this host might
1228                 # not be mapped yet in a cell and the scheduler may have
1229                 # issues dealing with the information. Later changes to
1230                 # instances on this host will update the scheduler, or the
1231                 # _sync_scheduler_instance_info periodic task will.
1232                 self._update_scheduler_instance_info(context, instances)
1233 
1234     def cleanup_host(self):
1235         self.driver.register_event_listener(None)
1236         self.instance_events.cancel_all_events()
1237         self.driver.cleanup_host(host=self.host)
1238         self._cleanup_live_migrations_in_pool()
1239 
1240     def _cleanup_live_migrations_in_pool(self):
1241         # Shutdown the pool so we don't get new requests.
1242         self._live_migration_executor.shutdown(wait=False)
1243         # For any queued migrations, cancel the migration and update
1244         # its status.
1245         for migration, future in self._waiting_live_migrations.values():
1246             # If we got here before the Future was submitted then we need
1247             # to move on since there isn't anything we can do.
1248             if future is None:
1249                 continue
1250             if future.cancel():
1251                 self._set_migration_status(migration, 'cancelled')
1252                 LOG.info('Successfully cancelled queued live migration.',
1253                          instance_uuid=migration.instance_uuid)
1254             else:
1255                 LOG.warning('Unable to cancel live migration.',
1256                             instance_uuid=migration.instance_uuid)
1257         self._waiting_live_migrations.clear()
1258 
1259     def pre_start_hook(self):
1260         """After the service is initialized, but before we fully bring
1261         the service up by listening on RPC queues, make sure to update
1262         our available resources (and indirectly our available nodes).
1263         """
1264         self.update_available_resource(nova.context.get_admin_context(),
1265                                        startup=True)
1266 
1267     def _get_power_state(self, context, instance):
1268         """Retrieve the power state for the given instance."""
1269         LOG.debug('Checking state', instance=instance)
1270         try:
1271             return self.driver.get_info(instance).state
1272         except exception.InstanceNotFound:
1273             return power_state.NOSTATE
1274 
1275     def get_console_topic(self, context):
1276         """Retrieves the console host for a project on this host.
1277 
1278         Currently this is just set in the flags for each compute host.
1279 
1280         """
1281         # TODO(mdragon): perhaps make this variable by console_type?
1282         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1283 
1284     @wrap_exception()
1285     def get_console_pool_info(self, context, console_type):
1286         return self.driver.get_console_pool_info(console_type)
1287 
1288     @wrap_exception()
1289     def refresh_instance_security_rules(self, context, instance):
1290         """Tell the virtualization driver to refresh security rules for
1291         an instance.
1292 
1293         Passes straight through to the virtualization driver.
1294 
1295         Synchronize the call because we may still be in the middle of
1296         creating the instance.
1297         """
1298         @utils.synchronized(instance.uuid)
1299         def _sync_refresh():
1300             try:
1301                 return self.driver.refresh_instance_security_rules(instance)
1302             except NotImplementedError:
1303                 LOG.debug('Hypervisor driver does not support '
1304                           'security groups.', instance=instance)
1305 
1306         return _sync_refresh()
1307 
1308     def _await_block_device_map_created(self, context, vol_id):
1309         # TODO(yamahata): creating volume simultaneously
1310         #                 reduces creation time?
1311         # TODO(yamahata): eliminate dumb polling
1312         start = time.time()
1313         retries = CONF.block_device_allocate_retries
1314         if retries < 0:
1315             LOG.warning("Treating negative config value (%(retries)s) for "
1316                         "'block_device_retries' as 0.",
1317                         {'retries': retries})
1318         # (1) treat  negative config value as 0
1319         # (2) the configured value is 0, one attempt should be made
1320         # (3) the configured value is > 0, then the total number attempts
1321         #      is (retries + 1)
1322         attempts = 1
1323         if retries >= 1:
1324             attempts = retries + 1
1325         for attempt in range(1, attempts + 1):
1326             volume = self.volume_api.get(context, vol_id)
1327             volume_status = volume['status']
1328             if volume_status not in ['creating', 'downloading']:
1329                 if volume_status == 'available':
1330                     return attempt
1331                 LOG.warning("Volume id: %(vol_id)s finished being "
1332                             "created but its status is %(vol_status)s.",
1333                             {'vol_id': vol_id,
1334                              'vol_status': volume_status})
1335                 break
1336             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1337         raise exception.VolumeNotCreated(volume_id=vol_id,
1338                                          seconds=int(time.time() - start),
1339                                          attempts=attempt,
1340                                          volume_status=volume_status)
1341 
1342     def _decode_files(self, injected_files):
1343         """Base64 decode the list of files to inject."""
1344         if not injected_files:
1345             return []
1346 
1347         def _decode(f):
1348             path, contents = f
1349             # Py3 raises binascii.Error instead of TypeError as in Py27
1350             try:
1351                 decoded = base64.b64decode(contents)
1352                 return path, decoded
1353             except (TypeError, binascii.Error):
1354                 raise exception.Base64Exception(path=path)
1355 
1356         return [_decode(f) for f in injected_files]
1357 
1358     def _validate_instance_group_policy(self, context, instance,
1359                                         scheduler_hints):
1360         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1361         # However, there is a race condition with the enforcement of
1362         # the policy.  Since more than one instance may be scheduled at the
1363         # same time, it's possible that more than one instance with an
1364         # anti-affinity policy may end up here.  It's also possible that
1365         # multiple instances with an affinity policy could end up on different
1366         # hosts.  This is a validation step to make sure that starting the
1367         # instance here doesn't violate the policy.
1368         group_hint = scheduler_hints.get('group')
1369         if not group_hint:
1370             return
1371 
1372         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1373         # to check the type on the value and pull the single entry out. The
1374         # API request schema validates that the 'group' hint is a single value.
1375         if isinstance(group_hint, list):
1376             group_hint = group_hint[0]
1377 
1378         @utils.synchronized(group_hint)
1379         def _do_validation(context, instance, group_hint):
1380             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1381             if group.policy and 'anti-affinity' == group.policy:
1382                 instances_uuids = objects.InstanceList.get_uuids_by_host(
1383                     context, self.host)
1384                 ins_on_host = set(instances_uuids)
1385                 members = set(group.members)
1386                 # Determine the set of instance group members on this host
1387                 # which are not the instance in question. This is used to
1388                 # determine how many other members from the same anti-affinity
1389                 # group can be on this host.
1390                 members_on_host = ins_on_host & members - set([instance.uuid])
1391                 rules = group.rules
1392                 if rules and 'max_server_per_host' in rules:
1393                     max_server = rules['max_server_per_host']
1394                 else:
1395                     max_server = 1
1396                 if len(members_on_host) >= max_server:
1397                     msg = _("Anti-affinity instance group policy "
1398                             "was violated.")
1399                     raise exception.RescheduledException(
1400                             instance_uuid=instance.uuid,
1401                             reason=msg)
1402             elif group.policy and 'affinity' == group.policy:
1403                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1404                 if group_hosts and self.host not in group_hosts:
1405                     msg = _("Affinity instance group policy was violated.")
1406                     raise exception.RescheduledException(
1407                             instance_uuid=instance.uuid,
1408                             reason=msg)
1409 
1410         if not CONF.workarounds.disable_group_policy_check_upcall:
1411             _do_validation(context, instance, group_hint)
1412 
1413     def _log_original_error(self, exc_info, instance_uuid):
1414         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1415                   exc_info=exc_info)
1416 
1417     # TODO(mriedem): This method is confusing and only ever used for resize
1418     # reschedules; remove it and merge into _reschedule_resize_or_reraise.
1419     def _reschedule(self, context, request_spec, filter_properties,
1420             instance, reschedule_method, method_args, task_state,
1421             exc_info=None, host_list=None):
1422         """Attempt to re-schedule a compute operation."""
1423 
1424         instance_uuid = instance.uuid
1425         retry = filter_properties.get('retry')
1426         if not retry:
1427             # no retry information, do not reschedule.
1428             LOG.debug("Retry info not present, will not reschedule",
1429                       instance_uuid=instance_uuid)
1430             return
1431 
1432         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1433                   {'method': reschedule_method.__name__,
1434                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1435 
1436         # reset the task state:
1437         self._instance_update(context, instance, task_state=task_state)
1438 
1439         if exc_info:
1440             # stringify to avoid circular ref problem in json serialization:
1441             retry['exc'] = traceback.format_exception_only(exc_info[0],
1442                                     exc_info[1])
1443 
1444         reschedule_method(context, *method_args, request_spec=request_spec,
1445                           host_list=host_list)
1446         return True
1447 
1448     @periodic_task.periodic_task
1449     def _check_instance_build_time(self, context):
1450         """Ensure that instances are not stuck in build."""
1451         timeout = CONF.instance_build_timeout
1452         if timeout == 0:
1453             return
1454 
1455         filters = {'vm_state': vm_states.BUILDING,
1456                    'host': self.host}
1457 
1458         building_insts = objects.InstanceList.get_by_filters(context,
1459                            filters, expected_attrs=[], use_slave=True)
1460 
1461         for instance in building_insts:
1462             if timeutils.is_older_than(instance.created_at, timeout):
1463                 self._set_instance_obj_error_state(context, instance)
1464                 LOG.warning("Instance build timed out. Set to error "
1465                             "state.", instance=instance)
1466 
1467     def _check_instance_exists(self, context, instance):
1468         """Ensure an instance with the same name is not already present."""
1469         if self.driver.instance_exists(instance):
1470             raise exception.InstanceExists(name=instance.name)
1471 
1472     def _allocate_network_async(self, context, instance, requested_networks,
1473                                 macs, security_groups, is_vpn,
1474                                 resource_provider_mapping):
1475         """Method used to allocate networks in the background.
1476 
1477         Broken out for testing.
1478         """
1479         # First check to see if we're specifically not supposed to allocate
1480         # networks because if so, we can exit early.
1481         if requested_networks and requested_networks.no_allocate:
1482             LOG.debug("Not allocating networking since 'none' was specified.",
1483                       instance=instance)
1484             return network_model.NetworkInfo([])
1485 
1486         LOG.debug("Allocating IP information in the background.",
1487                   instance=instance)
1488         retries = CONF.network_allocate_retries
1489         attempts = retries + 1
1490         retry_time = 1
1491         bind_host_id = self.driver.network_binding_host_id(context, instance)
1492         for attempt in range(1, attempts + 1):
1493             try:
1494                 nwinfo = self.network_api.allocate_for_instance(
1495                         context, instance, vpn=is_vpn,
1496                         requested_networks=requested_networks,
1497                         macs=macs,
1498                         security_groups=security_groups,
1499                         bind_host_id=bind_host_id,
1500                         resource_provider_mapping=resource_provider_mapping)
1501                 LOG.debug('Instance network_info: |%s|', nwinfo,
1502                           instance=instance)
1503                 instance.system_metadata['network_allocated'] = 'True'
1504                 # NOTE(JoshNang) do not save the instance here, as it can cause
1505                 # races. The caller shares a reference to instance and waits
1506                 # for this async greenthread to finish before calling
1507                 # instance.save().
1508                 return nwinfo
1509             except Exception:
1510                 exc_info = sys.exc_info()
1511                 log_info = {'attempt': attempt,
1512                             'attempts': attempts}
1513                 if attempt == attempts:
1514                     LOG.exception('Instance failed network setup '
1515                                   'after %(attempts)d attempt(s)',
1516                                   log_info)
1517                     six.reraise(*exc_info)
1518                 LOG.warning('Instance failed network setup '
1519                             '(attempt %(attempt)d of %(attempts)d)',
1520                             log_info, instance=instance)
1521                 time.sleep(retry_time)
1522                 retry_time *= 2
1523                 if retry_time > 30:
1524                     retry_time = 30
1525         # Not reached.
1526 
1527     def _build_networks_for_instance(self, context, instance,
1528             requested_networks, security_groups, resource_provider_mapping):
1529 
1530         # If we're here from a reschedule the network may already be allocated.
1531         if strutils.bool_from_string(
1532                 instance.system_metadata.get('network_allocated', 'False')):
1533             # NOTE(alex_xu): The network_allocated is True means the network
1534             # resource already allocated at previous scheduling, and the
1535             # network setup is cleanup at previous. After rescheduling, the
1536             # network resource need setup on the new host.
1537             self.network_api.setup_instance_network_on_host(
1538                 context, instance, instance.host)
1539             return self.network_api.get_instance_nw_info(context, instance)
1540 
1541         if not self.is_neutron_security_groups:
1542             security_groups = []
1543 
1544         macs = self.driver.macs_for_instance(instance)
1545         network_info = self._allocate_network(context, instance,
1546                 requested_networks, macs, security_groups,
1547                 resource_provider_mapping)
1548 
1549         return network_info
1550 
1551     def _allocate_network(self, context, instance, requested_networks, macs,
1552                           security_groups, resource_provider_mapping):
1553         """Start network allocation asynchronously.  Return an instance
1554         of NetworkInfoAsyncWrapper that can be used to retrieve the
1555         allocated networks when the operation has finished.
1556         """
1557         # NOTE(comstud): Since we're allocating networks asynchronously,
1558         # this task state has little meaning, as we won't be in this
1559         # state for very long.
1560         instance.vm_state = vm_states.BUILDING
1561         instance.task_state = task_states.NETWORKING
1562         instance.save(expected_task_state=[None])
1563 
1564         is_vpn = False
1565         return network_model.NetworkInfoAsyncWrapper(
1566                 self._allocate_network_async, context, instance,
1567                 requested_networks, macs, security_groups, is_vpn,
1568                 resource_provider_mapping)
1569 
1570     def _default_root_device_name(self, instance, image_meta, root_bdm):
1571         """Gets a default root device name from the driver.
1572 
1573         :param nova.objects.Instance instance:
1574             The instance for which to get the root device name.
1575         :param nova.objects.ImageMeta image_meta:
1576             The metadata of the image of the instance.
1577         :param nova.objects.BlockDeviceMapping root_bdm:
1578             The description of the root device.
1579         :returns: str -- The default root device name.
1580         :raises: InternalError, TooManyDiskDevices
1581         """
1582         try:
1583             return self.driver.default_root_device_name(instance,
1584                                                         image_meta,
1585                                                         root_bdm)
1586         except NotImplementedError:
1587             return compute_utils.get_next_device_name(instance, [])
1588 
1589     def _default_device_names_for_instance(self, instance,
1590                                            root_device_name,
1591                                            *block_device_lists):
1592         """Default the missing device names in the BDM from the driver.
1593 
1594         :param nova.objects.Instance instance:
1595             The instance for which to get default device names.
1596         :param str root_device_name: The root device name.
1597         :param list block_device_lists: List of block device mappings.
1598         :returns: None
1599         :raises: InternalError, TooManyDiskDevices
1600         """
1601         try:
1602             self.driver.default_device_names_for_instance(instance,
1603                                                           root_device_name,
1604                                                           *block_device_lists)
1605         except NotImplementedError:
1606             compute_utils.default_device_names_for_instance(
1607                 instance, root_device_name, *block_device_lists)
1608 
1609     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1610         """Get the next device name from the driver, based on the BDM.
1611 
1612         :param nova.objects.Instance instance:
1613             The instance whose volume is requesting a device name.
1614         :param nova.objects.BlockDeviceMappingList bdms:
1615             The block device mappings for the instance.
1616         :param nova.objects.BlockDeviceMapping block_device_obj:
1617             A block device mapping containing info about the requested block
1618             device.
1619         :returns: The next device name.
1620         :raises: InternalError, TooManyDiskDevices
1621         """
1622         # NOTE(ndipanov): Copy obj to avoid changing the original
1623         block_device_obj = block_device_obj.obj_clone()
1624         try:
1625             return self.driver.get_device_name_for_instance(
1626                 instance, bdms, block_device_obj)
1627         except NotImplementedError:
1628             return compute_utils.get_device_name_for_instance(
1629                 instance, bdms, block_device_obj.get("device_name"))
1630 
1631     def _default_block_device_names(self, instance, image_meta, block_devices):
1632         """Verify that all the devices have the device_name set. If not,
1633         provide a default name.
1634 
1635         It also ensures that there is a root_device_name and is set to the
1636         first block device in the boot sequence (boot_index=0).
1637         """
1638         root_bdm = block_device.get_root_bdm(block_devices)
1639         if not root_bdm:
1640             return
1641 
1642         # Get the root_device_name from the root BDM or the instance
1643         root_device_name = None
1644         update_root_bdm = False
1645 
1646         if root_bdm.device_name:
1647             root_device_name = root_bdm.device_name
1648             instance.root_device_name = root_device_name
1649         elif instance.root_device_name:
1650             root_device_name = instance.root_device_name
1651             root_bdm.device_name = root_device_name
1652             update_root_bdm = True
1653         else:
1654             root_device_name = self._default_root_device_name(instance,
1655                                                               image_meta,
1656                                                               root_bdm)
1657 
1658             instance.root_device_name = root_device_name
1659             root_bdm.device_name = root_device_name
1660             update_root_bdm = True
1661 
1662         if update_root_bdm:
1663             root_bdm.save()
1664 
1665         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1666                             block_devices))
1667         swap = list(filter(block_device.new_format_is_swap,
1668                       block_devices))
1669         block_device_mapping = list(filter(
1670               driver_block_device.is_block_device_mapping, block_devices))
1671 
1672         self._default_device_names_for_instance(instance,
1673                                                 root_device_name,
1674                                                 ephemerals,
1675                                                 swap,
1676                                                 block_device_mapping)
1677 
1678     def _block_device_info_to_legacy(self, block_device_info):
1679         """Convert BDI to the old format for drivers that need it."""
1680 
1681         if self.use_legacy_block_device_info:
1682             ephemerals = driver_block_device.legacy_block_devices(
1683                 driver.block_device_info_get_ephemerals(block_device_info))
1684             mapping = driver_block_device.legacy_block_devices(
1685                 driver.block_device_info_get_mapping(block_device_info))
1686             swap = block_device_info['swap']
1687             if swap:
1688                 swap = swap.legacy()
1689 
1690             block_device_info.update({
1691                 'ephemerals': ephemerals,
1692                 'swap': swap,
1693                 'block_device_mapping': mapping})
1694 
1695     def _add_missing_dev_names(self, bdms, instance):
1696         for bdm in bdms:
1697             if bdm.device_name is not None:
1698                 continue
1699 
1700             device_name = self._get_device_name_for_instance(instance,
1701                                                              bdms, bdm)
1702             values = {'device_name': device_name}
1703             bdm.update(values)
1704             bdm.save()
1705 
1706     def _prep_block_device(self, context, instance, bdms):
1707         """Set up the block device for an instance with error logging."""
1708         try:
1709             self._add_missing_dev_names(bdms, instance)
1710             block_device_info = driver.get_block_device_info(instance, bdms)
1711             mapping = driver.block_device_info_get_mapping(block_device_info)
1712             driver_block_device.attach_block_devices(
1713                 mapping, context, instance, self.volume_api, self.driver,
1714                 wait_func=self._await_block_device_map_created)
1715 
1716             self._block_device_info_to_legacy(block_device_info)
1717             return block_device_info
1718 
1719         except exception.OverQuota as e:
1720             LOG.warning('Failed to create block device for instance due'
1721                         ' to exceeding volume related resource quota.'
1722                         ' Error: %s', e.message, instance=instance)
1723             raise
1724 
1725         except Exception as ex:
1726             LOG.exception('Instance failed block device setup',
1727                           instance=instance)
1728             # InvalidBDM will eventually result in a BuildAbortException when
1729             # booting from volume, and will be recorded as an instance fault.
1730             # Maintain the original exception message which most likely has
1731             # useful details which the standard InvalidBDM error message lacks.
1732             raise exception.InvalidBDM(six.text_type(ex))
1733 
1734     def _update_instance_after_spawn(self, context, instance):
1735         instance.power_state = self._get_power_state(context, instance)
1736         instance.vm_state = vm_states.ACTIVE
1737         instance.task_state = None
1738         instance.launched_at = timeutils.utcnow()
1739         configdrive.update_instance(instance)
1740 
1741     def _update_scheduler_instance_info(self, context, instance):
1742         """Sends an InstanceList with created or updated Instance objects to
1743         the Scheduler client.
1744 
1745         In the case of init_host, the value passed will already be an
1746         InstanceList. Other calls will send individual Instance objects that
1747         have been created or resized. In this case, we create an InstanceList
1748         object containing that Instance.
1749         """
1750         if not self.send_instance_updates:
1751             return
1752         if isinstance(instance, obj_instance.Instance):
1753             instance = objects.InstanceList(objects=[instance])
1754         context = context.elevated()
1755         self.query_client.update_instance_info(context, self.host,
1756                                                instance)
1757 
1758     def _delete_scheduler_instance_info(self, context, instance_uuid):
1759         """Sends the uuid of the deleted Instance to the Scheduler client."""
1760         if not self.send_instance_updates:
1761             return
1762         context = context.elevated()
1763         self.query_client.delete_instance_info(context, self.host,
1764                                                instance_uuid)
1765 
1766     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1767     def _sync_scheduler_instance_info(self, context):
1768         if not self.send_instance_updates:
1769             return
1770         context = context.elevated()
1771         instances = objects.InstanceList.get_by_host(context, self.host,
1772                                                      expected_attrs=[],
1773                                                      use_slave=True)
1774         uuids = [instance.uuid for instance in instances]
1775         self.query_client.sync_instance_info(context, self.host, uuids)
1776 
1777     def _notify_about_instance_usage(self, context, instance, event_suffix,
1778                                      network_info=None, extra_usage_info=None,
1779                                      fault=None):
1780         compute_utils.notify_about_instance_usage(
1781             self.notifier, context, instance, event_suffix,
1782             network_info=network_info,
1783             extra_usage_info=extra_usage_info, fault=fault)
1784 
1785     def _deallocate_network(self, context, instance,
1786                             requested_networks=None):
1787         # If we were told not to allocate networks let's save ourselves
1788         # the trouble of calling the network API.
1789         if requested_networks and requested_networks.no_allocate:
1790             LOG.debug("Skipping network deallocation for instance since "
1791                       "networking was not requested.", instance=instance)
1792             return
1793 
1794         LOG.debug('Deallocating network for instance', instance=instance)
1795         with timeutils.StopWatch() as timer:
1796             self.network_api.deallocate_for_instance(
1797                 context, instance, requested_networks=requested_networks)
1798         # nova-network does an rpc call so we're OK tracking time spent here
1799         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1800                  timer.elapsed(), instance=instance)
1801 
1802     def _get_instance_block_device_info(self, context, instance,
1803                                         refresh_conn_info=False,
1804                                         bdms=None):
1805         """Transform block devices to the driver block_device format."""
1806 
1807         if bdms is None:
1808             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1809                     context, instance.uuid)
1810         block_device_info = driver.get_block_device_info(instance, bdms)
1811 
1812         if not refresh_conn_info:
1813             # if the block_device_mapping has no value in connection_info
1814             # (returned as None), don't include in the mapping
1815             block_device_info['block_device_mapping'] = [
1816                 bdm for bdm in driver.block_device_info_get_mapping(
1817                                     block_device_info)
1818                 if bdm.get('connection_info')]
1819         else:
1820             driver_block_device.refresh_conn_infos(
1821                 driver.block_device_info_get_mapping(block_device_info),
1822                 context, instance, self.volume_api, self.driver)
1823 
1824         self._block_device_info_to_legacy(block_device_info)
1825 
1826         return block_device_info
1827 
1828     def _build_failed(self, node):
1829         if CONF.compute.consecutive_build_service_disable_threshold:
1830             # NOTE(danms): Update our counter, but wait for the next
1831             # update_available_resource() periodic to flush it to the DB
1832             self.rt.build_failed(node)
1833 
1834     def _build_succeeded(self, node):
1835         self.rt.build_succeeded(node)
1836 
1837     @wrap_exception()
1838     @reverts_task_state
1839     @wrap_instance_fault
1840     def build_and_run_instance(self, context, instance, image, request_spec,
1841                      filter_properties, admin_password=None,
1842                      injected_files=None, requested_networks=None,
1843                      security_groups=None, block_device_mapping=None,
1844                      node=None, limits=None, host_list=None):
1845 
1846         @utils.synchronized(instance.uuid)
1847         def _locked_do_build_and_run_instance(*args, **kwargs):
1848             # NOTE(danms): We grab the semaphore with the instance uuid
1849             # locked because we could wait in line to build this instance
1850             # for a while and we want to make sure that nothing else tries
1851             # to do anything with this instance while we wait.
1852             with self._build_semaphore:
1853                 try:
1854                     result = self._do_build_and_run_instance(*args, **kwargs)
1855                 except Exception:
1856                     # NOTE(mriedem): This should really only happen if
1857                     # _decode_files in _do_build_and_run_instance fails, and
1858                     # that's before a guest is spawned so it's OK to remove
1859                     # allocations for the instance for this node from Placement
1860                     # below as there is no guest consuming resources anyway.
1861                     # The _decode_files case could be handled more specifically
1862                     # but that's left for another day.
1863                     result = build_results.FAILED
1864                     raise
1865                 finally:
1866                     if result == build_results.FAILED:
1867                         # Remove the allocation records from Placement for the
1868                         # instance if the build failed. The instance.host is
1869                         # likely set to None in _do_build_and_run_instance
1870                         # which means if the user deletes the instance, it
1871                         # will be deleted in the API, not the compute service.
1872                         # Setting the instance.host to None in
1873                         # _do_build_and_run_instance means that the
1874                         # ResourceTracker will no longer consider this instance
1875                         # to be claiming resources against it, so we want to
1876                         # reflect that same thing in Placement.  No need to
1877                         # call this for a reschedule, as the allocations will
1878                         # have already been removed in
1879                         # self._do_build_and_run_instance().
1880                         self.reportclient.delete_allocation_for_instance(
1881                             context, instance.uuid)
1882 
1883                     if result in (build_results.FAILED,
1884                                   build_results.RESCHEDULED):
1885                         self._build_failed(node)
1886                     else:
1887                         self._build_succeeded(node)
1888 
1889         # NOTE(danms): We spawn here to return the RPC worker thread back to
1890         # the pool. Since what follows could take a really long time, we don't
1891         # want to tie up RPC workers.
1892         utils.spawn_n(_locked_do_build_and_run_instance,
1893                       context, instance, image, request_spec,
1894                       filter_properties, admin_password, injected_files,
1895                       requested_networks, security_groups,
1896                       block_device_mapping, node, limits, host_list)
1897 
1898     def _check_device_tagging(self, requested_networks, block_device_mapping):
1899         tagging_requested = False
1900         if requested_networks:
1901             for net in requested_networks:
1902                 if 'tag' in net and net.tag is not None:
1903                     tagging_requested = True
1904                     break
1905         if block_device_mapping and not tagging_requested:
1906             for bdm in block_device_mapping:
1907                 if 'tag' in bdm and bdm.tag is not None:
1908                     tagging_requested = True
1909                     break
1910         if (tagging_requested and
1911                 not self.driver.capabilities.get('supports_device_tagging',
1912                                                  False)):
1913             raise exception.BuildAbortException('Attempt to boot guest with '
1914                                                 'tagged devices on host that '
1915                                                 'does not support tagging.')
1916 
1917     def _check_trusted_certs(self, instance):
1918         if (instance.trusted_certs and
1919                 not self.driver.capabilities.get('supports_trusted_certs',
1920                                                  False)):
1921             raise exception.BuildAbortException(
1922                 'Trusted image certificates provided on host that does not '
1923                 'support certificate validation.')
1924 
1925     @hooks.add_hook('build_instance')
1926     @wrap_exception()
1927     @reverts_task_state
1928     @wrap_instance_event(prefix='compute')
1929     @wrap_instance_fault
1930     def _do_build_and_run_instance(self, context, instance, image,
1931             request_spec, filter_properties, admin_password, injected_files,
1932             requested_networks, security_groups, block_device_mapping,
1933             node=None, limits=None, host_list=None):
1934 
1935         try:
1936             LOG.debug('Starting instance...', instance=instance)
1937             instance.vm_state = vm_states.BUILDING
1938             instance.task_state = None
1939             instance.save(expected_task_state=
1940                     (task_states.SCHEDULING, None))
1941         except exception.InstanceNotFound:
1942             msg = 'Instance disappeared before build.'
1943             LOG.debug(msg, instance=instance)
1944             return build_results.FAILED
1945         except exception.UnexpectedTaskStateError as e:
1946             LOG.debug(e.format_message(), instance=instance)
1947             return build_results.FAILED
1948 
1949         # b64 decode the files to inject:
1950         decoded_files = self._decode_files(injected_files)
1951 
1952         if limits is None:
1953             limits = {}
1954 
1955         if node is None:
1956             node = self._get_nodename(instance, refresh=True)
1957 
1958         try:
1959             with timeutils.StopWatch() as timer:
1960                 self._build_and_run_instance(context, instance, image,
1961                         decoded_files, admin_password, requested_networks,
1962                         security_groups, block_device_mapping, node, limits,
1963                         filter_properties, request_spec)
1964             LOG.info('Took %0.2f seconds to build instance.',
1965                      timer.elapsed(), instance=instance)
1966             return build_results.ACTIVE
1967         except exception.RescheduledException as e:
1968             retry = filter_properties.get('retry')
1969             if not retry:
1970                 # no retry information, do not reschedule.
1971                 LOG.debug("Retry info not present, will not reschedule",
1972                     instance=instance)
1973                 self._cleanup_allocated_networks(context, instance,
1974                     requested_networks)
1975                 self._cleanup_volumes(context, instance,
1976                     block_device_mapping, raise_exc=False)
1977                 compute_utils.add_instance_fault_from_exc(context,
1978                         instance, e, sys.exc_info(),
1979                         fault_message=e.kwargs['reason'])
1980                 self._nil_out_instance_obj_host_and_node(instance)
1981                 self._set_instance_obj_error_state(context, instance,
1982                                                    clean_task_state=True)
1983                 return build_results.FAILED
1984             LOG.debug(e.format_message(), instance=instance)
1985             # This will be used for logging the exception
1986             retry['exc'] = traceback.format_exception(*sys.exc_info())
1987             # This will be used for setting the instance fault message
1988             retry['exc_reason'] = e.kwargs['reason']
1989             # NOTE(comstud): Deallocate networks if the driver wants
1990             # us to do so.
1991             # NOTE(mriedem): Always deallocate networking when using Neutron.
1992             # This is to unbind any ports that the user supplied in the server
1993             # create request, or delete any ports that nova created which were
1994             # meant to be bound to this host. This check intentionally bypasses
1995             # the result of deallocate_networks_on_reschedule because the
1996             # default value in the driver is False, but that method was really
1997             # only meant for Ironic and should be removed when nova-network is
1998             # removed (since is_neutron() will then always be True).
1999             # NOTE(vladikr): SR-IOV ports should be deallocated to
2000             # allow new sriov pci devices to be allocated on a new host.
2001             # Otherwise, if devices with pci addresses are already allocated
2002             # on the destination host, the instance will fail to spawn.
2003             # info_cache.network_info should be present at this stage.
2004             if (self.driver.deallocate_networks_on_reschedule(instance) or
2005                 utils.is_neutron() or
2006                 self.deallocate_sriov_ports_on_reschedule(instance)):
2007                 self._cleanup_allocated_networks(context, instance,
2008                         requested_networks)
2009             else:
2010                 # NOTE(alex_xu): Network already allocated and we don't
2011                 # want to deallocate them before rescheduling. But we need
2012                 # to cleanup those network resources setup on this host before
2013                 # rescheduling.
2014                 self.network_api.cleanup_instance_network_on_host(
2015                     context, instance, self.host)
2016 
2017             self._nil_out_instance_obj_host_and_node(instance)
2018             instance.task_state = task_states.SCHEDULING
2019             instance.save()
2020             # The instance will have already claimed resources from this host
2021             # before this build was attempted. Now that it has failed, we need
2022             # to unclaim those resources before casting to the conductor, so
2023             # that if there are alternate hosts available for a retry, it can
2024             # claim resources on that new host for the instance.
2025             self.reportclient.delete_allocation_for_instance(context,
2026                                                              instance.uuid)
2027 
2028             self.compute_task_api.build_instances(context, [instance],
2029                     image, filter_properties, admin_password,
2030                     injected_files, requested_networks, security_groups,
2031                     block_device_mapping, request_spec=request_spec,
2032                     host_lists=[host_list])
2033             return build_results.RESCHEDULED
2034         except (exception.InstanceNotFound,
2035                 exception.UnexpectedDeletingTaskStateError):
2036             msg = 'Instance disappeared during build.'
2037             LOG.debug(msg, instance=instance)
2038             self._cleanup_allocated_networks(context, instance,
2039                     requested_networks)
2040             return build_results.FAILED
2041         except Exception as e:
2042             if isinstance(e, exception.BuildAbortException):
2043                 LOG.error(e.format_message(), instance=instance)
2044             else:
2045                 # Should not reach here.
2046                 LOG.exception('Unexpected build failure, not rescheduling '
2047                               'build.', instance=instance)
2048             self._cleanup_allocated_networks(context, instance,
2049                     requested_networks)
2050             self._cleanup_volumes(context, instance,
2051                     block_device_mapping, raise_exc=False)
2052             compute_utils.add_instance_fault_from_exc(context, instance,
2053                     e, sys.exc_info())
2054             self._nil_out_instance_obj_host_and_node(instance)
2055             self._set_instance_obj_error_state(context, instance,
2056                                                clean_task_state=True)
2057             return build_results.FAILED
2058 
2059     def deallocate_sriov_ports_on_reschedule(self, instance):
2060         """Determine if networks are needed to be deallocated before reschedule
2061 
2062         Check the cached network info for any assigned SR-IOV ports.
2063         SR-IOV ports should be deallocated prior to rescheduling
2064         in order to allow new sriov pci devices to be allocated on a new host.
2065         """
2066         info_cache = instance.info_cache
2067 
2068         def _has_sriov_port(vif):
2069             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
2070 
2071         if (info_cache and info_cache.network_info):
2072             for vif in info_cache.network_info:
2073                 if _has_sriov_port(vif):
2074                     return True
2075         return False
2076 
2077     @staticmethod
2078     def _get_scheduler_hints(filter_properties, request_spec=None):
2079         """Helper method to get scheduler hints.
2080 
2081         This method prefers to get the hints out of the request spec, but that
2082         might not be provided. Conductor will pass request_spec down to the
2083         first compute chosen for a build but older computes will not pass
2084         the request_spec to conductor's build_instances method for a
2085         a reschedule, so if we're on a host via a retry, request_spec may not
2086         be provided so we need to fallback to use the filter_properties
2087         to get scheduler hints.
2088         """
2089         hints = {}
2090         if request_spec is not None and 'scheduler_hints' in request_spec:
2091             hints = request_spec.scheduler_hints
2092         if not hints:
2093             hints = filter_properties.get('scheduler_hints') or {}
2094         return hints
2095 
2096     @staticmethod
2097     def _get_request_group_mapping(request_spec):
2098         """Return request group resource - provider mapping. This is currently
2099         used for Neutron ports that have resource request due to the port
2100         having QoS minimum bandwidth policy rule attached.
2101 
2102         :param request_spec: A RequestSpec object
2103         :returns: A dict keyed by RequestGroup requester_id, currently Neutron
2104         port_id, to resource provider UUID that provides resource for that
2105         RequestGroup.
2106         """
2107 
2108         if (request_spec
2109                 and 'requested_resources' in request_spec
2110                 and request_spec.requested_resources is not None):
2111             return {
2112                 group.requester_id: group.provider_uuids
2113                 for group in request_spec.requested_resources
2114             }
2115         else:
2116             return None
2117 
2118     def _build_and_run_instance(self, context, instance, image, injected_files,
2119             admin_password, requested_networks, security_groups,
2120             block_device_mapping, node, limits, filter_properties,
2121             request_spec=None):
2122 
2123         image_name = image.get('name')
2124         self._notify_about_instance_usage(context, instance, 'create.start',
2125                 extra_usage_info={'image_name': image_name})
2126         compute_utils.notify_about_instance_create(
2127             context, instance, self.host,
2128             phase=fields.NotificationPhase.START,
2129             bdms=block_device_mapping)
2130 
2131         # NOTE(mikal): cache the keystone roles associated with the instance
2132         # at boot time for later reference
2133         instance.system_metadata.update(
2134             {'boot_roles': ','.join(context.roles)})
2135 
2136         self._check_device_tagging(requested_networks, block_device_mapping)
2137         self._check_trusted_certs(instance)
2138 
2139         try:
2140             scheduler_hints = self._get_scheduler_hints(filter_properties,
2141                                                         request_spec)
2142             with self.rt.instance_claim(context, instance, node, limits):
2143                 # NOTE(russellb) It's important that this validation be done
2144                 # *after* the resource tracker instance claim, as that is where
2145                 # the host is set on the instance.
2146                 self._validate_instance_group_policy(context, instance,
2147                                                      scheduler_hints)
2148                 image_meta = objects.ImageMeta.from_dict(image)
2149 
2150                 request_group_resource_providers_mapping = \
2151                     self._get_request_group_mapping(request_spec)
2152 
2153                 with self._build_resources(context, instance,
2154                         requested_networks, security_groups, image_meta,
2155                         block_device_mapping,
2156                         request_group_resource_providers_mapping) as resources:
2157                     instance.vm_state = vm_states.BUILDING
2158                     instance.task_state = task_states.SPAWNING
2159                     # NOTE(JoshNang) This also saves the changes to the
2160                     # instance from _allocate_network_async, as they aren't
2161                     # saved in that function to prevent races.
2162                     instance.save(expected_task_state=
2163                             task_states.BLOCK_DEVICE_MAPPING)
2164                     block_device_info = resources['block_device_info']
2165                     network_info = resources['network_info']
2166                     allocs = resources['allocations']
2167                     LOG.debug('Start spawning the instance on the hypervisor.',
2168                               instance=instance)
2169                     with timeutils.StopWatch() as timer:
2170                         self.driver.spawn(context, instance, image_meta,
2171                                           injected_files, admin_password,
2172                                           allocs, network_info=network_info,
2173                                           block_device_info=block_device_info)
2174                     LOG.info('Took %0.2f seconds to spawn the instance on '
2175                              'the hypervisor.', timer.elapsed(),
2176                              instance=instance)
2177         except (exception.InstanceNotFound,
2178                 exception.UnexpectedDeletingTaskStateError) as e:
2179             with excutils.save_and_reraise_exception():
2180                 self._notify_about_instance_usage(context, instance,
2181                     'create.error', fault=e)
2182                 tb = traceback.format_exc()
2183                 compute_utils.notify_about_instance_create(
2184                     context, instance, self.host,
2185                     phase=fields.NotificationPhase.ERROR, exception=e,
2186                     bdms=block_device_mapping, tb=tb)
2187         except exception.ComputeResourcesUnavailable as e:
2188             LOG.debug(e.format_message(), instance=instance)
2189             self._notify_about_instance_usage(context, instance,
2190                     'create.error', fault=e)
2191             tb = traceback.format_exc()
2192             compute_utils.notify_about_instance_create(
2193                     context, instance, self.host,
2194                     phase=fields.NotificationPhase.ERROR, exception=e,
2195                     bdms=block_device_mapping, tb=tb)
2196             raise exception.RescheduledException(
2197                     instance_uuid=instance.uuid, reason=e.format_message())
2198         except exception.BuildAbortException as e:
2199             with excutils.save_and_reraise_exception():
2200                 LOG.debug(e.format_message(), instance=instance)
2201                 self._notify_about_instance_usage(context, instance,
2202                     'create.error', fault=e)
2203                 tb = traceback.format_exc()
2204                 compute_utils.notify_about_instance_create(
2205                     context, instance, self.host,
2206                     phase=fields.NotificationPhase.ERROR, exception=e,
2207                     bdms=block_device_mapping, tb=tb)
2208         except (exception.FixedIpLimitExceeded,
2209                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2210             LOG.warning('No more network or fixed IP to be allocated',
2211                         instance=instance)
2212             self._notify_about_instance_usage(context, instance,
2213                     'create.error', fault=e)
2214             tb = traceback.format_exc()
2215             compute_utils.notify_about_instance_create(
2216                     context, instance, self.host,
2217                     phase=fields.NotificationPhase.ERROR, exception=e,
2218                     bdms=block_device_mapping, tb=tb)
2219             msg = _('Failed to allocate the network(s) with error %s, '
2220                     'not rescheduling.') % e.format_message()
2221             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2222                     reason=msg)
2223         except (exception.VirtualInterfaceCreateException,
2224                 exception.VirtualInterfaceMacAddressException,
2225                 exception.FixedIpInvalidOnHost,
2226                 exception.UnableToAutoAllocateNetwork,
2227                 exception.NetworksWithQoSPolicyNotSupported) as e:
2228             LOG.exception('Failed to allocate network(s)',
2229                           instance=instance)
2230             self._notify_about_instance_usage(context, instance,
2231                     'create.error', fault=e)
2232             tb = traceback.format_exc()
2233             compute_utils.notify_about_instance_create(
2234                     context, instance, self.host,
2235                     phase=fields.NotificationPhase.ERROR, exception=e,
2236                     bdms=block_device_mapping, tb=tb)
2237             msg = _('Failed to allocate the network(s), not rescheduling.')
2238             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2239                     reason=msg)
2240         except (exception.FlavorDiskTooSmall,
2241                 exception.FlavorMemoryTooSmall,
2242                 exception.ImageNotActive,
2243                 exception.ImageUnacceptable,
2244                 exception.InvalidDiskInfo,
2245                 exception.InvalidDiskFormat,
2246                 cursive_exception.SignatureVerificationError,
2247                 exception.CertificateValidationFailed,
2248                 exception.VolumeEncryptionNotSupported,
2249                 exception.InvalidInput,
2250                 # TODO(mriedem): We should be validating RequestedVRamTooHigh
2251                 # in the API during server create and rebuild.
2252                 exception.RequestedVRamTooHigh) as e:
2253             self._notify_about_instance_usage(context, instance,
2254                     'create.error', fault=e)
2255             tb = traceback.format_exc()
2256             compute_utils.notify_about_instance_create(
2257                     context, instance, self.host,
2258                     phase=fields.NotificationPhase.ERROR, exception=e,
2259                     bdms=block_device_mapping, tb=tb)
2260             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2261                     reason=e.format_message())
2262         except Exception as e:
2263             self._notify_about_instance_usage(context, instance,
2264                     'create.error', fault=e)
2265             tb = traceback.format_exc()
2266             compute_utils.notify_about_instance_create(
2267                     context, instance, self.host,
2268                     phase=fields.NotificationPhase.ERROR, exception=e,
2269                     bdms=block_device_mapping, tb=tb)
2270             raise exception.RescheduledException(
2271                     instance_uuid=instance.uuid, reason=six.text_type(e))
2272 
2273         # NOTE(alaski): This is only useful during reschedules, remove it now.
2274         instance.system_metadata.pop('network_allocated', None)
2275 
2276         # If CONF.default_access_ip_network_name is set, grab the
2277         # corresponding network and set the access ip values accordingly.
2278         network_name = CONF.default_access_ip_network_name
2279         if (network_name and not instance.access_ip_v4 and
2280                 not instance.access_ip_v6):
2281             # Note that when there are multiple ips to choose from, an
2282             # arbitrary one will be chosen.
2283             for vif in network_info:
2284                 if vif['network']['label'] == network_name:
2285                     for ip in vif.fixed_ips():
2286                         if not instance.access_ip_v4 and ip['version'] == 4:
2287                             instance.access_ip_v4 = ip['address']
2288                         if not instance.access_ip_v6 and ip['version'] == 6:
2289                             instance.access_ip_v6 = ip['address']
2290                     break
2291 
2292         self._update_instance_after_spawn(context, instance)
2293 
2294         try:
2295             instance.save(expected_task_state=task_states.SPAWNING)
2296         except (exception.InstanceNotFound,
2297                 exception.UnexpectedDeletingTaskStateError) as e:
2298             with excutils.save_and_reraise_exception():
2299                 self._notify_about_instance_usage(context, instance,
2300                     'create.error', fault=e)
2301                 tb = traceback.format_exc()
2302                 compute_utils.notify_about_instance_create(
2303                     context, instance, self.host,
2304                     phase=fields.NotificationPhase.ERROR, exception=e,
2305                     bdms=block_device_mapping, tb=tb)
2306 
2307         self._update_scheduler_instance_info(context, instance)
2308         self._notify_about_instance_usage(context, instance, 'create.end',
2309                 extra_usage_info={'message': _('Success')},
2310                 network_info=network_info)
2311         compute_utils.notify_about_instance_create(context, instance,
2312                 self.host, phase=fields.NotificationPhase.END,
2313                 bdms=block_device_mapping)
2314 
2315     @contextlib.contextmanager
2316     def _build_resources(self, context, instance, requested_networks,
2317                          security_groups, image_meta, block_device_mapping,
2318                          resource_provider_mapping):
2319         resources = {}
2320         network_info = None
2321         try:
2322             LOG.debug('Start building networks asynchronously for instance.',
2323                       instance=instance)
2324             network_info = self._build_networks_for_instance(context, instance,
2325                     requested_networks, security_groups,
2326                     resource_provider_mapping)
2327             resources['network_info'] = network_info
2328         except (exception.InstanceNotFound,
2329                 exception.UnexpectedDeletingTaskStateError):
2330             raise
2331         except exception.UnexpectedTaskStateError as e:
2332             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2333                     reason=e.format_message())
2334         except Exception:
2335             # Because this allocation is async any failures are likely to occur
2336             # when the driver accesses network_info during spawn().
2337             LOG.exception('Failed to allocate network(s)',
2338                           instance=instance)
2339             msg = _('Failed to allocate the network(s), not rescheduling.')
2340             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2341                     reason=msg)
2342 
2343         try:
2344             # Perform any driver preparation work for the driver.
2345             self.driver.prepare_for_spawn(instance)
2346 
2347             # Depending on a virt driver, some network configuration is
2348             # necessary before preparing block devices.
2349             self.driver.prepare_networks_before_block_device_mapping(
2350                 instance, network_info)
2351 
2352             # Verify that all the BDMs have a device_name set and assign a
2353             # default to the ones missing it with the help of the driver.
2354             self._default_block_device_names(instance, image_meta,
2355                                              block_device_mapping)
2356 
2357             LOG.debug('Start building block device mappings for instance.',
2358                       instance=instance)
2359             instance.vm_state = vm_states.BUILDING
2360             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2361             instance.save()
2362 
2363             block_device_info = self._prep_block_device(context, instance,
2364                     block_device_mapping)
2365             resources['block_device_info'] = block_device_info
2366         except (exception.InstanceNotFound,
2367                 exception.UnexpectedDeletingTaskStateError):
2368             with excutils.save_and_reraise_exception():
2369                 # Make sure the async call finishes
2370                 if network_info is not None:
2371                     network_info.wait(do_raise=False)
2372                     self.driver.clean_networks_preparation(instance,
2373                                                            network_info)
2374                 self.driver.failed_spawn_cleanup(instance)
2375         except (exception.UnexpectedTaskStateError,
2376                 exception.OverQuota, exception.InvalidBDM) as e:
2377             # Make sure the async call finishes
2378             if network_info is not None:
2379                 network_info.wait(do_raise=False)
2380                 self.driver.clean_networks_preparation(instance, network_info)
2381             self.driver.failed_spawn_cleanup(instance)
2382             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2383                     reason=e.format_message())
2384         except Exception:
2385             LOG.exception('Failure prepping block device',
2386                           instance=instance)
2387             # Make sure the async call finishes
2388             if network_info is not None:
2389                 network_info.wait(do_raise=False)
2390                 self.driver.clean_networks_preparation(instance, network_info)
2391             self.driver.failed_spawn_cleanup(instance)
2392             msg = _('Failure prepping block device.')
2393             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2394                     reason=msg)
2395 
2396         try:
2397             resources['allocations'] = (
2398                 self.reportclient.get_allocations_for_consumer(context,
2399                                                                instance.uuid))
2400         except Exception:
2401             LOG.exception('Failure retrieving placement allocations',
2402                           instance=instance)
2403             # Make sure the async call finishes
2404             if network_info is not None:
2405                 network_info.wait(do_raise=False)
2406             self.driver.failed_spawn_cleanup(instance)
2407             msg = _('Failure retrieving placement allocations')
2408             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2409                                                 reason=msg)
2410 
2411         try:
2412             yield resources
2413         except Exception as exc:
2414             with excutils.save_and_reraise_exception() as ctxt:
2415                 if not isinstance(exc, (
2416                         exception.InstanceNotFound,
2417                         exception.UnexpectedDeletingTaskStateError)):
2418                     LOG.exception('Instance failed to spawn',
2419                                   instance=instance)
2420                 # Make sure the async call finishes
2421                 if network_info is not None:
2422                     network_info.wait(do_raise=False)
2423                 # if network_info is empty we're likely here because of
2424                 # network allocation failure. Since nothing can be reused on
2425                 # rescheduling it's better to deallocate network to eliminate
2426                 # the chance of orphaned ports in neutron
2427                 deallocate_networks = False if network_info else True
2428                 try:
2429                     self._shutdown_instance(context, instance,
2430                             block_device_mapping, requested_networks,
2431                             try_deallocate_networks=deallocate_networks)
2432                 except Exception as exc2:
2433                     ctxt.reraise = False
2434                     LOG.warning('Could not clean up failed build,'
2435                                 ' not rescheduling. Error: %s',
2436                                 six.text_type(exc2))
2437                     raise exception.BuildAbortException(
2438                             instance_uuid=instance.uuid,
2439                             reason=six.text_type(exc))
2440 
2441     def _cleanup_allocated_networks(self, context, instance,
2442             requested_networks):
2443         try:
2444             self._deallocate_network(context, instance, requested_networks)
2445         except Exception:
2446             LOG.exception('Failed to deallocate networks', instance=instance)
2447             return
2448 
2449         instance.system_metadata['network_allocated'] = 'False'
2450         try:
2451             instance.save()
2452         except exception.InstanceNotFound:
2453             # NOTE(alaski): It's possible that we're cleaning up the networks
2454             # because the instance was deleted.  If that's the case then this
2455             # exception will be raised by instance.save()
2456             pass
2457 
2458     def _try_deallocate_network(self, context, instance,
2459                                 requested_networks=None):
2460 
2461         # During auto-scale cleanup, we could be deleting a large number
2462         # of servers at the same time and overloading parts of the system,
2463         # so we retry a few times in case of connection failures to the
2464         # networking service.
2465         @loopingcall.RetryDecorator(
2466             max_retry_count=3, inc_sleep_time=2, max_sleep_time=12,
2467             exceptions=(keystone_exception.connection.ConnectFailure,))
2468         def _deallocate_network_with_retries():
2469             try:
2470                 self._deallocate_network(
2471                     context, instance, requested_networks)
2472             except keystone_exception.connection.ConnectFailure as e:
2473                 # Provide a warning that something is amiss.
2474                 with excutils.save_and_reraise_exception():
2475                     LOG.warning('Failed to deallocate network for instance; '
2476                                 'retrying. Error: %s', six.text_type(e),
2477                                 instance=instance)
2478 
2479         try:
2480             # tear down allocated network structure
2481             _deallocate_network_with_retries()
2482         except Exception as ex:
2483             with excutils.save_and_reraise_exception():
2484                 LOG.error('Failed to deallocate network for instance. '
2485                           'Error: %s', ex, instance=instance)
2486                 self._set_instance_obj_error_state(context, instance)
2487 
2488     def _get_power_off_values(self, context, instance, clean_shutdown):
2489         """Get the timing configuration for powering down this instance."""
2490         if clean_shutdown:
2491             timeout = compute_utils.get_value_from_system_metadata(instance,
2492                           key='image_os_shutdown_timeout', type=int,
2493                           default=CONF.shutdown_timeout)
2494             retry_interval = CONF.compute.shutdown_retry_interval
2495         else:
2496             timeout = 0
2497             retry_interval = 0
2498 
2499         return timeout, retry_interval
2500 
2501     def _power_off_instance(self, context, instance, clean_shutdown=True):
2502         """Power off an instance on this host."""
2503         timeout, retry_interval = self._get_power_off_values(context,
2504                                         instance, clean_shutdown)
2505         self.driver.power_off(instance, timeout, retry_interval)
2506 
2507     def _shutdown_instance(self, context, instance,
2508                            bdms, requested_networks=None, notify=True,
2509                            try_deallocate_networks=True):
2510         """Shutdown an instance on this host.
2511 
2512         :param:context: security context
2513         :param:instance: a nova.objects.Instance object
2514         :param:bdms: the block devices for the instance to be torn
2515                      down
2516         :param:requested_networks: the networks on which the instance
2517                                    has ports
2518         :param:notify: true if a final usage notification should be
2519                        emitted
2520         :param:try_deallocate_networks: false if we should avoid
2521                                         trying to teardown networking
2522         """
2523         context = context.elevated()
2524         LOG.info('Terminating instance', instance=instance)
2525 
2526         if notify:
2527             self._notify_about_instance_usage(context, instance,
2528                                               "shutdown.start")
2529             compute_utils.notify_about_instance_action(context, instance,
2530                     self.host, action=fields.NotificationAction.SHUTDOWN,
2531                     phase=fields.NotificationPhase.START, bdms=bdms)
2532 
2533         network_info = instance.get_network_info()
2534 
2535         # NOTE(vish) get bdms before destroying the instance
2536         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2537         block_device_info = self._get_instance_block_device_info(
2538             context, instance, bdms=bdms)
2539 
2540         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2541         #                want to keep ip allocated for certain failures
2542         try:
2543             LOG.debug('Start destroying the instance on the hypervisor.',
2544                       instance=instance)
2545             with timeutils.StopWatch() as timer:
2546                 self.driver.destroy(context, instance, network_info,
2547                                     block_device_info)
2548             LOG.info('Took %0.2f seconds to destroy the instance on the '
2549                      'hypervisor.', timer.elapsed(), instance=instance)
2550         except exception.InstancePowerOffFailure:
2551             # if the instance can't power off, don't release the ip
2552             with excutils.save_and_reraise_exception():
2553                 pass
2554         except Exception:
2555             with excutils.save_and_reraise_exception():
2556                 # deallocate ip and fail without proceeding to
2557                 # volume api calls, preserving current behavior
2558                 if try_deallocate_networks:
2559                     self._try_deallocate_network(context, instance,
2560                                                  requested_networks)
2561 
2562         if try_deallocate_networks:
2563             self._try_deallocate_network(context, instance, requested_networks)
2564 
2565         timer.restart()
2566         for bdm in vol_bdms:
2567             try:
2568                 if bdm.attachment_id:
2569                     self.volume_api.attachment_delete(context,
2570                                                       bdm.attachment_id)
2571                 else:
2572                     # NOTE(vish): actual driver detach done in driver.destroy,
2573                     #             so just tell cinder that we are done with it.
2574                     connector = self.driver.get_volume_connector(instance)
2575                     self.volume_api.terminate_connection(context,
2576                                                          bdm.volume_id,
2577                                                          connector)
2578                     self.volume_api.detach(context, bdm.volume_id,
2579                                            instance.uuid)
2580 
2581             except exception.VolumeAttachmentNotFound as exc:
2582                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2583                           instance=instance)
2584             except exception.DiskNotFound as exc:
2585                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2586                           instance=instance)
2587             except exception.VolumeNotFound as exc:
2588                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2589                           instance=instance)
2590             except (cinder_exception.EndpointNotFound,
2591                     keystone_exception.EndpointNotFound) as exc:
2592                 LOG.warning('Ignoring EndpointNotFound for '
2593                             'volume %(volume_id)s: %(exc)s',
2594                             {'exc': exc, 'volume_id': bdm.volume_id},
2595                             instance=instance)
2596             except cinder_exception.ClientException as exc:
2597                 LOG.warning('Ignoring unknown cinder exception for '
2598                             'volume %(volume_id)s: %(exc)s',
2599                             {'exc': exc, 'volume_id': bdm.volume_id},
2600                             instance=instance)
2601             except Exception as exc:
2602                 LOG.warning('Ignoring unknown exception for '
2603                             'volume %(volume_id)s: %(exc)s',
2604                             {'exc': exc, 'volume_id': bdm.volume_id},
2605                             instance=instance)
2606         if vol_bdms:
2607             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2608                      'for instance.',
2609                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2610                      instance=instance)
2611 
2612         if notify:
2613             self._notify_about_instance_usage(context, instance,
2614                                               "shutdown.end")
2615             compute_utils.notify_about_instance_action(context, instance,
2616                     self.host, action=fields.NotificationAction.SHUTDOWN,
2617                     phase=fields.NotificationPhase.END, bdms=bdms)
2618 
2619     def _cleanup_volumes(self, context, instance, bdms, raise_exc=True,
2620                          detach=True):
2621         exc_info = None
2622         for bdm in bdms:
2623             if detach and bdm.volume_id:
2624                 try:
2625                     LOG.debug("Detaching volume: %s", bdm.volume_id,
2626                               instance_uuid=instance.uuid)
2627                     destroy = bdm.delete_on_termination
2628                     self._detach_volume(context, bdm, instance,
2629                                         destroy_bdm=destroy)
2630                 except Exception as exc:
2631                     exc_info = sys.exc_info()
2632                     LOG.warning('Failed to detach volume: %(volume_id)s '
2633                                 'due to %(exc)s',
2634                                 {'volume_id': bdm.volume_id, 'exc': exc})
2635 
2636             if bdm.volume_id and bdm.delete_on_termination:
2637                 try:
2638                     LOG.debug("Deleting volume: %s", bdm.volume_id,
2639                               instance_uuid=instance.uuid)
2640                     self.volume_api.delete(context, bdm.volume_id)
2641                 except Exception as exc:
2642                     exc_info = sys.exc_info()
2643                     LOG.warning('Failed to delete volume: %(volume_id)s '
2644                                 'due to %(exc)s',
2645                                 {'volume_id': bdm.volume_id, 'exc': exc})
2646         if exc_info is not None and raise_exc:
2647             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2648 
2649     @hooks.add_hook("delete_instance")
2650     def _delete_instance(self, context, instance, bdms):
2651         """Delete an instance on this host.
2652 
2653         :param context: nova request context
2654         :param instance: nova.objects.instance.Instance object
2655         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2656         """
2657         events = self.instance_events.clear_events_for_instance(instance)
2658         if events:
2659             LOG.debug('Events pending at deletion: %(events)s',
2660                       {'events': ','.join(events.keys())},
2661                       instance=instance)
2662         self._notify_about_instance_usage(context, instance,
2663                                           "delete.start")
2664         compute_utils.notify_about_instance_action(context, instance,
2665                 self.host, action=fields.NotificationAction.DELETE,
2666                 phase=fields.NotificationPhase.START, bdms=bdms)
2667 
2668         self._shutdown_instance(context, instance, bdms)
2669 
2670         # NOTE(vish): We have already deleted the instance, so we have
2671         #             to ignore problems cleaning up the volumes. It
2672         #             would be nice to let the user know somehow that
2673         #             the volume deletion failed, but it is not
2674         #             acceptable to have an instance that can not be
2675         #             deleted. Perhaps this could be reworked in the
2676         #             future to set an instance fault the first time
2677         #             and to only ignore the failure if the instance
2678         #             is already in ERROR.
2679 
2680         # NOTE(ameeda): The volumes already detached during the above
2681         #               _shutdown_instance() call and this is why
2682         #               detach is not requested from _cleanup_volumes()
2683         #               in this case
2684 
2685         self._cleanup_volumes(context, instance, bdms,
2686                 raise_exc=False, detach=False)
2687         # if a delete task succeeded, always update vm state and task
2688         # state without expecting task state to be DELETING
2689         instance.vm_state = vm_states.DELETED
2690         instance.task_state = None
2691         instance.power_state = power_state.NOSTATE
2692         instance.terminated_at = timeutils.utcnow()
2693         instance.save()
2694 
2695         self._complete_deletion(context, instance)
2696         # only destroy the instance in the db if the _complete_deletion
2697         # doesn't raise and therefore allocation is successfully
2698         # deleted in placement
2699         instance.destroy()
2700 
2701         self._notify_about_instance_usage(context, instance, "delete.end")
2702         compute_utils.notify_about_instance_action(context, instance,
2703                 self.host, action=fields.NotificationAction.DELETE,
2704                 phase=fields.NotificationPhase.END, bdms=bdms)
2705 
2706     @wrap_exception()
2707     @reverts_task_state
2708     @wrap_instance_event(prefix='compute')
2709     @wrap_instance_fault
2710     def terminate_instance(self, context, instance, bdms):
2711         """Terminate an instance on this host."""
2712         @utils.synchronized(instance.uuid)
2713         def do_terminate_instance(instance, bdms):
2714             # NOTE(mriedem): If we are deleting the instance while it was
2715             # booting from volume, we could be racing with a database update of
2716             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2717             # to compute here, the BDMs may be stale at this point. So check
2718             # for any volume BDMs that don't have volume_id set and if we
2719             # detect that, we need to refresh the BDM list before proceeding.
2720             # TODO(mriedem): Move this into _delete_instance and make the bdms
2721             # parameter optional.
2722             for bdm in list(bdms):
2723                 if bdm.is_volume and not bdm.volume_id:
2724                     LOG.debug('There are potentially stale BDMs during '
2725                               'delete, refreshing the BlockDeviceMappingList.',
2726                               instance=instance)
2727                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2728                         context, instance.uuid)
2729                     break
2730             try:
2731                 self._delete_instance(context, instance, bdms)
2732             except exception.InstanceNotFound:
2733                 LOG.info("Instance disappeared during terminate",
2734                          instance=instance)
2735             except Exception:
2736                 # As we're trying to delete always go to Error if something
2737                 # goes wrong that _delete_instance can't handle.
2738                 with excutils.save_and_reraise_exception():
2739                     LOG.exception('Setting instance vm_state to ERROR',
2740                                   instance=instance)
2741                     self._set_instance_obj_error_state(context, instance)
2742 
2743         do_terminate_instance(instance, bdms)
2744 
2745     # NOTE(johannes): This is probably better named power_off_instance
2746     # so it matches the driver method, but because of other issues, we
2747     # can't use that name in grizzly.
2748     @wrap_exception()
2749     @reverts_task_state
2750     @wrap_instance_event(prefix='compute')
2751     @wrap_instance_fault
2752     def stop_instance(self, context, instance, clean_shutdown):
2753         """Stopping an instance on this host."""
2754 
2755         @utils.synchronized(instance.uuid)
2756         def do_stop_instance():
2757             current_power_state = self._get_power_state(context, instance)
2758             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2759                       'current task_state: %(task_state)s, current DB '
2760                       'power_state: %(db_power_state)s, current VM '
2761                       'power_state: %(current_power_state)s',
2762                       {'vm_state': instance.vm_state,
2763                        'task_state': instance.task_state,
2764                        'db_power_state': instance.power_state,
2765                        'current_power_state': current_power_state},
2766                       instance_uuid=instance.uuid)
2767 
2768             # NOTE(mriedem): If the instance is already powered off, we are
2769             # possibly tearing down and racing with other operations, so we can
2770             # expect the task_state to be None if something else updates the
2771             # instance and we're not locking it.
2772             expected_task_state = [task_states.POWERING_OFF]
2773             # The list of power states is from _sync_instance_power_state.
2774             if current_power_state in (power_state.NOSTATE,
2775                                        power_state.SHUTDOWN,
2776                                        power_state.CRASHED):
2777                 LOG.info('Instance is already powered off in the '
2778                          'hypervisor when stop is called.',
2779                          instance=instance)
2780                 expected_task_state.append(None)
2781 
2782             self._notify_about_instance_usage(context, instance,
2783                                               "power_off.start")
2784 
2785             compute_utils.notify_about_instance_action(context, instance,
2786                         self.host, action=fields.NotificationAction.POWER_OFF,
2787                         phase=fields.NotificationPhase.START)
2788 
2789             self._power_off_instance(context, instance, clean_shutdown)
2790             instance.power_state = self._get_power_state(context, instance)
2791             instance.vm_state = vm_states.STOPPED
2792             instance.task_state = None
2793             instance.save(expected_task_state=expected_task_state)
2794             self._notify_about_instance_usage(context, instance,
2795                                               "power_off.end")
2796 
2797             compute_utils.notify_about_instance_action(context, instance,
2798                         self.host, action=fields.NotificationAction.POWER_OFF,
2799                         phase=fields.NotificationPhase.END)
2800 
2801         do_stop_instance()
2802 
2803     def _power_on(self, context, instance):
2804         network_info = self.network_api.get_instance_nw_info(context, instance)
2805         block_device_info = self._get_instance_block_device_info(context,
2806                                                                  instance)
2807         self.driver.power_on(context, instance,
2808                              network_info,
2809                              block_device_info)
2810 
2811     def _delete_snapshot_of_shelved_instance(self, context, instance,
2812                                              snapshot_id):
2813         """Delete snapshot of shelved instance."""
2814         try:
2815             self.image_api.delete(context, snapshot_id)
2816         except (exception.ImageNotFound,
2817                 exception.ImageNotAuthorized) as exc:
2818             LOG.warning("Failed to delete snapshot "
2819                         "from shelved instance (%s).",
2820                         exc.format_message(), instance=instance)
2821         except Exception:
2822             LOG.exception("Something wrong happened when trying to "
2823                           "delete snapshot from shelved instance.",
2824                           instance=instance)
2825 
2826     # NOTE(johannes): This is probably better named power_on_instance
2827     # so it matches the driver method, but because of other issues, we
2828     # can't use that name in grizzly.
2829     @wrap_exception()
2830     @reverts_task_state
2831     @wrap_instance_event(prefix='compute')
2832     @wrap_instance_fault
2833     def start_instance(self, context, instance):
2834         """Starting an instance on this host."""
2835         self._notify_about_instance_usage(context, instance, "power_on.start")
2836         compute_utils.notify_about_instance_action(context, instance,
2837             self.host, action=fields.NotificationAction.POWER_ON,
2838             phase=fields.NotificationPhase.START)
2839         self._power_on(context, instance)
2840         instance.power_state = self._get_power_state(context, instance)
2841         instance.vm_state = vm_states.ACTIVE
2842         instance.task_state = None
2843 
2844         # Delete an image(VM snapshot) for a shelved instance
2845         snapshot_id = instance.system_metadata.get('shelved_image_id')
2846         if snapshot_id:
2847             self._delete_snapshot_of_shelved_instance(context, instance,
2848                                                       snapshot_id)
2849 
2850         # Delete system_metadata for a shelved instance
2851         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2852 
2853         instance.save(expected_task_state=task_states.POWERING_ON)
2854         self._notify_about_instance_usage(context, instance, "power_on.end")
2855         compute_utils.notify_about_instance_action(context, instance,
2856             self.host, action=fields.NotificationAction.POWER_ON,
2857             phase=fields.NotificationPhase.END)
2858 
2859     @messaging.expected_exceptions(NotImplementedError,
2860                                    exception.TriggerCrashDumpNotSupported,
2861                                    exception.InstanceNotRunning)
2862     @wrap_exception()
2863     @wrap_instance_event(prefix='compute')
2864     @wrap_instance_fault
2865     def trigger_crash_dump(self, context, instance):
2866         """Trigger crash dump in an instance."""
2867 
2868         self._notify_about_instance_usage(context, instance,
2869                                           "trigger_crash_dump.start")
2870         compute_utils.notify_about_instance_action(context, instance,
2871                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2872                 phase=fields.NotificationPhase.START)
2873 
2874         # This method does not change task_state and power_state because the
2875         # effect of a trigger depends on user's configuration.
2876         self.driver.trigger_crash_dump(instance)
2877 
2878         self._notify_about_instance_usage(context, instance,
2879                                           "trigger_crash_dump.end")
2880         compute_utils.notify_about_instance_action(context, instance,
2881                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2882                 phase=fields.NotificationPhase.END)
2883 
2884     @wrap_exception()
2885     @reverts_task_state
2886     @wrap_instance_event(prefix='compute')
2887     @wrap_instance_fault
2888     def soft_delete_instance(self, context, instance):
2889         """Soft delete an instance on this host."""
2890         with compute_utils.notify_about_instance_delete(
2891                 self.notifier, context, instance, 'soft_delete',
2892                 source=fields.NotificationSource.COMPUTE):
2893             try:
2894                 self.driver.soft_delete(instance)
2895             except NotImplementedError:
2896                 # Fallback to just powering off the instance if the
2897                 # hypervisor doesn't implement the soft_delete method
2898                 self.driver.power_off(instance)
2899             instance.power_state = self._get_power_state(context, instance)
2900             instance.vm_state = vm_states.SOFT_DELETED
2901             instance.task_state = None
2902             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2903 
2904     @wrap_exception()
2905     @reverts_task_state
2906     @wrap_instance_event(prefix='compute')
2907     @wrap_instance_fault
2908     def restore_instance(self, context, instance):
2909         """Restore a soft-deleted instance on this host."""
2910         self._notify_about_instance_usage(context, instance, "restore.start")
2911         compute_utils.notify_about_instance_action(context, instance,
2912             self.host, action=fields.NotificationAction.RESTORE,
2913             phase=fields.NotificationPhase.START)
2914         try:
2915             self.driver.restore(instance)
2916         except NotImplementedError:
2917             # Fallback to just powering on the instance if the hypervisor
2918             # doesn't implement the restore method
2919             self._power_on(context, instance)
2920         instance.power_state = self._get_power_state(context, instance)
2921         instance.vm_state = vm_states.ACTIVE
2922         instance.task_state = None
2923         instance.save(expected_task_state=task_states.RESTORING)
2924         self._notify_about_instance_usage(context, instance, "restore.end")
2925         compute_utils.notify_about_instance_action(context, instance,
2926             self.host, action=fields.NotificationAction.RESTORE,
2927             phase=fields.NotificationPhase.END)
2928 
2929     @staticmethod
2930     def _set_migration_status(migration, status):
2931         """Set the status, and guard against a None being passed in.
2932 
2933         This is useful as some of the compute RPC calls will not pass
2934         a migration object in older versions. The check can be removed when
2935         we move past 4.x major version of the RPC API.
2936         """
2937         if migration:
2938             migration.status = status
2939             migration.save()
2940 
2941     def _rebuild_default_impl(self, context, instance, image_meta,
2942                               injected_files, admin_password, allocations,
2943                               bdms, detach_block_devices, attach_block_devices,
2944                               network_info=None,
2945                               evacuate=False, block_device_info=None,
2946                               preserve_ephemeral=False):
2947         if preserve_ephemeral:
2948             # The default code path does not support preserving ephemeral
2949             # partitions.
2950             raise exception.PreserveEphemeralNotSupported()
2951 
2952         if evacuate:
2953             detach_block_devices(context, bdms)
2954         else:
2955             self._power_off_instance(context, instance, clean_shutdown=True)
2956             detach_block_devices(context, bdms)
2957             self.driver.destroy(context, instance,
2958                                 network_info=network_info,
2959                                 block_device_info=block_device_info)
2960 
2961         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2962         instance.save(expected_task_state=[task_states.REBUILDING])
2963 
2964         new_block_device_info = attach_block_devices(context, instance, bdms)
2965 
2966         instance.task_state = task_states.REBUILD_SPAWNING
2967         instance.save(
2968             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2969 
2970         with instance.mutated_migration_context():
2971             self.driver.spawn(context, instance, image_meta, injected_files,
2972                               admin_password, allocations,
2973                               network_info=network_info,
2974                               block_device_info=new_block_device_info)
2975 
2976     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
2977         tb = traceback.format_exc()
2978         self._notify_about_instance_usage(context, instance,
2979                                           'rebuild.error', fault=error)
2980         compute_utils.notify_about_instance_rebuild(
2981             context, instance, self.host,
2982             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms,
2983             tb=tb)
2984 
2985     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2986     @wrap_exception()
2987     @reverts_task_state
2988     @wrap_instance_event(prefix='compute')
2989     @wrap_instance_fault
2990     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2991                          injected_files, new_pass, orig_sys_metadata,
2992                          bdms, recreate, on_shared_storage,
2993                          preserve_ephemeral, migration,
2994                          scheduled_node, limits, request_spec):
2995         """Destroy and re-make this instance.
2996 
2997         A 'rebuild' effectively purges all existing data from the system and
2998         remakes the VM with given 'metadata' and 'personalities'.
2999 
3000         :param context: `nova.RequestContext` object
3001         :param instance: Instance object
3002         :param orig_image_ref: Original image_ref before rebuild
3003         :param image_ref: New image_ref for rebuild
3004         :param injected_files: Files to inject
3005         :param new_pass: password to set on rebuilt instance
3006         :param orig_sys_metadata: instance system metadata from pre-rebuild
3007         :param bdms: block-device-mappings to use for rebuild
3008         :param recreate: True if the instance is being recreated (e.g. the
3009             hypervisor it was on failed) - cleanup of old state will be
3010             skipped.
3011         :param on_shared_storage: True if instance files on shared storage.
3012                                   If not provided then information from the
3013                                   driver will be used to decide if the instance
3014                                   files are available or not on the target host
3015         :param preserve_ephemeral: True if the default ephemeral storage
3016                                    partition must be preserved on rebuild
3017         :param migration: a Migration object if one was created for this
3018                           rebuild operation (if it's a part of evacuate)
3019         :param scheduled_node: A node of the host chosen by the scheduler. If a
3020                                host was specified by the user, this will be
3021                                None
3022         :param limits: Overcommit limits set by the scheduler. If a host was
3023                        specified by the user, this will be None
3024         :param request_spec: a RequestSpec object used to schedule the instance
3025 
3026         """
3027         # recreate=True means the instance is being evacuated from a failed
3028         # host to a new destination host (this host). The 'recreate' variable
3029         # name is confusing, so rename it to evacuate here at the top, which
3030         # is simpler than renaming a parameter in an RPC versioned method.
3031         evacuate = recreate
3032         context = context.elevated()
3033 
3034         if evacuate:
3035             LOG.info("Evacuating instance", instance=instance)
3036         else:
3037             LOG.info("Rebuilding instance", instance=instance)
3038 
3039         if evacuate:
3040             # This is an evacuation to a new host, so we need to perform a
3041             # resource claim.
3042             rebuild_claim = self.rt.rebuild_claim
3043         else:
3044             # This is a rebuild to the same host, so we don't need to make
3045             # a claim since the instance is already on this host.
3046             rebuild_claim = claims.NopClaim
3047 
3048         if image_ref:
3049             image_meta = objects.ImageMeta.from_image_ref(
3050                 context, self.image_api, image_ref)
3051         elif evacuate:
3052             # For evacuate the API does not send down the image_ref since the
3053             # image does not change so just get it from what was stashed in
3054             # the instance system_metadata when the instance was created (or
3055             # last rebuilt). This also works for volume-backed instances.
3056             image_meta = instance.image_meta
3057         else:
3058             image_meta = objects.ImageMeta()
3059 
3060         # NOTE(mriedem): On an evacuate, we need to update
3061         # the instance's host and node properties to reflect it's
3062         # destination node for the evacuate.
3063         if not scheduled_node:
3064             if evacuate:
3065                 try:
3066                     compute_node = self._get_compute_info(context, self.host)
3067                     scheduled_node = compute_node.hypervisor_hostname
3068                 except exception.ComputeHostNotFound:
3069                     LOG.exception('Failed to get compute_info for %s',
3070                                   self.host)
3071             else:
3072                 scheduled_node = instance.node
3073 
3074         with self._error_out_instance_on_exception(context, instance):
3075             try:
3076                 claim_ctxt = rebuild_claim(
3077                     context, instance, scheduled_node,
3078                     limits=limits, image_meta=image_meta,
3079                     migration=migration)
3080                 self._do_rebuild_instance_with_claim(
3081                     claim_ctxt, context, instance, orig_image_ref,
3082                     image_meta, injected_files, new_pass, orig_sys_metadata,
3083                     bdms, evacuate, on_shared_storage, preserve_ephemeral,
3084                     migration, request_spec)
3085             except (exception.ComputeResourcesUnavailable,
3086                     exception.RescheduledException) as e:
3087                 if isinstance(e, exception.ComputeResourcesUnavailable):
3088                     LOG.debug("Could not rebuild instance on this host, not "
3089                               "enough resources available.", instance=instance)
3090                 else:
3091                     # RescheduledException is raised by the late server group
3092                     # policy check during evacuation if a parallel scheduling
3093                     # violated the policy.
3094                     # We catch the RescheduledException here but we don't have
3095                     # the plumbing to do an actual reschedule so we abort the
3096                     # operation.
3097                     LOG.debug("Could not rebuild instance on this host, "
3098                               "late server group check failed.",
3099                               instance=instance)
3100                 # NOTE(ndipanov): We just abort the build for now and leave a
3101                 # migration record for potential cleanup later
3102                 self._set_migration_status(migration, 'failed')
3103                 # Since the claim failed, we need to remove the allocation
3104                 # created against the destination node. Note that we can only
3105                 # get here when evacuating to a destination node. Rebuilding
3106                 # on the same host (not evacuate) uses the NopClaim which will
3107                 # not raise ComputeResourcesUnavailable.
3108                 self.rt.delete_allocation_for_evacuated_instance(
3109                     context, instance, scheduled_node, node_type='destination')
3110                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3111                 raise exception.BuildAbortException(
3112                     instance_uuid=instance.uuid, reason=e.format_message())
3113             except (exception.InstanceNotFound,
3114                     exception.UnexpectedDeletingTaskStateError) as e:
3115                 LOG.debug('Instance was deleted while rebuilding',
3116                           instance=instance)
3117                 self._set_migration_status(migration, 'failed')
3118                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3119             except Exception as e:
3120                 self._set_migration_status(migration, 'failed')
3121                 if evacuate or scheduled_node is not None:
3122                     self.rt.delete_allocation_for_evacuated_instance(
3123                         context, instance, scheduled_node,
3124                         node_type='destination')
3125                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3126                 raise
3127             else:
3128                 instance.apply_migration_context()
3129                 # NOTE (ndipanov): This save will now update the host and node
3130                 # attributes making sure that next RT pass is consistent since
3131                 # it will be based on the instance and not the migration DB
3132                 # entry.
3133                 instance.host = self.host
3134                 instance.node = scheduled_node
3135                 instance.save()
3136                 instance.drop_migration_context()
3137 
3138                 # NOTE (ndipanov): Mark the migration as done only after we
3139                 # mark the instance as belonging to this host.
3140                 self._set_migration_status(migration, 'done')
3141 
3142     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
3143         """Helper to avoid deep nesting in the top-level method."""
3144 
3145         with claim_context:
3146             self._do_rebuild_instance(*args, **kwargs)
3147 
3148     @staticmethod
3149     def _get_image_name(image_meta):
3150         if image_meta.obj_attr_is_set("name"):
3151             return image_meta.name
3152         else:
3153             return ''
3154 
3155     def _do_rebuild_instance(self, context, instance, orig_image_ref,
3156                              image_meta, injected_files, new_pass,
3157                              orig_sys_metadata, bdms, evacuate,
3158                              on_shared_storage, preserve_ephemeral,
3159                              migration, request_spec):
3160         orig_vm_state = instance.vm_state
3161 
3162         if evacuate:
3163             if request_spec:
3164                 # NOTE(gibi): Do a late check of server group policy as
3165                 # parallel scheduling could violate such policy. This will
3166                 # cause the evacuate to fail as rebuild does not implement
3167                 # reschedule.
3168                 hints = self._get_scheduler_hints({}, request_spec)
3169                 self._validate_instance_group_policy(context, instance, hints)
3170 
3171             if not self.driver.capabilities.get("supports_evacuate", False):
3172                 raise exception.InstanceEvacuateNotSupported
3173 
3174             self._check_instance_exists(context, instance)
3175 
3176             if on_shared_storage is None:
3177                 LOG.debug('on_shared_storage is not provided, using driver '
3178                           'information to decide if the instance needs to '
3179                           'be evacuated')
3180                 on_shared_storage = self.driver.instance_on_disk(instance)
3181 
3182             elif (on_shared_storage !=
3183                     self.driver.instance_on_disk(instance)):
3184                 # To cover case when admin expects that instance files are
3185                 # on shared storage, but not accessible and vice versa
3186                 raise exception.InvalidSharedStorage(
3187                         _("Invalid state of instance files on shared"
3188                             " storage"))
3189 
3190             if on_shared_storage:
3191                 LOG.info('disk on shared storage, evacuating using'
3192                          ' existing disk')
3193             elif instance.image_ref:
3194                 orig_image_ref = instance.image_ref
3195                 LOG.info("disk not on shared storage, evacuating from "
3196                          "image: '%s'", str(orig_image_ref))
3197             else:
3198                 LOG.info('disk on volume, evacuating using existing '
3199                          'volume')
3200 
3201         # We check trusted certs capabilities for both evacuate (rebuild on
3202         # another host) and rebuild (rebuild on the same host) because for
3203         # evacuate we need to make sure an instance with trusted certs can
3204         # have the image verified with those certs during rebuild, and for
3205         # rebuild we could be rebuilding a server that started out with no
3206         # trusted certs on this host, and then was rebuilt with trusted certs
3207         # for a new image, in which case we need to validate that new image
3208         # with the trusted certs during the rebuild.
3209         self._check_trusted_certs(instance)
3210 
3211         # This instance.exists message should contain the original
3212         # image_ref, not the new one.  Since the DB has been updated
3213         # to point to the new one... we have to override it.
3214         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
3215                                                                context)
3216         extra_usage_info = {'image_ref_url': orig_image_ref_url}
3217         compute_utils.notify_usage_exists(
3218                 self.notifier, context, instance, self.host,
3219                 current_period=True, system_metadata=orig_sys_metadata,
3220                 extra_usage_info=extra_usage_info)
3221 
3222         # This message should contain the new image_ref
3223         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
3224         self._notify_about_instance_usage(context, instance,
3225                 "rebuild.start", extra_usage_info=extra_usage_info)
3226         # NOTE: image_name is not included in the versioned notification
3227         # because we already provide the image_uuid in the notification
3228         # payload and the image details can be looked up via the uuid.
3229         compute_utils.notify_about_instance_rebuild(
3230             context, instance, self.host,
3231             phase=fields.NotificationPhase.START,
3232             bdms=bdms)
3233 
3234         instance.power_state = self._get_power_state(context, instance)
3235         instance.task_state = task_states.REBUILDING
3236         instance.save(expected_task_state=[task_states.REBUILDING])
3237 
3238         if evacuate:
3239             self.network_api.setup_networks_on_host(
3240                     context, instance, self.host)
3241             # For nova-network this is needed to move floating IPs
3242             # For neutron this updates the host in the port binding
3243             # TODO(cfriesen): this network_api call and the one above
3244             # are so similar, we should really try to unify them.
3245             self.network_api.setup_instance_network_on_host(
3246                     context, instance, self.host, migration)
3247             # TODO(mriedem): Consider decorating setup_instance_network_on_host
3248             # with @base_api.refresh_cache and then we wouldn't need this
3249             # explicit call to get_instance_nw_info.
3250             network_info = self.network_api.get_instance_nw_info(context,
3251                                                                  instance)
3252         else:
3253             network_info = instance.get_network_info()
3254 
3255         allocations = self.reportclient.get_allocations_for_consumer(
3256             context, instance.uuid)
3257 
3258         if bdms is None:
3259             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3260                     context, instance.uuid)
3261 
3262         block_device_info = \
3263             self._get_instance_block_device_info(
3264                     context, instance, bdms=bdms)
3265 
3266         def detach_block_devices(context, bdms):
3267             for bdm in bdms:
3268                 if bdm.is_volume:
3269                     # NOTE (ildikov): Having the attachment_id set in the BDM
3270                     # means that it's the new Cinder attach/detach flow
3271                     # (available from v3.44). In that case we explicitly
3272                     # attach and detach the volumes through attachment level
3273                     # operations. In this scenario _detach_volume will delete
3274                     # the existing attachment which would make the volume
3275                     # status change to 'available' if we don't pre-create
3276                     # another empty attachment before deleting the old one.
3277                     attachment_id = None
3278                     if bdm.attachment_id:
3279                         attachment_id = self.volume_api.attachment_create(
3280                             context, bdm['volume_id'], instance.uuid)['id']
3281                     self._detach_volume(context, bdm, instance,
3282                                         destroy_bdm=False)
3283                     if attachment_id:
3284                         bdm.attachment_id = attachment_id
3285                         bdm.save()
3286 
3287         files = self._decode_files(injected_files)
3288 
3289         kwargs = dict(
3290             context=context,
3291             instance=instance,
3292             image_meta=image_meta,
3293             injected_files=files,
3294             admin_password=new_pass,
3295             allocations=allocations,
3296             bdms=bdms,
3297             detach_block_devices=detach_block_devices,
3298             attach_block_devices=self._prep_block_device,
3299             block_device_info=block_device_info,
3300             network_info=network_info,
3301             preserve_ephemeral=preserve_ephemeral,
3302             evacuate=evacuate)
3303         try:
3304             with instance.mutated_migration_context():
3305                 self.driver.rebuild(**kwargs)
3306         except NotImplementedError:
3307             # NOTE(rpodolyaka): driver doesn't provide specialized version
3308             # of rebuild, fall back to the default implementation
3309             self._rebuild_default_impl(**kwargs)
3310         self._update_instance_after_spawn(context, instance)
3311         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3312 
3313         if orig_vm_state == vm_states.STOPPED:
3314             LOG.info("bringing vm to original state: '%s'",
3315                      orig_vm_state, instance=instance)
3316             instance.vm_state = vm_states.ACTIVE
3317             instance.task_state = task_states.POWERING_OFF
3318             instance.progress = 0
3319             instance.save()
3320             self.stop_instance(context, instance, False)
3321         # TODO(melwitt): We should clean up instance console tokens here in the
3322         # case of evacuate. The instance is on a new host and will need to
3323         # establish a new console connection.
3324         self._update_scheduler_instance_info(context, instance)
3325         self._notify_about_instance_usage(
3326                 context, instance, "rebuild.end",
3327                 network_info=network_info,
3328                 extra_usage_info=extra_usage_info)
3329         compute_utils.notify_about_instance_rebuild(
3330             context, instance, self.host,
3331             phase=fields.NotificationPhase.END,
3332             bdms=bdms)
3333 
3334     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3335                                      block_device_info):
3336         """Handle cases where the virt-layer had to detach non-working volumes
3337         in order to complete an operation.
3338         """
3339         for bdm in block_device_info['block_device_mapping']:
3340             if bdm.get('mount_device') in bad_devices:
3341                 try:
3342                     volume_id = bdm['connection_info']['data']['volume_id']
3343                 except KeyError:
3344                     continue
3345 
3346                 # NOTE(sirp): ideally we'd just call
3347                 # `compute_api.detach_volume` here but since that hits the
3348                 # DB directly, that's off limits from within the
3349                 # compute-manager.
3350                 #
3351                 # API-detach
3352                 LOG.info("Detaching from volume api: %s", volume_id)
3353                 self.volume_api.begin_detaching(context, volume_id)
3354 
3355                 # Manager-detach
3356                 self.detach_volume(context, volume_id, instance)
3357 
3358     @wrap_exception()
3359     @reverts_task_state
3360     @wrap_instance_event(prefix='compute')
3361     @wrap_instance_fault
3362     def reboot_instance(self, context, instance, block_device_info,
3363                         reboot_type):
3364         """Reboot an instance on this host."""
3365         # acknowledge the request made it to the manager
3366         if reboot_type == "SOFT":
3367             instance.task_state = task_states.REBOOT_PENDING
3368             expected_states = task_states.soft_reboot_states
3369         else:
3370             instance.task_state = task_states.REBOOT_PENDING_HARD
3371             expected_states = task_states.hard_reboot_states
3372 
3373         context = context.elevated()
3374         LOG.info("Rebooting instance", instance=instance)
3375 
3376         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3377             context, instance.uuid)
3378         block_device_info = self._get_instance_block_device_info(
3379             context, instance, bdms=bdms)
3380 
3381         network_info = self.network_api.get_instance_nw_info(context, instance)
3382 
3383         self._notify_about_instance_usage(context, instance, "reboot.start")
3384         compute_utils.notify_about_instance_action(
3385             context, instance, self.host,
3386             action=fields.NotificationAction.REBOOT,
3387             phase=fields.NotificationPhase.START,
3388             bdms=bdms
3389         )
3390 
3391         instance.power_state = self._get_power_state(context, instance)
3392         instance.save(expected_task_state=expected_states)
3393 
3394         if instance.power_state != power_state.RUNNING:
3395             state = instance.power_state
3396             running = power_state.RUNNING
3397             LOG.warning('trying to reboot a non-running instance:'
3398                         ' (state: %(state)s expected: %(running)s)',
3399                         {'state': state, 'running': running},
3400                         instance=instance)
3401 
3402         def bad_volumes_callback(bad_devices):
3403             self._handle_bad_volumes_detached(
3404                     context, instance, bad_devices, block_device_info)
3405 
3406         try:
3407             # Don't change it out of rescue mode
3408             if instance.vm_state == vm_states.RESCUED:
3409                 new_vm_state = vm_states.RESCUED
3410             else:
3411                 new_vm_state = vm_states.ACTIVE
3412             new_power_state = None
3413             if reboot_type == "SOFT":
3414                 instance.task_state = task_states.REBOOT_STARTED
3415                 expected_state = task_states.REBOOT_PENDING
3416             else:
3417                 instance.task_state = task_states.REBOOT_STARTED_HARD
3418                 expected_state = task_states.REBOOT_PENDING_HARD
3419             instance.save(expected_task_state=expected_state)
3420             self.driver.reboot(context, instance,
3421                                network_info,
3422                                reboot_type,
3423                                block_device_info=block_device_info,
3424                                bad_volumes_callback=bad_volumes_callback)
3425 
3426         except Exception as error:
3427             with excutils.save_and_reraise_exception() as ctxt:
3428                 exc_info = sys.exc_info()
3429                 # if the reboot failed but the VM is running don't
3430                 # put it into an error state
3431                 new_power_state = self._get_power_state(context, instance)
3432                 if new_power_state == power_state.RUNNING:
3433                     LOG.warning('Reboot failed but instance is running',
3434                                 instance=instance)
3435                     compute_utils.add_instance_fault_from_exc(context,
3436                             instance, error, exc_info)
3437                     self._notify_about_instance_usage(context, instance,
3438                             'reboot.error', fault=error)
3439                     tb = traceback.format_exc()
3440                     compute_utils.notify_about_instance_action(
3441                         context, instance, self.host,
3442                         action=fields.NotificationAction.REBOOT,
3443                         phase=fields.NotificationPhase.ERROR,
3444                         exception=error, bdms=bdms, tb=tb
3445                     )
3446                     ctxt.reraise = False
3447                 else:
3448                     LOG.error('Cannot reboot instance: %s', error,
3449                               instance=instance)
3450                     self._set_instance_obj_error_state(context, instance)
3451 
3452         if not new_power_state:
3453             new_power_state = self._get_power_state(context, instance)
3454         try:
3455             instance.power_state = new_power_state
3456             instance.vm_state = new_vm_state
3457             instance.task_state = None
3458             instance.save()
3459         except exception.InstanceNotFound:
3460             LOG.warning("Instance disappeared during reboot",
3461                         instance=instance)
3462 
3463         self._notify_about_instance_usage(context, instance, "reboot.end")
3464         compute_utils.notify_about_instance_action(
3465             context, instance, self.host,
3466             action=fields.NotificationAction.REBOOT,
3467             phase=fields.NotificationPhase.END,
3468             bdms=bdms
3469         )
3470 
3471     @delete_image_on_error
3472     def _do_snapshot_instance(self, context, image_id, instance):
3473         self._snapshot_instance(context, image_id, instance,
3474                                 task_states.IMAGE_BACKUP)
3475 
3476     @wrap_exception()
3477     @reverts_task_state
3478     @wrap_instance_event(prefix='compute')
3479     @wrap_instance_fault
3480     def backup_instance(self, context, image_id, instance, backup_type,
3481                         rotation):
3482         """Backup an instance on this host.
3483 
3484         :param backup_type: daily | weekly
3485         :param rotation: int representing how many backups to keep around
3486         """
3487         self._do_snapshot_instance(context, image_id, instance)
3488         self._rotate_backups(context, instance, backup_type, rotation)
3489 
3490     @wrap_exception()
3491     @reverts_task_state
3492     @wrap_instance_event(prefix='compute')
3493     @wrap_instance_fault
3494     @delete_image_on_error
3495     def snapshot_instance(self, context, image_id, instance):
3496         """Snapshot an instance on this host.
3497 
3498         :param context: security context
3499         :param image_id: glance.db.sqlalchemy.models.Image.Id
3500         :param instance: a nova.objects.instance.Instance object
3501         """
3502         # NOTE(dave-mcnally) the task state will already be set by the api
3503         # but if the compute manager has crashed/been restarted prior to the
3504         # request getting here the task state may have been cleared so we set
3505         # it again and things continue normally
3506         try:
3507             instance.task_state = task_states.IMAGE_SNAPSHOT
3508             instance.save(
3509                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3510         except exception.InstanceNotFound:
3511             # possibility instance no longer exists, no point in continuing
3512             LOG.debug("Instance not found, could not set state %s "
3513                       "for instance.",
3514                       task_states.IMAGE_SNAPSHOT, instance=instance)
3515             return
3516 
3517         except exception.UnexpectedDeletingTaskStateError:
3518             LOG.debug("Instance being deleted, snapshot cannot continue",
3519                       instance=instance)
3520             return
3521 
3522         self._snapshot_instance(context, image_id, instance,
3523                                 task_states.IMAGE_SNAPSHOT)
3524 
3525     def _snapshot_instance(self, context, image_id, instance,
3526                            expected_task_state):
3527         context = context.elevated()
3528 
3529         instance.power_state = self._get_power_state(context, instance)
3530         try:
3531             instance.save()
3532 
3533             LOG.info('instance snapshotting', instance=instance)
3534 
3535             if instance.power_state != power_state.RUNNING:
3536                 state = instance.power_state
3537                 running = power_state.RUNNING
3538                 LOG.warning('trying to snapshot a non-running instance: '
3539                             '(state: %(state)s expected: %(running)s)',
3540                             {'state': state, 'running': running},
3541                             instance=instance)
3542 
3543             self._notify_about_instance_usage(
3544                 context, instance, "snapshot.start")
3545             compute_utils.notify_about_instance_snapshot(context, instance,
3546                 self.host, phase=fields.NotificationPhase.START,
3547                 snapshot_image_id=image_id)
3548 
3549             def update_task_state(task_state,
3550                                   expected_state=expected_task_state):
3551                 instance.task_state = task_state
3552                 instance.save(expected_task_state=expected_state)
3553 
3554             with timeutils.StopWatch() as timer:
3555                 self.driver.snapshot(context, instance, image_id,
3556                                      update_task_state)
3557             LOG.info('Took %0.2f seconds to snapshot the instance on '
3558                      'the hypervisor.', timer.elapsed(), instance=instance)
3559 
3560             instance.task_state = None
3561             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3562 
3563             self._notify_about_instance_usage(context, instance,
3564                                               "snapshot.end")
3565             compute_utils.notify_about_instance_snapshot(context, instance,
3566                 self.host, phase=fields.NotificationPhase.END,
3567                 snapshot_image_id=image_id)
3568         except (exception.InstanceNotFound,
3569                 exception.UnexpectedDeletingTaskStateError):
3570             # the instance got deleted during the snapshot
3571             # Quickly bail out of here
3572             msg = 'Instance disappeared during snapshot'
3573             LOG.debug(msg, instance=instance)
3574             try:
3575                 image = self.image_api.get(context, image_id)
3576                 if image['status'] != 'active':
3577                     self.image_api.delete(context, image_id)
3578             except exception.ImageNotFound:
3579                 LOG.debug('Image not found during clean up %s', image_id)
3580             except Exception:
3581                 LOG.warning("Error while trying to clean up image %s",
3582                             image_id, instance=instance)
3583         except exception.ImageNotFound:
3584             instance.task_state = None
3585             instance.save()
3586             LOG.warning("Image not found during snapshot", instance=instance)
3587 
3588     def _post_interrupted_snapshot_cleanup(self, context, instance):
3589         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3590 
3591     @messaging.expected_exceptions(NotImplementedError)
3592     @wrap_exception()
3593     def volume_snapshot_create(self, context, instance, volume_id,
3594                                create_info):
3595         self.driver.volume_snapshot_create(context, instance, volume_id,
3596                                            create_info)
3597 
3598     @messaging.expected_exceptions(NotImplementedError)
3599     @wrap_exception()
3600     def volume_snapshot_delete(self, context, instance, volume_id,
3601                                snapshot_id, delete_info):
3602         self.driver.volume_snapshot_delete(context, instance, volume_id,
3603                                            snapshot_id, delete_info)
3604 
3605     @wrap_instance_fault
3606     def _rotate_backups(self, context, instance, backup_type, rotation):
3607         """Delete excess backups associated to an instance.
3608 
3609         Instances are allowed a fixed number of backups (the rotation number);
3610         this method deletes the oldest backups that exceed the rotation
3611         threshold.
3612 
3613         :param context: security context
3614         :param instance: Instance dict
3615         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3616         :param rotation: int representing how many backups to keep around;
3617             None if rotation shouldn't be used (as in the case of snapshots)
3618         """
3619         filters = {'property-image_type': 'backup',
3620                    'property-backup_type': backup_type,
3621                    'property-instance_uuid': instance.uuid}
3622 
3623         images = self.image_api.get_all(context, filters=filters,
3624                                         sort_key='created_at', sort_dir='desc')
3625         num_images = len(images)
3626         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3627                   {'num_images': num_images, 'rotation': rotation},
3628                   instance=instance)
3629 
3630         if num_images > rotation:
3631             # NOTE(sirp): this deletes all backups that exceed the rotation
3632             # limit
3633             excess = len(images) - rotation
3634             LOG.debug("Rotating out %d backups", excess,
3635                       instance=instance)
3636             for i in range(excess):
3637                 image = images.pop()
3638                 image_id = image['id']
3639                 LOG.debug("Deleting image %s", image_id,
3640                           instance=instance)
3641                 try:
3642                     self.image_api.delete(context, image_id)
3643                 except exception.ImageNotFound:
3644                     LOG.info("Failed to find image %(image_id)s to "
3645                              "delete", {'image_id': image_id},
3646                              instance=instance)
3647                 except (exception.ImageDeleteConflict, Exception) as exc:
3648                     LOG.info("Failed to delete image %(image_id)s during "
3649                              "deleting excess backups. "
3650                              "Continuing for next image.. %(exc)s",
3651                              {'image_id': image_id, 'exc': exc},
3652                              instance=instance)
3653 
3654     @wrap_exception()
3655     @reverts_task_state
3656     @wrap_instance_event(prefix='compute')
3657     @wrap_instance_fault
3658     def set_admin_password(self, context, instance, new_pass):
3659         """Set the root/admin password for an instance on this host.
3660 
3661         This is generally only called by API password resets after an
3662         image has been built.
3663 
3664         @param context: Nova auth context.
3665         @param instance: Nova instance object.
3666         @param new_pass: The admin password for the instance.
3667         """
3668 
3669         context = context.elevated()
3670         if new_pass is None:
3671             # Generate a random password
3672             new_pass = utils.generate_password()
3673 
3674         current_power_state = self._get_power_state(context, instance)
3675         expected_state = power_state.RUNNING
3676 
3677         if current_power_state != expected_state:
3678             instance.task_state = None
3679             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3680             _msg = _('instance %s is not running') % instance.uuid
3681             raise exception.InstancePasswordSetFailed(
3682                 instance=instance.uuid, reason=_msg)
3683 
3684         try:
3685             self.driver.set_admin_password(instance, new_pass)
3686             LOG.info("Admin password set", instance=instance)
3687             instance.task_state = None
3688             instance.save(
3689                 expected_task_state=task_states.UPDATING_PASSWORD)
3690         except exception.InstanceAgentNotEnabled:
3691             with excutils.save_and_reraise_exception():
3692                 LOG.debug('Guest agent is not enabled for the instance.',
3693                           instance=instance)
3694                 instance.task_state = None
3695                 instance.save(
3696                     expected_task_state=task_states.UPDATING_PASSWORD)
3697         except exception.SetAdminPasswdNotSupported:
3698             with excutils.save_and_reraise_exception():
3699                 LOG.info('set_admin_password is not supported '
3700                          'by this driver or guest instance.',
3701                          instance=instance)
3702                 instance.task_state = None
3703                 instance.save(
3704                     expected_task_state=task_states.UPDATING_PASSWORD)
3705         except NotImplementedError:
3706             LOG.warning('set_admin_password is not implemented '
3707                         'by this driver or guest instance.',
3708                         instance=instance)
3709             instance.task_state = None
3710             instance.save(
3711                 expected_task_state=task_states.UPDATING_PASSWORD)
3712             raise NotImplementedError(_('set_admin_password is not '
3713                                         'implemented by this driver or guest '
3714                                         'instance.'))
3715         except exception.UnexpectedTaskStateError:
3716             # interrupted by another (most likely delete) task
3717             # do not retry
3718             raise
3719         except Exception:
3720             # Catch all here because this could be anything.
3721             LOG.exception('set_admin_password failed', instance=instance)
3722             # We create a new exception here so that we won't
3723             # potentially reveal password information to the
3724             # API caller.  The real exception is logged above
3725             _msg = _('error setting admin password')
3726             raise exception.InstancePasswordSetFailed(
3727                 instance=instance.uuid, reason=_msg)
3728 
3729     @wrap_exception()
3730     @reverts_task_state
3731     @wrap_instance_fault
3732     def inject_file(self, context, path, file_contents, instance):
3733         """Write a file to the specified path in an instance on this host."""
3734         # NOTE(russellb) Remove this method, as well as the underlying virt
3735         # driver methods, when the compute rpc interface is bumped to 4.x
3736         # as it is no longer used.
3737         context = context.elevated()
3738         current_power_state = self._get_power_state(context, instance)
3739         expected_state = power_state.RUNNING
3740         if current_power_state != expected_state:
3741             LOG.warning('trying to inject a file into a non-running '
3742                         '(state: %(current_state)s expected: '
3743                         '%(expected_state)s)',
3744                         {'current_state': current_power_state,
3745                          'expected_state': expected_state},
3746                         instance=instance)
3747         LOG.info('injecting file to %s', path, instance=instance)
3748         self.driver.inject_file(instance, path, file_contents)
3749 
3750     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3751         """Determine what image should be used to boot the rescue VM."""
3752         # 1. If rescue_image_ref is passed in, use that for rescue.
3753         # 2. Else, use the base image associated with instance's current image.
3754         #       The idea here is to provide the customer with a rescue
3755         #       environment which they are familiar with.
3756         #       So, if they built their instance off of a Debian image,
3757         #       their rescue VM will also be Debian.
3758         # 3. As a last resort, use instance's current image.
3759         if not rescue_image_ref:
3760             system_meta = utils.instance_sys_meta(instance)
3761             rescue_image_ref = system_meta.get('image_base_image_ref')
3762 
3763         if not rescue_image_ref:
3764             LOG.warning('Unable to find a different image to use for '
3765                         'rescue VM, using instance\'s current image',
3766                         instance=instance)
3767             rescue_image_ref = instance.image_ref
3768 
3769         return objects.ImageMeta.from_image_ref(
3770             context, self.image_api, rescue_image_ref)
3771 
3772     @wrap_exception()
3773     @reverts_task_state
3774     @wrap_instance_event(prefix='compute')
3775     @wrap_instance_fault
3776     def rescue_instance(self, context, instance, rescue_password,
3777                         rescue_image_ref, clean_shutdown):
3778         context = context.elevated()
3779         LOG.info('Rescuing', instance=instance)
3780 
3781         admin_password = (rescue_password if rescue_password else
3782                       utils.generate_password())
3783 
3784         network_info = self.network_api.get_instance_nw_info(context, instance)
3785 
3786         rescue_image_meta = self._get_rescue_image(context, instance,
3787                                                    rescue_image_ref)
3788 
3789         extra_usage_info = {'rescue_image_name':
3790                             self._get_image_name(rescue_image_meta)}
3791         self._notify_about_instance_usage(context, instance,
3792                 "rescue.start", extra_usage_info=extra_usage_info,
3793                 network_info=network_info)
3794         compute_utils.notify_about_instance_rescue_action(
3795             context, instance, self.host, rescue_image_ref,
3796             phase=fields.NotificationPhase.START)
3797 
3798         try:
3799             self._power_off_instance(context, instance, clean_shutdown)
3800 
3801             self.driver.rescue(context, instance,
3802                                network_info,
3803                                rescue_image_meta, admin_password)
3804         except Exception as e:
3805             LOG.exception("Error trying to Rescue Instance",
3806                           instance=instance)
3807             self._set_instance_obj_error_state(context, instance)
3808             raise exception.InstanceNotRescuable(
3809                 instance_id=instance.uuid,
3810                 reason=_("Driver Error: %s") % e)
3811 
3812         compute_utils.notify_usage_exists(self.notifier, context, instance,
3813                                           self.host, current_period=True)
3814 
3815         instance.vm_state = vm_states.RESCUED
3816         instance.task_state = None
3817         instance.power_state = self._get_power_state(context, instance)
3818         instance.launched_at = timeutils.utcnow()
3819         instance.save(expected_task_state=task_states.RESCUING)
3820 
3821         self._notify_about_instance_usage(context, instance,
3822                 "rescue.end", extra_usage_info=extra_usage_info,
3823                 network_info=network_info)
3824         compute_utils.notify_about_instance_rescue_action(
3825             context, instance, self.host, rescue_image_ref,
3826             phase=fields.NotificationPhase.END)
3827 
3828     @wrap_exception()
3829     @reverts_task_state
3830     @wrap_instance_event(prefix='compute')
3831     @wrap_instance_fault
3832     def unrescue_instance(self, context, instance):
3833         context = context.elevated()
3834         LOG.info('Unrescuing', instance=instance)
3835 
3836         network_info = self.network_api.get_instance_nw_info(context, instance)
3837         self._notify_about_instance_usage(context, instance,
3838                 "unrescue.start", network_info=network_info)
3839         compute_utils.notify_about_instance_action(context, instance,
3840             self.host, action=fields.NotificationAction.UNRESCUE,
3841             phase=fields.NotificationPhase.START)
3842 
3843         with self._error_out_instance_on_exception(context, instance):
3844             self.driver.unrescue(instance,
3845                                  network_info)
3846 
3847         instance.vm_state = vm_states.ACTIVE
3848         instance.task_state = None
3849         instance.power_state = self._get_power_state(context, instance)
3850         instance.save(expected_task_state=task_states.UNRESCUING)
3851 
3852         self._notify_about_instance_usage(context,
3853                                           instance,
3854                                           "unrescue.end",
3855                                           network_info=network_info)
3856         compute_utils.notify_about_instance_action(context, instance,
3857             self.host, action=fields.NotificationAction.UNRESCUE,
3858             phase=fields.NotificationPhase.END)
3859 
3860     @wrap_exception()
3861     @wrap_instance_fault
3862     def change_instance_metadata(self, context, diff, instance):
3863         """Update the metadata published to the instance."""
3864         LOG.debug("Changing instance metadata according to %r",
3865                   diff, instance=instance)
3866         self.driver.change_instance_metadata(context, instance, diff)
3867 
3868     @wrap_exception()
3869     @wrap_instance_event(prefix='compute')
3870     @wrap_instance_fault
3871     def confirm_resize(self, context, instance, migration):
3872         """Confirms a migration/resize and deletes the 'old' instance.
3873 
3874         This is called from the API and runs on the source host.
3875 
3876         Nothing needs to happen on the destination host at this point since
3877         the instance is already running there. This routine just cleans up the
3878         source host.
3879         """
3880         @utils.synchronized(instance.uuid)
3881         def do_confirm_resize(context, instance, migration_id):
3882             # NOTE(wangpan): Get the migration status from db, if it has been
3883             #                confirmed, we do nothing and return here
3884             LOG.debug("Going to confirm migration %s", migration_id,
3885                       instance=instance)
3886             try:
3887                 # TODO(russellb) Why are we sending the migration object just
3888                 # to turn around and look it up from the db again?
3889                 migration = objects.Migration.get_by_id(
3890                                     context.elevated(), migration_id)
3891             except exception.MigrationNotFound:
3892                 LOG.error("Migration %s is not found during confirmation",
3893                           migration_id, instance=instance)
3894                 return
3895 
3896             if migration.status == 'confirmed':
3897                 LOG.info("Migration %s is already confirmed",
3898                          migration_id, instance=instance)
3899                 return
3900             elif migration.status not in ('finished', 'confirming'):
3901                 LOG.warning("Unexpected confirmation status '%(status)s' "
3902                             "of migration %(id)s, exit confirmation process",
3903                             {"status": migration.status, "id": migration_id},
3904                             instance=instance)
3905                 return
3906 
3907             # NOTE(wangpan): Get the instance from db, if it has been
3908             #                deleted, we do nothing and return here
3909             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3910             try:
3911                 instance = objects.Instance.get_by_uuid(
3912                         context, instance.uuid,
3913                         expected_attrs=expected_attrs)
3914             except exception.InstanceNotFound:
3915                 LOG.info("Instance is not found during confirmation",
3916                          instance=instance)
3917                 return
3918 
3919             self._confirm_resize(context, instance, migration=migration)
3920 
3921         do_confirm_resize(context, instance, migration.id)
3922 
3923     def _confirm_resize(self, context, instance, migration=None):
3924         """Destroys the source instance."""
3925         self._notify_about_instance_usage(context, instance,
3926                                           "resize.confirm.start")
3927         compute_utils.notify_about_instance_action(context, instance,
3928             self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3929             phase=fields.NotificationPhase.START)
3930 
3931         with self._error_out_instance_on_exception(context, instance):
3932             # NOTE(danms): delete stashed migration information
3933             old_instance_type = instance.old_flavor
3934             instance.old_flavor = None
3935             instance.new_flavor = None
3936             instance.system_metadata.pop('old_vm_state', None)
3937             instance.save()
3938 
3939             # NOTE(tr3buchet): tear down networks on source host
3940             self.network_api.setup_networks_on_host(context, instance,
3941                                migration.source_compute, teardown=True)
3942 
3943             network_info = self.network_api.get_instance_nw_info(context,
3944                                                                  instance)
3945             # TODO(mriedem): Get BDMs here and pass them to the driver.
3946             self.driver.confirm_migration(context, migration, instance,
3947                                           network_info)
3948 
3949             migration.status = 'confirmed'
3950             with migration.obj_as_admin():
3951                 migration.save()
3952 
3953             self.rt.drop_move_claim(context, instance, migration.source_node,
3954                                     old_instance_type, prefix='old_')
3955             self._delete_allocation_after_move(context, instance, migration)
3956             instance.drop_migration_context()
3957 
3958             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3959             # might have manually powered up the instance to confirm the
3960             # resize/migrate, so we need to check the current power state
3961             # on the instance and set the vm_state appropriately. We default
3962             # to ACTIVE because if the power state is not SHUTDOWN, we
3963             # assume _sync_instance_power_state will clean it up.
3964             p_state = instance.power_state
3965             vm_state = None
3966             if p_state == power_state.SHUTDOWN:
3967                 vm_state = vm_states.STOPPED
3968                 LOG.debug("Resized/migrated instance is powered off. "
3969                           "Setting vm_state to '%s'.", vm_state,
3970                           instance=instance)
3971             else:
3972                 vm_state = vm_states.ACTIVE
3973 
3974             instance.vm_state = vm_state
3975             instance.task_state = None
3976             instance.save(expected_task_state=[None, task_states.DELETING,
3977                                                task_states.SOFT_DELETING])
3978 
3979             self._notify_about_instance_usage(
3980                 context, instance, "resize.confirm.end",
3981                 network_info=network_info)
3982             compute_utils.notify_about_instance_action(context, instance,
3983                    self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3984                    phase=fields.NotificationPhase.END)
3985 
3986     def _delete_allocation_after_move(self, context, instance, migration):
3987         """Deletes resource allocations held by the migration record against
3988         the source compute node resource provider after a confirmed cold /
3989         successful live migration.
3990         """
3991         try:
3992             # NOTE(danms): We're finishing on the source node, so try
3993             # to delete the allocation based on the migration uuid
3994             self.reportclient.delete_allocation_for_instance(
3995                 context, migration.uuid)
3996         except exception.AllocationDeleteFailed:
3997             LOG.error('Deleting allocation in placement for migration '
3998                       '%(migration_uuid)s failed. The instance '
3999                       '%(instance_uuid)s will be put to ERROR state '
4000                       'but the allocation held by the migration is '
4001                       'leaked.',
4002                       {'instance_uuid': instance.uuid,
4003                        'migration_uuid': migration.uuid})
4004             raise
4005 
4006     @wrap_exception()
4007     @reverts_task_state
4008     @wrap_instance_event(prefix='compute')
4009     @errors_out_migration
4010     @wrap_instance_fault
4011     def revert_resize(self, context, instance, migration):
4012         """Destroys the new instance on the destination machine.
4013 
4014         Reverts the model changes, and powers on the old instance on the
4015         source machine.
4016 
4017         """
4018         # NOTE(comstud): A revert_resize is essentially a resize back to
4019         # the old size, so we need to send a usage event here.
4020         compute_utils.notify_usage_exists(self.notifier, context, instance,
4021                                           self.host, current_period=True)
4022 
4023         with self._error_out_instance_on_exception(context, instance):
4024             # NOTE(tr3buchet): tear down networks on destination host
4025             self.network_api.setup_networks_on_host(context, instance,
4026                                                     teardown=True)
4027 
4028             migration_p = obj_base.obj_to_primitive(migration)
4029             self.network_api.migrate_instance_start(context,
4030                                                     instance,
4031                                                     migration_p)
4032 
4033             network_info = self.network_api.get_instance_nw_info(context,
4034                                                                  instance)
4035             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4036                     context, instance.uuid)
4037             block_device_info = self._get_instance_block_device_info(
4038                                 context, instance, bdms=bdms)
4039 
4040             destroy_disks = not self._is_instance_storage_shared(
4041                 context, instance, host=migration.source_compute)
4042             self.driver.destroy(context, instance, network_info,
4043                                 block_device_info, destroy_disks)
4044 
4045             self._terminate_volume_connections(context, instance, bdms)
4046 
4047             migration.status = 'reverted'
4048             with migration.obj_as_admin():
4049                 migration.save()
4050 
4051             # NOTE(ndipanov): We need to do this here because dropping the
4052             # claim means we lose the migration_context data. We really should
4053             # fix this by moving the drop_move_claim call to the
4054             # finish_revert_resize method as this is racy (revert is dropped,
4055             # but instance resources will be tracked with the new flavor until
4056             # it gets rolled back in finish_revert_resize, which is
4057             # potentially wrong for a period of time).
4058             instance.revert_migration_context()
4059             instance.save()
4060 
4061             self.rt.drop_move_claim(context, instance, instance.node)
4062 
4063             # RPC cast back to the source host to finish the revert there.
4064             self.compute_rpcapi.finish_revert_resize(context, instance,
4065                     migration, migration.source_compute)
4066 
4067     @wrap_exception()
4068     @reverts_task_state
4069     @wrap_instance_event(prefix='compute')
4070     @errors_out_migration
4071     @wrap_instance_fault
4072     def finish_revert_resize(self, context, instance, migration):
4073         """Finishes the second half of reverting a resize on the source host.
4074 
4075         Bring the original source instance state back (active/shutoff) and
4076         revert the resized attributes in the database.
4077 
4078         """
4079         with self._error_out_instance_on_exception(context, instance):
4080             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4081                 context, instance.uuid)
4082             self._notify_about_instance_usage(
4083                     context, instance, "resize.revert.start")
4084             compute_utils.notify_about_instance_action(context, instance,
4085                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4086                     phase=fields.NotificationPhase.START, bdms=bdms)
4087 
4088             # NOTE(mriedem): delete stashed old_vm_state information; we
4089             # default to ACTIVE for backwards compatibility if old_vm_state
4090             # is not set
4091             old_vm_state = instance.system_metadata.pop('old_vm_state',
4092                                                         vm_states.ACTIVE)
4093 
4094             self._set_instance_info(instance, instance.old_flavor)
4095             instance.old_flavor = None
4096             instance.new_flavor = None
4097             instance.host = migration.source_compute
4098             instance.node = migration.source_node
4099             instance.save()
4100 
4101             try:
4102                 self._revert_allocation(context, instance, migration)
4103             except exception.AllocationMoveFailed:
4104                 LOG.error('Reverting allocation in placement for migration '
4105                           '%(migration_uuid)s failed. The instance '
4106                           '%(instance_uuid)s will be put into ERROR state but '
4107                           'the allocation held by the migration is leaked.',
4108                           {'instance_uuid': instance.uuid,
4109                            'migration_uuid': migration.uuid})
4110                 raise
4111 
4112             self.network_api.setup_networks_on_host(context, instance,
4113                                                     migration.source_compute)
4114             migration_p = obj_base.obj_to_primitive(migration)
4115             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
4116             # source host temporarily. "network_api.migrate_instance_finish"
4117             # will setup the network for the instance on the destination host.
4118             # For revert resize, the instance will back to the source host, the
4119             # setup of the network for instance should be on the source host.
4120             # So set the migration_p['dest_compute'] to source host at here.
4121             migration_p['dest_compute'] = migration.source_compute
4122             self.network_api.migrate_instance_finish(context,
4123                                                      instance,
4124                                                      migration_p)
4125             network_info = self.network_api.get_instance_nw_info(context,
4126                                                                  instance)
4127 
4128             # revert_resize deleted any volume attachments for the instance
4129             # and created new ones to be used on this host, but we
4130             # have to update those attachments with the host connector so the
4131             # BDM.connection_info will get set in the call to
4132             # _get_instance_block_device_info below with refresh_conn_info=True
4133             # and then the volumes can be re-connected via the driver on this
4134             # host.
4135             self._update_volume_attachments(context, instance, bdms)
4136 
4137             block_device_info = self._get_instance_block_device_info(
4138                     context, instance, refresh_conn_info=True, bdms=bdms)
4139 
4140             power_on = old_vm_state != vm_states.STOPPED
4141             self.driver.finish_revert_migration(context, instance,
4142                                        network_info,
4143                                        block_device_info, power_on)
4144 
4145             instance.drop_migration_context()
4146             instance.launched_at = timeutils.utcnow()
4147             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
4148 
4149             # Complete any volume attachments so the volumes are in-use.
4150             self._complete_volume_attachments(context, bdms)
4151 
4152             # if the original vm state was STOPPED, set it back to STOPPED
4153             LOG.info("Updating instance to original state: '%s'",
4154                      old_vm_state, instance=instance)
4155             if power_on:
4156                 instance.vm_state = vm_states.ACTIVE
4157                 instance.task_state = None
4158                 instance.save()
4159             else:
4160                 instance.task_state = task_states.POWERING_OFF
4161                 instance.save()
4162                 self.stop_instance(context, instance=instance,
4163                                    clean_shutdown=True)
4164 
4165             self._notify_about_instance_usage(
4166                     context, instance, "resize.revert.end")
4167             compute_utils.notify_about_instance_action(context, instance,
4168                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4169                     phase=fields.NotificationPhase.END, bdms=bdms)
4170 
4171     def _revert_allocation(self, context, instance, migration):
4172         """Revert an allocation that is held by migration to our instance."""
4173 
4174         # Fetch the original allocation that the instance had on the source
4175         # node, which are now held by the migration
4176         orig_alloc = self.reportclient.get_allocations_for_consumer(
4177             context, migration.uuid)
4178         if not orig_alloc:
4179             LOG.error('Did not find resource allocations for migration '
4180                       '%s on source node %s. Unable to revert source node '
4181                       'allocations back to the instance.',
4182                       migration.uuid, migration.source_node, instance=instance)
4183             return False
4184 
4185         if len(orig_alloc) > 1:
4186             # NOTE(danms): This may change later if we have other allocations
4187             # against other providers that need to be held by the migration
4188             # as well. Perhaps something like shared storage resources that
4189             # will actually be duplicated during a resize type operation.
4190             LOG.error('Migration %(mig)s has allocations against '
4191                       'more than one provider %(rps)s. This should not be '
4192                       'possible, but reverting it anyway.',
4193                       {'mig': migration.uuid,
4194                        'rps': ','.join(orig_alloc.keys())},
4195                       instance=instance)
4196 
4197         # We only have a claim against one provider, it is the source node
4198         cn_uuid = list(orig_alloc.keys())[0]
4199 
4200         # FIXME(danms): This method is flawed in that it asssumes allocations
4201         # against only one provider. So, this may overwite allocations against
4202         # a shared provider, if we had one.
4203         LOG.info('Swapping old allocation on %(node)s held by migration '
4204                  '%(mig)s for instance',
4205                  {'node': cn_uuid, 'mig': migration.uuid},
4206                  instance=instance)
4207         # TODO(cdent): Should we be doing anything with return values here?
4208         self.reportclient.move_allocations(context, migration.uuid,
4209                                            instance.uuid)
4210         return True
4211 
4212     def _prep_resize(self, context, image, instance, instance_type,
4213                      filter_properties, node, migration, clean_shutdown=True):
4214 
4215         if not filter_properties:
4216             filter_properties = {}
4217 
4218         if not instance.host:
4219             self._set_instance_obj_error_state(context, instance)
4220             msg = _('Instance has no source host')
4221             raise exception.MigrationError(reason=msg)
4222 
4223         same_host = instance.host == self.host
4224         # if the flavor IDs match, it's migrate; otherwise resize
4225         if same_host and instance_type.id == instance['instance_type_id']:
4226             # check driver whether support migrate to same host
4227             if not self.driver.capabilities.get(
4228                     'supports_migrate_to_same_host', False):
4229                 raise exception.UnableToMigrateToSelf(
4230                     instance_id=instance.uuid, host=self.host)
4231 
4232         # NOTE(danms): Stash the new instance_type to avoid having to
4233         # look it up in the database later
4234         instance.new_flavor = instance_type
4235         # NOTE(mriedem): Stash the old vm_state so we can set the
4236         # resized/reverted instance back to the same state later.
4237         vm_state = instance.vm_state
4238         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4239         instance.system_metadata['old_vm_state'] = vm_state
4240         instance.save()
4241 
4242         limits = filter_properties.get('limits', {})
4243         with self.rt.resize_claim(context, instance, instance_type, node,
4244                                   migration, image_meta=image,
4245                                   limits=limits) as claim:
4246             LOG.info('Migrating', instance=instance)
4247             # RPC cast to the source host to start the actual resize/migration.
4248             self.compute_rpcapi.resize_instance(
4249                     context, instance, claim.migration, image,
4250                     instance_type, clean_shutdown)
4251 
4252     def _send_prep_resize_notifications(
4253             self, context, instance, phase, flavor):
4254         """Send "resize.prep.*" notifications.
4255 
4256         :param context: nova auth request context
4257         :param instance: The instance being resized
4258         :param phase: The phase of the action (NotificationPhase enum)
4259         :param flavor: The (new) flavor for the resize (same as existing
4260             instance.flavor for a cold migration)
4261         """
4262         # Only send notify_usage_exists if it's the "start" phase.
4263         if phase == fields.NotificationPhase.START:
4264             compute_utils.notify_usage_exists(
4265                 self.notifier, context, instance, self.host,
4266                 current_period=True)
4267 
4268         # Send extra usage info about the flavor if it's the "end" phase for
4269         # the legacy unversioned notification.
4270         extra_usage_info = None
4271         if phase == fields.NotificationPhase.END:
4272             extra_usage_info = dict(
4273                 new_instance_type=flavor.name,
4274                 new_instance_type_id=flavor.id)
4275         self._notify_about_instance_usage(
4276             context, instance, "resize.prep.%s" % phase,
4277             extra_usage_info=extra_usage_info)
4278 
4279         # Send the versioned notification.
4280         compute_utils.notify_about_resize_prep_instance(
4281             context, instance, self.host, phase, flavor)
4282 
4283     @wrap_exception()
4284     @reverts_task_state
4285     @wrap_instance_event(prefix='compute')
4286     @wrap_instance_fault
4287     def prep_resize(self, context, image, instance, instance_type,
4288                     request_spec, filter_properties, node,
4289                     clean_shutdown, migration, host_list):
4290         """Initiates the process of moving a running instance to another host.
4291 
4292         Possibly changes the VCPU, RAM and disk size in the process.
4293 
4294         This is initiated from conductor and runs on the destination host.
4295 
4296         The main purpose of this method is performing some checks on the
4297         destination host and making a claim for resources. If the claim fails
4298         then a reschedule to another host may be attempted which involves
4299         calling back to conductor to start the process over again.
4300         """
4301         if node is None:
4302             node = self._get_nodename(instance, refresh=True)
4303 
4304         with self._error_out_instance_on_exception(context, instance), \
4305                  errors_out_migration_ctxt(migration):
4306             self._send_prep_resize_notifications(
4307                 context, instance, fields.NotificationPhase.START,
4308                 instance_type)
4309             try:
4310                 self._prep_resize(context, image, instance,
4311                                   instance_type, filter_properties,
4312                                   node, migration, clean_shutdown)
4313             except Exception:
4314                 # Since we hit a failure, we're either rescheduling or dead
4315                 # and either way we need to cleanup any allocations created
4316                 # by the scheduler for the destination node.
4317                 self._revert_allocation(context, instance, migration)
4318                 # try to re-schedule the resize elsewhere:
4319                 exc_info = sys.exc_info()
4320                 self._reschedule_resize_or_reraise(context, instance,
4321                         exc_info, instance_type, request_spec,
4322                         filter_properties, host_list)
4323             finally:
4324                 self._send_prep_resize_notifications(
4325                     context, instance, fields.NotificationPhase.END,
4326                     instance_type)
4327 
4328     def _reschedule_resize_or_reraise(self, context, instance, exc_info,
4329             instance_type, request_spec, filter_properties, host_list):
4330         """Try to re-schedule the resize or re-raise the original error to
4331         error out the instance.
4332         """
4333         if not filter_properties:
4334             filter_properties = {}
4335 
4336         rescheduled = False
4337         instance_uuid = instance.uuid
4338 
4339         try:
4340             reschedule_method = self.compute_task_api.resize_instance
4341             scheduler_hint = dict(filter_properties=filter_properties)
4342             method_args = (instance, None, scheduler_hint, instance_type)
4343             task_state = task_states.RESIZE_PREP
4344 
4345             rescheduled = self._reschedule(context, request_spec,
4346                     filter_properties, instance, reschedule_method,
4347                     method_args, task_state, exc_info, host_list=host_list)
4348         except Exception as error:
4349             rescheduled = False
4350             LOG.exception("Error trying to reschedule",
4351                           instance_uuid=instance_uuid)
4352             compute_utils.add_instance_fault_from_exc(context,
4353                     instance, error,
4354                     exc_info=sys.exc_info())
4355             self._notify_about_instance_usage(context, instance,
4356                     'resize.error', fault=error)
4357             compute_utils.notify_about_instance_action(
4358                 context, instance, self.host,
4359                 action=fields.NotificationAction.RESIZE,
4360                 phase=fields.NotificationPhase.ERROR,
4361                 exception=error,
4362                 tb=','.join(traceback.format_exception(*exc_info)))
4363         if rescheduled:
4364             self._log_original_error(exc_info, instance_uuid)
4365             compute_utils.add_instance_fault_from_exc(context,
4366                     instance, exc_info[1], exc_info=exc_info)
4367             self._notify_about_instance_usage(context, instance,
4368                     'resize.error', fault=exc_info[1])
4369             compute_utils.notify_about_instance_action(
4370                 context, instance, self.host,
4371                 action=fields.NotificationAction.RESIZE,
4372                 phase=fields.NotificationPhase.ERROR,
4373                 exception=exc_info[1],
4374                 tb=','.join(traceback.format_exception(*exc_info)))
4375         else:
4376             # not re-scheduling
4377             six.reraise(*exc_info)
4378 
4379     @wrap_exception()
4380     @reverts_task_state
4381     @wrap_instance_event(prefix='compute')
4382     @wrap_instance_fault
4383     def resize_instance(self, context, instance, image,
4384                         migration, instance_type, clean_shutdown):
4385         """Starts the migration of a running instance to another host.
4386 
4387         This is initiated from the destination host's ``prep_resize`` routine
4388         and runs on the source host.
4389         """
4390         try:
4391             self._resize_instance(context, instance, image, migration,
4392                                   instance_type, clean_shutdown)
4393         except Exception:
4394             with excutils.save_and_reraise_exception():
4395                 self._revert_allocation(context, instance, migration)
4396 
4397     def _resize_instance(self, context, instance, image,
4398                          migration, instance_type, clean_shutdown):
4399         with self._error_out_instance_on_exception(context, instance), \
4400              errors_out_migration_ctxt(migration):
4401             network_info = self.network_api.get_instance_nw_info(context,
4402                                                                  instance)
4403 
4404             migration.status = 'migrating'
4405             with migration.obj_as_admin():
4406                 migration.save()
4407 
4408             instance.task_state = task_states.RESIZE_MIGRATING
4409             instance.save(expected_task_state=task_states.RESIZE_PREP)
4410 
4411             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4412                     context, instance.uuid)
4413             self._send_resize_instance_notifications(
4414                 context, instance, bdms, network_info,
4415                 fields.NotificationPhase.START)
4416 
4417             block_device_info = self._get_instance_block_device_info(
4418                                 context, instance, bdms=bdms)
4419 
4420             timeout, retry_interval = self._get_power_off_values(context,
4421                                             instance, clean_shutdown)
4422             disk_info = self.driver.migrate_disk_and_power_off(
4423                     context, instance, migration.dest_host,
4424                     instance_type, network_info,
4425                     block_device_info,
4426                     timeout, retry_interval)
4427 
4428             self._terminate_volume_connections(context, instance, bdms)
4429 
4430             migration_p = obj_base.obj_to_primitive(migration)
4431             self.network_api.migrate_instance_start(context,
4432                                                     instance,
4433                                                     migration_p)
4434 
4435             migration.status = 'post-migrating'
4436             with migration.obj_as_admin():
4437                 migration.save()
4438 
4439             instance.host = migration.dest_compute
4440             instance.node = migration.dest_node
4441             instance.task_state = task_states.RESIZE_MIGRATED
4442             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4443 
4444             # RPC cast to the destination host to finish the resize/migration.
4445             self.compute_rpcapi.finish_resize(context, instance,
4446                     migration, image, disk_info, migration.dest_compute)
4447 
4448         self._send_resize_instance_notifications(
4449             context, instance, bdms, network_info,
4450             fields.NotificationPhase.END)
4451         self.instance_events.clear_events_for_instance(instance)
4452 
4453     def _send_resize_instance_notifications(
4454             self, context, instance, bdms, network_info, phase):
4455         """Send "resize.(start|end)" notifications.
4456 
4457         :param context: nova auth request context
4458         :param instance: The instance being resized
4459         :param bdms: BlockDeviceMappingList for the BDMs associated with the
4460             instance
4461         :param network_info: NetworkInfo for the instance info cache of ports
4462         :param phase: The phase of the action (NotificationPhase enum, either
4463             ``start`` or ``end``)
4464         """
4465         action = fields.NotificationAction.RESIZE
4466         # Send the legacy unversioned notification.
4467         self._notify_about_instance_usage(
4468             context, instance, "%s.%s" % (action, phase),
4469             network_info=network_info)
4470         # Send the versioned notification.
4471         compute_utils.notify_about_instance_action(
4472             context, instance, self.host, action=action, phase=phase,
4473             bdms=bdms)
4474 
4475     def _terminate_volume_connections(self, context, instance, bdms):
4476         connector = None
4477         for bdm in bdms:
4478             if bdm.is_volume:
4479                 if bdm.attachment_id:
4480                     # NOTE(jdg): So here's the thing, the idea behind the new
4481                     # attach API's was to have a new code fork/path that we
4482                     # followed, we're not going to do that so we have to do
4483                     # some extra work in here to make it *behave* just like the
4484                     # old code. Cinder doesn't allow disconnect/reconnect (you
4485                     # just delete the attachment and get a new one)
4486                     # attachments in the new attach code so we have to do
4487                     # a delete and create without a connector (reserve),
4488                     # in other words, beware
4489                     attachment_id = self.volume_api.attachment_create(
4490                         context, bdm.volume_id, instance.uuid)['id']
4491                     self.volume_api.attachment_delete(context,
4492                                                       bdm.attachment_id)
4493                     bdm.attachment_id = attachment_id
4494                     bdm.save()
4495 
4496                 else:
4497                     if connector is None:
4498                         connector = self.driver.get_volume_connector(instance)
4499                     self.volume_api.terminate_connection(context,
4500                                                          bdm.volume_id,
4501                                                          connector)
4502 
4503     @staticmethod
4504     def _set_instance_info(instance, instance_type):
4505         instance.instance_type_id = instance_type.id
4506         instance.memory_mb = instance_type.memory_mb
4507         instance.vcpus = instance_type.vcpus
4508         instance.root_gb = instance_type.root_gb
4509         instance.ephemeral_gb = instance_type.ephemeral_gb
4510         instance.flavor = instance_type
4511 
4512     def _update_volume_attachments(self, context, instance, bdms):
4513         """Updates volume attachments using the virt driver host connector.
4514 
4515         :param context: nova.context.RequestContext - user request context
4516         :param instance: nova.objects.Instance
4517         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4518                      device mappings for the given instance
4519         """
4520         if bdms:
4521             connector = None
4522             for bdm in bdms:
4523                 if bdm.is_volume and bdm.attachment_id:
4524                     if connector is None:
4525                         connector = self.driver.get_volume_connector(instance)
4526                     self.volume_api.attachment_update(
4527                         context, bdm.attachment_id, connector, bdm.device_name)
4528 
4529     def _complete_volume_attachments(self, context, bdms):
4530         """Completes volume attachments for the instance
4531 
4532         :param context: nova.context.RequestContext - user request context
4533         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4534                      device mappings for the given instance
4535         """
4536         if bdms:
4537             for bdm in bdms:
4538                 if bdm.is_volume and bdm.attachment_id:
4539                     self.volume_api.attachment_complete(
4540                         context, bdm.attachment_id)
4541 
4542     def _finish_resize(self, context, instance, migration, disk_info,
4543                        image_meta, bdms):
4544         resize_instance = False
4545         old_instance_type_id = migration['old_instance_type_id']
4546         new_instance_type_id = migration['new_instance_type_id']
4547         old_instance_type = instance.get_flavor()
4548         # NOTE(mriedem): Get the old_vm_state so we know if we should
4549         # power on the instance. If old_vm_state is not set we need to default
4550         # to ACTIVE for backwards compatibility
4551         old_vm_state = instance.system_metadata.get('old_vm_state',
4552                                                     vm_states.ACTIVE)
4553         instance.old_flavor = old_instance_type
4554 
4555         if old_instance_type_id != new_instance_type_id:
4556             instance_type = instance.get_flavor('new')
4557             self._set_instance_info(instance, instance_type)
4558             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4559                 if old_instance_type[key] != instance_type[key]:
4560                     resize_instance = True
4561                     break
4562         instance.apply_migration_context()
4563 
4564         # NOTE(tr3buchet): setup networks on destination host
4565         self.network_api.setup_networks_on_host(context, instance,
4566                                                 migration['dest_compute'])
4567 
4568         migration_p = obj_base.obj_to_primitive(migration)
4569         self.network_api.migrate_instance_finish(context,
4570                                                  instance,
4571                                                  migration_p)
4572 
4573         network_info = self.network_api.get_instance_nw_info(context, instance)
4574 
4575         instance.task_state = task_states.RESIZE_FINISH
4576         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4577 
4578         self._send_finish_resize_notifications(
4579             context, instance, bdms, network_info,
4580             fields.NotificationPhase.START)
4581 
4582         # We need to update any volume attachments using the destination
4583         # host connector so that we can update the BDM.connection_info
4584         # before calling driver.finish_migration otherwise the driver
4585         # won't know how to connect the volumes to this host.
4586         # Note that _get_instance_block_device_info with
4587         # refresh_conn_info=True will update the BDM.connection_info value
4588         # in the database so we must do this before calling that method.
4589         self._update_volume_attachments(context, instance, bdms)
4590 
4591         block_device_info = self._get_instance_block_device_info(
4592             context, instance, refresh_conn_info=True, bdms=bdms)
4593 
4594         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4595         # automatically power on the instance after it's migrated
4596         power_on = old_vm_state != vm_states.STOPPED
4597 
4598         try:
4599             self.driver.finish_migration(context, migration, instance,
4600                                          disk_info,
4601                                          network_info,
4602                                          image_meta, resize_instance,
4603                                          block_device_info, power_on)
4604         except Exception:
4605             with excutils.save_and_reraise_exception():
4606                 if old_instance_type_id != new_instance_type_id:
4607                     self._set_instance_info(instance,
4608                                             old_instance_type)
4609 
4610         # Now complete any volume attachments that were previously updated.
4611         self._complete_volume_attachments(context, bdms)
4612 
4613         migration.status = 'finished'
4614         with migration.obj_as_admin():
4615             migration.save()
4616 
4617         instance.vm_state = vm_states.RESIZED
4618         instance.task_state = None
4619         instance.launched_at = timeutils.utcnow()
4620         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4621 
4622         return network_info
4623 
4624     @wrap_exception()
4625     @reverts_task_state
4626     @wrap_instance_event(prefix='compute')
4627     @wrap_instance_fault
4628     def finish_resize(self, context, disk_info, image, instance,
4629                       migration):
4630         """Completes the migration process.
4631 
4632         Sets up the newly transferred disk and turns on the instance at its
4633         new host machine.
4634 
4635         """
4636         try:
4637             self._finish_resize_helper(context, disk_info, image, instance,
4638                                        migration)
4639         except Exception:
4640             with excutils.save_and_reraise_exception():
4641                 self._revert_allocation(context, instance, migration)
4642 
4643     def _finish_resize_helper(self, context, disk_info, image, instance,
4644                               migration):
4645         """Completes the migration process.
4646 
4647         The caller must revert the instance's allocations if the migration
4648         process failed.
4649         """
4650         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4651             context, instance.uuid)
4652 
4653         with self._error_out_instance_on_exception(context, instance), \
4654              errors_out_migration_ctxt(migration):
4655             image_meta = objects.ImageMeta.from_dict(image)
4656             network_info = self._finish_resize(context, instance, migration,
4657                                                disk_info, image_meta, bdms)
4658 
4659         # TODO(melwitt): We should clean up instance console tokens here. The
4660         # instance is on a new host and will need to establish a new console
4661         # connection.
4662         self._update_scheduler_instance_info(context, instance)
4663         self._send_finish_resize_notifications(
4664             context, instance, bdms, network_info,
4665             fields.NotificationPhase.END)
4666 
4667     def _send_finish_resize_notifications(
4668             self, context, instance, bdms, network_info, phase):
4669         """Send notifications for the finish_resize flow.
4670 
4671         :param context: nova auth request context
4672         :param instance: The instance being resized
4673         :param bdms: BlockDeviceMappingList for the BDMs associated with the
4674             instance
4675         :param network_info: NetworkInfo for the instance info cache of ports
4676         :param phase: The phase of the action (NotificationPhase enum, either
4677             ``start`` or ``end``)
4678         """
4679         # Send the legacy unversioned notification.
4680         self._notify_about_instance_usage(
4681             context, instance, "finish_resize.%s" % phase,
4682             network_info=network_info)
4683         # Send the versioned notification.
4684         compute_utils.notify_about_instance_action(
4685             context, instance, self.host,
4686             action=fields.NotificationAction.RESIZE_FINISH, phase=phase,
4687             bdms=bdms)
4688 
4689     @wrap_exception()
4690     @wrap_instance_fault
4691     def add_fixed_ip_to_instance(self, context, network_id, instance):
4692         """Calls network_api to add new fixed_ip to instance
4693         then injects the new network info and resets instance networking.
4694 
4695         """
4696         self._notify_about_instance_usage(
4697                 context, instance, "create_ip.start")
4698 
4699         network_info = self.network_api.add_fixed_ip_to_instance(context,
4700                                                                  instance,
4701                                                                  network_id)
4702         self._inject_network_info(context, instance, network_info)
4703         self.reset_network(context, instance)
4704 
4705         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4706         instance.updated_at = timeutils.utcnow()
4707         instance.save()
4708 
4709         self._notify_about_instance_usage(
4710             context, instance, "create_ip.end", network_info=network_info)
4711 
4712     @wrap_exception()
4713     @wrap_instance_fault
4714     def remove_fixed_ip_from_instance(self, context, address, instance):
4715         """Calls network_api to remove existing fixed_ip from instance
4716         by injecting the altered network info and resetting
4717         instance networking.
4718         """
4719         self._notify_about_instance_usage(
4720                 context, instance, "delete_ip.start")
4721 
4722         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4723                                                                       instance,
4724                                                                       address)
4725         self._inject_network_info(context, instance, network_info)
4726         self.reset_network(context, instance)
4727 
4728         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4729         instance.updated_at = timeutils.utcnow()
4730         instance.save()
4731 
4732         self._notify_about_instance_usage(
4733             context, instance, "delete_ip.end", network_info=network_info)
4734 
4735     @wrap_exception()
4736     @reverts_task_state
4737     @wrap_instance_event(prefix='compute')
4738     @wrap_instance_fault
4739     def pause_instance(self, context, instance):
4740         """Pause an instance on this host."""
4741         context = context.elevated()
4742         LOG.info('Pausing', instance=instance)
4743         self._notify_about_instance_usage(context, instance, 'pause.start')
4744         compute_utils.notify_about_instance_action(context, instance,
4745                self.host, action=fields.NotificationAction.PAUSE,
4746                phase=fields.NotificationPhase.START)
4747         self.driver.pause(instance)
4748         instance.power_state = self._get_power_state(context, instance)
4749         instance.vm_state = vm_states.PAUSED
4750         instance.task_state = None
4751         instance.save(expected_task_state=task_states.PAUSING)
4752         self._notify_about_instance_usage(context, instance, 'pause.end')
4753         compute_utils.notify_about_instance_action(context, instance,
4754                self.host, action=fields.NotificationAction.PAUSE,
4755                phase=fields.NotificationPhase.END)
4756 
4757     @wrap_exception()
4758     @reverts_task_state
4759     @wrap_instance_event(prefix='compute')
4760     @wrap_instance_fault
4761     def unpause_instance(self, context, instance):
4762         """Unpause a paused instance on this host."""
4763         context = context.elevated()
4764         LOG.info('Unpausing', instance=instance)
4765         self._notify_about_instance_usage(context, instance, 'unpause.start')
4766         compute_utils.notify_about_instance_action(context, instance,
4767             self.host, action=fields.NotificationAction.UNPAUSE,
4768             phase=fields.NotificationPhase.START)
4769         self.driver.unpause(instance)
4770         instance.power_state = self._get_power_state(context, instance)
4771         instance.vm_state = vm_states.ACTIVE
4772         instance.task_state = None
4773         instance.save(expected_task_state=task_states.UNPAUSING)
4774         self._notify_about_instance_usage(context, instance, 'unpause.end')
4775         compute_utils.notify_about_instance_action(context, instance,
4776             self.host, action=fields.NotificationAction.UNPAUSE,
4777             phase=fields.NotificationPhase.END)
4778 
4779     @wrap_exception()
4780     def host_power_action(self, context, action):
4781         """Reboots, shuts down or powers up the host."""
4782         return self.driver.host_power_action(action)
4783 
4784     @wrap_exception()
4785     def host_maintenance_mode(self, context, host, mode):
4786         """Start/Stop host maintenance window. On start, it triggers
4787         guest VMs evacuation.
4788         """
4789         return self.driver.host_maintenance_mode(host, mode)
4790 
4791     @wrap_exception()
4792     def set_host_enabled(self, context, enabled):
4793         """Sets the specified host's ability to accept new instances."""
4794         return self.driver.set_host_enabled(enabled)
4795 
4796     @wrap_exception()
4797     def get_host_uptime(self, context):
4798         """Returns the result of calling "uptime" on the target host."""
4799         return self.driver.get_host_uptime()
4800 
4801     @wrap_exception()
4802     @wrap_instance_fault
4803     def get_diagnostics(self, context, instance):
4804         """Retrieve diagnostics for an instance on this host."""
4805         current_power_state = self._get_power_state(context, instance)
4806         if current_power_state == power_state.RUNNING:
4807             LOG.info("Retrieving diagnostics", instance=instance)
4808             return self.driver.get_diagnostics(instance)
4809         else:
4810             raise exception.InstanceInvalidState(
4811                 attr='power state',
4812                 instance_uuid=instance.uuid,
4813                 state=power_state.STATE_MAP[instance.power_state],
4814                 method='get_diagnostics')
4815 
4816     @wrap_exception()
4817     @wrap_instance_fault
4818     def get_instance_diagnostics(self, context, instance):
4819         """Retrieve diagnostics for an instance on this host."""
4820         current_power_state = self._get_power_state(context, instance)
4821         if current_power_state == power_state.RUNNING:
4822             LOG.info("Retrieving diagnostics", instance=instance)
4823             return self.driver.get_instance_diagnostics(instance)
4824         else:
4825             raise exception.InstanceInvalidState(
4826                 attr='power state',
4827                 instance_uuid=instance.uuid,
4828                 state=power_state.STATE_MAP[instance.power_state],
4829                 method='get_diagnostics')
4830 
4831     @wrap_exception()
4832     @reverts_task_state
4833     @wrap_instance_event(prefix='compute')
4834     @wrap_instance_fault
4835     def suspend_instance(self, context, instance):
4836         """Suspend the given instance."""
4837         context = context.elevated()
4838 
4839         # Store the old state
4840         instance.system_metadata['old_vm_state'] = instance.vm_state
4841         self._notify_about_instance_usage(context, instance, 'suspend.start')
4842         compute_utils.notify_about_instance_action(context, instance,
4843                 self.host, action=fields.NotificationAction.SUSPEND,
4844                 phase=fields.NotificationPhase.START)
4845         with self._error_out_instance_on_exception(context, instance,
4846              instance_state=instance.vm_state):
4847             self.driver.suspend(context, instance)
4848         instance.power_state = self._get_power_state(context, instance)
4849         instance.vm_state = vm_states.SUSPENDED
4850         instance.task_state = None
4851         instance.save(expected_task_state=task_states.SUSPENDING)
4852         self._notify_about_instance_usage(context, instance, 'suspend.end')
4853         compute_utils.notify_about_instance_action(context, instance,
4854                 self.host, action=fields.NotificationAction.SUSPEND,
4855                 phase=fields.NotificationPhase.END)
4856 
4857     @wrap_exception()
4858     @reverts_task_state
4859     @wrap_instance_event(prefix='compute')
4860     @wrap_instance_fault
4861     def resume_instance(self, context, instance):
4862         """Resume the given suspended instance."""
4863         context = context.elevated()
4864         LOG.info('Resuming', instance=instance)
4865 
4866         self._notify_about_instance_usage(context, instance, 'resume.start')
4867 
4868         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4869             context, instance.uuid)
4870         block_device_info = self._get_instance_block_device_info(
4871             context, instance, bdms=bdms)
4872 
4873         compute_utils.notify_about_instance_action(context, instance,
4874             self.host, action=fields.NotificationAction.RESUME,
4875             phase=fields.NotificationPhase.START, bdms=bdms)
4876 
4877         network_info = self.network_api.get_instance_nw_info(context, instance)
4878 
4879         with self._error_out_instance_on_exception(context, instance,
4880              instance_state=instance.vm_state):
4881             self.driver.resume(context, instance, network_info,
4882                                block_device_info)
4883 
4884         instance.power_state = self._get_power_state(context, instance)
4885 
4886         # We default to the ACTIVE state for backwards compatibility
4887         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4888                                                          vm_states.ACTIVE)
4889 
4890         instance.task_state = None
4891         instance.save(expected_task_state=task_states.RESUMING)
4892         self._notify_about_instance_usage(context, instance, 'resume.end')
4893         compute_utils.notify_about_instance_action(context, instance,
4894             self.host, action=fields.NotificationAction.RESUME,
4895             phase=fields.NotificationPhase.END, bdms=bdms)
4896 
4897     @wrap_exception()
4898     @reverts_task_state
4899     @wrap_instance_event(prefix='compute')
4900     @wrap_instance_fault
4901     def shelve_instance(self, context, instance, image_id,
4902                         clean_shutdown):
4903         """Shelve an instance.
4904 
4905         This should be used when you want to take a snapshot of the instance.
4906         It also adds system_metadata that can be used by a periodic task to
4907         offload the shelved instance after a period of time.
4908 
4909         :param context: request context
4910         :param instance: an Instance object
4911         :param image_id: an image id to snapshot to.
4912         :param clean_shutdown: give the GuestOS a chance to stop
4913         """
4914 
4915         @utils.synchronized(instance.uuid)
4916         def do_shelve_instance():
4917             self._shelve_instance(context, instance, image_id, clean_shutdown)
4918         do_shelve_instance()
4919 
4920     def _shelve_instance(self, context, instance, image_id,
4921                          clean_shutdown):
4922         LOG.info('Shelving', instance=instance)
4923         offload = CONF.shelved_offload_time == 0
4924         if offload:
4925             # Get the BDMs early so we can pass them into versioned
4926             # notifications since _shelve_offload_instance needs the
4927             # BDMs anyway.
4928             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4929                 context, instance.uuid)
4930         else:
4931             bdms = None
4932         compute_utils.notify_usage_exists(self.notifier, context, instance,
4933                                           self.host, current_period=True)
4934         self._notify_about_instance_usage(context, instance, 'shelve.start')
4935         compute_utils.notify_about_instance_action(context, instance,
4936                 self.host, action=fields.NotificationAction.SHELVE,
4937                 phase=fields.NotificationPhase.START, bdms=bdms)
4938 
4939         def update_task_state(task_state, expected_state=task_states.SHELVING):
4940             shelving_state_map = {
4941                     task_states.IMAGE_PENDING_UPLOAD:
4942                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4943                     task_states.IMAGE_UPLOADING:
4944                         task_states.SHELVING_IMAGE_UPLOADING,
4945                     task_states.SHELVING: task_states.SHELVING}
4946             task_state = shelving_state_map[task_state]
4947             expected_state = shelving_state_map[expected_state]
4948             instance.task_state = task_state
4949             instance.save(expected_task_state=expected_state)
4950         # Do not attempt a clean shutdown of a paused guest since some
4951         # hypervisors will fail the clean shutdown if the guest is not
4952         # running.
4953         if instance.power_state == power_state.PAUSED:
4954             clean_shutdown = False
4955         self._power_off_instance(context, instance, clean_shutdown)
4956         self.driver.snapshot(context, instance, image_id, update_task_state)
4957 
4958         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4959         instance.system_metadata['shelved_image_id'] = image_id
4960         instance.system_metadata['shelved_host'] = self.host
4961         instance.vm_state = vm_states.SHELVED
4962         instance.task_state = None
4963         if CONF.shelved_offload_time == 0:
4964             instance.task_state = task_states.SHELVING_OFFLOADING
4965         instance.power_state = self._get_power_state(context, instance)
4966         instance.save(expected_task_state=[
4967                 task_states.SHELVING,
4968                 task_states.SHELVING_IMAGE_UPLOADING])
4969 
4970         self._notify_about_instance_usage(context, instance, 'shelve.end')
4971         compute_utils.notify_about_instance_action(context, instance,
4972                 self.host, action=fields.NotificationAction.SHELVE,
4973                 phase=fields.NotificationPhase.END, bdms=bdms)
4974 
4975         if offload:
4976             self._shelve_offload_instance(context, instance,
4977                                           clean_shutdown=False, bdms=bdms)
4978 
4979     @wrap_exception()
4980     @reverts_task_state
4981     @wrap_instance_event(prefix='compute')
4982     @wrap_instance_fault
4983     def shelve_offload_instance(self, context, instance, clean_shutdown):
4984         """Remove a shelved instance from the hypervisor.
4985 
4986         This frees up those resources for use by other instances, but may lead
4987         to slower unshelve times for this instance.  This method is used by
4988         volume backed instances since restoring them doesn't involve the
4989         potentially large download of an image.
4990 
4991         :param context: request context
4992         :param instance: nova.objects.instance.Instance
4993         :param clean_shutdown: give the GuestOS a chance to stop
4994         """
4995 
4996         @utils.synchronized(instance.uuid)
4997         def do_shelve_offload_instance():
4998             self._shelve_offload_instance(context, instance, clean_shutdown)
4999         do_shelve_offload_instance()
5000 
5001     def _shelve_offload_instance(self, context, instance, clean_shutdown,
5002                                  bdms=None):
5003         LOG.info('Shelve offloading', instance=instance)
5004         if bdms is None:
5005             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5006                 context, instance.uuid)
5007         self._notify_about_instance_usage(context, instance,
5008                 'shelve_offload.start')
5009         compute_utils.notify_about_instance_action(context, instance,
5010                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
5011                 phase=fields.NotificationPhase.START, bdms=bdms)
5012 
5013         self._power_off_instance(context, instance, clean_shutdown)
5014         current_power_state = self._get_power_state(context, instance)
5015 
5016         self.network_api.cleanup_instance_network_on_host(context, instance,
5017                                                           instance.host)
5018         network_info = self.network_api.get_instance_nw_info(context, instance)
5019 
5020         block_device_info = self._get_instance_block_device_info(context,
5021                                                                  instance,
5022                                                                  bdms=bdms)
5023         self.driver.destroy(context, instance, network_info,
5024                 block_device_info)
5025 
5026         # the instance is going to be removed from the host so we want to
5027         # terminate all the connections with the volume server and the host
5028         self._terminate_volume_connections(context, instance, bdms)
5029 
5030         # Free up the resource allocations in the placement service.
5031         # This should happen *before* the vm_state is changed to
5032         # SHELVED_OFFLOADED in case client-side code is polling the API to
5033         # schedule more instances (or unshelve) once this server is offloaded.
5034         self.rt.delete_allocation_for_shelve_offloaded_instance(context,
5035                                                                 instance)
5036 
5037         instance.power_state = current_power_state
5038         # NOTE(mriedem): The vm_state has to be set before updating the
5039         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
5040         # values cannot be nulled out until after updating the resource tracker
5041         # though.
5042         instance.vm_state = vm_states.SHELVED_OFFLOADED
5043         instance.task_state = None
5044         instance.save(expected_task_state=[task_states.SHELVING,
5045                                            task_states.SHELVING_OFFLOADING])
5046 
5047         # NOTE(ndipanov): Free resources from the resource tracker
5048         self._update_resource_tracker(context, instance)
5049 
5050         # NOTE(sfinucan): RPC calls should no longer be attempted against this
5051         # instance, so ensure any calls result in errors
5052         self._nil_out_instance_obj_host_and_node(instance)
5053         instance.save(expected_task_state=None)
5054 
5055         # TODO(melwitt): We should clean up instance console tokens here. The
5056         # instance has no host at this point and will need to establish a new
5057         # console connection in the future after it is unshelved.
5058         self._delete_scheduler_instance_info(context, instance.uuid)
5059         self._notify_about_instance_usage(context, instance,
5060                 'shelve_offload.end')
5061         compute_utils.notify_about_instance_action(context, instance,
5062                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
5063                 phase=fields.NotificationPhase.END, bdms=bdms)
5064 
5065     @wrap_exception()
5066     @reverts_task_state
5067     @wrap_instance_event(prefix='compute')
5068     @wrap_instance_fault
5069     def unshelve_instance(self, context, instance, image,
5070                           filter_properties, node):
5071         """Unshelve the instance.
5072 
5073         :param context: request context
5074         :param instance: a nova.objects.instance.Instance object
5075         :param image: an image to build from.  If None we assume a
5076             volume backed instance.
5077         :param filter_properties: dict containing limits, retry info etc.
5078         :param node: target compute node
5079         """
5080         if filter_properties is None:
5081             filter_properties = {}
5082 
5083         @utils.synchronized(instance.uuid)
5084         def do_unshelve_instance():
5085             self._unshelve_instance(context, instance, image,
5086                                     filter_properties, node)
5087         do_unshelve_instance()
5088 
5089     def _unshelve_instance_key_scrub(self, instance):
5090         """Remove data from the instance that may cause side effects."""
5091         cleaned_keys = dict(
5092                 key_data=instance.key_data,
5093                 auto_disk_config=instance.auto_disk_config)
5094         instance.key_data = None
5095         instance.auto_disk_config = False
5096         return cleaned_keys
5097 
5098     def _unshelve_instance_key_restore(self, instance, keys):
5099         """Restore previously scrubbed keys before saving the instance."""
5100         instance.update(keys)
5101 
5102     def _unshelve_instance(self, context, instance, image, filter_properties,
5103                            node):
5104         LOG.info('Unshelving', instance=instance)
5105         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5106                 context, instance.uuid)
5107 
5108         self._notify_about_instance_usage(context, instance, 'unshelve.start')
5109         compute_utils.notify_about_instance_action(context, instance,
5110                 self.host, action=fields.NotificationAction.UNSHELVE,
5111                 phase=fields.NotificationPhase.START, bdms=bdms)
5112 
5113         instance.task_state = task_states.SPAWNING
5114         instance.save()
5115 
5116         block_device_info = self._prep_block_device(context, instance, bdms)
5117         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
5118 
5119         if node is None:
5120             node = self._get_nodename(instance)
5121 
5122         limits = filter_properties.get('limits', {})
5123 
5124         allocations = self.reportclient.get_allocations_for_consumer(
5125             context, instance.uuid)
5126 
5127         shelved_image_ref = instance.image_ref
5128         if image:
5129             instance.image_ref = image['id']
5130             image_meta = objects.ImageMeta.from_dict(image)
5131         else:
5132             image_meta = objects.ImageMeta.from_dict(
5133                 utils.get_image_from_system_metadata(
5134                     instance.system_metadata))
5135 
5136         self.network_api.setup_instance_network_on_host(context, instance,
5137                                                         self.host)
5138         network_info = self.network_api.get_instance_nw_info(context, instance)
5139         try:
5140             with self.rt.instance_claim(context, instance, node, limits):
5141                 self.driver.spawn(context, instance, image_meta,
5142                                   injected_files=[],
5143                                   admin_password=None,
5144                                   allocations=allocations,
5145                                   network_info=network_info,
5146                                   block_device_info=block_device_info)
5147         except Exception:
5148             with excutils.save_and_reraise_exception(logger=LOG):
5149                 LOG.exception('Instance failed to spawn',
5150                               instance=instance)
5151                 # Cleanup allocations created by the scheduler on this host
5152                 # since we failed to spawn the instance. We do this both if
5153                 # the instance claim failed with ComputeResourcesUnavailable
5154                 # or if we did claim but the spawn failed, because aborting the
5155                 # instance claim will not remove the allocations.
5156                 self.reportclient.delete_allocation_for_instance(context,
5157                                                                  instance.uuid)
5158                 # FIXME: Umm, shouldn't we be rolling back port bindings too?
5159                 self._terminate_volume_connections(context, instance, bdms)
5160                 # The reverts_task_state decorator on unshelve_instance will
5161                 # eventually save these updates.
5162                 self._nil_out_instance_obj_host_and_node(instance)
5163 
5164         if image:
5165             instance.image_ref = shelved_image_ref
5166             self._delete_snapshot_of_shelved_instance(context, instance,
5167                                                       image['id'])
5168 
5169         self._unshelve_instance_key_restore(instance, scrubbed_keys)
5170         self._update_instance_after_spawn(context, instance)
5171         # Delete system_metadata for a shelved instance
5172         compute_utils.remove_shelved_keys_from_system_metadata(instance)
5173 
5174         instance.save(expected_task_state=task_states.SPAWNING)
5175         self._update_scheduler_instance_info(context, instance)
5176         self._notify_about_instance_usage(context, instance, 'unshelve.end')
5177         compute_utils.notify_about_instance_action(context, instance,
5178                 self.host, action=fields.NotificationAction.UNSHELVE,
5179                 phase=fields.NotificationPhase.END, bdms=bdms)
5180 
5181     @messaging.expected_exceptions(NotImplementedError)
5182     @wrap_instance_fault
5183     def reset_network(self, context, instance):
5184         """Reset networking on the given instance."""
5185         LOG.debug('Reset network', instance=instance)
5186         self.driver.reset_network(instance)
5187 
5188     def _inject_network_info(self, context, instance, network_info):
5189         """Inject network info for the given instance."""
5190         LOG.debug('Inject network info', instance=instance)
5191         LOG.debug('network_info to inject: |%s|', network_info,
5192                   instance=instance)
5193 
5194         self.driver.inject_network_info(instance,
5195                                         network_info)
5196 
5197     @wrap_instance_fault
5198     def inject_network_info(self, context, instance):
5199         """Inject network info, but don't return the info."""
5200         network_info = self.network_api.get_instance_nw_info(context, instance)
5201         self._inject_network_info(context, instance, network_info)
5202 
5203     @messaging.expected_exceptions(NotImplementedError,
5204                                    exception.ConsoleNotAvailable,
5205                                    exception.InstanceNotFound)
5206     @wrap_exception()
5207     @wrap_instance_fault
5208     def get_console_output(self, context, instance, tail_length):
5209         """Send the console output for the given instance."""
5210         context = context.elevated()
5211         LOG.info("Get console output", instance=instance)
5212         output = self.driver.get_console_output(context, instance)
5213 
5214         if type(output) is six.text_type:
5215             output = six.b(output)
5216 
5217         if tail_length is not None:
5218             output = self._tail_log(output, tail_length)
5219 
5220         return output.decode('ascii', 'replace')
5221 
5222     def _tail_log(self, log, length):
5223         try:
5224             length = int(length)
5225         except ValueError:
5226             length = 0
5227 
5228         if length == 0:
5229             return b''
5230         else:
5231             return b'\n'.join(log.split(b'\n')[-int(length):])
5232 
5233     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5234                                    exception.InstanceNotReady,
5235                                    exception.InstanceNotFound,
5236                                    exception.ConsoleTypeUnavailable,
5237                                    NotImplementedError)
5238     @wrap_exception()
5239     @wrap_instance_fault
5240     def get_vnc_console(self, context, console_type, instance):
5241         """Return connection information for a vnc console."""
5242         context = context.elevated()
5243         LOG.debug("Getting vnc console", instance=instance)
5244 
5245         if not CONF.vnc.enabled:
5246             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5247 
5248         if console_type == 'novnc':
5249             # For essex, novncproxy_base_url must include the full path
5250             # including the html file (like http://myhost/vnc_auto.html)
5251             access_url_base = CONF.vnc.novncproxy_base_url
5252         elif console_type == 'xvpvnc':
5253             access_url_base = CONF.vnc.xvpvncproxy_base_url
5254         else:
5255             raise exception.ConsoleTypeInvalid(console_type=console_type)
5256 
5257         try:
5258             # Retrieve connect info from driver, and then decorate with our
5259             # access info token
5260             console = self.driver.get_vnc_console(context, instance)
5261             console_auth = objects.ConsoleAuthToken(
5262                 context=context,
5263                 console_type=console_type,
5264                 host=console.host,
5265                 port=console.port,
5266                 internal_access_path=console.internal_access_path,
5267                 instance_uuid=instance.uuid,
5268                 access_url_base=access_url_base,
5269             )
5270             console_auth.authorize(CONF.consoleauth.token_ttl)
5271             connect_info = console.get_connection_info(
5272                 console_auth.token, console_auth.access_url)
5273 
5274         except exception.InstanceNotFound:
5275             if instance.vm_state != vm_states.BUILDING:
5276                 raise
5277             raise exception.InstanceNotReady(instance_id=instance.uuid)
5278 
5279         return connect_info
5280 
5281     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5282                                    exception.InstanceNotReady,
5283                                    exception.InstanceNotFound,
5284                                    exception.ConsoleTypeUnavailable,
5285                                    NotImplementedError)
5286     @wrap_exception()
5287     @wrap_instance_fault
5288     def get_spice_console(self, context, console_type, instance):
5289         """Return connection information for a spice console."""
5290         context = context.elevated()
5291         LOG.debug("Getting spice console", instance=instance)
5292 
5293         if not CONF.spice.enabled:
5294             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5295 
5296         if console_type != 'spice-html5':
5297             raise exception.ConsoleTypeInvalid(console_type=console_type)
5298 
5299         try:
5300             # Retrieve connect info from driver, and then decorate with our
5301             # access info token
5302             console = self.driver.get_spice_console(context, instance)
5303             console_auth = objects.ConsoleAuthToken(
5304                 context=context,
5305                 console_type=console_type,
5306                 host=console.host,
5307                 port=console.port,
5308                 internal_access_path=console.internal_access_path,
5309                 instance_uuid=instance.uuid,
5310                 access_url_base=CONF.spice.html5proxy_base_url,
5311             )
5312             console_auth.authorize(CONF.consoleauth.token_ttl)
5313             connect_info = console.get_connection_info(
5314                 console_auth.token, console_auth.access_url)
5315 
5316         except exception.InstanceNotFound:
5317             if instance.vm_state != vm_states.BUILDING:
5318                 raise
5319             raise exception.InstanceNotReady(instance_id=instance.uuid)
5320 
5321         return connect_info
5322 
5323     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5324                                    exception.InstanceNotReady,
5325                                    exception.InstanceNotFound,
5326                                    exception.ConsoleTypeUnavailable,
5327                                    NotImplementedError)
5328     @wrap_exception()
5329     @wrap_instance_fault
5330     def get_rdp_console(self, context, console_type, instance):
5331         """Return connection information for a RDP console."""
5332         context = context.elevated()
5333         LOG.debug("Getting RDP console", instance=instance)
5334 
5335         if not CONF.rdp.enabled:
5336             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5337 
5338         if console_type != 'rdp-html5':
5339             raise exception.ConsoleTypeInvalid(console_type=console_type)
5340 
5341         try:
5342             # Retrieve connect info from driver, and then decorate with our
5343             # access info token
5344             console = self.driver.get_rdp_console(context, instance)
5345             console_auth = objects.ConsoleAuthToken(
5346                 context=context,
5347                 console_type=console_type,
5348                 host=console.host,
5349                 port=console.port,
5350                 internal_access_path=console.internal_access_path,
5351                 instance_uuid=instance.uuid,
5352                 access_url_base=CONF.rdp.html5_proxy_base_url,
5353             )
5354             console_auth.authorize(CONF.consoleauth.token_ttl)
5355             connect_info = console.get_connection_info(
5356                 console_auth.token, console_auth.access_url)
5357 
5358         except exception.InstanceNotFound:
5359             if instance.vm_state != vm_states.BUILDING:
5360                 raise
5361             raise exception.InstanceNotReady(instance_id=instance.uuid)
5362 
5363         return connect_info
5364 
5365     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5366                                    exception.InstanceNotReady,
5367                                    exception.InstanceNotFound,
5368                                    exception.ConsoleTypeUnavailable,
5369                                    NotImplementedError)
5370     @wrap_exception()
5371     @wrap_instance_fault
5372     def get_mks_console(self, context, console_type, instance):
5373         """Return connection information for a MKS console."""
5374         context = context.elevated()
5375         LOG.debug("Getting MKS console", instance=instance)
5376 
5377         if not CONF.mks.enabled:
5378             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5379 
5380         if console_type != 'webmks':
5381             raise exception.ConsoleTypeInvalid(console_type=console_type)
5382 
5383         try:
5384             # Retrieve connect info from driver, and then decorate with our
5385             # access info token
5386             console = self.driver.get_mks_console(context, instance)
5387             console_auth = objects.ConsoleAuthToken(
5388                 context=context,
5389                 console_type=console_type,
5390                 host=console.host,
5391                 port=console.port,
5392                 internal_access_path=console.internal_access_path,
5393                 instance_uuid=instance.uuid,
5394                 access_url_base=CONF.mks.mksproxy_base_url,
5395             )
5396             console_auth.authorize(CONF.consoleauth.token_ttl)
5397             connect_info = console.get_connection_info(
5398                 console_auth.token, console_auth.access_url)
5399 
5400         except exception.InstanceNotFound:
5401             if instance.vm_state != vm_states.BUILDING:
5402                 raise
5403             raise exception.InstanceNotReady(instance_id=instance.uuid)
5404 
5405         return connect_info
5406 
5407     @messaging.expected_exceptions(
5408         exception.ConsoleTypeInvalid,
5409         exception.InstanceNotReady,
5410         exception.InstanceNotFound,
5411         exception.ConsoleTypeUnavailable,
5412         exception.SocketPortRangeExhaustedException,
5413         exception.ImageSerialPortNumberInvalid,
5414         exception.ImageSerialPortNumberExceedFlavorValue,
5415         NotImplementedError)
5416     @wrap_exception()
5417     @wrap_instance_fault
5418     def get_serial_console(self, context, console_type, instance):
5419         """Returns connection information for a serial console."""
5420 
5421         LOG.debug("Getting serial console", instance=instance)
5422 
5423         if not CONF.serial_console.enabled:
5424             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5425 
5426         context = context.elevated()
5427 
5428         try:
5429             # Retrieve connect info from driver, and then decorate with our
5430             # access info token
5431             console = self.driver.get_serial_console(context, instance)
5432             console_auth = objects.ConsoleAuthToken(
5433                 context=context,
5434                 console_type=console_type,
5435                 host=console.host,
5436                 port=console.port,
5437                 internal_access_path=console.internal_access_path,
5438                 instance_uuid=instance.uuid,
5439                 access_url_base=CONF.serial_console.base_url,
5440             )
5441             console_auth.authorize(CONF.consoleauth.token_ttl)
5442             connect_info = console.get_connection_info(
5443                 console_auth.token, console_auth.access_url)
5444 
5445         except exception.InstanceNotFound:
5446             if instance.vm_state != vm_states.BUILDING:
5447                 raise
5448             raise exception.InstanceNotReady(instance_id=instance.uuid)
5449 
5450         return connect_info
5451 
5452     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5453                                    exception.InstanceNotReady,
5454                                    exception.InstanceNotFound)
5455     @wrap_exception()
5456     @wrap_instance_fault
5457     def validate_console_port(self, ctxt, instance, port, console_type):
5458         if console_type == "spice-html5":
5459             console_info = self.driver.get_spice_console(ctxt, instance)
5460         elif console_type == "rdp-html5":
5461             console_info = self.driver.get_rdp_console(ctxt, instance)
5462         elif console_type == "serial":
5463             console_info = self.driver.get_serial_console(ctxt, instance)
5464         elif console_type == "webmks":
5465             console_info = self.driver.get_mks_console(ctxt, instance)
5466         else:
5467             console_info = self.driver.get_vnc_console(ctxt, instance)
5468 
5469         # Some drivers may return an int on console_info.port but the port
5470         # variable in this method is a string, so cast to be sure we are
5471         # comparing the correct types.
5472         return str(console_info.port) == port
5473 
5474     @wrap_exception()
5475     @reverts_task_state
5476     @wrap_instance_fault
5477     def reserve_block_device_name(self, context, instance, device,
5478                                   volume_id, disk_bus, device_type, tag,
5479                                   multiattach):
5480         if (tag and not
5481                 self.driver.capabilities.get('supports_tagged_attach_volume',
5482                                              False)):
5483             raise exception.VolumeTaggedAttachNotSupported()
5484 
5485         if (multiattach and not
5486                 self.driver.capabilities.get('supports_multiattach', False)):
5487             raise exception.MultiattachNotSupportedByVirtDriver(
5488                 volume_id=volume_id)
5489 
5490         @utils.synchronized(instance.uuid)
5491         def do_reserve():
5492             bdms = (
5493                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5494                     context, instance.uuid))
5495 
5496             # NOTE(ndipanov): We need to explicitly set all the fields on the
5497             #                 object so that obj_load_attr does not fail
5498             new_bdm = objects.BlockDeviceMapping(
5499                     context=context,
5500                     source_type='volume', destination_type='volume',
5501                     instance_uuid=instance.uuid, boot_index=None,
5502                     volume_id=volume_id,
5503                     device_name=device, guest_format=None,
5504                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5505 
5506             new_bdm.device_name = self._get_device_name_for_instance(
5507                     instance, bdms, new_bdm)
5508 
5509             # NOTE(vish): create bdm here to avoid race condition
5510             new_bdm.create()
5511             return new_bdm
5512 
5513         return do_reserve()
5514 
5515     @wrap_exception()
5516     @wrap_instance_event(prefix='compute')
5517     @wrap_instance_fault
5518     def attach_volume(self, context, instance, bdm):
5519         """Attach a volume to an instance."""
5520         driver_bdm = driver_block_device.convert_volume(bdm)
5521 
5522         @utils.synchronized(instance.uuid)
5523         def do_attach_volume(context, instance, driver_bdm):
5524             try:
5525                 return self._attach_volume(context, instance, driver_bdm)
5526             except Exception:
5527                 with excutils.save_and_reraise_exception():
5528                     bdm.destroy()
5529 
5530         do_attach_volume(context, instance, driver_bdm)
5531 
5532     def _attach_volume(self, context, instance, bdm):
5533         context = context.elevated()
5534         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5535                  {'volume_id': bdm.volume_id,
5536                   'mountpoint': bdm['mount_device']},
5537                  instance=instance)
5538         compute_utils.notify_about_volume_attach_detach(
5539             context, instance, self.host,
5540             action=fields.NotificationAction.VOLUME_ATTACH,
5541             phase=fields.NotificationPhase.START,
5542             volume_id=bdm.volume_id)
5543         try:
5544             bdm.attach(context, instance, self.volume_api, self.driver,
5545                        do_driver_attach=True)
5546         except Exception as e:
5547             with excutils.save_and_reraise_exception():
5548                 LOG.exception("Failed to attach %(volume_id)s "
5549                               "at %(mountpoint)s",
5550                               {'volume_id': bdm.volume_id,
5551                                'mountpoint': bdm['mount_device']},
5552                               instance=instance)
5553                 if bdm['attachment_id']:
5554                     # Try to delete the attachment to make the volume
5555                     # available again. Note that DriverVolumeBlockDevice
5556                     # may have already deleted the attachment so ignore
5557                     # VolumeAttachmentNotFound.
5558                     try:
5559                         self.volume_api.attachment_delete(
5560                             context, bdm['attachment_id'])
5561                     except exception.VolumeAttachmentNotFound as exc:
5562                         LOG.debug('Ignoring VolumeAttachmentNotFound: %s',
5563                                   exc, instance=instance)
5564                 else:
5565                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5566                 tb = traceback.format_exc()
5567                 compute_utils.notify_about_volume_attach_detach(
5568                     context, instance, self.host,
5569                     action=fields.NotificationAction.VOLUME_ATTACH,
5570                     phase=fields.NotificationPhase.ERROR,
5571                     exception=e,
5572                     volume_id=bdm.volume_id, tb=tb)
5573 
5574         info = {'volume_id': bdm.volume_id}
5575         self._notify_about_instance_usage(
5576             context, instance, "volume.attach", extra_usage_info=info)
5577         compute_utils.notify_about_volume_attach_detach(
5578             context, instance, self.host,
5579             action=fields.NotificationAction.VOLUME_ATTACH,
5580             phase=fields.NotificationPhase.END,
5581             volume_id=bdm.volume_id)
5582 
5583     def _notify_volume_usage_detach(self, context, instance, bdm):
5584         if CONF.volume_usage_poll_interval <= 0:
5585             return
5586 
5587         mp = bdm.device_name
5588         # Handle bootable volumes which will not contain /dev/
5589         if '/dev/' in mp:
5590             mp = mp[5:]
5591         try:
5592             vol_stats = self.driver.block_stats(instance, mp)
5593             if vol_stats is None:
5594                 return
5595         except NotImplementedError:
5596             return
5597 
5598         LOG.debug("Updating volume usage cache with totals", instance=instance)
5599         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5600         vol_usage = objects.VolumeUsage(context)
5601         vol_usage.volume_id = bdm.volume_id
5602         vol_usage.instance_uuid = instance.uuid
5603         vol_usage.project_id = instance.project_id
5604         vol_usage.user_id = instance.user_id
5605         vol_usage.availability_zone = instance.availability_zone
5606         vol_usage.curr_reads = rd_req
5607         vol_usage.curr_read_bytes = rd_bytes
5608         vol_usage.curr_writes = wr_req
5609         vol_usage.curr_write_bytes = wr_bytes
5610         vol_usage.save(update_totals=True)
5611         self.notifier.info(context, 'volume.usage', vol_usage.to_dict())
5612         compute_utils.notify_about_volume_usage(context, vol_usage, self.host)
5613 
5614     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5615                        attachment_id=None):
5616         """Detach a volume from an instance.
5617 
5618         :param context: security context
5619         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5620         :param instance: the Instance object to detach the volume from
5621         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5622                             as deleted. Disabling this is useful for operations
5623                             like rebuild, when we don't want to destroy BDM
5624         :param attachment_id: The volume attachment_id for the given instance
5625                               and volume.
5626         """
5627         volume_id = bdm.volume_id
5628         compute_utils.notify_about_volume_attach_detach(
5629             context, instance, self.host,
5630             action=fields.NotificationAction.VOLUME_DETACH,
5631             phase=fields.NotificationPhase.START,
5632             volume_id=volume_id)
5633 
5634         self._notify_volume_usage_detach(context, instance, bdm)
5635 
5636         LOG.info('Detaching volume %(volume_id)s',
5637                  {'volume_id': volume_id}, instance=instance)
5638 
5639         driver_bdm = driver_block_device.convert_volume(bdm)
5640         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5641                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5642 
5643         info = dict(volume_id=volume_id)
5644         self._notify_about_instance_usage(
5645             context, instance, "volume.detach", extra_usage_info=info)
5646         compute_utils.notify_about_volume_attach_detach(
5647             context, instance, self.host,
5648             action=fields.NotificationAction.VOLUME_DETACH,
5649             phase=fields.NotificationPhase.END,
5650             volume_id=volume_id)
5651 
5652         if 'tag' in bdm and bdm.tag:
5653             self._delete_disk_metadata(instance, bdm)
5654         if destroy_bdm:
5655             bdm.destroy()
5656 
5657     def _delete_disk_metadata(self, instance, bdm):
5658         for device in instance.device_metadata.devices:
5659             if isinstance(device, objects.DiskMetadata):
5660                 if 'serial' in device:
5661                     if device.serial == bdm.volume_id:
5662                         instance.device_metadata.devices.remove(device)
5663                         instance.save()
5664                         break
5665                 else:
5666                     # NOTE(artom) We log the entire device object because all
5667                     # fields are nullable and may not be set
5668                     LOG.warning('Unable to determine whether to clean up '
5669                                 'device metadata for disk %s', device,
5670                                 instance=instance)
5671 
5672     @wrap_exception()
5673     @wrap_instance_event(prefix='compute')
5674     @wrap_instance_fault
5675     def detach_volume(self, context, volume_id, instance, attachment_id):
5676         """Detach a volume from an instance.
5677 
5678         :param context: security context
5679         :param volume_id: the volume id
5680         :param instance: the Instance object to detach the volume from
5681         :param attachment_id: The volume attachment_id for the given instance
5682                               and volume.
5683 
5684         """
5685         @utils.synchronized(instance.uuid)
5686         def do_detach_volume(context, volume_id, instance, attachment_id):
5687             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5688                     context, volume_id, instance.uuid)
5689             self._detach_volume(context, bdm, instance,
5690                                 attachment_id=attachment_id)
5691 
5692         do_detach_volume(context, volume_id, instance, attachment_id)
5693 
5694     def _init_volume_connection(self, context, new_volume,
5695                                 old_volume_id, connector, bdm,
5696                                 new_attachment_id, mountpoint):
5697         new_volume_id = new_volume['id']
5698         if new_attachment_id is None:
5699             # We're dealing with an old-style attachment so initialize the
5700             # connection so we can get the connection_info.
5701             new_cinfo = self.volume_api.initialize_connection(context,
5702                                                               new_volume_id,
5703                                                               connector)
5704         else:
5705             # Check for multiattach on the new volume and if True, check to
5706             # see if the virt driver supports multiattach.
5707             # TODO(mriedem): This is copied from DriverVolumeBlockDevice
5708             # and should be consolidated into some common code at some point.
5709             vol_multiattach = new_volume.get('multiattach', False)
5710             virt_multiattach = self.driver.capabilities.get(
5711                 'supports_multiattach', False)
5712             if vol_multiattach and not virt_multiattach:
5713                 raise exception.MultiattachNotSupportedByVirtDriver(
5714                     volume_id=new_volume_id)
5715 
5716             # This is a new style attachment and the API created the new
5717             # volume attachment and passed the id to the compute over RPC.
5718             # At this point we need to update the new volume attachment with
5719             # the host connector, which will give us back the new attachment
5720             # connection_info.
5721             new_cinfo = self.volume_api.attachment_update(
5722                 context, new_attachment_id, connector,
5723                 mountpoint)['connection_info']
5724 
5725             if vol_multiattach:
5726                 # This will be used by the volume driver to determine the
5727                 # proper disk configuration.
5728                 new_cinfo['multiattach'] = True
5729 
5730         old_cinfo = jsonutils.loads(bdm['connection_info'])
5731         if old_cinfo and 'serial' not in old_cinfo:
5732             old_cinfo['serial'] = old_volume_id
5733         # NOTE(lyarwood): serial is not always present in the returned
5734         # connection_info so set it if it is missing as we do in
5735         # DriverVolumeBlockDevice.attach().
5736         if 'serial' not in new_cinfo:
5737             new_cinfo['serial'] = new_volume_id
5738         return (old_cinfo, new_cinfo)
5739 
5740     def _swap_volume(self, context, instance, bdm, connector,
5741                      old_volume_id, new_volume, resize_to,
5742                      new_attachment_id, is_cinder_migration):
5743         new_volume_id = new_volume['id']
5744         mountpoint = bdm['device_name']
5745         failed = False
5746         new_cinfo = None
5747         try:
5748             old_cinfo, new_cinfo = self._init_volume_connection(
5749                 context, new_volume, old_volume_id, connector,
5750                 bdm, new_attachment_id, mountpoint)
5751             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5752             # currently implementing swap_volume, will modify the contents of
5753             # new_cinfo when connect_volume is called. This is then saved to
5754             # the BDM in swap_volume for future use outside of this flow.
5755             msg = ("swap_volume: Calling driver volume swap with "
5756                    "connection infos: new: %(new_cinfo)s; "
5757                    "old: %(old_cinfo)s" %
5758                    {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo})
5759             # Both new and old info might contain password
5760             LOG.debug(strutils.mask_password(msg), instance=instance)
5761 
5762             self.driver.swap_volume(context, old_cinfo, new_cinfo, instance,
5763                                     mountpoint, resize_to)
5764             if new_attachment_id:
5765                 self.volume_api.attachment_complete(context, new_attachment_id)
5766             msg = ("swap_volume: Driver volume swap returned, new "
5767                    "connection_info is now : %(new_cinfo)s" %
5768                    {'new_cinfo': new_cinfo})
5769             LOG.debug(strutils.mask_password(msg))
5770         except Exception as ex:
5771             failed = True
5772             with excutils.save_and_reraise_exception():
5773                 tb = traceback.format_exc()
5774                 compute_utils.notify_about_volume_swap(
5775                     context, instance, self.host,
5776                     fields.NotificationPhase.ERROR,
5777                     old_volume_id, new_volume_id, ex, tb)
5778                 if new_cinfo:
5779                     msg = ("Failed to swap volume %(old_volume_id)s "
5780                            "for %(new_volume_id)s")
5781                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5782                                         'new_volume_id': new_volume_id},
5783                                   instance=instance)
5784                 else:
5785                     msg = ("Failed to connect to volume %(volume_id)s "
5786                            "with volume at %(mountpoint)s")
5787                     LOG.exception(msg, {'volume_id': new_volume_id,
5788                                         'mountpoint': bdm['device_name']},
5789                                   instance=instance)
5790 
5791                 # The API marked the volume as 'detaching' for the old volume
5792                 # so we need to roll that back so the volume goes back to
5793                 # 'in-use' state.
5794                 self.volume_api.roll_detaching(context, old_volume_id)
5795 
5796                 if new_attachment_id is None:
5797                     # The API reserved the new volume so it would be in
5798                     # 'attaching' status, so we need to unreserve it so it
5799                     # goes back to 'available' status.
5800                     self.volume_api.unreserve_volume(context, new_volume_id)
5801                 else:
5802                     # This is a new style attachment for the new volume, which
5803                     # was created in the API. We just need to delete it here
5804                     # to put the new volume back into 'available' status.
5805                     self.volume_api.attachment_delete(
5806                         context, new_attachment_id)
5807         finally:
5808             # TODO(mriedem): This finally block is terribly confusing and is
5809             # trying to do too much. We should consider removing the finally
5810             # block and move whatever needs to happen on success and failure
5811             # into the blocks above for clarity, even if it means a bit of
5812             # redundant code.
5813             conn_volume = new_volume_id if failed else old_volume_id
5814             if new_cinfo:
5815                 LOG.debug("swap_volume: removing Cinder connection "
5816                           "for volume %(volume)s", {'volume': conn_volume},
5817                           instance=instance)
5818                 if bdm.attachment_id is None:
5819                     # This is the pre-3.44 flow for new-style volume
5820                     # attachments so just terminate the connection.
5821                     self.volume_api.terminate_connection(context,
5822                                                          conn_volume,
5823                                                          connector)
5824                 else:
5825                     # This is a new style volume attachment. If we failed, then
5826                     # the new attachment was already deleted above in the
5827                     # exception block and we have nothing more to do here. If
5828                     # swap_volume was successful in the driver, then we need to
5829                     # "detach" the original attachment by deleting it.
5830                     if not failed:
5831                         self.volume_api.attachment_delete(
5832                             context, bdm.attachment_id)
5833 
5834             # Need to make some decisions based on whether this was
5835             # a Cinder initiated migration or not. The callback to
5836             # migration completion isn't needed in the case of a
5837             # nova initiated simple swap of two volume
5838             # "volume-update" call so skip that. The new attachment
5839             # scenarios will give us a new attachment record and
5840             # that's what we want.
5841             if bdm.attachment_id and not is_cinder_migration:
5842                 # we don't callback to cinder
5843                 comp_ret = {'save_volume_id': new_volume_id}
5844             else:
5845                 # NOTE(lyarwood): The following call to
5846                 # os-migrate-volume-completion returns a dict containing
5847                 # save_volume_id, this volume id has two possible values :
5848                 # 1. old_volume_id if we are migrating (retyping) volumes
5849                 # 2. new_volume_id if we are swapping between two existing
5850                 #    volumes
5851                 # This volume id is later used to update the volume_id and
5852                 # connection_info['serial'] of the BDM.
5853                 comp_ret = self.volume_api.migrate_volume_completion(
5854                                                           context,
5855                                                           old_volume_id,
5856                                                           new_volume_id,
5857                                                           error=failed)
5858                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5859                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5860                           instance=instance)
5861 
5862         return (comp_ret, new_cinfo)
5863 
5864     @wrap_exception()
5865     @wrap_instance_event(prefix='compute')
5866     @wrap_instance_fault
5867     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
5868                     new_attachment_id):
5869         """Swap volume for an instance."""
5870         context = context.elevated()
5871 
5872         compute_utils.notify_about_volume_swap(
5873             context, instance, self.host,
5874             fields.NotificationPhase.START,
5875             old_volume_id, new_volume_id)
5876 
5877         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5878                 context, old_volume_id, instance.uuid)
5879         connector = self.driver.get_volume_connector(instance)
5880 
5881         resize_to = 0
5882         old_volume = self.volume_api.get(context, old_volume_id)
5883         # Yes this is a tightly-coupled state check of what's going on inside
5884         # cinder, but we need this while we still support old (v1/v2) and
5885         # new style attachments (v3.44). Once we drop support for old style
5886         # attachments we could think about cleaning up the cinder-initiated
5887         # swap volume API flows.
5888         is_cinder_migration = (
5889             True if old_volume['status'] in ('retyping',
5890                                              'migrating') else False)
5891         old_vol_size = old_volume['size']
5892         new_volume = self.volume_api.get(context, new_volume_id)
5893         new_vol_size = new_volume['size']
5894         if new_vol_size > old_vol_size:
5895             resize_to = new_vol_size
5896 
5897         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5898                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5899                  instance=instance)
5900         comp_ret, new_cinfo = self._swap_volume(context,
5901                                                 instance,
5902                                                 bdm,
5903                                                 connector,
5904                                                 old_volume_id,
5905                                                 new_volume,
5906                                                 resize_to,
5907                                                 new_attachment_id,
5908                                                 is_cinder_migration)
5909 
5910         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5911         # correct volume_id returned by Cinder.
5912         save_volume_id = comp_ret['save_volume_id']
5913         new_cinfo['serial'] = save_volume_id
5914         values = {
5915             'connection_info': jsonutils.dumps(new_cinfo),
5916             'source_type': 'volume',
5917             'destination_type': 'volume',
5918             'snapshot_id': None,
5919             'volume_id': save_volume_id,
5920             'no_device': None}
5921 
5922         if resize_to:
5923             values['volume_size'] = resize_to
5924 
5925         if new_attachment_id is not None:
5926             # This was a volume swap for a new-style attachment so we
5927             # need to update the BDM attachment_id for the new attachment.
5928             values['attachment_id'] = new_attachment_id
5929 
5930         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5931                   "%(updates)s", {'volume_id': bdm.volume_id,
5932                                   'updates': values},
5933                   instance=instance)
5934         bdm.update(values)
5935         bdm.save()
5936 
5937         compute_utils.notify_about_volume_swap(
5938             context, instance, self.host,
5939             fields.NotificationPhase.END,
5940             old_volume_id, new_volume_id)
5941 
5942     @wrap_exception()
5943     def remove_volume_connection(self, context, volume_id, instance):
5944         """Remove the volume connection on this host
5945 
5946         Detach the volume from this instance on this host, and if this is
5947         the cinder v2 flow, call cinder to terminate the connection.
5948         """
5949         try:
5950             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5951                     context, volume_id, instance.uuid)
5952             driver_bdm = driver_block_device.convert_volume(bdm)
5953             driver_bdm.driver_detach(context, instance,
5954                                      self.volume_api, self.driver)
5955             if bdm.attachment_id is None:
5956                 # cinder v2 api flow
5957                 connector = self.driver.get_volume_connector(instance)
5958                 self.volume_api.terminate_connection(context, volume_id,
5959                                                      connector)
5960         except exception.NotFound:
5961             pass
5962 
5963     @wrap_exception()
5964     @wrap_instance_event(prefix='compute')
5965     @wrap_instance_fault
5966     def attach_interface(self, context, instance, network_id, port_id,
5967                          requested_ip, tag):
5968         """Use hotplug to add an network adapter to an instance."""
5969         if not self.driver.capabilities.get('supports_attach_interface',
5970                                             False):
5971             raise exception.AttachInterfaceNotSupported(
5972                 instance_uuid=instance.uuid)
5973         if (tag and not
5974             self.driver.capabilities.get('supports_tagged_attach_interface',
5975                                          False)):
5976             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5977 
5978         compute_utils.notify_about_instance_action(
5979             context, instance, self.host,
5980             action=fields.NotificationAction.INTERFACE_ATTACH,
5981             phase=fields.NotificationPhase.START)
5982 
5983         bind_host_id = self.driver.network_binding_host_id(context, instance)
5984         network_info = self.network_api.allocate_port_for_instance(
5985             context, instance, port_id, network_id, requested_ip,
5986             bind_host_id=bind_host_id, tag=tag)
5987         if len(network_info) != 1:
5988             LOG.error('allocate_port_for_instance returned %(ports)s '
5989                       'ports', {'ports': len(network_info)})
5990             # TODO(elod.illes): an instance.interface_attach.error notification
5991             # should be sent here
5992             raise exception.InterfaceAttachFailed(
5993                     instance_uuid=instance.uuid)
5994         image_meta = objects.ImageMeta.from_instance(instance)
5995 
5996         try:
5997             self.driver.attach_interface(context, instance, image_meta,
5998                                          network_info[0])
5999         except exception.NovaException as ex:
6000             port_id = network_info[0].get('id')
6001             LOG.warning("attach interface failed , try to deallocate "
6002                         "port %(port_id)s, reason: %(msg)s",
6003                         {'port_id': port_id, 'msg': ex},
6004                         instance=instance)
6005             try:
6006                 self.network_api.deallocate_port_for_instance(
6007                     context, instance, port_id)
6008             except Exception:
6009                 LOG.warning("deallocate port %(port_id)s failed",
6010                             {'port_id': port_id}, instance=instance)
6011 
6012             tb = traceback.format_exc()
6013             compute_utils.notify_about_instance_action(
6014                 context, instance, self.host,
6015                 action=fields.NotificationAction.INTERFACE_ATTACH,
6016                 phase=fields.NotificationPhase.ERROR,
6017                 exception=ex, tb=tb)
6018 
6019             raise exception.InterfaceAttachFailed(
6020                 instance_uuid=instance.uuid)
6021 
6022         compute_utils.notify_about_instance_action(
6023             context, instance, self.host,
6024             action=fields.NotificationAction.INTERFACE_ATTACH,
6025             phase=fields.NotificationPhase.END)
6026 
6027         return network_info[0]
6028 
6029     @wrap_exception()
6030     @wrap_instance_event(prefix='compute')
6031     @wrap_instance_fault
6032     def detach_interface(self, context, instance, port_id):
6033         """Detach a network adapter from an instance."""
6034         network_info = instance.info_cache.network_info
6035         condemned = None
6036         for vif in network_info:
6037             if vif['id'] == port_id:
6038                 condemned = vif
6039                 break
6040         if condemned is None:
6041             raise exception.PortNotFound(_("Port %s is not "
6042                                            "attached") % port_id)
6043 
6044         compute_utils.notify_about_instance_action(
6045             context, instance, self.host,
6046             action=fields.NotificationAction.INTERFACE_DETACH,
6047             phase=fields.NotificationPhase.START)
6048 
6049         try:
6050             self.driver.detach_interface(context, instance, condemned)
6051         except exception.NovaException as ex:
6052             # If the instance was deleted before the interface was detached,
6053             # just log it at debug.
6054             log_level = (logging.DEBUG
6055                          if isinstance(ex, exception.InstanceNotFound)
6056                          else logging.WARNING)
6057             LOG.log(log_level,
6058                     "Detach interface failed, port_id=%(port_id)s, reason: "
6059                     "%(msg)s", {'port_id': port_id, 'msg': ex},
6060                     instance=instance)
6061             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
6062         else:
6063             try:
6064                 self.network_api.deallocate_port_for_instance(
6065                     context, instance, port_id)
6066             except Exception as ex:
6067                 with excutils.save_and_reraise_exception():
6068                     # Since this is a cast operation, log the failure for
6069                     # triage.
6070                     LOG.warning('Failed to deallocate port %(port_id)s '
6071                                 'for instance. Error: %(error)s',
6072                                 {'port_id': port_id, 'error': ex},
6073                                 instance=instance)
6074 
6075         compute_utils.notify_about_instance_action(
6076             context, instance, self.host,
6077             action=fields.NotificationAction.INTERFACE_DETACH,
6078             phase=fields.NotificationPhase.END)
6079 
6080     def _get_compute_info(self, context, host):
6081         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
6082             context, host)
6083 
6084     @wrap_exception()
6085     def check_instance_shared_storage(self, ctxt, instance, data):
6086         """Check if the instance files are shared
6087 
6088         :param ctxt: security context
6089         :param instance: dict of instance data
6090         :param data: result of driver.check_instance_shared_storage_local
6091 
6092         Returns True if instance disks located on shared storage and
6093         False otherwise.
6094         """
6095         return self.driver.check_instance_shared_storage_remote(ctxt, data)
6096 
6097     @wrap_exception()
6098     @wrap_instance_event(prefix='compute')
6099     @wrap_instance_fault
6100     def check_can_live_migrate_destination(self, ctxt, instance,
6101                                            block_migration, disk_over_commit,
6102                                            migration=None, limits=None):
6103         """Check if it is possible to execute live migration.
6104 
6105         This runs checks on the destination host, and then calls
6106         back to the source host to check the results.
6107 
6108         :param context: security context
6109         :param instance: dict of instance data
6110         :param block_migration: if true, prepare for block migration
6111                                 if None, calculate it in driver
6112         :param disk_over_commit: if true, allow disk over commit
6113                                  if None, ignore disk usage checking
6114         :param migration: objects.Migration object for this live migration.
6115         :param limits: objects.SchedulerLimits object for this live migration.
6116         :returns: a dict containing migration info
6117         """
6118         src_compute_info = obj_base.obj_to_primitive(
6119             self._get_compute_info(ctxt, instance.host))
6120         dst_compute_info = obj_base.obj_to_primitive(
6121             self._get_compute_info(ctxt, CONF.host))
6122         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
6123             instance, src_compute_info, dst_compute_info,
6124             block_migration, disk_over_commit)
6125         LOG.debug('destination check data is %s', dest_check_data)
6126         try:
6127             source_check_data = self.compute_rpcapi.\
6128                                 check_can_live_migrate_source(ctxt, instance,
6129                                                               dest_check_data)
6130             migrate_data = self._prepare_numa_live_migration(ctxt, instance,
6131                                                              source_check_data,
6132                                                              migration, limits)
6133         finally:
6134             self.driver.cleanup_live_migration_destination_check(ctxt,
6135                     dest_check_data)
6136         return migrate_data
6137 
6138     def _prepare_numa_live_migration(self, ctxt, instance, migrate_data,
6139                                      migration, limits):
6140         """Prepares for a NUMA live migration if necessary by making a
6141         resources claim and asking our virt driver for dst_numa_config.
6142 
6143         :param ctxt: Request context
6144         :param instance: The Instance being live migrated
6145         :param migrate_data: The MigrateData object for this live migration
6146         :param migration: The Migration object for this live migration
6147         :param limits: The SchedulerLimits object for this live migration
6148         :returns: migrate_data with dst_numa_config if necessary
6149         """
6150         numa_live_migration = ('instance_numa_topology' in migrate_data
6151                                and migrate_data.instance_numa_topology)
6152         if numa_live_migration and migration:
6153             try:
6154                 claim = self.rt.live_migration_claim(
6155                     ctxt, instance, self._get_nodename(instance), migration,
6156                     limits)
6157                 LOG.debug('Created live migration claim %s', claim)
6158             except exception.ComputeResourcesUnavailable as e:
6159                 raise exception.MigrationPreCheckError(
6160                     reason=e.format_message())
6161             migrate_data.dst_numa_config = self.driver.get_dst_numa_config(
6162                 claim.claimed_numa_topology, instance.flavor,
6163                 instance.image_meta)
6164         return migrate_data
6165 
6166     @wrap_exception()
6167     @wrap_instance_event(prefix='compute')
6168     @wrap_instance_fault
6169     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
6170         """Check if it is possible to execute live migration.
6171 
6172         This checks if the live migration can succeed, based on the
6173         results from check_can_live_migrate_destination.
6174 
6175         :param ctxt: security context
6176         :param instance: dict of instance data
6177         :param dest_check_data: result of check_can_live_migrate_destination
6178         :returns: a dict containing migration info
6179         """
6180         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6181             ctxt, instance.uuid)
6182         is_volume_backed = compute_utils.is_volume_backed_instance(
6183             ctxt, instance, bdms)
6184         dest_check_data.is_volume_backed = is_volume_backed
6185         block_device_info = self._get_instance_block_device_info(
6186                             ctxt, instance, refresh_conn_info=False, bdms=bdms)
6187         result = self.driver.check_can_live_migrate_source(ctxt, instance,
6188                                                            dest_check_data,
6189                                                            block_device_info)
6190         LOG.debug('source check data is %s', result)
6191         return result
6192 
6193     @wrap_exception()
6194     @wrap_instance_event(prefix='compute')
6195     @wrap_instance_fault
6196     def pre_live_migration(self, context, instance, block_migration, disk,
6197                            migrate_data):
6198         """Preparations for live migration at dest host.
6199 
6200         :param context: security context
6201         :param instance: dict of instance data
6202         :param block_migration: if true, prepare for block migration
6203         :param disk: disk info of instance
6204         :param migrate_data: A dict or LiveMigrateData object holding data
6205                              required for live migration without shared
6206                              storage.
6207         :returns: migrate_data containing additional migration info
6208         """
6209         LOG.debug('pre_live_migration data is %s', migrate_data)
6210 
6211         migrate_data.old_vol_attachment_ids = {}
6212         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6213             context, instance.uuid)
6214         network_info = self.network_api.get_instance_nw_info(context, instance)
6215         self._notify_about_instance_usage(
6216             context, instance, "live_migration.pre.start",
6217             network_info=network_info)
6218         compute_utils.notify_about_instance_action(
6219             context, instance, self.host,
6220             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6221             phase=fields.NotificationPhase.START, bdms=bdms)
6222 
6223         connector = self.driver.get_volume_connector(instance)
6224         try:
6225             for bdm in bdms:
6226                 if bdm.is_volume and bdm.attachment_id is not None:
6227                     # This bdm uses the new cinder v3.44 API.
6228                     # We will create a new attachment for this
6229                     # volume on this migration destination host. The old
6230                     # attachment will be deleted on the source host
6231                     # when the migration succeeds. The old attachment_id
6232                     # is stored in dict with the key being the bdm.volume_id
6233                     # so it can be restored on rollback.
6234                     #
6235                     # Also note that attachment_update is not needed as we
6236                     # are providing the connector in the create call.
6237                     attach_ref = self.volume_api.attachment_create(
6238                         context, bdm.volume_id, bdm.instance_uuid,
6239                         connector=connector, mountpoint=bdm.device_name)
6240 
6241                     # save current attachment so we can detach it on success,
6242                     # or restore it on a rollback.
6243                     # NOTE(mdbooth): This data is no longer used by the source
6244                     # host since change I0390c9ff. We can't remove it until we
6245                     # are sure the source host has been upgraded.
6246                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
6247                         bdm.attachment_id
6248 
6249                     # update the bdm with the new attachment_id.
6250                     bdm.attachment_id = attach_ref['id']
6251                     bdm.save()
6252 
6253             block_device_info = self._get_instance_block_device_info(
6254                                 context, instance, refresh_conn_info=True,
6255                                 bdms=bdms)
6256 
6257             # The driver pre_live_migration will plug vifs on the host. We call
6258             # plug_vifs before calling ensure_filtering_rules_for_instance, to
6259             # ensure bridge is set up.
6260             migrate_data = self.driver.pre_live_migration(context,
6261                                            instance,
6262                                            block_device_info,
6263                                            network_info,
6264                                            disk,
6265                                            migrate_data)
6266             LOG.debug('driver pre_live_migration data is %s', migrate_data)
6267             # driver.pre_live_migration is what plugs vifs on the destination
6268             # host so now we can set the wait_for_vif_plugged flag in the
6269             # migrate_data object which the source compute will use to
6270             # determine if it should wait for a 'network-vif-plugged' event
6271             # from neutron before starting the actual guest transfer in the
6272             # hypervisor
6273             migrate_data.wait_for_vif_plugged = (
6274                 CONF.compute.live_migration_wait_for_vif_plug)
6275 
6276             # NOTE(tr3buchet): setup networks on destination host
6277             self.network_api.setup_networks_on_host(context, instance,
6278                                                              self.host)
6279 
6280             # Creating filters to hypervisors and firewalls.
6281             # An example is that nova-instance-instance-xxx,
6282             # which is written to libvirt.xml(Check "virsh nwfilter-list")
6283             # This nwfilter is necessary on the destination host.
6284             # In addition, this method is creating filtering rule
6285             # onto destination host.
6286             self.driver.ensure_filtering_rules_for_instance(instance,
6287                                                 network_info)
6288         except Exception:
6289             # If we raise, migrate_data with the updated attachment ids
6290             # will not be returned to the source host for rollback.
6291             # So we need to rollback new attachments here.
6292             with excutils.save_and_reraise_exception():
6293                 old_attachments = migrate_data.old_vol_attachment_ids
6294                 for bdm in bdms:
6295                     if (bdm.is_volume and bdm.attachment_id is not None and
6296                             bdm.volume_id in old_attachments):
6297                         self.volume_api.attachment_delete(context,
6298                                                           bdm.attachment_id)
6299                         bdm.attachment_id = old_attachments[bdm.volume_id]
6300                         bdm.save()
6301 
6302         # Volume connections are complete, tell cinder that all the
6303         # attachments have completed.
6304         for bdm in bdms:
6305             if bdm.is_volume and bdm.attachment_id is not None:
6306                 self.volume_api.attachment_complete(context,
6307                                                     bdm.attachment_id)
6308 
6309         self._notify_about_instance_usage(
6310                      context, instance, "live_migration.pre.end",
6311                      network_info=network_info)
6312         compute_utils.notify_about_instance_action(
6313             context, instance, self.host,
6314             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6315             phase=fields.NotificationPhase.END, bdms=bdms)
6316 
6317         LOG.debug('pre_live_migration result data is %s', migrate_data)
6318         return migrate_data
6319 
6320     @staticmethod
6321     def _neutron_failed_live_migration_callback(event_name, instance):
6322         msg = ('Neutron reported failure during live migration '
6323                'with %(event)s for instance %(uuid)s')
6324         msg_args = {'event': event_name, 'uuid': instance.uuid}
6325         if CONF.vif_plugging_is_fatal:
6326             raise exception.VirtualInterfacePlugException(msg % msg_args)
6327         LOG.error(msg, msg_args)
6328 
6329     @staticmethod
6330     def _get_neutron_events_for_live_migration(instance):
6331         # We don't generate events if CONF.vif_plugging_timeout=0
6332         # meaning that the operator disabled using them.
6333         if CONF.vif_plugging_timeout and utils.is_neutron():
6334             return [('network-vif-plugged', vif['id'])
6335                     for vif in instance.get_network_info()]
6336         else:
6337             return []
6338 
6339     def _cleanup_pre_live_migration(self, context, dest, instance,
6340                                     migration, migrate_data):
6341         """Helper method for when pre_live_migration fails
6342 
6343         Sets the migration status to "error" and rolls back the live migration
6344         setup on the destination host.
6345 
6346         :param context: The user request context.
6347         :type context: nova.context.RequestContext
6348         :param dest: The live migration destination hostname.
6349         :type dest: str
6350         :param instance: The instance being live migrated.
6351         :type instance: nova.objects.Instance
6352         :param migration: The migration record tracking this live migration.
6353         :type migration: nova.objects.Migration
6354         :param migrate_data: Data about the live migration, populated from
6355                              the destination host.
6356         :type migrate_data: Subclass of nova.objects.LiveMigrateData
6357         """
6358         self._set_migration_status(migration, 'error')
6359         # Make sure we set this for _rollback_live_migration()
6360         # so it can find it, as expected if it was called later
6361         migrate_data.migration = migration
6362         self._rollback_live_migration(context, instance, dest,
6363                                       migrate_data)
6364 
6365     def _do_live_migration(self, context, dest, instance, block_migration,
6366                            migration, migrate_data):
6367         # NOTE(danms): We should enhance the RT to account for migrations
6368         # and use the status field to denote when the accounting has been
6369         # done on source/destination. For now, this is just here for status
6370         # reporting
6371         self._set_migration_status(migration, 'preparing')
6372         source_bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6373                 context, instance.uuid)
6374 
6375         class _BreakWaitForInstanceEvent(Exception):
6376             """Used as a signal to stop waiting for the network-vif-plugged
6377             event when we discover that
6378             [compute]/live_migration_wait_for_vif_plug is not set on the
6379             destination.
6380             """
6381             pass
6382 
6383         events = self._get_neutron_events_for_live_migration(instance)
6384         try:
6385             if ('block_migration' in migrate_data and
6386                     migrate_data.block_migration):
6387                 block_device_info = self._get_instance_block_device_info(
6388                     context, instance, bdms=source_bdms)
6389                 disk = self.driver.get_instance_disk_info(
6390                     instance, block_device_info=block_device_info)
6391             else:
6392                 disk = None
6393 
6394             deadline = CONF.vif_plugging_timeout
6395             error_cb = self._neutron_failed_live_migration_callback
6396             # In order to avoid a race with the vif plugging that the virt
6397             # driver does on the destination host, we register our events
6398             # to wait for before calling pre_live_migration. Then if the
6399             # dest host reports back that we shouldn't wait, we can break
6400             # out of the context manager using _BreakWaitForInstanceEvent.
6401             with self.virtapi.wait_for_instance_event(
6402                     instance, events, deadline=deadline,
6403                     error_callback=error_cb):
6404                 with timeutils.StopWatch() as timer:
6405                     migrate_data = self.compute_rpcapi.pre_live_migration(
6406                         context, instance,
6407                         block_migration, disk, dest, migrate_data)
6408                 LOG.info('Took %0.2f seconds for pre_live_migration on '
6409                          'destination host %s.',
6410                          timer.elapsed(), dest, instance=instance)
6411                 wait_for_vif_plugged = (
6412                     'wait_for_vif_plugged' in migrate_data and
6413                     migrate_data.wait_for_vif_plugged)
6414                 if events and not wait_for_vif_plugged:
6415                     raise _BreakWaitForInstanceEvent
6416         except _BreakWaitForInstanceEvent:
6417             if events:
6418                 LOG.debug('Not waiting for events after pre_live_migration: '
6419                           '%s. ', events, instance=instance)
6420             # This is a bit weird, but we need to clear sys.exc_info() so that
6421             # oslo.log formatting does not inadvertently use it later if an
6422             # error message is logged without an explicit exc_info. This is
6423             # only a problem with python 2.
6424             if six.PY2:
6425                 sys.exc_clear()
6426         except exception.VirtualInterfacePlugException:
6427             with excutils.save_and_reraise_exception():
6428                 LOG.exception('Failed waiting for network virtual interfaces '
6429                               'to be plugged on the destination host %s.',
6430                               dest, instance=instance)
6431                 self._cleanup_pre_live_migration(
6432                     context, dest, instance, migration, migrate_data)
6433         except eventlet.timeout.Timeout:
6434             # We only get here if wait_for_vif_plugged is True which means
6435             # live_migration_wait_for_vif_plug=True on the destination host.
6436             msg = (
6437                 'Timed out waiting for events: %(events)s. If these timeouts '
6438                 'are a persistent issue it could mean the networking backend '
6439                 'on host %(dest)s does not support sending these events '
6440                 'unless there are port binding host changes which does not '
6441                 'happen at this point in the live migration process. You may '
6442                 'need to disable the live_migration_wait_for_vif_plug option '
6443                 'on host %(dest)s.')
6444             subs = {'events': events, 'dest': dest}
6445             LOG.warning(msg, subs, instance=instance)
6446             if CONF.vif_plugging_is_fatal:
6447                 self._cleanup_pre_live_migration(
6448                     context, dest, instance, migration, migrate_data)
6449                 raise exception.MigrationError(reason=msg % subs)
6450         except Exception:
6451             with excutils.save_and_reraise_exception():
6452                 LOG.exception('Pre live migration failed at %s',
6453                               dest, instance=instance)
6454                 self._cleanup_pre_live_migration(
6455                     context, dest, instance, migration, migrate_data)
6456 
6457         # NOTE(Kevin_Zheng): Pop the migration from the waiting queue
6458         # if it exist in the queue, then we are good to moving on, if
6459         # not, some other process must have aborted it, then we should
6460         # rollback.
6461         try:
6462             self._waiting_live_migrations.pop(instance.uuid)
6463         except KeyError:
6464             LOG.debug('Migration %s aborted by another process, rollback.',
6465                       migration.uuid, instance=instance)
6466             migrate_data.migration = migration
6467             self._rollback_live_migration(context, instance, dest,
6468                                           migrate_data, 'cancelled')
6469             self._notify_live_migrate_abort_end(context, instance)
6470             return
6471 
6472         self._set_migration_status(migration, 'running')
6473         if migrate_data:
6474             migrate_data.migration = migration
6475 
6476         # NOTE(mdbooth): pre_live_migration will update connection_info and
6477         # attachment_id on all volume BDMS to reflect the new destination
6478         # host attachment. We fetch BDMs before that to retain connection_info
6479         # and attachment_id relating to the source host for post migration
6480         # cleanup.
6481         post_live_migration = functools.partial(self._post_live_migration,
6482                                                 source_bdms=source_bdms)
6483 
6484         LOG.debug('live_migration data is %s', migrate_data)
6485         try:
6486             self.driver.live_migration(context, instance, dest,
6487                                        post_live_migration,
6488                                        self._rollback_live_migration,
6489                                        block_migration, migrate_data)
6490         except Exception:
6491             LOG.exception('Live migration failed.', instance=instance)
6492             with excutils.save_and_reraise_exception():
6493                 # Put instance and migration into error state,
6494                 # as its almost certainly too late to rollback
6495                 self._set_migration_status(migration, 'error')
6496                 # first refresh instance as it may have got updated by
6497                 # post_live_migration_at_destination
6498                 instance.refresh()
6499                 self._set_instance_obj_error_state(context, instance,
6500                                                    clean_task_state=True)
6501 
6502     @wrap_exception()
6503     @wrap_instance_event(prefix='compute')
6504     @wrap_instance_fault
6505     def live_migration(self, context, dest, instance, block_migration,
6506                        migration, migrate_data):
6507         """Executing live migration.
6508 
6509         :param context: security context
6510         :param dest: destination host
6511         :param instance: a nova.objects.instance.Instance object
6512         :param block_migration: if true, prepare for block migration
6513         :param migration: an nova.objects.Migration object
6514         :param migrate_data: implementation specific params
6515 
6516         """
6517         self._set_migration_status(migration, 'queued')
6518         # NOTE(Kevin_Zheng): Submit the live_migration job to the pool and
6519         # put the returned Future object into dict mapped with migration.uuid
6520         # in order to be able to track and abort it in the future.
6521         self._waiting_live_migrations[instance.uuid] = (None, None)
6522         try:
6523             future = self._live_migration_executor.submit(
6524                 self._do_live_migration, context, dest, instance,
6525                 block_migration, migration, migrate_data)
6526             self._waiting_live_migrations[instance.uuid] = (migration, future)
6527         except RuntimeError:
6528             # GreenThreadPoolExecutor.submit will raise RuntimeError if the
6529             # pool is shutdown, which happens in
6530             # _cleanup_live_migrations_in_pool.
6531             LOG.info('Migration %s failed to submit as the compute service '
6532                      'is shutting down.', migration.uuid, instance=instance)
6533             self._set_migration_status(migration, 'error')
6534             raise exception.LiveMigrationNotSubmitted(
6535                 migration_uuid=migration.uuid, instance_uuid=instance.uuid)
6536 
6537     @wrap_exception()
6538     @wrap_instance_event(prefix='compute')
6539     @wrap_instance_fault
6540     def live_migration_force_complete(self, context, instance):
6541         """Force live migration to complete.
6542 
6543         :param context: Security context
6544         :param instance: The instance that is being migrated
6545         """
6546 
6547         self._notify_about_instance_usage(
6548             context, instance, 'live.migration.force.complete.start')
6549         compute_utils.notify_about_instance_action(
6550             context, instance, self.host,
6551             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6552             phase=fields.NotificationPhase.START)
6553         self.driver.live_migration_force_complete(instance)
6554         self._notify_about_instance_usage(
6555             context, instance, 'live.migration.force.complete.end')
6556         compute_utils.notify_about_instance_action(
6557             context, instance, self.host,
6558             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6559             phase=fields.NotificationPhase.END)
6560 
6561     def _notify_live_migrate_abort_end(self, context, instance):
6562         self._notify_about_instance_usage(
6563             context, instance, 'live.migration.abort.end')
6564         compute_utils.notify_about_instance_action(
6565             context, instance, self.host,
6566             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6567             phase=fields.NotificationPhase.END)
6568 
6569     @wrap_exception()
6570     @wrap_instance_event(prefix='compute')
6571     @wrap_instance_fault
6572     def live_migration_abort(self, context, instance, migration_id):
6573         """Abort an in-progress live migration.
6574 
6575         :param context: Security context
6576         :param instance: The instance that is being migrated
6577         :param migration_id: ID of in-progress live migration
6578 
6579         """
6580         self._notify_about_instance_usage(
6581             context, instance, 'live.migration.abort.start')
6582         compute_utils.notify_about_instance_action(
6583             context, instance, self.host,
6584             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6585             phase=fields.NotificationPhase.START)
6586         # NOTE(Kevin_Zheng): Pop the migration out from the queue, this might
6587         # lead to 3 scenarios:
6588         # 1. The selected migration is still in queue, and the future.cancel()
6589         #    succeed, then the abort action is succeed, mark the migration
6590         #    status to 'cancelled'.
6591         # 2. The selected migration is still in queue, but the future.cancel()
6592         #    failed, then the _do_live_migration() has started executing, and
6593         #    the migration status is 'preparing', then we just pop it from the
6594         #    queue, and the migration process will handle it later. And the
6595         #    migration status couldn't be 'running' in this scenario because
6596         #    if _do_live_migration has started executing and we've already
6597         #    popped it from the queue and set the migration status to
6598         #    'running' at this point, popping it here will raise KeyError at
6599         #    which point we check if it's running and if so, we abort the old
6600         #    way.
6601         # 3. The selected migration is not in the queue, then the migration
6602         #    status is 'running', let the driver handle it.
6603         try:
6604             migration, future = (
6605                 self._waiting_live_migrations.pop(instance.uuid))
6606             if future and future.cancel():
6607                 # If we got here, we've successfully aborted the queued
6608                 # migration and _do_live_migration won't run so we need
6609                 # to set the migration status to cancelled and send the
6610                 # notification. If Future.cancel() fails, it means
6611                 # _do_live_migration is running and the migration status
6612                 # is preparing, and _do_live_migration() itself will attempt
6613                 # to pop the queued migration, hit a KeyError, and rollback,
6614                 # set the migration to cancelled and send the
6615                 # live.migration.abort.end notification.
6616                 self._set_migration_status(migration, 'cancelled')
6617         except KeyError:
6618             migration = objects.Migration.get_by_id(context, migration_id)
6619             if migration.status != 'running':
6620                 raise exception.InvalidMigrationState(
6621                     migration_id=migration_id, instance_uuid=instance.uuid,
6622                     state=migration.status, method='abort live migration')
6623             self.driver.live_migration_abort(instance)
6624         self._notify_live_migrate_abort_end(context, instance)
6625 
6626     def _live_migration_cleanup_flags(self, migrate_data):
6627         """Determine whether disks or instance path need to be cleaned up after
6628         live migration (at source on success, at destination on rollback)
6629 
6630         Block migration needs empty image at destination host before migration
6631         starts, so if any failure occurs, any empty images has to be deleted.
6632 
6633         Also Volume backed live migration w/o shared storage needs to delete
6634         newly created instance-xxx dir on the destination as a part of its
6635         rollback process
6636 
6637         :param migrate_data: implementation specific data
6638         :returns: (bool, bool) -- do_cleanup, destroy_disks
6639         """
6640         # NOTE(pkoniszewski): block migration specific params are set inside
6641         # migrate_data objects for drivers that expose block live migration
6642         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6643         # cleanup is not needed.
6644         do_cleanup = False
6645         destroy_disks = False
6646         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6647             # No instance booting at source host, but instance dir
6648             # must be deleted for preparing next block migration
6649             # must be deleted for preparing next live migration w/o shared
6650             # storage
6651             do_cleanup = not migrate_data.is_shared_instance_path
6652             destroy_disks = not migrate_data.is_shared_block_storage
6653         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6654             do_cleanup = migrate_data.block_migration
6655             destroy_disks = migrate_data.block_migration
6656         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6657             # NOTE(claudiub): We need to cleanup any zombie Planned VM.
6658             do_cleanup = True
6659             destroy_disks = not migrate_data.is_shared_instance_path
6660 
6661         return (do_cleanup, destroy_disks)
6662 
6663     @wrap_exception()
6664     @wrap_instance_fault
6665     def _post_live_migration(self, ctxt, instance, dest,
6666                              block_migration=False, migrate_data=None,
6667                              source_bdms=None):
6668         """Post operations for live migration.
6669 
6670         This method is called from live_migration
6671         and mainly updating database record.
6672 
6673         :param ctxt: security context
6674         :param instance: instance dict
6675         :param dest: destination host
6676         :param block_migration: if true, prepare for block migration
6677         :param migrate_data: if not None, it is a dict which has data
6678         :param source_bdms: BDMs prior to modification by the destination
6679                             compute host. Set by _do_live_migration and not
6680                             part of the callback interface, so this is never
6681                             None
6682         required for live migration without shared storage
6683 
6684         """
6685         LOG.info('_post_live_migration() is started..',
6686                  instance=instance)
6687 
6688         # Cleanup source host post live-migration
6689         block_device_info = self._get_instance_block_device_info(
6690                             ctxt, instance, bdms=source_bdms)
6691         self.driver.post_live_migration(ctxt, instance, block_device_info,
6692                                         migrate_data)
6693 
6694         # Detaching volumes.
6695         connector = self.driver.get_volume_connector(instance)
6696         for bdm in source_bdms:
6697             if bdm.is_volume:
6698                 # Detaching volumes is a call to an external API that can fail.
6699                 # If it does, we need to handle it gracefully so that the call
6700                 # to post_live_migration_at_destination - where we set instance
6701                 # host and task state - still happens. We need to rethink the
6702                 # current approach of setting instance host and task state
6703                 # AFTER a whole bunch of things that could fail in unhandled
6704                 # ways, but that is left as a TODO(artom).
6705                 try:
6706                     if bdm.attachment_id is None:
6707                         # Prior to cinder v3.44:
6708                         # We don't want to actually mark the volume detached,
6709                         # or delete the bdm, just remove the connection from
6710                         # this host.
6711                         #
6712                         # remove the volume connection without detaching from
6713                         # hypervisor because the instance is not running
6714                         # anymore on the current host
6715                         self.volume_api.terminate_connection(ctxt,
6716                                                              bdm.volume_id,
6717                                                              connector)
6718                     else:
6719                         # cinder v3.44 api flow - delete the old attachment
6720                         # for the source host
6721                         self.volume_api.attachment_delete(ctxt,
6722                                                           bdm.attachment_id)
6723 
6724                 except Exception as e:
6725                     if bdm.attachment_id is None:
6726                         LOG.error('Connection for volume %s not terminated on '
6727                                   'source host %s during post_live_migration: '
6728                                    '%s', bdm.volume_id, self.host,
6729                                    six.text_type(e), instance=instance)
6730                     else:
6731                         LOG.error('Volume attachment %s not deleted on source '
6732                                   'host %s during post_live_migration: %s',
6733                                   bdm.attachment_id, self.host,
6734                                   six.text_type(e), instance=instance)
6735 
6736         # Releasing vlan.
6737         # (not necessary in current implementation?)
6738 
6739         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
6740 
6741         self._notify_about_instance_usage(ctxt, instance,
6742                                           "live_migration._post.start",
6743                                           network_info=network_info)
6744         compute_utils.notify_about_instance_action(
6745             ctxt, instance, self.host,
6746             action=fields.NotificationAction.LIVE_MIGRATION_POST,
6747             phase=fields.NotificationPhase.START)
6748         # Releasing security group ingress rule.
6749         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
6750                   instance=instance)
6751         self.driver.unfilter_instance(instance,
6752                                       network_info)
6753 
6754         migration = {'source_compute': self.host,
6755                      'dest_compute': dest, }
6756         # For neutron, migrate_instance_start will activate the destination
6757         # host port bindings, if there are any created by conductor before live
6758         # migration started.
6759         self.network_api.migrate_instance_start(ctxt,
6760                                                 instance,
6761                                                 migration)
6762 
6763         destroy_vifs = False
6764         try:
6765             # It's possible that the vif type changed on the destination
6766             # host and is already bound and active, so we need to use the
6767             # stashed source vifs in migrate_data.vifs (if present) to unplug
6768             # on the source host.
6769             unplug_nw_info = network_info
6770             if migrate_data and 'vifs' in migrate_data:
6771                 nw_info = []
6772                 for migrate_vif in migrate_data.vifs:
6773                     nw_info.append(migrate_vif.source_vif)
6774                 unplug_nw_info = network_model.NetworkInfo.hydrate(nw_info)
6775                 LOG.debug('Calling driver.post_live_migration_at_source '
6776                           'with original source VIFs from migrate_data: %s',
6777                           unplug_nw_info, instance=instance)
6778             self.driver.post_live_migration_at_source(ctxt, instance,
6779                                                       unplug_nw_info)
6780         except NotImplementedError as ex:
6781             LOG.debug(ex, instance=instance)
6782             # For all hypervisors other than libvirt, there is a possibility
6783             # they are unplugging networks from source node in the cleanup
6784             # method
6785             destroy_vifs = True
6786 
6787         # NOTE(danms): Save source node before calling post method on
6788         # destination, which will update it
6789         source_node = instance.node
6790 
6791         # Define domain at destination host, without doing it,
6792         # pause/suspend/terminate do not work.
6793         post_at_dest_success = True
6794         try:
6795             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
6796                     instance, block_migration, dest)
6797         except Exception as error:
6798             post_at_dest_success = False
6799             # We don't want to break _post_live_migration() if
6800             # post_live_migration_at_destination() fails as it should never
6801             # affect cleaning up source node.
6802             LOG.exception("Post live migration at destination %s failed",
6803                           dest, instance=instance, error=error)
6804 
6805         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6806                 migrate_data)
6807 
6808         if do_cleanup:
6809             LOG.debug('Calling driver.cleanup from _post_live_migration',
6810                       instance=instance)
6811             self.driver.cleanup(ctxt, instance, unplug_nw_info,
6812                                 destroy_disks=destroy_disks,
6813                                 migrate_data=migrate_data,
6814                                 destroy_vifs=destroy_vifs)
6815 
6816         self.instance_events.clear_events_for_instance(instance)
6817 
6818         # NOTE(timello): make sure we update available resources on source
6819         # host even before next periodic task.
6820         self.update_available_resource(ctxt)
6821 
6822         self._update_scheduler_instance_info(ctxt, instance)
6823         self._notify_about_instance_usage(ctxt, instance,
6824                                           "live_migration._post.end",
6825                                           network_info=network_info)
6826         compute_utils.notify_about_instance_action(
6827             ctxt, instance, self.host,
6828             action=fields.NotificationAction.LIVE_MIGRATION_POST,
6829             phase=fields.NotificationPhase.END)
6830         if post_at_dest_success:
6831             LOG.info('Migrating instance to %s finished successfully.',
6832                      dest, instance=instance)
6833 
6834         self._clean_instance_console_tokens(ctxt, instance)
6835         if migrate_data and migrate_data.obj_attr_is_set('migration'):
6836             migrate_data.migration.status = 'completed'
6837             migrate_data.migration.save()
6838             self._delete_allocation_after_move(ctxt,
6839                                                instance,
6840                                                migrate_data.migration)
6841         else:
6842             # We didn't have data on a migration, which means we can't
6843             # look up to see if we had new-style migration-based
6844             # allocations. This should really only happen in cases of
6845             # a buggy virt driver. Log a warning so we know it happened.
6846             LOG.warning('Live migration ended with no migrate_data '
6847                         'record. Unable to clean up migration-based '
6848                         'allocations for node %s which is almost certainly '
6849                         'not an expected situation.', source_node,
6850                         instance=instance)
6851 
6852     def _consoles_enabled(self):
6853         """Returns whether a console is enable."""
6854         return (CONF.vnc.enabled or CONF.spice.enabled or
6855                 CONF.rdp.enabled or CONF.serial_console.enabled or
6856                 CONF.mks.enabled)
6857 
6858     def _clean_instance_console_tokens(self, ctxt, instance):
6859         """Clean console tokens stored for an instance."""
6860         # If the database backend isn't in use, don't bother trying to clean
6861         # tokens. The database backend is not supported for cells v1.
6862         if not CONF.cells.enable and self._consoles_enabled():
6863             objects.ConsoleAuthToken.\
6864                 clean_console_auths_for_instance(ctxt, instance.uuid)
6865 
6866     @wrap_exception()
6867     @wrap_instance_event(prefix='compute')
6868     @wrap_instance_fault
6869     def post_live_migration_at_destination(self, context, instance,
6870                                            block_migration):
6871         """Post operations for live migration .
6872 
6873         :param context: security context
6874         :param instance: Instance dict
6875         :param block_migration: if true, prepare for block migration
6876 
6877         """
6878         LOG.info('Post operation of migration started',
6879                  instance=instance)
6880 
6881         # NOTE(tr3buchet): setup networks on destination host
6882         #                  this is called a second time because
6883         #                  multi_host does not create the bridge in
6884         #                  plug_vifs
6885         # NOTE(mriedem): This is a no-op for neutron.
6886         self.network_api.setup_networks_on_host(context, instance,
6887                                                          self.host)
6888         migration = {'source_compute': instance.host,
6889                      'dest_compute': self.host, }
6890         self.network_api.migrate_instance_finish(context,
6891                                                  instance,
6892                                                  migration)
6893 
6894         network_info = self.network_api.get_instance_nw_info(context, instance)
6895         self._notify_about_instance_usage(
6896                      context, instance, "live_migration.post.dest.start",
6897                      network_info=network_info)
6898         compute_utils.notify_about_instance_action(context, instance,
6899                 self.host,
6900                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6901                 phase=fields.NotificationPhase.START)
6902         block_device_info = self._get_instance_block_device_info(context,
6903                                                                  instance)
6904 
6905         try:
6906             self.driver.post_live_migration_at_destination(
6907                 context, instance, network_info, block_migration,
6908                 block_device_info)
6909         except Exception:
6910             with excutils.save_and_reraise_exception():
6911                 instance.vm_state = vm_states.ERROR
6912                 LOG.error('Unexpected error during post live migration at '
6913                           'destination host.', instance=instance)
6914         finally:
6915             # Restore instance state and update host
6916             current_power_state = self._get_power_state(context, instance)
6917             node_name = None
6918             prev_host = instance.host
6919             try:
6920                 compute_node = self._get_compute_info(context, self.host)
6921                 node_name = compute_node.hypervisor_hostname
6922             except exception.ComputeHostNotFound:
6923                 LOG.exception('Failed to get compute_info for %s', self.host)
6924             finally:
6925                 instance.apply_migration_context()
6926                 instance.host = self.host
6927                 instance.power_state = current_power_state
6928                 instance.task_state = None
6929                 instance.node = node_name
6930                 instance.progress = 0
6931                 instance.save(expected_task_state=task_states.MIGRATING)
6932 
6933         # NOTE(tr3buchet): tear down networks on source host (nova-net)
6934         # NOTE(mriedem): For neutron, this will delete any inactive source
6935         # host port bindings.
6936         try:
6937             self.network_api.setup_networks_on_host(context, instance,
6938                                                     prev_host, teardown=True)
6939         except exception.PortBindingDeletionFailed as e:
6940             # Removing the inactive port bindings from the source host is not
6941             # critical so just log an error but don't fail.
6942             LOG.error('Network cleanup failed for source host %s during post '
6943                       'live migration. You may need to manually clean up '
6944                       'resources in the network service. Error: %s',
6945                       prev_host, six.text_type(e))
6946         # NOTE(vish): this is necessary to update dhcp for nova-network
6947         # NOTE(mriedem): This is a no-op for neutron.
6948         self.network_api.setup_networks_on_host(context, instance, self.host)
6949         self._notify_about_instance_usage(
6950                      context, instance, "live_migration.post.dest.end",
6951                      network_info=network_info)
6952         compute_utils.notify_about_instance_action(context, instance,
6953                 self.host,
6954                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6955                 phase=fields.NotificationPhase.END)
6956 
6957     @wrap_exception()
6958     @wrap_instance_fault
6959     def _rollback_live_migration(self, context, instance,
6960                                  dest, migrate_data=None,
6961                                  migration_status='error'):
6962         """Recovers Instance/volume state from migrating -> running.
6963 
6964         :param context: security context
6965         :param instance: nova.objects.instance.Instance object
6966         :param dest:
6967             This method is called from live migration src host.
6968             This param specifies destination host.
6969         :param migrate_data:
6970             if not none, contains implementation specific data.
6971         :param migration_status:
6972             Contains the status we want to set for the migration object
6973 
6974         """
6975         if (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
6976               migrate_data.obj_attr_is_set('migration')):
6977             migration = migrate_data.migration
6978         else:
6979             migration = None
6980 
6981         if migration:
6982             # Remove allocations created in Placement for the dest node.
6983             # If migration is None, the virt driver didn't pass it which is
6984             # a bug.
6985             self._revert_allocation(context, instance, migration)
6986         else:
6987             LOG.error('Unable to revert allocations during live migration '
6988                       'rollback; compute driver did not provide migrate_data',
6989                       instance=instance)
6990 
6991         instance.task_state = None
6992         instance.progress = 0
6993         instance.save(expected_task_state=[task_states.MIGRATING])
6994 
6995         # NOTE(tr3buchet): setup networks on source host (really it's re-setup
6996         #                  for nova-network)
6997         # NOTE(mriedem): This is a no-op for neutron.
6998         self.network_api.setup_networks_on_host(context, instance, self.host)
6999 
7000         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7001                 context, instance.uuid)
7002         for bdm in bdms:
7003             if bdm.is_volume:
7004                 # remove the connection on the destination host
7005                 self.compute_rpcapi.remove_volume_connection(
7006                         context, instance, bdm.volume_id, dest)
7007 
7008                 if bdm.attachment_id:
7009                     # 3.44 cinder api flow. Set the bdm's
7010                     # attachment_id to the old attachment of the source
7011                     # host. If old_attachments is not there, then
7012                     # there was an error before the new attachment was made.
7013                     old_attachments = migrate_data.old_vol_attachment_ids \
7014                         if 'old_vol_attachment_ids' in migrate_data else None
7015                     if old_attachments and bdm.volume_id in old_attachments:
7016                         self.volume_api.attachment_delete(context,
7017                                                           bdm.attachment_id)
7018                         bdm.attachment_id = old_attachments[bdm.volume_id]
7019                         bdm.save()
7020 
7021         self._notify_about_instance_usage(context, instance,
7022                                           "live_migration._rollback.start")
7023         compute_utils.notify_about_instance_action(context, instance,
7024                 self.host,
7025                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
7026                 phase=fields.NotificationPhase.START,
7027                 bdms=bdms)
7028 
7029         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
7030                 migrate_data)
7031         # NOTE(artom) Before NUMA live migration and the resource claim it
7032         # does, we only called rollback_live_migration_at_destination if
7033         # do_cleanup was True. Now, if the destination did a claim, we need to
7034         # call rlmad() regardless to ensure it drops the claim and migration
7035         # context that was created. We pass it do_cleanup to tell it wether an
7036         # old-style cleanup is necessary. However, if the destination isn't
7037         # aware of NUMA live migration, we need to preserve the old way of
7038         # calling it by checking do_cleanup ourselves.
7039         numa_live_migration = ('dst_numa_config' in migrate_data
7040                                and migrate_data.dst_numa_config)
7041         if do_cleanup or numa_live_migration:
7042             self.compute_rpcapi.rollback_live_migration_at_destination(
7043                     context, instance, dest, destroy_disks=destroy_disks,
7044                     migrate_data=migrate_data, do_cleanup=do_cleanup)
7045         elif utils.is_neutron():
7046             # The port binding profiles need to be cleaned up.
7047             with errors_out_migration_ctxt(migration):
7048                 try:
7049                     # This call will delete any inactive destination host
7050                     # port bindings.
7051                     self.network_api.setup_networks_on_host(
7052                         context, instance, host=dest, teardown=True)
7053                 except exception.PortBindingDeletionFailed as e:
7054                     # Removing the inactive port bindings from the destination
7055                     # host is not critical so just log an error but don't fail.
7056                     LOG.error(
7057                         'Network cleanup failed for destination host %s '
7058                         'during live migration rollback. You may need to '
7059                         'manually clean up resources in the network service. '
7060                         'Error: %s', dest, six.text_type(e))
7061                 except Exception:
7062                     with excutils.save_and_reraise_exception():
7063                         LOG.exception(
7064                             'An error occurred while cleaning up networking '
7065                             'during live migration rollback.',
7066                             instance=instance)
7067 
7068         self._notify_about_instance_usage(context, instance,
7069                                           "live_migration._rollback.end")
7070         compute_utils.notify_about_instance_action(context, instance,
7071                 self.host,
7072                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
7073                 phase=fields.NotificationPhase.END,
7074                 bdms=bdms)
7075 
7076         self._set_migration_status(migration, migration_status)
7077 
7078     @wrap_exception()
7079     @wrap_instance_event(prefix='compute')
7080     @wrap_instance_fault
7081     def rollback_live_migration_at_destination(self, context, instance,
7082                                                destroy_disks, migrate_data,
7083                                                do_cleanup=True):
7084         """Drop the MoveClaim (if one was created) for the live migration, and
7085         if necessary clean up the image directory that was created by
7086         pre_live_migration.
7087 
7088         :param context: security context
7089         :param instance: a nova.objects.instance.Instance object sent over rpc
7090         :param destroy_disks: whether to destroy volumes or not
7091         :param migrate_data: contains migration info
7092         """
7093         network_info = self.network_api.get_instance_nw_info(context, instance)
7094         self._notify_about_instance_usage(
7095                       context, instance, "live_migration.rollback.dest.start",
7096                       network_info=network_info)
7097         compute_utils.notify_about_instance_action(
7098             context, instance, self.host,
7099             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
7100             phase=fields.NotificationPhase.START)
7101         if 'dst_numa_config' in migrate_data and migrate_data.dst_numa_config:
7102             instance.drop_migration_context()
7103             self.rt.drop_move_claim(
7104                 context, instance, self._get_nodename(instance),
7105                 instance.flavor, prefix='_new')
7106         if do_cleanup:
7107             self._do_rollback_live_migration_at_destination(context, instance,
7108                                                             destroy_disks,
7109                                                             migrate_data,
7110                                                             network_info)
7111 
7112     def _do_rollback_live_migration_at_destination(self, context, instance,
7113                                                    destroy_disks,
7114                                                    migrate_data, network_info):
7115         try:
7116             # NOTE(tr3buchet): tear down networks on dest host (nova-net)
7117             # NOTE(mriedem): For neutron, this call will delete any
7118             # destination host port bindings.
7119             # TODO(mriedem): We should eventually remove this call from
7120             # this method (rollback_live_migration_at_destination) since this
7121             # method is only called conditionally based on whether or not the
7122             # instance is running on shared storage. _rollback_live_migration
7123             # already calls this method for neutron if we are running on
7124             # shared storage.
7125             self.network_api.setup_networks_on_host(context, instance,
7126                                                     self.host, teardown=True)
7127         except exception.PortBindingDeletionFailed as e:
7128             # Removing the inactive port bindings from the destination
7129             # host is not critical so just log an error but don't fail.
7130             LOG.error(
7131                 'Network cleanup failed for destination host %s '
7132                 'during live migration rollback. You may need to '
7133                 'manually clean up resources in the network service. '
7134                 'Error: %s', self.host, six.text_type(e))
7135         except Exception:
7136             with excutils.save_and_reraise_exception():
7137                 # NOTE(tdurakov): even if teardown networks fails driver
7138                 # should try to rollback live migration on destination.
7139                 LOG.exception('An error occurred while deallocating network.',
7140                               instance=instance)
7141         finally:
7142             # always run this even if setup_networks_on_host fails
7143             # NOTE(vish): The mapping is passed in so the driver can disconnect
7144             #             from remote volumes if necessary
7145             block_device_info = self._get_instance_block_device_info(context,
7146                                                                      instance)
7147             self.driver.rollback_live_migration_at_destination(
7148                 context, instance, network_info, block_device_info,
7149                 destroy_disks=destroy_disks, migrate_data=migrate_data)
7150 
7151         self._notify_about_instance_usage(
7152                         context, instance, "live_migration.rollback.dest.end",
7153                         network_info=network_info)
7154         compute_utils.notify_about_instance_action(
7155             context, instance, self.host,
7156             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
7157             phase=fields.NotificationPhase.END)
7158 
7159     @periodic_task.periodic_task(
7160         spacing=CONF.heal_instance_info_cache_interval)
7161     def _heal_instance_info_cache(self, context):
7162         """Called periodically.  On every call, try to update the
7163         info_cache's network information for another instance by
7164         calling to the network manager.
7165 
7166         This is implemented by keeping a cache of uuids of instances
7167         that live on this host.  On each call, we pop one off of a
7168         list, pull the DB record, and try the call to the network API.
7169         If anything errors don't fail, as it's possible the instance
7170         has been deleted, etc.
7171         """
7172         heal_interval = CONF.heal_instance_info_cache_interval
7173         if not heal_interval:
7174             return
7175 
7176         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
7177         instance = None
7178 
7179         LOG.debug('Starting heal instance info cache')
7180 
7181         if not instance_uuids:
7182             # The list of instances to heal is empty so rebuild it
7183             LOG.debug('Rebuilding the list of instances to heal')
7184             db_instances = objects.InstanceList.get_by_host(
7185                 context, self.host, expected_attrs=[], use_slave=True)
7186             for inst in db_instances:
7187                 # We don't want to refresh the cache for instances
7188                 # which are building or deleting so don't put them
7189                 # in the list. If they are building they will get
7190                 # added to the list next time we build it.
7191                 if (inst.vm_state == vm_states.BUILDING):
7192                     LOG.debug('Skipping network cache update for instance '
7193                               'because it is Building.', instance=inst)
7194                     continue
7195                 if (inst.task_state == task_states.DELETING):
7196                     LOG.debug('Skipping network cache update for instance '
7197                               'because it is being deleted.', instance=inst)
7198                     continue
7199 
7200                 if not instance:
7201                     # Save the first one we find so we don't
7202                     # have to get it again
7203                     instance = inst
7204                 else:
7205                     instance_uuids.append(inst['uuid'])
7206 
7207             self._instance_uuids_to_heal = instance_uuids
7208         else:
7209             # Find the next valid instance on the list
7210             while instance_uuids:
7211                 try:
7212                     inst = objects.Instance.get_by_uuid(
7213                             context, instance_uuids.pop(0),
7214                             expected_attrs=['system_metadata', 'info_cache',
7215                                             'flavor'],
7216                             use_slave=True)
7217                 except exception.InstanceNotFound:
7218                     # Instance is gone.  Try to grab another.
7219                     continue
7220 
7221                 # Check the instance hasn't been migrated
7222                 if inst.host != self.host:
7223                     LOG.debug('Skipping network cache update for instance '
7224                               'because it has been migrated to another '
7225                               'host.', instance=inst)
7226                 # Check the instance isn't being deleting
7227                 elif inst.task_state == task_states.DELETING:
7228                     LOG.debug('Skipping network cache update for instance '
7229                               'because it is being deleted.', instance=inst)
7230                 else:
7231                     instance = inst
7232                     break
7233 
7234         if instance:
7235             # We have an instance now to refresh
7236             try:
7237                 # Call to network API to get instance info.. this will
7238                 # force an update to the instance's info_cache
7239                 self.network_api.get_instance_nw_info(
7240                     context, instance, force_refresh=True)
7241                 LOG.debug('Updated the network info_cache for instance',
7242                           instance=instance)
7243             except exception.InstanceNotFound:
7244                 # Instance is gone.
7245                 LOG.debug('Instance no longer exists. Unable to refresh',
7246                           instance=instance)
7247                 return
7248             except exception.InstanceInfoCacheNotFound:
7249                 # InstanceInfoCache is gone.
7250                 LOG.debug('InstanceInfoCache no longer exists. '
7251                           'Unable to refresh', instance=instance)
7252             except Exception:
7253                 LOG.error('An error occurred while refreshing the network '
7254                           'cache.', instance=instance, exc_info=True)
7255         else:
7256             LOG.debug("Didn't find any instances for network info cache "
7257                       "update.")
7258 
7259     @periodic_task.periodic_task
7260     def _poll_rebooting_instances(self, context):
7261         if CONF.reboot_timeout > 0:
7262             filters = {'task_state':
7263                        [task_states.REBOOTING,
7264                         task_states.REBOOT_STARTED,
7265                         task_states.REBOOT_PENDING],
7266                        'host': self.host}
7267             rebooting = objects.InstanceList.get_by_filters(
7268                 context, filters, expected_attrs=[], use_slave=True)
7269 
7270             to_poll = []
7271             for instance in rebooting:
7272                 if timeutils.is_older_than(instance.updated_at,
7273                                            CONF.reboot_timeout):
7274                     to_poll.append(instance)
7275 
7276             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
7277 
7278     @periodic_task.periodic_task
7279     def _poll_rescued_instances(self, context):
7280         if CONF.rescue_timeout > 0:
7281             filters = {'vm_state': vm_states.RESCUED,
7282                        'host': self.host}
7283             rescued_instances = objects.InstanceList.get_by_filters(
7284                 context, filters, expected_attrs=["system_metadata"],
7285                 use_slave=True)
7286 
7287             to_unrescue = []
7288             for instance in rescued_instances:
7289                 if timeutils.is_older_than(instance.launched_at,
7290                                            CONF.rescue_timeout):
7291                     to_unrescue.append(instance)
7292 
7293             for instance in to_unrescue:
7294                 self.compute_api.unrescue(context, instance)
7295 
7296     @periodic_task.periodic_task
7297     def _poll_unconfirmed_resizes(self, context):
7298         if CONF.resize_confirm_window == 0:
7299             return
7300 
7301         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
7302                 context, CONF.resize_confirm_window, self.host,
7303                 use_slave=True)
7304 
7305         migrations_info = dict(migration_count=len(migrations),
7306                 confirm_window=CONF.resize_confirm_window)
7307 
7308         if migrations_info["migration_count"] > 0:
7309             LOG.info("Found %(migration_count)d unconfirmed migrations "
7310                      "older than %(confirm_window)d seconds",
7311                      migrations_info)
7312 
7313         def _set_migration_to_error(migration, reason, **kwargs):
7314             LOG.warning("Setting migration %(migration_id)s to error: "
7315                         "%(reason)s",
7316                         {'migration_id': migration['id'], 'reason': reason},
7317                         **kwargs)
7318             migration.status = 'error'
7319             with migration.obj_as_admin():
7320                 migration.save()
7321 
7322         for migration in migrations:
7323             instance_uuid = migration.instance_uuid
7324             LOG.info("Automatically confirming migration "
7325                      "%(migration_id)s for instance %(instance_uuid)s",
7326                      {'migration_id': migration.id,
7327                       'instance_uuid': instance_uuid})
7328             expected_attrs = ['metadata', 'system_metadata']
7329             try:
7330                 instance = objects.Instance.get_by_uuid(context,
7331                             instance_uuid, expected_attrs=expected_attrs,
7332                             use_slave=True)
7333             except exception.InstanceNotFound:
7334                 reason = (_("Instance %s not found") %
7335                           instance_uuid)
7336                 _set_migration_to_error(migration, reason)
7337                 continue
7338             if instance.vm_state == vm_states.ERROR:
7339                 reason = _("In ERROR state")
7340                 _set_migration_to_error(migration, reason,
7341                                         instance=instance)
7342                 continue
7343             # race condition: The instance in DELETING state should not be
7344             # set the migration state to error, otherwise the instance in
7345             # to be deleted which is in RESIZED state
7346             # will not be able to confirm resize
7347             if instance.task_state in [task_states.DELETING,
7348                                        task_states.SOFT_DELETING]:
7349                 msg = ("Instance being deleted or soft deleted during resize "
7350                        "confirmation. Skipping.")
7351                 LOG.debug(msg, instance=instance)
7352                 continue
7353 
7354             # race condition: This condition is hit when this method is
7355             # called between the save of the migration record with a status of
7356             # finished and the save of the instance object with a state of
7357             # RESIZED. The migration record should not be set to error.
7358             if instance.task_state == task_states.RESIZE_FINISH:
7359                 msg = ("Instance still resizing during resize "
7360                        "confirmation. Skipping.")
7361                 LOG.debug(msg, instance=instance)
7362                 continue
7363 
7364             vm_state = instance.vm_state
7365             task_state = instance.task_state
7366             if vm_state != vm_states.RESIZED or task_state is not None:
7367                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
7368                            "RESIZED/None") %
7369                           {'vm_state': vm_state,
7370                            'task_state': task_state})
7371                 _set_migration_to_error(migration, reason,
7372                                         instance=instance)
7373                 continue
7374             try:
7375                 self.compute_api.confirm_resize(context, instance,
7376                                                 migration=migration)
7377             except Exception as e:
7378                 LOG.info("Error auto-confirming resize: %s. "
7379                          "Will retry later.", e, instance=instance)
7380 
7381     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
7382     def _poll_shelved_instances(self, context):
7383 
7384         if CONF.shelved_offload_time <= 0:
7385             return
7386 
7387         filters = {'vm_state': vm_states.SHELVED,
7388                    'task_state': None,
7389                    'host': self.host}
7390         shelved_instances = objects.InstanceList.get_by_filters(
7391             context, filters=filters, expected_attrs=['system_metadata'],
7392             use_slave=True)
7393 
7394         to_gc = []
7395         for instance in shelved_instances:
7396             sys_meta = instance.system_metadata
7397             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
7398             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
7399                 to_gc.append(instance)
7400 
7401         for instance in to_gc:
7402             try:
7403                 instance.task_state = task_states.SHELVING_OFFLOADING
7404                 instance.save(expected_task_state=(None,))
7405                 self.shelve_offload_instance(context, instance,
7406                                              clean_shutdown=False)
7407             except Exception:
7408                 LOG.exception('Periodic task failed to offload instance.',
7409                               instance=instance)
7410 
7411     @periodic_task.periodic_task
7412     def _instance_usage_audit(self, context):
7413         if not CONF.instance_usage_audit:
7414             return
7415 
7416         begin, end = utils.last_completed_audit_period()
7417         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
7418                                self.host):
7419             return
7420 
7421         instances = objects.InstanceList.get_active_by_window_joined(
7422             context, begin, end, host=self.host,
7423             expected_attrs=['system_metadata', 'info_cache', 'metadata',
7424                             'flavor'],
7425             use_slave=True)
7426         num_instances = len(instances)
7427         errors = 0
7428         successes = 0
7429         LOG.info("Running instance usage audit for host %(host)s "
7430                  "from %(begin_time)s to %(end_time)s. "
7431                  "%(number_instances)s instances.",
7432                  {'host': self.host,
7433                   'begin_time': begin,
7434                   'end_time': end,
7435                   'number_instances': num_instances})
7436         start_time = time.time()
7437         task_log = objects.TaskLog(context)
7438         task_log.task_name = 'instance_usage_audit'
7439         task_log.period_beginning = begin
7440         task_log.period_ending = end
7441         task_log.host = self.host
7442         task_log.task_items = num_instances
7443         task_log.message = 'Instance usage audit started...'
7444         task_log.begin_task()
7445         for instance in instances:
7446             try:
7447                 compute_utils.notify_usage_exists(
7448                     self.notifier, context, instance, self.host,
7449                     ignore_missing_network_data=False)
7450                 successes += 1
7451             except Exception:
7452                 LOG.exception('Failed to generate usage '
7453                               'audit for instance '
7454                               'on host %s', self.host,
7455                               instance=instance)
7456                 errors += 1
7457         task_log.errors = errors
7458         task_log.message = (
7459             'Instance usage audit ran for host %s, %s instances in %s seconds.'
7460             % (self.host, num_instances, time.time() - start_time))
7461         task_log.end_task()
7462 
7463     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
7464     def _poll_bandwidth_usage(self, context):
7465 
7466         if not self._bw_usage_supported:
7467             return
7468 
7469         prev_time, start_time = utils.last_completed_audit_period()
7470 
7471         curr_time = time.time()
7472         if (curr_time - self._last_bw_usage_poll >
7473                 CONF.bandwidth_poll_interval):
7474             self._last_bw_usage_poll = curr_time
7475             LOG.info("Updating bandwidth usage cache")
7476             cells_update_interval = CONF.cells.bandwidth_update_interval
7477             if (cells_update_interval > 0 and
7478                    curr_time - self._last_bw_usage_cell_update >
7479                            cells_update_interval):
7480                 self._last_bw_usage_cell_update = curr_time
7481                 update_cells = True
7482             else:
7483                 update_cells = False
7484 
7485             instances = objects.InstanceList.get_by_host(context,
7486                                                               self.host,
7487                                                               use_slave=True)
7488             try:
7489                 bw_counters = self.driver.get_all_bw_counters(instances)
7490             except NotImplementedError:
7491                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
7492                 # implemented yet.  If they don't it doesn't break anything,
7493                 # they just don't get the info in the usage events.
7494                 # NOTE(PhilDay): Record that its not supported so we can
7495                 # skip fast on future calls rather than waste effort getting
7496                 # the list of instances.
7497                 LOG.info("Bandwidth usage not supported by %(driver)s.",
7498                          {'driver': CONF.compute_driver})
7499                 self._bw_usage_supported = False
7500                 return
7501 
7502             refreshed = timeutils.utcnow()
7503             for bw_ctr in bw_counters:
7504                 # Allow switching of greenthreads between queries.
7505                 greenthread.sleep(0)
7506                 bw_in = 0
7507                 bw_out = 0
7508                 last_ctr_in = None
7509                 last_ctr_out = None
7510                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
7511                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
7512                     start_period=start_time, use_slave=True)
7513                 if usage:
7514                     bw_in = usage.bw_in
7515                     bw_out = usage.bw_out
7516                     last_ctr_in = usage.last_ctr_in
7517                     last_ctr_out = usage.last_ctr_out
7518                 else:
7519                     usage = (objects.BandwidthUsage.
7520                              get_by_instance_uuid_and_mac(
7521                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
7522                         start_period=prev_time, use_slave=True))
7523                     if usage:
7524                         last_ctr_in = usage.last_ctr_in
7525                         last_ctr_out = usage.last_ctr_out
7526 
7527                 if last_ctr_in is not None:
7528                     if bw_ctr['bw_in'] < last_ctr_in:
7529                         # counter rollover
7530                         bw_in += bw_ctr['bw_in']
7531                     else:
7532                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
7533 
7534                 if last_ctr_out is not None:
7535                     if bw_ctr['bw_out'] < last_ctr_out:
7536                         # counter rollover
7537                         bw_out += bw_ctr['bw_out']
7538                     else:
7539                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
7540 
7541                 objects.BandwidthUsage(context=context).create(
7542                                               bw_ctr['uuid'],
7543                                               bw_ctr['mac_address'],
7544                                               bw_in,
7545                                               bw_out,
7546                                               bw_ctr['bw_in'],
7547                                               bw_ctr['bw_out'],
7548                                               start_period=start_time,
7549                                               last_refreshed=refreshed,
7550                                               update_cells=update_cells)
7551 
7552     def _get_host_volume_bdms(self, context, use_slave=False):
7553         """Return all block device mappings on a compute host."""
7554         compute_host_bdms = []
7555         instances = objects.InstanceList.get_by_host(context, self.host,
7556             use_slave=use_slave)
7557         for instance in instances:
7558             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7559                     context, instance.uuid, use_slave=use_slave)
7560             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
7561             compute_host_bdms.append(dict(instance=instance,
7562                                           instance_bdms=instance_bdms))
7563 
7564         return compute_host_bdms
7565 
7566     def _update_volume_usage_cache(self, context, vol_usages):
7567         """Updates the volume usage cache table with a list of stats."""
7568         for usage in vol_usages:
7569             # Allow switching of greenthreads between queries.
7570             greenthread.sleep(0)
7571             vol_usage = objects.VolumeUsage(context)
7572             vol_usage.volume_id = usage['volume']
7573             vol_usage.instance_uuid = usage['instance'].uuid
7574             vol_usage.project_id = usage['instance'].project_id
7575             vol_usage.user_id = usage['instance'].user_id
7576             vol_usage.availability_zone = usage['instance'].availability_zone
7577             vol_usage.curr_reads = usage['rd_req']
7578             vol_usage.curr_read_bytes = usage['rd_bytes']
7579             vol_usage.curr_writes = usage['wr_req']
7580             vol_usage.curr_write_bytes = usage['wr_bytes']
7581             vol_usage.save()
7582             self.notifier.info(context, 'volume.usage', vol_usage.to_dict())
7583             compute_utils.notify_about_volume_usage(context, vol_usage,
7584                                                     self.host)
7585 
7586     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
7587     def _poll_volume_usage(self, context):
7588         if CONF.volume_usage_poll_interval == 0:
7589             return
7590 
7591         compute_host_bdms = self._get_host_volume_bdms(context,
7592                                                        use_slave=True)
7593         if not compute_host_bdms:
7594             return
7595 
7596         LOG.debug("Updating volume usage cache")
7597         try:
7598             vol_usages = self.driver.get_all_volume_usage(context,
7599                                                           compute_host_bdms)
7600         except NotImplementedError:
7601             return
7602 
7603         self._update_volume_usage_cache(context, vol_usages)
7604 
7605     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
7606                                  run_immediately=True)
7607     def _sync_power_states(self, context):
7608         """Align power states between the database and the hypervisor.
7609 
7610         To sync power state data we make a DB call to get the number of
7611         virtual machines known by the hypervisor and if the number matches the
7612         number of virtual machines known by the database, we proceed in a lazy
7613         loop, one database record at a time, checking if the hypervisor has the
7614         same power state as is in the database.
7615         """
7616         db_instances = objects.InstanceList.get_by_host(context, self.host,
7617                                                         expected_attrs=[],
7618                                                         use_slave=True)
7619 
7620         try:
7621             num_vm_instances = self.driver.get_num_instances()
7622         except exception.VirtDriverNotReady as e:
7623             # If the virt driver is not ready, like ironic-api not being up
7624             # yet in the case of ironic, just log it and exit.
7625             LOG.info('Skipping _sync_power_states periodic task due to: %s', e)
7626             return
7627 
7628         num_db_instances = len(db_instances)
7629 
7630         if num_vm_instances != num_db_instances:
7631             LOG.warning("While synchronizing instance power states, found "
7632                         "%(num_db_instances)s instances in the database "
7633                         "and %(num_vm_instances)s instances on the "
7634                         "hypervisor.",
7635                         {'num_db_instances': num_db_instances,
7636                          'num_vm_instances': num_vm_instances})
7637 
7638         def _sync(db_instance):
7639             # NOTE(melwitt): This must be synchronized as we query state from
7640             #                two separate sources, the driver and the database.
7641             #                They are set (in stop_instance) and read, in sync.
7642             @utils.synchronized(db_instance.uuid)
7643             def query_driver_power_state_and_sync():
7644                 self._query_driver_power_state_and_sync(context, db_instance)
7645 
7646             try:
7647                 query_driver_power_state_and_sync()
7648             except Exception:
7649                 LOG.exception("Periodic sync_power_state task had an "
7650                               "error while processing an instance.",
7651                               instance=db_instance)
7652 
7653             self._syncs_in_progress.pop(db_instance.uuid)
7654 
7655         for db_instance in db_instances:
7656             # process syncs asynchronously - don't want instance locking to
7657             # block entire periodic task thread
7658             uuid = db_instance.uuid
7659             if uuid in self._syncs_in_progress:
7660                 LOG.debug('Sync already in progress for %s', uuid)
7661             else:
7662                 LOG.debug('Triggering sync for uuid %s', uuid)
7663                 self._syncs_in_progress[uuid] = True
7664                 self._sync_power_pool.spawn_n(_sync, db_instance)
7665 
7666     def _query_driver_power_state_and_sync(self, context, db_instance):
7667         if db_instance.task_state is not None:
7668             LOG.info("During sync_power_state the instance has a "
7669                      "pending task (%(task)s). Skip.",
7670                      {'task': db_instance.task_state}, instance=db_instance)
7671             return
7672         # No pending tasks. Now try to figure out the real vm_power_state.
7673         try:
7674             vm_instance = self.driver.get_info(db_instance)
7675             vm_power_state = vm_instance.state
7676         except exception.InstanceNotFound:
7677             vm_power_state = power_state.NOSTATE
7678         # Note(maoy): the above get_info call might take a long time,
7679         # for example, because of a broken libvirt driver.
7680         try:
7681             self._sync_instance_power_state(context,
7682                                             db_instance,
7683                                             vm_power_state,
7684                                             use_slave=True)
7685         except exception.InstanceNotFound:
7686             # NOTE(hanlind): If the instance gets deleted during sync,
7687             # silently ignore.
7688             pass
7689 
7690     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
7691                                    use_slave=False):
7692         """Align instance power state between the database and hypervisor.
7693 
7694         If the instance is not found on the hypervisor, but is in the database,
7695         then a stop() API will be called on the instance.
7696         """
7697 
7698         # We re-query the DB to get the latest instance info to minimize
7699         # (not eliminate) race condition.
7700         db_instance.refresh(use_slave=use_slave)
7701         db_power_state = db_instance.power_state
7702         vm_state = db_instance.vm_state
7703 
7704         if self.host != db_instance.host:
7705             # on the sending end of nova-compute _sync_power_state
7706             # may have yielded to the greenthread performing a live
7707             # migration; this in turn has changed the resident-host
7708             # for the VM; However, the instance is still active, it
7709             # is just in the process of migrating to another host.
7710             # This implies that the compute source must relinquish
7711             # control to the compute destination.
7712             LOG.info("During the sync_power process the "
7713                      "instance has moved from "
7714                      "host %(src)s to host %(dst)s",
7715                      {'src': db_instance.host,
7716                       'dst': self.host},
7717                      instance=db_instance)
7718             return
7719         elif db_instance.task_state is not None:
7720             # on the receiving end of nova-compute, it could happen
7721             # that the DB instance already report the new resident
7722             # but the actual VM has not showed up on the hypervisor
7723             # yet. In this case, let's allow the loop to continue
7724             # and run the state sync in a later round
7725             LOG.info("During sync_power_state the instance has a "
7726                      "pending task (%(task)s). Skip.",
7727                      {'task': db_instance.task_state},
7728                      instance=db_instance)
7729             return
7730 
7731         orig_db_power_state = db_power_state
7732         if vm_power_state != db_power_state:
7733             LOG.info('During _sync_instance_power_state the DB '
7734                      'power_state (%(db_power_state)s) does not match '
7735                      'the vm_power_state from the hypervisor '
7736                      '(%(vm_power_state)s). Updating power_state in the '
7737                      'DB to match the hypervisor.',
7738                      {'db_power_state': db_power_state,
7739                       'vm_power_state': vm_power_state},
7740                      instance=db_instance)
7741             # power_state is always updated from hypervisor to db
7742             db_instance.power_state = vm_power_state
7743             db_instance.save()
7744             db_power_state = vm_power_state
7745 
7746         # Note(maoy): Now resolve the discrepancy between vm_state and
7747         # vm_power_state. We go through all possible vm_states.
7748         if vm_state in (vm_states.BUILDING,
7749                         vm_states.RESCUED,
7750                         vm_states.RESIZED,
7751                         vm_states.SUSPENDED,
7752                         vm_states.ERROR):
7753             # TODO(maoy): we ignore these vm_state for now.
7754             pass
7755         elif vm_state == vm_states.ACTIVE:
7756             # The only rational power state should be RUNNING
7757             if vm_power_state in (power_state.SHUTDOWN,
7758                                   power_state.CRASHED):
7759                 LOG.warning("Instance shutdown by itself. Calling the "
7760                             "stop API. Current vm_state: %(vm_state)s, "
7761                             "current task_state: %(task_state)s, "
7762                             "original DB power_state: %(db_power_state)s, "
7763                             "current VM power_state: %(vm_power_state)s",
7764                             {'vm_state': vm_state,
7765                              'task_state': db_instance.task_state,
7766                              'db_power_state': orig_db_power_state,
7767                              'vm_power_state': vm_power_state},
7768                             instance=db_instance)
7769                 try:
7770                     # Note(maoy): here we call the API instead of
7771                     # brutally updating the vm_state in the database
7772                     # to allow all the hooks and checks to be performed.
7773                     if db_instance.shutdown_terminate:
7774                         self.compute_api.delete(context, db_instance)
7775                     else:
7776                         self.compute_api.stop(context, db_instance)
7777                 except Exception:
7778                     # Note(maoy): there is no need to propagate the error
7779                     # because the same power_state will be retrieved next
7780                     # time and retried.
7781                     # For example, there might be another task scheduled.
7782                     LOG.exception("error during stop() in sync_power_state.",
7783                                   instance=db_instance)
7784             elif vm_power_state == power_state.SUSPENDED:
7785                 LOG.warning("Instance is suspended unexpectedly. Calling "
7786                             "the stop API.", instance=db_instance)
7787                 try:
7788                     self.compute_api.stop(context, db_instance)
7789                 except Exception:
7790                     LOG.exception("error during stop() in sync_power_state.",
7791                                   instance=db_instance)
7792             elif vm_power_state == power_state.PAUSED:
7793                 # Note(maoy): a VM may get into the paused state not only
7794                 # because the user request via API calls, but also
7795                 # due to (temporary) external instrumentations.
7796                 # Before the virt layer can reliably report the reason,
7797                 # we simply ignore the state discrepancy. In many cases,
7798                 # the VM state will go back to running after the external
7799                 # instrumentation is done. See bug 1097806 for details.
7800                 LOG.warning("Instance is paused unexpectedly. Ignore.",
7801                             instance=db_instance)
7802             elif vm_power_state == power_state.NOSTATE:
7803                 # Occasionally, depending on the status of the hypervisor,
7804                 # which could be restarting for example, an instance may
7805                 # not be found.  Therefore just log the condition.
7806                 LOG.warning("Instance is unexpectedly not found. Ignore.",
7807                             instance=db_instance)
7808         elif vm_state == vm_states.STOPPED:
7809             if vm_power_state not in (power_state.NOSTATE,
7810                                       power_state.SHUTDOWN,
7811                                       power_state.CRASHED):
7812                 LOG.warning("Instance is not stopped. Calling "
7813                             "the stop API. Current vm_state: %(vm_state)s,"
7814                             " current task_state: %(task_state)s, "
7815                             "original DB power_state: %(db_power_state)s, "
7816                             "current VM power_state: %(vm_power_state)s",
7817                             {'vm_state': vm_state,
7818                              'task_state': db_instance.task_state,
7819                              'db_power_state': orig_db_power_state,
7820                              'vm_power_state': vm_power_state},
7821                             instance=db_instance)
7822                 try:
7823                     # NOTE(russellb) Force the stop, because normally the
7824                     # compute API would not allow an attempt to stop a stopped
7825                     # instance.
7826                     self.compute_api.force_stop(context, db_instance)
7827                 except Exception:
7828                     LOG.exception("error during stop() in sync_power_state.",
7829                                   instance=db_instance)
7830         elif vm_state == vm_states.PAUSED:
7831             if vm_power_state in (power_state.SHUTDOWN,
7832                                   power_state.CRASHED):
7833                 LOG.warning("Paused instance shutdown by itself. Calling "
7834                             "the stop API.", instance=db_instance)
7835                 try:
7836                     self.compute_api.force_stop(context, db_instance)
7837                 except Exception:
7838                     LOG.exception("error during stop() in sync_power_state.",
7839                                   instance=db_instance)
7840         elif vm_state in (vm_states.SOFT_DELETED,
7841                           vm_states.DELETED):
7842             if vm_power_state not in (power_state.NOSTATE,
7843                                       power_state.SHUTDOWN):
7844                 # Note(maoy): this should be taken care of periodically in
7845                 # _cleanup_running_deleted_instances().
7846                 LOG.warning("Instance is not (soft-)deleted.",
7847                             instance=db_instance)
7848 
7849     @periodic_task.periodic_task
7850     def _reclaim_queued_deletes(self, context):
7851         """Reclaim instances that are queued for deletion."""
7852         interval = CONF.reclaim_instance_interval
7853         if interval <= 0:
7854             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
7855             return
7856 
7857         filters = {'vm_state': vm_states.SOFT_DELETED,
7858                    'task_state': None,
7859                    'host': self.host}
7860         instances = objects.InstanceList.get_by_filters(
7861             context, filters,
7862             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
7863             use_slave=True)
7864         for instance in instances:
7865             if self._deleted_old_enough(instance, interval):
7866                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7867                         context, instance.uuid)
7868                 LOG.info('Reclaiming deleted instance', instance=instance)
7869                 try:
7870                     self._delete_instance(context, instance, bdms)
7871                 except Exception as e:
7872                     LOG.warning("Periodic reclaim failed to delete "
7873                                 "instance: %s",
7874                                 e, instance=instance)
7875 
7876     def _get_nodename(self, instance, refresh=False):
7877         """Helper method to get the name of the first available node
7878         on this host. This method should not be used with any operations
7879         on ironic instances since it does not handle multiple nodes.
7880         """
7881         node = self.driver.get_available_nodes(refresh=refresh)[0]
7882         LOG.debug("No node specified, defaulting to %s", node,
7883                   instance=instance)
7884         return node
7885 
7886     def _update_available_resource_for_node(self, context, nodename,
7887                                             startup=False):
7888 
7889         try:
7890             self.rt.update_available_resource(context, nodename,
7891                                               startup=startup)
7892         except exception.ComputeHostNotFound:
7893             LOG.warning("Compute node '%s' not found in "
7894                         "update_available_resource.", nodename)
7895         except exception.ReshapeFailed:
7896             # We're only supposed to get here on startup, if a reshape was
7897             # needed, was attempted, and failed. We want to kill the service.
7898             with excutils.save_and_reraise_exception():
7899                 LOG.critical("Resource provider data migration failed "
7900                              "fatally during startup for node %s.", nodename)
7901         except exception.ReshapeNeeded:
7902             # This exception should only find its way here if the virt driver's
7903             # update_provider_tree raised it incorrectly: either
7904             # a) After the resource tracker already caught it once and
7905             # reinvoked update_provider_tree with allocations. At this point
7906             # the driver is just supposed to *do* the reshape, so if it raises
7907             # ReshapeNeeded, it's a bug, and we want to kill the compute
7908             # service.
7909             # b) On periodic rather than startup (we only allow reshapes to
7910             # happen on startup). In this case we'll just make the logs red and
7911             # go again at the next periodic interval, where the same thing may
7912             # or may not happen again. Depending on the previous and intended
7913             # shape of the providers/inventories, this may not actually cause
7914             # any immediately visible symptoms (in terms of scheduling, etc.)
7915             # If this becomes a problem, we may wish to make it pop immediately
7916             # (e.g. disable the service).
7917             with excutils.save_and_reraise_exception():
7918                 LOG.exception("ReshapeNeeded exception is unexpected here!")
7919         except Exception:
7920             LOG.exception("Error updating resources for node %(node)s.",
7921                           {'node': nodename})
7922 
7923     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
7924     def update_available_resource(self, context, startup=False):
7925         """See driver.get_available_resource()
7926 
7927         Periodic process that keeps that the compute host's understanding of
7928         resource availability and usage in sync with the underlying hypervisor.
7929 
7930         :param context: security context
7931         :param startup: True if this is being called when the nova-compute
7932             service is starting, False otherwise.
7933         """
7934 
7935         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
7936                                                             use_slave=True,
7937                                                             startup=startup)
7938         try:
7939             nodenames = set(self.driver.get_available_nodes())
7940         except exception.VirtDriverNotReady:
7941             LOG.warning("Virt driver is not ready.")
7942             return
7943 
7944         # Delete orphan compute node not reported by driver but still in db
7945         for cn in compute_nodes_in_db:
7946             if cn.hypervisor_hostname not in nodenames:
7947                 LOG.info("Deleting orphan compute node %(id)s "
7948                          "hypervisor host is %(hh)s, "
7949                          "nodes are %(nodes)s",
7950                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
7951                           'nodes': nodenames})
7952                 cn.destroy()
7953                 self.rt.remove_node(cn.hypervisor_hostname)
7954                 # Delete the corresponding resource provider in placement,
7955                 # along with any associated allocations and inventory.
7956                 self.reportclient.delete_resource_provider(context, cn,
7957                                                            cascade=True)
7958 
7959         for nodename in nodenames:
7960             self._update_available_resource_for_node(context, nodename,
7961                                                      startup=startup)
7962 
7963     def _get_compute_nodes_in_db(self, context, use_slave=False,
7964                                  startup=False):
7965         try:
7966             return objects.ComputeNodeList.get_all_by_host(context, self.host,
7967                                                            use_slave=use_slave)
7968         except exception.NotFound:
7969             if startup:
7970                 LOG.warning(
7971                     "No compute node record found for host %s. If this is "
7972                     "the first time this service is starting on this "
7973                     "host, then you can ignore this warning.", self.host)
7974             else:
7975                 LOG.error("No compute node record for host %s", self.host)
7976             return []
7977 
7978     @periodic_task.periodic_task(
7979         spacing=CONF.running_deleted_instance_poll_interval)
7980     def _cleanup_running_deleted_instances(self, context):
7981         """Cleanup any instances which are erroneously still running after
7982         having been deleted.
7983 
7984         Valid actions to take are:
7985 
7986             1. noop - do nothing
7987             2. log - log which instances are erroneously running
7988             3. reap - shutdown and cleanup any erroneously running instances
7989             4. shutdown - power off *and disable* any erroneously running
7990                           instances
7991 
7992         The use-case for this cleanup task is: for various reasons, it may be
7993         possible for the database to show an instance as deleted but for that
7994         instance to still be running on a host machine (see bug
7995         https://bugs.launchpad.net/nova/+bug/911366).
7996 
7997         This cleanup task is a cross-hypervisor utility for finding these
7998         zombied instances and either logging the discrepancy (likely what you
7999         should do in production), or automatically reaping the instances (more
8000         appropriate for dev environments).
8001         """
8002         action = CONF.running_deleted_instance_action
8003 
8004         if action == "noop":
8005             return
8006 
8007         # NOTE(sirp): admin contexts don't ordinarily return deleted records
8008         with utils.temporary_mutation(context, read_deleted="yes"):
8009             for instance in self._running_deleted_instances(context):
8010                 if action == "log":
8011                     LOG.warning("Detected instance with name label "
8012                                 "'%s' which is marked as "
8013                                 "DELETED but still present on host.",
8014                                 instance.name, instance=instance)
8015 
8016                 elif action == 'shutdown':
8017                     LOG.info("Powering off instance with name label "
8018                              "'%s' which is marked as "
8019                              "DELETED but still present on host.",
8020                              instance.name, instance=instance)
8021                     try:
8022                         try:
8023                             # disable starting the instance
8024                             self.driver.set_bootable(instance, False)
8025                         except NotImplementedError:
8026                             LOG.debug("set_bootable is not implemented "
8027                                       "for the current driver")
8028                         # and power it off
8029                         self.driver.power_off(instance)
8030                     except Exception:
8031                         LOG.warning("Failed to power off instance",
8032                                     instance=instance, exc_info=True)
8033 
8034                 elif action == 'reap':
8035                     LOG.info("Destroying instance with name label "
8036                              "'%s' which is marked as "
8037                              "DELETED but still present on host.",
8038                              instance.name, instance=instance)
8039                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
8040                         context, instance.uuid, use_slave=True)
8041                     self.instance_events.clear_events_for_instance(instance)
8042                     try:
8043                         self._shutdown_instance(context, instance, bdms,
8044                                                 notify=False)
8045                         self._cleanup_volumes(context, instance, bdms,
8046                                               detach=False)
8047                     except Exception as e:
8048                         LOG.warning("Periodic cleanup failed to delete "
8049                                     "instance: %s",
8050                                     e, instance=instance)
8051                 else:
8052                     raise Exception(_("Unrecognized value '%s'"
8053                                       " for CONF.running_deleted_"
8054                                       "instance_action") % action)
8055 
8056     def _running_deleted_instances(self, context):
8057         """Returns a list of instances nova thinks is deleted,
8058         but the hypervisor thinks is still running.
8059         """
8060         timeout = CONF.running_deleted_instance_timeout
8061         filters = {'deleted': True,
8062                    'soft_deleted': False}
8063         instances = self._get_instances_on_driver(context, filters)
8064         return [i for i in instances if self._deleted_old_enough(i, timeout)]
8065 
8066     def _deleted_old_enough(self, instance, timeout):
8067         deleted_at = instance.deleted_at
8068         if deleted_at:
8069             deleted_at = deleted_at.replace(tzinfo=None)
8070         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
8071 
8072     @contextlib.contextmanager
8073     def _error_out_instance_on_exception(self, context, instance,
8074                                          instance_state=vm_states.ACTIVE):
8075         instance_uuid = instance.uuid
8076         try:
8077             yield
8078         except NotImplementedError as error:
8079             with excutils.save_and_reraise_exception():
8080                 LOG.info("Setting instance back to %(state)s after: "
8081                          "%(error)s",
8082                          {'state': instance_state, 'error': error},
8083                          instance_uuid=instance_uuid)
8084                 self._instance_update(context, instance,
8085                                       vm_state=instance_state,
8086                                       task_state=None)
8087         except exception.InstanceFaultRollback as error:
8088             LOG.info("Setting instance back to ACTIVE after: %s",
8089                      error, instance_uuid=instance_uuid)
8090             self._instance_update(context, instance,
8091                                   vm_state=vm_states.ACTIVE,
8092                                   task_state=None)
8093             raise error.inner_exception
8094         except Exception:
8095             LOG.exception('Setting instance vm_state to ERROR',
8096                           instance_uuid=instance_uuid)
8097             with excutils.save_and_reraise_exception():
8098                 self._set_instance_obj_error_state(context, instance)
8099 
8100     @wrap_exception()
8101     def add_aggregate_host(self, context, aggregate, host, slave_info):
8102         """Notify hypervisor of change (for hypervisor pools)."""
8103         try:
8104             self.driver.add_to_aggregate(context, aggregate, host,
8105                                          slave_info=slave_info)
8106         except NotImplementedError:
8107             LOG.debug('Hypervisor driver does not support '
8108                       'add_aggregate_host')
8109         except exception.AggregateError:
8110             with excutils.save_and_reraise_exception():
8111                 self.driver.undo_aggregate_operation(
8112                                     context,
8113                                     aggregate.delete_host,
8114                                     aggregate, host)
8115 
8116     @wrap_exception()
8117     def remove_aggregate_host(self, context, host, slave_info, aggregate):
8118         """Removes a host from a physical hypervisor pool."""
8119         try:
8120             self.driver.remove_from_aggregate(context, aggregate, host,
8121                                               slave_info=slave_info)
8122         except NotImplementedError:
8123             LOG.debug('Hypervisor driver does not support '
8124                       'remove_aggregate_host')
8125         except (exception.AggregateError,
8126                 exception.InvalidAggregateAction) as e:
8127             with excutils.save_and_reraise_exception():
8128                 self.driver.undo_aggregate_operation(
8129                                     context,
8130                                     aggregate.add_host,
8131                                     aggregate, host,
8132                                     isinstance(e, exception.AggregateError))
8133 
8134     def _process_instance_event(self, instance, event):
8135         _event = self.instance_events.pop_instance_event(instance, event)
8136         if _event:
8137             LOG.debug('Processing event %(event)s',
8138                       {'event': event.key}, instance=instance)
8139             _event.send(event)
8140         else:
8141             # If it's a network-vif-unplugged event and the instance is being
8142             # deleted then we don't need to make this a warning as it's
8143             # expected. There are other things which could trigger this like
8144             # detaching an interface, but we don't have a task state for that.
8145             if (event.name == 'network-vif-unplugged' and
8146                     instance.task_state == task_states.DELETING):
8147                 LOG.debug('Received event %s for instance which is being '
8148                           'deleted.', event.key, instance=instance)
8149             else:
8150                 LOG.warning('Received unexpected event %(event)s for '
8151                             'instance with vm_state %(vm_state)s and '
8152                             'task_state %(task_state)s.',
8153                             {'event': event.key,
8154                              'vm_state': instance.vm_state,
8155                              'task_state': instance.task_state},
8156                             instance=instance)
8157 
8158     def _process_instance_vif_deleted_event(self, context, instance,
8159                                             deleted_vif_id):
8160         # If an attached port is deleted by neutron, it needs to
8161         # be detached from the instance.
8162         # And info cache needs to be updated.
8163         network_info = instance.info_cache.network_info
8164         for index, vif in enumerate(network_info):
8165             if vif['id'] == deleted_vif_id:
8166                 LOG.info('Neutron deleted interface %(intf)s; '
8167                          'detaching it from the instance and '
8168                          'deleting it from the info cache',
8169                          {'intf': vif['id']},
8170                          instance=instance)
8171                 del network_info[index]
8172                 base_net_api.update_instance_cache_with_nw_info(
8173                                  self.network_api, context,
8174                                  instance,
8175                                  nw_info=network_info)
8176                 try:
8177                     self.driver.detach_interface(context, instance, vif)
8178                 except NotImplementedError:
8179                     # Not all virt drivers support attach/detach of interfaces
8180                     # yet (like Ironic), so just ignore this.
8181                     pass
8182                 except exception.NovaException as ex:
8183                     # If the instance was deleted before the interface was
8184                     # detached, just log it at debug.
8185                     log_level = (logging.DEBUG
8186                                  if isinstance(ex, exception.InstanceNotFound)
8187                                  else logging.WARNING)
8188                     LOG.log(log_level,
8189                             "Detach interface failed, "
8190                             "port_id=%(port_id)s, reason: %(msg)s",
8191                             {'port_id': deleted_vif_id, 'msg': ex},
8192                             instance=instance)
8193                 break
8194 
8195     @wrap_instance_event(prefix='compute')
8196     @wrap_instance_fault
8197     def extend_volume(self, context, instance, extended_volume_id):
8198 
8199         # If an attached volume is extended by cinder, it needs to
8200         # be extended by virt driver so host can detect its new size.
8201         # And bdm needs to be updated.
8202         LOG.debug('Handling volume-extended event for volume %(vol)s',
8203                   {'vol': extended_volume_id}, instance=instance)
8204 
8205         try:
8206             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
8207                    context, extended_volume_id, instance.uuid)
8208         except exception.NotFound:
8209             LOG.warning('Extend volume failed, '
8210                         'volume %(vol)s is not attached to instance.',
8211                         {'vol': extended_volume_id},
8212                         instance=instance)
8213             return
8214 
8215         LOG.info('Cinder extended volume %(vol)s; '
8216                  'extending it to detect new size',
8217                  {'vol': extended_volume_id},
8218                  instance=instance)
8219         volume = self.volume_api.get(context, bdm.volume_id)
8220 
8221         if bdm.connection_info is None:
8222             LOG.warning('Extend volume failed, '
8223                         'attached volume %(vol)s has no connection_info',
8224                         {'vol': extended_volume_id},
8225                         instance=instance)
8226             return
8227 
8228         connection_info = jsonutils.loads(bdm.connection_info)
8229         bdm.volume_size = volume['size']
8230         bdm.save()
8231 
8232         if not self.driver.capabilities.get('supports_extend_volume', False):
8233             raise exception.ExtendVolumeNotSupported()
8234 
8235         try:
8236             self.driver.extend_volume(connection_info,
8237                                       instance)
8238         except Exception as ex:
8239             LOG.warning('Extend volume failed, '
8240                         'volume_id=%(volume_id)s, reason: %(msg)s',
8241                         {'volume_id': extended_volume_id, 'msg': ex},
8242                         instance=instance)
8243             raise
8244 
8245     @wrap_exception()
8246     def external_instance_event(self, context, instances, events):
8247         # NOTE(danms): Some event types are handled by the manager, such
8248         # as when we're asked to update the instance's info_cache. If it's
8249         # not one of those, look for some thread(s) waiting for the event and
8250         # unblock them if so.
8251         for event in events:
8252             instance = [inst for inst in instances
8253                         if inst.uuid == event.instance_uuid][0]
8254             LOG.debug('Received event %(event)s',
8255                       {'event': event.key},
8256                       instance=instance)
8257             if event.name == 'network-changed':
8258                 try:
8259                     LOG.debug('Refreshing instance network info cache due to '
8260                               'event %s.', event.key, instance=instance)
8261                     self.network_api.get_instance_nw_info(
8262                         context, instance, refresh_vif_id=event.tag)
8263                 except exception.NotFound as e:
8264                     LOG.info('Failed to process external instance event '
8265                              '%(event)s due to: %(error)s',
8266                              {'event': event.key, 'error': six.text_type(e)},
8267                              instance=instance)
8268             elif event.name == 'network-vif-deleted':
8269                 try:
8270                     self._process_instance_vif_deleted_event(context,
8271                                                              instance,
8272                                                              event.tag)
8273                 except exception.NotFound as e:
8274                     LOG.info('Failed to process external instance event '
8275                              '%(event)s due to: %(error)s',
8276                              {'event': event.key, 'error': six.text_type(e)},
8277                              instance=instance)
8278             elif event.name == 'volume-extended':
8279                 self.extend_volume(context, instance, event.tag)
8280             else:
8281                 self._process_instance_event(instance, event)
8282 
8283     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
8284                                  external_process_ok=True)
8285     def _run_image_cache_manager_pass(self, context):
8286         """Run a single pass of the image cache manager."""
8287 
8288         if not self.driver.capabilities.get("has_imagecache", False):
8289             return
8290 
8291         # Determine what other nodes use this storage
8292         storage_users.register_storage_use(CONF.instances_path, CONF.host)
8293         nodes = storage_users.get_storage_users(CONF.instances_path)
8294 
8295         # Filter all_instances to only include those nodes which share this
8296         # storage path.
8297         # TODO(mikal): this should be further refactored so that the cache
8298         # cleanup code doesn't know what those instances are, just a remote
8299         # count, and then this logic should be pushed up the stack.
8300         filters = {'deleted': False,
8301                    'soft_deleted': True,
8302                    'host': nodes}
8303         filtered_instances = objects.InstanceList.get_by_filters(context,
8304                                  filters, expected_attrs=[], use_slave=True)
8305 
8306         self.driver.manage_image_cache(context, filtered_instances)
8307 
8308     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8309     def _run_pending_deletes(self, context):
8310         """Retry any pending instance file deletes."""
8311         LOG.debug('Cleaning up deleted instances')
8312         filters = {'deleted': True,
8313                    'soft_deleted': False,
8314                    'host': CONF.host,
8315                    'cleaned': False}
8316         attrs = ['system_metadata']
8317         with utils.temporary_mutation(context, read_deleted='yes'):
8318             instances = objects.InstanceList.get_by_filters(
8319                 context, filters, expected_attrs=attrs, use_slave=True)
8320         LOG.debug('There are %d instances to clean', len(instances))
8321 
8322         for instance in instances:
8323             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
8324             LOG.debug('Instance has had %(attempts)s of %(max)s '
8325                       'cleanup attempts',
8326                       {'attempts': attempts,
8327                        'max': CONF.maximum_instance_delete_attempts},
8328                       instance=instance)
8329             if attempts < CONF.maximum_instance_delete_attempts:
8330                 success = self.driver.delete_instance_files(instance)
8331 
8332                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
8333                 if success:
8334                     instance.cleaned = True
8335                 with utils.temporary_mutation(context, read_deleted='yes'):
8336                     instance.save()
8337 
8338     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8339     def _cleanup_incomplete_migrations(self, context):
8340         """Delete instance files on failed resize/revert-resize operation
8341 
8342         During resize/revert-resize operation, if that instance gets deleted
8343         in-between then instance files might remain either on source or
8344         destination compute node because of race condition.
8345         """
8346         LOG.debug('Cleaning up deleted instances with incomplete migration ')
8347         migration_filters = {'host': CONF.host,
8348                              'status': 'error'}
8349         migrations = objects.MigrationList.get_by_filters(context,
8350                                                           migration_filters)
8351 
8352         if not migrations:
8353             return
8354 
8355         inst_uuid_from_migrations = set([migration.instance_uuid for migration
8356                                          in migrations])
8357 
8358         inst_filters = {'deleted': True, 'soft_deleted': False,
8359                         'uuid': inst_uuid_from_migrations}
8360         attrs = ['info_cache', 'security_groups', 'system_metadata']
8361         with utils.temporary_mutation(context, read_deleted='yes'):
8362             instances = objects.InstanceList.get_by_filters(
8363                 context, inst_filters, expected_attrs=attrs, use_slave=True)
8364 
8365         for instance in instances:
8366             if instance.host != CONF.host:
8367                 for migration in migrations:
8368                     if instance.uuid == migration.instance_uuid:
8369                         # Delete instance files if not cleanup properly either
8370                         # from the source or destination compute nodes when
8371                         # the instance is deleted during resizing.
8372                         self.driver.delete_instance_files(instance)
8373                         try:
8374                             migration.status = 'failed'
8375                             with migration.obj_as_admin():
8376                                 migration.save()
8377                         except exception.MigrationNotFound:
8378                             LOG.warning("Migration %s is not found.",
8379                                         migration.id,
8380                                         instance=instance)
8381                         break
8382 
8383     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8384                                    exception.QemuGuestAgentNotEnabled,
8385                                    exception.NovaException,
8386                                    NotImplementedError)
8387     @wrap_exception()
8388     def quiesce_instance(self, context, instance):
8389         """Quiesce an instance on this host."""
8390         context = context.elevated()
8391         image_meta = objects.ImageMeta.from_instance(instance)
8392         self.driver.quiesce(context, instance, image_meta)
8393 
8394     def _wait_for_snapshots_completion(self, context, mapping):
8395         for mapping_dict in mapping:
8396             if mapping_dict.get('source_type') == 'snapshot':
8397 
8398                 def _wait_snapshot():
8399                     snapshot = self.volume_api.get_snapshot(
8400                         context, mapping_dict['snapshot_id'])
8401                     if snapshot.get('status') != 'creating':
8402                         raise loopingcall.LoopingCallDone()
8403 
8404                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
8405                 timer.start(interval=0.5).wait()
8406 
8407     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8408                                    exception.QemuGuestAgentNotEnabled,
8409                                    exception.NovaException,
8410                                    NotImplementedError)
8411     @wrap_exception()
8412     def unquiesce_instance(self, context, instance, mapping=None):
8413         """Unquiesce an instance on this host.
8414 
8415         If snapshots' image mapping is provided, it waits until snapshots are
8416         completed before unqueiscing.
8417         """
8418         context = context.elevated()
8419         if mapping:
8420             try:
8421                 self._wait_for_snapshots_completion(context, mapping)
8422             except Exception as error:
8423                 LOG.exception("Exception while waiting completion of "
8424                               "volume snapshots: %s",
8425                               error, instance=instance)
8426         image_meta = objects.ImageMeta.from_instance(instance)
8427         self.driver.unquiesce(context, instance, image_meta)
8428 
8429     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8430     def _cleanup_expired_console_auth_tokens(self, context):
8431         """Remove expired console auth tokens for this host.
8432 
8433         Console authorization tokens and their connection data are stored
8434         in the database when a user asks for a console connection to an
8435         instance. After a time they expire. We periodically remove any expired
8436         tokens from the database.
8437         """
8438         # If the database backend isn't in use, don't bother looking for
8439         # expired tokens. The database backend is not supported for cells v1.
8440         if not CONF.cells.enable:
8441             objects.ConsoleAuthToken.\
8442                 clean_expired_console_auths_for_host(context, self.host)
