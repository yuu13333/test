Please review the code below for security defects. You can consider defect types in terms of:
1.CWE-284 (Improper Access Control)
2.CWE-435 (Improper Interaction Between Multiple Entities)
3.CWE-664 (Improper Control of a Resource Through its Lifetime)
4.CWE-682 (Incorrect Calculation)
5.CWE-691 (Insufficient Control Flow Management)
6.CWE-693 (Protection Mechanism Failure)
7.CWE-697 (Incorrect Comparison)
8.CWE-703 (Improper Check or Handling of Exceptional Conditions)
9.CWE-707 (Improper Neutralization)
10.CWE-710 (Improper Adherence to Coding Standards)
If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are detected, states: 'No security defects are detected in the code'.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 from cursive import exception as cursive_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 from keystoneauth1 import exceptions as keystone_exception
44 from oslo_log import log as logging
45 import oslo_messaging as messaging
46 from oslo_serialization import jsonutils
47 from oslo_service import loopingcall
48 from oslo_service import periodic_task
49 from oslo_utils import excutils
50 from oslo_utils import strutils
51 from oslo_utils import timeutils
52 from oslo_utils import uuidutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova.console import rpcapi as console_rpcapi
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova import image
77 from nova import manager
78 from nova import network
79 from nova.network import base_api as base_net_api
80 from nova.network import model as network_model
81 from nova.network.security_group import openstack_driver
82 from nova import objects
83 from nova.objects import base as obj_base
84 from nova.objects import fields
85 from nova.objects import instance as obj_instance
86 from nova.objects import migrate_data as migrate_data_obj
87 from nova.pci import whitelist
88 from nova import rpc
89 from nova import safe_utils
90 from nova.scheduler import client as scheduler_client
91 from nova.scheduler import utils as scheduler_utils
92 from nova import utils
93 from nova.virt import block_device as driver_block_device
94 from nova.virt import configdrive
95 from nova.virt import driver
96 from nova.virt import event as virtevent
97 from nova.virt import storage_users
98 from nova.virt import virtapi
99 from nova.volume import cinder
100 
101 CONF = nova.conf.CONF
102 
103 LOG = logging.getLogger(__name__)
104 
105 get_notifier = functools.partial(rpc.get_notifier, service='compute')
106 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
107                                    get_notifier=get_notifier,
108                                    binary='nova-compute')
109 
110 
111 @contextlib.contextmanager
112 def errors_out_migration_ctxt(migration):
113     """Context manager to error out migration on failure."""
114 
115     try:
116         yield
117     except Exception:
118         with excutils.save_and_reraise_exception():
119             if migration:
120                 # We may have been passed None for our migration if we're
121                 # receiving from an older client. The migration will be
122                 # errored via the legacy path.
123                 migration.status = 'error'
124                 try:
125                     with migration.obj_as_admin():
126                         migration.save()
127                 except Exception:
128                     LOG.debug(
129                         'Error setting migration status for instance %s.',
130                         migration.instance_uuid, exc_info=True)
131 
132 
133 @utils.expects_func_args('migration')
134 def errors_out_migration(function):
135     """Decorator to error out migration on failure."""
136 
137     @functools.wraps(function)
138     def decorated_function(self, context, *args, **kwargs):
139         wrapped_func = safe_utils.get_wrapped_function(function)
140         keyed_args = inspect.getcallargs(wrapped_func, self, context,
141                                          *args, **kwargs)
142         migration = keyed_args['migration']
143         with errors_out_migration_ctxt(migration):
144             return function(self, context, *args, **kwargs)
145 
146     return decorated_function
147 
148 
149 @utils.expects_func_args('instance')
150 def reverts_task_state(function):
151     """Decorator to revert task_state on failure."""
152 
153     @functools.wraps(function)
154     def decorated_function(self, context, *args, **kwargs):
155         try:
156             return function(self, context, *args, **kwargs)
157         except exception.UnexpectedTaskStateError as e:
158             # Note(maoy): unexpected task state means the current
159             # task is preempted. Do not clear task state in this
160             # case.
161             with excutils.save_and_reraise_exception():
162                 LOG.info("Task possibly preempted: %s",
163                          e.format_message())
164         except Exception:
165             with excutils.save_and_reraise_exception():
166                 wrapped_func = safe_utils.get_wrapped_function(function)
167                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
168                                                  *args, **kwargs)
169                 # NOTE(mriedem): 'instance' must be in keyed_args because we
170                 # have utils.expects_func_args('instance') decorating this
171                 # method.
172                 instance = keyed_args['instance']
173                 original_task_state = instance.task_state
174                 try:
175                     self._instance_update(context, instance, task_state=None)
176                     LOG.info("Successfully reverted task state from %s on "
177                              "failure for instance.",
178                              original_task_state, instance=instance)
179                 except exception.InstanceNotFound:
180                     # We might delete an instance that failed to build shortly
181                     # after it errored out this is an expected case and we
182                     # should not trace on it.
183                     pass
184                 except Exception as e:
185                     LOG.warning("Failed to revert task state for instance. "
186                                 "Error: %s", e, instance=instance)
187 
188     return decorated_function
189 
190 
191 @utils.expects_func_args('instance')
192 def wrap_instance_fault(function):
193     """Wraps a method to catch exceptions related to instances.
194 
195     This decorator wraps a method to catch any exceptions having to do with
196     an instance that may get thrown. It then logs an instance fault in the db.
197     """
198 
199     @functools.wraps(function)
200     def decorated_function(self, context, *args, **kwargs):
201         try:
202             return function(self, context, *args, **kwargs)
203         except exception.InstanceNotFound:
204             raise
205         except Exception as e:
206             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
207             # we will get a KeyError exception which will cover up the real
208             # exception. So, we update kwargs with the values from args first.
209             # then, we can get 'instance' from kwargs easily.
210             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
211 
212             with excutils.save_and_reraise_exception():
213                 compute_utils.add_instance_fault_from_exc(context,
214                         kwargs['instance'], e, sys.exc_info())
215 
216     return decorated_function
217 
218 
219 @utils.expects_func_args('image_id', 'instance')
220 def delete_image_on_error(function):
221     """Used for snapshot related method to ensure the image created in
222     compute.api is deleted when an error occurs.
223     """
224 
225     @functools.wraps(function)
226     def decorated_function(self, context, image_id, instance,
227                            *args, **kwargs):
228         try:
229             return function(self, context, image_id, instance,
230                             *args, **kwargs)
231         except Exception:
232             with excutils.save_and_reraise_exception():
233                 LOG.debug("Cleaning up image %s", image_id,
234                           exc_info=True, instance=instance)
235                 try:
236                     self.image_api.delete(context, image_id)
237                 except exception.ImageNotFound:
238                     # Since we're trying to cleanup an image, we don't care if
239                     # if it's already gone.
240                     pass
241                 except Exception:
242                     LOG.exception("Error while trying to clean up image %s",
243                                   image_id, instance=instance)
244 
245     return decorated_function
246 
247 
248 # TODO(danms): Remove me after Icehouse
249 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
250 # NOTE(mikal): if the method being decorated has more than one decorator, then
251 # put this one first. Otherwise the various exception handling decorators do
252 # not function correctly.
253 def object_compat(function):
254     """Wraps a method that expects a new-world instance
255 
256     This provides compatibility for callers passing old-style dict
257     instances.
258     """
259 
260     @functools.wraps(function)
261     def decorated_function(self, context, *args, **kwargs):
262         def _load_instance(instance_or_dict):
263             if isinstance(instance_or_dict, dict):
264                 # try to get metadata and system_metadata for most cases but
265                 # only attempt to load those if the db instance already has
266                 # those fields joined
267                 metas = [meta for meta in ('metadata', 'system_metadata')
268                          if meta in instance_or_dict]
269                 instance = objects.Instance._from_db_object(
270                     context, objects.Instance(), instance_or_dict,
271                     expected_attrs=metas)
272                 instance._context = context
273                 return instance
274             return instance_or_dict
275 
276         try:
277             kwargs['instance'] = _load_instance(kwargs['instance'])
278         except KeyError:
279             args = (_load_instance(args[0]),) + args[1:]
280 
281         migration = kwargs.get('migration')
282         if isinstance(migration, dict):
283             migration = objects.Migration._from_db_object(
284                     context.elevated(), objects.Migration(),
285                     migration)
286             kwargs['migration'] = migration
287 
288         return function(self, context, *args, **kwargs)
289 
290     return decorated_function
291 
292 
293 class InstanceEvents(object):
294     def __init__(self):
295         self._events = {}
296 
297     @staticmethod
298     def _lock_name(instance):
299         return '%s-%s' % (instance.uuid, 'events')
300 
301     def prepare_for_instance_event(self, instance, event_name):
302         """Prepare to receive an event for an instance.
303 
304         This will register an event for the given instance that we will
305         wait on later. This should be called before initiating whatever
306         action will trigger the event. The resulting eventlet.event.Event
307         object should be wait()'d on to ensure completion.
308 
309         :param instance: the instance for which the event will be generated
310         :param event_name: the name of the event we're expecting
311         :returns: an event object that should be wait()'d on
312         """
313         if self._events is None:
314             # NOTE(danms): We really should have a more specific error
315             # here, but this is what we use for our default error case
316             raise exception.NovaException('In shutdown, no new events '
317                                           'can be scheduled')
318 
319         @utils.synchronized(self._lock_name(instance))
320         def _create_or_get_event():
321             instance_events = self._events.setdefault(instance.uuid, {})
322             return instance_events.setdefault(event_name,
323                                               eventlet.event.Event())
324         LOG.debug('Preparing to wait for external event %(event)s',
325                   {'event': event_name}, instance=instance)
326         return _create_or_get_event()
327 
328     def pop_instance_event(self, instance, event):
329         """Remove a pending event from the wait list.
330 
331         This will remove a pending event from the wait list so that it
332         can be used to signal the waiters to wake up.
333 
334         :param instance: the instance for which the event was generated
335         :param event: the nova.objects.external_event.InstanceExternalEvent
336                       that describes the event
337         :returns: the eventlet.event.Event object on which the waiters
338                   are blocked
339         """
340         no_events_sentinel = object()
341         no_matching_event_sentinel = object()
342 
343         @utils.synchronized(self._lock_name(instance))
344         def _pop_event():
345             if not self._events:
346                 LOG.debug('Unexpected attempt to pop events during shutdown',
347                           instance=instance)
348                 return no_events_sentinel
349             events = self._events.get(instance.uuid)
350             if not events:
351                 return no_events_sentinel
352             _event = events.pop(event.key, None)
353             if not events:
354                 del self._events[instance.uuid]
355             if _event is None:
356                 return no_matching_event_sentinel
357             return _event
358 
359         result = _pop_event()
360         if result is no_events_sentinel:
361             LOG.debug('No waiting events found dispatching %(event)s',
362                       {'event': event.key},
363                       instance=instance)
364             return None
365         elif result is no_matching_event_sentinel:
366             LOG.debug('No event matching %(event)s in %(events)s',
367                       {'event': event.key,
368                        'events': self._events.get(instance.uuid, {}).keys()},
369                       instance=instance)
370             return None
371         else:
372             return result
373 
374     def clear_events_for_instance(self, instance):
375         """Remove all pending events for an instance.
376 
377         This will remove all events currently pending for an instance
378         and return them (indexed by event name).
379 
380         :param instance: the instance for which events should be purged
381         :returns: a dictionary of {event_name: eventlet.event.Event}
382         """
383         @utils.synchronized(self._lock_name(instance))
384         def _clear_events():
385             if self._events is None:
386                 LOG.debug('Unexpected attempt to clear events during shutdown',
387                           instance=instance)
388                 return dict()
389             return self._events.pop(instance.uuid, {})
390         return _clear_events()
391 
392     def cancel_all_events(self):
393         if self._events is None:
394             LOG.debug('Unexpected attempt to cancel events during shutdown.')
395             return
396         our_events = self._events
397         # NOTE(danms): Block new events
398         self._events = None
399 
400         for instance_uuid, events in our_events.items():
401             for event_name, eventlet_event in events.items():
402                 LOG.debug('Canceling in-flight event %(event)s for '
403                           'instance %(instance_uuid)s',
404                           {'event': event_name,
405                            'instance_uuid': instance_uuid})
406                 name, tag = event_name.rsplit('-', 1)
407                 event = objects.InstanceExternalEvent(
408                     instance_uuid=instance_uuid,
409                     name=name, status='failed',
410                     tag=tag, data={})
411                 eventlet_event.send(event)
412 
413 
414 class ComputeVirtAPI(virtapi.VirtAPI):
415     def __init__(self, compute):
416         super(ComputeVirtAPI, self).__init__()
417         self._compute = compute
418 
419     def _default_error_callback(self, event_name, instance):
420         raise exception.NovaException(_('Instance event failed'))
421 
422     @contextlib.contextmanager
423     def wait_for_instance_event(self, instance, event_names, deadline=300,
424                                 error_callback=None):
425         """Plan to wait for some events, run some code, then wait.
426 
427         This context manager will first create plans to wait for the
428         provided event_names, yield, and then wait for all the scheduled
429         events to complete.
430 
431         Note that this uses an eventlet.timeout.Timeout to bound the
432         operation, so callers should be prepared to catch that
433         failure and handle that situation appropriately.
434 
435         If the event is not received by the specified timeout deadline,
436         eventlet.timeout.Timeout is raised.
437 
438         If the event is received but did not have a 'completed'
439         status, a NovaException is raised.  If an error_callback is
440         provided, instead of raising an exception as detailed above
441         for the failure case, the callback will be called with the
442         event_name and instance, and can return True to continue
443         waiting for the rest of the events, False to stop processing,
444         or raise an exception which will bubble up to the waiter.
445 
446         :param instance: The instance for which an event is expected
447         :param event_names: A list of event names. Each element can be a
448                             string event name or tuple of strings to
449                             indicate (name, tag).
450         :param deadline: Maximum number of seconds we should wait for all
451                          of the specified events to arrive.
452         :param error_callback: A function to be called if an event arrives
453 
454         """
455 
456         if error_callback is None:
457             error_callback = self._default_error_callback
458         events = {}
459         for event_name in event_names:
460             if isinstance(event_name, tuple):
461                 name, tag = event_name
462                 event_name = objects.InstanceExternalEvent.make_key(
463                     name, tag)
464             try:
465                 events[event_name] = (
466                     self._compute.instance_events.prepare_for_instance_event(
467                         instance, event_name))
468             except exception.NovaException:
469                 error_callback(event_name, instance)
470                 # NOTE(danms): Don't wait for any of the events. They
471                 # should all be canceled and fired immediately below,
472                 # but don't stick around if not.
473                 deadline = 0
474         yield
475         with eventlet.timeout.Timeout(deadline):
476             for event_name, event in events.items():
477                 actual_event = event.wait()
478                 if actual_event.status == 'completed':
479                     continue
480                 decision = error_callback(event_name, instance)
481                 if decision is False:
482                     break
483 
484 
485 class ComputeManager(manager.Manager):
486     """Manages the running instances from creation to destruction."""
487 
488     target = messaging.Target(version='4.20')
489 
490     # How long to wait in seconds before re-issuing a shutdown
491     # signal to an instance during power off.  The overall
492     # time to wait is set by CONF.shutdown_timeout.
493     SHUTDOWN_RETRY_INTERVAL = 10
494 
495     def __init__(self, compute_driver=None, *args, **kwargs):
496         """Load configuration options and connect to the hypervisor."""
497         self.virtapi = ComputeVirtAPI(self)
498         self.network_api = network.API()
499         self.volume_api = cinder.API()
500         self.image_api = image.API()
501         self._last_host_check = 0
502         self._last_bw_usage_poll = 0
503         self._bw_usage_supported = True
504         self._last_bw_usage_cell_update = 0
505         self.compute_api = compute.API()
506         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
507         self.conductor_api = conductor.API()
508         self.compute_task_api = conductor.ComputeTaskAPI()
509         self.is_neutron_security_groups = (
510             openstack_driver.is_neutron_security_groups())
511         self.cells_rpcapi = cells_rpcapi.CellsAPI()
512         self.scheduler_client = scheduler_client.SchedulerClient()
513         self.reportclient = self.scheduler_client.reportclient
514         self._resource_tracker = None
515         self.instance_events = InstanceEvents()
516         self._sync_power_pool = eventlet.GreenPool(
517             size=CONF.sync_power_state_pool_size)
518         self._syncs_in_progress = {}
519         self.send_instance_updates = (
520             CONF.filter_scheduler.track_instance_changes)
521         if CONF.max_concurrent_builds != 0:
522             self._build_semaphore = eventlet.semaphore.Semaphore(
523                 CONF.max_concurrent_builds)
524         else:
525             self._build_semaphore = compute_utils.UnlimitedSemaphore()
526         if max(CONF.max_concurrent_live_migrations, 0) != 0:
527             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
528                 CONF.max_concurrent_live_migrations)
529         else:
530             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
531         self._failed_builds = 0
532 
533         super(ComputeManager, self).__init__(service_name="compute",
534                                              *args, **kwargs)
535 
536         # NOTE(russellb) Load the driver last.  It may call back into the
537         # compute manager via the virtapi, so we want it to be fully
538         # initialized before that happens.
539         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
540         self.use_legacy_block_device_info = \
541                             self.driver.need_legacy_block_device_info
542 
543     def reset(self):
544         LOG.info('Reloading compute RPC API')
545         compute_rpcapi.LAST_VERSION = None
546         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
547 
548     def _get_resource_tracker(self):
549         if not self._resource_tracker:
550             rt = resource_tracker.ResourceTracker(self.host, self.driver)
551             self._resource_tracker = rt
552         return self._resource_tracker
553 
554     def _update_resource_tracker(self, context, instance):
555         """Let the resource tracker know that an instance has changed state."""
556 
557         if instance.host == self.host:
558             rt = self._get_resource_tracker()
559             rt.update_usage(context, instance, instance.node)
560 
561     def _instance_update(self, context, instance, **kwargs):
562         """Update an instance in the database using kwargs as value."""
563 
564         for k, v in kwargs.items():
565             setattr(instance, k, v)
566         instance.save()
567         self._update_resource_tracker(context, instance)
568 
569     def _nil_out_instance_obj_host_and_node(self, instance):
570         # NOTE(jwcroppe): We don't do instance.save() here for performance
571         # reasons; a call to this is expected to be immediately followed by
572         # another call that does instance.save(), thus avoiding two writes
573         # to the database layer.
574         instance.host = None
575         instance.node = None
576 
577     def _set_instance_obj_error_state(self, context, instance,
578                                       clean_task_state=False):
579         try:
580             instance.vm_state = vm_states.ERROR
581             if clean_task_state:
582                 instance.task_state = None
583             instance.save()
584         except exception.InstanceNotFound:
585             LOG.debug('Instance has been destroyed from under us while '
586                       'trying to set it to ERROR', instance=instance)
587 
588     def _get_instances_on_driver(self, context, filters=None):
589         """Return a list of instance records for the instances found
590         on the hypervisor which satisfy the specified filters. If filters=None
591         return a list of instance records for all the instances found on the
592         hypervisor.
593         """
594         if not filters:
595             filters = {}
596         try:
597             driver_uuids = self.driver.list_instance_uuids()
598             if len(driver_uuids) == 0:
599                 # Short circuit, don't waste a DB call
600                 return objects.InstanceList()
601             filters['uuid'] = driver_uuids
602             local_instances = objects.InstanceList.get_by_filters(
603                 context, filters, use_slave=True)
604             return local_instances
605         except NotImplementedError:
606             pass
607 
608         # The driver doesn't support uuids listing, so we'll have
609         # to brute force.
610         driver_instances = self.driver.list_instances()
611         # NOTE(mjozefcz): In this case we need to apply host filter.
612         # Without this all instance data would be fetched from db.
613         filters['host'] = self.host
614         instances = objects.InstanceList.get_by_filters(context, filters,
615                                                         use_slave=True)
616         name_map = {instance.name: instance for instance in instances}
617         local_instances = []
618         for driver_instance in driver_instances:
619             instance = name_map.get(driver_instance)
620             if not instance:
621                 continue
622             local_instances.append(instance)
623         return local_instances
624 
625     def _destroy_evacuated_instances(self, context):
626         """Destroys evacuated instances.
627 
628         While nova-compute was down, the instances running on it could be
629         evacuated to another host. This method looks for evacuation migration
630         records where this is the source host and which were either started
631         (accepted) or complete (done). From those migration records, local
632         instances reported by the hypervisor are compared to the instances
633         for the migration records and those local guests are destroyed, along
634         with instance allocation records in Placement for this node.
635         """
636         filters = {
637             'source_compute': self.host,
638             # NOTE(mriedem): Migration records that have been accepted are
639             # included in case the source node comes back up while instances
640             # are being evacuated to another host. We don't want the same
641             # instance being reported from multiple hosts.
642             'status': ['accepted', 'done'],
643             'migration_type': 'evacuation',
644         }
645         with utils.temporary_mutation(context, read_deleted='yes'):
646             evacuations = objects.MigrationList.get_by_filters(context,
647                                                                filters)
648         if not evacuations:
649             return
650         evacuations = {mig.instance_uuid: mig for mig in evacuations}
651 
652         local_instances = self._get_instances_on_driver(context)
653         evacuated = [inst for inst in local_instances
654                      if inst.uuid in evacuations]
655 
656         # NOTE(gibi): We are called from init_host and at this point the
657         # compute_nodes of the resource tracker has not been populated yet so
658         # we cannot rely on the resource tracker here.
659         compute_nodes = {}
660 
661         for instance in evacuated:
662             migration = evacuations[instance.uuid]
663             LOG.info('Deleting instance as it has been evacuated from '
664                      'this host', instance=instance)
665             try:
666                 network_info = self.network_api.get_instance_nw_info(
667                     context, instance)
668                 bdi = self._get_instance_block_device_info(context,
669                                                            instance)
670                 destroy_disks = not (self._is_instance_storage_shared(
671                     context, instance))
672             except exception.InstanceNotFound:
673                 network_info = network_model.NetworkInfo()
674                 bdi = {}
675                 LOG.info('Instance has been marked deleted already, '
676                          'removing it from the hypervisor.',
677                          instance=instance)
678                 # always destroy disks if the instance was deleted
679                 destroy_disks = True
680             self.driver.destroy(context, instance,
681                                 network_info,
682                                 bdi, destroy_disks)
683 
684             # delete the allocation of the evacuated instance from this host
685             if migration.source_node not in compute_nodes:
686                 try:
687                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
688                         context, self.host, migration.source_node).uuid
689                     compute_nodes[migration.source_node] = cn_uuid
690                 except exception.ComputeHostNotFound:
691                     LOG.error("Failed to clean allocation of evacuated "
692                               "instance as the source node %s is not found",
693                               migration.source_node, instance=instance)
694                     continue
695             cn_uuid = compute_nodes[migration.source_node]
696 
697             my_resources = scheduler_utils.resources_from_flavor(
698                 instance, instance.flavor)
699             res = self.reportclient.remove_provider_from_instance_allocation(
700                 instance.uuid, cn_uuid, instance.user_id,
701                 instance.project_id, my_resources)
702             if not res:
703                 LOG.error("Failed to clean allocation of evacuated instance "
704                           "on the source node %s",
705                           cn_uuid, instance=instance)
706 
707             migration.status = 'completed'
708             migration.save()
709 
710     def _is_instance_storage_shared(self, context, instance, host=None):
711         shared_storage = True
712         data = None
713         try:
714             data = self.driver.check_instance_shared_storage_local(context,
715                                                        instance)
716             if data:
717                 shared_storage = (self.compute_rpcapi.
718                                   check_instance_shared_storage(context,
719                                   instance, data, host=host))
720         except NotImplementedError:
721             LOG.debug('Hypervisor driver does not support '
722                       'instance shared storage check, '
723                       'assuming it\'s not on shared storage',
724                       instance=instance)
725             shared_storage = False
726         except Exception:
727             LOG.exception('Failed to check if instance shared',
728                           instance=instance)
729         finally:
730             if data:
731                 self.driver.check_instance_shared_storage_cleanup(context,
732                                                                   data)
733         return shared_storage
734 
735     def _complete_partial_deletion(self, context, instance):
736         """Complete deletion for instances in DELETED status but not marked as
737         deleted in the DB
738         """
739         system_meta = instance.system_metadata
740         instance.destroy()
741         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
742                 context, instance.uuid)
743         self._complete_deletion(context,
744                                 instance,
745                                 bdms,
746                                 system_meta)
747 
748     def _complete_deletion(self, context, instance, bdms,
749                            system_meta):
750         self._update_resource_tracker(context, instance)
751 
752         rt = self._get_resource_tracker()
753         rt.reportclient.delete_allocation_for_instance(context, instance.uuid)
754 
755         self._notify_about_instance_usage(context, instance, "delete.end",
756                 system_metadata=system_meta)
757         compute_utils.notify_about_instance_action(context, instance,
758                 self.host, action=fields.NotificationAction.DELETE,
759                 phase=fields.NotificationPhase.END, bdms=bdms)
760         self._delete_scheduler_instance_info(context, instance.uuid)
761 
762     def _init_instance(self, context, instance):
763         """Initialize this instance during service init."""
764 
765         # NOTE(danms): If the instance appears to not be owned by this
766         # host, it may have been evacuated away, but skipped by the
767         # evacuation cleanup code due to configuration. Thus, if that
768         # is a possibility, don't touch the instance in any way, but
769         # log the concern. This will help avoid potential issues on
770         # startup due to misconfiguration.
771         if instance.host != self.host:
772             LOG.warning('Instance %(uuid)s appears to not be owned '
773                         'by this host, but by %(host)s. Startup '
774                         'processing is being skipped.',
775                         {'uuid': instance.uuid,
776                          'host': instance.host})
777             return
778 
779         # Instances that are shut down, or in an error state can not be
780         # initialized and are not attempted to be recovered. The exception
781         # to this are instances that are in RESIZE_MIGRATING or DELETING,
782         # which are dealt with further down.
783         if (instance.vm_state == vm_states.SOFT_DELETED or
784             (instance.vm_state == vm_states.ERROR and
785             instance.task_state not in
786             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
787             LOG.debug("Instance is in %s state.",
788                       instance.vm_state, instance=instance)
789             return
790 
791         if instance.vm_state == vm_states.DELETED:
792             try:
793                 self._complete_partial_deletion(context, instance)
794             except Exception:
795                 # we don't want that an exception blocks the init_host
796                 LOG.exception('Failed to complete a deletion',
797                               instance=instance)
798             return
799 
800         if (instance.vm_state == vm_states.BUILDING or
801             instance.task_state in [task_states.SCHEDULING,
802                                     task_states.BLOCK_DEVICE_MAPPING,
803                                     task_states.NETWORKING,
804                                     task_states.SPAWNING]):
805             # NOTE(dave-mcnally) compute stopped before instance was fully
806             # spawned so set to ERROR state. This is safe to do as the state
807             # may be set by the api but the host is not so if we get here the
808             # instance has already been scheduled to this particular host.
809             LOG.debug("Instance failed to spawn correctly, "
810                       "setting to ERROR state", instance=instance)
811             instance.task_state = None
812             instance.vm_state = vm_states.ERROR
813             instance.save()
814             return
815 
816         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
817             instance.task_state in [task_states.REBUILDING,
818                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
819                                     task_states.REBUILD_SPAWNING]):
820             # NOTE(jichenjc) compute stopped before instance was fully
821             # spawned so set to ERROR state. This is consistent to BUILD
822             LOG.debug("Instance failed to rebuild correctly, "
823                       "setting to ERROR state", instance=instance)
824             instance.task_state = None
825             instance.vm_state = vm_states.ERROR
826             instance.save()
827             return
828 
829         if (instance.vm_state != vm_states.ERROR and
830             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
831                                     task_states.IMAGE_PENDING_UPLOAD,
832                                     task_states.IMAGE_UPLOADING,
833                                     task_states.IMAGE_SNAPSHOT]):
834             LOG.debug("Instance in transitional state %s at start-up "
835                       "clearing task state",
836                       instance.task_state, instance=instance)
837             try:
838                 self._post_interrupted_snapshot_cleanup(context, instance)
839             except Exception:
840                 # we don't want that an exception blocks the init_host
841                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
842             instance.task_state = None
843             instance.save()
844 
845         if (instance.vm_state != vm_states.ERROR and
846             instance.task_state in [task_states.RESIZE_PREP]):
847             LOG.debug("Instance in transitional state %s at start-up "
848                       "clearing task state",
849                       instance['task_state'], instance=instance)
850             instance.task_state = None
851             instance.save()
852 
853         if instance.task_state == task_states.DELETING:
854             try:
855                 LOG.info('Service started deleting the instance during '
856                          'the previous run, but did not finish. Restarting'
857                          ' the deletion now.', instance=instance)
858                 instance.obj_load_attr('metadata')
859                 instance.obj_load_attr('system_metadata')
860                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
861                         context, instance.uuid)
862                 self._delete_instance(context, instance, bdms)
863             except Exception:
864                 # we don't want that an exception blocks the init_host
865                 LOG.exception('Failed to complete a deletion',
866                               instance=instance)
867                 self._set_instance_obj_error_state(context, instance)
868             return
869 
870         current_power_state = self._get_power_state(context, instance)
871         try_reboot, reboot_type = self._retry_reboot(context, instance,
872                                                      current_power_state)
873 
874         if try_reboot:
875             LOG.debug("Instance in transitional state (%(task_state)s) at "
876                       "start-up and power state is (%(power_state)s), "
877                       "triggering reboot",
878                       {'task_state': instance.task_state,
879                        'power_state': current_power_state},
880                       instance=instance)
881 
882             # NOTE(mikal): if the instance was doing a soft reboot that got as
883             # far as shutting down the instance but not as far as starting it
884             # again, then we've just become a hard reboot. That means the
885             # task state for the instance needs to change so that we're in one
886             # of the expected task states for a hard reboot.
887             if (instance.task_state in task_states.soft_reboot_states and
888                 reboot_type == 'HARD'):
889                 instance.task_state = task_states.REBOOT_PENDING_HARD
890                 instance.save()
891 
892             self.reboot_instance(context, instance, block_device_info=None,
893                                  reboot_type=reboot_type)
894             return
895 
896         elif (current_power_state == power_state.RUNNING and
897               instance.task_state in [task_states.REBOOT_STARTED,
898                                       task_states.REBOOT_STARTED_HARD,
899                                       task_states.PAUSING,
900                                       task_states.UNPAUSING]):
901             LOG.warning("Instance in transitional state "
902                         "(%(task_state)s) at start-up and power state "
903                         "is (%(power_state)s), clearing task state",
904                         {'task_state': instance.task_state,
905                          'power_state': current_power_state},
906                         instance=instance)
907             instance.task_state = None
908             instance.vm_state = vm_states.ACTIVE
909             instance.save()
910         elif (current_power_state == power_state.PAUSED and
911               instance.task_state == task_states.UNPAUSING):
912             LOG.warning("Instance in transitional state "
913                         "(%(task_state)s) at start-up and power state "
914                         "is (%(power_state)s), clearing task state "
915                         "and unpausing the instance",
916                         {'task_state': instance.task_state,
917                          'power_state': current_power_state},
918                         instance=instance)
919             try:
920                 self.unpause_instance(context, instance)
921             except NotImplementedError:
922                 # Some virt driver didn't support pause and unpause
923                 pass
924             except Exception:
925                 LOG.exception('Failed to unpause instance', instance=instance)
926             return
927 
928         if instance.task_state == task_states.POWERING_OFF:
929             try:
930                 LOG.debug("Instance in transitional state %s at start-up "
931                           "retrying stop request",
932                           instance.task_state, instance=instance)
933                 self.stop_instance(context, instance, True)
934             except Exception:
935                 # we don't want that an exception blocks the init_host
936                 LOG.exception('Failed to stop instance', instance=instance)
937             return
938 
939         if instance.task_state == task_states.POWERING_ON:
940             try:
941                 LOG.debug("Instance in transitional state %s at start-up "
942                           "retrying start request",
943                           instance.task_state, instance=instance)
944                 self.start_instance(context, instance)
945             except Exception:
946                 # we don't want that an exception blocks the init_host
947                 LOG.exception('Failed to start instance', instance=instance)
948             return
949 
950         net_info = instance.get_network_info()
951         try:
952             self.driver.plug_vifs(instance, net_info)
953         except NotImplementedError as e:
954             LOG.debug(e, instance=instance)
955         except exception.VirtualInterfacePlugException:
956             # we don't want an exception to block the init_host
957             LOG.exception("Vifs plug failed", instance=instance)
958             self._set_instance_obj_error_state(context, instance)
959             return
960 
961         if instance.task_state == task_states.RESIZE_MIGRATING:
962             # We crashed during resize/migration, so roll back for safety
963             try:
964                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
965                 # not in system_metadata we default to True for backwards
966                 # compatibility
967                 power_on = (instance.system_metadata.get('old_vm_state') !=
968                             vm_states.STOPPED)
969 
970                 block_dev_info = self._get_instance_block_device_info(context,
971                                                                       instance)
972 
973                 self.driver.finish_revert_migration(context,
974                     instance, net_info, block_dev_info, power_on)
975 
976             except Exception:
977                 LOG.exception('Failed to revert crashed migration',
978                               instance=instance)
979             finally:
980                 LOG.info('Instance found in migrating state during '
981                          'startup. Resetting task_state',
982                          instance=instance)
983                 instance.task_state = None
984                 instance.save()
985         if instance.task_state == task_states.MIGRATING:
986             # Live migration did not complete, but instance is on this
987             # host, so reset the state.
988             instance.task_state = None
989             instance.save(expected_task_state=[task_states.MIGRATING])
990 
991         db_state = instance.power_state
992         drv_state = self._get_power_state(context, instance)
993         expect_running = (db_state == power_state.RUNNING and
994                           drv_state != db_state)
995 
996         LOG.debug('Current state is %(drv_state)s, state in DB is '
997                   '%(db_state)s.',
998                   {'drv_state': drv_state, 'db_state': db_state},
999                   instance=instance)
1000 
1001         if expect_running and CONF.resume_guests_state_on_host_boot:
1002             self._resume_guests_state(context, instance, net_info)
1003         elif drv_state == power_state.RUNNING:
1004             # VMwareAPI drivers will raise an exception
1005             try:
1006                 self.driver.ensure_filtering_rules_for_instance(
1007                                        instance, net_info)
1008             except NotImplementedError:
1009                 LOG.debug('Hypervisor driver does not support '
1010                           'firewall rules', instance=instance)
1011 
1012     def _resume_guests_state(self, context, instance, net_info):
1013         LOG.info('Rebooting instance after nova-compute restart.',
1014                  instance=instance)
1015         block_device_info = \
1016             self._get_instance_block_device_info(context, instance)
1017 
1018         try:
1019             self.driver.resume_state_on_host_boot(
1020                 context, instance, net_info, block_device_info)
1021         except NotImplementedError:
1022             LOG.warning('Hypervisor driver does not support '
1023                         'resume guests', instance=instance)
1024         except Exception:
1025             # NOTE(vish): The instance failed to resume, so we set the
1026             #             instance to error and attempt to continue.
1027             LOG.warning('Failed to resume instance',
1028                         instance=instance)
1029             self._set_instance_obj_error_state(context, instance)
1030 
1031     def _retry_reboot(self, context, instance, current_power_state):
1032         current_task_state = instance.task_state
1033         retry_reboot = False
1034         reboot_type = compute_utils.get_reboot_type(current_task_state,
1035                                                     current_power_state)
1036 
1037         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1038                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1039         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1040                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1041         started_not_running = (current_task_state in
1042                                [task_states.REBOOT_STARTED,
1043                                 task_states.REBOOT_STARTED_HARD] and
1044                                current_power_state != power_state.RUNNING)
1045 
1046         if pending_soft or pending_hard or started_not_running:
1047             retry_reboot = True
1048 
1049         return retry_reboot, reboot_type
1050 
1051     def handle_lifecycle_event(self, event):
1052         LOG.info("VM %(state)s (Lifecycle Event)",
1053                  {'state': event.get_name()},
1054                  instance_uuid=event.get_instance_uuid())
1055         context = nova.context.get_admin_context(read_deleted='yes')
1056         instance = objects.Instance.get_by_uuid(context,
1057                                                 event.get_instance_uuid(),
1058                                                 expected_attrs=[])
1059         vm_power_state = None
1060         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1061             vm_power_state = power_state.SHUTDOWN
1062         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1063             vm_power_state = power_state.RUNNING
1064         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1065             vm_power_state = power_state.PAUSED
1066         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1067             vm_power_state = power_state.RUNNING
1068         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1069             vm_power_state = power_state.SUSPENDED
1070         else:
1071             LOG.warning("Unexpected power state %d", event.get_transition())
1072 
1073         # Note(lpetrut): The event may be delayed, thus not reflecting
1074         # the current instance power state. In that case, ignore the event.
1075         current_power_state = self._get_power_state(context, instance)
1076         if current_power_state == vm_power_state:
1077             LOG.debug('Synchronizing instance power state after lifecycle '
1078                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1079                       'current task_state: %(task_state)s, current DB '
1080                       'power_state: %(db_power_state)s, VM power_state: '
1081                       '%(vm_power_state)s',
1082                       {'event': event.get_name(),
1083                        'vm_state': instance.vm_state,
1084                        'task_state': instance.task_state,
1085                        'db_power_state': instance.power_state,
1086                        'vm_power_state': vm_power_state},
1087                       instance_uuid=instance.uuid)
1088             self._sync_instance_power_state(context,
1089                                             instance,
1090                                             vm_power_state)
1091 
1092     def handle_events(self, event):
1093         if isinstance(event, virtevent.LifecycleEvent):
1094             try:
1095                 self.handle_lifecycle_event(event)
1096             except exception.InstanceNotFound:
1097                 LOG.debug("Event %s arrived for non-existent instance. The "
1098                           "instance was probably deleted.", event)
1099         else:
1100             LOG.debug("Ignoring event %s", event)
1101 
1102     def init_virt_events(self):
1103         if CONF.workarounds.handle_virt_lifecycle_events:
1104             self.driver.register_event_listener(self.handle_events)
1105         else:
1106             # NOTE(mriedem): If the _sync_power_states periodic task is
1107             # disabled we should emit a warning in the logs.
1108             if CONF.sync_power_state_interval < 0:
1109                 LOG.warning('Instance lifecycle events from the compute '
1110                             'driver have been disabled. Note that lifecycle '
1111                             'changes to an instance outside of the compute '
1112                             'service will not be synchronized '
1113                             'automatically since the _sync_power_states '
1114                             'periodic task is also disabled.')
1115             else:
1116                 LOG.info('Instance lifecycle events from the compute '
1117                          'driver have been disabled. Note that lifecycle '
1118                          'changes to an instance outside of the compute '
1119                          'service will only be synchronized by the '
1120                          '_sync_power_states periodic task.')
1121 
1122     def init_host(self):
1123         """Initialization for a standalone compute service."""
1124 
1125         if CONF.pci.passthrough_whitelist:
1126             # Simply loading the PCI passthrough whitelist will do a bunch of
1127             # validation that would otherwise wait until the PciDevTracker is
1128             # constructed when updating available resources for the compute
1129             # node(s) in the resource tracker, effectively killing that task.
1130             # So load up the whitelist when starting the compute service to
1131             # flush any invalid configuration early so we can kill the service
1132             # if the configuration is wrong.
1133             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1134 
1135         # NOTE(sbauza): We want the compute node to hard fail if it won't be
1136         # able to provide its resources to the placement API, or it will not
1137         # be able to be eligible as a destination.
1138         if CONF.placement.os_region_name is None:
1139             raise exception.PlacementNotConfigured()
1140 
1141         self.driver.init_host(host=self.host)
1142         context = nova.context.get_admin_context()
1143         instances = objects.InstanceList.get_by_host(
1144             context, self.host, expected_attrs=['info_cache', 'metadata'])
1145 
1146         if CONF.defer_iptables_apply:
1147             self.driver.filter_defer_apply_on()
1148 
1149         self.init_virt_events()
1150 
1151         try:
1152             # checking that instance was not already evacuated to other host
1153             self._destroy_evacuated_instances(context)
1154             for instance in instances:
1155                 self._init_instance(context, instance)
1156         finally:
1157             if CONF.defer_iptables_apply:
1158                 self.driver.filter_defer_apply_off()
1159             if instances:
1160                 # We only send the instance info to the scheduler on startup
1161                 # if there is anything to send, otherwise this host might
1162                 # not be mapped yet in a cell and the scheduler may have
1163                 # issues dealing with the information. Later changes to
1164                 # instances on this host will update the scheduler, or the
1165                 # _sync_scheduler_instance_info periodic task will.
1166                 self._update_scheduler_instance_info(context, instances)
1167 
1168     def cleanup_host(self):
1169         self.driver.register_event_listener(None)
1170         self.instance_events.cancel_all_events()
1171         self.driver.cleanup_host(host=self.host)
1172 
1173     def pre_start_hook(self):
1174         """After the service is initialized, but before we fully bring
1175         the service up by listening on RPC queues, make sure to update
1176         our available resources (and indirectly our available nodes).
1177         """
1178         self.update_available_resource(nova.context.get_admin_context(),
1179                                        startup=True)
1180 
1181     def _get_power_state(self, context, instance):
1182         """Retrieve the power state for the given instance."""
1183         LOG.debug('Checking state', instance=instance)
1184         try:
1185             return self.driver.get_info(instance).state
1186         except exception.InstanceNotFound:
1187             return power_state.NOSTATE
1188 
1189     def get_console_topic(self, context):
1190         """Retrieves the console host for a project on this host.
1191 
1192         Currently this is just set in the flags for each compute host.
1193 
1194         """
1195         # TODO(mdragon): perhaps make this variable by console_type?
1196         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1197 
1198     @wrap_exception()
1199     def get_console_pool_info(self, context, console_type):
1200         return self.driver.get_console_pool_info(console_type)
1201 
1202     # NOTE(hanlind): This and the virt method it calls can be removed in
1203     # version 5.0 of the RPC API
1204     @wrap_exception()
1205     def refresh_security_group_rules(self, context, security_group_id):
1206         """Tell the virtualization driver to refresh security group rules.
1207 
1208         Passes straight through to the virtualization driver.
1209 
1210         """
1211         return self.driver.refresh_security_group_rules(security_group_id)
1212 
1213     # TODO(alaski): Remove object_compat for RPC version 5.0
1214     @object_compat
1215     @wrap_exception()
1216     def refresh_instance_security_rules(self, context, instance):
1217         """Tell the virtualization driver to refresh security rules for
1218         an instance.
1219 
1220         Passes straight through to the virtualization driver.
1221 
1222         Synchronize the call because we may still be in the middle of
1223         creating the instance.
1224         """
1225         @utils.synchronized(instance.uuid)
1226         def _sync_refresh():
1227             try:
1228                 return self.driver.refresh_instance_security_rules(instance)
1229             except NotImplementedError:
1230                 LOG.debug('Hypervisor driver does not support '
1231                           'security groups.', instance=instance)
1232 
1233         return _sync_refresh()
1234 
1235     def _await_block_device_map_created(self, context, vol_id):
1236         # TODO(yamahata): creating volume simultaneously
1237         #                 reduces creation time?
1238         # TODO(yamahata): eliminate dumb polling
1239         start = time.time()
1240         retries = CONF.block_device_allocate_retries
1241         if retries < 0:
1242             LOG.warning("Treating negative config value (%(retries)s) for "
1243                         "'block_device_retries' as 0.",
1244                         {'retries': retries})
1245         # (1) treat  negative config value as 0
1246         # (2) the configured value is 0, one attempt should be made
1247         # (3) the configured value is > 0, then the total number attempts
1248         #      is (retries + 1)
1249         attempts = 1
1250         if retries >= 1:
1251             attempts = retries + 1
1252         for attempt in range(1, attempts + 1):
1253             volume = self.volume_api.get(context, vol_id)
1254             volume_status = volume['status']
1255             if volume_status not in ['creating', 'downloading']:
1256                 if volume_status == 'available':
1257                     return attempt
1258                 LOG.warning("Volume id: %(vol_id)s finished being "
1259                             "created but its status is %(vol_status)s.",
1260                             {'vol_id': vol_id,
1261                              'vol_status': volume_status})
1262                 break
1263             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1264         raise exception.VolumeNotCreated(volume_id=vol_id,
1265                                          seconds=int(time.time() - start),
1266                                          attempts=attempt,
1267                                          volume_status=volume_status)
1268 
1269     def _decode_files(self, injected_files):
1270         """Base64 decode the list of files to inject."""
1271         if not injected_files:
1272             return []
1273 
1274         def _decode(f):
1275             path, contents = f
1276             # Py3 raises binascii.Error instead of TypeError as in Py27
1277             try:
1278                 decoded = base64.b64decode(contents)
1279                 return path, decoded
1280             except (TypeError, binascii.Error):
1281                 raise exception.Base64Exception(path=path)
1282 
1283         return [_decode(f) for f in injected_files]
1284 
1285     def _validate_instance_group_policy(self, context, instance,
1286                                         scheduler_hints):
1287         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1288         # However, there is a race condition with the enforcement of
1289         # the policy.  Since more than one instance may be scheduled at the
1290         # same time, it's possible that more than one instance with an
1291         # anti-affinity policy may end up here.  It's also possible that
1292         # multiple instances with an affinity policy could end up on different
1293         # hosts.  This is a validation step to make sure that starting the
1294         # instance here doesn't violate the policy.
1295         group_hint = scheduler_hints.get('group')
1296         if not group_hint:
1297             return
1298 
1299         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1300         # to check the type on the value and pull the single entry out. The
1301         # API request schema validates that the 'group' hint is a single value.
1302         if isinstance(group_hint, list):
1303             group_hint = group_hint[0]
1304 
1305         @utils.synchronized(group_hint)
1306         def _do_validation(context, instance, group_hint):
1307             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1308             if 'anti-affinity' in group.policies:
1309                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1310                 if self.host in group_hosts:
1311                     msg = _("Anti-affinity instance group policy "
1312                             "was violated.")
1313                     raise exception.RescheduledException(
1314                             instance_uuid=instance.uuid,
1315                             reason=msg)
1316             elif 'affinity' in group.policies:
1317                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1318                 if group_hosts and self.host not in group_hosts:
1319                     msg = _("Affinity instance group policy was violated.")
1320                     raise exception.RescheduledException(
1321                             instance_uuid=instance.uuid,
1322                             reason=msg)
1323 
1324         if not CONF.workarounds.disable_group_policy_check_upcall:
1325             _do_validation(context, instance, group_hint)
1326 
1327     def _log_original_error(self, exc_info, instance_uuid):
1328         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1329                   exc_info=exc_info)
1330 
1331     def _reschedule(self, context, request_spec, filter_properties,
1332             instance, reschedule_method, method_args, task_state,
1333             exc_info=None):
1334         """Attempt to re-schedule a compute operation."""
1335 
1336         instance_uuid = instance.uuid
1337         retry = filter_properties.get('retry')
1338         if not retry:
1339             # no retry information, do not reschedule.
1340             LOG.debug("Retry info not present, will not reschedule",
1341                       instance_uuid=instance_uuid)
1342             return
1343 
1344         if not request_spec:
1345             LOG.debug("No request spec, will not reschedule",
1346                       instance_uuid=instance_uuid)
1347             return
1348 
1349         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1350                   {'method': reschedule_method.__name__,
1351                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1352 
1353         # reset the task state:
1354         self._instance_update(context, instance, task_state=task_state)
1355 
1356         if exc_info:
1357             # stringify to avoid circular ref problem in json serialization:
1358             retry['exc'] = traceback.format_exception_only(exc_info[0],
1359                                     exc_info[1])
1360 
1361         reschedule_method(context, *method_args)
1362         return True
1363 
1364     @periodic_task.periodic_task
1365     def _check_instance_build_time(self, context):
1366         """Ensure that instances are not stuck in build."""
1367         timeout = CONF.instance_build_timeout
1368         if timeout == 0:
1369             return
1370 
1371         filters = {'vm_state': vm_states.BUILDING,
1372                    'host': self.host}
1373 
1374         building_insts = objects.InstanceList.get_by_filters(context,
1375                            filters, expected_attrs=[], use_slave=True)
1376 
1377         for instance in building_insts:
1378             if timeutils.is_older_than(instance.created_at, timeout):
1379                 self._set_instance_obj_error_state(context, instance)
1380                 LOG.warning("Instance build timed out. Set to error "
1381                             "state.", instance=instance)
1382 
1383     def _check_instance_exists(self, context, instance):
1384         """Ensure an instance with the same name is not already present."""
1385         if self.driver.instance_exists(instance):
1386             raise exception.InstanceExists(name=instance.name)
1387 
1388     def _allocate_network_async(self, context, instance, requested_networks,
1389                                 macs, security_groups, is_vpn):
1390         """Method used to allocate networks in the background.
1391 
1392         Broken out for testing.
1393         """
1394         # First check to see if we're specifically not supposed to allocate
1395         # networks because if so, we can exit early.
1396         if requested_networks and requested_networks.no_allocate:
1397             LOG.debug("Not allocating networking since 'none' was specified.",
1398                       instance=instance)
1399             return network_model.NetworkInfo([])
1400 
1401         LOG.debug("Allocating IP information in the background.",
1402                   instance=instance)
1403         retries = CONF.network_allocate_retries
1404         attempts = retries + 1
1405         retry_time = 1
1406         bind_host_id = self.driver.network_binding_host_id(context, instance)
1407         for attempt in range(1, attempts + 1):
1408             try:
1409                 nwinfo = self.network_api.allocate_for_instance(
1410                         context, instance, vpn=is_vpn,
1411                         requested_networks=requested_networks,
1412                         macs=macs,
1413                         security_groups=security_groups,
1414                         bind_host_id=bind_host_id)
1415                 LOG.debug('Instance network_info: |%s|', nwinfo,
1416                           instance=instance)
1417                 instance.system_metadata['network_allocated'] = 'True'
1418                 # NOTE(JoshNang) do not save the instance here, as it can cause
1419                 # races. The caller shares a reference to instance and waits
1420                 # for this async greenthread to finish before calling
1421                 # instance.save().
1422                 return nwinfo
1423             except Exception:
1424                 exc_info = sys.exc_info()
1425                 log_info = {'attempt': attempt,
1426                             'attempts': attempts}
1427                 if attempt == attempts:
1428                     LOG.exception('Instance failed network setup '
1429                                   'after %(attempts)d attempt(s)',
1430                                   log_info)
1431                     six.reraise(*exc_info)
1432                 LOG.warning('Instance failed network setup '
1433                             '(attempt %(attempt)d of %(attempts)d)',
1434                             log_info, instance=instance)
1435                 time.sleep(retry_time)
1436                 retry_time *= 2
1437                 if retry_time > 30:
1438                     retry_time = 30
1439         # Not reached.
1440 
1441     def _build_networks_for_instance(self, context, instance,
1442             requested_networks, security_groups):
1443 
1444         # If we're here from a reschedule the network may already be allocated.
1445         if strutils.bool_from_string(
1446                 instance.system_metadata.get('network_allocated', 'False')):
1447             # NOTE(alex_xu): The network_allocated is True means the network
1448             # resource already allocated at previous scheduling, and the
1449             # network setup is cleanup at previous. After rescheduling, the
1450             # network resource need setup on the new host.
1451             self.network_api.setup_instance_network_on_host(
1452                 context, instance, instance.host)
1453             return self.network_api.get_instance_nw_info(context, instance)
1454 
1455         if not self.is_neutron_security_groups:
1456             security_groups = []
1457 
1458         macs = self.driver.macs_for_instance(instance)
1459         network_info = self._allocate_network(context, instance,
1460                 requested_networks, macs, security_groups)
1461 
1462         return network_info
1463 
1464     def _allocate_network(self, context, instance, requested_networks, macs,
1465                           security_groups):
1466         """Start network allocation asynchronously.  Return an instance
1467         of NetworkInfoAsyncWrapper that can be used to retrieve the
1468         allocated networks when the operation has finished.
1469         """
1470         # NOTE(comstud): Since we're allocating networks asynchronously,
1471         # this task state has little meaning, as we won't be in this
1472         # state for very long.
1473         instance.vm_state = vm_states.BUILDING
1474         instance.task_state = task_states.NETWORKING
1475         instance.save(expected_task_state=[None])
1476 
1477         is_vpn = False
1478         return network_model.NetworkInfoAsyncWrapper(
1479                 self._allocate_network_async, context, instance,
1480                 requested_networks, macs, security_groups, is_vpn)
1481 
1482     def _default_root_device_name(self, instance, image_meta, root_bdm):
1483         try:
1484             return self.driver.default_root_device_name(instance,
1485                                                         image_meta,
1486                                                         root_bdm)
1487         except NotImplementedError:
1488             return compute_utils.get_next_device_name(instance, [])
1489 
1490     def _default_device_names_for_instance(self, instance,
1491                                            root_device_name,
1492                                            *block_device_lists):
1493         try:
1494             self.driver.default_device_names_for_instance(instance,
1495                                                           root_device_name,
1496                                                           *block_device_lists)
1497         except NotImplementedError:
1498             compute_utils.default_device_names_for_instance(
1499                 instance, root_device_name, *block_device_lists)
1500 
1501     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1502         # NOTE(ndipanov): Copy obj to avoid changing the original
1503         block_device_obj = block_device_obj.obj_clone()
1504         try:
1505             return self.driver.get_device_name_for_instance(
1506                 instance, bdms, block_device_obj)
1507         except NotImplementedError:
1508             return compute_utils.get_device_name_for_instance(
1509                 instance, bdms, block_device_obj.get("device_name"))
1510 
1511     def _default_block_device_names(self, instance, image_meta, block_devices):
1512         """Verify that all the devices have the device_name set. If not,
1513         provide a default name.
1514 
1515         It also ensures that there is a root_device_name and is set to the
1516         first block device in the boot sequence (boot_index=0).
1517         """
1518         root_bdm = block_device.get_root_bdm(block_devices)
1519         if not root_bdm:
1520             return
1521 
1522         # Get the root_device_name from the root BDM or the instance
1523         root_device_name = None
1524         update_root_bdm = False
1525 
1526         if root_bdm.device_name:
1527             root_device_name = root_bdm.device_name
1528             instance.root_device_name = root_device_name
1529         elif instance.root_device_name:
1530             root_device_name = instance.root_device_name
1531             root_bdm.device_name = root_device_name
1532             update_root_bdm = True
1533         else:
1534             root_device_name = self._default_root_device_name(instance,
1535                                                               image_meta,
1536                                                               root_bdm)
1537 
1538             instance.root_device_name = root_device_name
1539             root_bdm.device_name = root_device_name
1540             update_root_bdm = True
1541 
1542         if update_root_bdm:
1543             root_bdm.save()
1544 
1545         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1546                             block_devices))
1547         swap = list(filter(block_device.new_format_is_swap,
1548                       block_devices))
1549         block_device_mapping = list(filter(
1550               driver_block_device.is_block_device_mapping, block_devices))
1551 
1552         self._default_device_names_for_instance(instance,
1553                                                 root_device_name,
1554                                                 ephemerals,
1555                                                 swap,
1556                                                 block_device_mapping)
1557 
1558     def _block_device_info_to_legacy(self, block_device_info):
1559         """Convert BDI to the old format for drivers that need it."""
1560 
1561         if self.use_legacy_block_device_info:
1562             ephemerals = driver_block_device.legacy_block_devices(
1563                 driver.block_device_info_get_ephemerals(block_device_info))
1564             mapping = driver_block_device.legacy_block_devices(
1565                 driver.block_device_info_get_mapping(block_device_info))
1566             swap = block_device_info['swap']
1567             if swap:
1568                 swap = swap.legacy()
1569 
1570             block_device_info.update({
1571                 'ephemerals': ephemerals,
1572                 'swap': swap,
1573                 'block_device_mapping': mapping})
1574 
1575     def _add_missing_dev_names(self, bdms, instance):
1576         for bdm in bdms:
1577             if bdm.device_name is not None:
1578                 continue
1579 
1580             device_name = self._get_device_name_for_instance(instance,
1581                                                              bdms, bdm)
1582             values = {'device_name': device_name}
1583             bdm.update(values)
1584             bdm.save()
1585 
1586     def _prep_block_device(self, context, instance, bdms):
1587         """Set up the block device for an instance with error logging."""
1588         try:
1589             self._add_missing_dev_names(bdms, instance)
1590             block_device_info = driver.get_block_device_info(instance, bdms)
1591             mapping = driver.block_device_info_get_mapping(block_device_info)
1592             driver_block_device.attach_block_devices(
1593                 mapping, context, instance, self.volume_api, self.driver,
1594                 wait_func=self._await_block_device_map_created)
1595 
1596             self._block_device_info_to_legacy(block_device_info)
1597             return block_device_info
1598 
1599         except exception.OverQuota as e:
1600             LOG.warning('Failed to create block device for instance due'
1601                         ' to exceeding volume related resource quota.'
1602                         ' Error: %s', e.message, instance=instance)
1603             raise
1604 
1605         except Exception as ex:
1606             LOG.exception('Instance failed block device setup',
1607                           instance=instance)
1608             # InvalidBDM will eventually result in a BuildAbortException when
1609             # booting from volume, and will be recorded as an instance fault.
1610             # Maintain the original exception message which most likely has
1611             # useful details which the standard InvalidBDM error message lacks.
1612             raise exception.InvalidBDM(six.text_type(ex))
1613 
1614     def _update_instance_after_spawn(self, context, instance):
1615         instance.power_state = self._get_power_state(context, instance)
1616         instance.vm_state = vm_states.ACTIVE
1617         instance.task_state = None
1618         instance.launched_at = timeutils.utcnow()
1619         configdrive.update_instance(instance)
1620 
1621     def _update_scheduler_instance_info(self, context, instance):
1622         """Sends an InstanceList with created or updated Instance objects to
1623         the Scheduler client.
1624 
1625         In the case of init_host, the value passed will already be an
1626         InstanceList. Other calls will send individual Instance objects that
1627         have been created or resized. In this case, we create an InstanceList
1628         object containing that Instance.
1629         """
1630         if not self.send_instance_updates:
1631             return
1632         if isinstance(instance, obj_instance.Instance):
1633             instance = objects.InstanceList(objects=[instance])
1634         context = context.elevated()
1635         self.scheduler_client.update_instance_info(context, self.host,
1636                                                    instance)
1637 
1638     def _delete_scheduler_instance_info(self, context, instance_uuid):
1639         """Sends the uuid of the deleted Instance to the Scheduler client."""
1640         if not self.send_instance_updates:
1641             return
1642         context = context.elevated()
1643         self.scheduler_client.delete_instance_info(context, self.host,
1644                                                    instance_uuid)
1645 
1646     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1647     def _sync_scheduler_instance_info(self, context):
1648         if not self.send_instance_updates:
1649             return
1650         context = context.elevated()
1651         instances = objects.InstanceList.get_by_host(context, self.host,
1652                                                      expected_attrs=[],
1653                                                      use_slave=True)
1654         uuids = [instance.uuid for instance in instances]
1655         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1656 
1657     def _notify_about_instance_usage(self, context, instance, event_suffix,
1658                                      network_info=None, system_metadata=None,
1659                                      extra_usage_info=None, fault=None):
1660         compute_utils.notify_about_instance_usage(
1661             self.notifier, context, instance, event_suffix,
1662             network_info=network_info,
1663             system_metadata=system_metadata,
1664             extra_usage_info=extra_usage_info, fault=fault)
1665 
1666     def _deallocate_network(self, context, instance,
1667                             requested_networks=None):
1668         # If we were told not to allocate networks let's save ourselves
1669         # the trouble of calling the network API.
1670         if requested_networks and requested_networks.no_allocate:
1671             LOG.debug("Skipping network deallocation for instance since "
1672                       "networking was not requested.", instance=instance)
1673             return
1674 
1675         LOG.debug('Deallocating network for instance', instance=instance)
1676         with timeutils.StopWatch() as timer:
1677             self.network_api.deallocate_for_instance(
1678                 context, instance, requested_networks=requested_networks)
1679         # nova-network does an rpc call so we're OK tracking time spent here
1680         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1681                  timer.elapsed(), instance=instance)
1682 
1683     def _get_instance_block_device_info(self, context, instance,
1684                                         refresh_conn_info=False,
1685                                         bdms=None):
1686         """Transform block devices to the driver block_device format."""
1687 
1688         if not bdms:
1689             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1690                     context, instance.uuid)
1691         block_device_info = driver.get_block_device_info(instance, bdms)
1692 
1693         if not refresh_conn_info:
1694             # if the block_device_mapping has no value in connection_info
1695             # (returned as None), don't include in the mapping
1696             block_device_info['block_device_mapping'] = [
1697                 bdm for bdm in driver.block_device_info_get_mapping(
1698                                     block_device_info)
1699                 if bdm.get('connection_info')]
1700         else:
1701             driver_block_device.refresh_conn_infos(
1702                 driver.block_device_info_get_mapping(block_device_info),
1703                 context, instance, self.volume_api, self.driver)
1704 
1705         self._block_device_info_to_legacy(block_device_info)
1706 
1707         return block_device_info
1708 
1709     def _build_failed(self):
1710         self._failed_builds += 1
1711         limit = CONF.compute.consecutive_build_service_disable_threshold
1712         if limit and self._failed_builds >= limit:
1713             # NOTE(danms): If we're doing a bunch of parallel builds,
1714             # it is possible (although not likely) that we have already
1715             # failed N-1 builds before this and we race with a successful
1716             # build and disable ourselves here when we might've otherwise
1717             # not.
1718             LOG.error('Disabling service due to %(fails)i '
1719                       'consecutive build failures',
1720                       {'fails': self._failed_builds})
1721             ctx = nova.context.get_admin_context()
1722             service = objects.Service.get_by_compute_host(ctx, CONF.host)
1723             service.disabled = True
1724             service.disabled_reason = (
1725                 'Auto-disabled due to %i build failures' % self._failed_builds)
1726             service.save()
1727             # NOTE(danms): Reset our counter now so that when the admin
1728             # re-enables us we can start fresh
1729             self._failed_builds = 0
1730         elif self._failed_builds > 1:
1731             LOG.warning('%(fails)i consecutive build failures',
1732                         {'fails': self._failed_builds})
1733 
1734     @wrap_exception()
1735     @reverts_task_state
1736     @wrap_instance_fault
1737     def build_and_run_instance(self, context, instance, image, request_spec,
1738                      filter_properties, admin_password=None,
1739                      injected_files=None, requested_networks=None,
1740                      security_groups=None, block_device_mapping=None,
1741                      node=None, limits=None, host_list=None):
1742 
1743         @utils.synchronized(instance.uuid)
1744         def _locked_do_build_and_run_instance(*args, **kwargs):
1745             # NOTE(danms): We grab the semaphore with the instance uuid
1746             # locked because we could wait in line to build this instance
1747             # for a while and we want to make sure that nothing else tries
1748             # to do anything with this instance while we wait.
1749             with self._build_semaphore:
1750                 try:
1751                     result = self._do_build_and_run_instance(*args, **kwargs)
1752                 except Exception:
1753                     # NOTE(mriedem): This should really only happen if
1754                     # _decode_files in _do_build_and_run_instance fails, and
1755                     # that's before a guest is spawned so it's OK to remove
1756                     # allocations for the instance for this node from Placement
1757                     # below as there is no guest consuming resources anyway.
1758                     # The _decode_files case could be handled more specifically
1759                     # but that's left for another day.
1760                     result = build_results.FAILED
1761                     raise
1762                 finally:
1763                     if result == build_results.FAILED:
1764                         # Remove the allocation records from Placement for the
1765                         # instance if the build failed. The instance.host is
1766                         # likely set to None in _do_build_and_run_instance
1767                         # which means if the user deletes the instance, it
1768                         # will be deleted in the API, not the compute service.
1769                         # Setting the instance.host to None in
1770                         # _do_build_and_run_instance means that the
1771                         # ResourceTracker will no longer consider this instance
1772                         # to be claiming resources against it, so we want to
1773                         # reflect that same thing in Placement.  No need to
1774                         # call this for a reschedule, as the allocations will
1775                         # have already been removed in
1776                         # self._do_build_and_run_instance().
1777                         self._delete_allocation_for_instance(context,
1778                                                              instance.uuid)
1779 
1780                     if result in (build_results.FAILED,
1781                                   build_results.RESCHEDULED):
1782                         self._build_failed()
1783                     else:
1784                         self._failed_builds = 0
1785 
1786         # NOTE(danms): We spawn here to return the RPC worker thread back to
1787         # the pool. Since what follows could take a really long time, we don't
1788         # want to tie up RPC workers.
1789         utils.spawn_n(_locked_do_build_and_run_instance,
1790                       context, instance, image, request_spec,
1791                       filter_properties, admin_password, injected_files,
1792                       requested_networks, security_groups,
1793                       block_device_mapping, node, limits, host_list)
1794 
1795     def _delete_allocation_for_instance(self, context, instance_uuid):
1796         rt = self._get_resource_tracker()
1797         rt.reportclient.delete_allocation_for_instance(context, instance_uuid)
1798 
1799     def _check_device_tagging(self, requested_networks, block_device_mapping):
1800         tagging_requested = False
1801         if requested_networks:
1802             for net in requested_networks:
1803                 if 'tag' in net and net.tag is not None:
1804                     tagging_requested = True
1805                     break
1806         if block_device_mapping and not tagging_requested:
1807             for bdm in block_device_mapping:
1808                 if 'tag' in bdm and bdm.tag is not None:
1809                     tagging_requested = True
1810                     break
1811         if (tagging_requested and
1812                 not self.driver.capabilities.get('supports_device_tagging')):
1813             raise exception.BuildAbortException('Attempt to boot guest with '
1814                                                 'tagged devices on host that '
1815                                                 'does not support tagging.')
1816 
1817     @hooks.add_hook('build_instance')
1818     @wrap_exception()
1819     @reverts_task_state
1820     @wrap_instance_event(prefix='compute')
1821     @wrap_instance_fault
1822     def _do_build_and_run_instance(self, context, instance, image,
1823             request_spec, filter_properties, admin_password, injected_files,
1824             requested_networks, security_groups, block_device_mapping,
1825             node=None, limits=None, host_list=None):
1826 
1827         try:
1828             LOG.debug('Starting instance...', instance=instance)
1829             instance.vm_state = vm_states.BUILDING
1830             instance.task_state = None
1831             instance.save(expected_task_state=
1832                     (task_states.SCHEDULING, None))
1833         except exception.InstanceNotFound:
1834             msg = 'Instance disappeared before build.'
1835             LOG.debug(msg, instance=instance)
1836             return build_results.FAILED
1837         except exception.UnexpectedTaskStateError as e:
1838             LOG.debug(e.format_message(), instance=instance)
1839             return build_results.FAILED
1840 
1841         # b64 decode the files to inject:
1842         decoded_files = self._decode_files(injected_files)
1843 
1844         if limits is None:
1845             limits = {}
1846 
1847         if node is None:
1848             node = self._get_nodename(instance, refresh=True)
1849 
1850         try:
1851             with timeutils.StopWatch() as timer:
1852                 self._build_and_run_instance(context, instance, image,
1853                         decoded_files, admin_password, requested_networks,
1854                         security_groups, block_device_mapping, node, limits,
1855                         filter_properties, request_spec)
1856             LOG.info('Took %0.2f seconds to build instance.',
1857                      timer.elapsed(), instance=instance)
1858             return build_results.ACTIVE
1859         except exception.RescheduledException as e:
1860             retry = filter_properties.get('retry')
1861             if not retry:
1862                 # no retry information, do not reschedule.
1863                 LOG.debug("Retry info not present, will not reschedule",
1864                     instance=instance)
1865                 self._cleanup_allocated_networks(context, instance,
1866                     requested_networks)
1867                 self._cleanup_volumes(context, instance.uuid,
1868                     block_device_mapping, raise_exc=False)
1869                 compute_utils.add_instance_fault_from_exc(context,
1870                         instance, e, sys.exc_info(),
1871                         fault_message=e.kwargs['reason'])
1872                 self._nil_out_instance_obj_host_and_node(instance)
1873                 self._set_instance_obj_error_state(context, instance,
1874                                                    clean_task_state=True)
1875                 return build_results.FAILED
1876             LOG.debug(e.format_message(), instance=instance)
1877             # This will be used for logging the exception
1878             retry['exc'] = traceback.format_exception(*sys.exc_info())
1879             # This will be used for setting the instance fault message
1880             retry['exc_reason'] = e.kwargs['reason']
1881             # NOTE(comstud): Deallocate networks if the driver wants
1882             # us to do so.
1883             # NOTE(vladikr): SR-IOV ports should be deallocated to
1884             # allow new sriov pci devices to be allocated on a new host.
1885             # Otherwise, if devices with pci addresses are already allocated
1886             # on the destination host, the instance will fail to spawn.
1887             # info_cache.network_info should be present at this stage.
1888             if (self.driver.deallocate_networks_on_reschedule(instance) or
1889                 self.deallocate_sriov_ports_on_reschedule(instance)):
1890                 self._cleanup_allocated_networks(context, instance,
1891                         requested_networks)
1892             else:
1893                 # NOTE(alex_xu): Network already allocated and we don't
1894                 # want to deallocate them before rescheduling. But we need
1895                 # to cleanup those network resources setup on this host before
1896                 # rescheduling.
1897                 self.network_api.cleanup_instance_network_on_host(
1898                     context, instance, self.host)
1899 
1900             self._nil_out_instance_obj_host_and_node(instance)
1901             instance.task_state = task_states.SCHEDULING
1902             instance.save()
1903             # The instance will have already claimed resources from this host
1904             # before this build was attempted. Now that it has failed, we need
1905             # to unclaim those resources before casting to the conductor, so
1906             # that if there are alternate hosts available for a retry, it can
1907             # claim resources on that new host for the instance.
1908             self._delete_allocation_for_instance(context, instance.uuid)
1909 
1910             self.compute_task_api.build_instances(context, [instance],
1911                     image, filter_properties, admin_password,
1912                     injected_files, requested_networks, security_groups,
1913                     block_device_mapping, request_spec=request_spec,
1914                     host_lists=[host_list])
1915             return build_results.RESCHEDULED
1916         except (exception.InstanceNotFound,
1917                 exception.UnexpectedDeletingTaskStateError):
1918             msg = 'Instance disappeared during build.'
1919             LOG.debug(msg, instance=instance)
1920             self._cleanup_allocated_networks(context, instance,
1921                     requested_networks)
1922             return build_results.FAILED
1923         except exception.BuildAbortException as e:
1924             LOG.exception(e.format_message(), instance=instance)
1925             self._cleanup_allocated_networks(context, instance,
1926                     requested_networks)
1927             self._cleanup_volumes(context, instance.uuid,
1928                     block_device_mapping, raise_exc=False)
1929             compute_utils.add_instance_fault_from_exc(context, instance,
1930                     e, sys.exc_info())
1931             self._nil_out_instance_obj_host_and_node(instance)
1932             self._set_instance_obj_error_state(context, instance,
1933                                                clean_task_state=True)
1934             return build_results.FAILED
1935         except Exception as e:
1936             # Should not reach here.
1937             LOG.exception('Unexpected build failure, not rescheduling build.',
1938                           instance=instance)
1939             self._cleanup_allocated_networks(context, instance,
1940                     requested_networks)
1941             self._cleanup_volumes(context, instance.uuid,
1942                     block_device_mapping, raise_exc=False)
1943             compute_utils.add_instance_fault_from_exc(context, instance,
1944                     e, sys.exc_info())
1945             self._nil_out_instance_obj_host_and_node(instance)
1946             self._set_instance_obj_error_state(context, instance,
1947                                                clean_task_state=True)
1948             return build_results.FAILED
1949 
1950     def deallocate_sriov_ports_on_reschedule(self, instance):
1951         """Determine if networks are needed to be deallocated before reschedule
1952 
1953         Check the cached network info for any assigned SR-IOV ports.
1954         SR-IOV ports should be deallocated prior to rescheduling
1955         in order to allow new sriov pci devices to be allocated on a new host.
1956         """
1957         info_cache = instance.info_cache
1958 
1959         def _has_sriov_port(vif):
1960             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1961 
1962         if (info_cache and info_cache.network_info):
1963             for vif in info_cache.network_info:
1964                 if _has_sriov_port(vif):
1965                     return True
1966         return False
1967 
1968     @staticmethod
1969     def _get_scheduler_hints(filter_properties, request_spec=None):
1970         """Helper method to get scheduler hints.
1971 
1972         This method prefers to get the hints out of the request spec, but that
1973         might not be provided. Conductor will pass request_spec down to the
1974         first compute chosen for a build but older computes will not pass
1975         the request_spec to conductor's build_instances method for a
1976         a reschedule, so if we're on a host via a retry, request_spec may not
1977         be provided so we need to fallback to use the filter_properties
1978         to get scheduler hints.
1979         """
1980         hints = {}
1981         if request_spec is not None and 'scheduler_hints' in request_spec:
1982             hints = request_spec.scheduler_hints
1983         if not hints:
1984             hints = filter_properties.get('scheduler_hints') or {}
1985         return hints
1986 
1987     def _build_and_run_instance(self, context, instance, image, injected_files,
1988             admin_password, requested_networks, security_groups,
1989             block_device_mapping, node, limits, filter_properties,
1990             request_spec=None):
1991 
1992         image_name = image.get('name')
1993         self._notify_about_instance_usage(context, instance, 'create.start',
1994                 extra_usage_info={'image_name': image_name})
1995         compute_utils.notify_about_instance_create(
1996             context, instance, self.host,
1997             phase=fields.NotificationPhase.START,
1998             bdms=block_device_mapping)
1999 
2000         # NOTE(mikal): cache the keystone roles associated with the instance
2001         # at boot time for later reference
2002         instance.system_metadata.update(
2003             {'boot_roles': ','.join(context.roles)})
2004 
2005         self._check_device_tagging(requested_networks, block_device_mapping)
2006 
2007         try:
2008             scheduler_hints = self._get_scheduler_hints(filter_properties,
2009                                                         request_spec)
2010             rt = self._get_resource_tracker()
2011             with rt.instance_claim(context, instance, node, limits):
2012                 # NOTE(russellb) It's important that this validation be done
2013                 # *after* the resource tracker instance claim, as that is where
2014                 # the host is set on the instance.
2015                 self._validate_instance_group_policy(context, instance,
2016                                                      scheduler_hints)
2017                 image_meta = objects.ImageMeta.from_dict(image)
2018                 with self._build_resources(context, instance,
2019                         requested_networks, security_groups, image_meta,
2020                         block_device_mapping) as resources:
2021                     instance.vm_state = vm_states.BUILDING
2022                     instance.task_state = task_states.SPAWNING
2023                     # NOTE(JoshNang) This also saves the changes to the
2024                     # instance from _allocate_network_async, as they aren't
2025                     # saved in that function to prevent races.
2026                     instance.save(expected_task_state=
2027                             task_states.BLOCK_DEVICE_MAPPING)
2028                     block_device_info = resources['block_device_info']
2029                     network_info = resources['network_info']
2030                     allocs = resources['allocations']
2031                     LOG.debug('Start spawning the instance on the hypervisor.',
2032                               instance=instance)
2033                     with timeutils.StopWatch() as timer:
2034                         self.driver.spawn(context, instance, image_meta,
2035                                           injected_files, admin_password,
2036                                           allocs, network_info=network_info,
2037                                           block_device_info=block_device_info)
2038                     LOG.info('Took %0.2f seconds to spawn the instance on '
2039                              'the hypervisor.', timer.elapsed(),
2040                              instance=instance)
2041         except (exception.InstanceNotFound,
2042                 exception.UnexpectedDeletingTaskStateError) as e:
2043             with excutils.save_and_reraise_exception():
2044                 self._notify_about_instance_usage(context, instance,
2045                     'create.error', fault=e)
2046                 compute_utils.notify_about_instance_create(
2047                     context, instance, self.host,
2048                     phase=fields.NotificationPhase.ERROR, exception=e,
2049                     bdms=block_device_mapping)
2050         except exception.ComputeResourcesUnavailable as e:
2051             LOG.debug(e.format_message(), instance=instance)
2052             self._notify_about_instance_usage(context, instance,
2053                     'create.error', fault=e)
2054             compute_utils.notify_about_instance_create(
2055                     context, instance, self.host,
2056                     phase=fields.NotificationPhase.ERROR, exception=e,
2057                     bdms=block_device_mapping)
2058             raise exception.RescheduledException(
2059                     instance_uuid=instance.uuid, reason=e.format_message())
2060         except exception.BuildAbortException as e:
2061             with excutils.save_and_reraise_exception():
2062                 LOG.debug(e.format_message(), instance=instance)
2063                 self._notify_about_instance_usage(context, instance,
2064                     'create.error', fault=e)
2065                 compute_utils.notify_about_instance_create(
2066                     context, instance, self.host,
2067                     phase=fields.NotificationPhase.ERROR, exception=e,
2068                     bdms=block_device_mapping)
2069         except (exception.FixedIpLimitExceeded,
2070                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2071             LOG.warning('No more network or fixed IP to be allocated',
2072                         instance=instance)
2073             self._notify_about_instance_usage(context, instance,
2074                     'create.error', fault=e)
2075             compute_utils.notify_about_instance_create(
2076                     context, instance, self.host,
2077                     phase=fields.NotificationPhase.ERROR, exception=e,
2078                     bdms=block_device_mapping)
2079             msg = _('Failed to allocate the network(s) with error %s, '
2080                     'not rescheduling.') % e.format_message()
2081             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2082                     reason=msg)
2083         except (exception.VirtualInterfaceCreateException,
2084                 exception.VirtualInterfaceMacAddressException,
2085                 exception.FixedIpInvalidOnHost,
2086                 exception.UnableToAutoAllocateNetwork) as e:
2087             LOG.exception('Failed to allocate network(s)',
2088                           instance=instance)
2089             self._notify_about_instance_usage(context, instance,
2090                     'create.error', fault=e)
2091             compute_utils.notify_about_instance_create(
2092                     context, instance, self.host,
2093                     phase=fields.NotificationPhase.ERROR, exception=e,
2094                     bdms=block_device_mapping)
2095             msg = _('Failed to allocate the network(s), not rescheduling.')
2096             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2097                     reason=msg)
2098         except (exception.FlavorDiskTooSmall,
2099                 exception.FlavorMemoryTooSmall,
2100                 exception.ImageNotActive,
2101                 exception.ImageUnacceptable,
2102                 exception.InvalidDiskInfo,
2103                 exception.InvalidDiskFormat,
2104                 cursive_exception.SignatureVerificationError,
2105                 exception.VolumeEncryptionNotSupported,
2106                 exception.InvalidInput) as e:
2107             self._notify_about_instance_usage(context, instance,
2108                     'create.error', fault=e)
2109             compute_utils.notify_about_instance_create(
2110                     context, instance, self.host,
2111                     phase=fields.NotificationPhase.ERROR, exception=e,
2112                     bdms=block_device_mapping)
2113             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2114                     reason=e.format_message())
2115         except Exception as e:
2116             self._notify_about_instance_usage(context, instance,
2117                     'create.error', fault=e)
2118             compute_utils.notify_about_instance_create(
2119                     context, instance, self.host,
2120                     phase=fields.NotificationPhase.ERROR, exception=e,
2121                     bdms=block_device_mapping)
2122             raise exception.RescheduledException(
2123                     instance_uuid=instance.uuid, reason=six.text_type(e))
2124 
2125         # NOTE(alaski): This is only useful during reschedules, remove it now.
2126         instance.system_metadata.pop('network_allocated', None)
2127 
2128         # If CONF.default_access_ip_network_name is set, grab the
2129         # corresponding network and set the access ip values accordingly.
2130         network_name = CONF.default_access_ip_network_name
2131         if (network_name and not instance.access_ip_v4 and
2132                 not instance.access_ip_v6):
2133             # Note that when there are multiple ips to choose from, an
2134             # arbitrary one will be chosen.
2135             for vif in network_info:
2136                 if vif['network']['label'] == network_name:
2137                     for ip in vif.fixed_ips():
2138                         if not instance.access_ip_v4 and ip['version'] == 4:
2139                             instance.access_ip_v4 = ip['address']
2140                         if not instance.access_ip_v6 and ip['version'] == 6:
2141                             instance.access_ip_v6 = ip['address']
2142                     break
2143 
2144         self._update_instance_after_spawn(context, instance)
2145 
2146         try:
2147             instance.save(expected_task_state=task_states.SPAWNING)
2148         except (exception.InstanceNotFound,
2149                 exception.UnexpectedDeletingTaskStateError) as e:
2150             with excutils.save_and_reraise_exception():
2151                 self._notify_about_instance_usage(context, instance,
2152                     'create.error', fault=e)
2153                 compute_utils.notify_about_instance_create(
2154                     context, instance, self.host,
2155                     phase=fields.NotificationPhase.ERROR, exception=e,
2156                     bdms=block_device_mapping)
2157 
2158         self._update_scheduler_instance_info(context, instance)
2159         self._notify_about_instance_usage(context, instance, 'create.end',
2160                 extra_usage_info={'message': _('Success')},
2161                 network_info=network_info)
2162         compute_utils.notify_about_instance_create(context, instance,
2163                 self.host, phase=fields.NotificationPhase.END,
2164                 bdms=block_device_mapping)
2165 
2166     @contextlib.contextmanager
2167     def _build_resources(self, context, instance, requested_networks,
2168                          security_groups, image_meta, block_device_mapping):
2169         resources = {}
2170         network_info = None
2171         try:
2172             LOG.debug('Start building networks asynchronously for instance.',
2173                       instance=instance)
2174             network_info = self._build_networks_for_instance(context, instance,
2175                     requested_networks, security_groups)
2176             resources['network_info'] = network_info
2177         except (exception.InstanceNotFound,
2178                 exception.UnexpectedDeletingTaskStateError):
2179             raise
2180         except exception.UnexpectedTaskStateError as e:
2181             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2182                     reason=e.format_message())
2183         except Exception:
2184             # Because this allocation is async any failures are likely to occur
2185             # when the driver accesses network_info during spawn().
2186             LOG.exception('Failed to allocate network(s)',
2187                           instance=instance)
2188             msg = _('Failed to allocate the network(s), not rescheduling.')
2189             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2190                     reason=msg)
2191 
2192         try:
2193             # Verify that all the BDMs have a device_name set and assign a
2194             # default to the ones missing it with the help of the driver.
2195             self._default_block_device_names(instance, image_meta,
2196                                              block_device_mapping)
2197 
2198             LOG.debug('Start building block device mappings for instance.',
2199                       instance=instance)
2200             instance.vm_state = vm_states.BUILDING
2201             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2202             instance.save()
2203 
2204             block_device_info = self._prep_block_device(context, instance,
2205                     block_device_mapping)
2206             resources['block_device_info'] = block_device_info
2207         except (exception.InstanceNotFound,
2208                 exception.UnexpectedDeletingTaskStateError):
2209             with excutils.save_and_reraise_exception():
2210                 # Make sure the async call finishes
2211                 if network_info is not None:
2212                     network_info.wait(do_raise=False)
2213         except (exception.UnexpectedTaskStateError,
2214                 exception.OverQuota, exception.InvalidBDM) as e:
2215             # Make sure the async call finishes
2216             if network_info is not None:
2217                 network_info.wait(do_raise=False)
2218             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2219                     reason=e.format_message())
2220         except Exception:
2221             LOG.exception('Failure prepping block device',
2222                           instance=instance)
2223             # Make sure the async call finishes
2224             if network_info is not None:
2225                 network_info.wait(do_raise=False)
2226             msg = _('Failure prepping block device.')
2227             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2228                     reason=msg)
2229 
2230         try:
2231             resources['allocations'] = (
2232                 self.reportclient.get_allocations_for_consumer(instance.uuid))
2233         except Exception:
2234             LOG.exception('Failure retrieving placement allocations',
2235                           instance=instance)
2236             # Make sure the async call finishes
2237             if network_info is not None:
2238                 network_info.wait(do_raise=False)
2239             msg = _('Failure retrieving placement allocations')
2240             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2241                                                 reason=msg)
2242 
2243         try:
2244             yield resources
2245         except Exception as exc:
2246             with excutils.save_and_reraise_exception() as ctxt:
2247                 if not isinstance(exc, (
2248                         exception.InstanceNotFound,
2249                         exception.UnexpectedDeletingTaskStateError)):
2250                     LOG.exception('Instance failed to spawn',
2251                                   instance=instance)
2252                 # Make sure the async call finishes
2253                 if network_info is not None:
2254                     network_info.wait(do_raise=False)
2255                 # if network_info is empty we're likely here because of
2256                 # network allocation failure. Since nothing can be reused on
2257                 # rescheduling it's better to deallocate network to eliminate
2258                 # the chance of orphaned ports in neutron
2259                 deallocate_networks = False if network_info else True
2260                 try:
2261                     self._shutdown_instance(context, instance,
2262                             block_device_mapping, requested_networks,
2263                             try_deallocate_networks=deallocate_networks)
2264                 except Exception as exc2:
2265                     ctxt.reraise = False
2266                     LOG.warning('Could not clean up failed build,'
2267                                 ' not rescheduling. Error: %s',
2268                                 six.text_type(exc2))
2269                     raise exception.BuildAbortException(
2270                             instance_uuid=instance.uuid,
2271                             reason=six.text_type(exc))
2272 
2273     def _cleanup_allocated_networks(self, context, instance,
2274             requested_networks):
2275         try:
2276             self._deallocate_network(context, instance, requested_networks)
2277         except Exception:
2278             LOG.exception('Failed to deallocate networks', instance=instance)
2279             return
2280 
2281         instance.system_metadata['network_allocated'] = 'False'
2282         try:
2283             instance.save()
2284         except exception.InstanceNotFound:
2285             # NOTE(alaski): It's possible that we're cleaning up the networks
2286             # because the instance was deleted.  If that's the case then this
2287             # exception will be raised by instance.save()
2288             pass
2289 
2290     def _try_deallocate_network(self, context, instance,
2291                                 requested_networks=None):
2292         try:
2293             # tear down allocated network structure
2294             self._deallocate_network(context, instance, requested_networks)
2295         except Exception as ex:
2296             with excutils.save_and_reraise_exception():
2297                 LOG.error('Failed to deallocate network for instance. '
2298                           'Error: %s', ex, instance=instance)
2299                 self._set_instance_obj_error_state(context, instance)
2300 
2301     def _get_power_off_values(self, context, instance, clean_shutdown):
2302         """Get the timing configuration for powering down this instance."""
2303         if clean_shutdown:
2304             timeout = compute_utils.get_value_from_system_metadata(instance,
2305                           key='image_os_shutdown_timeout', type=int,
2306                           default=CONF.shutdown_timeout)
2307             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2308         else:
2309             timeout = 0
2310             retry_interval = 0
2311 
2312         return timeout, retry_interval
2313 
2314     def _power_off_instance(self, context, instance, clean_shutdown=True):
2315         """Power off an instance on this host."""
2316         timeout, retry_interval = self._get_power_off_values(context,
2317                                         instance, clean_shutdown)
2318         self.driver.power_off(instance, timeout, retry_interval)
2319 
2320     def _shutdown_instance(self, context, instance,
2321                            bdms, requested_networks=None, notify=True,
2322                            try_deallocate_networks=True):
2323         """Shutdown an instance on this host.
2324 
2325         :param:context: security context
2326         :param:instance: a nova.objects.Instance object
2327         :param:bdms: the block devices for the instance to be torn
2328                      down
2329         :param:requested_networks: the networks on which the instance
2330                                    has ports
2331         :param:notify: true if a final usage notification should be
2332                        emitted
2333         :param:try_deallocate_networks: false if we should avoid
2334                                         trying to teardown networking
2335         """
2336         context = context.elevated()
2337         LOG.info('Terminating instance', instance=instance)
2338 
2339         if notify:
2340             self._notify_about_instance_usage(context, instance,
2341                                               "shutdown.start")
2342             compute_utils.notify_about_instance_action(context, instance,
2343                     self.host, action=fields.NotificationAction.SHUTDOWN,
2344                     phase=fields.NotificationPhase.START, bdms=bdms)
2345 
2346         network_info = instance.get_network_info()
2347 
2348         # NOTE(vish) get bdms before destroying the instance
2349         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2350         block_device_info = self._get_instance_block_device_info(
2351             context, instance, bdms=bdms)
2352 
2353         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2354         #                want to keep ip allocated for certain failures
2355         timer = timeutils.StopWatch()
2356         try:
2357             LOG.debug('Start destroying the instance on the hypervisor.',
2358                       instance=instance)
2359             timer.start()
2360             self.driver.destroy(context, instance, network_info,
2361                     block_device_info)
2362             LOG.info('Took %0.2f seconds to destroy the instance on the '
2363                      'hypervisor.', timer.elapsed(), instance=instance)
2364         except exception.InstancePowerOffFailure:
2365             # if the instance can't power off, don't release the ip
2366             with excutils.save_and_reraise_exception():
2367                 pass
2368         except Exception:
2369             with excutils.save_and_reraise_exception():
2370                 # deallocate ip and fail without proceeding to
2371                 # volume api calls, preserving current behavior
2372                 if try_deallocate_networks:
2373                     self._try_deallocate_network(context, instance,
2374                                                  requested_networks)
2375 
2376         if try_deallocate_networks:
2377             self._try_deallocate_network(context, instance, requested_networks)
2378 
2379         timer.restart()
2380         for bdm in vol_bdms:
2381             try:
2382                 if bdm.attachment_id:
2383                     self.volume_api.attachment_delete(context,
2384                                                       bdm.attachment_id)
2385                 else:
2386                     # NOTE(vish): actual driver detach done in driver.destroy,
2387                     #             so just tell cinder that we are done with it.
2388                     connector = self.driver.get_volume_connector(instance)
2389                     self.volume_api.terminate_connection(context,
2390                                                          bdm.volume_id,
2391                                                          connector)
2392                     self.volume_api.detach(context, bdm.volume_id,
2393                                            instance.uuid)
2394 
2395             except exception.VolumeAttachmentNotFound as exc:
2396                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2397                           instance=instance)
2398             except exception.DiskNotFound as exc:
2399                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2400                           instance=instance)
2401             except exception.VolumeNotFound as exc:
2402                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2403                           instance=instance)
2404             except (cinder_exception.EndpointNotFound,
2405                     keystone_exception.EndpointNotFound) as exc:
2406                 LOG.warning('Ignoring EndpointNotFound for '
2407                             'volume %(volume_id)s: %(exc)s',
2408                             {'exc': exc, 'volume_id': bdm.volume_id},
2409                             instance=instance)
2410             except cinder_exception.ClientException as exc:
2411                 LOG.warning('Ignoring unknown cinder exception for '
2412                             'volume %(volume_id)s: %(exc)s',
2413                             {'exc': exc, 'volume_id': bdm.volume_id},
2414                             instance=instance)
2415             except Exception as exc:
2416                 LOG.warning('Ignoring unknown exception for '
2417                             'volume %(volume_id)s: %(exc)s',
2418                             {'exc': exc, 'volume_id': bdm.volume_id},
2419                             instance=instance)
2420         if vol_bdms:
2421             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2422                      'for instance.',
2423                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2424                      instance=instance)
2425 
2426         if notify:
2427             self._notify_about_instance_usage(context, instance,
2428                                               "shutdown.end")
2429             compute_utils.notify_about_instance_action(context, instance,
2430                     self.host, action=fields.NotificationAction.SHUTDOWN,
2431                     phase=fields.NotificationPhase.END, bdms=bdms)
2432 
2433     def _cleanup_volumes(self, context, instance_uuid, bdms, raise_exc=True):
2434         exc_info = None
2435 
2436         try:
2437             instance = objects.Instance.get_by_uuid(
2438                 context, instance_uuid,
2439                 expected_attrs=[])
2440         except exception.InstanceNotFound:
2441             LOG.info("Instance is not found",
2442                      instance=instance)
2443         for bdm in bdms:
2444             if bdm.is_volume and bdm.volume_id:
2445                 volume = self.volume_api.get(context, bdm.volume_id)
2446                 if volume.get('attach_status') != "detached":
2447                     self._detach_volume(context, bdm, instance,
2448                                     destroy_bdm=False)
2449 
2450             LOG.debug("terminating bdm %s", bdm,
2451                       instance_uuid=instance_uuid)
2452             if bdm.volume_id and bdm.delete_on_termination:
2453                 try:
2454                     self.volume_api.delete(context, bdm.volume_id)
2455                 except Exception as exc:
2456                     exc_info = sys.exc_info()
2457                     LOG.warning('Failed to delete volume: %(volume_id)s '
2458                                 'due to %(exc)s',
2459                                 {'volume_id': bdm.volume_id, 'exc': exc})
2460         if exc_info is not None and raise_exc:
2461             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2462 
2463     @hooks.add_hook("delete_instance")
2464     def _delete_instance(self, context, instance, bdms):
2465         """Delete an instance on this host.
2466 
2467         :param context: nova request context
2468         :param instance: nova.objects.instance.Instance object
2469         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2470         """
2471         events = self.instance_events.clear_events_for_instance(instance)
2472         if events:
2473             LOG.debug('Events pending at deletion: %(events)s',
2474                       {'events': ','.join(events.keys())},
2475                       instance=instance)
2476         self._notify_about_instance_usage(context, instance,
2477                                           "delete.start")
2478         compute_utils.notify_about_instance_action(context, instance,
2479                 self.host, action=fields.NotificationAction.DELETE,
2480                 phase=fields.NotificationPhase.START, bdms=bdms)
2481 
2482         self._shutdown_instance(context, instance, bdms)
2483         # NOTE(dims): instance.info_cache.delete() should be called after
2484         # _shutdown_instance in the compute manager as shutdown calls
2485         # deallocate_for_instance so the info_cache is still needed
2486         # at this point.
2487         if instance.info_cache is not None:
2488             instance.info_cache.delete()
2489         else:
2490             # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2491             # is None. When the root cause that instance.info_cache becomes
2492             # None is fixed, the log level should be reconsidered.
2493             LOG.warning("Info cache for instance could not be found. "
2494                         "Ignore.", instance=instance)
2495 
2496         # NOTE(vish): We have already deleted the instance, so we have
2497         #             to ignore problems cleaning up the volumes. It
2498         #             would be nice to let the user know somehow that
2499         #             the volume deletion failed, but it is not
2500         #             acceptable to have an instance that can not be
2501         #             deleted. Perhaps this could be reworked in the
2502         #             future to set an instance fault the first time
2503         #             and to only ignore the failure if the instance
2504         #             is already in ERROR.
2505         self._cleanup_volumes(context, instance.uuid, bdms,
2506                 raise_exc=False)
2507         # if a delete task succeeded, always update vm state and task
2508         # state without expecting task state to be DELETING
2509         instance.vm_state = vm_states.DELETED
2510         instance.task_state = None
2511         instance.power_state = power_state.NOSTATE
2512         instance.terminated_at = timeutils.utcnow()
2513         instance.save()
2514         system_meta = instance.system_metadata
2515         instance.destroy()
2516 
2517         self._complete_deletion(context,
2518                                 instance,
2519                                 bdms,
2520                                 system_meta)
2521 
2522     @wrap_exception()
2523     @reverts_task_state
2524     @wrap_instance_event(prefix='compute')
2525     @wrap_instance_fault
2526     def terminate_instance(self, context, instance, bdms, reservations):
2527         """Terminate an instance on this host."""
2528         @utils.synchronized(instance.uuid)
2529         def do_terminate_instance(instance, bdms):
2530             # NOTE(mriedem): If we are deleting the instance while it was
2531             # booting from volume, we could be racing with a database update of
2532             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2533             # to compute here, the BDMs may be stale at this point. So check
2534             # for any volume BDMs that don't have volume_id set and if we
2535             # detect that, we need to refresh the BDM list before proceeding.
2536             # TODO(mriedem): Move this into _delete_instance and make the bdms
2537             # parameter optional.
2538             for bdm in list(bdms):
2539                 if bdm.is_volume and not bdm.volume_id:
2540                     LOG.debug('There are potentially stale BDMs during '
2541                               'delete, refreshing the BlockDeviceMappingList.',
2542                               instance=instance)
2543                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2544                         context, instance.uuid)
2545                     break
2546             try:
2547                 self._delete_instance(context, instance, bdms)
2548             except exception.InstanceNotFound:
2549                 LOG.info("Instance disappeared during terminate",
2550                          instance=instance)
2551             except Exception:
2552                 # As we're trying to delete always go to Error if something
2553                 # goes wrong that _delete_instance can't handle.
2554                 with excutils.save_and_reraise_exception():
2555                     LOG.exception('Setting instance vm_state to ERROR',
2556                                   instance=instance)
2557                     self._set_instance_obj_error_state(context, instance)
2558 
2559         do_terminate_instance(instance, bdms)
2560 
2561     # NOTE(johannes): This is probably better named power_off_instance
2562     # so it matches the driver method, but because of other issues, we
2563     # can't use that name in grizzly.
2564     @wrap_exception()
2565     @reverts_task_state
2566     @wrap_instance_event(prefix='compute')
2567     @wrap_instance_fault
2568     def stop_instance(self, context, instance, clean_shutdown):
2569         """Stopping an instance on this host."""
2570 
2571         @utils.synchronized(instance.uuid)
2572         def do_stop_instance():
2573             current_power_state = self._get_power_state(context, instance)
2574             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2575                       'current task_state: %(task_state)s, current DB '
2576                       'power_state: %(db_power_state)s, current VM '
2577                       'power_state: %(current_power_state)s',
2578                       {'vm_state': instance.vm_state,
2579                        'task_state': instance.task_state,
2580                        'db_power_state': instance.power_state,
2581                        'current_power_state': current_power_state},
2582                       instance_uuid=instance.uuid)
2583 
2584             # NOTE(mriedem): If the instance is already powered off, we are
2585             # possibly tearing down and racing with other operations, so we can
2586             # expect the task_state to be None if something else updates the
2587             # instance and we're not locking it.
2588             expected_task_state = [task_states.POWERING_OFF]
2589             # The list of power states is from _sync_instance_power_state.
2590             if current_power_state in (power_state.NOSTATE,
2591                                        power_state.SHUTDOWN,
2592                                        power_state.CRASHED):
2593                 LOG.info('Instance is already powered off in the '
2594                          'hypervisor when stop is called.',
2595                          instance=instance)
2596                 expected_task_state.append(None)
2597 
2598             self._notify_about_instance_usage(context, instance,
2599                                               "power_off.start")
2600 
2601             compute_utils.notify_about_instance_action(context, instance,
2602                         self.host, action=fields.NotificationAction.POWER_OFF,
2603                         phase=fields.NotificationPhase.START)
2604 
2605             self._power_off_instance(context, instance, clean_shutdown)
2606             instance.power_state = self._get_power_state(context, instance)
2607             instance.vm_state = vm_states.STOPPED
2608             instance.task_state = None
2609             instance.save(expected_task_state=expected_task_state)
2610             self._notify_about_instance_usage(context, instance,
2611                                               "power_off.end")
2612 
2613             compute_utils.notify_about_instance_action(context, instance,
2614                         self.host, action=fields.NotificationAction.POWER_OFF,
2615                         phase=fields.NotificationPhase.END)
2616 
2617         do_stop_instance()
2618 
2619     def _power_on(self, context, instance):
2620         network_info = self.network_api.get_instance_nw_info(context, instance)
2621         block_device_info = self._get_instance_block_device_info(context,
2622                                                                  instance)
2623         self.driver.power_on(context, instance,
2624                              network_info,
2625                              block_device_info)
2626 
2627     def _delete_snapshot_of_shelved_instance(self, context, instance,
2628                                              snapshot_id):
2629         """Delete snapshot of shelved instance."""
2630         try:
2631             self.image_api.delete(context, snapshot_id)
2632         except (exception.ImageNotFound,
2633                 exception.ImageNotAuthorized) as exc:
2634             LOG.warning("Failed to delete snapshot "
2635                         "from shelved instance (%s).",
2636                         exc.format_message(), instance=instance)
2637         except Exception:
2638             LOG.exception("Something wrong happened when trying to "
2639                           "delete snapshot from shelved instance.",
2640                           instance=instance)
2641 
2642     # NOTE(johannes): This is probably better named power_on_instance
2643     # so it matches the driver method, but because of other issues, we
2644     # can't use that name in grizzly.
2645     @wrap_exception()
2646     @reverts_task_state
2647     @wrap_instance_event(prefix='compute')
2648     @wrap_instance_fault
2649     def start_instance(self, context, instance):
2650         """Starting an instance on this host."""
2651         self._notify_about_instance_usage(context, instance, "power_on.start")
2652         compute_utils.notify_about_instance_action(context, instance,
2653             self.host, action=fields.NotificationAction.POWER_ON,
2654             phase=fields.NotificationPhase.START)
2655         self._power_on(context, instance)
2656         instance.power_state = self._get_power_state(context, instance)
2657         instance.vm_state = vm_states.ACTIVE
2658         instance.task_state = None
2659 
2660         # Delete an image(VM snapshot) for a shelved instance
2661         snapshot_id = instance.system_metadata.get('shelved_image_id')
2662         if snapshot_id:
2663             self._delete_snapshot_of_shelved_instance(context, instance,
2664                                                       snapshot_id)
2665 
2666         # Delete system_metadata for a shelved instance
2667         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2668 
2669         instance.save(expected_task_state=task_states.POWERING_ON)
2670         self._notify_about_instance_usage(context, instance, "power_on.end")
2671         compute_utils.notify_about_instance_action(context, instance,
2672             self.host, action=fields.NotificationAction.POWER_ON,
2673             phase=fields.NotificationPhase.END)
2674 
2675     @messaging.expected_exceptions(NotImplementedError,
2676                                    exception.TriggerCrashDumpNotSupported,
2677                                    exception.InstanceNotRunning)
2678     @wrap_exception()
2679     @wrap_instance_event(prefix='compute')
2680     @wrap_instance_fault
2681     def trigger_crash_dump(self, context, instance):
2682         """Trigger crash dump in an instance."""
2683 
2684         self._notify_about_instance_usage(context, instance,
2685                                           "trigger_crash_dump.start")
2686         compute_utils.notify_about_instance_action(context, instance,
2687                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2688                 phase=fields.NotificationPhase.START)
2689 
2690         # This method does not change task_state and power_state because the
2691         # effect of a trigger depends on user's configuration.
2692         self.driver.trigger_crash_dump(instance)
2693 
2694         self._notify_about_instance_usage(context, instance,
2695                                           "trigger_crash_dump.end")
2696         compute_utils.notify_about_instance_action(context, instance,
2697                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2698                 phase=fields.NotificationPhase.END)
2699 
2700     @wrap_exception()
2701     @reverts_task_state
2702     @wrap_instance_event(prefix='compute')
2703     @wrap_instance_fault
2704     def soft_delete_instance(self, context, instance, reservations):
2705         """Soft delete an instance on this host."""
2706         with compute_utils.notify_about_instance_delete(
2707                 self.notifier, context, instance, 'soft_delete'):
2708             compute_utils.notify_about_instance_action(context, instance,
2709                 self.host, action=fields.NotificationAction.SOFT_DELETE,
2710                 phase=fields.NotificationPhase.START)
2711             try:
2712                 self.driver.soft_delete(instance)
2713             except NotImplementedError:
2714                 # Fallback to just powering off the instance if the
2715                 # hypervisor doesn't implement the soft_delete method
2716                 self.driver.power_off(instance)
2717             instance.power_state = self._get_power_state(context, instance)
2718             instance.vm_state = vm_states.SOFT_DELETED
2719             instance.task_state = None
2720             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2721             compute_utils.notify_about_instance_action(
2722                 context, instance, self.host,
2723                 action=fields.NotificationAction.SOFT_DELETE,
2724                 phase=fields.NotificationPhase.END)
2725 
2726     @wrap_exception()
2727     @reverts_task_state
2728     @wrap_instance_event(prefix='compute')
2729     @wrap_instance_fault
2730     def restore_instance(self, context, instance):
2731         """Restore a soft-deleted instance on this host."""
2732         self._notify_about_instance_usage(context, instance, "restore.start")
2733         compute_utils.notify_about_instance_action(context, instance,
2734             self.host, action=fields.NotificationAction.RESTORE,
2735             phase=fields.NotificationPhase.START)
2736         try:
2737             self.driver.restore(instance)
2738         except NotImplementedError:
2739             # Fallback to just powering on the instance if the hypervisor
2740             # doesn't implement the restore method
2741             self._power_on(context, instance)
2742         instance.power_state = self._get_power_state(context, instance)
2743         instance.vm_state = vm_states.ACTIVE
2744         instance.task_state = None
2745         instance.save(expected_task_state=task_states.RESTORING)
2746         self._notify_about_instance_usage(context, instance, "restore.end")
2747         compute_utils.notify_about_instance_action(context, instance,
2748             self.host, action=fields.NotificationAction.RESTORE,
2749             phase=fields.NotificationPhase.END)
2750 
2751     @staticmethod
2752     def _set_migration_status(migration, status):
2753         """Set the status, and guard against a None being passed in.
2754 
2755         This is useful as some of the compute RPC calls will not pass
2756         a migration object in older versions. The check can be removed when
2757         we move past 4.x major version of the RPC API.
2758         """
2759         if migration:
2760             migration.status = status
2761             migration.save()
2762 
2763     def _rebuild_default_impl(self, context, instance, image_meta,
2764                               injected_files, admin_password, allocations,
2765                               bdms, detach_block_devices, attach_block_devices,
2766                               network_info=None,
2767                               recreate=False, block_device_info=None,
2768                               preserve_ephemeral=False):
2769         if preserve_ephemeral:
2770             # The default code path does not support preserving ephemeral
2771             # partitions.
2772             raise exception.PreserveEphemeralNotSupported()
2773 
2774         if recreate:
2775             detach_block_devices(context, bdms)
2776         else:
2777             self._power_off_instance(context, instance, clean_shutdown=True)
2778             detach_block_devices(context, bdms)
2779             self.driver.destroy(context, instance,
2780                                 network_info=network_info,
2781                                 block_device_info=block_device_info)
2782 
2783         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2784         instance.save(expected_task_state=[task_states.REBUILDING])
2785 
2786         new_block_device_info = attach_block_devices(context, instance, bdms)
2787 
2788         instance.task_state = task_states.REBUILD_SPAWNING
2789         instance.save(
2790             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2791 
2792         with instance.mutated_migration_context():
2793             self.driver.spawn(context, instance, image_meta, injected_files,
2794                               admin_password, allocations,
2795                               network_info=network_info,
2796                               block_device_info=new_block_device_info)
2797 
2798     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
2799         self._notify_about_instance_usage(context, instance,
2800                                           'rebuild.error', fault=error)
2801         compute_utils.notify_about_instance_action(
2802             context, instance, self.host,
2803             action=fields.NotificationAction.REBUILD,
2804             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms)
2805 
2806     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2807     @wrap_exception()
2808     @reverts_task_state
2809     @wrap_instance_event(prefix='compute')
2810     @wrap_instance_fault
2811     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2812                          injected_files, new_pass, orig_sys_metadata,
2813                          bdms, recreate, on_shared_storage=None,
2814                          preserve_ephemeral=False, migration=None,
2815                          scheduled_node=None, limits=None):
2816         """Destroy and re-make this instance.
2817 
2818         A 'rebuild' effectively purges all existing data from the system and
2819         remakes the VM with given 'metadata' and 'personalities'.
2820 
2821         :param context: `nova.RequestContext` object
2822         :param instance: Instance object
2823         :param orig_image_ref: Original image_ref before rebuild
2824         :param image_ref: New image_ref for rebuild
2825         :param injected_files: Files to inject
2826         :param new_pass: password to set on rebuilt instance
2827         :param orig_sys_metadata: instance system metadata from pre-rebuild
2828         :param bdms: block-device-mappings to use for rebuild
2829         :param recreate: True if the instance is being recreated (e.g. the
2830             hypervisor it was on failed) - cleanup of old state will be
2831             skipped.
2832         :param on_shared_storage: True if instance files on shared storage.
2833                                   If not provided then information from the
2834                                   driver will be used to decide if the instance
2835                                   files are available or not on the target host
2836         :param preserve_ephemeral: True if the default ephemeral storage
2837                                    partition must be preserved on rebuild
2838         :param migration: a Migration object if one was created for this
2839                           rebuild operation (if it's a part of evacuate)
2840         :param scheduled_node: A node of the host chosen by the scheduler. If a
2841                                host was specified by the user, this will be
2842                                None
2843         :param limits: Overcommit limits set by the scheduler. If a host was
2844                        specified by the user, this will be None
2845         """
2846         context = context.elevated()
2847 
2848         LOG.info("Rebuilding instance", instance=instance)
2849 
2850         # NOTE(gyee): there are three possible scenarios.
2851         #
2852         #   1. instance is being rebuilt on the same node. In this case,
2853         #      recreate should be False and scheduled_node should be None.
2854         #   2. instance is being rebuilt on a node chosen by the
2855         #      scheduler (i.e. evacuate). In this case, scheduled_node should
2856         #      be specified and recreate should be True.
2857         #   3. instance is being rebuilt on a node chosen by the user. (i.e.
2858         #      force evacuate). In this case, scheduled_node is not specified
2859         #      and recreate is set to True.
2860         #
2861         # For scenarios #2 and #3, we must do rebuild claim as server is
2862         # being evacuated to a different node.
2863         rt = self._get_resource_tracker()
2864         if recreate or scheduled_node is not None:
2865             rebuild_claim = rt.rebuild_claim
2866         else:
2867             rebuild_claim = claims.NopClaim
2868 
2869         image_meta = {}
2870         if image_ref:
2871             image_meta = self.image_api.get(context, image_ref)
2872 
2873         # NOTE(mriedem): On a recreate (evacuate), we need to update
2874         # the instance's host and node properties to reflect it's
2875         # destination node for the recreate.
2876         if not scheduled_node:
2877             if recreate:
2878                 try:
2879                     compute_node = self._get_compute_info(context, self.host)
2880                     scheduled_node = compute_node.hypervisor_hostname
2881                 except exception.ComputeHostNotFound:
2882                     LOG.exception('Failed to get compute_info for %s',
2883                                   self.host)
2884             else:
2885                 scheduled_node = instance.node
2886 
2887         with self._error_out_instance_on_exception(context, instance):
2888             try:
2889                 claim_ctxt = rebuild_claim(
2890                     context, instance, scheduled_node,
2891                     limits=limits, image_meta=image_meta,
2892                     migration=migration)
2893                 self._do_rebuild_instance_with_claim(
2894                     claim_ctxt, context, instance, orig_image_ref,
2895                     image_ref, injected_files, new_pass, orig_sys_metadata,
2896                     bdms, recreate, on_shared_storage, preserve_ephemeral,
2897                     migration)
2898             except exception.ComputeResourcesUnavailable as e:
2899                 LOG.debug("Could not rebuild instance on this host, not "
2900                           "enough resources available.", instance=instance)
2901 
2902                 # NOTE(ndipanov): We just abort the build for now and leave a
2903                 # migration record for potential cleanup later
2904                 self._set_migration_status(migration, 'failed')
2905                 # Since the claim failed, we need to remove the allocation
2906                 # created against the destination node. Note that we can only
2907                 # get here when evacuating to a destination node. Rebuilding
2908                 # on the same host (not evacuate) uses the NopClaim which will
2909                 # not raise ComputeResourcesUnavailable.
2910                 rt.delete_allocation_for_evacuated_instance(
2911                     instance, scheduled_node, node_type='destination')
2912                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2913                 raise exception.BuildAbortException(
2914                     instance_uuid=instance.uuid, reason=e.format_message())
2915             except (exception.InstanceNotFound,
2916                     exception.UnexpectedDeletingTaskStateError) as e:
2917                 LOG.debug('Instance was deleted while rebuilding',
2918                           instance=instance)
2919                 self._set_migration_status(migration, 'failed')
2920                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2921             except Exception as e:
2922                 self._set_migration_status(migration, 'failed')
2923                 if recreate or scheduled_node is not None:
2924                     rt.delete_allocation_for_evacuated_instance(
2925                         instance, scheduled_node, node_type='destination')
2926                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2927                 raise
2928             else:
2929                 instance.apply_migration_context()
2930                 # NOTE (ndipanov): This save will now update the host and node
2931                 # attributes making sure that next RT pass is consistent since
2932                 # it will be based on the instance and not the migration DB
2933                 # entry.
2934                 instance.host = self.host
2935                 instance.node = scheduled_node
2936                 instance.save()
2937                 instance.drop_migration_context()
2938 
2939                 # NOTE (ndipanov): Mark the migration as done only after we
2940                 # mark the instance as belonging to this host.
2941                 self._set_migration_status(migration, 'done')
2942 
2943     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2944         """Helper to avoid deep nesting in the top-level method."""
2945 
2946         with claim_context:
2947             self._do_rebuild_instance(*args, **kwargs)
2948 
2949     @staticmethod
2950     def _get_image_name(image_meta):
2951         if image_meta.obj_attr_is_set("name"):
2952             return image_meta.name
2953         else:
2954             return ''
2955 
2956     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2957                              image_ref, injected_files, new_pass,
2958                              orig_sys_metadata, bdms, recreate,
2959                              on_shared_storage, preserve_ephemeral,
2960                              migration):
2961         orig_vm_state = instance.vm_state
2962 
2963         if recreate:
2964             if not self.driver.capabilities["supports_recreate"]:
2965                 raise exception.InstanceRecreateNotSupported
2966 
2967             self._check_instance_exists(context, instance)
2968 
2969             if on_shared_storage is None:
2970                 LOG.debug('on_shared_storage is not provided, using driver'
2971                             'information to decide if the instance needs to'
2972                             'be recreated')
2973                 on_shared_storage = self.driver.instance_on_disk(instance)
2974 
2975             elif (on_shared_storage !=
2976                     self.driver.instance_on_disk(instance)):
2977                 # To cover case when admin expects that instance files are
2978                 # on shared storage, but not accessible and vice versa
2979                 raise exception.InvalidSharedStorage(
2980                         _("Invalid state of instance files on shared"
2981                             " storage"))
2982 
2983             if on_shared_storage:
2984                 LOG.info('disk on shared storage, recreating using'
2985                          ' existing disk')
2986             else:
2987                 image_ref = orig_image_ref = instance.image_ref
2988                 LOG.info("disk not on shared storage, rebuilding from:"
2989                          " '%s'", str(image_ref))
2990 
2991         if image_ref:
2992             image_meta = objects.ImageMeta.from_image_ref(
2993                 context, self.image_api, image_ref)
2994         else:
2995             image_meta = instance.image_meta
2996 
2997         # This instance.exists message should contain the original
2998         # image_ref, not the new one.  Since the DB has been updated
2999         # to point to the new one... we have to override it.
3000         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
3001                                                                context)
3002         extra_usage_info = {'image_ref_url': orig_image_ref_url}
3003         compute_utils.notify_usage_exists(
3004                 self.notifier, context, instance,
3005                 current_period=True, system_metadata=orig_sys_metadata,
3006                 extra_usage_info=extra_usage_info)
3007 
3008         # This message should contain the new image_ref
3009         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
3010         self._notify_about_instance_usage(context, instance,
3011                 "rebuild.start", extra_usage_info=extra_usage_info)
3012         # NOTE: image_name is not included in the versioned notification
3013         # because we already provide the image_uuid in the notification
3014         # payload and the image details can be looked up via the uuid.
3015         compute_utils.notify_about_instance_action(
3016             context, instance, self.host,
3017             action=fields.NotificationAction.REBUILD,
3018             phase=fields.NotificationPhase.START,
3019             bdms=bdms)
3020 
3021         instance.power_state = self._get_power_state(context, instance)
3022         instance.task_state = task_states.REBUILDING
3023         instance.save(expected_task_state=[task_states.REBUILDING])
3024 
3025         if recreate:
3026             self.network_api.setup_networks_on_host(
3027                     context, instance, self.host)
3028             # For nova-network this is needed to move floating IPs
3029             # For neutron this updates the host in the port binding
3030             # TODO(cfriesen): this network_api call and the one above
3031             # are so similar, we should really try to unify them.
3032             self.network_api.setup_instance_network_on_host(
3033                     context, instance, self.host, migration)
3034 
3035         allocations = self.reportclient.get_allocations_for_consumer(
3036             instance.uuid)
3037 
3038         network_info = instance.get_network_info()
3039         if bdms is None:
3040             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3041                     context, instance.uuid)
3042 
3043         block_device_info = \
3044             self._get_instance_block_device_info(
3045                     context, instance, bdms=bdms)
3046 
3047         def detach_block_devices(context, bdms):
3048             for bdm in bdms:
3049                 if bdm.is_volume:
3050                     # NOTE (ildikov): Having the attachment_id set in the BDM
3051                     # means that it's the new Cinder attach/detach flow
3052                     # (available from v3.44). In that case we explicitly
3053                     # attach and detach the volumes through attachment level
3054                     # operations. In this scenario _detach_volume will delete
3055                     # the existing attachment which would make the volume
3056                     # status change to 'in-use' if we don't pre-create another
3057                     # empty attachment before deleting the old one.
3058                     attachment_id = None
3059                     if bdm.attachment_id:
3060                         attachment_id = self.volume_api.attachment_create(
3061                             context, bdm['volume_id'], instance.uuid)['id']
3062                     self._detach_volume(context, bdm, instance,
3063                                         destroy_bdm=False)
3064                     if attachment_id:
3065                         bdm.attachment_id = attachment_id
3066                         bdm.save()
3067 
3068         files = self._decode_files(injected_files)
3069 
3070         kwargs = dict(
3071             context=context,
3072             instance=instance,
3073             image_meta=image_meta,
3074             injected_files=files,
3075             admin_password=new_pass,
3076             allocations=allocations,
3077             bdms=bdms,
3078             detach_block_devices=detach_block_devices,
3079             attach_block_devices=self._prep_block_device,
3080             block_device_info=block_device_info,
3081             network_info=network_info,
3082             preserve_ephemeral=preserve_ephemeral,
3083             recreate=recreate)
3084         try:
3085             with instance.mutated_migration_context():
3086                 self.driver.rebuild(**kwargs)
3087         except NotImplementedError:
3088             # NOTE(rpodolyaka): driver doesn't provide specialized version
3089             # of rebuild, fall back to the default implementation
3090             self._rebuild_default_impl(**kwargs)
3091         self._update_instance_after_spawn(context, instance)
3092         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3093 
3094         if orig_vm_state == vm_states.STOPPED:
3095             LOG.info("bringing vm to original state: '%s'",
3096                      orig_vm_state, instance=instance)
3097             instance.vm_state = vm_states.ACTIVE
3098             instance.task_state = task_states.POWERING_OFF
3099             instance.progress = 0
3100             instance.save()
3101             self.stop_instance(context, instance, False)
3102         self._update_scheduler_instance_info(context, instance)
3103         self._notify_about_instance_usage(
3104                 context, instance, "rebuild.end",
3105                 network_info=network_info,
3106                 extra_usage_info=extra_usage_info)
3107         compute_utils.notify_about_instance_action(
3108             context, instance, self.host,
3109             action=fields.NotificationAction.REBUILD,
3110             phase=fields.NotificationPhase.END,
3111             bdms=bdms)
3112 
3113     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3114                                      block_device_info):
3115         """Handle cases where the virt-layer had to detach non-working volumes
3116         in order to complete an operation.
3117         """
3118         for bdm in block_device_info['block_device_mapping']:
3119             if bdm.get('mount_device') in bad_devices:
3120                 try:
3121                     volume_id = bdm['connection_info']['data']['volume_id']
3122                 except KeyError:
3123                     continue
3124 
3125                 # NOTE(sirp): ideally we'd just call
3126                 # `compute_api.detach_volume` here but since that hits the
3127                 # DB directly, that's off limits from within the
3128                 # compute-manager.
3129                 #
3130                 # API-detach
3131                 LOG.info("Detaching from volume api: %s", volume_id)
3132                 self.volume_api.begin_detaching(context, volume_id)
3133 
3134                 # Manager-detach
3135                 self.detach_volume(context, volume_id, instance)
3136 
3137     @wrap_exception()
3138     @reverts_task_state
3139     @wrap_instance_event(prefix='compute')
3140     @wrap_instance_fault
3141     def reboot_instance(self, context, instance, block_device_info,
3142                         reboot_type):
3143         """Reboot an instance on this host."""
3144         # acknowledge the request made it to the manager
3145         if reboot_type == "SOFT":
3146             instance.task_state = task_states.REBOOT_PENDING
3147             expected_states = task_states.soft_reboot_states
3148         else:
3149             instance.task_state = task_states.REBOOT_PENDING_HARD
3150             expected_states = task_states.hard_reboot_states
3151 
3152         context = context.elevated()
3153         LOG.info("Rebooting instance", instance=instance)
3154 
3155         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3156             context, instance.uuid)
3157         block_device_info = self._get_instance_block_device_info(
3158             context, instance, bdms=bdms)
3159 
3160         network_info = self.network_api.get_instance_nw_info(context, instance)
3161 
3162         self._notify_about_instance_usage(context, instance, "reboot.start")
3163         compute_utils.notify_about_instance_action(
3164             context, instance, self.host,
3165             action=fields.NotificationAction.REBOOT,
3166             phase=fields.NotificationPhase.START,
3167             bdms=bdms
3168         )
3169 
3170         instance.power_state = self._get_power_state(context, instance)
3171         instance.save(expected_task_state=expected_states)
3172 
3173         if instance.power_state != power_state.RUNNING:
3174             state = instance.power_state
3175             running = power_state.RUNNING
3176             LOG.warning('trying to reboot a non-running instance:'
3177                         ' (state: %(state)s expected: %(running)s)',
3178                         {'state': state, 'running': running},
3179                         instance=instance)
3180 
3181         def bad_volumes_callback(bad_devices):
3182             self._handle_bad_volumes_detached(
3183                     context, instance, bad_devices, block_device_info)
3184 
3185         try:
3186             # Don't change it out of rescue mode
3187             if instance.vm_state == vm_states.RESCUED:
3188                 new_vm_state = vm_states.RESCUED
3189             else:
3190                 new_vm_state = vm_states.ACTIVE
3191             new_power_state = None
3192             if reboot_type == "SOFT":
3193                 instance.task_state = task_states.REBOOT_STARTED
3194                 expected_state = task_states.REBOOT_PENDING
3195             else:
3196                 instance.task_state = task_states.REBOOT_STARTED_HARD
3197                 expected_state = task_states.REBOOT_PENDING_HARD
3198             instance.save(expected_task_state=expected_state)
3199             self.driver.reboot(context, instance,
3200                                network_info,
3201                                reboot_type,
3202                                block_device_info=block_device_info,
3203                                bad_volumes_callback=bad_volumes_callback)
3204 
3205         except Exception as error:
3206             with excutils.save_and_reraise_exception() as ctxt:
3207                 exc_info = sys.exc_info()
3208                 # if the reboot failed but the VM is running don't
3209                 # put it into an error state
3210                 new_power_state = self._get_power_state(context, instance)
3211                 if new_power_state == power_state.RUNNING:
3212                     LOG.warning('Reboot failed but instance is running',
3213                                 instance=instance)
3214                     compute_utils.add_instance_fault_from_exc(context,
3215                             instance, error, exc_info)
3216                     self._notify_about_instance_usage(context, instance,
3217                             'reboot.error', fault=error)
3218                     compute_utils.notify_about_instance_action(
3219                         context, instance, self.host,
3220                         action=fields.NotificationAction.REBOOT,
3221                         phase=fields.NotificationPhase.ERROR,
3222                         exception=error, bdms=bdms
3223                     )
3224                     ctxt.reraise = False
3225                 else:
3226                     LOG.error('Cannot reboot instance: %s', error,
3227                               instance=instance)
3228                     self._set_instance_obj_error_state(context, instance)
3229 
3230         if not new_power_state:
3231             new_power_state = self._get_power_state(context, instance)
3232         try:
3233             instance.power_state = new_power_state
3234             instance.vm_state = new_vm_state
3235             instance.task_state = None
3236             instance.save()
3237         except exception.InstanceNotFound:
3238             LOG.warning("Instance disappeared during reboot",
3239                         instance=instance)
3240 
3241         self._notify_about_instance_usage(context, instance, "reboot.end")
3242         compute_utils.notify_about_instance_action(
3243             context, instance, self.host,
3244             action=fields.NotificationAction.REBOOT,
3245             phase=fields.NotificationPhase.END,
3246             bdms=bdms
3247         )
3248 
3249     @delete_image_on_error
3250     def _do_snapshot_instance(self, context, image_id, instance):
3251         self._snapshot_instance(context, image_id, instance,
3252                                 task_states.IMAGE_BACKUP)
3253 
3254     @wrap_exception()
3255     @reverts_task_state
3256     @wrap_instance_event(prefix='compute')
3257     @wrap_instance_fault
3258     def backup_instance(self, context, image_id, instance, backup_type,
3259                         rotation):
3260         """Backup an instance on this host.
3261 
3262         :param backup_type: daily | weekly
3263         :param rotation: int representing how many backups to keep around
3264         """
3265         self._do_snapshot_instance(context, image_id, instance)
3266         self._rotate_backups(context, instance, backup_type, rotation)
3267 
3268     @wrap_exception()
3269     @reverts_task_state
3270     @wrap_instance_event(prefix='compute')
3271     @wrap_instance_fault
3272     @delete_image_on_error
3273     def snapshot_instance(self, context, image_id, instance):
3274         """Snapshot an instance on this host.
3275 
3276         :param context: security context
3277         :param image_id: glance.db.sqlalchemy.models.Image.Id
3278         :param instance: a nova.objects.instance.Instance object
3279         """
3280         # NOTE(dave-mcnally) the task state will already be set by the api
3281         # but if the compute manager has crashed/been restarted prior to the
3282         # request getting here the task state may have been cleared so we set
3283         # it again and things continue normally
3284         try:
3285             instance.task_state = task_states.IMAGE_SNAPSHOT
3286             instance.save(
3287                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3288         except exception.InstanceNotFound:
3289             # possibility instance no longer exists, no point in continuing
3290             LOG.debug("Instance not found, could not set state %s "
3291                       "for instance.",
3292                       task_states.IMAGE_SNAPSHOT, instance=instance)
3293             return
3294 
3295         except exception.UnexpectedDeletingTaskStateError:
3296             LOG.debug("Instance being deleted, snapshot cannot continue",
3297                       instance=instance)
3298             return
3299 
3300         self._snapshot_instance(context, image_id, instance,
3301                                 task_states.IMAGE_SNAPSHOT)
3302 
3303     def _snapshot_instance(self, context, image_id, instance,
3304                            expected_task_state):
3305         context = context.elevated()
3306 
3307         instance.power_state = self._get_power_state(context, instance)
3308         try:
3309             instance.save()
3310 
3311             LOG.info('instance snapshotting', instance=instance)
3312 
3313             if instance.power_state != power_state.RUNNING:
3314                 state = instance.power_state
3315                 running = power_state.RUNNING
3316                 LOG.warning('trying to snapshot a non-running instance: '
3317                             '(state: %(state)s expected: %(running)s)',
3318                             {'state': state, 'running': running},
3319                             instance=instance)
3320 
3321             self._notify_about_instance_usage(
3322                 context, instance, "snapshot.start")
3323             compute_utils.notify_about_instance_snapshot(context, instance,
3324                 self.host, phase=fields.NotificationPhase.START,
3325                 snapshot_image_id=image_id)
3326 
3327             def update_task_state(task_state,
3328                                   expected_state=expected_task_state):
3329                 instance.task_state = task_state
3330                 instance.save(expected_task_state=expected_state)
3331 
3332             self.driver.snapshot(context, instance, image_id,
3333                                  update_task_state)
3334 
3335             instance.task_state = None
3336             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3337 
3338             self._notify_about_instance_usage(context, instance,
3339                                               "snapshot.end")
3340             compute_utils.notify_about_instance_snapshot(context, instance,
3341                 self.host, phase=fields.NotificationPhase.END,
3342                 snapshot_image_id=image_id)
3343         except (exception.InstanceNotFound,
3344                 exception.UnexpectedDeletingTaskStateError):
3345             # the instance got deleted during the snapshot
3346             # Quickly bail out of here
3347             msg = 'Instance disappeared during snapshot'
3348             LOG.debug(msg, instance=instance)
3349             try:
3350                 image = self.image_api.get(context, image_id)
3351                 if image['status'] != 'active':
3352                     self.image_api.delete(context, image_id)
3353             except Exception:
3354                 LOG.warning("Error while trying to clean up image %s",
3355                             image_id, instance=instance)
3356         except exception.ImageNotFound:
3357             instance.task_state = None
3358             instance.save()
3359             LOG.warning("Image not found during snapshot", instance=instance)
3360 
3361     def _post_interrupted_snapshot_cleanup(self, context, instance):
3362         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3363 
3364     @messaging.expected_exceptions(NotImplementedError)
3365     @wrap_exception()
3366     def volume_snapshot_create(self, context, instance, volume_id,
3367                                create_info):
3368         self.driver.volume_snapshot_create(context, instance, volume_id,
3369                                            create_info)
3370 
3371     @messaging.expected_exceptions(NotImplementedError)
3372     @wrap_exception()
3373     def volume_snapshot_delete(self, context, instance, volume_id,
3374                                snapshot_id, delete_info):
3375         self.driver.volume_snapshot_delete(context, instance, volume_id,
3376                                            snapshot_id, delete_info)
3377 
3378     @wrap_instance_fault
3379     def _rotate_backups(self, context, instance, backup_type, rotation):
3380         """Delete excess backups associated to an instance.
3381 
3382         Instances are allowed a fixed number of backups (the rotation number);
3383         this method deletes the oldest backups that exceed the rotation
3384         threshold.
3385 
3386         :param context: security context
3387         :param instance: Instance dict
3388         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3389         :param rotation: int representing how many backups to keep around;
3390             None if rotation shouldn't be used (as in the case of snapshots)
3391         """
3392         filters = {'property-image_type': 'backup',
3393                    'property-backup_type': backup_type,
3394                    'property-instance_uuid': instance.uuid}
3395 
3396         images = self.image_api.get_all(context, filters=filters,
3397                                         sort_key='created_at', sort_dir='desc')
3398         num_images = len(images)
3399         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3400                   {'num_images': num_images, 'rotation': rotation},
3401                   instance=instance)
3402 
3403         if num_images > rotation:
3404             # NOTE(sirp): this deletes all backups that exceed the rotation
3405             # limit
3406             excess = len(images) - rotation
3407             LOG.debug("Rotating out %d backups", excess,
3408                       instance=instance)
3409             for i in range(excess):
3410                 image = images.pop()
3411                 image_id = image['id']
3412                 LOG.debug("Deleting image %s", image_id,
3413                           instance=instance)
3414                 try:
3415                     self.image_api.delete(context, image_id)
3416                 except exception.ImageNotFound:
3417                     LOG.info("Failed to find image %(image_id)s to "
3418                              "delete", {'image_id': image_id},
3419                              instance=instance)
3420                 except (exception.ImageDeleteConflict, Exception) as exc:
3421                     LOG.info("Failed to delete image %(image_id)s during "
3422                              "deleting excess backups. "
3423                              "Continuing for next image.. %(exc)s",
3424                              {'image_id': image_id, 'exc': exc},
3425                              instance=instance)
3426 
3427     @wrap_exception()
3428     @reverts_task_state
3429     @wrap_instance_event(prefix='compute')
3430     @wrap_instance_fault
3431     def set_admin_password(self, context, instance, new_pass):
3432         """Set the root/admin password for an instance on this host.
3433 
3434         This is generally only called by API password resets after an
3435         image has been built.
3436 
3437         @param context: Nova auth context.
3438         @param instance: Nova instance object.
3439         @param new_pass: The admin password for the instance.
3440         """
3441 
3442         context = context.elevated()
3443         if new_pass is None:
3444             # Generate a random password
3445             new_pass = utils.generate_password()
3446 
3447         current_power_state = self._get_power_state(context, instance)
3448         expected_state = power_state.RUNNING
3449 
3450         if current_power_state != expected_state:
3451             instance.task_state = None
3452             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3453             _msg = _('instance %s is not running') % instance.uuid
3454             raise exception.InstancePasswordSetFailed(
3455                 instance=instance.uuid, reason=_msg)
3456 
3457         try:
3458             self.driver.set_admin_password(instance, new_pass)
3459             LOG.info("Admin password set", instance=instance)
3460             instance.task_state = None
3461             instance.save(
3462                 expected_task_state=task_states.UPDATING_PASSWORD)
3463         except exception.InstanceAgentNotEnabled:
3464             with excutils.save_and_reraise_exception():
3465                 LOG.debug('Guest agent is not enabled for the instance.',
3466                           instance=instance)
3467                 instance.task_state = None
3468                 instance.save(
3469                     expected_task_state=task_states.UPDATING_PASSWORD)
3470         except exception.SetAdminPasswdNotSupported:
3471             with excutils.save_and_reraise_exception():
3472                 LOG.info('set_admin_password is not supported '
3473                          'by this driver or guest instance.',
3474                          instance=instance)
3475                 instance.task_state = None
3476                 instance.save(
3477                     expected_task_state=task_states.UPDATING_PASSWORD)
3478         except NotImplementedError:
3479             LOG.warning('set_admin_password is not implemented '
3480                         'by this driver or guest instance.',
3481                         instance=instance)
3482             instance.task_state = None
3483             instance.save(
3484                 expected_task_state=task_states.UPDATING_PASSWORD)
3485             raise NotImplementedError(_('set_admin_password is not '
3486                                         'implemented by this driver or guest '
3487                                         'instance.'))
3488         except exception.UnexpectedTaskStateError:
3489             # interrupted by another (most likely delete) task
3490             # do not retry
3491             raise
3492         except Exception:
3493             # Catch all here because this could be anything.
3494             LOG.exception('set_admin_password failed', instance=instance)
3495             self._set_instance_obj_error_state(context, instance)
3496             # We create a new exception here so that we won't
3497             # potentially reveal password information to the
3498             # API caller.  The real exception is logged above
3499             _msg = _('error setting admin password')
3500             raise exception.InstancePasswordSetFailed(
3501                 instance=instance.uuid, reason=_msg)
3502 
3503     @wrap_exception()
3504     @reverts_task_state
3505     @wrap_instance_fault
3506     def inject_file(self, context, path, file_contents, instance):
3507         """Write a file to the specified path in an instance on this host."""
3508         # NOTE(russellb) Remove this method, as well as the underlying virt
3509         # driver methods, when the compute rpc interface is bumped to 4.x
3510         # as it is no longer used.
3511         context = context.elevated()
3512         current_power_state = self._get_power_state(context, instance)
3513         expected_state = power_state.RUNNING
3514         if current_power_state != expected_state:
3515             LOG.warning('trying to inject a file into a non-running '
3516                         '(state: %(current_state)s expected: '
3517                         '%(expected_state)s)',
3518                         {'current_state': current_power_state,
3519                          'expected_state': expected_state},
3520                         instance=instance)
3521         LOG.info('injecting file to %s', path, instance=instance)
3522         self.driver.inject_file(instance, path, file_contents)
3523 
3524     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3525         """Determine what image should be used to boot the rescue VM."""
3526         # 1. If rescue_image_ref is passed in, use that for rescue.
3527         # 2. Else, use the base image associated with instance's current image.
3528         #       The idea here is to provide the customer with a rescue
3529         #       environment which they are familiar with.
3530         #       So, if they built their instance off of a Debian image,
3531         #       their rescue VM will also be Debian.
3532         # 3. As a last resort, use instance's current image.
3533         if not rescue_image_ref:
3534             system_meta = utils.instance_sys_meta(instance)
3535             rescue_image_ref = system_meta.get('image_base_image_ref')
3536 
3537         if not rescue_image_ref:
3538             LOG.warning('Unable to find a different image to use for '
3539                         'rescue VM, using instance\'s current image',
3540                         instance=instance)
3541             rescue_image_ref = instance.image_ref
3542 
3543         return objects.ImageMeta.from_image_ref(
3544             context, self.image_api, rescue_image_ref)
3545 
3546     @wrap_exception()
3547     @reverts_task_state
3548     @wrap_instance_event(prefix='compute')
3549     @wrap_instance_fault
3550     def rescue_instance(self, context, instance, rescue_password,
3551                         rescue_image_ref, clean_shutdown):
3552         context = context.elevated()
3553         LOG.info('Rescuing', instance=instance)
3554 
3555         admin_password = (rescue_password if rescue_password else
3556                       utils.generate_password())
3557 
3558         network_info = self.network_api.get_instance_nw_info(context, instance)
3559 
3560         rescue_image_meta = self._get_rescue_image(context, instance,
3561                                                    rescue_image_ref)
3562 
3563         extra_usage_info = {'rescue_image_name':
3564                             self._get_image_name(rescue_image_meta)}
3565         self._notify_about_instance_usage(context, instance,
3566                 "rescue.start", extra_usage_info=extra_usage_info,
3567                 network_info=network_info)
3568         compute_utils.notify_about_instance_rescue_action(
3569             context, instance, self.host, rescue_image_ref,
3570             action=fields.NotificationAction.RESCUE,
3571             phase=fields.NotificationPhase.START)
3572 
3573         try:
3574             self._power_off_instance(context, instance, clean_shutdown)
3575 
3576             self.driver.rescue(context, instance,
3577                                network_info,
3578                                rescue_image_meta, admin_password)
3579         except Exception as e:
3580             LOG.exception("Error trying to Rescue Instance",
3581                           instance=instance)
3582             self._set_instance_obj_error_state(context, instance)
3583             raise exception.InstanceNotRescuable(
3584                 instance_id=instance.uuid,
3585                 reason=_("Driver Error: %s") % e)
3586 
3587         compute_utils.notify_usage_exists(self.notifier, context, instance,
3588                                           current_period=True)
3589 
3590         instance.vm_state = vm_states.RESCUED
3591         instance.task_state = None
3592         instance.power_state = self._get_power_state(context, instance)
3593         instance.launched_at = timeutils.utcnow()
3594         instance.save(expected_task_state=task_states.RESCUING)
3595 
3596         self._notify_about_instance_usage(context, instance,
3597                 "rescue.end", extra_usage_info=extra_usage_info,
3598                 network_info=network_info)
3599         compute_utils.notify_about_instance_rescue_action(
3600             context, instance, self.host, rescue_image_ref,
3601             action=fields.NotificationAction.RESCUE,
3602             phase=fields.NotificationPhase.END)
3603 
3604     @wrap_exception()
3605     @reverts_task_state
3606     @wrap_instance_event(prefix='compute')
3607     @wrap_instance_fault
3608     def unrescue_instance(self, context, instance):
3609         context = context.elevated()
3610         LOG.info('Unrescuing', instance=instance)
3611 
3612         network_info = self.network_api.get_instance_nw_info(context, instance)
3613         self._notify_about_instance_usage(context, instance,
3614                 "unrescue.start", network_info=network_info)
3615         compute_utils.notify_about_instance_action(context, instance,
3616             self.host, action=fields.NotificationAction.UNRESCUE,
3617             phase=fields.NotificationPhase.START)
3618 
3619         with self._error_out_instance_on_exception(context, instance):
3620             self.driver.unrescue(instance,
3621                                  network_info)
3622 
3623         instance.vm_state = vm_states.ACTIVE
3624         instance.task_state = None
3625         instance.power_state = self._get_power_state(context, instance)
3626         instance.save(expected_task_state=task_states.UNRESCUING)
3627 
3628         self._notify_about_instance_usage(context,
3629                                           instance,
3630                                           "unrescue.end",
3631                                           network_info=network_info)
3632         compute_utils.notify_about_instance_action(context, instance,
3633             self.host, action=fields.NotificationAction.UNRESCUE,
3634             phase=fields.NotificationPhase.END)
3635 
3636     @wrap_exception()
3637     @wrap_instance_fault
3638     def change_instance_metadata(self, context, diff, instance):
3639         """Update the metadata published to the instance."""
3640         LOG.debug("Changing instance metadata according to %r",
3641                   diff, instance=instance)
3642         self.driver.change_instance_metadata(context, instance, diff)
3643 
3644     @wrap_exception()
3645     @wrap_instance_event(prefix='compute')
3646     @wrap_instance_fault
3647     def confirm_resize(self, context, instance, reservations, migration):
3648         """Confirms a migration/resize and deletes the 'old' instance.
3649 
3650         This is called from the API and runs on the source host.
3651 
3652         Nothing needs to happen on the destination host at this point since
3653         the instance is already running there. This routine just cleans up the
3654         source host.
3655         """
3656         @utils.synchronized(instance.uuid)
3657         def do_confirm_resize(context, instance, migration_id):
3658             # NOTE(wangpan): Get the migration status from db, if it has been
3659             #                confirmed, we do nothing and return here
3660             LOG.debug("Going to confirm migration %s", migration_id,
3661                       instance=instance)
3662             try:
3663                 # TODO(russellb) Why are we sending the migration object just
3664                 # to turn around and look it up from the db again?
3665                 migration = objects.Migration.get_by_id(
3666                                     context.elevated(), migration_id)
3667             except exception.MigrationNotFound:
3668                 LOG.error("Migration %s is not found during confirmation",
3669                           migration_id, instance=instance)
3670                 return
3671 
3672             if migration.status == 'confirmed':
3673                 LOG.info("Migration %s is already confirmed",
3674                          migration_id, instance=instance)
3675                 return
3676             elif migration.status not in ('finished', 'confirming'):
3677                 LOG.warning("Unexpected confirmation status '%(status)s' "
3678                             "of migration %(id)s, exit confirmation process",
3679                             {"status": migration.status, "id": migration_id},
3680                             instance=instance)
3681                 return
3682 
3683             # NOTE(wangpan): Get the instance from db, if it has been
3684             #                deleted, we do nothing and return here
3685             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3686             try:
3687                 instance = objects.Instance.get_by_uuid(
3688                         context, instance.uuid,
3689                         expected_attrs=expected_attrs)
3690             except exception.InstanceNotFound:
3691                 LOG.info("Instance is not found during confirmation",
3692                          instance=instance)
3693                 return
3694 
3695             self._confirm_resize(context, instance, migration=migration)
3696 
3697         do_confirm_resize(context, instance, migration.id)
3698 
3699     def _confirm_resize(self, context, instance, migration=None):
3700         """Destroys the source instance."""
3701         self._notify_about_instance_usage(context, instance,
3702                                           "resize.confirm.start")
3703         compute_utils.notify_about_instance_action(context, instance,
3704             self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3705             phase=fields.NotificationPhase.START)
3706 
3707         with self._error_out_instance_on_exception(context, instance):
3708             # NOTE(danms): delete stashed migration information
3709             old_instance_type = instance.old_flavor
3710             instance.old_flavor = None
3711             instance.new_flavor = None
3712             instance.system_metadata.pop('old_vm_state', None)
3713             instance.save()
3714 
3715             # NOTE(tr3buchet): tear down networks on source host
3716             self.network_api.setup_networks_on_host(context, instance,
3717                                migration.source_compute, teardown=True)
3718 
3719             network_info = self.network_api.get_instance_nw_info(context,
3720                                                                  instance)
3721             # TODO(mriedem): Get BDMs here and pass them to the driver.
3722             self.driver.confirm_migration(context, migration, instance,
3723                                           network_info)
3724 
3725             migration.status = 'confirmed'
3726             with migration.obj_as_admin():
3727                 migration.save()
3728 
3729             rt = self._get_resource_tracker()
3730             rt.drop_move_claim(context, instance, migration.source_node,
3731                                old_instance_type, prefix='old_')
3732             self._delete_allocation_after_move(context, instance, migration,
3733                                                old_instance_type,
3734                                                migration.source_node)
3735             instance.drop_migration_context()
3736 
3737             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3738             # might have manually powered up the instance to confirm the
3739             # resize/migrate, so we need to check the current power state
3740             # on the instance and set the vm_state appropriately. We default
3741             # to ACTIVE because if the power state is not SHUTDOWN, we
3742             # assume _sync_instance_power_state will clean it up.
3743             p_state = instance.power_state
3744             vm_state = None
3745             if p_state == power_state.SHUTDOWN:
3746                 vm_state = vm_states.STOPPED
3747                 LOG.debug("Resized/migrated instance is powered off. "
3748                           "Setting vm_state to '%s'.", vm_state,
3749                           instance=instance)
3750             else:
3751                 vm_state = vm_states.ACTIVE
3752 
3753             instance.vm_state = vm_state
3754             instance.task_state = None
3755             instance.save(expected_task_state=[None, task_states.DELETING])
3756 
3757             self._notify_about_instance_usage(
3758                 context, instance, "resize.confirm.end",
3759                 network_info=network_info)
3760             compute_utils.notify_about_instance_action(context, instance,
3761                    self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3762                    phase=fields.NotificationPhase.END)
3763 
3764     def _delete_allocation_after_move(self, context, instance, migration,
3765                                       flavor, nodename):
3766         rt = self._get_resource_tracker()
3767         cn_uuid = rt.get_node_uuid(nodename)
3768 
3769         if migration.source_node == nodename:
3770             if migration.status in ('confirmed', 'completed'):
3771                 # NOTE(danms): We're finishing on the source node, so try to
3772                 # delete the allocation based on the migration uuid
3773                 deleted = self.reportclient.delete_allocation_for_instance(
3774                     context, migration.uuid)
3775                 if deleted:
3776                     LOG.info(_('Source node %(node)s confirmed migration '
3777                                '%(mig)s; deleted migration-based '
3778                                'allocation'),
3779                              {'node': nodename, 'mig': migration.uuid})
3780                     # NOTE(danms): We succeeded, which means we do not
3781                     # need to do the complex double allocation dance
3782                     return
3783             else:
3784                 # We're reverting (or failed) on the source, so we
3785                 # need to check if our migration holds a claim and if
3786                 # so, avoid doing the legacy behavior below.
3787                 mig_allocs = (
3788                     self.reportclient.get_allocations_for_consumer_by_provider(
3789                         cn_uuid, migration.uuid))
3790                 if mig_allocs:
3791                     LOG.info(_('Source node %(node)s reverted migration '
3792                                '%(mig)s; not deleting migration-based '
3793                                'allocation'),
3794                              {'node': nodename, 'mig': migration.uuid})
3795                     return
3796         elif migration.dest_node == nodename:
3797             # NOTE(danms): We're reverting on the destination node
3798             # (and we must not be doing a same-host migration if we
3799             # made it past the check above), so we need to check to
3800             # see if the source did migration-based allocation
3801             # accounting
3802             allocs = (
3803                 self.reportclient.get_allocations_for_consumer_by_provider(
3804                     cn_uuid, migration.uuid))
3805             if allocs:
3806                 # NOTE(danms): The source did migration-based allocation
3807                 # accounting, so we should let the source node rejigger
3808                 # the allocations in finish_resize_revert()
3809                 LOG.info(_('Destination node %(node)s reverted migration '
3810                            '%(mig)s; not deleting migration-based '
3811                            'allocation'),
3812                          {'node': nodename, 'mig': migration.uuid})
3813                 return
3814 
3815         # TODO(danms): Remove below this line when we remove compatibility
3816         # for double-accounting migrations (likely rocky)
3817         LOG.info(_('Doing legacy allocation math for migration %(mig)s after '
3818                    'instance move'),
3819                  {'mig': migration.uuid},
3820                  instance=instance)
3821 
3822         # NOTE(jaypipes): This sucks, but due to the fact that confirm_resize()
3823         # only runs on the source host and revert_resize() runs on the
3824         # destination host, we need to do this here. Basically, what we're
3825         # doing here is grabbing the existing allocations for this instance
3826         # from the placement API, dropping the resources in the doubled-up
3827         # allocation set that refer to the source host UUID and calling PUT
3828         # /allocations back to the placement API. The allocation that gets
3829         # PUT'd back to placement will only include the destination host and
3830         # any shared providers in the case of a confirm_resize operation and
3831         # the source host and shared providers for a revert_resize operation..
3832         my_resources = scheduler_utils.resources_from_flavor(instance, flavor)
3833         res = self.reportclient.remove_provider_from_instance_allocation(
3834             instance.uuid, cn_uuid, instance.user_id,
3835             instance.project_id, my_resources)
3836         if not res:
3837             LOG.error("Failed to save manipulated allocation",
3838                       instance=instance)
3839 
3840     @wrap_exception()
3841     @reverts_task_state
3842     @wrap_instance_event(prefix='compute')
3843     @errors_out_migration
3844     @wrap_instance_fault
3845     def revert_resize(self, context, instance, migration, reservations):
3846         """Destroys the new instance on the destination machine.
3847 
3848         Reverts the model changes, and powers on the old instance on the
3849         source machine.
3850 
3851         """
3852         # NOTE(comstud): A revert_resize is essentially a resize back to
3853         # the old size, so we need to send a usage event here.
3854         compute_utils.notify_usage_exists(self.notifier, context, instance,
3855                                           current_period=True)
3856 
3857         with self._error_out_instance_on_exception(context, instance):
3858             # NOTE(tr3buchet): tear down networks on destination host
3859             self.network_api.setup_networks_on_host(context, instance,
3860                                                     teardown=True)
3861 
3862             migration_p = obj_base.obj_to_primitive(migration)
3863             self.network_api.migrate_instance_start(context,
3864                                                     instance,
3865                                                     migration_p)
3866 
3867             network_info = self.network_api.get_instance_nw_info(context,
3868                                                                  instance)
3869             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3870                     context, instance.uuid)
3871             block_device_info = self._get_instance_block_device_info(
3872                                 context, instance, bdms=bdms)
3873 
3874             destroy_disks = not self._is_instance_storage_shared(
3875                 context, instance, host=migration.source_compute)
3876             self.driver.destroy(context, instance, network_info,
3877                                 block_device_info, destroy_disks)
3878 
3879             self._terminate_volume_connections(context, instance, bdms)
3880 
3881             migration.status = 'reverted'
3882             with migration.obj_as_admin():
3883                 migration.save()
3884 
3885             # NOTE(ndipanov): We need to do this here because dropping the
3886             # claim means we lose the migration_context data. We really should
3887             # fix this by moving the drop_move_claim call to the
3888             # finish_revert_resize method as this is racy (revert is dropped,
3889             # but instance resources will be tracked with the new flavor until
3890             # it gets rolled back in finish_revert_resize, which is
3891             # potentially wrong for a period of time).
3892             instance.revert_migration_context()
3893             instance.save()
3894 
3895             rt = self._get_resource_tracker()
3896             rt.drop_move_claim(context, instance, instance.node)
3897             self._delete_allocation_after_move(context, instance, migration,
3898                                                instance.flavor,
3899                                                instance.node)
3900 
3901             # RPC cast back to the source host to finish the revert there.
3902             self.compute_rpcapi.finish_revert_resize(context, instance,
3903                     migration, migration.source_compute)
3904 
3905     @wrap_exception()
3906     @reverts_task_state
3907     @wrap_instance_event(prefix='compute')
3908     @errors_out_migration
3909     @wrap_instance_fault
3910     def finish_revert_resize(self, context, instance, reservations, migration):
3911         """Finishes the second half of reverting a resize on the source host.
3912 
3913         Bring the original source instance state back (active/shutoff) and
3914         revert the resized attributes in the database.
3915 
3916         """
3917         with self._error_out_instance_on_exception(context, instance):
3918             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3919                 context, instance.uuid)
3920             self._notify_about_instance_usage(
3921                     context, instance, "resize.revert.start")
3922             compute_utils.notify_about_instance_action(context, instance,
3923                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
3924                     phase=fields.NotificationPhase.START, bdms=bdms)
3925 
3926             # NOTE(mriedem): delete stashed old_vm_state information; we
3927             # default to ACTIVE for backwards compatibility if old_vm_state
3928             # is not set
3929             old_vm_state = instance.system_metadata.pop('old_vm_state',
3930                                                         vm_states.ACTIVE)
3931 
3932             self._set_instance_info(instance, instance.old_flavor)
3933             instance.old_flavor = None
3934             instance.new_flavor = None
3935             instance.host = migration.source_compute
3936             instance.node = migration.source_node
3937             instance.save()
3938 
3939             self._revert_allocation(context, instance, migration)
3940 
3941             self.network_api.setup_networks_on_host(context, instance,
3942                                                     migration.source_compute)
3943             migration_p = obj_base.obj_to_primitive(migration)
3944             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
3945             # source host temporarily. "network_api.migrate_instance_finish"
3946             # will setup the network for the instance on the destination host.
3947             # For revert resize, the instance will back to the source host, the
3948             # setup of the network for instance should be on the source host.
3949             # So set the migration_p['dest_compute'] to source host at here.
3950             migration_p['dest_compute'] = migration.source_compute
3951             self.network_api.migrate_instance_finish(context,
3952                                                      instance,
3953                                                      migration_p)
3954             network_info = self.network_api.get_instance_nw_info(context,
3955                                                                  instance)
3956 
3957             # revert_resize deleted any volume attachments for the instance
3958             # and created new ones to be used on this host, but we
3959             # have to update those attachments with the host connector so the
3960             # BDM.connection_info will get set in the call to
3961             # _get_instance_block_device_info below with refresh_conn_info=True
3962             # and then the volumes can be re-connected via the driver on this
3963             # host.
3964             self._update_volume_attachments(context, instance, bdms)
3965 
3966             block_device_info = self._get_instance_block_device_info(
3967                     context, instance, refresh_conn_info=True, bdms=bdms)
3968 
3969             power_on = old_vm_state != vm_states.STOPPED
3970             self.driver.finish_revert_migration(context, instance,
3971                                        network_info,
3972                                        block_device_info, power_on)
3973 
3974             instance.drop_migration_context()
3975             instance.launched_at = timeutils.utcnow()
3976             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
3977 
3978             # Complete any volume attachments so the volumes are in-use.
3979             self._complete_volume_attachments(context, bdms)
3980 
3981             # if the original vm state was STOPPED, set it back to STOPPED
3982             LOG.info("Updating instance to original state: '%s'",
3983                      old_vm_state, instance=instance)
3984             if power_on:
3985                 instance.vm_state = vm_states.ACTIVE
3986                 instance.task_state = None
3987                 instance.save()
3988             else:
3989                 instance.task_state = task_states.POWERING_OFF
3990                 instance.save()
3991                 self.stop_instance(context, instance=instance,
3992                                    clean_shutdown=True)
3993 
3994             self._notify_about_instance_usage(
3995                     context, instance, "resize.revert.end")
3996             compute_utils.notify_about_instance_action(context, instance,
3997                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
3998                     phase=fields.NotificationPhase.END, bdms=bdms)
3999 
4000     def _revert_allocation(self, context, instance, migration):
4001         """Revert an allocation that is held by migration to our instance."""
4002 
4003         # Fetch the original allocation that the instance had on the source
4004         # node, which are now held by the migration
4005         orig_alloc = self.reportclient.get_allocations_for_consumer(
4006             migration.uuid)
4007         if not orig_alloc:
4008             # NOTE(danms): This migration did not do per-migration allocation
4009             # accounting, so nothing to do here.
4010             LOG.info('Old-style migration %(mig)s is being reverted; '
4011                      'no migration claims found on original node '
4012                      'to swap.',
4013                      {'mig': migration.uuid},
4014                      instance=instance)
4015             return False
4016 
4017         if len(orig_alloc) > 1:
4018             # NOTE(danms): This may change later if we have other allocations
4019             # against other providers that need to be held by the migration
4020             # as well. Perhaps something like shared storage resources that
4021             # will actually be duplicated during a resize type operation.
4022             LOG.error('New-style migration %(mig)s has allocations against '
4023                       'more than one provider %(rps)s. This should not be '
4024                       'possible, but reverting it anyway.',
4025                       {'mig': migration.uuid,
4026                        'rps': ','.join(orig_alloc.keys())},
4027                       instance=instance)
4028 
4029         # We only have a claim against one provider, it is the source node
4030         cn_uuid = list(orig_alloc.keys())[0]
4031 
4032         # Get just the resources part of the one allocation we need below
4033         orig_alloc = orig_alloc[cn_uuid].get('resources', {})
4034 
4035         # FIXME(danms): This method is flawed in that it asssumes allocations
4036         # against only one provider. So, this may overwite allocations against
4037         # a shared provider, if we had one.
4038         LOG.info('Swapping old allocation on %(node)s held by migration '
4039                  '%(mig)s for instance',
4040                  {'node': cn_uuid, 'mig': migration.uuid},
4041                  instance=instance)
4042         # TODO(cdent): Should we be doing anything with return values here?
4043         self.reportclient.set_and_clear_allocations(
4044             cn_uuid, instance.uuid, orig_alloc, instance.project_id,
4045             instance.user_id, consumer_to_clear=migration.uuid)
4046         return True
4047 
4048     def _prep_resize(self, context, image, instance, instance_type,
4049                      filter_properties, node, migration, clean_shutdown=True):
4050 
4051         if not filter_properties:
4052             filter_properties = {}
4053 
4054         if not instance.host:
4055             self._set_instance_obj_error_state(context, instance)
4056             msg = _('Instance has no source host')
4057             raise exception.MigrationError(reason=msg)
4058 
4059         same_host = instance.host == self.host
4060         # if the flavor IDs match, it's migrate; otherwise resize
4061         if same_host and instance_type.id == instance['instance_type_id']:
4062             # check driver whether support migrate to same host
4063             if not self.driver.capabilities['supports_migrate_to_same_host']:
4064                 raise exception.UnableToMigrateToSelf(
4065                     instance_id=instance.uuid, host=self.host)
4066 
4067         # NOTE(danms): Stash the new instance_type to avoid having to
4068         # look it up in the database later
4069         instance.new_flavor = instance_type
4070         # NOTE(mriedem): Stash the old vm_state so we can set the
4071         # resized/reverted instance back to the same state later.
4072         vm_state = instance.vm_state
4073         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4074         instance.system_metadata['old_vm_state'] = vm_state
4075         instance.save()
4076 
4077         limits = filter_properties.get('limits', {})
4078         rt = self._get_resource_tracker()
4079         with rt.resize_claim(context, instance, instance_type, node,
4080                              migration, image_meta=image,
4081                              limits=limits) as claim:
4082             LOG.info('Migrating', instance=instance)
4083             # RPC cast to the source host to start the actual resize/migration.
4084             self.compute_rpcapi.resize_instance(
4085                     context, instance, claim.migration, image,
4086                     instance_type, clean_shutdown)
4087 
4088     @wrap_exception()
4089     @reverts_task_state
4090     @wrap_instance_event(prefix='compute')
4091     @wrap_instance_fault
4092     def prep_resize(self, context, image, instance, instance_type,
4093                     reservations, request_spec, filter_properties, node,
4094                     clean_shutdown, migration=None):
4095         """Initiates the process of moving a running instance to another host.
4096 
4097         Possibly changes the VCPU, RAM and disk size in the process.
4098 
4099         This is initiated from conductor and runs on the destination host.
4100 
4101         The main purpose of this method is performing some checks on the
4102         destination host and making a claim for resources. If the claim fails
4103         then a reschedule to another host may be attempted which involves
4104         calling back to conductor to start the process over again.
4105         """
4106         if node is None:
4107             node = self._get_nodename(instance, refresh=True)
4108 
4109         # NOTE(melwitt): Remove this in version 5.0 of the RPC API
4110         # Code downstream may expect extra_specs to be populated since it
4111         # is receiving an object, so lookup the flavor to ensure this.
4112         if not isinstance(instance_type, objects.Flavor):
4113             instance_type = objects.Flavor.get_by_id(context,
4114                                                      instance_type['id'])
4115         with self._error_out_instance_on_exception(context, instance), \
4116                  errors_out_migration_ctxt(migration):
4117             compute_utils.notify_usage_exists(self.notifier, context, instance,
4118                                               current_period=True)
4119             self._notify_about_instance_usage(
4120                     context, instance, "resize.prep.start")
4121             try:
4122                 self._prep_resize(context, image, instance,
4123                                   instance_type, filter_properties,
4124                                   node, migration, clean_shutdown)
4125             except Exception:
4126                 # Since we hit a failure, we're either rescheduling or dead
4127                 # and either way we need to cleanup any allocations created
4128                 # by the scheduler for the destination node.
4129                 if migration and not self._revert_allocation(
4130                         context, instance, migration):
4131                     # We did not do a migration-based
4132                     # allocation. Note that for a resize to the
4133                     # same host, the scheduler will merge the
4134                     # flavors, so here we'd be subtracting the new
4135                     # flavor from the allocated resources on this
4136                     # node.
4137                     # FIXME(danms): Remove this in Rocky
4138                     rt = self._get_resource_tracker()
4139                     rt.delete_allocation_for_failed_resize(
4140                         instance, node, instance_type)
4141                 # try to re-schedule the resize elsewhere:
4142                 exc_info = sys.exc_info()
4143                 self._reschedule_resize_or_reraise(context, image, instance,
4144                         exc_info, instance_type, request_spec,
4145                         filter_properties)
4146             finally:
4147                 extra_usage_info = dict(
4148                         new_instance_type=instance_type.name,
4149                         new_instance_type_id=instance_type.id)
4150 
4151                 self._notify_about_instance_usage(
4152                     context, instance, "resize.prep.end",
4153                     extra_usage_info=extra_usage_info)
4154 
4155     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
4156             instance_type, request_spec, filter_properties):
4157         """Try to re-schedule the resize or re-raise the original error to
4158         error out the instance.
4159         """
4160         if not request_spec:
4161             request_spec = {}
4162         if not filter_properties:
4163             filter_properties = {}
4164 
4165         rescheduled = False
4166         instance_uuid = instance.uuid
4167 
4168         try:
4169             reschedule_method = self.compute_task_api.resize_instance
4170             scheduler_hint = dict(filter_properties=filter_properties)
4171             method_args = (instance, None, scheduler_hint, instance_type)
4172             task_state = task_states.RESIZE_PREP
4173 
4174             rescheduled = self._reschedule(context, request_spec,
4175                     filter_properties, instance, reschedule_method,
4176                     method_args, task_state, exc_info)
4177         except Exception as error:
4178             rescheduled = False
4179             LOG.exception("Error trying to reschedule",
4180                           instance_uuid=instance_uuid)
4181             compute_utils.add_instance_fault_from_exc(context,
4182                     instance, error,
4183                     exc_info=sys.exc_info())
4184             self._notify_about_instance_usage(context, instance,
4185                     'resize.error', fault=error)
4186             compute_utils.notify_about_instance_action(
4187                 context, instance, self.host,
4188                 action=fields.NotificationAction.RESIZE,
4189                 phase=fields.NotificationPhase.ERROR,
4190                 exception=error)
4191         if rescheduled:
4192             self._log_original_error(exc_info, instance_uuid)
4193             compute_utils.add_instance_fault_from_exc(context,
4194                     instance, exc_info[1], exc_info=exc_info)
4195             self._notify_about_instance_usage(context, instance,
4196                     'resize.error', fault=exc_info[1])
4197             compute_utils.notify_about_instance_action(
4198                 context, instance, self.host,
4199                 action=fields.NotificationAction.RESIZE,
4200                 phase=fields.NotificationPhase.ERROR,
4201                 exception=exc_info[1])
4202         else:
4203             # not re-scheduling
4204             six.reraise(*exc_info)
4205 
4206     @wrap_exception()
4207     @reverts_task_state
4208     @wrap_instance_event(prefix='compute')
4209     @wrap_instance_fault
4210     def resize_instance(self, context, instance, image,
4211                         reservations, migration, instance_type,
4212                         clean_shutdown):
4213         """Starts the migration of a running instance to another host.
4214 
4215         This is initiated from the destination host's ``prep_resize`` routine
4216         and runs on the source host.
4217         """
4218         with self._error_out_instance_on_exception(context, instance), \
4219              errors_out_migration_ctxt(migration):
4220             # TODO(chaochin) Remove this until v5 RPC API
4221             # Code downstream may expect extra_specs to be populated since it
4222             # is receiving an object, so lookup the flavor to ensure this.
4223             if (not instance_type or
4224                 not isinstance(instance_type, objects.Flavor)):
4225                 instance_type = objects.Flavor.get_by_id(
4226                     context, migration['new_instance_type_id'])
4227 
4228             network_info = self.network_api.get_instance_nw_info(context,
4229                                                                  instance)
4230 
4231             migration.status = 'migrating'
4232             with migration.obj_as_admin():
4233                 migration.save()
4234 
4235             instance.task_state = task_states.RESIZE_MIGRATING
4236             instance.save(expected_task_state=task_states.RESIZE_PREP)
4237 
4238             self._notify_about_instance_usage(
4239                 context, instance, "resize.start", network_info=network_info)
4240 
4241             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4242                     context, instance.uuid)
4243 
4244             compute_utils.notify_about_instance_action(context, instance,
4245                    self.host, action=fields.NotificationAction.RESIZE,
4246                    phase=fields.NotificationPhase.START, bdms=bdms)
4247 
4248             block_device_info = self._get_instance_block_device_info(
4249                                 context, instance, bdms=bdms)
4250 
4251             timeout, retry_interval = self._get_power_off_values(context,
4252                                             instance, clean_shutdown)
4253             disk_info = self.driver.migrate_disk_and_power_off(
4254                     context, instance, migration.dest_host,
4255                     instance_type, network_info,
4256                     block_device_info,
4257                     timeout, retry_interval)
4258 
4259             self._terminate_volume_connections(context, instance, bdms)
4260 
4261             migration_p = obj_base.obj_to_primitive(migration)
4262             self.network_api.migrate_instance_start(context,
4263                                                     instance,
4264                                                     migration_p)
4265 
4266             migration.status = 'post-migrating'
4267             with migration.obj_as_admin():
4268                 migration.save()
4269 
4270             instance.host = migration.dest_compute
4271             instance.node = migration.dest_node
4272             instance.task_state = task_states.RESIZE_MIGRATED
4273             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4274 
4275             # RPC cast to the destination host to finish the resize/migration.
4276             self.compute_rpcapi.finish_resize(context, instance,
4277                     migration, image, disk_info, migration.dest_compute)
4278 
4279         self._notify_about_instance_usage(context, instance, "resize.end",
4280                                           network_info=network_info)
4281 
4282         compute_utils.notify_about_instance_action(context, instance,
4283                self.host, action=fields.NotificationAction.RESIZE,
4284                phase=fields.NotificationPhase.END, bdms=bdms)
4285         self.instance_events.clear_events_for_instance(instance)
4286 
4287     def _terminate_volume_connections(self, context, instance, bdms):
4288         connector = None
4289         for bdm in bdms:
4290             if bdm.is_volume:
4291                 if bdm.attachment_id:
4292                     # NOTE(jdg): So here's the thing, the idea behind the new
4293                     # attach API's was to have a new code fork/path that we
4294                     # followed, we're not going to do that so we have to do
4295                     # some extra work in here to make it *behave* just like the
4296                     # old code. Cinder doesn't allow disconnect/reconnect (you
4297                     # just delete the attachment and get a new one)
4298                     # attachments in the new attach code so we have to do
4299                     # a delete and create without a connector (reserve),
4300                     # in other words, beware
4301                     attachment_id = self.volume_api.attachment_create(
4302                         context, bdm.volume_id, instance.uuid)['id']
4303                     self.volume_api.attachment_delete(context,
4304                                                       bdm.attachment_id)
4305                     bdm.attachment_id = attachment_id
4306                     bdm.save()
4307 
4308                 else:
4309                     if connector is None:
4310                         connector = self.driver.get_volume_connector(instance)
4311                     self.volume_api.terminate_connection(context,
4312                                                          bdm.volume_id,
4313                                                          connector)
4314 
4315     @staticmethod
4316     def _set_instance_info(instance, instance_type):
4317         instance.instance_type_id = instance_type.id
4318         instance.memory_mb = instance_type.memory_mb
4319         instance.vcpus = instance_type.vcpus
4320         instance.root_gb = instance_type.root_gb
4321         instance.ephemeral_gb = instance_type.ephemeral_gb
4322         instance.flavor = instance_type
4323 
4324     def _update_volume_attachments(self, context, instance, bdms):
4325         """Updates volume attachments using the virt driver host connector.
4326 
4327         :param context: nova.context.RequestContext - user request context
4328         :param instance: nova.objects.Instance
4329         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4330                      device mappings for the given instance
4331         """
4332         if bdms:
4333             connector = None
4334             for bdm in bdms:
4335                 if bdm.is_volume and bdm.attachment_id:
4336                     if connector is None:
4337                         connector = self.driver.get_volume_connector(instance)
4338                     self.volume_api.attachment_update(
4339                         context, bdm.attachment_id, connector, bdm.device_name)
4340 
4341     def _complete_volume_attachments(self, context, bdms):
4342         """Completes volume attachments for the instance
4343 
4344         :param context: nova.context.RequestContext - user request context
4345         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4346                      device mappings for the given instance
4347         """
4348         if bdms:
4349             for bdm in bdms:
4350                 if bdm.is_volume and bdm.attachment_id:
4351                     self.volume_api.attachment_complete(
4352                         context, bdm.attachment_id)
4353 
4354     def _finish_resize(self, context, instance, migration, disk_info,
4355                        image_meta, bdms):
4356         resize_instance = False
4357         old_instance_type_id = migration['old_instance_type_id']
4358         new_instance_type_id = migration['new_instance_type_id']
4359         old_instance_type = instance.get_flavor()
4360         # NOTE(mriedem): Get the old_vm_state so we know if we should
4361         # power on the instance. If old_vm_state is not set we need to default
4362         # to ACTIVE for backwards compatibility
4363         old_vm_state = instance.system_metadata.get('old_vm_state',
4364                                                     vm_states.ACTIVE)
4365         instance.old_flavor = old_instance_type
4366 
4367         if old_instance_type_id != new_instance_type_id:
4368             instance_type = instance.get_flavor('new')
4369             self._set_instance_info(instance, instance_type)
4370             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4371                 if old_instance_type[key] != instance_type[key]:
4372                     resize_instance = True
4373                     break
4374         instance.apply_migration_context()
4375 
4376         # NOTE(tr3buchet): setup networks on destination host
4377         self.network_api.setup_networks_on_host(context, instance,
4378                                                 migration['dest_compute'])
4379 
4380         migration_p = obj_base.obj_to_primitive(migration)
4381         self.network_api.migrate_instance_finish(context,
4382                                                  instance,
4383                                                  migration_p)
4384 
4385         network_info = self.network_api.get_instance_nw_info(context, instance)
4386 
4387         instance.task_state = task_states.RESIZE_FINISH
4388         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4389 
4390         self._notify_about_instance_usage(
4391             context, instance, "finish_resize.start",
4392             network_info=network_info)
4393         compute_utils.notify_about_instance_action(context, instance,
4394                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4395                phase=fields.NotificationPhase.START, bdms=bdms)
4396 
4397         # We need to update any volume attachments using the destination
4398         # host connector so that we can update the BDM.connection_info
4399         # before calling driver.finish_migration otherwise the driver
4400         # won't know how to connect the volumes to this host.
4401         # Note that _get_instance_block_device_info with
4402         # refresh_conn_info=True will update the BDM.connection_info value
4403         # in the database so we must do this before calling that method.
4404         self._update_volume_attachments(context, instance, bdms)
4405 
4406         block_device_info = self._get_instance_block_device_info(
4407             context, instance, refresh_conn_info=True, bdms=bdms)
4408 
4409         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4410         # automatically power on the instance after it's migrated
4411         power_on = old_vm_state != vm_states.STOPPED
4412 
4413         try:
4414             self.driver.finish_migration(context, migration, instance,
4415                                          disk_info,
4416                                          network_info,
4417                                          image_meta, resize_instance,
4418                                          block_device_info, power_on)
4419         except Exception:
4420             with excutils.save_and_reraise_exception():
4421                 if old_instance_type_id != new_instance_type_id:
4422                     self._set_instance_info(instance,
4423                                             old_instance_type)
4424 
4425         # Now complete any volume attachments that were previously updated.
4426         self._complete_volume_attachments(context, bdms)
4427 
4428         migration.status = 'finished'
4429         with migration.obj_as_admin():
4430             migration.save()
4431 
4432         instance.vm_state = vm_states.RESIZED
4433         instance.task_state = None
4434         instance.launched_at = timeutils.utcnow()
4435         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4436 
4437         return network_info
4438 
4439     @wrap_exception()
4440     @reverts_task_state
4441     @wrap_instance_event(prefix='compute')
4442     @wrap_instance_fault
4443     def finish_resize(self, context, disk_info, image, instance,
4444                       reservations, migration):
4445         """Completes the migration process.
4446 
4447         Sets up the newly transferred disk and turns on the instance at its
4448         new host machine.
4449 
4450         """
4451         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4452             context, instance.uuid)
4453 
4454         with self._error_out_instance_on_exception(context, instance), \
4455              errors_out_migration_ctxt(migration):
4456             image_meta = objects.ImageMeta.from_dict(image)
4457             network_info = self._finish_resize(context, instance, migration,
4458                                                disk_info, image_meta, bdms)
4459 
4460         self._update_scheduler_instance_info(context, instance)
4461         self._notify_about_instance_usage(
4462             context, instance, "finish_resize.end",
4463             network_info=network_info)
4464         compute_utils.notify_about_instance_action(context, instance,
4465                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4466                phase=fields.NotificationPhase.END, bdms=bdms)
4467 
4468     @wrap_exception()
4469     @wrap_instance_fault
4470     def add_fixed_ip_to_instance(self, context, network_id, instance):
4471         """Calls network_api to add new fixed_ip to instance
4472         then injects the new network info and resets instance networking.
4473 
4474         """
4475         self._notify_about_instance_usage(
4476                 context, instance, "create_ip.start")
4477 
4478         network_info = self.network_api.add_fixed_ip_to_instance(context,
4479                                                                  instance,
4480                                                                  network_id)
4481         self._inject_network_info(context, instance, network_info)
4482         self.reset_network(context, instance)
4483 
4484         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4485         instance.updated_at = timeutils.utcnow()
4486         instance.save()
4487 
4488         self._notify_about_instance_usage(
4489             context, instance, "create_ip.end", network_info=network_info)
4490 
4491     @wrap_exception()
4492     @wrap_instance_fault
4493     def remove_fixed_ip_from_instance(self, context, address, instance):
4494         """Calls network_api to remove existing fixed_ip from instance
4495         by injecting the altered network info and resetting
4496         instance networking.
4497         """
4498         self._notify_about_instance_usage(
4499                 context, instance, "delete_ip.start")
4500 
4501         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4502                                                                       instance,
4503                                                                       address)
4504         self._inject_network_info(context, instance, network_info)
4505         self.reset_network(context, instance)
4506 
4507         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4508         instance.updated_at = timeutils.utcnow()
4509         instance.save()
4510 
4511         self._notify_about_instance_usage(
4512             context, instance, "delete_ip.end", network_info=network_info)
4513 
4514     @wrap_exception()
4515     @reverts_task_state
4516     @wrap_instance_event(prefix='compute')
4517     @wrap_instance_fault
4518     def pause_instance(self, context, instance):
4519         """Pause an instance on this host."""
4520         context = context.elevated()
4521         LOG.info('Pausing', instance=instance)
4522         self._notify_about_instance_usage(context, instance, 'pause.start')
4523         compute_utils.notify_about_instance_action(context, instance,
4524                self.host, action=fields.NotificationAction.PAUSE,
4525                phase=fields.NotificationPhase.START)
4526         self.driver.pause(instance)
4527         instance.power_state = self._get_power_state(context, instance)
4528         instance.vm_state = vm_states.PAUSED
4529         instance.task_state = None
4530         instance.save(expected_task_state=task_states.PAUSING)
4531         self._notify_about_instance_usage(context, instance, 'pause.end')
4532         compute_utils.notify_about_instance_action(context, instance,
4533                self.host, action=fields.NotificationAction.PAUSE,
4534                phase=fields.NotificationPhase.END)
4535 
4536     @wrap_exception()
4537     @reverts_task_state
4538     @wrap_instance_event(prefix='compute')
4539     @wrap_instance_fault
4540     def unpause_instance(self, context, instance):
4541         """Unpause a paused instance on this host."""
4542         context = context.elevated()
4543         LOG.info('Unpausing', instance=instance)
4544         self._notify_about_instance_usage(context, instance, 'unpause.start')
4545         compute_utils.notify_about_instance_action(context, instance,
4546             self.host, action=fields.NotificationAction.UNPAUSE,
4547             phase=fields.NotificationPhase.START)
4548         self.driver.unpause(instance)
4549         instance.power_state = self._get_power_state(context, instance)
4550         instance.vm_state = vm_states.ACTIVE
4551         instance.task_state = None
4552         instance.save(expected_task_state=task_states.UNPAUSING)
4553         self._notify_about_instance_usage(context, instance, 'unpause.end')
4554         compute_utils.notify_about_instance_action(context, instance,
4555             self.host, action=fields.NotificationAction.UNPAUSE,
4556             phase=fields.NotificationPhase.END)
4557 
4558     @wrap_exception()
4559     def host_power_action(self, context, action):
4560         """Reboots, shuts down or powers up the host."""
4561         return self.driver.host_power_action(action)
4562 
4563     @wrap_exception()
4564     def host_maintenance_mode(self, context, host, mode):
4565         """Start/Stop host maintenance window. On start, it triggers
4566         guest VMs evacuation.
4567         """
4568         return self.driver.host_maintenance_mode(host, mode)
4569 
4570     @wrap_exception()
4571     def set_host_enabled(self, context, enabled):
4572         """Sets the specified host's ability to accept new instances."""
4573         return self.driver.set_host_enabled(enabled)
4574 
4575     @wrap_exception()
4576     def get_host_uptime(self, context):
4577         """Returns the result of calling "uptime" on the target host."""
4578         return self.driver.get_host_uptime()
4579 
4580     @wrap_exception()
4581     @wrap_instance_fault
4582     def get_diagnostics(self, context, instance):
4583         """Retrieve diagnostics for an instance on this host."""
4584         current_power_state = self._get_power_state(context, instance)
4585         if current_power_state == power_state.RUNNING:
4586             LOG.info("Retrieving diagnostics", instance=instance)
4587             return self.driver.get_diagnostics(instance)
4588         else:
4589             raise exception.InstanceInvalidState(
4590                 attr='power state',
4591                 instance_uuid=instance.uuid,
4592                 state=power_state.STATE_MAP[instance.power_state],
4593                 method='get_diagnostics')
4594 
4595     # TODO(alaski): Remove object_compat for RPC version 5.0
4596     @object_compat
4597     @wrap_exception()
4598     @wrap_instance_fault
4599     def get_instance_diagnostics(self, context, instance):
4600         """Retrieve diagnostics for an instance on this host."""
4601         current_power_state = self._get_power_state(context, instance)
4602         if current_power_state == power_state.RUNNING:
4603             LOG.info("Retrieving diagnostics", instance=instance)
4604             return self.driver.get_instance_diagnostics(instance)
4605         else:
4606             raise exception.InstanceInvalidState(
4607                 attr='power state',
4608                 instance_uuid=instance.uuid,
4609                 state=power_state.STATE_MAP[instance.power_state],
4610                 method='get_diagnostics')
4611 
4612     @wrap_exception()
4613     @reverts_task_state
4614     @wrap_instance_event(prefix='compute')
4615     @wrap_instance_fault
4616     def suspend_instance(self, context, instance):
4617         """Suspend the given instance."""
4618         context = context.elevated()
4619 
4620         # Store the old state
4621         instance.system_metadata['old_vm_state'] = instance.vm_state
4622         self._notify_about_instance_usage(context, instance, 'suspend.start')
4623         compute_utils.notify_about_instance_action(context, instance,
4624                 self.host, action=fields.NotificationAction.SUSPEND,
4625                 phase=fields.NotificationPhase.START)
4626         with self._error_out_instance_on_exception(context, instance,
4627              instance_state=instance.vm_state):
4628             self.driver.suspend(context, instance)
4629         instance.power_state = self._get_power_state(context, instance)
4630         instance.vm_state = vm_states.SUSPENDED
4631         instance.task_state = None
4632         instance.save(expected_task_state=task_states.SUSPENDING)
4633         self._notify_about_instance_usage(context, instance, 'suspend.end')
4634         compute_utils.notify_about_instance_action(context, instance,
4635                 self.host, action=fields.NotificationAction.SUSPEND,
4636                 phase=fields.NotificationPhase.END)
4637 
4638     @wrap_exception()
4639     @reverts_task_state
4640     @wrap_instance_event(prefix='compute')
4641     @wrap_instance_fault
4642     def resume_instance(self, context, instance):
4643         """Resume the given suspended instance."""
4644         context = context.elevated()
4645         LOG.info('Resuming', instance=instance)
4646 
4647         self._notify_about_instance_usage(context, instance, 'resume.start')
4648 
4649         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4650             context, instance.uuid)
4651         block_device_info = self._get_instance_block_device_info(
4652             context, instance, bdms=bdms)
4653 
4654         compute_utils.notify_about_instance_action(context, instance,
4655             self.host, action=fields.NotificationAction.RESUME,
4656             phase=fields.NotificationPhase.START, bdms=bdms)
4657 
4658         network_info = self.network_api.get_instance_nw_info(context, instance)
4659 
4660         with self._error_out_instance_on_exception(context, instance,
4661              instance_state=instance.vm_state):
4662             self.driver.resume(context, instance, network_info,
4663                                block_device_info)
4664 
4665         instance.power_state = self._get_power_state(context, instance)
4666 
4667         # We default to the ACTIVE state for backwards compatibility
4668         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4669                                                          vm_states.ACTIVE)
4670 
4671         instance.task_state = None
4672         instance.save(expected_task_state=task_states.RESUMING)
4673         self._notify_about_instance_usage(context, instance, 'resume.end')
4674         compute_utils.notify_about_instance_action(context, instance,
4675             self.host, action=fields.NotificationAction.RESUME,
4676             phase=fields.NotificationPhase.END, bdms=bdms)
4677 
4678     @wrap_exception()
4679     @reverts_task_state
4680     @wrap_instance_event(prefix='compute')
4681     @wrap_instance_fault
4682     def shelve_instance(self, context, instance, image_id,
4683                         clean_shutdown):
4684         """Shelve an instance.
4685 
4686         This should be used when you want to take a snapshot of the instance.
4687         It also adds system_metadata that can be used by a periodic task to
4688         offload the shelved instance after a period of time.
4689 
4690         :param context: request context
4691         :param instance: an Instance object
4692         :param image_id: an image id to snapshot to.
4693         :param clean_shutdown: give the GuestOS a chance to stop
4694         """
4695 
4696         @utils.synchronized(instance.uuid)
4697         def do_shelve_instance():
4698             self._shelve_instance(context, instance, image_id, clean_shutdown)
4699         do_shelve_instance()
4700 
4701     def _shelve_instance(self, context, instance, image_id,
4702                          clean_shutdown):
4703         LOG.info('Shelving', instance=instance)
4704         offload = CONF.shelved_offload_time == 0
4705         if offload:
4706             # Get the BDMs early so we can pass them into versioned
4707             # notifications since _shelve_offload_instance needs the
4708             # BDMs anyway.
4709             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4710                 context, instance.uuid)
4711         else:
4712             bdms = None
4713         compute_utils.notify_usage_exists(self.notifier, context, instance,
4714                                           current_period=True)
4715         self._notify_about_instance_usage(context, instance, 'shelve.start')
4716         compute_utils.notify_about_instance_action(context, instance,
4717                 self.host, action=fields.NotificationAction.SHELVE,
4718                 phase=fields.NotificationPhase.START, bdms=bdms)
4719 
4720         def update_task_state(task_state, expected_state=task_states.SHELVING):
4721             shelving_state_map = {
4722                     task_states.IMAGE_PENDING_UPLOAD:
4723                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4724                     task_states.IMAGE_UPLOADING:
4725                         task_states.SHELVING_IMAGE_UPLOADING,
4726                     task_states.SHELVING: task_states.SHELVING}
4727             task_state = shelving_state_map[task_state]
4728             expected_state = shelving_state_map[expected_state]
4729             instance.task_state = task_state
4730             instance.save(expected_task_state=expected_state)
4731 
4732         self._power_off_instance(context, instance, clean_shutdown)
4733         self.driver.snapshot(context, instance, image_id, update_task_state)
4734 
4735         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4736         instance.system_metadata['shelved_image_id'] = image_id
4737         instance.system_metadata['shelved_host'] = self.host
4738         instance.vm_state = vm_states.SHELVED
4739         instance.task_state = None
4740         if CONF.shelved_offload_time == 0:
4741             instance.task_state = task_states.SHELVING_OFFLOADING
4742         instance.power_state = self._get_power_state(context, instance)
4743         instance.save(expected_task_state=[
4744                 task_states.SHELVING,
4745                 task_states.SHELVING_IMAGE_UPLOADING])
4746 
4747         self._notify_about_instance_usage(context, instance, 'shelve.end')
4748         compute_utils.notify_about_instance_action(context, instance,
4749                 self.host, action=fields.NotificationAction.SHELVE,
4750                 phase=fields.NotificationPhase.END, bdms=bdms)
4751 
4752         if offload:
4753             self._shelve_offload_instance(context, instance,
4754                                           clean_shutdown=False, bdms=bdms)
4755 
4756     @wrap_exception()
4757     @reverts_task_state
4758     @wrap_instance_event(prefix='compute')
4759     @wrap_instance_fault
4760     def shelve_offload_instance(self, context, instance, clean_shutdown):
4761         """Remove a shelved instance from the hypervisor.
4762 
4763         This frees up those resources for use by other instances, but may lead
4764         to slower unshelve times for this instance.  This method is used by
4765         volume backed instances since restoring them doesn't involve the
4766         potentially large download of an image.
4767 
4768         :param context: request context
4769         :param instance: nova.objects.instance.Instance
4770         :param clean_shutdown: give the GuestOS a chance to stop
4771         """
4772 
4773         @utils.synchronized(instance.uuid)
4774         def do_shelve_offload_instance():
4775             self._shelve_offload_instance(context, instance, clean_shutdown)
4776         do_shelve_offload_instance()
4777 
4778     def _shelve_offload_instance(self, context, instance, clean_shutdown,
4779                                  bdms=None):
4780         LOG.info('Shelve offloading', instance=instance)
4781         if bdms is None:
4782             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4783                 context, instance.uuid)
4784         self._notify_about_instance_usage(context, instance,
4785                 'shelve_offload.start')
4786         compute_utils.notify_about_instance_action(context, instance,
4787                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4788                 phase=fields.NotificationPhase.START, bdms=bdms)
4789 
4790         self._power_off_instance(context, instance, clean_shutdown)
4791         current_power_state = self._get_power_state(context, instance)
4792 
4793         self.network_api.cleanup_instance_network_on_host(context, instance,
4794                                                           instance.host)
4795         network_info = self.network_api.get_instance_nw_info(context, instance)
4796 
4797         block_device_info = self._get_instance_block_device_info(context,
4798                                                                  instance,
4799                                                                  bdms=bdms)
4800         self.driver.destroy(context, instance, network_info,
4801                 block_device_info)
4802 
4803         # the instance is going to be removed from the host so we want to
4804         # terminate all the connections with the volume server and the host
4805         self._terminate_volume_connections(context, instance, bdms)
4806 
4807         instance.power_state = current_power_state
4808         # NOTE(mriedem): The vm_state has to be set before updating the
4809         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4810         # values cannot be nulled out until after updating the resource tracker
4811         # though.
4812         instance.vm_state = vm_states.SHELVED_OFFLOADED
4813         instance.task_state = None
4814         instance.save(expected_task_state=[task_states.SHELVING,
4815                                            task_states.SHELVING_OFFLOADING])
4816 
4817         # NOTE(ndipanov): Free resources from the resource tracker
4818         self._update_resource_tracker(context, instance)
4819 
4820         rt = self._get_resource_tracker()
4821         rt.delete_allocation_for_shelve_offloaded_instance(context, instance)
4822 
4823         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4824         # instance, so ensure any calls result in errors
4825         self._nil_out_instance_obj_host_and_node(instance)
4826         instance.save(expected_task_state=None)
4827 
4828         self._delete_scheduler_instance_info(context, instance.uuid)
4829         self._notify_about_instance_usage(context, instance,
4830                 'shelve_offload.end')
4831         compute_utils.notify_about_instance_action(context, instance,
4832                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4833                 phase=fields.NotificationPhase.END, bdms=bdms)
4834 
4835     @wrap_exception()
4836     @reverts_task_state
4837     @wrap_instance_event(prefix='compute')
4838     @wrap_instance_fault
4839     def unshelve_instance(self, context, instance, image,
4840                           filter_properties, node):
4841         """Unshelve the instance.
4842 
4843         :param context: request context
4844         :param instance: a nova.objects.instance.Instance object
4845         :param image: an image to build from.  If None we assume a
4846             volume backed instance.
4847         :param filter_properties: dict containing limits, retry info etc.
4848         :param node: target compute node
4849         """
4850         if filter_properties is None:
4851             filter_properties = {}
4852 
4853         @utils.synchronized(instance.uuid)
4854         def do_unshelve_instance():
4855             self._unshelve_instance(context, instance, image,
4856                                     filter_properties, node)
4857         do_unshelve_instance()
4858 
4859     def _unshelve_instance_key_scrub(self, instance):
4860         """Remove data from the instance that may cause side effects."""
4861         cleaned_keys = dict(
4862                 key_data=instance.key_data,
4863                 auto_disk_config=instance.auto_disk_config)
4864         instance.key_data = None
4865         instance.auto_disk_config = False
4866         return cleaned_keys
4867 
4868     def _unshelve_instance_key_restore(self, instance, keys):
4869         """Restore previously scrubbed keys before saving the instance."""
4870         instance.update(keys)
4871 
4872     def _unshelve_instance(self, context, instance, image, filter_properties,
4873                            node):
4874         LOG.info('Unshelving', instance=instance)
4875         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4876                 context, instance.uuid)
4877 
4878         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4879         compute_utils.notify_about_instance_action(context, instance,
4880                 self.host, action=fields.NotificationAction.UNSHELVE,
4881                 phase=fields.NotificationPhase.START, bdms=bdms)
4882 
4883         instance.task_state = task_states.SPAWNING
4884         instance.save()
4885 
4886         block_device_info = self._prep_block_device(context, instance, bdms)
4887         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4888 
4889         if node is None:
4890             node = self._get_nodename(instance)
4891 
4892         rt = self._get_resource_tracker()
4893         limits = filter_properties.get('limits', {})
4894 
4895         allocations = self.reportclient.get_allocations_for_consumer(
4896             instance.uuid)
4897 
4898         shelved_image_ref = instance.image_ref
4899         if image:
4900             instance.image_ref = image['id']
4901             image_meta = objects.ImageMeta.from_dict(image)
4902         else:
4903             image_meta = objects.ImageMeta.from_dict(
4904                 utils.get_image_from_system_metadata(
4905                     instance.system_metadata))
4906 
4907         self.network_api.setup_instance_network_on_host(context, instance,
4908                                                         self.host)
4909         network_info = self.network_api.get_instance_nw_info(context, instance)
4910         try:
4911             with rt.instance_claim(context, instance, node, limits):
4912                 self.driver.spawn(context, instance, image_meta,
4913                                   injected_files=[],
4914                                   admin_password=None,
4915                                   allocations=allocations,
4916                                   network_info=network_info,
4917                                   block_device_info=block_device_info)
4918         except Exception:
4919             with excutils.save_and_reraise_exception(logger=LOG):
4920                 LOG.exception('Instance failed to spawn',
4921                               instance=instance)
4922                 # Cleanup allocations created by the scheduler on this host
4923                 # since we failed to spawn the instance. We do this both if
4924                 # the instance claim failed with ComputeResourcesUnavailable
4925                 # or if we did claim but the spawn failed, because aborting the
4926                 # instance claim will not remove the allocations.
4927                 rt.reportclient.delete_allocation_for_instance(context,
4928                                                                instance.uuid)
4929                 # FIXME: Umm, shouldn't we be rolling back volume connections
4930                 # and port bindings?
4931 
4932         if image:
4933             instance.image_ref = shelved_image_ref
4934             self._delete_snapshot_of_shelved_instance(context, instance,
4935                                                       image['id'])
4936 
4937         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4938         self._update_instance_after_spawn(context, instance)
4939         # Delete system_metadata for a shelved instance
4940         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4941 
4942         instance.save(expected_task_state=task_states.SPAWNING)
4943         self._update_scheduler_instance_info(context, instance)
4944         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4945         compute_utils.notify_about_instance_action(context, instance,
4946                 self.host, action=fields.NotificationAction.UNSHELVE,
4947                 phase=fields.NotificationPhase.END, bdms=bdms)
4948 
4949     @messaging.expected_exceptions(NotImplementedError)
4950     @wrap_instance_fault
4951     def reset_network(self, context, instance):
4952         """Reset networking on the given instance."""
4953         LOG.debug('Reset network', instance=instance)
4954         self.driver.reset_network(instance)
4955 
4956     def _inject_network_info(self, context, instance, network_info):
4957         """Inject network info for the given instance."""
4958         LOG.debug('Inject network info', instance=instance)
4959         LOG.debug('network_info to inject: |%s|', network_info,
4960                   instance=instance)
4961 
4962         self.driver.inject_network_info(instance,
4963                                         network_info)
4964 
4965     @wrap_instance_fault
4966     def inject_network_info(self, context, instance):
4967         """Inject network info, but don't return the info."""
4968         network_info = self.network_api.get_instance_nw_info(context, instance)
4969         self._inject_network_info(context, instance, network_info)
4970 
4971     @messaging.expected_exceptions(NotImplementedError,
4972                                    exception.ConsoleNotAvailable,
4973                                    exception.InstanceNotFound)
4974     @wrap_exception()
4975     @wrap_instance_fault
4976     def get_console_output(self, context, instance, tail_length):
4977         """Send the console output for the given instance."""
4978         context = context.elevated()
4979         LOG.info("Get console output", instance=instance)
4980         output = self.driver.get_console_output(context, instance)
4981 
4982         if type(output) is six.text_type:
4983             output = six.b(output)
4984 
4985         if tail_length is not None:
4986             output = self._tail_log(output, tail_length)
4987 
4988         return output.decode('ascii', 'replace')
4989 
4990     def _tail_log(self, log, length):
4991         try:
4992             length = int(length)
4993         except ValueError:
4994             length = 0
4995 
4996         if length == 0:
4997             return b''
4998         else:
4999             return b'\n'.join(log.split(b'\n')[-int(length):])
5000 
5001     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5002                                    exception.InstanceNotReady,
5003                                    exception.InstanceNotFound,
5004                                    exception.ConsoleTypeUnavailable,
5005                                    NotImplementedError)
5006     @wrap_exception()
5007     @wrap_instance_fault
5008     def get_vnc_console(self, context, console_type, instance):
5009         """Return connection information for a vnc console."""
5010         context = context.elevated()
5011         LOG.debug("Getting vnc console", instance=instance)
5012         token = uuidutils.generate_uuid()
5013 
5014         if not CONF.vnc.enabled:
5015             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5016 
5017         if console_type == 'novnc':
5018             # For essex, novncproxy_base_url must include the full path
5019             # including the html file (like http://myhost/vnc_auto.html)
5020             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
5021         elif console_type == 'xvpvnc':
5022             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
5023         else:
5024             raise exception.ConsoleTypeInvalid(console_type=console_type)
5025 
5026         try:
5027             # Retrieve connect info from driver, and then decorate with our
5028             # access info token
5029             console = self.driver.get_vnc_console(context, instance)
5030             connect_info = console.get_connection_info(token, access_url)
5031         except exception.InstanceNotFound:
5032             if instance.vm_state != vm_states.BUILDING:
5033                 raise
5034             raise exception.InstanceNotReady(instance_id=instance.uuid)
5035 
5036         return connect_info
5037 
5038     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5039                                    exception.InstanceNotReady,
5040                                    exception.InstanceNotFound,
5041                                    exception.ConsoleTypeUnavailable,
5042                                    NotImplementedError)
5043     @wrap_exception()
5044     @wrap_instance_fault
5045     def get_spice_console(self, context, console_type, instance):
5046         """Return connection information for a spice console."""
5047         context = context.elevated()
5048         LOG.debug("Getting spice console", instance=instance)
5049         token = uuidutils.generate_uuid()
5050 
5051         if not CONF.spice.enabled:
5052             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5053 
5054         if console_type == 'spice-html5':
5055             # For essex, spicehtml5proxy_base_url must include the full path
5056             # including the html file (like http://myhost/spice_auto.html)
5057             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
5058                                           token)
5059         else:
5060             raise exception.ConsoleTypeInvalid(console_type=console_type)
5061 
5062         try:
5063             # Retrieve connect info from driver, and then decorate with our
5064             # access info token
5065             console = self.driver.get_spice_console(context, instance)
5066             connect_info = console.get_connection_info(token, access_url)
5067         except exception.InstanceNotFound:
5068             if instance.vm_state != vm_states.BUILDING:
5069                 raise
5070             raise exception.InstanceNotReady(instance_id=instance.uuid)
5071 
5072         return connect_info
5073 
5074     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5075                                    exception.InstanceNotReady,
5076                                    exception.InstanceNotFound,
5077                                    exception.ConsoleTypeUnavailable,
5078                                    NotImplementedError)
5079     @wrap_exception()
5080     @wrap_instance_fault
5081     def get_rdp_console(self, context, console_type, instance):
5082         """Return connection information for a RDP console."""
5083         context = context.elevated()
5084         LOG.debug("Getting RDP console", instance=instance)
5085         token = uuidutils.generate_uuid()
5086 
5087         if not CONF.rdp.enabled:
5088             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5089 
5090         if console_type == 'rdp-html5':
5091             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
5092                                           token)
5093         else:
5094             raise exception.ConsoleTypeInvalid(console_type=console_type)
5095 
5096         try:
5097             # Retrieve connect info from driver, and then decorate with our
5098             # access info token
5099             console = self.driver.get_rdp_console(context, instance)
5100             connect_info = console.get_connection_info(token, access_url)
5101         except exception.InstanceNotFound:
5102             if instance.vm_state != vm_states.BUILDING:
5103                 raise
5104             raise exception.InstanceNotReady(instance_id=instance.uuid)
5105 
5106         return connect_info
5107 
5108     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5109                                    exception.InstanceNotReady,
5110                                    exception.InstanceNotFound,
5111                                    exception.ConsoleTypeUnavailable,
5112                                    NotImplementedError)
5113     @wrap_exception()
5114     @wrap_instance_fault
5115     def get_mks_console(self, context, console_type, instance):
5116         """Return connection information for a MKS console."""
5117         context = context.elevated()
5118         LOG.debug("Getting MKS console", instance=instance)
5119         token = uuidutils.generate_uuid()
5120 
5121         if not CONF.mks.enabled:
5122             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5123 
5124         if console_type == 'webmks':
5125             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
5126                                           token)
5127         else:
5128             raise exception.ConsoleTypeInvalid(console_type=console_type)
5129 
5130         try:
5131             # Retrieve connect info from driver, and then decorate with our
5132             # access info token
5133             console = self.driver.get_mks_console(context, instance)
5134             connect_info = console.get_connection_info(token, access_url)
5135         except exception.InstanceNotFound:
5136             if instance.vm_state != vm_states.BUILDING:
5137                 raise
5138             raise exception.InstanceNotReady(instance_id=instance.uuid)
5139 
5140         return connect_info
5141 
5142     @messaging.expected_exceptions(
5143         exception.ConsoleTypeInvalid,
5144         exception.InstanceNotReady,
5145         exception.InstanceNotFound,
5146         exception.ConsoleTypeUnavailable,
5147         exception.SocketPortRangeExhaustedException,
5148         exception.ImageSerialPortNumberInvalid,
5149         exception.ImageSerialPortNumberExceedFlavorValue,
5150         NotImplementedError)
5151     @wrap_exception()
5152     @wrap_instance_fault
5153     def get_serial_console(self, context, console_type, instance):
5154         """Returns connection information for a serial console."""
5155 
5156         LOG.debug("Getting serial console", instance=instance)
5157 
5158         if not CONF.serial_console.enabled:
5159             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5160 
5161         context = context.elevated()
5162 
5163         token = uuidutils.generate_uuid()
5164         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
5165 
5166         try:
5167             # Retrieve connect info from driver, and then decorate with our
5168             # access info token
5169             console = self.driver.get_serial_console(context, instance)
5170             connect_info = console.get_connection_info(token, access_url)
5171         except exception.InstanceNotFound:
5172             if instance.vm_state != vm_states.BUILDING:
5173                 raise
5174             raise exception.InstanceNotReady(instance_id=instance.uuid)
5175 
5176         return connect_info
5177 
5178     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5179                                    exception.InstanceNotReady,
5180                                    exception.InstanceNotFound)
5181     @wrap_exception()
5182     @wrap_instance_fault
5183     def validate_console_port(self, ctxt, instance, port, console_type):
5184         if console_type == "spice-html5":
5185             console_info = self.driver.get_spice_console(ctxt, instance)
5186         elif console_type == "rdp-html5":
5187             console_info = self.driver.get_rdp_console(ctxt, instance)
5188         elif console_type == "serial":
5189             console_info = self.driver.get_serial_console(ctxt, instance)
5190         elif console_type == "webmks":
5191             console_info = self.driver.get_mks_console(ctxt, instance)
5192         else:
5193             console_info = self.driver.get_vnc_console(ctxt, instance)
5194 
5195         return console_info.port == port
5196 
5197     @wrap_exception()
5198     @reverts_task_state
5199     @wrap_instance_fault
5200     def reserve_block_device_name(self, context, instance, device,
5201                                   volume_id, disk_bus, device_type, tag=None,
5202                                   multiattach=False):
5203         if (tag and not
5204                 self.driver.capabilities.get('supports_tagged_attach_volume',
5205                                              False)):
5206             raise exception.VolumeTaggedAttachNotSupported()
5207 
5208         if (multiattach and not
5209                 self.driver.capabilities.get('supports_multiattach', False)):
5210             raise exception.MultiattachNotSupportedByVirtDriver(
5211                 volume_id=volume_id)
5212 
5213         @utils.synchronized(instance.uuid)
5214         def do_reserve():
5215             bdms = (
5216                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5217                     context, instance.uuid))
5218 
5219             # NOTE(ndipanov): We need to explicitly set all the fields on the
5220             #                 object so that obj_load_attr does not fail
5221             new_bdm = objects.BlockDeviceMapping(
5222                     context=context,
5223                     source_type='volume', destination_type='volume',
5224                     instance_uuid=instance.uuid, boot_index=None,
5225                     volume_id=volume_id,
5226                     device_name=device, guest_format=None,
5227                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5228 
5229             new_bdm.device_name = self._get_device_name_for_instance(
5230                     instance, bdms, new_bdm)
5231 
5232             # NOTE(vish): create bdm here to avoid race condition
5233             new_bdm.create()
5234             return new_bdm
5235 
5236         return do_reserve()
5237 
5238     @wrap_exception()
5239     @wrap_instance_event(prefix='compute')
5240     @wrap_instance_fault
5241     def attach_volume(self, context, instance, bdm):
5242         """Attach a volume to an instance."""
5243         driver_bdm = driver_block_device.convert_volume(bdm)
5244 
5245         @utils.synchronized(instance.uuid)
5246         def do_attach_volume(context, instance, driver_bdm):
5247             try:
5248                 return self._attach_volume(context, instance, driver_bdm)
5249             except Exception:
5250                 with excutils.save_and_reraise_exception():
5251                     bdm.destroy()
5252 
5253         do_attach_volume(context, instance, driver_bdm)
5254 
5255     def _attach_volume(self, context, instance, bdm):
5256         context = context.elevated()
5257         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5258                  {'volume_id': bdm.volume_id,
5259                   'mountpoint': bdm['mount_device']},
5260                  instance=instance)
5261         compute_utils.notify_about_volume_attach_detach(
5262             context, instance, self.host,
5263             action=fields.NotificationAction.VOLUME_ATTACH,
5264             phase=fields.NotificationPhase.START,
5265             volume_id=bdm.volume_id)
5266         try:
5267             bdm.attach(context, instance, self.volume_api, self.driver,
5268                        do_driver_attach=True)
5269         except Exception as e:
5270             with excutils.save_and_reraise_exception():
5271                 LOG.exception("Failed to attach %(volume_id)s "
5272                               "at %(mountpoint)s",
5273                               {'volume_id': bdm.volume_id,
5274                                'mountpoint': bdm['mount_device']},
5275                               instance=instance)
5276                 if bdm['attachment_id']:
5277                     self.volume_api.attachment_delete(context,
5278                                                       bdm['attachment_id'])
5279                 else:
5280                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5281                 compute_utils.notify_about_volume_attach_detach(
5282                     context, instance, self.host,
5283                     action=fields.NotificationAction.VOLUME_ATTACH,
5284                     phase=fields.NotificationPhase.ERROR,
5285                     exception=e,
5286                     volume_id=bdm.volume_id)
5287 
5288         info = {'volume_id': bdm.volume_id}
5289         self._notify_about_instance_usage(
5290             context, instance, "volume.attach", extra_usage_info=info)
5291         compute_utils.notify_about_volume_attach_detach(
5292             context, instance, self.host,
5293             action=fields.NotificationAction.VOLUME_ATTACH,
5294             phase=fields.NotificationPhase.END,
5295             volume_id=bdm.volume_id)
5296 
5297     def _notify_volume_usage_detach(self, context, instance, bdm):
5298         if CONF.volume_usage_poll_interval <= 0:
5299             return
5300 
5301         vol_stats = []
5302         mp = bdm.device_name
5303         # Handle bootable volumes which will not contain /dev/
5304         if '/dev/' in mp:
5305             mp = mp[5:]
5306         try:
5307             vol_stats = self.driver.block_stats(instance, mp)
5308         except NotImplementedError:
5309             return
5310 
5311         LOG.debug("Updating volume usage cache with totals", instance=instance)
5312         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5313         vol_usage = objects.VolumeUsage(context)
5314         vol_usage.volume_id = bdm.volume_id
5315         vol_usage.instance_uuid = instance.uuid
5316         vol_usage.project_id = instance.project_id
5317         vol_usage.user_id = instance.user_id
5318         vol_usage.availability_zone = instance.availability_zone
5319         vol_usage.curr_reads = rd_req
5320         vol_usage.curr_read_bytes = rd_bytes
5321         vol_usage.curr_writes = wr_req
5322         vol_usage.curr_write_bytes = wr_bytes
5323         vol_usage.save(update_totals=True)
5324         self.notifier.info(context, 'volume.usage',
5325                            compute_utils.usage_volume_info(vol_usage))
5326 
5327     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5328                        attachment_id=None):
5329         """Detach a volume from an instance.
5330 
5331         :param context: security context
5332         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5333         :param instance: the Instance object to detach the volume from
5334         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5335                             as deleted. Disabling this is useful for operations
5336                             like rebuild, when we don't want to destroy BDM
5337         :param attachment_id: The volume attachment_id for the given instance
5338                               and volume.
5339         """
5340         volume_id = bdm.volume_id
5341         compute_utils.notify_about_volume_attach_detach(
5342             context, instance, self.host,
5343             action=fields.NotificationAction.VOLUME_DETACH,
5344             phase=fields.NotificationPhase.START,
5345             volume_id=volume_id)
5346 
5347         self._notify_volume_usage_detach(context, instance, bdm)
5348 
5349         LOG.info('Detaching volume %(volume_id)s',
5350                  {'volume_id': volume_id}, instance=instance)
5351 
5352         driver_bdm = driver_block_device.convert_volume(bdm)
5353         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5354                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5355 
5356         info = dict(volume_id=volume_id)
5357         self._notify_about_instance_usage(
5358             context, instance, "volume.detach", extra_usage_info=info)
5359         compute_utils.notify_about_volume_attach_detach(
5360             context, instance, self.host,
5361             action=fields.NotificationAction.VOLUME_DETACH,
5362             phase=fields.NotificationPhase.END,
5363             volume_id=volume_id)
5364 
5365         if 'tag' in bdm and bdm.tag:
5366             self._delete_disk_metadata(instance, bdm)
5367         if destroy_bdm:
5368             bdm.destroy()
5369 
5370     def _delete_disk_metadata(self, instance, bdm):
5371         for device in instance.device_metadata.devices:
5372             if isinstance(device, objects.DiskMetadata):
5373                 if 'serial' in device:
5374                     if device.serial == bdm.volume_id:
5375                         instance.device_metadata.devices.remove(device)
5376                         instance.save()
5377                         break
5378                 else:
5379                     # NOTE(artom) We log the entire device object because all
5380                     # fields are nullable and may not be set
5381                     LOG.warning('Unable to determine whether to clean up '
5382                                 'device metadata for disk %s', device,
5383                                 instance=instance)
5384 
5385     @wrap_exception()
5386     @wrap_instance_event(prefix='compute')
5387     @wrap_instance_fault
5388     def detach_volume(self, context, volume_id, instance, attachment_id=None):
5389         """Detach a volume from an instance.
5390 
5391         :param context: security context
5392         :param volume_id: the volume id
5393         :param instance: the Instance object to detach the volume from
5394         :param attachment_id: The volume attachment_id for the given instance
5395                               and volume.
5396 
5397         """
5398         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5399                 context, volume_id, instance.uuid)
5400         self._detach_volume(context, bdm, instance,
5401                             attachment_id=attachment_id)
5402 
5403     def _init_volume_connection(self, context, new_volume,
5404                                 old_volume_id, connector, bdm,
5405                                 new_attachment_id, mountpoint):
5406         new_volume_id = new_volume['id']
5407         if new_attachment_id is None:
5408             # We're dealing with an old-style attachment so initialize the
5409             # connection so we can get the connection_info.
5410             new_cinfo = self.volume_api.initialize_connection(context,
5411                                                               new_volume_id,
5412                                                               connector)
5413         else:
5414             # Check for multiattach on the new volume and if True, check to
5415             # see if the virt driver supports multiattach.
5416             # TODO(mriedem): This is copied from DriverVolumeBlockDevice
5417             # and should be consolidated into some common code at some point.
5418             vol_multiattach = new_volume.get('multiattach', False)
5419             virt_multiattach = self.driver.capabilities['supports_multiattach']
5420             if vol_multiattach and not virt_multiattach:
5421                 raise exception.MultiattachNotSupportedByVirtDriver(
5422                     volume_id=new_volume_id)
5423 
5424             # This is a new style attachment and the API created the new
5425             # volume attachment and passed the id to the compute over RPC.
5426             # At this point we need to update the new volume attachment with
5427             # the host connector, which will give us back the new attachment
5428             # connection_info.
5429             new_cinfo = self.volume_api.attachment_update(
5430                 context, new_attachment_id, connector,
5431                 mountpoint)['connection_info']
5432 
5433             if vol_multiattach:
5434                 # This will be used by the volume driver to determine the
5435                 # proper disk configuration.
5436                 new_cinfo['multiattach'] = True
5437 
5438         old_cinfo = jsonutils.loads(bdm['connection_info'])
5439         if old_cinfo and 'serial' not in old_cinfo:
5440             old_cinfo['serial'] = old_volume_id
5441         # NOTE(lyarwood): serial is not always present in the returned
5442         # connection_info so set it if it is missing as we do in
5443         # DriverVolumeBlockDevice.attach().
5444         if 'serial' not in new_cinfo:
5445             new_cinfo['serial'] = new_volume_id
5446         return (old_cinfo, new_cinfo)
5447 
5448     def _swap_volume(self, context, instance, bdm, connector,
5449                      old_volume_id, new_volume, resize_to,
5450                      new_attachment_id, is_cinder_migration):
5451         new_volume_id = new_volume['id']
5452         mountpoint = bdm['device_name']
5453         failed = False
5454         new_cinfo = None
5455         try:
5456             old_cinfo, new_cinfo = self._init_volume_connection(
5457                 context, new_volume, old_volume_id, connector,
5458                 bdm, new_attachment_id, mountpoint)
5459             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5460             # currently implementing swap_volume, will modify the contents of
5461             # new_cinfo when connect_volume is called. This is then saved to
5462             # the BDM in swap_volume for future use outside of this flow.
5463             LOG.debug("swap_volume: Calling driver volume swap with "
5464                       "connection infos: new: %(new_cinfo)s; "
5465                       "old: %(old_cinfo)s",
5466                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo},
5467                       instance=instance)
5468             self.driver.swap_volume(context, old_cinfo, new_cinfo, instance,
5469                                     mountpoint, resize_to)
5470             if new_attachment_id:
5471                 self.volume_api.attachment_complete(context, new_attachment_id)
5472             LOG.debug("swap_volume: Driver volume swap returned, new "
5473                       "connection_info is now : %(new_cinfo)s",
5474                       {'new_cinfo': new_cinfo})
5475         except Exception as ex:
5476             failed = True
5477             with excutils.save_and_reraise_exception():
5478                 compute_utils.notify_about_volume_swap(
5479                     context, instance, self.host,
5480                     fields.NotificationAction.VOLUME_SWAP,
5481                     fields.NotificationPhase.ERROR,
5482                     old_volume_id, new_volume_id, ex)
5483                 if new_cinfo:
5484                     msg = ("Failed to swap volume %(old_volume_id)s "
5485                            "for %(new_volume_id)s")
5486                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5487                                         'new_volume_id': new_volume_id},
5488                                   instance=instance)
5489                 else:
5490                     msg = ("Failed to connect to volume %(volume_id)s "
5491                            "with volume at %(mountpoint)s")
5492                     LOG.exception(msg, {'volume_id': new_volume_id,
5493                                         'mountpoint': bdm['device_name']},
5494                                   instance=instance)
5495 
5496                 # The API marked the volume as 'detaching' for the old volume
5497                 # so we need to roll that back so the volume goes back to
5498                 # 'in-use' state.
5499                 self.volume_api.roll_detaching(context, old_volume_id)
5500 
5501                 if new_attachment_id is None:
5502                     # The API reserved the new volume so it would be in
5503                     # 'attaching' status, so we need to unreserve it so it
5504                     # goes back to 'available' status.
5505                     self.volume_api.unreserve_volume(context, new_volume_id)
5506                 else:
5507                     # This is a new style attachment for the new volume, which
5508                     # was created in the API. We just need to delete it here
5509                     # to put the new volume back into 'available' status.
5510                     self.volume_api.attachment_delete(
5511                         context, new_attachment_id)
5512         finally:
5513             # TODO(mriedem): This finally block is terribly confusing and is
5514             # trying to do too much. We should consider removing the finally
5515             # block and move whatever needs to happen on success and failure
5516             # into the blocks above for clarity, even if it means a bit of
5517             # redundant code.
5518             conn_volume = new_volume_id if failed else old_volume_id
5519             if new_cinfo:
5520                 LOG.debug("swap_volume: removing Cinder connection "
5521                           "for volume %(volume)s", {'volume': conn_volume},
5522                           instance=instance)
5523                 if bdm.attachment_id is None:
5524                     # This is the pre-3.44 flow for new-style volume
5525                     # attachments so just terminate the connection.
5526                     self.volume_api.terminate_connection(context,
5527                                                          conn_volume,
5528                                                          connector)
5529                 else:
5530                     # This is a new style volume attachment. If we failed, then
5531                     # the new attachment was already deleted above in the
5532                     # exception block and we have nothing more to do here. If
5533                     # swap_volume was successful in the driver, then we need to
5534                     # "detach" the original attachment by deleting it.
5535                     if not failed:
5536                         self.volume_api.attachment_delete(
5537                             context, bdm.attachment_id)
5538 
5539             # Need to make some decisions based on whether this was
5540             # a Cinder initiated migration or not. The callback to
5541             # migration completion isn't needed in the case of a
5542             # nova initiated simple swap of two volume
5543             # "volume-update" call so skip that. The new attachment
5544             # scenarios will give us a new attachment record and
5545             # that's what we want.
5546             if bdm.attachment_id and not is_cinder_migration:
5547                 # we don't callback to cinder
5548                 comp_ret = {'save_volume_id': new_volume_id}
5549             else:
5550                 # NOTE(lyarwood): The following call to
5551                 # os-migrate-volume-completion returns a dict containing
5552                 # save_volume_id, this volume id has two possible values :
5553                 # 1. old_volume_id if we are migrating (retyping) volumes
5554                 # 2. new_volume_id if we are swapping between two existing
5555                 #    volumes
5556                 # This volume id is later used to update the volume_id and
5557                 # connection_info['serial'] of the BDM.
5558                 comp_ret = self.volume_api.migrate_volume_completion(
5559                                                           context,
5560                                                           old_volume_id,
5561                                                           new_volume_id,
5562                                                           error=failed)
5563                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5564                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5565                           instance=instance)
5566 
5567         return (comp_ret, new_cinfo)
5568 
5569     @wrap_exception()
5570     @wrap_instance_event(prefix='compute')
5571     @wrap_instance_fault
5572     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
5573                     new_attachment_id=None):
5574         """Swap volume for an instance."""
5575         context = context.elevated()
5576 
5577         compute_utils.notify_about_volume_swap(
5578             context, instance, self.host,
5579             fields.NotificationAction.VOLUME_SWAP,
5580             fields.NotificationPhase.START,
5581             old_volume_id, new_volume_id)
5582 
5583         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5584                 context, old_volume_id, instance.uuid)
5585         connector = self.driver.get_volume_connector(instance)
5586 
5587         resize_to = 0
5588         old_volume = self.volume_api.get(context, old_volume_id)
5589         # Yes this is a tightly-coupled state check of what's going on inside
5590         # cinder, but we need this while we still support old (v1/v2) and
5591         # new style attachments (v3.44). Once we drop support for old style
5592         # attachments we could think about cleaning up the cinder-initiated
5593         # swap volume API flows.
5594         is_cinder_migration = (
5595             True if old_volume['status'] in ('retyping',
5596                                              'migrating') else False)
5597         old_vol_size = old_volume['size']
5598         new_volume = self.volume_api.get(context, new_volume_id)
5599         new_vol_size = new_volume['size']
5600         if new_vol_size > old_vol_size:
5601             resize_to = new_vol_size
5602 
5603         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5604                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5605                  instance=instance)
5606         comp_ret, new_cinfo = self._swap_volume(context,
5607                                                 instance,
5608                                                 bdm,
5609                                                 connector,
5610                                                 old_volume_id,
5611                                                 new_volume,
5612                                                 resize_to,
5613                                                 new_attachment_id,
5614                                                 is_cinder_migration)
5615 
5616         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5617         # correct volume_id returned by Cinder.
5618         save_volume_id = comp_ret['save_volume_id']
5619         new_cinfo['serial'] = save_volume_id
5620         values = {
5621             'connection_info': jsonutils.dumps(new_cinfo),
5622             'source_type': 'volume',
5623             'destination_type': 'volume',
5624             'snapshot_id': None,
5625             'volume_id': save_volume_id,
5626             'no_device': None}
5627 
5628         if resize_to:
5629             values['volume_size'] = resize_to
5630 
5631         if new_attachment_id is not None:
5632             # This was a volume swap for a new-style attachment so we
5633             # need to update the BDM attachment_id for the new attachment.
5634             values['attachment_id'] = new_attachment_id
5635 
5636         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5637                   "%(updates)s", {'volume_id': bdm.volume_id,
5638                                   'updates': values},
5639                   instance=instance)
5640         bdm.update(values)
5641         bdm.save()
5642 
5643         compute_utils.notify_about_volume_swap(
5644             context, instance, self.host,
5645             fields.NotificationAction.VOLUME_SWAP,
5646             fields.NotificationPhase.END,
5647             old_volume_id, new_volume_id)
5648 
5649     @wrap_exception()
5650     def remove_volume_connection(self, context, volume_id, instance):
5651         """Remove the volume connection on this host
5652 
5653         Detach the volume from this instance on this host, and if this is
5654         the cinder v2 flow, call cinder to terminate the connection.
5655         """
5656         try:
5657             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5658                     context, volume_id, instance.uuid)
5659             driver_bdm = driver_block_device.convert_volume(bdm)
5660             driver_bdm.driver_detach(context, instance,
5661                                      self.volume_api, self.driver)
5662             if bdm.attachment_id is None:
5663                 # cinder v2 api flow
5664                 connector = self.driver.get_volume_connector(instance)
5665                 self.volume_api.terminate_connection(context, volume_id,
5666                                                      connector)
5667         except exception.NotFound:
5668             pass
5669 
5670     @wrap_exception()
5671     @wrap_instance_event(prefix='compute')
5672     @wrap_instance_fault
5673     def attach_interface(self, context, instance, network_id, port_id,
5674                          requested_ip, tag=None):
5675         """Use hotplug to add an network adapter to an instance."""
5676         if not self.driver.capabilities['supports_attach_interface']:
5677             raise exception.AttachInterfaceNotSupported(
5678                 instance_uuid=instance.uuid)
5679         if (tag and not
5680             self.driver.capabilities.get('supports_tagged_attach_interface',
5681                                          False)):
5682             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5683 
5684         compute_utils.notify_about_instance_action(
5685             context, instance, self.host,
5686             action=fields.NotificationAction.INTERFACE_ATTACH,
5687             phase=fields.NotificationPhase.START)
5688 
5689         bind_host_id = self.driver.network_binding_host_id(context, instance)
5690         network_info = self.network_api.allocate_port_for_instance(
5691             context, instance, port_id, network_id, requested_ip,
5692             bind_host_id=bind_host_id, tag=tag)
5693         if len(network_info) != 1:
5694             LOG.error('allocate_port_for_instance returned %(ports)s '
5695                       'ports', {'ports': len(network_info)})
5696             # TODO(elod.illes): an instance.interface_attach.error notification
5697             # should be sent here
5698             raise exception.InterfaceAttachFailed(
5699                     instance_uuid=instance.uuid)
5700         image_meta = objects.ImageMeta.from_instance(instance)
5701 
5702         try:
5703             self.driver.attach_interface(context, instance, image_meta,
5704                                          network_info[0])
5705         except exception.NovaException as ex:
5706             port_id = network_info[0].get('id')
5707             LOG.warning("attach interface failed , try to deallocate "
5708                         "port %(port_id)s, reason: %(msg)s",
5709                         {'port_id': port_id, 'msg': ex},
5710                         instance=instance)
5711             try:
5712                 self.network_api.deallocate_port_for_instance(
5713                     context, instance, port_id)
5714             except Exception:
5715                 LOG.warning("deallocate port %(port_id)s failed",
5716                             {'port_id': port_id}, instance=instance)
5717 
5718             compute_utils.notify_about_instance_action(
5719                 context, instance, self.host,
5720                 action=fields.NotificationAction.INTERFACE_ATTACH,
5721                 phase=fields.NotificationPhase.ERROR,
5722                 exception=ex)
5723 
5724             raise exception.InterfaceAttachFailed(
5725                 instance_uuid=instance.uuid)
5726 
5727         compute_utils.notify_about_instance_action(
5728             context, instance, self.host,
5729             action=fields.NotificationAction.INTERFACE_ATTACH,
5730             phase=fields.NotificationPhase.END)
5731 
5732         return network_info[0]
5733 
5734     @wrap_exception()
5735     @wrap_instance_event(prefix='compute')
5736     @wrap_instance_fault
5737     def detach_interface(self, context, instance, port_id):
5738         """Detach a network adapter from an instance."""
5739         network_info = instance.info_cache.network_info
5740         condemned = None
5741         for vif in network_info:
5742             if vif['id'] == port_id:
5743                 condemned = vif
5744                 break
5745         if condemned is None:
5746             raise exception.PortNotFound(_("Port %s is not "
5747                                            "attached") % port_id)
5748 
5749         compute_utils.notify_about_instance_action(
5750             context, instance, self.host,
5751             action=fields.NotificationAction.INTERFACE_DETACH,
5752             phase=fields.NotificationPhase.START)
5753 
5754         try:
5755             self.driver.detach_interface(context, instance, condemned)
5756         except exception.NovaException as ex:
5757             LOG.warning("Detach interface failed, port_id=%(port_id)s,"
5758                         " reason: %(msg)s",
5759                         {'port_id': port_id, 'msg': ex}, instance=instance)
5760             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5761         else:
5762             try:
5763                 self.network_api.deallocate_port_for_instance(
5764                     context, instance, port_id)
5765             except Exception as ex:
5766                 with excutils.save_and_reraise_exception():
5767                     # Since this is a cast operation, log the failure for
5768                     # triage.
5769                     LOG.warning('Failed to deallocate port %(port_id)s '
5770                                 'for instance. Error: %(error)s',
5771                                 {'port_id': port_id, 'error': ex},
5772                                 instance=instance)
5773 
5774         compute_utils.notify_about_instance_action(
5775             context, instance, self.host,
5776             action=fields.NotificationAction.INTERFACE_DETACH,
5777             phase=fields.NotificationPhase.END)
5778 
5779     def _get_compute_info(self, context, host):
5780         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5781             context, host)
5782 
5783     @wrap_exception()
5784     def check_instance_shared_storage(self, ctxt, instance, data):
5785         """Check if the instance files are shared
5786 
5787         :param ctxt: security context
5788         :param instance: dict of instance data
5789         :param data: result of driver.check_instance_shared_storage_local
5790 
5791         Returns True if instance disks located on shared storage and
5792         False otherwise.
5793         """
5794         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5795 
5796     @wrap_exception()
5797     @wrap_instance_event(prefix='compute')
5798     @wrap_instance_fault
5799     def check_can_live_migrate_destination(self, ctxt, instance,
5800                                            block_migration, disk_over_commit):
5801         """Check if it is possible to execute live migration.
5802 
5803         This runs checks on the destination host, and then calls
5804         back to the source host to check the results.
5805 
5806         :param context: security context
5807         :param instance: dict of instance data
5808         :param block_migration: if true, prepare for block migration
5809                                 if None, calculate it in driver
5810         :param disk_over_commit: if true, allow disk over commit
5811                                  if None, ignore disk usage checking
5812         :returns: a dict containing migration info
5813         """
5814         return self._do_check_can_live_migrate_destination(ctxt, instance,
5815                                                             block_migration,
5816                                                             disk_over_commit)
5817 
5818     def _do_check_can_live_migrate_destination(self, ctxt, instance,
5819                                                block_migration,
5820                                                disk_over_commit):
5821         src_compute_info = obj_base.obj_to_primitive(
5822             self._get_compute_info(ctxt, instance.host))
5823         dst_compute_info = obj_base.obj_to_primitive(
5824             self._get_compute_info(ctxt, CONF.host))
5825         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5826             instance, src_compute_info, dst_compute_info,
5827             block_migration, disk_over_commit)
5828         LOG.debug('destination check data is %s', dest_check_data)
5829         try:
5830             migrate_data = self.compute_rpcapi.\
5831                                 check_can_live_migrate_source(ctxt, instance,
5832                                                               dest_check_data)
5833         finally:
5834             self.driver.cleanup_live_migration_destination_check(ctxt,
5835                     dest_check_data)
5836         return migrate_data
5837 
5838     @wrap_exception()
5839     @wrap_instance_event(prefix='compute')
5840     @wrap_instance_fault
5841     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5842         """Check if it is possible to execute live migration.
5843 
5844         This checks if the live migration can succeed, based on the
5845         results from check_can_live_migrate_destination.
5846 
5847         :param ctxt: security context
5848         :param instance: dict of instance data
5849         :param dest_check_data: result of check_can_live_migrate_destination
5850         :returns: a dict containing migration info
5851         """
5852         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5853             ctxt, instance.uuid)
5854         is_volume_backed = compute_utils.is_volume_backed_instance(
5855             ctxt, instance, bdms)
5856         # TODO(tdurakov): remove dict to object conversion once RPC API version
5857         # is bumped to 5.x
5858         got_migrate_data_object = isinstance(dest_check_data,
5859                                              migrate_data_obj.LiveMigrateData)
5860         if not got_migrate_data_object:
5861             dest_check_data = \
5862                 migrate_data_obj.LiveMigrateData.detect_implementation(
5863                     dest_check_data)
5864         dest_check_data.is_volume_backed = is_volume_backed
5865         block_device_info = self._get_instance_block_device_info(
5866                             ctxt, instance, refresh_conn_info=False, bdms=bdms)
5867         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5868                                                            dest_check_data,
5869                                                            block_device_info)
5870         if not got_migrate_data_object:
5871             result = result.to_legacy_dict()
5872         LOG.debug('source check data is %s', result)
5873         return result
5874 
5875     @wrap_exception()
5876     @wrap_instance_event(prefix='compute')
5877     @wrap_instance_fault
5878     def pre_live_migration(self, context, instance, block_migration, disk,
5879                            migrate_data):
5880         """Preparations for live migration at dest host.
5881 
5882         :param context: security context
5883         :param instance: dict of instance data
5884         :param block_migration: if true, prepare for block migration
5885         :param disk: disk info of instance
5886         :param migrate_data: A dict or LiveMigrateData object holding data
5887                              required for live migration without shared
5888                              storage.
5889         :returns: migrate_data containing additional migration info
5890         """
5891         LOG.debug('pre_live_migration data is %s', migrate_data)
5892         # TODO(tdurakov): remove dict to object conversion once RPC API version
5893         # is bumped to 5.x
5894         got_migrate_data_object = isinstance(migrate_data,
5895                                              migrate_data_obj.LiveMigrateData)
5896         if not got_migrate_data_object:
5897             migrate_data = \
5898                 migrate_data_obj.LiveMigrateData.detect_implementation(
5899                     migrate_data)
5900 
5901         migrate_data.old_vol_attachment_ids = {}
5902         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5903             context, instance.uuid)
5904         try:
5905             connector = self.driver.get_volume_connector(instance)
5906             for bdm in bdms:
5907                 if bdm.is_volume and bdm.attachment_id is not None:
5908                     # This bdm uses the new cinder v3.44 API.
5909                     # We will create a new attachment for this
5910                     # volume on this migration destination host. The old
5911                     # attachment will be deleted on the source host
5912                     # when the migration succeeds. The old attachment_id
5913                     # is stored in dict with the key being the bdm.volume_id
5914                     # so it can be restored on rollback.
5915                     #
5916                     # Also note that attachment_update is not needed as we
5917                     # are providing the connector in the create call.
5918                     attach_ref = self.volume_api.attachment_create(
5919                         context, bdm.volume_id, bdm.instance_uuid,
5920                         connector=connector, mountpoint=bdm.device_name)
5921 
5922                     # save current attachment so we can detach it on success,
5923                     # or restore it on a rollback.
5924                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
5925                         bdm.attachment_id
5926 
5927                     # update the bdm with the new attachment_id.
5928                     bdm.attachment_id = attach_ref['id']
5929                     bdm.save()
5930         except Exception:
5931             # If we raise, migrate_data with the updated attachment ids
5932             # will not be returned to the source host for rollback.
5933             # So we need to rollback new attachments here.
5934             with excutils.save_and_reraise_exception():
5935                 old_attachments = migrate_data.old_vol_attachment_ids
5936                 for bdm in bdms:
5937                     if (bdm.is_volume and bdm.attachment_id is not None and
5938                             bdm.volume_id in old_attachments):
5939                         self.volume_api.attachment_delete(context,
5940                                                           bdm.attachment_id)
5941                         bdm.attachment_id = old_attachments[bdm.volume_id]
5942                         bdm.save()
5943 
5944         block_device_info = self._get_instance_block_device_info(
5945                             context, instance, refresh_conn_info=True,
5946                             bdms=bdms)
5947 
5948         network_info = self.network_api.get_instance_nw_info(context, instance)
5949         self._notify_about_instance_usage(
5950                      context, instance, "live_migration.pre.start",
5951                      network_info=network_info)
5952         compute_utils.notify_about_instance_action(
5953             context, instance, self.host,
5954             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
5955             phase=fields.NotificationPhase.START)
5956 
5957         migrate_data = self.driver.pre_live_migration(context,
5958                                        instance,
5959                                        block_device_info,
5960                                        network_info,
5961                                        disk,
5962                                        migrate_data)
5963         LOG.debug('driver pre_live_migration data is %s', migrate_data)
5964 
5965         # Volume connections are complete, tell cinder that all the
5966         # attachments have completed.
5967         for bdm in bdms:
5968             if bdm.is_volume and bdm.attachment_id is not None:
5969                 self.volume_api.attachment_complete(context,
5970                                                     bdm.attachment_id)
5971 
5972         # NOTE(tr3buchet): setup networks on destination host
5973         self.network_api.setup_networks_on_host(context, instance,
5974                                                          self.host)
5975 
5976         # Creating filters to hypervisors and firewalls.
5977         # An example is that nova-instance-instance-xxx,
5978         # which is written to libvirt.xml(Check "virsh nwfilter-list")
5979         # This nwfilter is necessary on the destination host.
5980         # In addition, this method is creating filtering rule
5981         # onto destination host.
5982         self.driver.ensure_filtering_rules_for_instance(instance,
5983                                             network_info)
5984 
5985         self._notify_about_instance_usage(
5986                      context, instance, "live_migration.pre.end",
5987                      network_info=network_info)
5988         compute_utils.notify_about_instance_action(
5989             context, instance, self.host,
5990             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
5991             phase=fields.NotificationPhase.END)
5992 
5993         # TODO(tdurakov): remove dict to object conversion once RPC API version
5994         # is bumped to 5.x
5995         if not got_migrate_data_object and migrate_data:
5996             migrate_data = migrate_data.to_legacy_dict(
5997                 pre_migration_result=True)
5998             migrate_data = migrate_data['pre_live_migration_result']
5999         LOG.debug('pre_live_migration result data is %s', migrate_data)
6000         return migrate_data
6001 
6002     def _do_live_migration(self, context, dest, instance, block_migration,
6003                            migration, migrate_data):
6004         # NOTE(danms): We should enhance the RT to account for migrations
6005         # and use the status field to denote when the accounting has been
6006         # done on source/destination. For now, this is just here for status
6007         # reporting
6008         self._set_migration_status(migration, 'preparing')
6009 
6010         got_migrate_data_object = isinstance(migrate_data,
6011                                              migrate_data_obj.LiveMigrateData)
6012         if not got_migrate_data_object:
6013             migrate_data = \
6014                 migrate_data_obj.LiveMigrateData.detect_implementation(
6015                     migrate_data)
6016 
6017         try:
6018             if ('block_migration' in migrate_data and
6019                     migrate_data.block_migration):
6020                 block_device_info = self._get_instance_block_device_info(
6021                     context, instance)
6022                 disk = self.driver.get_instance_disk_info(
6023                     instance, block_device_info=block_device_info)
6024             else:
6025                 disk = None
6026 
6027             migrate_data = self.compute_rpcapi.pre_live_migration(
6028                 context, instance,
6029                 block_migration, disk, dest, migrate_data)
6030         except Exception:
6031             with excutils.save_and_reraise_exception():
6032                 LOG.exception('Pre live migration failed at %s',
6033                               dest, instance=instance)
6034                 self._set_migration_status(migration, 'error')
6035                 # Make sure we set this for _rollback_live_migration()
6036                 # so it can find it, as expected if it was called later
6037                 migrate_data.migration = migration
6038                 self._rollback_live_migration(context, instance, dest,
6039                                               migrate_data)
6040 
6041         self._set_migration_status(migration, 'running')
6042 
6043         if migrate_data:
6044             migrate_data.migration = migration
6045         LOG.debug('live_migration data is %s', migrate_data)
6046         try:
6047             self.driver.live_migration(context, instance, dest,
6048                                        self._post_live_migration,
6049                                        self._rollback_live_migration,
6050                                        block_migration, migrate_data)
6051         except Exception:
6052             LOG.exception('Live migration failed.', instance=instance)
6053             with excutils.save_and_reraise_exception():
6054                 # Put instance and migration into error state,
6055                 # as its almost certainly too late to rollback
6056                 self._set_migration_status(migration, 'error')
6057                 # first refresh instance as it may have got updated by
6058                 # post_live_migration_at_destination
6059                 instance.refresh()
6060                 self._set_instance_obj_error_state(context, instance,
6061                                                    clean_task_state=True)
6062 
6063     @wrap_exception()
6064     @wrap_instance_event(prefix='compute')
6065     @wrap_instance_fault
6066     def live_migration(self, context, dest, instance, block_migration,
6067                        migration, migrate_data):
6068         """Executing live migration.
6069 
6070         :param context: security context
6071         :param dest: destination host
6072         :param instance: a nova.objects.instance.Instance object
6073         :param block_migration: if true, prepare for block migration
6074         :param migration: an nova.objects.Migration object
6075         :param migrate_data: implementation specific params
6076 
6077         """
6078         self._set_migration_status(migration, 'queued')
6079 
6080         def dispatch_live_migration(*args, **kwargs):
6081             with self._live_migration_semaphore:
6082                 self._do_live_migration(*args, **kwargs)
6083 
6084         # NOTE(danms): We spawn here to return the RPC worker thread back to
6085         # the pool. Since what follows could take a really long time, we don't
6086         # want to tie up RPC workers.
6087         utils.spawn_n(dispatch_live_migration,
6088                       context, dest, instance,
6089                       block_migration, migration,
6090                       migrate_data)
6091 
6092     # TODO(tdurakov): migration_id is used since 4.12 rpc api version
6093     # remove migration_id parameter when the compute RPC version
6094     # is bumped to 5.x.
6095     @wrap_exception()
6096     @wrap_instance_event(prefix='compute')
6097     @wrap_instance_fault
6098     def live_migration_force_complete(self, context, instance,
6099                                       migration_id=None):
6100         """Force live migration to complete.
6101 
6102         :param context: Security context
6103         :param instance: The instance that is being migrated
6104         :param migration_id: ID of ongoing migration; is currently not used,
6105         and isn't removed for backward compatibility
6106         """
6107 
6108         self._notify_about_instance_usage(
6109             context, instance, 'live.migration.force.complete.start')
6110         self.driver.live_migration_force_complete(instance)
6111         self._notify_about_instance_usage(
6112             context, instance, 'live.migration.force.complete.end')
6113 
6114     @wrap_exception()
6115     @wrap_instance_event(prefix='compute')
6116     @wrap_instance_fault
6117     def live_migration_abort(self, context, instance, migration_id):
6118         """Abort an in-progress live migration.
6119 
6120         :param context: Security context
6121         :param instance: The instance that is being migrated
6122         :param migration_id: ID of in-progress live migration
6123 
6124         """
6125         migration = objects.Migration.get_by_id(context, migration_id)
6126         if migration.status != 'running':
6127             raise exception.InvalidMigrationState(migration_id=migration_id,
6128                     instance_uuid=instance.uuid,
6129                     state=migration.status,
6130                     method='abort live migration')
6131 
6132         self._notify_about_instance_usage(
6133             context, instance, 'live.migration.abort.start')
6134         compute_utils.notify_about_instance_action(
6135             context, instance, self.host,
6136             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6137             phase=fields.NotificationPhase.START)
6138         self.driver.live_migration_abort(instance)
6139         self._notify_about_instance_usage(
6140             context, instance, 'live.migration.abort.end')
6141         compute_utils.notify_about_instance_action(
6142             context, instance, self.host,
6143             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6144             phase=fields.NotificationPhase.END)
6145 
6146     def _live_migration_cleanup_flags(self, migrate_data):
6147         """Determine whether disks or instance path need to be cleaned up after
6148         live migration (at source on success, at destination on rollback)
6149 
6150         Block migration needs empty image at destination host before migration
6151         starts, so if any failure occurs, any empty images has to be deleted.
6152 
6153         Also Volume backed live migration w/o shared storage needs to delete
6154         newly created instance-xxx dir on the destination as a part of its
6155         rollback process
6156 
6157         :param migrate_data: implementation specific data
6158         :returns: (bool, bool) -- do_cleanup, destroy_disks
6159         """
6160         # NOTE(pkoniszewski): block migration specific params are set inside
6161         # migrate_data objects for drivers that expose block live migration
6162         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6163         # cleanup is not needed.
6164         is_shared_block_storage = True
6165         is_shared_instance_path = True
6166         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6167             is_shared_block_storage = migrate_data.is_shared_block_storage
6168             is_shared_instance_path = migrate_data.is_shared_instance_path
6169         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6170             is_shared_block_storage = not migrate_data.block_migration
6171             is_shared_instance_path = not migrate_data.block_migration
6172         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6173             is_shared_instance_path = migrate_data.is_shared_instance_path
6174             is_shared_block_storage = migrate_data.is_shared_instance_path
6175 
6176         # No instance booting at source host, but instance dir
6177         # must be deleted for preparing next block migration
6178         # must be deleted for preparing next live migration w/o shared storage
6179         do_cleanup = not is_shared_instance_path
6180         destroy_disks = not is_shared_block_storage
6181 
6182         return (do_cleanup, destroy_disks)
6183 
6184     @wrap_exception()
6185     @wrap_instance_fault
6186     def _post_live_migration(self, ctxt, instance,
6187                             dest, block_migration=False, migrate_data=None):
6188         """Post operations for live migration.
6189 
6190         This method is called from live_migration
6191         and mainly updating database record.
6192 
6193         :param ctxt: security context
6194         :param instance: instance dict
6195         :param dest: destination host
6196         :param block_migration: if true, prepare for block migration
6197         :param migrate_data: if not None, it is a dict which has data
6198         required for live migration without shared storage
6199 
6200         """
6201         LOG.info('_post_live_migration() is started..',
6202                  instance=instance)
6203 
6204         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6205                 ctxt, instance.uuid)
6206 
6207         # Cleanup source host post live-migration
6208         block_device_info = self._get_instance_block_device_info(
6209                             ctxt, instance, bdms=bdms)
6210         self.driver.post_live_migration(ctxt, instance, block_device_info,
6211                                         migrate_data)
6212 
6213         # Detaching volumes.
6214         connector = self.driver.get_volume_connector(instance)
6215         for bdm in bdms:
6216             if bdm.is_volume:
6217                 if bdm.attachment_id is None:
6218                     # Prior to cinder v3.44:
6219                     # We don't want to actually mark the volume detached, or
6220                     # delete the bdm, just remove the connection from this
6221                     # host.
6222                     #
6223                     # remove the volume connection without detaching from
6224                     # hypervisor because the instance is not running anymore
6225                     # on the current host
6226                     self.volume_api.terminate_connection(ctxt, bdm.volume_id,
6227                                                          connector)
6228                 else:
6229                     # cinder v3.44 api flow - delete the old attachment
6230                     # for the source host
6231                     old_attachment_id = \
6232                         migrate_data.old_vol_attachment_ids[bdm.volume_id]
6233                     self.volume_api.attachment_delete(ctxt, old_attachment_id)
6234 
6235         # Releasing vlan.
6236         # (not necessary in current implementation?)
6237 
6238         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
6239 
6240         self._notify_about_instance_usage(ctxt, instance,
6241                                           "live_migration._post.start",
6242                                           network_info=network_info)
6243         # Releasing security group ingress rule.
6244         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
6245                   instance=instance)
6246         self.driver.unfilter_instance(instance,
6247                                       network_info)
6248 
6249         migration = {'source_compute': self.host,
6250                      'dest_compute': dest, }
6251         self.network_api.migrate_instance_start(ctxt,
6252                                                 instance,
6253                                                 migration)
6254 
6255         destroy_vifs = False
6256         try:
6257             self.driver.post_live_migration_at_source(ctxt, instance,
6258                                                       network_info)
6259         except NotImplementedError as ex:
6260             LOG.debug(ex, instance=instance)
6261             # For all hypervisors other than libvirt, there is a possibility
6262             # they are unplugging networks from source node in the cleanup
6263             # method
6264             destroy_vifs = True
6265 
6266         # NOTE(danms): Save source node before calling post method on
6267         # destination, which will update it
6268         source_node = instance.node
6269 
6270         # Define domain at destination host, without doing it,
6271         # pause/suspend/terminate do not work.
6272         post_at_dest_success = True
6273         try:
6274             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
6275                     instance, block_migration, dest)
6276         except Exception as error:
6277             post_at_dest_success = False
6278             # We don't want to break _post_live_migration() if
6279             # post_live_migration_at_destination() fails as it should never
6280             # affect cleaning up source node.
6281             LOG.exception("Post live migration at destination %s failed",
6282                           dest, instance=instance, error=error)
6283 
6284         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6285                 migrate_data)
6286 
6287         if do_cleanup:
6288             LOG.debug('Calling driver.cleanup from _post_live_migration',
6289                       instance=instance)
6290             self.driver.cleanup(ctxt, instance, network_info,
6291                                 destroy_disks=destroy_disks,
6292                                 migrate_data=migrate_data,
6293                                 destroy_vifs=destroy_vifs)
6294 
6295         self.instance_events.clear_events_for_instance(instance)
6296 
6297         # NOTE(timello): make sure we update available resources on source
6298         # host even before next periodic task.
6299         self.update_available_resource(ctxt)
6300 
6301         self._update_scheduler_instance_info(ctxt, instance)
6302         self._notify_about_instance_usage(ctxt, instance,
6303                                           "live_migration._post.end",
6304                                           network_info=network_info)
6305         if post_at_dest_success:
6306             LOG.info('Migrating instance to %s finished successfully.',
6307                      dest, instance=instance)
6308 
6309         if migrate_data and migrate_data.obj_attr_is_set('migration'):
6310             migrate_data.migration.status = 'completed'
6311             migrate_data.migration.save()
6312             migration = migrate_data.migration
6313             rc = self.scheduler_client.reportclient
6314             # Check to see if our migration has its own allocations
6315             allocs = rc.get_allocations_for_consumer(migration.uuid)
6316         else:
6317             # We didn't have data on a migration, which means we can't
6318             # look up to see if we had new-style migration-based
6319             # allocations. This should really only happen in cases of
6320             # a buggy virt driver or some really old component in the
6321             # system. Log a warning so we know it happened.
6322             allocs = None
6323             LOG.warning('Live migration ended with no migrate_data '
6324                         'record. Unable to clean up migration-based '
6325                         'allocations which is almost certainly not '
6326                         'an expected situation.')
6327 
6328         if allocs:
6329             # We had a migration-based allocation that we need to handle
6330             self._delete_allocation_after_move(ctxt,
6331                                                instance,
6332                                                migrate_data.migration,
6333                                                instance.flavor,
6334                                                source_node)
6335         else:
6336             # No migration-based allocations, so do the old thing and
6337             # attempt to clean up any doubled per-instance allocation
6338             rt = self._get_resource_tracker()
6339             rt.delete_allocation_for_migrated_instance(
6340                 instance, source_node)
6341 
6342     def _consoles_enabled(self):
6343         """Returns whether a console is enable."""
6344         return (CONF.vnc.enabled or CONF.spice.enabled or
6345                 CONF.rdp.enabled or CONF.serial_console.enabled or
6346                 CONF.mks.enabled)
6347 
6348     @wrap_exception()
6349     @wrap_instance_event(prefix='compute')
6350     @wrap_instance_fault
6351     def post_live_migration_at_destination(self, context, instance,
6352                                            block_migration):
6353         """Post operations for live migration .
6354 
6355         :param context: security context
6356         :param instance: Instance dict
6357         :param block_migration: if true, prepare for block migration
6358 
6359         """
6360         LOG.info('Post operation of migration started',
6361                  instance=instance)
6362 
6363         # NOTE(tr3buchet): setup networks on destination host
6364         #                  this is called a second time because
6365         #                  multi_host does not create the bridge in
6366         #                  plug_vifs
6367         self.network_api.setup_networks_on_host(context, instance,
6368                                                          self.host)
6369         migration = {'source_compute': instance.host,
6370                      'dest_compute': self.host, }
6371         self.network_api.migrate_instance_finish(context,
6372                                                  instance,
6373                                                  migration)
6374 
6375         network_info = self.network_api.get_instance_nw_info(context, instance)
6376         self._notify_about_instance_usage(
6377                      context, instance, "live_migration.post.dest.start",
6378                      network_info=network_info)
6379         block_device_info = self._get_instance_block_device_info(context,
6380                                                                  instance)
6381 
6382         try:
6383             self.driver.post_live_migration_at_destination(
6384                 context, instance, network_info, block_migration,
6385                 block_device_info)
6386         except Exception:
6387             with excutils.save_and_reraise_exception():
6388                 instance.vm_state = vm_states.ERROR
6389                 LOG.error('Unexpected error during post live migration at '
6390                           'destination host.', instance=instance)
6391         finally:
6392             # Restore instance state and update host
6393             current_power_state = self._get_power_state(context, instance)
6394             node_name = None
6395             prev_host = instance.host
6396             try:
6397                 compute_node = self._get_compute_info(context, self.host)
6398                 node_name = compute_node.hypervisor_hostname
6399             except exception.ComputeHostNotFound:
6400                 LOG.exception('Failed to get compute_info for %s', self.host)
6401             finally:
6402                 instance.host = self.host
6403                 instance.power_state = current_power_state
6404                 instance.task_state = None
6405                 instance.node = node_name
6406                 instance.progress = 0
6407                 instance.save(expected_task_state=task_states.MIGRATING)
6408 
6409         # NOTE(tr3buchet): tear down networks on source host
6410         self.network_api.setup_networks_on_host(context, instance,
6411                                                 prev_host, teardown=True)
6412         # NOTE(vish): this is necessary to update dhcp
6413         self.network_api.setup_networks_on_host(context, instance, self.host)
6414         self._notify_about_instance_usage(
6415                      context, instance, "live_migration.post.dest.end",
6416                      network_info=network_info)
6417 
6418     @wrap_exception()
6419     @wrap_instance_fault
6420     def _rollback_live_migration(self, context, instance,
6421                                  dest, migrate_data=None,
6422                                  migration_status='error'):
6423         """Recovers Instance/volume state from migrating -> running.
6424 
6425         :param context: security context
6426         :param instance: nova.objects.instance.Instance object
6427         :param dest:
6428             This method is called from live migration src host.
6429             This param specifies destination host.
6430         :param migrate_data:
6431             if not none, contains implementation specific data.
6432         :param migration_status:
6433             Contains the status we want to set for the migration object
6434 
6435         """
6436         # TODO(tdurakov): remove dict to object conversion once RPC API version
6437         # is bumped to 5.x
6438         if isinstance(migrate_data, dict):
6439             migration = migrate_data.pop('migration', None)
6440             migrate_data = \
6441                 migrate_data_obj.LiveMigrateData.detect_implementation(
6442                     migrate_data)
6443         elif (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
6444               migrate_data.obj_attr_is_set('migration')):
6445             migration = migrate_data.migration
6446         else:
6447             migration = None
6448 
6449         if migration:
6450             # Remove allocations created in Placement for the dest node.
6451             # If migration is None, we must be so old we don't have placement,
6452             # so no need to do something else.
6453             self._revert_allocation(context, instance, migration)
6454         else:
6455             LOG.error('Unable to revert allocations during live migration '
6456                       'rollback; compute driver did not provide migrate_data',
6457                       instance=instance)
6458 
6459         instance.task_state = None
6460         instance.progress = 0
6461         instance.save(expected_task_state=[task_states.MIGRATING])
6462 
6463         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
6464         self.network_api.setup_networks_on_host(context, instance, self.host)
6465 
6466         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6467                 context, instance.uuid)
6468         for bdm in bdms:
6469             if bdm.is_volume:
6470                 # remove the connection on the destination host
6471                 self.compute_rpcapi.remove_volume_connection(
6472                         context, instance, bdm.volume_id, dest)
6473 
6474                 if bdm.attachment_id:
6475                     # 3.44 cinder api flow. Set the bdm's
6476                     # attachment_id to the old attachment of the source
6477                     # host. If old_attachments is not there, then
6478                     # there was an error before the new attachment was made.
6479                     old_attachments = migrate_data.old_vol_attachment_ids \
6480                         if 'old_vol_attachment_ids' in migrate_data else None
6481                     if old_attachments and bdm.volume_id in old_attachments:
6482                         self.volume_api.attachment_delete(context,
6483                                                           bdm.attachment_id)
6484                         bdm.attachment_id = old_attachments[bdm.volume_id]
6485                         bdm.save()
6486 
6487         self._notify_about_instance_usage(context, instance,
6488                                           "live_migration._rollback.start")
6489         compute_utils.notify_about_instance_action(context, instance,
6490                 self.host,
6491                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6492                 phase=fields.NotificationPhase.START,
6493                 bdms=bdms)
6494 
6495         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6496                 migrate_data)
6497 
6498         if do_cleanup:
6499             self.compute_rpcapi.rollback_live_migration_at_destination(
6500                     context, instance, dest, destroy_disks=destroy_disks,
6501                     migrate_data=migrate_data)
6502 
6503         self._notify_about_instance_usage(context, instance,
6504                                           "live_migration._rollback.end")
6505         compute_utils.notify_about_instance_action(context, instance,
6506 
6507                 self.host,
6508                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6509                 phase=fields.NotificationPhase.END,
6510                 bdms=bdms)
6511 
6512         self._set_migration_status(migration, migration_status)
6513 
6514     @wrap_exception()
6515     @wrap_instance_event(prefix='compute')
6516     @wrap_instance_fault
6517     def rollback_live_migration_at_destination(self, context, instance,
6518                                                destroy_disks,
6519                                                migrate_data):
6520         """Cleaning up image directory that is created pre_live_migration.
6521 
6522         :param context: security context
6523         :param instance: a nova.objects.instance.Instance object sent over rpc
6524         :param destroy_disks: whether to destroy volumes or not
6525         :param migrate_data: contains migration info
6526         """
6527         network_info = self.network_api.get_instance_nw_info(context, instance)
6528         self._notify_about_instance_usage(
6529                       context, instance, "live_migration.rollback.dest.start",
6530                       network_info=network_info)
6531         try:
6532             # NOTE(tr3buchet): tear down networks on destination host
6533             self.network_api.setup_networks_on_host(context, instance,
6534                                                     self.host, teardown=True)
6535         except Exception:
6536             with excutils.save_and_reraise_exception():
6537                 # NOTE(tdurakov): even if teardown networks fails driver
6538                 # should try to rollback live migration on destination.
6539                 LOG.exception('An error occurred while deallocating network.',
6540                               instance=instance)
6541         finally:
6542             # always run this even if setup_networks_on_host fails
6543             # NOTE(vish): The mapping is passed in so the driver can disconnect
6544             #             from remote volumes if necessary
6545             block_device_info = self._get_instance_block_device_info(context,
6546                                                                      instance)
6547             # TODO(tdurakov): remove dict to object conversion once RPC API
6548             # version is bumped to 5.x
6549             if isinstance(migrate_data, dict):
6550                 migrate_data = \
6551                     migrate_data_obj.LiveMigrateData.detect_implementation(
6552                         migrate_data)
6553             self.driver.rollback_live_migration_at_destination(
6554                 context, instance, network_info, block_device_info,
6555                 destroy_disks=destroy_disks, migrate_data=migrate_data)
6556 
6557         self._notify_about_instance_usage(
6558                         context, instance, "live_migration.rollback.dest.end",
6559                         network_info=network_info)
6560 
6561     @periodic_task.periodic_task(
6562         spacing=CONF.heal_instance_info_cache_interval)
6563     def _heal_instance_info_cache(self, context):
6564         """Called periodically.  On every call, try to update the
6565         info_cache's network information for another instance by
6566         calling to the network manager.
6567 
6568         This is implemented by keeping a cache of uuids of instances
6569         that live on this host.  On each call, we pop one off of a
6570         list, pull the DB record, and try the call to the network API.
6571         If anything errors don't fail, as it's possible the instance
6572         has been deleted, etc.
6573         """
6574         heal_interval = CONF.heal_instance_info_cache_interval
6575         if not heal_interval:
6576             return
6577 
6578         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
6579         instance = None
6580 
6581         LOG.debug('Starting heal instance info cache')
6582 
6583         if not instance_uuids:
6584             # The list of instances to heal is empty so rebuild it
6585             LOG.debug('Rebuilding the list of instances to heal')
6586             db_instances = objects.InstanceList.get_by_host(
6587                 context, self.host, expected_attrs=[], use_slave=True)
6588             for inst in db_instances:
6589                 # We don't want to refresh the cache for instances
6590                 # which are building or deleting so don't put them
6591                 # in the list. If they are building they will get
6592                 # added to the list next time we build it.
6593                 if (inst.vm_state == vm_states.BUILDING):
6594                     LOG.debug('Skipping network cache update for instance '
6595                               'because it is Building.', instance=inst)
6596                     continue
6597                 if (inst.task_state == task_states.DELETING):
6598                     LOG.debug('Skipping network cache update for instance '
6599                               'because it is being deleted.', instance=inst)
6600                     continue
6601 
6602                 if not instance:
6603                     # Save the first one we find so we don't
6604                     # have to get it again
6605                     instance = inst
6606                 else:
6607                     instance_uuids.append(inst['uuid'])
6608 
6609             self._instance_uuids_to_heal = instance_uuids
6610         else:
6611             # Find the next valid instance on the list
6612             while instance_uuids:
6613                 try:
6614                     inst = objects.Instance.get_by_uuid(
6615                             context, instance_uuids.pop(0),
6616                             expected_attrs=['system_metadata', 'info_cache',
6617                                             'flavor'],
6618                             use_slave=True)
6619                 except exception.InstanceNotFound:
6620                     # Instance is gone.  Try to grab another.
6621                     continue
6622 
6623                 # Check the instance hasn't been migrated
6624                 if inst.host != self.host:
6625                     LOG.debug('Skipping network cache update for instance '
6626                               'because it has been migrated to another '
6627                               'host.', instance=inst)
6628                 # Check the instance isn't being deleting
6629                 elif inst.task_state == task_states.DELETING:
6630                     LOG.debug('Skipping network cache update for instance '
6631                               'because it is being deleted.', instance=inst)
6632                 else:
6633                     instance = inst
6634                     break
6635 
6636         if instance:
6637             # We have an instance now to refresh
6638             try:
6639                 # Call to network API to get instance info.. this will
6640                 # force an update to the instance's info_cache
6641                 self.network_api.get_instance_nw_info(context, instance)
6642                 LOG.debug('Updated the network info_cache for instance',
6643                           instance=instance)
6644             except exception.InstanceNotFound:
6645                 # Instance is gone.
6646                 LOG.debug('Instance no longer exists. Unable to refresh',
6647                           instance=instance)
6648                 return
6649             except exception.InstanceInfoCacheNotFound:
6650                 # InstanceInfoCache is gone.
6651                 LOG.debug('InstanceInfoCache no longer exists. '
6652                           'Unable to refresh', instance=instance)
6653             except Exception:
6654                 LOG.error('An error occurred while refreshing the network '
6655                           'cache.', instance=instance, exc_info=True)
6656         else:
6657             LOG.debug("Didn't find any instances for network info cache "
6658                       "update.")
6659 
6660     @periodic_task.periodic_task
6661     def _poll_rebooting_instances(self, context):
6662         if CONF.reboot_timeout > 0:
6663             filters = {'task_state':
6664                        [task_states.REBOOTING,
6665                         task_states.REBOOT_STARTED,
6666                         task_states.REBOOT_PENDING],
6667                        'host': self.host}
6668             rebooting = objects.InstanceList.get_by_filters(
6669                 context, filters, expected_attrs=[], use_slave=True)
6670 
6671             to_poll = []
6672             for instance in rebooting:
6673                 if timeutils.is_older_than(instance.updated_at,
6674                                            CONF.reboot_timeout):
6675                     to_poll.append(instance)
6676 
6677             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
6678 
6679     @periodic_task.periodic_task
6680     def _poll_rescued_instances(self, context):
6681         if CONF.rescue_timeout > 0:
6682             filters = {'vm_state': vm_states.RESCUED,
6683                        'host': self.host}
6684             rescued_instances = objects.InstanceList.get_by_filters(
6685                 context, filters, expected_attrs=["system_metadata"],
6686                 use_slave=True)
6687 
6688             to_unrescue = []
6689             for instance in rescued_instances:
6690                 if timeutils.is_older_than(instance.launched_at,
6691                                            CONF.rescue_timeout):
6692                     to_unrescue.append(instance)
6693 
6694             for instance in to_unrescue:
6695                 self.compute_api.unrescue(context, instance)
6696 
6697     @periodic_task.periodic_task
6698     def _poll_unconfirmed_resizes(self, context):
6699         if CONF.resize_confirm_window == 0:
6700             return
6701 
6702         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
6703                 context, CONF.resize_confirm_window, self.host,
6704                 use_slave=True)
6705 
6706         migrations_info = dict(migration_count=len(migrations),
6707                 confirm_window=CONF.resize_confirm_window)
6708 
6709         if migrations_info["migration_count"] > 0:
6710             LOG.info("Found %(migration_count)d unconfirmed migrations "
6711                      "older than %(confirm_window)d seconds",
6712                      migrations_info)
6713 
6714         def _set_migration_to_error(migration, reason, **kwargs):
6715             LOG.warning("Setting migration %(migration_id)s to error: "
6716                         "%(reason)s",
6717                         {'migration_id': migration['id'], 'reason': reason},
6718                         **kwargs)
6719             migration.status = 'error'
6720             with migration.obj_as_admin():
6721                 migration.save()
6722 
6723         for migration in migrations:
6724             instance_uuid = migration.instance_uuid
6725             LOG.info("Automatically confirming migration "
6726                      "%(migration_id)s for instance %(instance_uuid)s",
6727                      {'migration_id': migration.id,
6728                       'instance_uuid': instance_uuid})
6729             expected_attrs = ['metadata', 'system_metadata']
6730             try:
6731                 instance = objects.Instance.get_by_uuid(context,
6732                             instance_uuid, expected_attrs=expected_attrs,
6733                             use_slave=True)
6734             except exception.InstanceNotFound:
6735                 reason = (_("Instance %s not found") %
6736                           instance_uuid)
6737                 _set_migration_to_error(migration, reason)
6738                 continue
6739             if instance.vm_state == vm_states.ERROR:
6740                 reason = _("In ERROR state")
6741                 _set_migration_to_error(migration, reason,
6742                                         instance=instance)
6743                 continue
6744             # race condition: The instance in DELETING state should not be
6745             # set the migration state to error, otherwise the instance in
6746             # to be deleted which is in RESIZED state
6747             # will not be able to confirm resize
6748             if instance.task_state in [task_states.DELETING,
6749                                        task_states.SOFT_DELETING]:
6750                 msg = ("Instance being deleted or soft deleted during resize "
6751                        "confirmation. Skipping.")
6752                 LOG.debug(msg, instance=instance)
6753                 continue
6754 
6755             # race condition: This condition is hit when this method is
6756             # called between the save of the migration record with a status of
6757             # finished and the save of the instance object with a state of
6758             # RESIZED. The migration record should not be set to error.
6759             if instance.task_state == task_states.RESIZE_FINISH:
6760                 msg = ("Instance still resizing during resize "
6761                        "confirmation. Skipping.")
6762                 LOG.debug(msg, instance=instance)
6763                 continue
6764 
6765             vm_state = instance.vm_state
6766             task_state = instance.task_state
6767             if vm_state != vm_states.RESIZED or task_state is not None:
6768                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
6769                            "RESIZED/None") %
6770                           {'vm_state': vm_state,
6771                            'task_state': task_state})
6772                 _set_migration_to_error(migration, reason,
6773                                         instance=instance)
6774                 continue
6775             try:
6776                 self.compute_api.confirm_resize(context, instance,
6777                                                 migration=migration)
6778             except Exception as e:
6779                 LOG.info("Error auto-confirming resize: %s. "
6780                          "Will retry later.", e, instance=instance)
6781 
6782     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
6783     def _poll_shelved_instances(self, context):
6784 
6785         if CONF.shelved_offload_time <= 0:
6786             return
6787 
6788         filters = {'vm_state': vm_states.SHELVED,
6789                    'task_state': None,
6790                    'host': self.host}
6791         shelved_instances = objects.InstanceList.get_by_filters(
6792             context, filters=filters, expected_attrs=['system_metadata'],
6793             use_slave=True)
6794 
6795         to_gc = []
6796         for instance in shelved_instances:
6797             sys_meta = instance.system_metadata
6798             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
6799             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
6800                 to_gc.append(instance)
6801 
6802         for instance in to_gc:
6803             try:
6804                 instance.task_state = task_states.SHELVING_OFFLOADING
6805                 instance.save(expected_task_state=(None,))
6806                 self.shelve_offload_instance(context, instance,
6807                                              clean_shutdown=False)
6808             except Exception:
6809                 LOG.exception('Periodic task failed to offload instance.',
6810                               instance=instance)
6811 
6812     @periodic_task.periodic_task
6813     def _instance_usage_audit(self, context):
6814         if not CONF.instance_usage_audit:
6815             return
6816 
6817         begin, end = utils.last_completed_audit_period()
6818         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
6819                                self.host):
6820             return
6821 
6822         instances = objects.InstanceList.get_active_by_window_joined(
6823             context, begin, end, host=self.host,
6824             expected_attrs=['system_metadata', 'info_cache', 'metadata',
6825                             'flavor'],
6826             use_slave=True)
6827         num_instances = len(instances)
6828         errors = 0
6829         successes = 0
6830         LOG.info("Running instance usage audit for host %(host)s "
6831                  "from %(begin_time)s to %(end_time)s. "
6832                  "%(number_instances)s instances.",
6833                  {'host': self.host,
6834                   'begin_time': begin,
6835                   'end_time': end,
6836                   'number_instances': num_instances})
6837         start_time = time.time()
6838         task_log = objects.TaskLog(context)
6839         task_log.task_name = 'instance_usage_audit'
6840         task_log.period_beginning = begin
6841         task_log.period_ending = end
6842         task_log.host = self.host
6843         task_log.task_items = num_instances
6844         task_log.message = 'Instance usage audit started...'
6845         task_log.begin_task()
6846         for instance in instances:
6847             try:
6848                 compute_utils.notify_usage_exists(
6849                     self.notifier, context, instance,
6850                     ignore_missing_network_data=False)
6851                 successes += 1
6852             except Exception:
6853                 LOG.exception('Failed to generate usage '
6854                               'audit for instance '
6855                               'on host %s', self.host,
6856                               instance=instance)
6857                 errors += 1
6858         task_log.errors = errors
6859         task_log.message = (
6860             'Instance usage audit ran for host %s, %s instances in %s seconds.'
6861             % (self.host, num_instances, time.time() - start_time))
6862         task_log.end_task()
6863 
6864     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
6865     def _poll_bandwidth_usage(self, context):
6866 
6867         if not self._bw_usage_supported:
6868             return
6869 
6870         prev_time, start_time = utils.last_completed_audit_period()
6871 
6872         curr_time = time.time()
6873         if (curr_time - self._last_bw_usage_poll >
6874                 CONF.bandwidth_poll_interval):
6875             self._last_bw_usage_poll = curr_time
6876             LOG.info("Updating bandwidth usage cache")
6877             cells_update_interval = CONF.cells.bandwidth_update_interval
6878             if (cells_update_interval > 0 and
6879                    curr_time - self._last_bw_usage_cell_update >
6880                            cells_update_interval):
6881                 self._last_bw_usage_cell_update = curr_time
6882                 update_cells = True
6883             else:
6884                 update_cells = False
6885 
6886             instances = objects.InstanceList.get_by_host(context,
6887                                                               self.host,
6888                                                               use_slave=True)
6889             try:
6890                 bw_counters = self.driver.get_all_bw_counters(instances)
6891             except NotImplementedError:
6892                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
6893                 # implemented yet.  If they don't it doesn't break anything,
6894                 # they just don't get the info in the usage events.
6895                 # NOTE(PhilDay): Record that its not supported so we can
6896                 # skip fast on future calls rather than waste effort getting
6897                 # the list of instances.
6898                 LOG.info("Bandwidth usage not supported by %(driver)s.",
6899                          {'driver': CONF.compute_driver})
6900                 self._bw_usage_supported = False
6901                 return
6902 
6903             refreshed = timeutils.utcnow()
6904             for bw_ctr in bw_counters:
6905                 # Allow switching of greenthreads between queries.
6906                 greenthread.sleep(0)
6907                 bw_in = 0
6908                 bw_out = 0
6909                 last_ctr_in = None
6910                 last_ctr_out = None
6911                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6912                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6913                     start_period=start_time, use_slave=True)
6914                 if usage:
6915                     bw_in = usage.bw_in
6916                     bw_out = usage.bw_out
6917                     last_ctr_in = usage.last_ctr_in
6918                     last_ctr_out = usage.last_ctr_out
6919                 else:
6920                     usage = (objects.BandwidthUsage.
6921                              get_by_instance_uuid_and_mac(
6922                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6923                         start_period=prev_time, use_slave=True))
6924                     if usage:
6925                         last_ctr_in = usage.last_ctr_in
6926                         last_ctr_out = usage.last_ctr_out
6927 
6928                 if last_ctr_in is not None:
6929                     if bw_ctr['bw_in'] < last_ctr_in:
6930                         # counter rollover
6931                         bw_in += bw_ctr['bw_in']
6932                     else:
6933                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6934 
6935                 if last_ctr_out is not None:
6936                     if bw_ctr['bw_out'] < last_ctr_out:
6937                         # counter rollover
6938                         bw_out += bw_ctr['bw_out']
6939                     else:
6940                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6941 
6942                 objects.BandwidthUsage(context=context).create(
6943                                               bw_ctr['uuid'],
6944                                               bw_ctr['mac_address'],
6945                                               bw_in,
6946                                               bw_out,
6947                                               bw_ctr['bw_in'],
6948                                               bw_ctr['bw_out'],
6949                                               start_period=start_time,
6950                                               last_refreshed=refreshed,
6951                                               update_cells=update_cells)
6952 
6953     def _get_host_volume_bdms(self, context, use_slave=False):
6954         """Return all block device mappings on a compute host."""
6955         compute_host_bdms = []
6956         instances = objects.InstanceList.get_by_host(context, self.host,
6957             use_slave=use_slave)
6958         for instance in instances:
6959             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6960                     context, instance.uuid, use_slave=use_slave)
6961             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6962             compute_host_bdms.append(dict(instance=instance,
6963                                           instance_bdms=instance_bdms))
6964 
6965         return compute_host_bdms
6966 
6967     def _update_volume_usage_cache(self, context, vol_usages):
6968         """Updates the volume usage cache table with a list of stats."""
6969         for usage in vol_usages:
6970             # Allow switching of greenthreads between queries.
6971             greenthread.sleep(0)
6972             vol_usage = objects.VolumeUsage(context)
6973             vol_usage.volume_id = usage['volume']
6974             vol_usage.instance_uuid = usage['instance'].uuid
6975             vol_usage.project_id = usage['instance'].project_id
6976             vol_usage.user_id = usage['instance'].user_id
6977             vol_usage.availability_zone = usage['instance'].availability_zone
6978             vol_usage.curr_reads = usage['rd_req']
6979             vol_usage.curr_read_bytes = usage['rd_bytes']
6980             vol_usage.curr_writes = usage['wr_req']
6981             vol_usage.curr_write_bytes = usage['wr_bytes']
6982             vol_usage.save()
6983             self.notifier.info(context, 'volume.usage',
6984                                compute_utils.usage_volume_info(vol_usage))
6985 
6986     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
6987     def _poll_volume_usage(self, context):
6988         if CONF.volume_usage_poll_interval == 0:
6989             return
6990 
6991         compute_host_bdms = self._get_host_volume_bdms(context,
6992                                                        use_slave=True)
6993         if not compute_host_bdms:
6994             return
6995 
6996         LOG.debug("Updating volume usage cache")
6997         try:
6998             vol_usages = self.driver.get_all_volume_usage(context,
6999                                                           compute_host_bdms)
7000         except NotImplementedError:
7001             return
7002 
7003         self._update_volume_usage_cache(context, vol_usages)
7004 
7005     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
7006                                  run_immediately=True)
7007     def _sync_power_states(self, context):
7008         """Align power states between the database and the hypervisor.
7009 
7010         To sync power state data we make a DB call to get the number of
7011         virtual machines known by the hypervisor and if the number matches the
7012         number of virtual machines known by the database, we proceed in a lazy
7013         loop, one database record at a time, checking if the hypervisor has the
7014         same power state as is in the database.
7015         """
7016         db_instances = objects.InstanceList.get_by_host(context, self.host,
7017                                                         expected_attrs=[],
7018                                                         use_slave=True)
7019 
7020         num_vm_instances = self.driver.get_num_instances()
7021         num_db_instances = len(db_instances)
7022 
7023         if num_vm_instances != num_db_instances:
7024             LOG.warning("While synchronizing instance power states, found "
7025                         "%(num_db_instances)s instances in the database "
7026                         "and %(num_vm_instances)s instances on the "
7027                         "hypervisor.",
7028                         {'num_db_instances': num_db_instances,
7029                          'num_vm_instances': num_vm_instances})
7030 
7031         def _sync(db_instance):
7032             # NOTE(melwitt): This must be synchronized as we query state from
7033             #                two separate sources, the driver and the database.
7034             #                They are set (in stop_instance) and read, in sync.
7035             @utils.synchronized(db_instance.uuid)
7036             def query_driver_power_state_and_sync():
7037                 self._query_driver_power_state_and_sync(context, db_instance)
7038 
7039             try:
7040                 query_driver_power_state_and_sync()
7041             except Exception:
7042                 LOG.exception("Periodic sync_power_state task had an "
7043                               "error while processing an instance.",
7044                               instance=db_instance)
7045 
7046             self._syncs_in_progress.pop(db_instance.uuid)
7047 
7048         for db_instance in db_instances:
7049             # process syncs asynchronously - don't want instance locking to
7050             # block entire periodic task thread
7051             uuid = db_instance.uuid
7052             if uuid in self._syncs_in_progress:
7053                 LOG.debug('Sync already in progress for %s', uuid)
7054             else:
7055                 LOG.debug('Triggering sync for uuid %s', uuid)
7056                 self._syncs_in_progress[uuid] = True
7057                 self._sync_power_pool.spawn_n(_sync, db_instance)
7058 
7059     def _query_driver_power_state_and_sync(self, context, db_instance):
7060         if db_instance.task_state is not None:
7061             LOG.info("During sync_power_state the instance has a "
7062                      "pending task (%(task)s). Skip.",
7063                      {'task': db_instance.task_state}, instance=db_instance)
7064             return
7065         # No pending tasks. Now try to figure out the real vm_power_state.
7066         try:
7067             vm_instance = self.driver.get_info(db_instance)
7068             vm_power_state = vm_instance.state
7069         except exception.InstanceNotFound:
7070             vm_power_state = power_state.NOSTATE
7071         # Note(maoy): the above get_info call might take a long time,
7072         # for example, because of a broken libvirt driver.
7073         try:
7074             self._sync_instance_power_state(context,
7075                                             db_instance,
7076                                             vm_power_state,
7077                                             use_slave=True)
7078         except exception.InstanceNotFound:
7079             # NOTE(hanlind): If the instance gets deleted during sync,
7080             # silently ignore.
7081             pass
7082 
7083     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
7084                                    use_slave=False):
7085         """Align instance power state between the database and hypervisor.
7086 
7087         If the instance is not found on the hypervisor, but is in the database,
7088         then a stop() API will be called on the instance.
7089         """
7090 
7091         # We re-query the DB to get the latest instance info to minimize
7092         # (not eliminate) race condition.
7093         db_instance.refresh(use_slave=use_slave)
7094         db_power_state = db_instance.power_state
7095         vm_state = db_instance.vm_state
7096 
7097         if self.host != db_instance.host:
7098             # on the sending end of nova-compute _sync_power_state
7099             # may have yielded to the greenthread performing a live
7100             # migration; this in turn has changed the resident-host
7101             # for the VM; However, the instance is still active, it
7102             # is just in the process of migrating to another host.
7103             # This implies that the compute source must relinquish
7104             # control to the compute destination.
7105             LOG.info("During the sync_power process the "
7106                      "instance has moved from "
7107                      "host %(src)s to host %(dst)s",
7108                      {'src': db_instance.host,
7109                       'dst': self.host},
7110                      instance=db_instance)
7111             return
7112         elif db_instance.task_state is not None:
7113             # on the receiving end of nova-compute, it could happen
7114             # that the DB instance already report the new resident
7115             # but the actual VM has not showed up on the hypervisor
7116             # yet. In this case, let's allow the loop to continue
7117             # and run the state sync in a later round
7118             LOG.info("During sync_power_state the instance has a "
7119                      "pending task (%(task)s). Skip.",
7120                      {'task': db_instance.task_state},
7121                      instance=db_instance)
7122             return
7123 
7124         orig_db_power_state = db_power_state
7125         if vm_power_state != db_power_state:
7126             LOG.info('During _sync_instance_power_state the DB '
7127                      'power_state (%(db_power_state)s) does not match '
7128                      'the vm_power_state from the hypervisor '
7129                      '(%(vm_power_state)s). Updating power_state in the '
7130                      'DB to match the hypervisor.',
7131                      {'db_power_state': db_power_state,
7132                       'vm_power_state': vm_power_state},
7133                      instance=db_instance)
7134             # power_state is always updated from hypervisor to db
7135             db_instance.power_state = vm_power_state
7136             db_instance.save()
7137             db_power_state = vm_power_state
7138 
7139         # Note(maoy): Now resolve the discrepancy between vm_state and
7140         # vm_power_state. We go through all possible vm_states.
7141         if vm_state in (vm_states.BUILDING,
7142                         vm_states.RESCUED,
7143                         vm_states.RESIZED,
7144                         vm_states.SUSPENDED,
7145                         vm_states.ERROR):
7146             # TODO(maoy): we ignore these vm_state for now.
7147             pass
7148         elif vm_state == vm_states.ACTIVE:
7149             # The only rational power state should be RUNNING
7150             if vm_power_state in (power_state.SHUTDOWN,
7151                                   power_state.CRASHED):
7152                 LOG.warning("Instance shutdown by itself. Calling the "
7153                             "stop API. Current vm_state: %(vm_state)s, "
7154                             "current task_state: %(task_state)s, "
7155                             "original DB power_state: %(db_power_state)s, "
7156                             "current VM power_state: %(vm_power_state)s",
7157                             {'vm_state': vm_state,
7158                              'task_state': db_instance.task_state,
7159                              'db_power_state': orig_db_power_state,
7160                              'vm_power_state': vm_power_state},
7161                             instance=db_instance)
7162                 try:
7163                     # Note(maoy): here we call the API instead of
7164                     # brutally updating the vm_state in the database
7165                     # to allow all the hooks and checks to be performed.
7166                     if db_instance.shutdown_terminate:
7167                         self.compute_api.delete(context, db_instance)
7168                     else:
7169                         self.compute_api.stop(context, db_instance)
7170                 except Exception:
7171                     # Note(maoy): there is no need to propagate the error
7172                     # because the same power_state will be retrieved next
7173                     # time and retried.
7174                     # For example, there might be another task scheduled.
7175                     LOG.exception("error during stop() in sync_power_state.",
7176                                   instance=db_instance)
7177             elif vm_power_state == power_state.SUSPENDED:
7178                 LOG.warning("Instance is suspended unexpectedly. Calling "
7179                             "the stop API.", instance=db_instance)
7180                 try:
7181                     self.compute_api.stop(context, db_instance)
7182                 except Exception:
7183                     LOG.exception("error during stop() in sync_power_state.",
7184                                   instance=db_instance)
7185             elif vm_power_state == power_state.PAUSED:
7186                 # Note(maoy): a VM may get into the paused state not only
7187                 # because the user request via API calls, but also
7188                 # due to (temporary) external instrumentations.
7189                 # Before the virt layer can reliably report the reason,
7190                 # we simply ignore the state discrepancy. In many cases,
7191                 # the VM state will go back to running after the external
7192                 # instrumentation is done. See bug 1097806 for details.
7193                 LOG.warning("Instance is paused unexpectedly. Ignore.",
7194                             instance=db_instance)
7195             elif vm_power_state == power_state.NOSTATE:
7196                 # Occasionally, depending on the status of the hypervisor,
7197                 # which could be restarting for example, an instance may
7198                 # not be found.  Therefore just log the condition.
7199                 LOG.warning("Instance is unexpectedly not found. Ignore.",
7200                             instance=db_instance)
7201         elif vm_state == vm_states.STOPPED:
7202             if vm_power_state not in (power_state.NOSTATE,
7203                                       power_state.SHUTDOWN,
7204                                       power_state.CRASHED):
7205                 LOG.warning("Instance is not stopped. Calling "
7206                             "the stop API. Current vm_state: %(vm_state)s,"
7207                             " current task_state: %(task_state)s, "
7208                             "original DB power_state: %(db_power_state)s, "
7209                             "current VM power_state: %(vm_power_state)s",
7210                             {'vm_state': vm_state,
7211                              'task_state': db_instance.task_state,
7212                              'db_power_state': orig_db_power_state,
7213                              'vm_power_state': vm_power_state},
7214                             instance=db_instance)
7215                 try:
7216                     # NOTE(russellb) Force the stop, because normally the
7217                     # compute API would not allow an attempt to stop a stopped
7218                     # instance.
7219                     self.compute_api.force_stop(context, db_instance)
7220                 except Exception:
7221                     LOG.exception("error during stop() in sync_power_state.",
7222                                   instance=db_instance)
7223         elif vm_state == vm_states.PAUSED:
7224             if vm_power_state in (power_state.SHUTDOWN,
7225                                   power_state.CRASHED):
7226                 LOG.warning("Paused instance shutdown by itself. Calling "
7227                             "the stop API.", instance=db_instance)
7228                 try:
7229                     self.compute_api.force_stop(context, db_instance)
7230                 except Exception:
7231                     LOG.exception("error during stop() in sync_power_state.",
7232                                   instance=db_instance)
7233         elif vm_state in (vm_states.SOFT_DELETED,
7234                           vm_states.DELETED):
7235             if vm_power_state not in (power_state.NOSTATE,
7236                                       power_state.SHUTDOWN):
7237                 # Note(maoy): this should be taken care of periodically in
7238                 # _cleanup_running_deleted_instances().
7239                 LOG.warning("Instance is not (soft-)deleted.",
7240                             instance=db_instance)
7241 
7242     @periodic_task.periodic_task
7243     def _reclaim_queued_deletes(self, context):
7244         """Reclaim instances that are queued for deletion."""
7245         interval = CONF.reclaim_instance_interval
7246         if interval <= 0:
7247             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
7248             return
7249 
7250         filters = {'vm_state': vm_states.SOFT_DELETED,
7251                    'task_state': None,
7252                    'host': self.host}
7253         instances = objects.InstanceList.get_by_filters(
7254             context, filters,
7255             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
7256             use_slave=True)
7257         for instance in instances:
7258             if self._deleted_old_enough(instance, interval):
7259                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7260                         context, instance.uuid)
7261                 LOG.info('Reclaiming deleted instance', instance=instance)
7262                 try:
7263                     self._delete_instance(context, instance, bdms)
7264                 except Exception as e:
7265                     LOG.warning("Periodic reclaim failed to delete "
7266                                 "instance: %s",
7267                                 e, instance=instance)
7268 
7269     def _get_nodename(self, instance, refresh=False):
7270         """Helper method to get the name of the first available node
7271         on this host. This method should not be used with any operations
7272         on ironic instances since it does not handle multiple nodes.
7273         """
7274         node = self.driver.get_available_nodes(refresh=refresh)[0]
7275         LOG.debug("No node specified, defaulting to %s", node,
7276                   instance=instance)
7277         return node
7278 
7279     def update_available_resource_for_node(self, context, nodename):
7280 
7281         rt = self._get_resource_tracker()
7282         try:
7283             rt.update_available_resource(context, nodename)
7284         except exception.ComputeHostNotFound:
7285             # NOTE(comstud): We can get to this case if a node was
7286             # marked 'deleted' in the DB and then re-added with a
7287             # different auto-increment id. The cached resource
7288             # tracker tried to update a deleted record and failed.
7289             # Don't add this resource tracker to the new dict, so
7290             # that this will resolve itself on the next run.
7291             LOG.info("Compute node '%s' not found in "
7292                      "update_available_resource.", nodename)
7293             # TODO(jaypipes): Yes, this is inefficient to throw away all of the
7294             # compute nodes to force a rebuild, but this is only temporary
7295             # until Ironic baremetal node resource providers are tracked
7296             # properly in the report client and this is a tiny edge case
7297             # anyway.
7298             self._resource_tracker = None
7299             return
7300         except Exception:
7301             LOG.exception("Error updating resources for node %(node)s.",
7302                           {'node': nodename})
7303 
7304     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
7305     def update_available_resource(self, context, startup=False):
7306         """See driver.get_available_resource()
7307 
7308         Periodic process that keeps that the compute host's understanding of
7309         resource availability and usage in sync with the underlying hypervisor.
7310 
7311         :param context: security context
7312         :param startup: True if this is being called when the nova-compute
7313             service is starting, False otherwise.
7314         """
7315 
7316         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
7317                                                             use_slave=True,
7318                                                             startup=startup)
7319         nodenames = set(self.driver.get_available_nodes())
7320         for nodename in nodenames:
7321             self.update_available_resource_for_node(context, nodename)
7322 
7323         # Delete orphan compute node not reported by driver but still in db
7324         for cn in compute_nodes_in_db:
7325             if cn.hypervisor_hostname not in nodenames:
7326                 LOG.info("Deleting orphan compute node %(id)s "
7327                          "hypervisor host is %(hh)s, "
7328                          "nodes are %(nodes)s",
7329                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
7330                           'nodes': nodenames})
7331                 cn.destroy()
7332                 # Delete the corresponding resource provider in placement,
7333                 # along with any associated allocations and inventory.
7334                 # TODO(cdent): Move use of reportclient into resource tracker.
7335                 self.scheduler_client.reportclient.delete_resource_provider(
7336                     context, cn, cascade=True)
7337 
7338     def _get_compute_nodes_in_db(self, context, use_slave=False,
7339                                  startup=False):
7340         try:
7341             return objects.ComputeNodeList.get_all_by_host(context, self.host,
7342                                                            use_slave=use_slave)
7343         except exception.NotFound:
7344             if startup:
7345                 LOG.warning(
7346                     "No compute node record found for host %s. If this is "
7347                     "the first time this service is starting on this "
7348                     "host, then you can ignore this warning.", self.host)
7349             else:
7350                 LOG.error("No compute node record for host %s", self.host)
7351             return []
7352 
7353     @periodic_task.periodic_task(
7354         spacing=CONF.running_deleted_instance_poll_interval)
7355     def _cleanup_running_deleted_instances(self, context):
7356         """Cleanup any instances which are erroneously still running after
7357         having been deleted.
7358 
7359         Valid actions to take are:
7360 
7361             1. noop - do nothing
7362             2. log - log which instances are erroneously running
7363             3. reap - shutdown and cleanup any erroneously running instances
7364             4. shutdown - power off *and disable* any erroneously running
7365                           instances
7366 
7367         The use-case for this cleanup task is: for various reasons, it may be
7368         possible for the database to show an instance as deleted but for that
7369         instance to still be running on a host machine (see bug
7370         https://bugs.launchpad.net/nova/+bug/911366).
7371 
7372         This cleanup task is a cross-hypervisor utility for finding these
7373         zombied instances and either logging the discrepancy (likely what you
7374         should do in production), or automatically reaping the instances (more
7375         appropriate for dev environments).
7376         """
7377         action = CONF.running_deleted_instance_action
7378 
7379         if action == "noop":
7380             return
7381 
7382         # NOTE(sirp): admin contexts don't ordinarily return deleted records
7383         with utils.temporary_mutation(context, read_deleted="yes"):
7384             for instance in self._running_deleted_instances(context):
7385                 if action == "log":
7386                     LOG.warning("Detected instance with name label "
7387                                 "'%s' which is marked as "
7388                                 "DELETED but still present on host.",
7389                                 instance.name, instance=instance)
7390 
7391                 elif action == 'shutdown':
7392                     LOG.info("Powering off instance with name label "
7393                              "'%s' which is marked as "
7394                              "DELETED but still present on host.",
7395                              instance.name, instance=instance)
7396                     try:
7397                         try:
7398                             # disable starting the instance
7399                             self.driver.set_bootable(instance, False)
7400                         except NotImplementedError:
7401                             LOG.debug("set_bootable is not implemented "
7402                                       "for the current driver")
7403                         # and power it off
7404                         self.driver.power_off(instance)
7405                     except Exception:
7406                         LOG.warning("Failed to power off instance",
7407                                     instance=instance, exc_info=True)
7408 
7409                 elif action == 'reap':
7410                     LOG.info("Destroying instance with name label "
7411                              "'%s' which is marked as "
7412                              "DELETED but still present on host.",
7413                              instance.name, instance=instance)
7414                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7415                         context, instance.uuid, use_slave=True)
7416                     self.instance_events.clear_events_for_instance(instance)
7417                     try:
7418                         self._shutdown_instance(context, instance, bdms,
7419                                                 notify=False)
7420                         self._cleanup_volumes(context, instance.uuid, bdms)
7421                     except Exception as e:
7422                         LOG.warning("Periodic cleanup failed to delete "
7423                                     "instance: %s",
7424                                     e, instance=instance)
7425                 else:
7426                     raise Exception(_("Unrecognized value '%s'"
7427                                       " for CONF.running_deleted_"
7428                                       "instance_action") % action)
7429 
7430     def _running_deleted_instances(self, context):
7431         """Returns a list of instances nova thinks is deleted,
7432         but the hypervisor thinks is still running.
7433         """
7434         timeout = CONF.running_deleted_instance_timeout
7435         filters = {'deleted': True,
7436                    'soft_deleted': False}
7437         instances = self._get_instances_on_driver(context, filters)
7438         return [i for i in instances if self._deleted_old_enough(i, timeout)]
7439 
7440     def _deleted_old_enough(self, instance, timeout):
7441         deleted_at = instance.deleted_at
7442         if deleted_at:
7443             deleted_at = deleted_at.replace(tzinfo=None)
7444         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
7445 
7446     @contextlib.contextmanager
7447     def _error_out_instance_on_exception(self, context, instance,
7448                                          instance_state=vm_states.ACTIVE):
7449         instance_uuid = instance.uuid
7450         try:
7451             yield
7452         except NotImplementedError as error:
7453             with excutils.save_and_reraise_exception():
7454                 LOG.info("Setting instance back to %(state)s after: "
7455                          "%(error)s",
7456                          {'state': instance_state, 'error': error},
7457                          instance_uuid=instance_uuid)
7458                 self._instance_update(context, instance,
7459                                       vm_state=instance_state,
7460                                       task_state=None)
7461         except exception.InstanceFaultRollback as error:
7462             LOG.info("Setting instance back to ACTIVE after: %s",
7463                      error, instance_uuid=instance_uuid)
7464             self._instance_update(context, instance,
7465                                   vm_state=vm_states.ACTIVE,
7466                                   task_state=None)
7467             raise error.inner_exception
7468         except Exception:
7469             LOG.exception('Setting instance vm_state to ERROR',
7470                           instance_uuid=instance_uuid)
7471             with excutils.save_and_reraise_exception():
7472                 self._set_instance_obj_error_state(context, instance)
7473 
7474     @wrap_exception()
7475     def add_aggregate_host(self, context, aggregate, host, slave_info):
7476         """Notify hypervisor of change (for hypervisor pools)."""
7477         try:
7478             self.driver.add_to_aggregate(context, aggregate, host,
7479                                          slave_info=slave_info)
7480         except NotImplementedError:
7481             LOG.debug('Hypervisor driver does not support '
7482                       'add_aggregate_host')
7483         except exception.AggregateError:
7484             with excutils.save_and_reraise_exception():
7485                 self.driver.undo_aggregate_operation(
7486                                     context,
7487                                     aggregate.delete_host,
7488                                     aggregate, host)
7489 
7490     @wrap_exception()
7491     def remove_aggregate_host(self, context, host, slave_info, aggregate):
7492         """Removes a host from a physical hypervisor pool."""
7493         try:
7494             self.driver.remove_from_aggregate(context, aggregate, host,
7495                                               slave_info=slave_info)
7496         except NotImplementedError:
7497             LOG.debug('Hypervisor driver does not support '
7498                       'remove_aggregate_host')
7499         except (exception.AggregateError,
7500                 exception.InvalidAggregateAction) as e:
7501             with excutils.save_and_reraise_exception():
7502                 self.driver.undo_aggregate_operation(
7503                                     context,
7504                                     aggregate.add_host,
7505                                     aggregate, host,
7506                                     isinstance(e, exception.AggregateError))
7507 
7508     def _process_instance_event(self, instance, event):
7509         _event = self.instance_events.pop_instance_event(instance, event)
7510         if _event:
7511             LOG.debug('Processing event %(event)s',
7512                       {'event': event.key}, instance=instance)
7513             _event.send(event)
7514         else:
7515             # If it's a network-vif-unplugged event and the instance is being
7516             # deleted then we don't need to make this a warning as it's
7517             # expected. There are other things which could trigger this like
7518             # detaching an interface, but we don't have a task state for that.
7519             if (event.name == 'network-vif-unplugged' and
7520                     instance.task_state == task_states.DELETING):
7521                 LOG.debug('Received event %s for instance which is being '
7522                           'deleted.', event.key, instance=instance)
7523             else:
7524                 LOG.warning('Received unexpected event %(event)s for '
7525                             'instance with vm_state %(vm_state)s and '
7526                             'task_state %(task_state)s.',
7527                             {'event': event.key,
7528                              'vm_state': instance.vm_state,
7529                              'task_state': instance.task_state},
7530                             instance=instance)
7531 
7532     def _process_instance_vif_deleted_event(self, context, instance,
7533                                             deleted_vif_id):
7534         # If an attached port is deleted by neutron, it needs to
7535         # be detached from the instance.
7536         # And info cache needs to be updated.
7537         network_info = instance.info_cache.network_info
7538         for index, vif in enumerate(network_info):
7539             if vif['id'] == deleted_vif_id:
7540                 LOG.info('Neutron deleted interface %(intf)s; '
7541                          'detaching it from the instance and '
7542                          'deleting it from the info cache',
7543                          {'intf': vif['id']},
7544                          instance=instance)
7545                 del network_info[index]
7546                 base_net_api.update_instance_cache_with_nw_info(
7547                                  self.network_api, context,
7548                                  instance,
7549                                  nw_info=network_info)
7550                 try:
7551                     self.driver.detach_interface(context, instance, vif)
7552                 except NotImplementedError:
7553                     # Not all virt drivers support attach/detach of interfaces
7554                     # yet (like Ironic), so just ignore this.
7555                     pass
7556                 except exception.NovaException as ex:
7557                     LOG.warning("Detach interface failed, "
7558                                 "port_id=%(port_id)s, reason: %(msg)s",
7559                                 {'port_id': deleted_vif_id, 'msg': ex},
7560                                 instance=instance)
7561                 break
7562 
7563     @wrap_instance_event(prefix='compute')
7564     @wrap_instance_fault
7565     def extend_volume(self, context, instance, extended_volume_id):
7566 
7567         # If an attached volume is extended by cinder, it needs to
7568         # be extended by virt driver so host can detect its new size.
7569         # And bdm needs to be updated.
7570         LOG.debug('Handling volume-extended event for volume %(vol)s',
7571                   {'vol': extended_volume_id}, instance=instance)
7572 
7573         try:
7574             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
7575                    context, extended_volume_id, instance.uuid)
7576         except exception.NotFound:
7577             LOG.warning('Extend volume failed, '
7578                         'volume %(vol)s is not attached to instance.',
7579                         {'vol': extended_volume_id},
7580                         instance=instance)
7581             return
7582 
7583         LOG.info('Cinder extended volume %(vol)s; '
7584                  'extending it to detect new size',
7585                  {'vol': extended_volume_id},
7586                  instance=instance)
7587         volume = self.volume_api.get(context, bdm.volume_id)
7588 
7589         if bdm.connection_info is None:
7590             LOG.warning('Extend volume failed, '
7591                         'attached volume %(vol)s has no connection_info',
7592                         {'vol': extended_volume_id},
7593                         instance=instance)
7594             return
7595 
7596         connection_info = jsonutils.loads(bdm.connection_info)
7597         bdm.volume_size = volume['size']
7598         bdm.save()
7599 
7600         if not self.driver.capabilities.get('supports_extend_volume', False):
7601             raise exception.ExtendVolumeNotSupported()
7602 
7603         try:
7604             self.driver.extend_volume(connection_info,
7605                                       instance)
7606         except Exception as ex:
7607             LOG.warning('Extend volume failed, '
7608                         'volume_id=%(volume_id)s, reason: %(msg)s',
7609                         {'volume_id': extended_volume_id, 'msg': ex},
7610                         instance=instance)
7611             raise
7612 
7613     @wrap_exception()
7614     def external_instance_event(self, context, instances, events):
7615         # NOTE(danms): Some event types are handled by the manager, such
7616         # as when we're asked to update the instance's info_cache. If it's
7617         # not one of those, look for some thread(s) waiting for the event and
7618         # unblock them if so.
7619         for event in events:
7620             instance = [inst for inst in instances
7621                         if inst.uuid == event.instance_uuid][0]
7622             LOG.debug('Received event %(event)s',
7623                       {'event': event.key},
7624                       instance=instance)
7625             if event.name == 'network-changed':
7626                 try:
7627                     self.network_api.get_instance_nw_info(context, instance)
7628                 except exception.NotFound as e:
7629                     LOG.info('Failed to process external instance event '
7630                              '%(event)s due to: %(error)s',
7631                              {'event': event.key, 'error': six.text_type(e)},
7632                              instance=instance)
7633             elif event.name == 'network-vif-deleted':
7634                 try:
7635                     self._process_instance_vif_deleted_event(context,
7636                                                              instance,
7637                                                              event.tag)
7638                 except exception.NotFound as e:
7639                     LOG.info('Failed to process external instance event '
7640                              '%(event)s due to: %(error)s',
7641                              {'event': event.key, 'error': six.text_type(e)},
7642                              instance=instance)
7643             elif event.name == 'volume-extended':
7644                 self.extend_volume(context, instance, event.tag)
7645             else:
7646                 self._process_instance_event(instance, event)
7647 
7648     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
7649                                  external_process_ok=True)
7650     def _run_image_cache_manager_pass(self, context):
7651         """Run a single pass of the image cache manager."""
7652 
7653         if not self.driver.capabilities["has_imagecache"]:
7654             return
7655 
7656         # Determine what other nodes use this storage
7657         storage_users.register_storage_use(CONF.instances_path, CONF.host)
7658         nodes = storage_users.get_storage_users(CONF.instances_path)
7659 
7660         # Filter all_instances to only include those nodes which share this
7661         # storage path.
7662         # TODO(mikal): this should be further refactored so that the cache
7663         # cleanup code doesn't know what those instances are, just a remote
7664         # count, and then this logic should be pushed up the stack.
7665         filters = {'deleted': False,
7666                    'soft_deleted': True,
7667                    'host': nodes}
7668         filtered_instances = objects.InstanceList.get_by_filters(context,
7669                                  filters, expected_attrs=[], use_slave=True)
7670 
7671         self.driver.manage_image_cache(context, filtered_instances)
7672 
7673     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7674     def _run_pending_deletes(self, context):
7675         """Retry any pending instance file deletes."""
7676         LOG.debug('Cleaning up deleted instances')
7677         filters = {'deleted': True,
7678                    'soft_deleted': False,
7679                    'host': CONF.host,
7680                    'cleaned': False}
7681         attrs = ['system_metadata']
7682         with utils.temporary_mutation(context, read_deleted='yes'):
7683             instances = objects.InstanceList.get_by_filters(
7684                 context, filters, expected_attrs=attrs, use_slave=True)
7685         LOG.debug('There are %d instances to clean', len(instances))
7686 
7687         # TODO(raj_singh): Remove this if condition when min value is
7688         # introduced to "maximum_instance_delete_attempts" cfg option.
7689         if CONF.maximum_instance_delete_attempts < 1:
7690             LOG.warning('Future versions of Nova will restrict the '
7691                         '"maximum_instance_delete_attempts" config option '
7692                         'to values >=1. Update your configuration file to '
7693                         'mitigate future upgrade issues.')
7694 
7695         for instance in instances:
7696             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
7697             LOG.debug('Instance has had %(attempts)s of %(max)s '
7698                       'cleanup attempts',
7699                       {'attempts': attempts,
7700                        'max': CONF.maximum_instance_delete_attempts},
7701                       instance=instance)
7702             if attempts < CONF.maximum_instance_delete_attempts:
7703                 success = self.driver.delete_instance_files(instance)
7704 
7705                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
7706                 if success:
7707                     instance.cleaned = True
7708                 with utils.temporary_mutation(context, read_deleted='yes'):
7709                     instance.save()
7710 
7711     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7712     def _cleanup_incomplete_migrations(self, context):
7713         """Delete instance files on failed resize/revert-resize operation
7714 
7715         During resize/revert-resize operation, if that instance gets deleted
7716         in-between then instance files might remain either on source or
7717         destination compute node because of race condition.
7718         """
7719         LOG.debug('Cleaning up deleted instances with incomplete migration ')
7720         migration_filters = {'host': CONF.host,
7721                              'status': 'error'}
7722         migrations = objects.MigrationList.get_by_filters(context,
7723                                                           migration_filters)
7724 
7725         if not migrations:
7726             return
7727 
7728         inst_uuid_from_migrations = set([migration.instance_uuid for migration
7729                                          in migrations])
7730 
7731         inst_filters = {'deleted': True, 'soft_deleted': False,
7732                         'uuid': inst_uuid_from_migrations}
7733         attrs = ['info_cache', 'security_groups', 'system_metadata']
7734         with utils.temporary_mutation(context, read_deleted='yes'):
7735             instances = objects.InstanceList.get_by_filters(
7736                 context, inst_filters, expected_attrs=attrs, use_slave=True)
7737 
7738         for instance in instances:
7739             if instance.host != CONF.host:
7740                 for migration in migrations:
7741                     if instance.uuid == migration.instance_uuid:
7742                         # Delete instance files if not cleanup properly either
7743                         # from the source or destination compute nodes when
7744                         # the instance is deleted during resizing.
7745                         self.driver.delete_instance_files(instance)
7746                         try:
7747                             migration.status = 'failed'
7748                             with migration.obj_as_admin():
7749                                 migration.save()
7750                         except exception.MigrationNotFound:
7751                             LOG.warning("Migration %s is not found.",
7752                                         migration.id,
7753                                         instance=instance)
7754                         break
7755 
7756     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7757                                    exception.QemuGuestAgentNotEnabled,
7758                                    exception.NovaException,
7759                                    NotImplementedError)
7760     @wrap_exception()
7761     def quiesce_instance(self, context, instance):
7762         """Quiesce an instance on this host."""
7763         context = context.elevated()
7764         image_meta = objects.ImageMeta.from_instance(instance)
7765         self.driver.quiesce(context, instance, image_meta)
7766 
7767     def _wait_for_snapshots_completion(self, context, mapping):
7768         for mapping_dict in mapping:
7769             if mapping_dict.get('source_type') == 'snapshot':
7770 
7771                 def _wait_snapshot():
7772                     snapshot = self.volume_api.get_snapshot(
7773                         context, mapping_dict['snapshot_id'])
7774                     if snapshot.get('status') != 'creating':
7775                         raise loopingcall.LoopingCallDone()
7776 
7777                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
7778                 timer.start(interval=0.5).wait()
7779 
7780     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7781                                    exception.QemuGuestAgentNotEnabled,
7782                                    exception.NovaException,
7783                                    NotImplementedError)
7784     @wrap_exception()
7785     def unquiesce_instance(self, context, instance, mapping=None):
7786         """Unquiesce an instance on this host.
7787 
7788         If snapshots' image mapping is provided, it waits until snapshots are
7789         completed before unqueiscing.
7790         """
7791         context = context.elevated()
7792         if mapping:
7793             try:
7794                 self._wait_for_snapshots_completion(context, mapping)
7795             except Exception as error:
7796                 LOG.exception("Exception while waiting completion of "
7797                               "volume snapshots: %s",
7798                               error, instance=instance)
7799         image_meta = objects.ImageMeta.from_instance(instance)
7800         self.driver.unquiesce(context, instance, image_meta)
