Please review the code below to detect security defects. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are found, please state '''No security defects are detected in the code'''.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 from cursive import exception as cursive_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 from keystoneauth1 import exceptions as keystone_exception
44 from oslo_log import log as logging
45 import oslo_messaging as messaging
46 from oslo_serialization import jsonutils
47 from oslo_service import loopingcall
48 from oslo_service import periodic_task
49 from oslo_utils import excutils
50 from oslo_utils import strutils
51 from oslo_utils import timeutils
52 from oslo_utils import uuidutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova.console import rpcapi as console_rpcapi
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova import image
77 from nova import manager
78 from nova import network
79 from nova.network import base_api as base_net_api
80 from nova.network import model as network_model
81 from nova.network.security_group import openstack_driver
82 from nova import objects
83 from nova.objects import base as obj_base
84 from nova.objects import console_connection as obj_console_connection
85 from nova.objects import fields
86 from nova.objects import instance as obj_instance
87 from nova.objects import migrate_data as migrate_data_obj
88 from nova.pci import whitelist
89 from nova import rpc
90 from nova import safe_utils
91 from nova.scheduler import client as scheduler_client
92 from nova.scheduler import utils as scheduler_utils
93 from nova import utils
94 from nova.virt import block_device as driver_block_device
95 from nova.virt import configdrive
96 from nova.virt import driver
97 from nova.virt import event as virtevent
98 from nova.virt import storage_users
99 from nova.virt import virtapi
100 from nova.volume import cinder
101 
102 CONF = nova.conf.CONF
103 
104 LOG = logging.getLogger(__name__)
105 
106 get_notifier = functools.partial(rpc.get_notifier, service='compute')
107 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
108                                    get_notifier=get_notifier,
109                                    binary='nova-compute')
110 
111 
112 @contextlib.contextmanager
113 def errors_out_migration_ctxt(migration):
114     """Context manager to error out migration on failure."""
115 
116     try:
117         yield
118     except Exception:
119         with excutils.save_and_reraise_exception():
120             if migration:
121                 # We may have been passed None for our migration if we're
122                 # receiving from an older client. The migration will be
123                 # errored via the legacy path.
124                 migration.status = 'error'
125                 try:
126                     with migration.obj_as_admin():
127                         migration.save()
128                 except Exception:
129                     LOG.debug(
130                         'Error setting migration status for instance %s.',
131                         migration.instance_uuid, exc_info=True)
132 
133 
134 @utils.expects_func_args('migration')
135 def errors_out_migration(function):
136     """Decorator to error out migration on failure."""
137 
138     @functools.wraps(function)
139     def decorated_function(self, context, *args, **kwargs):
140         wrapped_func = safe_utils.get_wrapped_function(function)
141         keyed_args = inspect.getcallargs(wrapped_func, self, context,
142                                          *args, **kwargs)
143         migration = keyed_args['migration']
144         with errors_out_migration_ctxt(migration):
145             return function(self, context, *args, **kwargs)
146 
147     return decorated_function
148 
149 
150 @utils.expects_func_args('instance')
151 def reverts_task_state(function):
152     """Decorator to revert task_state on failure."""
153 
154     @functools.wraps(function)
155     def decorated_function(self, context, *args, **kwargs):
156         try:
157             return function(self, context, *args, **kwargs)
158         except exception.UnexpectedTaskStateError as e:
159             # Note(maoy): unexpected task state means the current
160             # task is preempted. Do not clear task state in this
161             # case.
162             with excutils.save_and_reraise_exception():
163                 LOG.info("Task possibly preempted: %s",
164                          e.format_message())
165         except Exception:
166             with excutils.save_and_reraise_exception():
167                 wrapped_func = safe_utils.get_wrapped_function(function)
168                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
169                                                  *args, **kwargs)
170                 # NOTE(mriedem): 'instance' must be in keyed_args because we
171                 # have utils.expects_func_args('instance') decorating this
172                 # method.
173                 instance = keyed_args['instance']
174                 original_task_state = instance.task_state
175                 try:
176                     self._instance_update(context, instance, task_state=None)
177                     LOG.info("Successfully reverted task state from %s on "
178                              "failure for instance.",
179                              original_task_state, instance=instance)
180                 except exception.InstanceNotFound:
181                     # We might delete an instance that failed to build shortly
182                     # after it errored out this is an expected case and we
183                     # should not trace on it.
184                     pass
185                 except Exception as e:
186                     LOG.warning("Failed to revert task state for instance. "
187                                 "Error: %s", e, instance=instance)
188 
189     return decorated_function
190 
191 
192 @utils.expects_func_args('instance')
193 def wrap_instance_fault(function):
194     """Wraps a method to catch exceptions related to instances.
195 
196     This decorator wraps a method to catch any exceptions having to do with
197     an instance that may get thrown. It then logs an instance fault in the db.
198     """
199 
200     @functools.wraps(function)
201     def decorated_function(self, context, *args, **kwargs):
202         try:
203             return function(self, context, *args, **kwargs)
204         except exception.InstanceNotFound:
205             raise
206         except Exception as e:
207             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
208             # we will get a KeyError exception which will cover up the real
209             # exception. So, we update kwargs with the values from args first.
210             # then, we can get 'instance' from kwargs easily.
211             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
212 
213             with excutils.save_and_reraise_exception():
214                 compute_utils.add_instance_fault_from_exc(context,
215                         kwargs['instance'], e, sys.exc_info())
216 
217     return decorated_function
218 
219 
220 @utils.expects_func_args('image_id', 'instance')
221 def delete_image_on_error(function):
222     """Used for snapshot related method to ensure the image created in
223     compute.api is deleted when an error occurs.
224     """
225 
226     @functools.wraps(function)
227     def decorated_function(self, context, image_id, instance,
228                            *args, **kwargs):
229         try:
230             return function(self, context, image_id, instance,
231                             *args, **kwargs)
232         except Exception:
233             with excutils.save_and_reraise_exception():
234                 LOG.debug("Cleaning up image %s", image_id,
235                           exc_info=True, instance=instance)
236                 try:
237                     self.image_api.delete(context, image_id)
238                 except exception.ImageNotFound:
239                     # Since we're trying to cleanup an image, we don't care if
240                     # if it's already gone.
241                     pass
242                 except Exception:
243                     LOG.exception("Error while trying to clean up image %s",
244                                   image_id, instance=instance)
245 
246     return decorated_function
247 
248 
249 # TODO(danms): Remove me after Icehouse
250 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
251 # NOTE(mikal): if the method being decorated has more than one decorator, then
252 # put this one first. Otherwise the various exception handling decorators do
253 # not function correctly.
254 def object_compat(function):
255     """Wraps a method that expects a new-world instance
256 
257     This provides compatibility for callers passing old-style dict
258     instances.
259     """
260 
261     @functools.wraps(function)
262     def decorated_function(self, context, *args, **kwargs):
263         def _load_instance(instance_or_dict):
264             if isinstance(instance_or_dict, dict):
265                 # try to get metadata and system_metadata for most cases but
266                 # only attempt to load those if the db instance already has
267                 # those fields joined
268                 metas = [meta for meta in ('metadata', 'system_metadata')
269                          if meta in instance_or_dict]
270                 instance = objects.Instance._from_db_object(
271                     context, objects.Instance(), instance_or_dict,
272                     expected_attrs=metas)
273                 instance._context = context
274                 return instance
275             return instance_or_dict
276 
277         try:
278             kwargs['instance'] = _load_instance(kwargs['instance'])
279         except KeyError:
280             args = (_load_instance(args[0]),) + args[1:]
281 
282         migration = kwargs.get('migration')
283         if isinstance(migration, dict):
284             migration = objects.Migration._from_db_object(
285                     context.elevated(), objects.Migration(),
286                     migration)
287             kwargs['migration'] = migration
288 
289         return function(self, context, *args, **kwargs)
290 
291     return decorated_function
292 
293 
294 class InstanceEvents(object):
295     def __init__(self):
296         self._events = {}
297 
298     @staticmethod
299     def _lock_name(instance):
300         return '%s-%s' % (instance.uuid, 'events')
301 
302     def prepare_for_instance_event(self, instance, event_name):
303         """Prepare to receive an event for an instance.
304 
305         This will register an event for the given instance that we will
306         wait on later. This should be called before initiating whatever
307         action will trigger the event. The resulting eventlet.event.Event
308         object should be wait()'d on to ensure completion.
309 
310         :param instance: the instance for which the event will be generated
311         :param event_name: the name of the event we're expecting
312         :returns: an event object that should be wait()'d on
313         """
314         if self._events is None:
315             # NOTE(danms): We really should have a more specific error
316             # here, but this is what we use for our default error case
317             raise exception.NovaException('In shutdown, no new events '
318                                           'can be scheduled')
319 
320         @utils.synchronized(self._lock_name(instance))
321         def _create_or_get_event():
322             instance_events = self._events.setdefault(instance.uuid, {})
323             return instance_events.setdefault(event_name,
324                                               eventlet.event.Event())
325         LOG.debug('Preparing to wait for external event %(event)s',
326                   {'event': event_name}, instance=instance)
327         return _create_or_get_event()
328 
329     def pop_instance_event(self, instance, event):
330         """Remove a pending event from the wait list.
331 
332         This will remove a pending event from the wait list so that it
333         can be used to signal the waiters to wake up.
334 
335         :param instance: the instance for which the event was generated
336         :param event: the nova.objects.external_event.InstanceExternalEvent
337                       that describes the event
338         :returns: the eventlet.event.Event object on which the waiters
339                   are blocked
340         """
341         no_events_sentinel = object()
342         no_matching_event_sentinel = object()
343 
344         @utils.synchronized(self._lock_name(instance))
345         def _pop_event():
346             if not self._events:
347                 LOG.debug('Unexpected attempt to pop events during shutdown',
348                           instance=instance)
349                 return no_events_sentinel
350             events = self._events.get(instance.uuid)
351             if not events:
352                 return no_events_sentinel
353             _event = events.pop(event.key, None)
354             if not events:
355                 del self._events[instance.uuid]
356             if _event is None:
357                 return no_matching_event_sentinel
358             return _event
359 
360         result = _pop_event()
361         if result is no_events_sentinel:
362             LOG.debug('No waiting events found dispatching %(event)s',
363                       {'event': event.key},
364                       instance=instance)
365             return None
366         elif result is no_matching_event_sentinel:
367             LOG.debug('No event matching %(event)s in %(events)s',
368                       {'event': event.key,
369                        'events': self._events.get(instance.uuid, {}).keys()},
370                       instance=instance)
371             return None
372         else:
373             return result
374 
375     def clear_events_for_instance(self, instance):
376         """Remove all pending events for an instance.
377 
378         This will remove all events currently pending for an instance
379         and return them (indexed by event name).
380 
381         :param instance: the instance for which events should be purged
382         :returns: a dictionary of {event_name: eventlet.event.Event}
383         """
384         @utils.synchronized(self._lock_name(instance))
385         def _clear_events():
386             if self._events is None:
387                 LOG.debug('Unexpected attempt to clear events during shutdown',
388                           instance=instance)
389                 return dict()
390             return self._events.pop(instance.uuid, {})
391         return _clear_events()
392 
393     def cancel_all_events(self):
394         if self._events is None:
395             LOG.debug('Unexpected attempt to cancel events during shutdown.')
396             return
397         our_events = self._events
398         # NOTE(danms): Block new events
399         self._events = None
400 
401         for instance_uuid, events in our_events.items():
402             for event_name, eventlet_event in events.items():
403                 LOG.debug('Canceling in-flight event %(event)s for '
404                           'instance %(instance_uuid)s',
405                           {'event': event_name,
406                            'instance_uuid': instance_uuid})
407                 name, tag = event_name.rsplit('-', 1)
408                 event = objects.InstanceExternalEvent(
409                     instance_uuid=instance_uuid,
410                     name=name, status='failed',
411                     tag=tag, data={})
412                 eventlet_event.send(event)
413 
414 
415 class ComputeVirtAPI(virtapi.VirtAPI):
416     def __init__(self, compute):
417         super(ComputeVirtAPI, self).__init__()
418         self._compute = compute
419 
420     def _default_error_callback(self, event_name, instance):
421         raise exception.NovaException(_('Instance event failed'))
422 
423     @contextlib.contextmanager
424     def wait_for_instance_event(self, instance, event_names, deadline=300,
425                                 error_callback=None):
426         """Plan to wait for some events, run some code, then wait.
427 
428         This context manager will first create plans to wait for the
429         provided event_names, yield, and then wait for all the scheduled
430         events to complete.
431 
432         Note that this uses an eventlet.timeout.Timeout to bound the
433         operation, so callers should be prepared to catch that
434         failure and handle that situation appropriately.
435 
436         If the event is not received by the specified timeout deadline,
437         eventlet.timeout.Timeout is raised.
438 
439         If the event is received but did not have a 'completed'
440         status, a NovaException is raised.  If an error_callback is
441         provided, instead of raising an exception as detailed above
442         for the failure case, the callback will be called with the
443         event_name and instance, and can return True to continue
444         waiting for the rest of the events, False to stop processing,
445         or raise an exception which will bubble up to the waiter.
446 
447         :param instance: The instance for which an event is expected
448         :param event_names: A list of event names. Each element can be a
449                             string event name or tuple of strings to
450                             indicate (name, tag).
451         :param deadline: Maximum number of seconds we should wait for all
452                          of the specified events to arrive.
453         :param error_callback: A function to be called if an event arrives
454 
455         """
456 
457         if error_callback is None:
458             error_callback = self._default_error_callback
459         events = {}
460         for event_name in event_names:
461             if isinstance(event_name, tuple):
462                 name, tag = event_name
463                 event_name = objects.InstanceExternalEvent.make_key(
464                     name, tag)
465             try:
466                 events[event_name] = (
467                     self._compute.instance_events.prepare_for_instance_event(
468                         instance, event_name))
469             except exception.NovaException:
470                 error_callback(event_name, instance)
471                 # NOTE(danms): Don't wait for any of the events. They
472                 # should all be canceled and fired immediately below,
473                 # but don't stick around if not.
474                 deadline = 0
475         yield
476         with eventlet.timeout.Timeout(deadline):
477             for event_name, event in events.items():
478                 actual_event = event.wait()
479                 if actual_event.status == 'completed':
480                     continue
481                 decision = error_callback(event_name, instance)
482                 if decision is False:
483                     break
484 
485 
486 class ComputeManager(manager.Manager):
487     """Manages the running instances from creation to destruction."""
488 
489     target = messaging.Target(version='4.18')
490 
491     # How long to wait in seconds before re-issuing a shutdown
492     # signal to an instance during power off.  The overall
493     # time to wait is set by CONF.shutdown_timeout.
494     SHUTDOWN_RETRY_INTERVAL = 10
495 
496     def __init__(self, compute_driver=None, *args, **kwargs):
497         """Load configuration options and connect to the hypervisor."""
498         self.virtapi = ComputeVirtAPI(self)
499         self.network_api = network.API()
500         self.volume_api = cinder.API()
501         self.image_api = image.API()
502         self._last_host_check = 0
503         self._last_bw_usage_poll = 0
504         self._bw_usage_supported = True
505         self._last_bw_usage_cell_update = 0
506         self.compute_api = compute.API()
507         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
508         self.conductor_api = conductor.API()
509         self.compute_task_api = conductor.ComputeTaskAPI()
510         self.is_neutron_security_groups = (
511             openstack_driver.is_neutron_security_groups())
512         self.cells_rpcapi = cells_rpcapi.CellsAPI()
513         self.scheduler_client = scheduler_client.SchedulerClient()
514         self.reportclient = self.scheduler_client.reportclient
515         self._resource_tracker = None
516         self.instance_events = InstanceEvents()
517         self._sync_power_pool = eventlet.GreenPool(
518             size=CONF.sync_power_state_pool_size)
519         self._syncs_in_progress = {}
520         self.send_instance_updates = (
521             CONF.filter_scheduler.track_instance_changes)
522         if CONF.max_concurrent_builds != 0:
523             self._build_semaphore = eventlet.semaphore.Semaphore(
524                 CONF.max_concurrent_builds)
525         else:
526             self._build_semaphore = compute_utils.UnlimitedSemaphore()
527         if max(CONF.max_concurrent_live_migrations, 0) != 0:
528             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
529                 CONF.max_concurrent_live_migrations)
530         else:
531             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
532         self._failed_builds = 0
533 
534         super(ComputeManager, self).__init__(service_name="compute",
535                                              *args, **kwargs)
536 
537         # NOTE(russellb) Load the driver last.  It may call back into the
538         # compute manager via the virtapi, so we want it to be fully
539         # initialized before that happens.
540         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
541         self.use_legacy_block_device_info = \
542                             self.driver.need_legacy_block_device_info
543 
544     def reset(self):
545         LOG.info('Reloading compute RPC API')
546         compute_rpcapi.LAST_VERSION = None
547         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
548 
549     def _get_resource_tracker(self):
550         if not self._resource_tracker:
551             rt = resource_tracker.ResourceTracker(self.host, self.driver)
552             self._resource_tracker = rt
553         return self._resource_tracker
554 
555     def _update_resource_tracker(self, context, instance):
556         """Let the resource tracker know that an instance has changed state."""
557 
558         if instance.host == self.host:
559             rt = self._get_resource_tracker()
560             rt.update_usage(context, instance, instance.node)
561 
562     def _instance_update(self, context, instance, **kwargs):
563         """Update an instance in the database using kwargs as value."""
564 
565         for k, v in kwargs.items():
566             setattr(instance, k, v)
567         instance.save()
568         self._update_resource_tracker(context, instance)
569 
570     def _nil_out_instance_obj_host_and_node(self, instance):
571         # NOTE(jwcroppe): We don't do instance.save() here for performance
572         # reasons; a call to this is expected to be immediately followed by
573         # another call that does instance.save(), thus avoiding two writes
574         # to the database layer.
575         instance.host = None
576         instance.node = None
577 
578     def _set_instance_obj_error_state(self, context, instance,
579                                       clean_task_state=False):
580         try:
581             instance.vm_state = vm_states.ERROR
582             if clean_task_state:
583                 instance.task_state = None
584             instance.save()
585         except exception.InstanceNotFound:
586             LOG.debug('Instance has been destroyed from under us while '
587                       'trying to set it to ERROR', instance=instance)
588 
589     def _get_instances_on_driver(self, context, filters=None):
590         """Return a list of instance records for the instances found
591         on the hypervisor which satisfy the specified filters. If filters=None
592         return a list of instance records for all the instances found on the
593         hypervisor.
594         """
595         if not filters:
596             filters = {}
597         try:
598             driver_uuids = self.driver.list_instance_uuids()
599             if len(driver_uuids) == 0:
600                 # Short circuit, don't waste a DB call
601                 return objects.InstanceList()
602             filters['uuid'] = driver_uuids
603             local_instances = objects.InstanceList.get_by_filters(
604                 context, filters, use_slave=True)
605             return local_instances
606         except NotImplementedError:
607             pass
608 
609         # The driver doesn't support uuids listing, so we'll have
610         # to brute force.
611         driver_instances = self.driver.list_instances()
612         # NOTE(mjozefcz): In this case we need to apply host filter.
613         # Without this all instance data would be fetched from db.
614         filters['host'] = self.host
615         instances = objects.InstanceList.get_by_filters(context, filters,
616                                                         use_slave=True)
617         name_map = {instance.name: instance for instance in instances}
618         local_instances = []
619         for driver_instance in driver_instances:
620             instance = name_map.get(driver_instance)
621             if not instance:
622                 continue
623             local_instances.append(instance)
624         return local_instances
625 
626     def _destroy_evacuated_instances(self, context):
627         """Destroys evacuated instances.
628 
629         While nova-compute was down, the instances running on it could be
630         evacuated to another host. This method looks for evacuation migration
631         records where this is the source host and which were either started
632         (accepted) or complete (done). From those migration records, local
633         instances reported by the hypervisor are compared to the instances
634         for the migration records and those local guests are destroyed, along
635         with instance allocation records in Placement for this node.
636         """
637         filters = {
638             'source_compute': self.host,
639             # NOTE(mriedem): Migration records that have been accepted are
640             # included in case the source node comes back up while instances
641             # are being evacuated to another host. We don't want the same
642             # instance being reported from multiple hosts.
643             'status': ['accepted', 'done'],
644             'migration_type': 'evacuation',
645         }
646         with utils.temporary_mutation(context, read_deleted='yes'):
647             evacuations = objects.MigrationList.get_by_filters(context,
648                                                                filters)
649         if not evacuations:
650             return
651         evacuations = {mig.instance_uuid: mig for mig in evacuations}
652 
653         local_instances = self._get_instances_on_driver(context)
654         evacuated = [inst for inst in local_instances
655                      if inst.uuid in evacuations]
656 
657         # NOTE(gibi): We are called from init_host and at this point the
658         # compute_nodes of the resource tracker has not been populated yet so
659         # we cannot rely on the resource tracker here.
660         compute_nodes = {}
661 
662         for instance in evacuated:
663             migration = evacuations[instance.uuid]
664             LOG.info('Deleting instance as it has been evacuated from '
665                      'this host', instance=instance)
666             try:
667                 network_info = self.network_api.get_instance_nw_info(
668                     context, instance)
669                 bdi = self._get_instance_block_device_info(context,
670                                                            instance)
671                 destroy_disks = not (self._is_instance_storage_shared(
672                     context, instance))
673             except exception.InstanceNotFound:
674                 network_info = network_model.NetworkInfo()
675                 bdi = {}
676                 LOG.info('Instance has been marked deleted already, '
677                          'removing it from the hypervisor.',
678                          instance=instance)
679                 # always destroy disks if the instance was deleted
680                 destroy_disks = True
681             self.driver.destroy(context, instance,
682                                 network_info,
683                                 bdi, destroy_disks)
684 
685             # delete the allocation of the evacuated instance from this host
686             if migration.source_node not in compute_nodes:
687                 try:
688                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
689                         context, self.host, migration.source_node).uuid
690                     compute_nodes[migration.source_node] = cn_uuid
691                 except exception.ComputeHostNotFound:
692                     LOG.error("Failed to clean allocation of evacuated "
693                               "instance as the source node %s is not found",
694                               migration.source_node, instance=instance)
695                     continue
696             cn_uuid = compute_nodes[migration.source_node]
697 
698             my_resources = scheduler_utils.resources_from_flavor(
699                 instance, instance.flavor)
700             res = self.reportclient.remove_provider_from_instance_allocation(
701                 instance.uuid, cn_uuid, instance.user_id,
702                 instance.project_id, my_resources)
703             if not res:
704                 LOG.error("Failed to clean allocation of evacuated instance "
705                           "on the source node %s",
706                           cn_uuid, instance=instance)
707 
708             migration.status = 'completed'
709             migration.save()
710 
711     def _is_instance_storage_shared(self, context, instance, host=None):
712         shared_storage = True
713         data = None
714         try:
715             data = self.driver.check_instance_shared_storage_local(context,
716                                                        instance)
717             if data:
718                 shared_storage = (self.compute_rpcapi.
719                                   check_instance_shared_storage(context,
720                                   instance, data, host=host))
721         except NotImplementedError:
722             LOG.debug('Hypervisor driver does not support '
723                       'instance shared storage check, '
724                       'assuming it\'s not on shared storage',
725                       instance=instance)
726             shared_storage = False
727         except Exception:
728             LOG.exception('Failed to check if instance shared',
729                           instance=instance)
730         finally:
731             if data:
732                 self.driver.check_instance_shared_storage_cleanup(context,
733                                                                   data)
734         return shared_storage
735 
736     def _complete_partial_deletion(self, context, instance):
737         """Complete deletion for instances in DELETED status but not marked as
738         deleted in the DB
739         """
740         system_meta = instance.system_metadata
741         instance.destroy()
742         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
743                 context, instance.uuid)
744         self._complete_deletion(context,
745                                 instance,
746                                 bdms,
747                                 system_meta)
748 
749     def _complete_deletion(self, context, instance, bdms,
750                            system_meta):
751         self._update_resource_tracker(context, instance)
752 
753         rt = self._get_resource_tracker()
754         rt.reportclient.delete_allocation_for_instance(instance.uuid)
755 
756         self._notify_about_instance_usage(context, instance, "delete.end",
757                 system_metadata=system_meta)
758         compute_utils.notify_about_instance_action(context, instance,
759                 self.host, action=fields.NotificationAction.DELETE,
760                 phase=fields.NotificationPhase.END, bdms=bdms)
761         self._clean_instance_console_tokens(context, instance)
762         self._delete_scheduler_instance_info(context, instance.uuid)
763 
764     def _init_instance(self, context, instance):
765         """Initialize this instance during service init."""
766 
767         # NOTE(danms): If the instance appears to not be owned by this
768         # host, it may have been evacuated away, but skipped by the
769         # evacuation cleanup code due to configuration. Thus, if that
770         # is a possibility, don't touch the instance in any way, but
771         # log the concern. This will help avoid potential issues on
772         # startup due to misconfiguration.
773         if instance.host != self.host:
774             LOG.warning('Instance %(uuid)s appears to not be owned '
775                         'by this host, but by %(host)s. Startup '
776                         'processing is being skipped.',
777                         {'uuid': instance.uuid,
778                          'host': instance.host})
779             return
780 
781         # Instances that are shut down, or in an error state can not be
782         # initialized and are not attempted to be recovered. The exception
783         # to this are instances that are in RESIZE_MIGRATING or DELETING,
784         # which are dealt with further down.
785         if (instance.vm_state == vm_states.SOFT_DELETED or
786             (instance.vm_state == vm_states.ERROR and
787             instance.task_state not in
788             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
789             LOG.debug("Instance is in %s state.",
790                       instance.vm_state, instance=instance)
791             return
792 
793         if instance.vm_state == vm_states.DELETED:
794             try:
795                 self._complete_partial_deletion(context, instance)
796             except Exception:
797                 # we don't want that an exception blocks the init_host
798                 LOG.exception('Failed to complete a deletion',
799                               instance=instance)
800             return
801 
802         if (instance.vm_state == vm_states.BUILDING or
803             instance.task_state in [task_states.SCHEDULING,
804                                     task_states.BLOCK_DEVICE_MAPPING,
805                                     task_states.NETWORKING,
806                                     task_states.SPAWNING]):
807             # NOTE(dave-mcnally) compute stopped before instance was fully
808             # spawned so set to ERROR state. This is safe to do as the state
809             # may be set by the api but the host is not so if we get here the
810             # instance has already been scheduled to this particular host.
811             LOG.debug("Instance failed to spawn correctly, "
812                       "setting to ERROR state", instance=instance)
813             instance.task_state = None
814             instance.vm_state = vm_states.ERROR
815             instance.save()
816             return
817 
818         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
819             instance.task_state in [task_states.REBUILDING,
820                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
821                                     task_states.REBUILD_SPAWNING]):
822             # NOTE(jichenjc) compute stopped before instance was fully
823             # spawned so set to ERROR state. This is consistent to BUILD
824             LOG.debug("Instance failed to rebuild correctly, "
825                       "setting to ERROR state", instance=instance)
826             instance.task_state = None
827             instance.vm_state = vm_states.ERROR
828             instance.save()
829             return
830 
831         if (instance.vm_state != vm_states.ERROR and
832             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
833                                     task_states.IMAGE_PENDING_UPLOAD,
834                                     task_states.IMAGE_UPLOADING,
835                                     task_states.IMAGE_SNAPSHOT]):
836             LOG.debug("Instance in transitional state %s at start-up "
837                       "clearing task state",
838                       instance.task_state, instance=instance)
839             try:
840                 self._post_interrupted_snapshot_cleanup(context, instance)
841             except Exception:
842                 # we don't want that an exception blocks the init_host
843                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
844             instance.task_state = None
845             instance.save()
846 
847         if (instance.vm_state != vm_states.ERROR and
848             instance.task_state in [task_states.RESIZE_PREP]):
849             LOG.debug("Instance in transitional state %s at start-up "
850                       "clearing task state",
851                       instance['task_state'], instance=instance)
852             instance.task_state = None
853             instance.save()
854 
855         if instance.task_state == task_states.DELETING:
856             try:
857                 LOG.info('Service started deleting the instance during '
858                          'the previous run, but did not finish. Restarting'
859                          ' the deletion now.', instance=instance)
860                 instance.obj_load_attr('metadata')
861                 instance.obj_load_attr('system_metadata')
862                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
863                         context, instance.uuid)
864                 self._delete_instance(context, instance, bdms)
865             except Exception:
866                 # we don't want that an exception blocks the init_host
867                 LOG.exception('Failed to complete a deletion',
868                               instance=instance)
869                 self._set_instance_obj_error_state(context, instance)
870             return
871 
872         current_power_state = self._get_power_state(context, instance)
873         try_reboot, reboot_type = self._retry_reboot(context, instance,
874                                                      current_power_state)
875 
876         if try_reboot:
877             LOG.debug("Instance in transitional state (%(task_state)s) at "
878                       "start-up and power state is (%(power_state)s), "
879                       "triggering reboot",
880                       {'task_state': instance.task_state,
881                        'power_state': current_power_state},
882                       instance=instance)
883 
884             # NOTE(mikal): if the instance was doing a soft reboot that got as
885             # far as shutting down the instance but not as far as starting it
886             # again, then we've just become a hard reboot. That means the
887             # task state for the instance needs to change so that we're in one
888             # of the expected task states for a hard reboot.
889             if (instance.task_state in task_states.soft_reboot_states and
890                 reboot_type == 'HARD'):
891                 instance.task_state = task_states.REBOOT_PENDING_HARD
892                 instance.save()
893 
894             self.reboot_instance(context, instance, block_device_info=None,
895                                  reboot_type=reboot_type)
896             return
897 
898         elif (current_power_state == power_state.RUNNING and
899               instance.task_state in [task_states.REBOOT_STARTED,
900                                       task_states.REBOOT_STARTED_HARD,
901                                       task_states.PAUSING,
902                                       task_states.UNPAUSING]):
903             LOG.warning("Instance in transitional state "
904                         "(%(task_state)s) at start-up and power state "
905                         "is (%(power_state)s), clearing task state",
906                         {'task_state': instance.task_state,
907                          'power_state': current_power_state},
908                         instance=instance)
909             instance.task_state = None
910             instance.vm_state = vm_states.ACTIVE
911             instance.save()
912         elif (current_power_state == power_state.PAUSED and
913               instance.task_state == task_states.UNPAUSING):
914             LOG.warning("Instance in transitional state "
915                         "(%(task_state)s) at start-up and power state "
916                         "is (%(power_state)s), clearing task state "
917                         "and unpausing the instance",
918                         {'task_state': instance.task_state,
919                          'power_state': current_power_state},
920                         instance=instance)
921             try:
922                 self.unpause_instance(context, instance)
923             except NotImplementedError:
924                 # Some virt driver didn't support pause and unpause
925                 pass
926             except Exception:
927                 LOG.exception('Failed to unpause instance', instance=instance)
928             return
929 
930         if instance.task_state == task_states.POWERING_OFF:
931             try:
932                 LOG.debug("Instance in transitional state %s at start-up "
933                           "retrying stop request",
934                           instance.task_state, instance=instance)
935                 self.stop_instance(context, instance, True)
936             except Exception:
937                 # we don't want that an exception blocks the init_host
938                 LOG.exception('Failed to stop instance', instance=instance)
939             return
940 
941         if instance.task_state == task_states.POWERING_ON:
942             try:
943                 LOG.debug("Instance in transitional state %s at start-up "
944                           "retrying start request",
945                           instance.task_state, instance=instance)
946                 self.start_instance(context, instance)
947             except Exception:
948                 # we don't want that an exception blocks the init_host
949                 LOG.exception('Failed to start instance', instance=instance)
950             return
951 
952         net_info = instance.get_network_info()
953         try:
954             self.driver.plug_vifs(instance, net_info)
955         except NotImplementedError as e:
956             LOG.debug(e, instance=instance)
957         except exception.VirtualInterfacePlugException:
958             # we don't want an exception to block the init_host
959             LOG.exception("Vifs plug failed", instance=instance)
960             self._set_instance_obj_error_state(context, instance)
961             return
962 
963         if instance.task_state == task_states.RESIZE_MIGRATING:
964             # We crashed during resize/migration, so roll back for safety
965             try:
966                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
967                 # not in system_metadata we default to True for backwards
968                 # compatibility
969                 power_on = (instance.system_metadata.get('old_vm_state') !=
970                             vm_states.STOPPED)
971 
972                 block_dev_info = self._get_instance_block_device_info(context,
973                                                                       instance)
974 
975                 self.driver.finish_revert_migration(context,
976                     instance, net_info, block_dev_info, power_on)
977 
978             except Exception:
979                 LOG.exception('Failed to revert crashed migration',
980                               instance=instance)
981             finally:
982                 LOG.info('Instance found in migrating state during '
983                          'startup. Resetting task_state',
984                          instance=instance)
985                 instance.task_state = None
986                 instance.save()
987         if instance.task_state == task_states.MIGRATING:
988             # Live migration did not complete, but instance is on this
989             # host, so reset the state.
990             instance.task_state = None
991             instance.save(expected_task_state=[task_states.MIGRATING])
992 
993         db_state = instance.power_state
994         drv_state = self._get_power_state(context, instance)
995         expect_running = (db_state == power_state.RUNNING and
996                           drv_state != db_state)
997 
998         LOG.debug('Current state is %(drv_state)s, state in DB is '
999                   '%(db_state)s.',
1000                   {'drv_state': drv_state, 'db_state': db_state},
1001                   instance=instance)
1002 
1003         if expect_running and CONF.resume_guests_state_on_host_boot:
1004             self._resume_guests_state(context, instance, net_info)
1005         elif drv_state == power_state.RUNNING:
1006             # VMwareAPI drivers will raise an exception
1007             try:
1008                 self.driver.ensure_filtering_rules_for_instance(
1009                                        instance, net_info)
1010             except NotImplementedError:
1011                 LOG.debug('Hypervisor driver does not support '
1012                           'firewall rules', instance=instance)
1013 
1014     def _resume_guests_state(self, context, instance, net_info):
1015         LOG.info('Rebooting instance after nova-compute restart.',
1016                  instance=instance)
1017         block_device_info = \
1018             self._get_instance_block_device_info(context, instance)
1019 
1020         try:
1021             self.driver.resume_state_on_host_boot(
1022                 context, instance, net_info, block_device_info)
1023         except NotImplementedError:
1024             LOG.warning('Hypervisor driver does not support '
1025                         'resume guests', instance=instance)
1026         except Exception:
1027             # NOTE(vish): The instance failed to resume, so we set the
1028             #             instance to error and attempt to continue.
1029             LOG.warning('Failed to resume instance',
1030                         instance=instance)
1031             self._set_instance_obj_error_state(context, instance)
1032 
1033     def _retry_reboot(self, context, instance, current_power_state):
1034         current_task_state = instance.task_state
1035         retry_reboot = False
1036         reboot_type = compute_utils.get_reboot_type(current_task_state,
1037                                                     current_power_state)
1038 
1039         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1040                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1041         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1042                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1043         started_not_running = (current_task_state in
1044                                [task_states.REBOOT_STARTED,
1045                                 task_states.REBOOT_STARTED_HARD] and
1046                                current_power_state != power_state.RUNNING)
1047 
1048         if pending_soft or pending_hard or started_not_running:
1049             retry_reboot = True
1050 
1051         return retry_reboot, reboot_type
1052 
1053     def handle_lifecycle_event(self, event):
1054         LOG.info("VM %(state)s (Lifecycle Event)",
1055                  {'state': event.get_name()},
1056                  instance_uuid=event.get_instance_uuid())
1057         context = nova.context.get_admin_context(read_deleted='yes')
1058         instance = objects.Instance.get_by_uuid(context,
1059                                                 event.get_instance_uuid(),
1060                                                 expected_attrs=[])
1061         vm_power_state = None
1062         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1063             vm_power_state = power_state.SHUTDOWN
1064         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1065             vm_power_state = power_state.RUNNING
1066         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1067             vm_power_state = power_state.PAUSED
1068         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1069             vm_power_state = power_state.RUNNING
1070         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1071             vm_power_state = power_state.SUSPENDED
1072         else:
1073             LOG.warning("Unexpected power state %d", event.get_transition())
1074 
1075         # Note(lpetrut): The event may be delayed, thus not reflecting
1076         # the current instance power state. In that case, ignore the event.
1077         current_power_state = self._get_power_state(context, instance)
1078         if current_power_state == vm_power_state:
1079             LOG.debug('Synchronizing instance power state after lifecycle '
1080                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1081                       'current task_state: %(task_state)s, current DB '
1082                       'power_state: %(db_power_state)s, VM power_state: '
1083                       '%(vm_power_state)s',
1084                       {'event': event.get_name(),
1085                        'vm_state': instance.vm_state,
1086                        'task_state': instance.task_state,
1087                        'db_power_state': instance.power_state,
1088                        'vm_power_state': vm_power_state},
1089                       instance_uuid=instance.uuid)
1090             self._sync_instance_power_state(context,
1091                                             instance,
1092                                             vm_power_state)
1093 
1094     def handle_events(self, event):
1095         if isinstance(event, virtevent.LifecycleEvent):
1096             try:
1097                 self.handle_lifecycle_event(event)
1098             except exception.InstanceNotFound:
1099                 LOG.debug("Event %s arrived for non-existent instance. The "
1100                           "instance was probably deleted.", event)
1101         else:
1102             LOG.debug("Ignoring event %s", event)
1103 
1104     def init_virt_events(self):
1105         if CONF.workarounds.handle_virt_lifecycle_events:
1106             self.driver.register_event_listener(self.handle_events)
1107         else:
1108             # NOTE(mriedem): If the _sync_power_states periodic task is
1109             # disabled we should emit a warning in the logs.
1110             if CONF.sync_power_state_interval < 0:
1111                 LOG.warning('Instance lifecycle events from the compute '
1112                             'driver have been disabled. Note that lifecycle '
1113                             'changes to an instance outside of the compute '
1114                             'service will not be synchronized '
1115                             'automatically since the _sync_power_states '
1116                             'periodic task is also disabled.')
1117             else:
1118                 LOG.info('Instance lifecycle events from the compute '
1119                          'driver have been disabled. Note that lifecycle '
1120                          'changes to an instance outside of the compute '
1121                          'service will only be synchronized by the '
1122                          '_sync_power_states periodic task.')
1123 
1124     def init_host(self):
1125         """Initialization for a standalone compute service."""
1126 
1127         if CONF.pci.passthrough_whitelist:
1128             # Simply loading the PCI passthrough whitelist will do a bunch of
1129             # validation that would otherwise wait until the PciDevTracker is
1130             # constructed when updating available resources for the compute
1131             # node(s) in the resource tracker, effectively killing that task.
1132             # So load up the whitelist when starting the compute service to
1133             # flush any invalid configuration early so we can kill the service
1134             # if the configuration is wrong.
1135             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1136 
1137         # NOTE(sbauza): We want the compute node to hard fail if it won't be
1138         # able to provide its resources to the placement API, or it will not
1139         # be able to be eligible as a destination.
1140         if CONF.placement.os_region_name is None:
1141             raise exception.PlacementNotConfigured()
1142 
1143         self.driver.init_host(host=self.host)
1144         context = nova.context.get_admin_context()
1145         instances = objects.InstanceList.get_by_host(
1146             context, self.host, expected_attrs=['info_cache', 'metadata'])
1147 
1148         if CONF.defer_iptables_apply:
1149             self.driver.filter_defer_apply_on()
1150 
1151         self.init_virt_events()
1152 
1153         try:
1154             # checking that instance was not already evacuated to other host
1155             self._destroy_evacuated_instances(context)
1156             for instance in instances:
1157                 self._init_instance(context, instance)
1158         finally:
1159             if CONF.defer_iptables_apply:
1160                 self.driver.filter_defer_apply_off()
1161             if instances:
1162                 # We only send the instance info to the scheduler on startup
1163                 # if there is anything to send, otherwise this host might
1164                 # not be mapped yet in a cell and the scheduler may have
1165                 # issues dealing with the information. Later changes to
1166                 # instances on this host will update the scheduler, or the
1167                 # _sync_scheduler_instance_info periodic task will.
1168                 self._update_scheduler_instance_info(context, instances)
1169 
1170     def cleanup_host(self):
1171         self.driver.register_event_listener(None)
1172         self.instance_events.cancel_all_events()
1173         self.driver.cleanup_host(host=self.host)
1174 
1175     def pre_start_hook(self):
1176         """After the service is initialized, but before we fully bring
1177         the service up by listening on RPC queues, make sure to update
1178         our available resources (and indirectly our available nodes).
1179         """
1180         self.update_available_resource(nova.context.get_admin_context(),
1181                                        startup=True)
1182 
1183     def _get_power_state(self, context, instance):
1184         """Retrieve the power state for the given instance."""
1185         LOG.debug('Checking state', instance=instance)
1186         try:
1187             return self.driver.get_info(instance).state
1188         except exception.InstanceNotFound:
1189             return power_state.NOSTATE
1190 
1191     def get_console_topic(self, context):
1192         """Retrieves the console host for a project on this host.
1193 
1194         Currently this is just set in the flags for each compute host.
1195 
1196         """
1197         # TODO(mdragon): perhaps make this variable by console_type?
1198         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1199 
1200     @wrap_exception()
1201     def get_console_pool_info(self, context, console_type):
1202         return self.driver.get_console_pool_info(console_type)
1203 
1204     # NOTE(hanlind): This and the virt method it calls can be removed in
1205     # version 5.0 of the RPC API
1206     @wrap_exception()
1207     def refresh_security_group_rules(self, context, security_group_id):
1208         """Tell the virtualization driver to refresh security group rules.
1209 
1210         Passes straight through to the virtualization driver.
1211 
1212         """
1213         return self.driver.refresh_security_group_rules(security_group_id)
1214 
1215     # TODO(alaski): Remove object_compat for RPC version 5.0
1216     @object_compat
1217     @wrap_exception()
1218     def refresh_instance_security_rules(self, context, instance):
1219         """Tell the virtualization driver to refresh security rules for
1220         an instance.
1221 
1222         Passes straight through to the virtualization driver.
1223 
1224         Synchronize the call because we may still be in the middle of
1225         creating the instance.
1226         """
1227         @utils.synchronized(instance.uuid)
1228         def _sync_refresh():
1229             try:
1230                 return self.driver.refresh_instance_security_rules(instance)
1231             except NotImplementedError:
1232                 LOG.debug('Hypervisor driver does not support '
1233                           'security groups.', instance=instance)
1234 
1235         return _sync_refresh()
1236 
1237     def _await_block_device_map_created(self, context, vol_id):
1238         # TODO(yamahata): creating volume simultaneously
1239         #                 reduces creation time?
1240         # TODO(yamahata): eliminate dumb polling
1241         start = time.time()
1242         retries = CONF.block_device_allocate_retries
1243         if retries < 0:
1244             LOG.warning("Treating negative config value (%(retries)s) for "
1245                         "'block_device_retries' as 0.",
1246                         {'retries': retries})
1247         # (1) treat  negative config value as 0
1248         # (2) the configured value is 0, one attempt should be made
1249         # (3) the configured value is > 0, then the total number attempts
1250         #      is (retries + 1)
1251         attempts = 1
1252         if retries >= 1:
1253             attempts = retries + 1
1254         for attempt in range(1, attempts + 1):
1255             volume = self.volume_api.get(context, vol_id)
1256             volume_status = volume['status']
1257             if volume_status not in ['creating', 'downloading']:
1258                 if volume_status == 'available':
1259                     return attempt
1260                 LOG.warning("Volume id: %(vol_id)s finished being "
1261                             "created but its status is %(vol_status)s.",
1262                             {'vol_id': vol_id,
1263                              'vol_status': volume_status})
1264                 break
1265             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1266         raise exception.VolumeNotCreated(volume_id=vol_id,
1267                                          seconds=int(time.time() - start),
1268                                          attempts=attempt,
1269                                          volume_status=volume_status)
1270 
1271     def _decode_files(self, injected_files):
1272         """Base64 decode the list of files to inject."""
1273         if not injected_files:
1274             return []
1275 
1276         def _decode(f):
1277             path, contents = f
1278             # Py3 raises binascii.Error instead of TypeError as in Py27
1279             try:
1280                 decoded = base64.b64decode(contents)
1281                 return path, decoded
1282             except (TypeError, binascii.Error):
1283                 raise exception.Base64Exception(path=path)
1284 
1285         return [_decode(f) for f in injected_files]
1286 
1287     def _validate_instance_group_policy(self, context, instance,
1288                                         scheduler_hints):
1289         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1290         # However, there is a race condition with the enforcement of
1291         # the policy.  Since more than one instance may be scheduled at the
1292         # same time, it's possible that more than one instance with an
1293         # anti-affinity policy may end up here.  It's also possible that
1294         # multiple instances with an affinity policy could end up on different
1295         # hosts.  This is a validation step to make sure that starting the
1296         # instance here doesn't violate the policy.
1297         group_hint = scheduler_hints.get('group')
1298         if not group_hint:
1299             return
1300 
1301         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1302         # to check the type on the value and pull the single entry out. The
1303         # API request schema validates that the 'group' hint is a single value.
1304         if isinstance(group_hint, list):
1305             group_hint = group_hint[0]
1306 
1307         @utils.synchronized(group_hint)
1308         def _do_validation(context, instance, group_hint):
1309             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1310             if 'anti-affinity' in group.policies:
1311                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1312                 if self.host in group_hosts:
1313                     msg = _("Anti-affinity instance group policy "
1314                             "was violated.")
1315                     raise exception.RescheduledException(
1316                             instance_uuid=instance.uuid,
1317                             reason=msg)
1318             elif 'affinity' in group.policies:
1319                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1320                 if group_hosts and self.host not in group_hosts:
1321                     msg = _("Affinity instance group policy was violated.")
1322                     raise exception.RescheduledException(
1323                             instance_uuid=instance.uuid,
1324                             reason=msg)
1325 
1326         if not CONF.workarounds.disable_group_policy_check_upcall:
1327             _do_validation(context, instance, group_hint)
1328 
1329     def _log_original_error(self, exc_info, instance_uuid):
1330         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1331                   exc_info=exc_info)
1332 
1333     def _reschedule(self, context, request_spec, filter_properties,
1334             instance, reschedule_method, method_args, task_state,
1335             exc_info=None):
1336         """Attempt to re-schedule a compute operation."""
1337 
1338         instance_uuid = instance.uuid
1339         retry = filter_properties.get('retry')
1340         if not retry:
1341             # no retry information, do not reschedule.
1342             LOG.debug("Retry info not present, will not reschedule",
1343                       instance_uuid=instance_uuid)
1344             return
1345 
1346         if not request_spec:
1347             LOG.debug("No request spec, will not reschedule",
1348                       instance_uuid=instance_uuid)
1349             return
1350 
1351         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1352                   {'method': reschedule_method.__name__,
1353                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1354 
1355         # reset the task state:
1356         self._instance_update(context, instance, task_state=task_state)
1357 
1358         if exc_info:
1359             # stringify to avoid circular ref problem in json serialization:
1360             retry['exc'] = traceback.format_exception_only(exc_info[0],
1361                                     exc_info[1])
1362 
1363         reschedule_method(context, *method_args)
1364         return True
1365 
1366     @periodic_task.periodic_task
1367     def _check_instance_build_time(self, context):
1368         """Ensure that instances are not stuck in build."""
1369         timeout = CONF.instance_build_timeout
1370         if timeout == 0:
1371             return
1372 
1373         filters = {'vm_state': vm_states.BUILDING,
1374                    'host': self.host}
1375 
1376         building_insts = objects.InstanceList.get_by_filters(context,
1377                            filters, expected_attrs=[], use_slave=True)
1378 
1379         for instance in building_insts:
1380             if timeutils.is_older_than(instance.created_at, timeout):
1381                 self._set_instance_obj_error_state(context, instance)
1382                 LOG.warning("Instance build timed out. Set to error "
1383                             "state.", instance=instance)
1384 
1385     def _check_instance_exists(self, context, instance):
1386         """Ensure an instance with the same name is not already present."""
1387         if self.driver.instance_exists(instance):
1388             raise exception.InstanceExists(name=instance.name)
1389 
1390     def _allocate_network_async(self, context, instance, requested_networks,
1391                                 macs, security_groups, is_vpn):
1392         """Method used to allocate networks in the background.
1393 
1394         Broken out for testing.
1395         """
1396         # First check to see if we're specifically not supposed to allocate
1397         # networks because if so, we can exit early.
1398         if requested_networks and requested_networks.no_allocate:
1399             LOG.debug("Not allocating networking since 'none' was specified.",
1400                       instance=instance)
1401             return network_model.NetworkInfo([])
1402 
1403         LOG.debug("Allocating IP information in the background.",
1404                   instance=instance)
1405         retries = CONF.network_allocate_retries
1406         attempts = retries + 1
1407         retry_time = 1
1408         bind_host_id = self.driver.network_binding_host_id(context, instance)
1409         for attempt in range(1, attempts + 1):
1410             try:
1411                 nwinfo = self.network_api.allocate_for_instance(
1412                         context, instance, vpn=is_vpn,
1413                         requested_networks=requested_networks,
1414                         macs=macs,
1415                         security_groups=security_groups,
1416                         bind_host_id=bind_host_id)
1417                 LOG.debug('Instance network_info: |%s|', nwinfo,
1418                           instance=instance)
1419                 instance.system_metadata['network_allocated'] = 'True'
1420                 # NOTE(JoshNang) do not save the instance here, as it can cause
1421                 # races. The caller shares a reference to instance and waits
1422                 # for this async greenthread to finish before calling
1423                 # instance.save().
1424                 return nwinfo
1425             except Exception:
1426                 exc_info = sys.exc_info()
1427                 log_info = {'attempt': attempt,
1428                             'attempts': attempts}
1429                 if attempt == attempts:
1430                     LOG.exception('Instance failed network setup '
1431                                   'after %(attempts)d attempt(s)',
1432                                   log_info)
1433                     six.reraise(*exc_info)
1434                 LOG.warning('Instance failed network setup '
1435                             '(attempt %(attempt)d of %(attempts)d)',
1436                             log_info, instance=instance)
1437                 time.sleep(retry_time)
1438                 retry_time *= 2
1439                 if retry_time > 30:
1440                     retry_time = 30
1441         # Not reached.
1442 
1443     def _build_networks_for_instance(self, context, instance,
1444             requested_networks, security_groups):
1445 
1446         # If we're here from a reschedule the network may already be allocated.
1447         if strutils.bool_from_string(
1448                 instance.system_metadata.get('network_allocated', 'False')):
1449             # NOTE(alex_xu): The network_allocated is True means the network
1450             # resource already allocated at previous scheduling, and the
1451             # network setup is cleanup at previous. After rescheduling, the
1452             # network resource need setup on the new host.
1453             self.network_api.setup_instance_network_on_host(
1454                 context, instance, instance.host)
1455             return self.network_api.get_instance_nw_info(context, instance)
1456 
1457         if not self.is_neutron_security_groups:
1458             security_groups = []
1459 
1460         macs = self.driver.macs_for_instance(instance)
1461         network_info = self._allocate_network(context, instance,
1462                 requested_networks, macs, security_groups)
1463 
1464         return network_info
1465 
1466     def _allocate_network(self, context, instance, requested_networks, macs,
1467                           security_groups):
1468         """Start network allocation asynchronously.  Return an instance
1469         of NetworkInfoAsyncWrapper that can be used to retrieve the
1470         allocated networks when the operation has finished.
1471         """
1472         # NOTE(comstud): Since we're allocating networks asynchronously,
1473         # this task state has little meaning, as we won't be in this
1474         # state for very long.
1475         instance.vm_state = vm_states.BUILDING
1476         instance.task_state = task_states.NETWORKING
1477         instance.save(expected_task_state=[None])
1478 
1479         is_vpn = False
1480         return network_model.NetworkInfoAsyncWrapper(
1481                 self._allocate_network_async, context, instance,
1482                 requested_networks, macs, security_groups, is_vpn)
1483 
1484     def _default_root_device_name(self, instance, image_meta, root_bdm):
1485         try:
1486             return self.driver.default_root_device_name(instance,
1487                                                         image_meta,
1488                                                         root_bdm)
1489         except NotImplementedError:
1490             return compute_utils.get_next_device_name(instance, [])
1491 
1492     def _default_device_names_for_instance(self, instance,
1493                                            root_device_name,
1494                                            *block_device_lists):
1495         try:
1496             self.driver.default_device_names_for_instance(instance,
1497                                                           root_device_name,
1498                                                           *block_device_lists)
1499         except NotImplementedError:
1500             compute_utils.default_device_names_for_instance(
1501                 instance, root_device_name, *block_device_lists)
1502 
1503     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1504         # NOTE(ndipanov): Copy obj to avoid changing the original
1505         block_device_obj = block_device_obj.obj_clone()
1506         try:
1507             return self.driver.get_device_name_for_instance(
1508                 instance, bdms, block_device_obj)
1509         except NotImplementedError:
1510             return compute_utils.get_device_name_for_instance(
1511                 instance, bdms, block_device_obj.get("device_name"))
1512 
1513     def _default_block_device_names(self, instance, image_meta, block_devices):
1514         """Verify that all the devices have the device_name set. If not,
1515         provide a default name.
1516 
1517         It also ensures that there is a root_device_name and is set to the
1518         first block device in the boot sequence (boot_index=0).
1519         """
1520         root_bdm = block_device.get_root_bdm(block_devices)
1521         if not root_bdm:
1522             return
1523 
1524         # Get the root_device_name from the root BDM or the instance
1525         root_device_name = None
1526         update_root_bdm = False
1527 
1528         if root_bdm.device_name:
1529             root_device_name = root_bdm.device_name
1530             instance.root_device_name = root_device_name
1531         elif instance.root_device_name:
1532             root_device_name = instance.root_device_name
1533             root_bdm.device_name = root_device_name
1534             update_root_bdm = True
1535         else:
1536             root_device_name = self._default_root_device_name(instance,
1537                                                               image_meta,
1538                                                               root_bdm)
1539 
1540             instance.root_device_name = root_device_name
1541             root_bdm.device_name = root_device_name
1542             update_root_bdm = True
1543 
1544         if update_root_bdm:
1545             root_bdm.save()
1546 
1547         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1548                             block_devices))
1549         swap = list(filter(block_device.new_format_is_swap,
1550                       block_devices))
1551         block_device_mapping = list(filter(
1552               driver_block_device.is_block_device_mapping, block_devices))
1553 
1554         self._default_device_names_for_instance(instance,
1555                                                 root_device_name,
1556                                                 ephemerals,
1557                                                 swap,
1558                                                 block_device_mapping)
1559 
1560     def _block_device_info_to_legacy(self, block_device_info):
1561         """Convert BDI to the old format for drivers that need it."""
1562 
1563         if self.use_legacy_block_device_info:
1564             ephemerals = driver_block_device.legacy_block_devices(
1565                 driver.block_device_info_get_ephemerals(block_device_info))
1566             mapping = driver_block_device.legacy_block_devices(
1567                 driver.block_device_info_get_mapping(block_device_info))
1568             swap = block_device_info['swap']
1569             if swap:
1570                 swap = swap.legacy()
1571 
1572             block_device_info.update({
1573                 'ephemerals': ephemerals,
1574                 'swap': swap,
1575                 'block_device_mapping': mapping})
1576 
1577     def _add_missing_dev_names(self, bdms, instance):
1578         for bdm in bdms:
1579             if bdm.device_name is not None:
1580                 continue
1581 
1582             device_name = self._get_device_name_for_instance(instance,
1583                                                              bdms, bdm)
1584             values = {'device_name': device_name}
1585             bdm.update(values)
1586             bdm.save()
1587 
1588     def _prep_block_device(self, context, instance, bdms):
1589         """Set up the block device for an instance with error logging."""
1590         try:
1591             self._add_missing_dev_names(bdms, instance)
1592             block_device_info = driver.get_block_device_info(instance, bdms)
1593             mapping = driver.block_device_info_get_mapping(block_device_info)
1594             driver_block_device.attach_block_devices(
1595                 mapping, context, instance, self.volume_api, self.driver,
1596                 wait_func=self._await_block_device_map_created)
1597 
1598             self._block_device_info_to_legacy(block_device_info)
1599             return block_device_info
1600 
1601         except exception.OverQuota as e:
1602             LOG.warning('Failed to create block device for instance due'
1603                         ' to exceeding volume related resource quota.'
1604                         ' Error: %s', e.message, instance=instance)
1605             raise
1606 
1607         except Exception as ex:
1608             LOG.exception('Instance failed block device setup',
1609                           instance=instance)
1610             # InvalidBDM will eventually result in a BuildAbortException when
1611             # booting from volume, and will be recorded as an instance fault.
1612             # Maintain the original exception message which most likely has
1613             # useful details which the standard InvalidBDM error message lacks.
1614             raise exception.InvalidBDM(six.text_type(ex))
1615 
1616     def _update_instance_after_spawn(self, context, instance):
1617         instance.power_state = self._get_power_state(context, instance)
1618         instance.vm_state = vm_states.ACTIVE
1619         instance.task_state = None
1620         instance.launched_at = timeutils.utcnow()
1621         configdrive.update_instance(instance)
1622 
1623     def _update_scheduler_instance_info(self, context, instance):
1624         """Sends an InstanceList with created or updated Instance objects to
1625         the Scheduler client.
1626 
1627         In the case of init_host, the value passed will already be an
1628         InstanceList. Other calls will send individual Instance objects that
1629         have been created or resized. In this case, we create an InstanceList
1630         object containing that Instance.
1631         """
1632         if not self.send_instance_updates:
1633             return
1634         if isinstance(instance, obj_instance.Instance):
1635             instance = objects.InstanceList(objects=[instance])
1636         context = context.elevated()
1637         self.scheduler_client.update_instance_info(context, self.host,
1638                                                    instance)
1639 
1640     def _delete_scheduler_instance_info(self, context, instance_uuid):
1641         """Sends the uuid of the deleted Instance to the Scheduler client."""
1642         if not self.send_instance_updates:
1643             return
1644         context = context.elevated()
1645         self.scheduler_client.delete_instance_info(context, self.host,
1646                                                    instance_uuid)
1647 
1648     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1649     def _sync_scheduler_instance_info(self, context):
1650         if not self.send_instance_updates:
1651             return
1652         context = context.elevated()
1653         instances = objects.InstanceList.get_by_host(context, self.host,
1654                                                      expected_attrs=[],
1655                                                      use_slave=True)
1656         uuids = [instance.uuid for instance in instances]
1657         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1658 
1659     def _notify_about_instance_usage(self, context, instance, event_suffix,
1660                                      network_info=None, system_metadata=None,
1661                                      extra_usage_info=None, fault=None):
1662         compute_utils.notify_about_instance_usage(
1663             self.notifier, context, instance, event_suffix,
1664             network_info=network_info,
1665             system_metadata=system_metadata,
1666             extra_usage_info=extra_usage_info, fault=fault)
1667 
1668     def _deallocate_network(self, context, instance,
1669                             requested_networks=None):
1670         # If we were told not to allocate networks let's save ourselves
1671         # the trouble of calling the network API.
1672         if requested_networks and requested_networks.no_allocate:
1673             LOG.debug("Skipping network deallocation for instance since "
1674                       "networking was not requested.", instance=instance)
1675             return
1676 
1677         LOG.debug('Deallocating network for instance', instance=instance)
1678         with timeutils.StopWatch() as timer:
1679             self.network_api.deallocate_for_instance(
1680                 context, instance, requested_networks=requested_networks)
1681         # nova-network does an rpc call so we're OK tracking time spent here
1682         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1683                  timer.elapsed(), instance=instance)
1684 
1685     def _get_instance_block_device_info(self, context, instance,
1686                                         refresh_conn_info=False,
1687                                         bdms=None):
1688         """Transform block devices to the driver block_device format."""
1689 
1690         if not bdms:
1691             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1692                     context, instance.uuid)
1693         block_device_info = driver.get_block_device_info(instance, bdms)
1694 
1695         if not refresh_conn_info:
1696             # if the block_device_mapping has no value in connection_info
1697             # (returned as None), don't include in the mapping
1698             block_device_info['block_device_mapping'] = [
1699                 bdm for bdm in driver.block_device_info_get_mapping(
1700                                     block_device_info)
1701                 if bdm.get('connection_info')]
1702         else:
1703             driver_block_device.refresh_conn_infos(
1704                 driver.block_device_info_get_mapping(block_device_info),
1705                 context, instance, self.volume_api, self.driver)
1706 
1707         self._block_device_info_to_legacy(block_device_info)
1708 
1709         return block_device_info
1710 
1711     def _build_failed(self):
1712         self._failed_builds += 1
1713         limit = CONF.compute.consecutive_build_service_disable_threshold
1714         if limit and self._failed_builds >= limit:
1715             # NOTE(danms): If we're doing a bunch of parallel builds,
1716             # it is possible (although not likely) that we have already
1717             # failed N-1 builds before this and we race with a successful
1718             # build and disable ourselves here when we might've otherwise
1719             # not.
1720             LOG.error('Disabling service due to %(fails)i '
1721                       'consecutive build failures',
1722                       {'fails': self._failed_builds})
1723             ctx = nova.context.get_admin_context()
1724             service = objects.Service.get_by_compute_host(ctx, CONF.host)
1725             service.disabled = True
1726             service.disabled_reason = (
1727                 'Auto-disabled due to %i build failures' % self._failed_builds)
1728             service.save()
1729             # NOTE(danms): Reset our counter now so that when the admin
1730             # re-enables us we can start fresh
1731             self._failed_builds = 0
1732         elif self._failed_builds > 1:
1733             LOG.warning('%(fails)i consecutive build failures',
1734                         {'fails': self._failed_builds})
1735 
1736     @wrap_exception()
1737     @reverts_task_state
1738     @wrap_instance_fault
1739     def build_and_run_instance(self, context, instance, image, request_spec,
1740                      filter_properties, admin_password=None,
1741                      injected_files=None, requested_networks=None,
1742                      security_groups=None, block_device_mapping=None,
1743                      node=None, limits=None):
1744 
1745         @utils.synchronized(instance.uuid)
1746         def _locked_do_build_and_run_instance(*args, **kwargs):
1747             # NOTE(danms): We grab the semaphore with the instance uuid
1748             # locked because we could wait in line to build this instance
1749             # for a while and we want to make sure that nothing else tries
1750             # to do anything with this instance while we wait.
1751             with self._build_semaphore:
1752                 try:
1753                     result = self._do_build_and_run_instance(*args, **kwargs)
1754                 except Exception:
1755                     # NOTE(mriedem): This should really only happen if
1756                     # _decode_files in _do_build_and_run_instance fails, and
1757                     # that's before a guest is spawned so it's OK to remove
1758                     # allocations for the instance for this node from Placement
1759                     # below as there is no guest consuming resources anyway.
1760                     # The _decode_files case could be handled more specifically
1761                     # but that's left for another day.
1762                     result = build_results.FAILED
1763                     raise
1764                 finally:
1765                     fails = (build_results.FAILED,
1766                              build_results.RESCHEDULED)
1767                     if result in fails:
1768                         # Remove the allocation records from Placement for
1769                         # the instance if the build failed or is being
1770                         # rescheduled to another node. The instance.host is
1771                         # likely set to None in _do_build_and_run_instance
1772                         # which means if the user deletes the instance, it will
1773                         # be deleted in the API, not the compute service.
1774                         # Setting the instance.host to None in
1775                         # _do_build_and_run_instance means that the
1776                         # ResourceTracker will no longer consider this instance
1777                         # to be claiming resources against it, so we want to
1778                         # reflect that same thing in Placement.
1779                         rt = self._get_resource_tracker()
1780                         rt.reportclient.delete_allocation_for_instance(
1781                             instance.uuid)
1782 
1783                         self._build_failed()
1784                     else:
1785                         self._failed_builds = 0
1786 
1787         # NOTE(danms): We spawn here to return the RPC worker thread back to
1788         # the pool. Since what follows could take a really long time, we don't
1789         # want to tie up RPC workers.
1790         utils.spawn_n(_locked_do_build_and_run_instance,
1791                       context, instance, image, request_spec,
1792                       filter_properties, admin_password, injected_files,
1793                       requested_networks, security_groups,
1794                       block_device_mapping, node, limits)
1795 
1796     def _check_device_tagging(self, requested_networks, block_device_mapping):
1797         tagging_requested = False
1798         if requested_networks:
1799             for net in requested_networks:
1800                 if 'tag' in net and net.tag is not None:
1801                     tagging_requested = True
1802                     break
1803         if block_device_mapping and not tagging_requested:
1804             for bdm in block_device_mapping:
1805                 if 'tag' in bdm and bdm.tag is not None:
1806                     tagging_requested = True
1807                     break
1808         if (tagging_requested and
1809                 not self.driver.capabilities.get('supports_device_tagging')):
1810             raise exception.BuildAbortException('Attempt to boot guest with '
1811                                                 'tagged devices on host that '
1812                                                 'does not support tagging.')
1813 
1814     @hooks.add_hook('build_instance')
1815     @wrap_exception()
1816     @reverts_task_state
1817     @wrap_instance_event(prefix='compute')
1818     @wrap_instance_fault
1819     def _do_build_and_run_instance(self, context, instance, image,
1820             request_spec, filter_properties, admin_password, injected_files,
1821             requested_networks, security_groups, block_device_mapping,
1822             node=None, limits=None):
1823 
1824         try:
1825             LOG.debug('Starting instance...', instance=instance)
1826             instance.vm_state = vm_states.BUILDING
1827             instance.task_state = None
1828             instance.save(expected_task_state=
1829                     (task_states.SCHEDULING, None))
1830         except exception.InstanceNotFound:
1831             msg = 'Instance disappeared before build.'
1832             LOG.debug(msg, instance=instance)
1833             return build_results.FAILED
1834         except exception.UnexpectedTaskStateError as e:
1835             LOG.debug(e.format_message(), instance=instance)
1836             return build_results.FAILED
1837 
1838         # b64 decode the files to inject:
1839         decoded_files = self._decode_files(injected_files)
1840 
1841         if limits is None:
1842             limits = {}
1843 
1844         if node is None:
1845             node = self._get_nodename(instance, refresh=True)
1846 
1847         try:
1848             with timeutils.StopWatch() as timer:
1849                 self._build_and_run_instance(context, instance, image,
1850                         decoded_files, admin_password, requested_networks,
1851                         security_groups, block_device_mapping, node, limits,
1852                         filter_properties, request_spec)
1853             LOG.info('Took %0.2f seconds to build instance.',
1854                      timer.elapsed(), instance=instance)
1855             return build_results.ACTIVE
1856         except exception.RescheduledException as e:
1857             retry = filter_properties.get('retry')
1858             if not retry:
1859                 # no retry information, do not reschedule.
1860                 LOG.debug("Retry info not present, will not reschedule",
1861                     instance=instance)
1862                 self._cleanup_allocated_networks(context, instance,
1863                     requested_networks)
1864                 self._cleanup_volumes(context, instance.uuid,
1865                     block_device_mapping, raise_exc=False)
1866                 compute_utils.add_instance_fault_from_exc(context,
1867                         instance, e, sys.exc_info(),
1868                         fault_message=e.kwargs['reason'])
1869                 self._nil_out_instance_obj_host_and_node(instance)
1870                 self._set_instance_obj_error_state(context, instance,
1871                                                    clean_task_state=True)
1872                 return build_results.FAILED
1873             LOG.debug(e.format_message(), instance=instance)
1874             # This will be used for logging the exception
1875             retry['exc'] = traceback.format_exception(*sys.exc_info())
1876             # This will be used for setting the instance fault message
1877             retry['exc_reason'] = e.kwargs['reason']
1878             # NOTE(comstud): Deallocate networks if the driver wants
1879             # us to do so.
1880             # NOTE(vladikr): SR-IOV ports should be deallocated to
1881             # allow new sriov pci devices to be allocated on a new host.
1882             # Otherwise, if devices with pci addresses are already allocated
1883             # on the destination host, the instance will fail to spawn.
1884             # info_cache.network_info should be present at this stage.
1885             if (self.driver.deallocate_networks_on_reschedule(instance) or
1886                 self.deallocate_sriov_ports_on_reschedule(instance)):
1887                 self._cleanup_allocated_networks(context, instance,
1888                         requested_networks)
1889             else:
1890                 # NOTE(alex_xu): Network already allocated and we don't
1891                 # want to deallocate them before rescheduling. But we need
1892                 # to cleanup those network resources setup on this host before
1893                 # rescheduling.
1894                 self.network_api.cleanup_instance_network_on_host(
1895                     context, instance, self.host)
1896 
1897             self._nil_out_instance_obj_host_and_node(instance)
1898             instance.task_state = task_states.SCHEDULING
1899             instance.save()
1900 
1901             # TODO(mriedem): Pass the request_spec back to conductor so that
1902             # it gets to the next chosen host during the reschedule and we
1903             # can hopefully eventually get rid of the legacy filter_properties.
1904             self.compute_task_api.build_instances(context, [instance],
1905                     image, filter_properties, admin_password,
1906                     injected_files, requested_networks, security_groups,
1907                     block_device_mapping)
1908             return build_results.RESCHEDULED
1909         except (exception.InstanceNotFound,
1910                 exception.UnexpectedDeletingTaskStateError):
1911             msg = 'Instance disappeared during build.'
1912             LOG.debug(msg, instance=instance)
1913             self._cleanup_allocated_networks(context, instance,
1914                     requested_networks)
1915             return build_results.FAILED
1916         except exception.BuildAbortException as e:
1917             LOG.exception(e.format_message(), instance=instance)
1918             self._cleanup_allocated_networks(context, instance,
1919                     requested_networks)
1920             self._cleanup_volumes(context, instance.uuid,
1921                     block_device_mapping, raise_exc=False)
1922             compute_utils.add_instance_fault_from_exc(context, instance,
1923                     e, sys.exc_info())
1924             self._nil_out_instance_obj_host_and_node(instance)
1925             self._set_instance_obj_error_state(context, instance,
1926                                                clean_task_state=True)
1927             return build_results.FAILED
1928         except Exception as e:
1929             # Should not reach here.
1930             LOG.exception('Unexpected build failure, not rescheduling build.',
1931                           instance=instance)
1932             self._cleanup_allocated_networks(context, instance,
1933                     requested_networks)
1934             self._cleanup_volumes(context, instance.uuid,
1935                     block_device_mapping, raise_exc=False)
1936             compute_utils.add_instance_fault_from_exc(context, instance,
1937                     e, sys.exc_info())
1938             self._nil_out_instance_obj_host_and_node(instance)
1939             self._set_instance_obj_error_state(context, instance,
1940                                                clean_task_state=True)
1941             return build_results.FAILED
1942 
1943     def deallocate_sriov_ports_on_reschedule(self, instance):
1944         """Determine if networks are needed to be deallocated before reschedule
1945 
1946         Check the cached network info for any assigned SR-IOV ports.
1947         SR-IOV ports should be deallocated prior to rescheduling
1948         in order to allow new sriov pci devices to be allocated on a new host.
1949         """
1950         info_cache = instance.info_cache
1951 
1952         def _has_sriov_port(vif):
1953             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1954 
1955         if (info_cache and info_cache.network_info):
1956             for vif in info_cache.network_info:
1957                 if _has_sriov_port(vif):
1958                     return True
1959         return False
1960 
1961     @staticmethod
1962     def _get_scheduler_hints(filter_properties, request_spec=None):
1963         """Helper method to get scheduler hints.
1964 
1965         This method prefers to get the hints out of the request spec, but that
1966         might not be provided. Conductor will pass request_spec down to the
1967         first compute chosen for a build but older computes will not pass
1968         the request_spec to conductor's build_instances method for a
1969         a reschedule, so if we're on a host via a retry, request_spec may not
1970         be provided so we need to fallback to use the filter_properties
1971         to get scheduler hints.
1972         """
1973         hints = {}
1974         if request_spec is not None and 'scheduler_hints' in request_spec:
1975             hints = request_spec.scheduler_hints
1976         if not hints:
1977             hints = filter_properties.get('scheduler_hints') or {}
1978         return hints
1979 
1980     def _build_and_run_instance(self, context, instance, image, injected_files,
1981             admin_password, requested_networks, security_groups,
1982             block_device_mapping, node, limits, filter_properties,
1983             request_spec=None):
1984 
1985         image_name = image.get('name')
1986         self._notify_about_instance_usage(context, instance, 'create.start',
1987                 extra_usage_info={'image_name': image_name})
1988         compute_utils.notify_about_instance_create(
1989             context, instance, self.host,
1990             phase=fields.NotificationPhase.START,
1991             bdms=block_device_mapping)
1992 
1993         # NOTE(mikal): cache the keystone roles associated with the instance
1994         # at boot time for later reference
1995         instance.system_metadata.update(
1996             {'boot_roles': ','.join(context.roles)})
1997 
1998         self._check_device_tagging(requested_networks, block_device_mapping)
1999 
2000         try:
2001             scheduler_hints = self._get_scheduler_hints(filter_properties,
2002                                                         request_spec)
2003             rt = self._get_resource_tracker()
2004             with rt.instance_claim(context, instance, node, limits):
2005                 # NOTE(russellb) It's important that this validation be done
2006                 # *after* the resource tracker instance claim, as that is where
2007                 # the host is set on the instance.
2008                 self._validate_instance_group_policy(context, instance,
2009                                                      scheduler_hints)
2010                 image_meta = objects.ImageMeta.from_dict(image)
2011                 with self._build_resources(context, instance,
2012                         requested_networks, security_groups, image_meta,
2013                         block_device_mapping) as resources:
2014                     instance.vm_state = vm_states.BUILDING
2015                     instance.task_state = task_states.SPAWNING
2016                     # NOTE(JoshNang) This also saves the changes to the
2017                     # instance from _allocate_network_async, as they aren't
2018                     # saved in that function to prevent races.
2019                     instance.save(expected_task_state=
2020                             task_states.BLOCK_DEVICE_MAPPING)
2021                     block_device_info = resources['block_device_info']
2022                     network_info = resources['network_info']
2023                     allocs = resources['allocations']
2024                     LOG.debug('Start spawning the instance on the hypervisor.',
2025                               instance=instance)
2026                     with timeutils.StopWatch() as timer:
2027                         self.driver.spawn(context, instance, image_meta,
2028                                           injected_files, admin_password,
2029                                           allocs, network_info=network_info,
2030                                           block_device_info=block_device_info)
2031                     LOG.info('Took %0.2f seconds to spawn the instance on '
2032                              'the hypervisor.', timer.elapsed(),
2033                              instance=instance)
2034         except (exception.InstanceNotFound,
2035                 exception.UnexpectedDeletingTaskStateError) as e:
2036             with excutils.save_and_reraise_exception():
2037                 self._notify_about_instance_usage(context, instance,
2038                     'create.error', fault=e)
2039                 compute_utils.notify_about_instance_create(
2040                     context, instance, self.host,
2041                     phase=fields.NotificationPhase.ERROR, exception=e,
2042                     bdms=block_device_mapping)
2043         except exception.ComputeResourcesUnavailable as e:
2044             LOG.debug(e.format_message(), instance=instance)
2045             self._notify_about_instance_usage(context, instance,
2046                     'create.error', fault=e)
2047             compute_utils.notify_about_instance_create(
2048                     context, instance, self.host,
2049                     phase=fields.NotificationPhase.ERROR, exception=e,
2050                     bdms=block_device_mapping)
2051             raise exception.RescheduledException(
2052                     instance_uuid=instance.uuid, reason=e.format_message())
2053         except exception.BuildAbortException as e:
2054             with excutils.save_and_reraise_exception():
2055                 LOG.debug(e.format_message(), instance=instance)
2056                 self._notify_about_instance_usage(context, instance,
2057                     'create.error', fault=e)
2058                 compute_utils.notify_about_instance_create(
2059                     context, instance, self.host,
2060                     phase=fields.NotificationPhase.ERROR, exception=e,
2061                     bdms=block_device_mapping)
2062         except (exception.FixedIpLimitExceeded,
2063                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2064             LOG.warning('No more network or fixed IP to be allocated',
2065                         instance=instance)
2066             self._notify_about_instance_usage(context, instance,
2067                     'create.error', fault=e)
2068             compute_utils.notify_about_instance_create(
2069                     context, instance, self.host,
2070                     phase=fields.NotificationPhase.ERROR, exception=e,
2071                     bdms=block_device_mapping)
2072             msg = _('Failed to allocate the network(s) with error %s, '
2073                     'not rescheduling.') % e.format_message()
2074             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2075                     reason=msg)
2076         except (exception.VirtualInterfaceCreateException,
2077                 exception.VirtualInterfaceMacAddressException,
2078                 exception.FixedIpInvalidOnHost,
2079                 exception.UnableToAutoAllocateNetwork) as e:
2080             LOG.exception('Failed to allocate network(s)',
2081                           instance=instance)
2082             self._notify_about_instance_usage(context, instance,
2083                     'create.error', fault=e)
2084             compute_utils.notify_about_instance_create(
2085                     context, instance, self.host,
2086                     phase=fields.NotificationPhase.ERROR, exception=e,
2087                     bdms=block_device_mapping)
2088             msg = _('Failed to allocate the network(s), not rescheduling.')
2089             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2090                     reason=msg)
2091         except (exception.FlavorDiskTooSmall,
2092                 exception.FlavorMemoryTooSmall,
2093                 exception.ImageNotActive,
2094                 exception.ImageUnacceptable,
2095                 exception.InvalidDiskInfo,
2096                 exception.InvalidDiskFormat,
2097                 cursive_exception.SignatureVerificationError,
2098                 exception.VolumeEncryptionNotSupported,
2099                 exception.InvalidInput) as e:
2100             self._notify_about_instance_usage(context, instance,
2101                     'create.error', fault=e)
2102             compute_utils.notify_about_instance_create(
2103                     context, instance, self.host,
2104                     phase=fields.NotificationPhase.ERROR, exception=e,
2105                     bdms=block_device_mapping)
2106             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2107                     reason=e.format_message())
2108         except Exception as e:
2109             self._notify_about_instance_usage(context, instance,
2110                     'create.error', fault=e)
2111             compute_utils.notify_about_instance_create(
2112                     context, instance, self.host,
2113                     phase=fields.NotificationPhase.ERROR, exception=e,
2114                     bdms=block_device_mapping)
2115             raise exception.RescheduledException(
2116                     instance_uuid=instance.uuid, reason=six.text_type(e))
2117 
2118         # NOTE(alaski): This is only useful during reschedules, remove it now.
2119         instance.system_metadata.pop('network_allocated', None)
2120 
2121         # If CONF.default_access_ip_network_name is set, grab the
2122         # corresponding network and set the access ip values accordingly.
2123         network_name = CONF.default_access_ip_network_name
2124         if (network_name and not instance.access_ip_v4 and
2125                 not instance.access_ip_v6):
2126             # Note that when there are multiple ips to choose from, an
2127             # arbitrary one will be chosen.
2128             for vif in network_info:
2129                 if vif['network']['label'] == network_name:
2130                     for ip in vif.fixed_ips():
2131                         if not instance.access_ip_v4 and ip['version'] == 4:
2132                             instance.access_ip_v4 = ip['address']
2133                         if not instance.access_ip_v6 and ip['version'] == 6:
2134                             instance.access_ip_v6 = ip['address']
2135                     break
2136 
2137         self._update_instance_after_spawn(context, instance)
2138 
2139         try:
2140             instance.save(expected_task_state=task_states.SPAWNING)
2141         except (exception.InstanceNotFound,
2142                 exception.UnexpectedDeletingTaskStateError) as e:
2143             with excutils.save_and_reraise_exception():
2144                 self._notify_about_instance_usage(context, instance,
2145                     'create.error', fault=e)
2146                 compute_utils.notify_about_instance_create(
2147                     context, instance, self.host,
2148                     phase=fields.NotificationPhase.ERROR, exception=e,
2149                     bdms=block_device_mapping)
2150 
2151         self._update_scheduler_instance_info(context, instance)
2152         self._notify_about_instance_usage(context, instance, 'create.end',
2153                 extra_usage_info={'message': _('Success')},
2154                 network_info=network_info)
2155         compute_utils.notify_about_instance_create(context, instance,
2156                 self.host, phase=fields.NotificationPhase.END,
2157                 bdms=block_device_mapping)
2158 
2159     @contextlib.contextmanager
2160     def _build_resources(self, context, instance, requested_networks,
2161                          security_groups, image_meta, block_device_mapping):
2162         resources = {}
2163         network_info = None
2164         try:
2165             LOG.debug('Start building networks asynchronously for instance.',
2166                       instance=instance)
2167             network_info = self._build_networks_for_instance(context, instance,
2168                     requested_networks, security_groups)
2169             resources['network_info'] = network_info
2170         except (exception.InstanceNotFound,
2171                 exception.UnexpectedDeletingTaskStateError):
2172             raise
2173         except exception.UnexpectedTaskStateError as e:
2174             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2175                     reason=e.format_message())
2176         except Exception:
2177             # Because this allocation is async any failures are likely to occur
2178             # when the driver accesses network_info during spawn().
2179             LOG.exception('Failed to allocate network(s)',
2180                           instance=instance)
2181             msg = _('Failed to allocate the network(s), not rescheduling.')
2182             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2183                     reason=msg)
2184 
2185         try:
2186             # Verify that all the BDMs have a device_name set and assign a
2187             # default to the ones missing it with the help of the driver.
2188             self._default_block_device_names(instance, image_meta,
2189                                              block_device_mapping)
2190 
2191             LOG.debug('Start building block device mappings for instance.',
2192                       instance=instance)
2193             instance.vm_state = vm_states.BUILDING
2194             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2195             instance.save()
2196 
2197             block_device_info = self._prep_block_device(context, instance,
2198                     block_device_mapping)
2199             resources['block_device_info'] = block_device_info
2200         except (exception.InstanceNotFound,
2201                 exception.UnexpectedDeletingTaskStateError):
2202             with excutils.save_and_reraise_exception():
2203                 # Make sure the async call finishes
2204                 if network_info is not None:
2205                     network_info.wait(do_raise=False)
2206         except (exception.UnexpectedTaskStateError,
2207                 exception.OverQuota, exception.InvalidBDM) as e:
2208             # Make sure the async call finishes
2209             if network_info is not None:
2210                 network_info.wait(do_raise=False)
2211             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2212                     reason=e.format_message())
2213         except Exception:
2214             LOG.exception('Failure prepping block device',
2215                           instance=instance)
2216             # Make sure the async call finishes
2217             if network_info is not None:
2218                 network_info.wait(do_raise=False)
2219             msg = _('Failure prepping block device.')
2220             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2221                     reason=msg)
2222 
2223         try:
2224             resources['allocations'] = (
2225                 self.reportclient.get_allocations_for_consumer(instance.uuid))
2226         except Exception:
2227             LOG.exception('Failure retrieving placement allocations',
2228                           instance=instance)
2229             # Make sure the async call finishes
2230             if network_info is not None:
2231                 network_info.wait(do_raise=False)
2232             msg = _('Failure retrieving placement allocations')
2233             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2234                                                 reason=msg)
2235 
2236         try:
2237             yield resources
2238         except Exception as exc:
2239             with excutils.save_and_reraise_exception() as ctxt:
2240                 if not isinstance(exc, (
2241                         exception.InstanceNotFound,
2242                         exception.UnexpectedDeletingTaskStateError)):
2243                     LOG.exception('Instance failed to spawn',
2244                                   instance=instance)
2245                 # Make sure the async call finishes
2246                 if network_info is not None:
2247                     network_info.wait(do_raise=False)
2248                 # if network_info is empty we're likely here because of
2249                 # network allocation failure. Since nothing can be reused on
2250                 # rescheduling it's better to deallocate network to eliminate
2251                 # the chance of orphaned ports in neutron
2252                 deallocate_networks = False if network_info else True
2253                 try:
2254                     self._shutdown_instance(context, instance,
2255                             block_device_mapping, requested_networks,
2256                             try_deallocate_networks=deallocate_networks)
2257                 except Exception as exc2:
2258                     ctxt.reraise = False
2259                     LOG.warning('Could not clean up failed build,'
2260                                 ' not rescheduling. Error: %s',
2261                                 six.text_type(exc2))
2262                     raise exception.BuildAbortException(
2263                             instance_uuid=instance.uuid,
2264                             reason=six.text_type(exc))
2265 
2266     def _cleanup_allocated_networks(self, context, instance,
2267             requested_networks):
2268         try:
2269             self._deallocate_network(context, instance, requested_networks)
2270         except Exception:
2271             LOG.exception('Failed to deallocate networks', instance=instance)
2272             return
2273 
2274         instance.system_metadata['network_allocated'] = 'False'
2275         try:
2276             instance.save()
2277         except exception.InstanceNotFound:
2278             # NOTE(alaski): It's possible that we're cleaning up the networks
2279             # because the instance was deleted.  If that's the case then this
2280             # exception will be raised by instance.save()
2281             pass
2282 
2283     def _try_deallocate_network(self, context, instance,
2284                                 requested_networks=None):
2285         try:
2286             # tear down allocated network structure
2287             self._deallocate_network(context, instance, requested_networks)
2288         except Exception as ex:
2289             with excutils.save_and_reraise_exception():
2290                 LOG.error('Failed to deallocate network for instance. '
2291                           'Error: %s', ex, instance=instance)
2292                 self._set_instance_obj_error_state(context, instance)
2293 
2294     def _get_power_off_values(self, context, instance, clean_shutdown):
2295         """Get the timing configuration for powering down this instance."""
2296         if clean_shutdown:
2297             timeout = compute_utils.get_value_from_system_metadata(instance,
2298                           key='image_os_shutdown_timeout', type=int,
2299                           default=CONF.shutdown_timeout)
2300             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2301         else:
2302             timeout = 0
2303             retry_interval = 0
2304 
2305         return timeout, retry_interval
2306 
2307     def _power_off_instance(self, context, instance, clean_shutdown=True):
2308         """Power off an instance on this host."""
2309         timeout, retry_interval = self._get_power_off_values(context,
2310                                         instance, clean_shutdown)
2311         self.driver.power_off(instance, timeout, retry_interval)
2312 
2313     def _shutdown_instance(self, context, instance,
2314                            bdms, requested_networks=None, notify=True,
2315                            try_deallocate_networks=True):
2316         """Shutdown an instance on this host.
2317 
2318         :param:context: security context
2319         :param:instance: a nova.objects.Instance object
2320         :param:bdms: the block devices for the instance to be torn
2321                      down
2322         :param:requested_networks: the networks on which the instance
2323                                    has ports
2324         :param:notify: true if a final usage notification should be
2325                        emitted
2326         :param:try_deallocate_networks: false if we should avoid
2327                                         trying to teardown networking
2328         """
2329         context = context.elevated()
2330         LOG.info('Terminating instance', instance=instance)
2331 
2332         if notify:
2333             self._notify_about_instance_usage(context, instance,
2334                                               "shutdown.start")
2335             compute_utils.notify_about_instance_action(context, instance,
2336                     self.host, action=fields.NotificationAction.SHUTDOWN,
2337                     phase=fields.NotificationPhase.START, bdms=bdms)
2338 
2339         network_info = instance.get_network_info()
2340 
2341         # NOTE(vish) get bdms before destroying the instance
2342         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2343         block_device_info = self._get_instance_block_device_info(
2344             context, instance, bdms=bdms)
2345 
2346         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2347         #                want to keep ip allocated for certain failures
2348         timer = timeutils.StopWatch()
2349         try:
2350             LOG.debug('Start destroying the instance on the hypervisor.',
2351                       instance=instance)
2352             timer.start()
2353             self.driver.destroy(context, instance, network_info,
2354                     block_device_info)
2355             LOG.info('Took %0.2f seconds to destroy the instance on the '
2356                      'hypervisor.', timer.elapsed(), instance=instance)
2357         except exception.InstancePowerOffFailure:
2358             # if the instance can't power off, don't release the ip
2359             with excutils.save_and_reraise_exception():
2360                 pass
2361         except Exception:
2362             with excutils.save_and_reraise_exception():
2363                 # deallocate ip and fail without proceeding to
2364                 # volume api calls, preserving current behavior
2365                 if try_deallocate_networks:
2366                     self._try_deallocate_network(context, instance,
2367                                                  requested_networks)
2368 
2369         if try_deallocate_networks:
2370             self._try_deallocate_network(context, instance, requested_networks)
2371 
2372         timer.restart()
2373         for bdm in vol_bdms:
2374             try:
2375                 if bdm.attachment_id:
2376                     self.volume_api.attachment_delete(context,
2377                                                       bdm.attachment_id)
2378                 else:
2379                     # NOTE(vish): actual driver detach done in driver.destroy,
2380                     #             so just tell cinder that we are done with it.
2381                     connector = self.driver.get_volume_connector(instance)
2382                     self.volume_api.terminate_connection(context,
2383                                                          bdm.volume_id,
2384                                                          connector)
2385                     self.volume_api.detach(context, bdm.volume_id,
2386                                            instance.uuid)
2387 
2388             except exception.VolumeAttachmentNotFound as exc:
2389                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2390                           instance=instance)
2391             except exception.DiskNotFound as exc:
2392                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2393                           instance=instance)
2394             except exception.VolumeNotFound as exc:
2395                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2396                           instance=instance)
2397             except (cinder_exception.EndpointNotFound,
2398                     keystone_exception.EndpointNotFound) as exc:
2399                 LOG.warning('Ignoring EndpointNotFound for '
2400                             'volume %(volume_id)s: %(exc)s',
2401                             {'exc': exc, 'volume_id': bdm.volume_id},
2402                             instance=instance)
2403             except cinder_exception.ClientException as exc:
2404                 LOG.warning('Ignoring unknown cinder exception for '
2405                             'volume %(volume_id)s: %(exc)s',
2406                             {'exc': exc, 'volume_id': bdm.volume_id},
2407                             instance=instance)
2408             except Exception as exc:
2409                 LOG.warning('Ignoring unknown exception for '
2410                             'volume %(volume_id)s: %(exc)s',
2411                             {'exc': exc, 'volume_id': bdm.volume_id},
2412                             instance=instance)
2413         if vol_bdms:
2414             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2415                      'for instance.',
2416                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2417                      instance=instance)
2418 
2419         if notify:
2420             self._notify_about_instance_usage(context, instance,
2421                                               "shutdown.end")
2422             compute_utils.notify_about_instance_action(context, instance,
2423                     self.host, action=fields.NotificationAction.SHUTDOWN,
2424                     phase=fields.NotificationPhase.END, bdms=bdms)
2425 
2426     def _cleanup_volumes(self, context, instance_uuid, bdms, raise_exc=True):
2427         exc_info = None
2428 
2429         for bdm in bdms:
2430             LOG.debug("terminating bdm %s", bdm,
2431                       instance_uuid=instance_uuid)
2432             if bdm.volume_id and bdm.delete_on_termination:
2433                 try:
2434                     self.volume_api.delete(context, bdm.volume_id)
2435                 except Exception as exc:
2436                     exc_info = sys.exc_info()
2437                     LOG.warning('Failed to delete volume: %(volume_id)s '
2438                                 'due to %(exc)s',
2439                                 {'volume_id': bdm.volume_id, 'exc': exc})
2440         if exc_info is not None and raise_exc:
2441             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2442 
2443     @hooks.add_hook("delete_instance")
2444     def _delete_instance(self, context, instance, bdms):
2445         """Delete an instance on this host.
2446 
2447         :param context: nova request context
2448         :param instance: nova.objects.instance.Instance object
2449         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2450         """
2451         events = self.instance_events.clear_events_for_instance(instance)
2452         if events:
2453             LOG.debug('Events pending at deletion: %(events)s',
2454                       {'events': ','.join(events.keys())},
2455                       instance=instance)
2456         self._notify_about_instance_usage(context, instance,
2457                                           "delete.start")
2458         compute_utils.notify_about_instance_action(context, instance,
2459                 self.host, action=fields.NotificationAction.DELETE,
2460                 phase=fields.NotificationPhase.START, bdms=bdms)
2461 
2462         self._shutdown_instance(context, instance, bdms)
2463         # NOTE(dims): instance.info_cache.delete() should be called after
2464         # _shutdown_instance in the compute manager as shutdown calls
2465         # deallocate_for_instance so the info_cache is still needed
2466         # at this point.
2467         if instance.info_cache is not None:
2468             instance.info_cache.delete()
2469         else:
2470             # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2471             # is None. When the root cause that instance.info_cache becomes
2472             # None is fixed, the log level should be reconsidered.
2473             LOG.warning("Info cache for instance could not be found. "
2474                         "Ignore.", instance=instance)
2475 
2476         # NOTE(vish): We have already deleted the instance, so we have
2477         #             to ignore problems cleaning up the volumes. It
2478         #             would be nice to let the user know somehow that
2479         #             the volume deletion failed, but it is not
2480         #             acceptable to have an instance that can not be
2481         #             deleted. Perhaps this could be reworked in the
2482         #             future to set an instance fault the first time
2483         #             and to only ignore the failure if the instance
2484         #             is already in ERROR.
2485         self._cleanup_volumes(context, instance.uuid, bdms,
2486                 raise_exc=False)
2487         # if a delete task succeeded, always update vm state and task
2488         # state without expecting task state to be DELETING
2489         instance.vm_state = vm_states.DELETED
2490         instance.task_state = None
2491         instance.power_state = power_state.NOSTATE
2492         instance.terminated_at = timeutils.utcnow()
2493         instance.save()
2494         system_meta = instance.system_metadata
2495         instance.destroy()
2496 
2497         self._complete_deletion(context,
2498                                 instance,
2499                                 bdms,
2500                                 system_meta)
2501 
2502     @wrap_exception()
2503     @reverts_task_state
2504     @wrap_instance_event(prefix='compute')
2505     @wrap_instance_fault
2506     def terminate_instance(self, context, instance, bdms, reservations):
2507         """Terminate an instance on this host."""
2508         @utils.synchronized(instance.uuid)
2509         def do_terminate_instance(instance, bdms):
2510             # NOTE(mriedem): If we are deleting the instance while it was
2511             # booting from volume, we could be racing with a database update of
2512             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2513             # to compute here, the BDMs may be stale at this point. So check
2514             # for any volume BDMs that don't have volume_id set and if we
2515             # detect that, we need to refresh the BDM list before proceeding.
2516             # TODO(mriedem): Move this into _delete_instance and make the bdms
2517             # parameter optional.
2518             for bdm in list(bdms):
2519                 if bdm.is_volume and not bdm.volume_id:
2520                     LOG.debug('There are potentially stale BDMs during '
2521                               'delete, refreshing the BlockDeviceMappingList.',
2522                               instance=instance)
2523                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2524                         context, instance.uuid)
2525                     break
2526             try:
2527                 self._delete_instance(context, instance, bdms)
2528             except exception.InstanceNotFound:
2529                 LOG.info("Instance disappeared during terminate",
2530                          instance=instance)
2531             except Exception:
2532                 # As we're trying to delete always go to Error if something
2533                 # goes wrong that _delete_instance can't handle.
2534                 with excutils.save_and_reraise_exception():
2535                     LOG.exception('Setting instance vm_state to ERROR',
2536                                   instance=instance)
2537                     self._set_instance_obj_error_state(context, instance)
2538 
2539         do_terminate_instance(instance, bdms)
2540 
2541     # NOTE(johannes): This is probably better named power_off_instance
2542     # so it matches the driver method, but because of other issues, we
2543     # can't use that name in grizzly.
2544     @wrap_exception()
2545     @reverts_task_state
2546     @wrap_instance_event(prefix='compute')
2547     @wrap_instance_fault
2548     def stop_instance(self, context, instance, clean_shutdown):
2549         """Stopping an instance on this host."""
2550 
2551         @utils.synchronized(instance.uuid)
2552         def do_stop_instance():
2553             current_power_state = self._get_power_state(context, instance)
2554             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2555                       'current task_state: %(task_state)s, current DB '
2556                       'power_state: %(db_power_state)s, current VM '
2557                       'power_state: %(current_power_state)s',
2558                       {'vm_state': instance.vm_state,
2559                        'task_state': instance.task_state,
2560                        'db_power_state': instance.power_state,
2561                        'current_power_state': current_power_state},
2562                       instance_uuid=instance.uuid)
2563 
2564             # NOTE(mriedem): If the instance is already powered off, we are
2565             # possibly tearing down and racing with other operations, so we can
2566             # expect the task_state to be None if something else updates the
2567             # instance and we're not locking it.
2568             expected_task_state = [task_states.POWERING_OFF]
2569             # The list of power states is from _sync_instance_power_state.
2570             if current_power_state in (power_state.NOSTATE,
2571                                        power_state.SHUTDOWN,
2572                                        power_state.CRASHED):
2573                 LOG.info('Instance is already powered off in the '
2574                          'hypervisor when stop is called.',
2575                          instance=instance)
2576                 expected_task_state.append(None)
2577 
2578             self._notify_about_instance_usage(context, instance,
2579                                               "power_off.start")
2580 
2581             compute_utils.notify_about_instance_action(context, instance,
2582                         self.host, action=fields.NotificationAction.POWER_OFF,
2583                         phase=fields.NotificationPhase.START)
2584 
2585             self._power_off_instance(context, instance, clean_shutdown)
2586             instance.power_state = self._get_power_state(context, instance)
2587             instance.vm_state = vm_states.STOPPED
2588             instance.task_state = None
2589             instance.save(expected_task_state=expected_task_state)
2590             self._notify_about_instance_usage(context, instance,
2591                                               "power_off.end")
2592 
2593             compute_utils.notify_about_instance_action(context, instance,
2594                         self.host, action=fields.NotificationAction.POWER_OFF,
2595                         phase=fields.NotificationPhase.END)
2596 
2597         do_stop_instance()
2598 
2599     def _power_on(self, context, instance):
2600         network_info = self.network_api.get_instance_nw_info(context, instance)
2601         block_device_info = self._get_instance_block_device_info(context,
2602                                                                  instance)
2603         self.driver.power_on(context, instance,
2604                              network_info,
2605                              block_device_info)
2606 
2607     def _delete_snapshot_of_shelved_instance(self, context, instance,
2608                                              snapshot_id):
2609         """Delete snapshot of shelved instance."""
2610         try:
2611             self.image_api.delete(context, snapshot_id)
2612         except (exception.ImageNotFound,
2613                 exception.ImageNotAuthorized) as exc:
2614             LOG.warning("Failed to delete snapshot "
2615                         "from shelved instance (%s).",
2616                         exc.format_message(), instance=instance)
2617         except Exception:
2618             LOG.exception("Something wrong happened when trying to "
2619                           "delete snapshot from shelved instance.",
2620                           instance=instance)
2621 
2622     # NOTE(johannes): This is probably better named power_on_instance
2623     # so it matches the driver method, but because of other issues, we
2624     # can't use that name in grizzly.
2625     @wrap_exception()
2626     @reverts_task_state
2627     @wrap_instance_event(prefix='compute')
2628     @wrap_instance_fault
2629     def start_instance(self, context, instance):
2630         """Starting an instance on this host."""
2631         self._notify_about_instance_usage(context, instance, "power_on.start")
2632         compute_utils.notify_about_instance_action(context, instance,
2633             self.host, action=fields.NotificationAction.POWER_ON,
2634             phase=fields.NotificationPhase.START)
2635         self._power_on(context, instance)
2636         instance.power_state = self._get_power_state(context, instance)
2637         instance.vm_state = vm_states.ACTIVE
2638         instance.task_state = None
2639 
2640         # Delete an image(VM snapshot) for a shelved instance
2641         snapshot_id = instance.system_metadata.get('shelved_image_id')
2642         if snapshot_id:
2643             self._delete_snapshot_of_shelved_instance(context, instance,
2644                                                       snapshot_id)
2645 
2646         # Delete system_metadata for a shelved instance
2647         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2648 
2649         instance.save(expected_task_state=task_states.POWERING_ON)
2650         self._notify_about_instance_usage(context, instance, "power_on.end")
2651         compute_utils.notify_about_instance_action(context, instance,
2652             self.host, action=fields.NotificationAction.POWER_ON,
2653             phase=fields.NotificationPhase.END)
2654 
2655     @messaging.expected_exceptions(NotImplementedError,
2656                                    exception.TriggerCrashDumpNotSupported,
2657                                    exception.InstanceNotRunning)
2658     @wrap_exception()
2659     @wrap_instance_event(prefix='compute')
2660     @wrap_instance_fault
2661     def trigger_crash_dump(self, context, instance):
2662         """Trigger crash dump in an instance."""
2663 
2664         self._notify_about_instance_usage(context, instance,
2665                                           "trigger_crash_dump.start")
2666         compute_utils.notify_about_instance_action(context, instance,
2667                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2668                 phase=fields.NotificationPhase.START)
2669 
2670         # This method does not change task_state and power_state because the
2671         # effect of a trigger depends on user's configuration.
2672         self.driver.trigger_crash_dump(instance)
2673 
2674         self._notify_about_instance_usage(context, instance,
2675                                           "trigger_crash_dump.end")
2676         compute_utils.notify_about_instance_action(context, instance,
2677                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2678                 phase=fields.NotificationPhase.END)
2679 
2680     @wrap_exception()
2681     @reverts_task_state
2682     @wrap_instance_event(prefix='compute')
2683     @wrap_instance_fault
2684     def soft_delete_instance(self, context, instance, reservations):
2685         """Soft delete an instance on this host."""
2686         with compute_utils.notify_about_instance_delete(
2687                 self.notifier, context, instance, 'soft_delete'):
2688             compute_utils.notify_about_instance_action(context, instance,
2689                 self.host, action=fields.NotificationAction.SOFT_DELETE,
2690                 phase=fields.NotificationPhase.START)
2691             try:
2692                 self.driver.soft_delete(instance)
2693             except NotImplementedError:
2694                 # Fallback to just powering off the instance if the
2695                 # hypervisor doesn't implement the soft_delete method
2696                 self.driver.power_off(instance)
2697             instance.power_state = self._get_power_state(context, instance)
2698             instance.vm_state = vm_states.SOFT_DELETED
2699             instance.task_state = None
2700             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2701             compute_utils.notify_about_instance_action(
2702                 context, instance, self.host,
2703                 action=fields.NotificationAction.SOFT_DELETE,
2704                 phase=fields.NotificationPhase.END)
2705 
2706     @wrap_exception()
2707     @reverts_task_state
2708     @wrap_instance_event(prefix='compute')
2709     @wrap_instance_fault
2710     def restore_instance(self, context, instance):
2711         """Restore a soft-deleted instance on this host."""
2712         self._notify_about_instance_usage(context, instance, "restore.start")
2713         compute_utils.notify_about_instance_action(context, instance,
2714             self.host, action=fields.NotificationAction.RESTORE,
2715             phase=fields.NotificationPhase.START)
2716         try:
2717             self.driver.restore(instance)
2718         except NotImplementedError:
2719             # Fallback to just powering on the instance if the hypervisor
2720             # doesn't implement the restore method
2721             self._power_on(context, instance)
2722         instance.power_state = self._get_power_state(context, instance)
2723         instance.vm_state = vm_states.ACTIVE
2724         instance.task_state = None
2725         instance.save(expected_task_state=task_states.RESTORING)
2726         self._notify_about_instance_usage(context, instance, "restore.end")
2727         compute_utils.notify_about_instance_action(context, instance,
2728             self.host, action=fields.NotificationAction.RESTORE,
2729             phase=fields.NotificationPhase.END)
2730 
2731     @staticmethod
2732     def _set_migration_status(migration, status):
2733         """Set the status, and guard against a None being passed in.
2734 
2735         This is useful as some of the compute RPC calls will not pass
2736         a migration object in older versions. The check can be removed when
2737         we move past 4.x major version of the RPC API.
2738         """
2739         if migration:
2740             migration.status = status
2741             migration.save()
2742 
2743     def _rebuild_default_impl(self, context, instance, image_meta,
2744                               injected_files, admin_password, allocations,
2745                               bdms, detach_block_devices, attach_block_devices,
2746                               network_info=None,
2747                               recreate=False, block_device_info=None,
2748                               preserve_ephemeral=False):
2749         if preserve_ephemeral:
2750             # The default code path does not support preserving ephemeral
2751             # partitions.
2752             raise exception.PreserveEphemeralNotSupported()
2753 
2754         if recreate:
2755             detach_block_devices(context, bdms)
2756         else:
2757             self._power_off_instance(context, instance, clean_shutdown=True)
2758             detach_block_devices(context, bdms)
2759             self.driver.destroy(context, instance,
2760                                 network_info=network_info,
2761                                 block_device_info=block_device_info)
2762 
2763         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2764         instance.save(expected_task_state=[task_states.REBUILDING])
2765 
2766         new_block_device_info = attach_block_devices(context, instance, bdms)
2767 
2768         instance.task_state = task_states.REBUILD_SPAWNING
2769         instance.save(
2770             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2771 
2772         with instance.mutated_migration_context():
2773             self.driver.spawn(context, instance, image_meta, injected_files,
2774                               admin_password, allocations,
2775                               network_info=network_info,
2776                               block_device_info=new_block_device_info)
2777 
2778     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
2779         self._notify_about_instance_usage(context, instance,
2780                                           'rebuild.error', fault=error)
2781         compute_utils.notify_about_instance_action(
2782             context, instance, self.host,
2783             action=fields.NotificationAction.REBUILD,
2784             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms)
2785 
2786     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2787     @wrap_exception()
2788     @reverts_task_state
2789     @wrap_instance_event(prefix='compute')
2790     @wrap_instance_fault
2791     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2792                          injected_files, new_pass, orig_sys_metadata,
2793                          bdms, recreate, on_shared_storage=None,
2794                          preserve_ephemeral=False, migration=None,
2795                          scheduled_node=None, limits=None):
2796         """Destroy and re-make this instance.
2797 
2798         A 'rebuild' effectively purges all existing data from the system and
2799         remakes the VM with given 'metadata' and 'personalities'.
2800 
2801         :param context: `nova.RequestContext` object
2802         :param instance: Instance object
2803         :param orig_image_ref: Original image_ref before rebuild
2804         :param image_ref: New image_ref for rebuild
2805         :param injected_files: Files to inject
2806         :param new_pass: password to set on rebuilt instance
2807         :param orig_sys_metadata: instance system metadata from pre-rebuild
2808         :param bdms: block-device-mappings to use for rebuild
2809         :param recreate: True if the instance is being recreated (e.g. the
2810             hypervisor it was on failed) - cleanup of old state will be
2811             skipped.
2812         :param on_shared_storage: True if instance files on shared storage.
2813                                   If not provided then information from the
2814                                   driver will be used to decide if the instance
2815                                   files are available or not on the target host
2816         :param preserve_ephemeral: True if the default ephemeral storage
2817                                    partition must be preserved on rebuild
2818         :param migration: a Migration object if one was created for this
2819                           rebuild operation (if it's a part of evacuate)
2820         :param scheduled_node: A node of the host chosen by the scheduler. If a
2821                                host was specified by the user, this will be
2822                                None
2823         :param limits: Overcommit limits set by the scheduler. If a host was
2824                        specified by the user, this will be None
2825         """
2826         context = context.elevated()
2827 
2828         LOG.info("Rebuilding instance", instance=instance)
2829 
2830         # NOTE(gyee): there are three possible scenarios.
2831         #
2832         #   1. instance is being rebuilt on the same node. In this case,
2833         #      recreate should be False and scheduled_node should be None.
2834         #   2. instance is being rebuilt on a node chosen by the
2835         #      scheduler (i.e. evacuate). In this case, scheduled_node should
2836         #      be specified and recreate should be True.
2837         #   3. instance is being rebuilt on a node chosen by the user. (i.e.
2838         #      force evacuate). In this case, scheduled_node is not specified
2839         #      and recreate is set to True.
2840         #
2841         # For scenarios #2 and #3, we must do rebuild claim as server is
2842         # being evacuated to a different node.
2843         rt = self._get_resource_tracker()
2844         if recreate or scheduled_node is not None:
2845             rebuild_claim = rt.rebuild_claim
2846         else:
2847             rebuild_claim = claims.NopClaim
2848 
2849         image_meta = {}
2850         if image_ref:
2851             image_meta = self.image_api.get(context, image_ref)
2852 
2853         # NOTE(mriedem): On a recreate (evacuate), we need to update
2854         # the instance's host and node properties to reflect it's
2855         # destination node for the recreate.
2856         if not scheduled_node:
2857             if recreate:
2858                 try:
2859                     compute_node = self._get_compute_info(context, self.host)
2860                     scheduled_node = compute_node.hypervisor_hostname
2861                 except exception.ComputeHostNotFound:
2862                     LOG.exception('Failed to get compute_info for %s',
2863                                   self.host)
2864             else:
2865                 scheduled_node = instance.node
2866 
2867         with self._error_out_instance_on_exception(context, instance):
2868             try:
2869                 claim_ctxt = rebuild_claim(
2870                     context, instance, scheduled_node,
2871                     limits=limits, image_meta=image_meta,
2872                     migration=migration)
2873                 self._do_rebuild_instance_with_claim(
2874                     claim_ctxt, context, instance, orig_image_ref,
2875                     image_ref, injected_files, new_pass, orig_sys_metadata,
2876                     bdms, recreate, on_shared_storage, preserve_ephemeral)
2877             except exception.ComputeResourcesUnavailable as e:
2878                 LOG.debug("Could not rebuild instance on this host, not "
2879                           "enough resources available.", instance=instance)
2880 
2881                 # NOTE(ndipanov): We just abort the build for now and leave a
2882                 # migration record for potential cleanup later
2883                 self._set_migration_status(migration, 'failed')
2884                 # Since the claim failed, we need to remove the allocation
2885                 # created against the destination node. Note that we can only
2886                 # get here when evacuating to a destination node. Rebuilding
2887                 # on the same host (not evacuate) uses the NopClaim which will
2888                 # not raise ComputeResourcesUnavailable.
2889                 rt.delete_allocation_for_evacuated_instance(
2890                     instance, scheduled_node, node_type='destination')
2891                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2892                 raise exception.BuildAbortException(
2893                     instance_uuid=instance.uuid, reason=e.format_message())
2894             except (exception.InstanceNotFound,
2895                     exception.UnexpectedDeletingTaskStateError) as e:
2896                 LOG.debug('Instance was deleted while rebuilding',
2897                           instance=instance)
2898                 self._set_migration_status(migration, 'failed')
2899                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2900             except Exception as e:
2901                 self._set_migration_status(migration, 'failed')
2902                 if recreate or scheduled_node is not None:
2903                     rt.delete_allocation_for_evacuated_instance(
2904                         instance, scheduled_node, node_type='destination')
2905                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2906                 raise
2907             else:
2908                 instance.apply_migration_context()
2909                 # NOTE (ndipanov): This save will now update the host and node
2910                 # attributes making sure that next RT pass is consistent since
2911                 # it will be based on the instance and not the migration DB
2912                 # entry.
2913                 instance.host = self.host
2914                 instance.node = scheduled_node
2915                 instance.save()
2916                 instance.drop_migration_context()
2917 
2918                 # NOTE (ndipanov): Mark the migration as done only after we
2919                 # mark the instance as belonging to this host.
2920                 self._set_migration_status(migration, 'done')
2921 
2922     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2923         """Helper to avoid deep nesting in the top-level method."""
2924 
2925         with claim_context:
2926             self._do_rebuild_instance(*args, **kwargs)
2927 
2928     @staticmethod
2929     def _get_image_name(image_meta):
2930         if image_meta.obj_attr_is_set("name"):
2931             return image_meta.name
2932         else:
2933             return ''
2934 
2935     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2936                              image_ref, injected_files, new_pass,
2937                              orig_sys_metadata, bdms, recreate,
2938                              on_shared_storage, preserve_ephemeral):
2939         orig_vm_state = instance.vm_state
2940 
2941         if recreate:
2942             if not self.driver.capabilities["supports_recreate"]:
2943                 raise exception.InstanceRecreateNotSupported
2944 
2945             self._check_instance_exists(context, instance)
2946 
2947             if on_shared_storage is None:
2948                 LOG.debug('on_shared_storage is not provided, using driver'
2949                             'information to decide if the instance needs to'
2950                             'be recreated')
2951                 on_shared_storage = self.driver.instance_on_disk(instance)
2952 
2953             elif (on_shared_storage !=
2954                     self.driver.instance_on_disk(instance)):
2955                 # To cover case when admin expects that instance files are
2956                 # on shared storage, but not accessible and vice versa
2957                 raise exception.InvalidSharedStorage(
2958                         _("Invalid state of instance files on shared"
2959                             " storage"))
2960 
2961             if on_shared_storage:
2962                 LOG.info('disk on shared storage, recreating using'
2963                          ' existing disk')
2964             else:
2965                 image_ref = orig_image_ref = instance.image_ref
2966                 LOG.info("disk not on shared storage, rebuilding from:"
2967                          " '%s'", str(image_ref))
2968 
2969         if image_ref:
2970             image_meta = objects.ImageMeta.from_image_ref(
2971                 context, self.image_api, image_ref)
2972         else:
2973             image_meta = instance.image_meta
2974 
2975         # This instance.exists message should contain the original
2976         # image_ref, not the new one.  Since the DB has been updated
2977         # to point to the new one... we have to override it.
2978         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
2979                                                                context)
2980         extra_usage_info = {'image_ref_url': orig_image_ref_url}
2981         compute_utils.notify_usage_exists(
2982                 self.notifier, context, instance,
2983                 current_period=True, system_metadata=orig_sys_metadata,
2984                 extra_usage_info=extra_usage_info)
2985 
2986         # This message should contain the new image_ref
2987         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
2988         self._notify_about_instance_usage(context, instance,
2989                 "rebuild.start", extra_usage_info=extra_usage_info)
2990         # NOTE: image_name is not included in the versioned notification
2991         # because we already provide the image_uuid in the notification
2992         # payload and the image details can be looked up via the uuid.
2993         compute_utils.notify_about_instance_action(
2994             context, instance, self.host,
2995             action=fields.NotificationAction.REBUILD,
2996             phase=fields.NotificationPhase.START,
2997             bdms=bdms)
2998 
2999         instance.power_state = self._get_power_state(context, instance)
3000         instance.task_state = task_states.REBUILDING
3001         instance.save(expected_task_state=[task_states.REBUILDING])
3002 
3003         if recreate:
3004             self.network_api.setup_networks_on_host(
3005                     context, instance, self.host)
3006             # For nova-network this is needed to move floating IPs
3007             # For neutron this updates the host in the port binding
3008             # TODO(cfriesen): this network_api call and the one above
3009             # are so similar, we should really try to unify them.
3010             self.network_api.setup_instance_network_on_host(
3011                     context, instance, self.host)
3012 
3013         allocations = self.reportclient.get_allocations_for_consumer(
3014             instance.uuid)
3015 
3016         network_info = instance.get_network_info()
3017         if bdms is None:
3018             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3019                     context, instance.uuid)
3020 
3021         block_device_info = \
3022             self._get_instance_block_device_info(
3023                     context, instance, bdms=bdms)
3024 
3025         def detach_block_devices(context, bdms):
3026             for bdm in bdms:
3027                 if bdm.is_volume:
3028                     # NOTE (ildikov): Having the attachment_id set in the BDM
3029                     # means that it's the new Cinder attach/detach flow
3030                     # (available from v3.44). In that case we explicitly
3031                     # attach and detach the volumes through attachment level
3032                     # operations. In this scenario _detach_volume will delete
3033                     # the existing attachment which would make the volume
3034                     # status change to 'in-use' if we don't pre-create another
3035                     # empty attachment before deleting the old one.
3036                     attachment_id = None
3037                     if bdm.attachment_id:
3038                         attachment_id = self.volume_api.attachment_create(
3039                             context, bdm['volume_id'], instance.uuid)['id']
3040                     self._detach_volume(context, bdm, instance,
3041                                         destroy_bdm=False)
3042                     if attachment_id:
3043                         bdm.attachment_id = attachment_id
3044                         bdm.save()
3045 
3046         files = self._decode_files(injected_files)
3047 
3048         kwargs = dict(
3049             context=context,
3050             instance=instance,
3051             image_meta=image_meta,
3052             injected_files=files,
3053             admin_password=new_pass,
3054             allocations=allocations,
3055             bdms=bdms,
3056             detach_block_devices=detach_block_devices,
3057             attach_block_devices=self._prep_block_device,
3058             block_device_info=block_device_info,
3059             network_info=network_info,
3060             preserve_ephemeral=preserve_ephemeral,
3061             recreate=recreate)
3062         try:
3063             with instance.mutated_migration_context():
3064                 self.driver.rebuild(**kwargs)
3065         except NotImplementedError:
3066             # NOTE(rpodolyaka): driver doesn't provide specialized version
3067             # of rebuild, fall back to the default implementation
3068             self._rebuild_default_impl(**kwargs)
3069         self._update_instance_after_spawn(context, instance)
3070         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3071 
3072         if orig_vm_state == vm_states.STOPPED:
3073             LOG.info("bringing vm to original state: '%s'",
3074                      orig_vm_state, instance=instance)
3075             instance.vm_state = vm_states.ACTIVE
3076             instance.task_state = task_states.POWERING_OFF
3077             instance.progress = 0
3078             instance.save()
3079             self.stop_instance(context, instance, False)
3080         self._update_scheduler_instance_info(context, instance)
3081         self._notify_about_instance_usage(
3082                 context, instance, "rebuild.end",
3083                 network_info=network_info,
3084                 extra_usage_info=extra_usage_info)
3085         compute_utils.notify_about_instance_action(
3086             context, instance, self.host,
3087             action=fields.NotificationAction.REBUILD,
3088             phase=fields.NotificationPhase.END,
3089             bdms=bdms)
3090 
3091     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3092                                      block_device_info):
3093         """Handle cases where the virt-layer had to detach non-working volumes
3094         in order to complete an operation.
3095         """
3096         for bdm in block_device_info['block_device_mapping']:
3097             if bdm.get('mount_device') in bad_devices:
3098                 try:
3099                     volume_id = bdm['connection_info']['data']['volume_id']
3100                 except KeyError:
3101                     continue
3102 
3103                 # NOTE(sirp): ideally we'd just call
3104                 # `compute_api.detach_volume` here but since that hits the
3105                 # DB directly, that's off limits from within the
3106                 # compute-manager.
3107                 #
3108                 # API-detach
3109                 LOG.info("Detaching from volume api: %s", volume_id)
3110                 self.volume_api.begin_detaching(context, volume_id)
3111 
3112                 # Manager-detach
3113                 self.detach_volume(context, volume_id, instance)
3114 
3115     @wrap_exception()
3116     @reverts_task_state
3117     @wrap_instance_event(prefix='compute')
3118     @wrap_instance_fault
3119     def reboot_instance(self, context, instance, block_device_info,
3120                         reboot_type):
3121         """Reboot an instance on this host."""
3122         # acknowledge the request made it to the manager
3123         if reboot_type == "SOFT":
3124             instance.task_state = task_states.REBOOT_PENDING
3125             expected_states = task_states.soft_reboot_states
3126         else:
3127             instance.task_state = task_states.REBOOT_PENDING_HARD
3128             expected_states = task_states.hard_reboot_states
3129 
3130         context = context.elevated()
3131         LOG.info("Rebooting instance", instance=instance)
3132 
3133         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3134             context, instance.uuid)
3135         block_device_info = self._get_instance_block_device_info(
3136             context, instance, bdms=bdms)
3137 
3138         network_info = self.network_api.get_instance_nw_info(context, instance)
3139 
3140         self._notify_about_instance_usage(context, instance, "reboot.start")
3141         compute_utils.notify_about_instance_action(
3142             context, instance, self.host,
3143             action=fields.NotificationAction.REBOOT,
3144             phase=fields.NotificationPhase.START,
3145             bdms=bdms
3146         )
3147 
3148         instance.power_state = self._get_power_state(context, instance)
3149         instance.save(expected_task_state=expected_states)
3150 
3151         if instance.power_state != power_state.RUNNING:
3152             state = instance.power_state
3153             running = power_state.RUNNING
3154             LOG.warning('trying to reboot a non-running instance:'
3155                         ' (state: %(state)s expected: %(running)s)',
3156                         {'state': state, 'running': running},
3157                         instance=instance)
3158 
3159         def bad_volumes_callback(bad_devices):
3160             self._handle_bad_volumes_detached(
3161                     context, instance, bad_devices, block_device_info)
3162 
3163         try:
3164             # Don't change it out of rescue mode
3165             if instance.vm_state == vm_states.RESCUED:
3166                 new_vm_state = vm_states.RESCUED
3167             else:
3168                 new_vm_state = vm_states.ACTIVE
3169             new_power_state = None
3170             if reboot_type == "SOFT":
3171                 instance.task_state = task_states.REBOOT_STARTED
3172                 expected_state = task_states.REBOOT_PENDING
3173             else:
3174                 instance.task_state = task_states.REBOOT_STARTED_HARD
3175                 expected_state = task_states.REBOOT_PENDING_HARD
3176             instance.save(expected_task_state=expected_state)
3177             self.driver.reboot(context, instance,
3178                                network_info,
3179                                reboot_type,
3180                                block_device_info=block_device_info,
3181                                bad_volumes_callback=bad_volumes_callback)
3182 
3183         except Exception as error:
3184             with excutils.save_and_reraise_exception() as ctxt:
3185                 exc_info = sys.exc_info()
3186                 # if the reboot failed but the VM is running don't
3187                 # put it into an error state
3188                 new_power_state = self._get_power_state(context, instance)
3189                 if new_power_state == power_state.RUNNING:
3190                     LOG.warning('Reboot failed but instance is running',
3191                                 instance=instance)
3192                     compute_utils.add_instance_fault_from_exc(context,
3193                             instance, error, exc_info)
3194                     self._notify_about_instance_usage(context, instance,
3195                             'reboot.error', fault=error)
3196                     compute_utils.notify_about_instance_action(
3197                         context, instance, self.host,
3198                         action=fields.NotificationAction.REBOOT,
3199                         phase=fields.NotificationPhase.ERROR,
3200                         exception=error, bdms=bdms
3201                     )
3202                     ctxt.reraise = False
3203                 else:
3204                     LOG.error('Cannot reboot instance: %s', error,
3205                               instance=instance)
3206                     self._set_instance_obj_error_state(context, instance)
3207 
3208         if not new_power_state:
3209             new_power_state = self._get_power_state(context, instance)
3210         try:
3211             instance.power_state = new_power_state
3212             instance.vm_state = new_vm_state
3213             instance.task_state = None
3214             instance.save()
3215         except exception.InstanceNotFound:
3216             LOG.warning("Instance disappeared during reboot",
3217                         instance=instance)
3218 
3219         self._notify_about_instance_usage(context, instance, "reboot.end")
3220         compute_utils.notify_about_instance_action(
3221             context, instance, self.host,
3222             action=fields.NotificationAction.REBOOT,
3223             phase=fields.NotificationPhase.END,
3224             bdms=bdms
3225         )
3226 
3227     @delete_image_on_error
3228     def _do_snapshot_instance(self, context, image_id, instance):
3229         self._snapshot_instance(context, image_id, instance,
3230                                 task_states.IMAGE_BACKUP)
3231 
3232     @wrap_exception()
3233     @reverts_task_state
3234     @wrap_instance_fault
3235     def backup_instance(self, context, image_id, instance, backup_type,
3236                         rotation):
3237         """Backup an instance on this host.
3238 
3239         :param backup_type: daily | weekly
3240         :param rotation: int representing how many backups to keep around
3241         """
3242         self._do_snapshot_instance(context, image_id, instance)
3243         self._rotate_backups(context, instance, backup_type, rotation)
3244 
3245     @wrap_exception()
3246     @reverts_task_state
3247     @wrap_instance_fault
3248     @delete_image_on_error
3249     def snapshot_instance(self, context, image_id, instance):
3250         """Snapshot an instance on this host.
3251 
3252         :param context: security context
3253         :param image_id: glance.db.sqlalchemy.models.Image.Id
3254         :param instance: a nova.objects.instance.Instance object
3255         """
3256         # NOTE(dave-mcnally) the task state will already be set by the api
3257         # but if the compute manager has crashed/been restarted prior to the
3258         # request getting here the task state may have been cleared so we set
3259         # it again and things continue normally
3260         try:
3261             instance.task_state = task_states.IMAGE_SNAPSHOT
3262             instance.save(
3263                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3264         except exception.InstanceNotFound:
3265             # possibility instance no longer exists, no point in continuing
3266             LOG.debug("Instance not found, could not set state %s "
3267                       "for instance.",
3268                       task_states.IMAGE_SNAPSHOT, instance=instance)
3269             return
3270 
3271         except exception.UnexpectedDeletingTaskStateError:
3272             LOG.debug("Instance being deleted, snapshot cannot continue",
3273                       instance=instance)
3274             return
3275 
3276         self._snapshot_instance(context, image_id, instance,
3277                                 task_states.IMAGE_SNAPSHOT)
3278 
3279     def _snapshot_instance(self, context, image_id, instance,
3280                            expected_task_state):
3281         context = context.elevated()
3282 
3283         instance.power_state = self._get_power_state(context, instance)
3284         try:
3285             instance.save()
3286 
3287             LOG.info('instance snapshotting', instance=instance)
3288 
3289             if instance.power_state != power_state.RUNNING:
3290                 state = instance.power_state
3291                 running = power_state.RUNNING
3292                 LOG.warning('trying to snapshot a non-running instance: '
3293                             '(state: %(state)s expected: %(running)s)',
3294                             {'state': state, 'running': running},
3295                             instance=instance)
3296 
3297             self._notify_about_instance_usage(
3298                 context, instance, "snapshot.start")
3299             compute_utils.notify_about_instance_snapshot(context, instance,
3300                 self.host, phase=fields.NotificationPhase.START,
3301                 snapshot_image_id=image_id)
3302 
3303             def update_task_state(task_state,
3304                                   expected_state=expected_task_state):
3305                 instance.task_state = task_state
3306                 instance.save(expected_task_state=expected_state)
3307 
3308             self.driver.snapshot(context, instance, image_id,
3309                                  update_task_state)
3310 
3311             instance.task_state = None
3312             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3313 
3314             self._notify_about_instance_usage(context, instance,
3315                                               "snapshot.end")
3316             compute_utils.notify_about_instance_snapshot(context, instance,
3317                 self.host, phase=fields.NotificationPhase.END,
3318                 snapshot_image_id=image_id)
3319         except (exception.InstanceNotFound,
3320                 exception.UnexpectedDeletingTaskStateError):
3321             # the instance got deleted during the snapshot
3322             # Quickly bail out of here
3323             msg = 'Instance disappeared during snapshot'
3324             LOG.debug(msg, instance=instance)
3325             try:
3326                 image = self.image_api.get(context, image_id)
3327                 if image['status'] != 'active':
3328                     self.image_api.delete(context, image_id)
3329             except Exception:
3330                 LOG.warning("Error while trying to clean up image %s",
3331                             image_id, instance=instance)
3332         except exception.ImageNotFound:
3333             instance.task_state = None
3334             instance.save()
3335             LOG.warning("Image not found during snapshot", instance=instance)
3336 
3337     def _post_interrupted_snapshot_cleanup(self, context, instance):
3338         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3339 
3340     @messaging.expected_exceptions(NotImplementedError)
3341     @wrap_exception()
3342     def volume_snapshot_create(self, context, instance, volume_id,
3343                                create_info):
3344         self.driver.volume_snapshot_create(context, instance, volume_id,
3345                                            create_info)
3346 
3347     @messaging.expected_exceptions(NotImplementedError)
3348     @wrap_exception()
3349     def volume_snapshot_delete(self, context, instance, volume_id,
3350                                snapshot_id, delete_info):
3351         self.driver.volume_snapshot_delete(context, instance, volume_id,
3352                                            snapshot_id, delete_info)
3353 
3354     @wrap_instance_fault
3355     def _rotate_backups(self, context, instance, backup_type, rotation):
3356         """Delete excess backups associated to an instance.
3357 
3358         Instances are allowed a fixed number of backups (the rotation number);
3359         this method deletes the oldest backups that exceed the rotation
3360         threshold.
3361 
3362         :param context: security context
3363         :param instance: Instance dict
3364         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3365         :param rotation: int representing how many backups to keep around;
3366             None if rotation shouldn't be used (as in the case of snapshots)
3367         """
3368         filters = {'property-image_type': 'backup',
3369                    'property-backup_type': backup_type,
3370                    'property-instance_uuid': instance.uuid}
3371 
3372         images = self.image_api.get_all(context, filters=filters,
3373                                         sort_key='created_at', sort_dir='desc')
3374         num_images = len(images)
3375         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3376                   {'num_images': num_images, 'rotation': rotation},
3377                   instance=instance)
3378 
3379         if num_images > rotation:
3380             # NOTE(sirp): this deletes all backups that exceed the rotation
3381             # limit
3382             excess = len(images) - rotation
3383             LOG.debug("Rotating out %d backups", excess,
3384                       instance=instance)
3385             for i in range(excess):
3386                 image = images.pop()
3387                 image_id = image['id']
3388                 LOG.debug("Deleting image %s", image_id,
3389                           instance=instance)
3390                 try:
3391                     self.image_api.delete(context, image_id)
3392                 except exception.ImageNotFound:
3393                     LOG.info("Failed to find image %(image_id)s to "
3394                              "delete", {'image_id': image_id},
3395                              instance=instance)
3396 
3397     @wrap_exception()
3398     @reverts_task_state
3399     @wrap_instance_event(prefix='compute')
3400     @wrap_instance_fault
3401     def set_admin_password(self, context, instance, new_pass):
3402         """Set the root/admin password for an instance on this host.
3403 
3404         This is generally only called by API password resets after an
3405         image has been built.
3406 
3407         @param context: Nova auth context.
3408         @param instance: Nova instance object.
3409         @param new_pass: The admin password for the instance.
3410         """
3411 
3412         context = context.elevated()
3413         if new_pass is None:
3414             # Generate a random password
3415             new_pass = utils.generate_password()
3416 
3417         current_power_state = self._get_power_state(context, instance)
3418         expected_state = power_state.RUNNING
3419 
3420         if current_power_state != expected_state:
3421             instance.task_state = None
3422             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3423             _msg = _('instance %s is not running') % instance.uuid
3424             raise exception.InstancePasswordSetFailed(
3425                 instance=instance.uuid, reason=_msg)
3426 
3427         try:
3428             self.driver.set_admin_password(instance, new_pass)
3429             LOG.info("Admin password set", instance=instance)
3430             instance.task_state = None
3431             instance.save(
3432                 expected_task_state=task_states.UPDATING_PASSWORD)
3433         except exception.InstanceAgentNotEnabled:
3434             with excutils.save_and_reraise_exception():
3435                 LOG.debug('Guest agent is not enabled for the instance.',
3436                           instance=instance)
3437                 instance.task_state = None
3438                 instance.save(
3439                     expected_task_state=task_states.UPDATING_PASSWORD)
3440         except exception.SetAdminPasswdNotSupported:
3441             with excutils.save_and_reraise_exception():
3442                 LOG.info('set_admin_password is not supported '
3443                          'by this driver or guest instance.',
3444                          instance=instance)
3445                 instance.task_state = None
3446                 instance.save(
3447                     expected_task_state=task_states.UPDATING_PASSWORD)
3448         except NotImplementedError:
3449             LOG.warning('set_admin_password is not implemented '
3450                         'by this driver or guest instance.',
3451                         instance=instance)
3452             instance.task_state = None
3453             instance.save(
3454                 expected_task_state=task_states.UPDATING_PASSWORD)
3455             raise NotImplementedError(_('set_admin_password is not '
3456                                         'implemented by this driver or guest '
3457                                         'instance.'))
3458         except exception.UnexpectedTaskStateError:
3459             # interrupted by another (most likely delete) task
3460             # do not retry
3461             raise
3462         except Exception:
3463             # Catch all here because this could be anything.
3464             LOG.exception('set_admin_password failed', instance=instance)
3465             self._set_instance_obj_error_state(context, instance)
3466             # We create a new exception here so that we won't
3467             # potentially reveal password information to the
3468             # API caller.  The real exception is logged above
3469             _msg = _('error setting admin password')
3470             raise exception.InstancePasswordSetFailed(
3471                 instance=instance.uuid, reason=_msg)
3472 
3473     @wrap_exception()
3474     @reverts_task_state
3475     @wrap_instance_fault
3476     def inject_file(self, context, path, file_contents, instance):
3477         """Write a file to the specified path in an instance on this host."""
3478         # NOTE(russellb) Remove this method, as well as the underlying virt
3479         # driver methods, when the compute rpc interface is bumped to 4.x
3480         # as it is no longer used.
3481         context = context.elevated()
3482         current_power_state = self._get_power_state(context, instance)
3483         expected_state = power_state.RUNNING
3484         if current_power_state != expected_state:
3485             LOG.warning('trying to inject a file into a non-running '
3486                         '(state: %(current_state)s expected: '
3487                         '%(expected_state)s)',
3488                         {'current_state': current_power_state,
3489                          'expected_state': expected_state},
3490                         instance=instance)
3491         LOG.info('injecting file to %s', path, instance=instance)
3492         self.driver.inject_file(instance, path, file_contents)
3493 
3494     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3495         """Determine what image should be used to boot the rescue VM."""
3496         # 1. If rescue_image_ref is passed in, use that for rescue.
3497         # 2. Else, use the base image associated with instance's current image.
3498         #       The idea here is to provide the customer with a rescue
3499         #       environment which they are familiar with.
3500         #       So, if they built their instance off of a Debian image,
3501         #       their rescue VM will also be Debian.
3502         # 3. As a last resort, use instance's current image.
3503         if not rescue_image_ref:
3504             system_meta = utils.instance_sys_meta(instance)
3505             rescue_image_ref = system_meta.get('image_base_image_ref')
3506 
3507         if not rescue_image_ref:
3508             LOG.warning('Unable to find a different image to use for '
3509                         'rescue VM, using instance\'s current image',
3510                         instance=instance)
3511             rescue_image_ref = instance.image_ref
3512 
3513         return objects.ImageMeta.from_image_ref(
3514             context, self.image_api, rescue_image_ref)
3515 
3516     @wrap_exception()
3517     @reverts_task_state
3518     @wrap_instance_event(prefix='compute')
3519     @wrap_instance_fault
3520     def rescue_instance(self, context, instance, rescue_password,
3521                         rescue_image_ref, clean_shutdown):
3522         context = context.elevated()
3523         LOG.info('Rescuing', instance=instance)
3524 
3525         admin_password = (rescue_password if rescue_password else
3526                       utils.generate_password())
3527 
3528         network_info = self.network_api.get_instance_nw_info(context, instance)
3529 
3530         rescue_image_meta = self._get_rescue_image(context, instance,
3531                                                    rescue_image_ref)
3532 
3533         extra_usage_info = {'rescue_image_name':
3534                             self._get_image_name(rescue_image_meta)}
3535         self._notify_about_instance_usage(context, instance,
3536                 "rescue.start", extra_usage_info=extra_usage_info,
3537                 network_info=network_info)
3538 
3539         try:
3540             self._power_off_instance(context, instance, clean_shutdown)
3541 
3542             self.driver.rescue(context, instance,
3543                                network_info,
3544                                rescue_image_meta, admin_password)
3545         except Exception as e:
3546             LOG.exception("Error trying to Rescue Instance",
3547                           instance=instance)
3548             self._set_instance_obj_error_state(context, instance)
3549             raise exception.InstanceNotRescuable(
3550                 instance_id=instance.uuid,
3551                 reason=_("Driver Error: %s") % e)
3552 
3553         compute_utils.notify_usage_exists(self.notifier, context, instance,
3554                                           current_period=True)
3555 
3556         instance.vm_state = vm_states.RESCUED
3557         instance.task_state = None
3558         instance.power_state = self._get_power_state(context, instance)
3559         instance.launched_at = timeutils.utcnow()
3560         instance.save(expected_task_state=task_states.RESCUING)
3561 
3562         self._notify_about_instance_usage(context, instance,
3563                 "rescue.end", extra_usage_info=extra_usage_info,
3564                 network_info=network_info)
3565 
3566     @wrap_exception()
3567     @reverts_task_state
3568     @wrap_instance_event(prefix='compute')
3569     @wrap_instance_fault
3570     def unrescue_instance(self, context, instance):
3571         context = context.elevated()
3572         LOG.info('Unrescuing', instance=instance)
3573 
3574         network_info = self.network_api.get_instance_nw_info(context, instance)
3575         self._notify_about_instance_usage(context, instance,
3576                 "unrescue.start", network_info=network_info)
3577         with self._error_out_instance_on_exception(context, instance):
3578             self.driver.unrescue(instance,
3579                                  network_info)
3580 
3581         instance.vm_state = vm_states.ACTIVE
3582         instance.task_state = None
3583         instance.power_state = self._get_power_state(context, instance)
3584         instance.save(expected_task_state=task_states.UNRESCUING)
3585 
3586         self._notify_about_instance_usage(context,
3587                                           instance,
3588                                           "unrescue.end",
3589                                           network_info=network_info)
3590 
3591     @wrap_exception()
3592     @wrap_instance_fault
3593     def change_instance_metadata(self, context, diff, instance):
3594         """Update the metadata published to the instance."""
3595         LOG.debug("Changing instance metadata according to %r",
3596                   diff, instance=instance)
3597         self.driver.change_instance_metadata(context, instance, diff)
3598 
3599     @wrap_exception()
3600     @wrap_instance_event(prefix='compute')
3601     @wrap_instance_fault
3602     def confirm_resize(self, context, instance, reservations, migration):
3603         """Confirms a migration/resize and deletes the 'old' instance.
3604 
3605         This is called from the API and runs on the source host.
3606 
3607         Nothing needs to happen on the destination host at this point since
3608         the instance is already running there. This routine just cleans up the
3609         source host.
3610         """
3611         @utils.synchronized(instance.uuid)
3612         def do_confirm_resize(context, instance, migration_id):
3613             # NOTE(wangpan): Get the migration status from db, if it has been
3614             #                confirmed, we do nothing and return here
3615             LOG.debug("Going to confirm migration %s", migration_id,
3616                       instance=instance)
3617             try:
3618                 # TODO(russellb) Why are we sending the migration object just
3619                 # to turn around and look it up from the db again?
3620                 migration = objects.Migration.get_by_id(
3621                                     context.elevated(), migration_id)
3622             except exception.MigrationNotFound:
3623                 LOG.error("Migration %s is not found during confirmation",
3624                           migration_id, instance=instance)
3625                 return
3626 
3627             if migration.status == 'confirmed':
3628                 LOG.info("Migration %s is already confirmed",
3629                          migration_id, instance=instance)
3630                 return
3631             elif migration.status not in ('finished', 'confirming'):
3632                 LOG.warning("Unexpected confirmation status '%(status)s' "
3633                             "of migration %(id)s, exit confirmation process",
3634                             {"status": migration.status, "id": migration_id},
3635                             instance=instance)
3636                 return
3637 
3638             # NOTE(wangpan): Get the instance from db, if it has been
3639             #                deleted, we do nothing and return here
3640             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3641             try:
3642                 instance = objects.Instance.get_by_uuid(
3643                         context, instance.uuid,
3644                         expected_attrs=expected_attrs)
3645             except exception.InstanceNotFound:
3646                 LOG.info("Instance is not found during confirmation",
3647                          instance=instance)
3648                 return
3649 
3650             self._confirm_resize(context, instance, migration=migration)
3651 
3652         do_confirm_resize(context, instance, migration.id)
3653 
3654     def _confirm_resize(self, context, instance, migration=None):
3655         """Destroys the source instance."""
3656         self._notify_about_instance_usage(context, instance,
3657                                           "resize.confirm.start")
3658 
3659         with self._error_out_instance_on_exception(context, instance):
3660             # NOTE(danms): delete stashed migration information
3661             old_instance_type = instance.old_flavor
3662             instance.old_flavor = None
3663             instance.new_flavor = None
3664             instance.system_metadata.pop('old_vm_state', None)
3665             instance.save()
3666 
3667             # NOTE(tr3buchet): tear down networks on source host
3668             self.network_api.setup_networks_on_host(context, instance,
3669                                migration.source_compute, teardown=True)
3670 
3671             network_info = self.network_api.get_instance_nw_info(context,
3672                                                                  instance)
3673             # TODO(mriedem): Get BDMs here and pass them to the driver.
3674             self.driver.confirm_migration(context, migration, instance,
3675                                           network_info)
3676 
3677             migration.status = 'confirmed'
3678             with migration.obj_as_admin():
3679                 migration.save()
3680 
3681             rt = self._get_resource_tracker()
3682             rt.drop_move_claim(context, instance, migration.source_node,
3683                                old_instance_type, prefix='old_')
3684             self._delete_allocation_after_move(instance, migration,
3685                                                old_instance_type,
3686                                                migration.source_node)
3687             instance.drop_migration_context()
3688 
3689             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3690             # might have manually powered up the instance to confirm the
3691             # resize/migrate, so we need to check the current power state
3692             # on the instance and set the vm_state appropriately. We default
3693             # to ACTIVE because if the power state is not SHUTDOWN, we
3694             # assume _sync_instance_power_state will clean it up.
3695             p_state = instance.power_state
3696             vm_state = None
3697             if p_state == power_state.SHUTDOWN:
3698                 vm_state = vm_states.STOPPED
3699                 LOG.debug("Resized/migrated instance is powered off. "
3700                           "Setting vm_state to '%s'.", vm_state,
3701                           instance=instance)
3702             else:
3703                 vm_state = vm_states.ACTIVE
3704 
3705             instance.vm_state = vm_state
3706             instance.task_state = None
3707             instance.save(expected_task_state=[None, task_states.DELETING])
3708 
3709             self._notify_about_instance_usage(
3710                 context, instance, "resize.confirm.end",
3711                 network_info=network_info)
3712 
3713     def _delete_allocation_after_move(self, instance, migration, flavor,
3714                                       nodename):
3715         rt = self._get_resource_tracker()
3716         cn_uuid = rt.get_node_uuid(nodename)
3717 
3718         if migration.source_node == nodename:
3719             if migration.status in ('confirmed', 'completed'):
3720                 # NOTE(danms): We're finishing on the source node, so try to
3721                 # delete the allocation based on the migration uuid
3722                 deleted = self.reportclient.delete_allocation_for_instance(
3723                     migration.uuid)
3724                 if deleted:
3725                     LOG.info(_('Source node %(node)s confirmed migration '
3726                                '%(mig)s; deleted migration-based '
3727                                'allocation'),
3728                              {'node': nodename, 'mig': migration.uuid})
3729                     # NOTE(danms): We succeeded, which means we do not
3730                     # need to do the complex double allocation dance
3731                     return
3732             else:
3733                 # We're reverting (or failed) on the source, so we
3734                 # need to check if our migration holds a claim and if
3735                 # so, avoid doing the legacy behavior below.
3736                 mig_allocs = (
3737                     self.reportclient.get_allocations_for_consumer_by_provider(
3738                         cn_uuid, migration.uuid))
3739                 if mig_allocs:
3740                     LOG.info(_('Source node %(node)s reverted migration '
3741                                '%(mig)s; not deleting migration-based '
3742                                'allocation'),
3743                              {'node': nodename, 'mig': migration.uuid})
3744                     return
3745         elif migration.dest_node == nodename:
3746             # NOTE(danms): We're reverting on the destination node
3747             # (and we must not be doing a same-host migration if we
3748             # made it past the check above), so we need to check to
3749             # see if the source did migration-based allocation
3750             # accounting
3751             allocs = (
3752                 self.reportclient.get_allocations_for_consumer_by_provider(
3753                     cn_uuid, migration.uuid))
3754             if allocs:
3755                 # NOTE(danms): The source did migration-based allocation
3756                 # accounting, so we should let the source node rejigger
3757                 # the allocations in finish_resize_revert()
3758                 LOG.info(_('Destination node %(node)s reverted migration '
3759                            '%(mig)s; not deleting migration-based '
3760                            'allocation'),
3761                          {'node': nodename, 'mig': migration.uuid})
3762                 return
3763 
3764         # TODO(danms): Remove below this line when we remove compatibility
3765         # for double-accounting migrations (likely rocky)
3766         LOG.info(_('Doing legacy allocation math for migration %(mig)s after '
3767                    'instance move'),
3768                  {'mig': migration.uuid},
3769                  instance=instance)
3770 
3771         # NOTE(jaypipes): This sucks, but due to the fact that confirm_resize()
3772         # only runs on the source host and revert_resize() runs on the
3773         # destination host, we need to do this here. Basically, what we're
3774         # doing here is grabbing the existing allocations for this instance
3775         # from the placement API, dropping the resources in the doubled-up
3776         # allocation set that refer to the source host UUID and calling PUT
3777         # /allocations back to the placement API. The allocation that gets
3778         # PUT'd back to placement will only include the destination host and
3779         # any shared providers in the case of a confirm_resize operation and
3780         # the source host and shared providers for a revert_resize operation..
3781         my_resources = scheduler_utils.resources_from_flavor(instance, flavor)
3782         res = self.reportclient.remove_provider_from_instance_allocation(
3783             instance.uuid, cn_uuid, instance.user_id,
3784             instance.project_id, my_resources)
3785         if not res:
3786             LOG.error("Failed to save manipulated allocation",
3787                       instance=instance)
3788 
3789     @wrap_exception()
3790     @reverts_task_state
3791     @wrap_instance_event(prefix='compute')
3792     @errors_out_migration
3793     @wrap_instance_fault
3794     def revert_resize(self, context, instance, migration, reservations):
3795         """Destroys the new instance on the destination machine.
3796 
3797         Reverts the model changes, and powers on the old instance on the
3798         source machine.
3799 
3800         """
3801         # NOTE(comstud): A revert_resize is essentially a resize back to
3802         # the old size, so we need to send a usage event here.
3803         compute_utils.notify_usage_exists(self.notifier, context, instance,
3804                                           current_period=True)
3805 
3806         with self._error_out_instance_on_exception(context, instance):
3807             # NOTE(tr3buchet): tear down networks on destination host
3808             self.network_api.setup_networks_on_host(context, instance,
3809                                                     teardown=True)
3810 
3811             migration_p = obj_base.obj_to_primitive(migration)
3812             self.network_api.migrate_instance_start(context,
3813                                                     instance,
3814                                                     migration_p)
3815 
3816             network_info = self.network_api.get_instance_nw_info(context,
3817                                                                  instance)
3818             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3819                     context, instance.uuid)
3820             block_device_info = self._get_instance_block_device_info(
3821                                 context, instance, bdms=bdms)
3822 
3823             destroy_disks = not self._is_instance_storage_shared(
3824                 context, instance, host=migration.source_compute)
3825             self.driver.destroy(context, instance, network_info,
3826                                 block_device_info, destroy_disks)
3827 
3828             self._terminate_volume_connections(context, instance, bdms)
3829 
3830             migration.status = 'reverted'
3831             with migration.obj_as_admin():
3832                 migration.save()
3833 
3834             # NOTE(ndipanov): We need to do this here because dropping the
3835             # claim means we lose the migration_context data. We really should
3836             # fix this by moving the drop_move_claim call to the
3837             # finish_revert_resize method as this is racy (revert is dropped,
3838             # but instance resources will be tracked with the new flavor until
3839             # it gets rolled back in finish_revert_resize, which is
3840             # potentially wrong for a period of time).
3841             instance.revert_migration_context()
3842             instance.save()
3843 
3844             rt = self._get_resource_tracker()
3845             rt.drop_move_claim(context, instance, instance.node)
3846             self._delete_allocation_after_move(instance, migration,
3847                                                instance.flavor,
3848                                                instance.node)
3849 
3850             # RPC cast back to the source host to finish the revert there.
3851             self.compute_rpcapi.finish_revert_resize(context, instance,
3852                     migration, migration.source_compute)
3853 
3854     @wrap_exception()
3855     @reverts_task_state
3856     @wrap_instance_event(prefix='compute')
3857     @errors_out_migration
3858     @wrap_instance_fault
3859     def finish_revert_resize(self, context, instance, reservations, migration):
3860         """Finishes the second half of reverting a resize on the source host.
3861 
3862         Bring the original source instance state back (active/shutoff) and
3863         revert the resized attributes in the database.
3864 
3865         """
3866         with self._error_out_instance_on_exception(context, instance):
3867             self._notify_about_instance_usage(
3868                     context, instance, "resize.revert.start")
3869             compute_utils.notify_about_instance_action(context, instance,
3870                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
3871                     phase=fields.NotificationPhase.START)
3872 
3873             # NOTE(mriedem): delete stashed old_vm_state information; we
3874             # default to ACTIVE for backwards compatibility if old_vm_state
3875             # is not set
3876             old_vm_state = instance.system_metadata.pop('old_vm_state',
3877                                                         vm_states.ACTIVE)
3878 
3879             self._set_instance_info(instance, instance.old_flavor)
3880             instance.old_flavor = None
3881             instance.new_flavor = None
3882             instance.host = migration.source_compute
3883             instance.node = migration.source_node
3884             instance.save()
3885 
3886             self._revert_allocation(context, instance, migration)
3887 
3888             self.network_api.setup_networks_on_host(context, instance,
3889                                                     migration.source_compute)
3890             migration_p = obj_base.obj_to_primitive(migration)
3891             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
3892             # source host temporarily. "network_api.migrate_instance_finish"
3893             # will setup the network for the instance on the destination host.
3894             # For revert resize, the instance will back to the source host, the
3895             # setup of the network for instance should be on the source host.
3896             # So set the migration_p['dest_compute'] to source host at here.
3897             migration_p['dest_compute'] = migration.source_compute
3898             self.network_api.migrate_instance_finish(context,
3899                                                      instance,
3900                                                      migration_p)
3901             network_info = self.network_api.get_instance_nw_info(context,
3902                                                                  instance)
3903 
3904             block_device_info = self._get_instance_block_device_info(
3905                     context, instance, refresh_conn_info=True)
3906 
3907             power_on = old_vm_state != vm_states.STOPPED
3908             self.driver.finish_revert_migration(context, instance,
3909                                        network_info,
3910                                        block_device_info, power_on)
3911 
3912             instance.drop_migration_context()
3913             instance.launched_at = timeutils.utcnow()
3914             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
3915 
3916             # if the original vm state was STOPPED, set it back to STOPPED
3917             LOG.info("Updating instance to original state: '%s'",
3918                      old_vm_state, instance=instance)
3919             if power_on:
3920                 instance.vm_state = vm_states.ACTIVE
3921                 instance.task_state = None
3922                 instance.save()
3923             else:
3924                 instance.task_state = task_states.POWERING_OFF
3925                 instance.save()
3926                 self.stop_instance(context, instance=instance,
3927                                    clean_shutdown=True)
3928 
3929             self._notify_about_instance_usage(
3930                     context, instance, "resize.revert.end")
3931             compute_utils.notify_about_instance_action(context, instance,
3932                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
3933                     phase=fields.NotificationPhase.END)
3934 
3935     def _revert_allocation(self, context, instance, migration):
3936         """Revert an allocation that is held by migration to our instance."""
3937 
3938         # Fetch the original allocation that the instance had on the source
3939         # node, which are now held by the migration
3940         orig_alloc = self.reportclient.get_allocations_for_consumer(
3941             migration.uuid)
3942         if not orig_alloc:
3943             # NOTE(danms): This migration did not do per-migration allocation
3944             # accounting, so nothing to do here.
3945             LOG.info('Old-style migration %(mig)s is being reverted; '
3946                      'no migration claims found on original node '
3947                      'to swap.',
3948                      {'mig': migration.uuid},
3949                      instance=instance)
3950             return False
3951 
3952         if len(orig_alloc) > 1:
3953             # NOTE(danms): This may change later if we have other allocations
3954             # against other providers that need to be held by the migration
3955             # as well. Perhaps something like shared storage resources that
3956             # will actually be duplicated during a resize type operation.
3957             LOG.error('New-style migration %(mig)s has allocations against '
3958                       'more than one provider %(rps)s. This should not be '
3959                       'possible, but reverting it anyway.',
3960                       {'mig': migration.uuid,
3961                        'rps': ','.join(orig_alloc.keys())},
3962                       instance=instance)
3963 
3964         # We only have a claim against one provider, it is the source node
3965         cn_uuid = list(orig_alloc.keys())[0]
3966 
3967         # Get just the resources part of the one allocation we need below
3968         orig_alloc = orig_alloc[cn_uuid].get('resources', {})
3969 
3970         # FIXME(danms): Since we don't have an atomic operation to adjust
3971         # allocations for multiple consumers, we have to have space on the
3972         # source for double the claim before we delete the old one
3973         # FIXME(danms): This method is flawed in that it asssumes allocations
3974         # against only one provider. So, this may overwite allocations against
3975         # a shared provider, if we had one.
3976         LOG.info('Swapping old allocation on %(node)s held by migration '
3977                  '%(mig)s for instance',
3978                  {'node': cn_uuid, 'mig': migration.uuid},
3979                  instance=instance)
3980         self.reportclient.put_allocations(cn_uuid, instance.uuid, orig_alloc,
3981                                           instance.project_id,
3982                                           instance.user_id)
3983         self.reportclient.delete_allocation_for_instance(migration.uuid)
3984         return True
3985 
3986     def _prep_resize(self, context, image, instance, instance_type,
3987                      filter_properties, node, migration, clean_shutdown=True):
3988 
3989         if not filter_properties:
3990             filter_properties = {}
3991 
3992         if not instance.host:
3993             self._set_instance_obj_error_state(context, instance)
3994             msg = _('Instance has no source host')
3995             raise exception.MigrationError(reason=msg)
3996 
3997         same_host = instance.host == self.host
3998         # if the flavor IDs match, it's migrate; otherwise resize
3999         if same_host and instance_type.id == instance['instance_type_id']:
4000             # check driver whether support migrate to same host
4001             if not self.driver.capabilities['supports_migrate_to_same_host']:
4002                 raise exception.UnableToMigrateToSelf(
4003                     instance_id=instance.uuid, host=self.host)
4004 
4005         # NOTE(danms): Stash the new instance_type to avoid having to
4006         # look it up in the database later
4007         instance.new_flavor = instance_type
4008         # NOTE(mriedem): Stash the old vm_state so we can set the
4009         # resized/reverted instance back to the same state later.
4010         vm_state = instance.vm_state
4011         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4012         instance.system_metadata['old_vm_state'] = vm_state
4013         instance.save()
4014 
4015         limits = filter_properties.get('limits', {})
4016         rt = self._get_resource_tracker()
4017         with rt.resize_claim(context, instance, instance_type, node,
4018                              migration, image_meta=image,
4019                              limits=limits) as claim:
4020             LOG.info('Migrating', instance=instance)
4021             # RPC cast to the source host to start the actual resize/migration.
4022             self.compute_rpcapi.resize_instance(
4023                     context, instance, claim.migration, image,
4024                     instance_type, clean_shutdown)
4025 
4026     @wrap_exception()
4027     @reverts_task_state
4028     @wrap_instance_event(prefix='compute')
4029     @wrap_instance_fault
4030     def prep_resize(self, context, image, instance, instance_type,
4031                     reservations, request_spec, filter_properties, node,
4032                     clean_shutdown, migration=None):
4033         """Initiates the process of moving a running instance to another host.
4034 
4035         Possibly changes the VCPU, RAM and disk size in the process.
4036 
4037         This is initiated from conductor and runs on the destination host.
4038 
4039         The main purpose of this method is performing some checks on the
4040         destination host and making a claim for resources. If the claim fails
4041         then a reschedule to another host may be attempted which involves
4042         calling back to conductor to start the process over again.
4043         """
4044         if node is None:
4045             node = self._get_nodename(instance, refresh=True)
4046 
4047         # NOTE(melwitt): Remove this in version 5.0 of the RPC API
4048         # Code downstream may expect extra_specs to be populated since it
4049         # is receiving an object, so lookup the flavor to ensure this.
4050         if not isinstance(instance_type, objects.Flavor):
4051             instance_type = objects.Flavor.get_by_id(context,
4052                                                      instance_type['id'])
4053         with self._error_out_instance_on_exception(context, instance), \
4054                  errors_out_migration_ctxt(migration):
4055             compute_utils.notify_usage_exists(self.notifier, context, instance,
4056                                               current_period=True)
4057             self._notify_about_instance_usage(
4058                     context, instance, "resize.prep.start")
4059             failed = False
4060             try:
4061                 self._prep_resize(context, image, instance,
4062                                   instance_type, filter_properties,
4063                                   node, migration, clean_shutdown)
4064             except Exception:
4065                 failed = True
4066                 # try to re-schedule the resize elsewhere:
4067                 exc_info = sys.exc_info()
4068                 self._reschedule_resize_or_reraise(context, image, instance,
4069                         exc_info, instance_type, request_spec,
4070                         filter_properties)
4071             finally:
4072                 if failed:
4073                     # Since we hit a failure, we're either rescheduling or dead
4074                     # and either way we need to cleanup any allocations created
4075                     # by the scheduler for the destination node.
4076                     if migration and not self._revert_allocation(
4077                             context, instance, migration):
4078                         # We did not do a migration-based
4079                         # allocation. Note that for a resize to the
4080                         # same host, the scheduler will merge the
4081                         # flavors, so here we'd be subtracting the new
4082                         # flavor from the allocated resources on this
4083                         # node.
4084                         # FIXME(danms): Remove this in Rocky
4085                         rt = self._get_resource_tracker()
4086                         rt.delete_allocation_for_failed_resize(
4087                             instance, node, instance_type)
4088 
4089                 extra_usage_info = dict(
4090                         new_instance_type=instance_type.name,
4091                         new_instance_type_id=instance_type.id)
4092 
4093                 self._notify_about_instance_usage(
4094                     context, instance, "resize.prep.end",
4095                     extra_usage_info=extra_usage_info)
4096 
4097     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
4098             instance_type, request_spec, filter_properties):
4099         """Try to re-schedule the resize or re-raise the original error to
4100         error out the instance.
4101         """
4102         if not request_spec:
4103             request_spec = {}
4104         if not filter_properties:
4105             filter_properties = {}
4106 
4107         rescheduled = False
4108         instance_uuid = instance.uuid
4109 
4110         try:
4111             reschedule_method = self.compute_task_api.resize_instance
4112             scheduler_hint = dict(filter_properties=filter_properties)
4113             method_args = (instance, None, scheduler_hint, instance_type)
4114             task_state = task_states.RESIZE_PREP
4115 
4116             rescheduled = self._reschedule(context, request_spec,
4117                     filter_properties, instance, reschedule_method,
4118                     method_args, task_state, exc_info)
4119         except Exception as error:
4120             rescheduled = False
4121             LOG.exception("Error trying to reschedule",
4122                           instance_uuid=instance_uuid)
4123             compute_utils.add_instance_fault_from_exc(context,
4124                     instance, error,
4125                     exc_info=sys.exc_info())
4126             self._notify_about_instance_usage(context, instance,
4127                     'resize.error', fault=error)
4128             compute_utils.notify_about_instance_action(
4129                 context, instance, self.host,
4130                 action=fields.NotificationAction.RESIZE,
4131                 phase=fields.NotificationPhase.ERROR,
4132                 exception=error)
4133         if rescheduled:
4134             self._log_original_error(exc_info, instance_uuid)
4135             compute_utils.add_instance_fault_from_exc(context,
4136                     instance, exc_info[1], exc_info=exc_info)
4137             self._notify_about_instance_usage(context, instance,
4138                     'resize.error', fault=exc_info[1])
4139             compute_utils.notify_about_instance_action(
4140                 context, instance, self.host,
4141                 action=fields.NotificationAction.RESIZE,
4142                 phase=fields.NotificationPhase.ERROR,
4143                 exception=exc_info[1])
4144         else:
4145             # not re-scheduling
4146             six.reraise(*exc_info)
4147 
4148     @wrap_exception()
4149     @reverts_task_state
4150     @wrap_instance_event(prefix='compute')
4151     @wrap_instance_fault
4152     def resize_instance(self, context, instance, image,
4153                         reservations, migration, instance_type,
4154                         clean_shutdown):
4155         """Starts the migration of a running instance to another host.
4156 
4157         This is initiated from the destination host's ``prep_resize`` routine
4158         and runs on the source host.
4159         """
4160         with self._error_out_instance_on_exception(context, instance), \
4161              errors_out_migration_ctxt(migration):
4162             # TODO(chaochin) Remove this until v5 RPC API
4163             # Code downstream may expect extra_specs to be populated since it
4164             # is receiving an object, so lookup the flavor to ensure this.
4165             if (not instance_type or
4166                 not isinstance(instance_type, objects.Flavor)):
4167                 instance_type = objects.Flavor.get_by_id(
4168                     context, migration['new_instance_type_id'])
4169 
4170             network_info = self.network_api.get_instance_nw_info(context,
4171                                                                  instance)
4172 
4173             migration.status = 'migrating'
4174             with migration.obj_as_admin():
4175                 migration.save()
4176 
4177             instance.task_state = task_states.RESIZE_MIGRATING
4178             instance.save(expected_task_state=task_states.RESIZE_PREP)
4179 
4180             self._notify_about_instance_usage(
4181                 context, instance, "resize.start", network_info=network_info)
4182 
4183             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4184                     context, instance.uuid)
4185 
4186             compute_utils.notify_about_instance_action(context, instance,
4187                    self.host, action=fields.NotificationAction.RESIZE,
4188                    phase=fields.NotificationPhase.START, bdms=bdms)
4189 
4190             block_device_info = self._get_instance_block_device_info(
4191                                 context, instance, bdms=bdms)
4192 
4193             timeout, retry_interval = self._get_power_off_values(context,
4194                                             instance, clean_shutdown)
4195             disk_info = self.driver.migrate_disk_and_power_off(
4196                     context, instance, migration.dest_host,
4197                     instance_type, network_info,
4198                     block_device_info,
4199                     timeout, retry_interval)
4200 
4201             self._terminate_volume_connections(context, instance, bdms)
4202 
4203             migration_p = obj_base.obj_to_primitive(migration)
4204             self.network_api.migrate_instance_start(context,
4205                                                     instance,
4206                                                     migration_p)
4207 
4208             migration.status = 'post-migrating'
4209             with migration.obj_as_admin():
4210                 migration.save()
4211 
4212             instance.host = migration.dest_compute
4213             instance.node = migration.dest_node
4214             instance.task_state = task_states.RESIZE_MIGRATED
4215             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4216 
4217             # RPC cast to the destination host to finish the resize/migration.
4218             self.compute_rpcapi.finish_resize(context, instance,
4219                     migration, image, disk_info, migration.dest_compute)
4220 
4221         self._notify_about_instance_usage(context, instance, "resize.end",
4222                                           network_info=network_info)
4223 
4224         compute_utils.notify_about_instance_action(context, instance,
4225                self.host, action=fields.NotificationAction.RESIZE,
4226                phase=fields.NotificationPhase.END, bdms=bdms)
4227         self.instance_events.clear_events_for_instance(instance)
4228 
4229     def _terminate_volume_connections(self, context, instance, bdms):
4230         connector = None
4231         for bdm in bdms:
4232             if bdm.is_volume:
4233                 if bdm.attachment_id:
4234                     # NOTE(jdg): So here's the thing, the idea behind the new
4235                     # attach API's was to have a new code fork/path that we
4236                     # followed, we're not going to do that so we have to do
4237                     # some extra work in here to make it *behave* just like the
4238                     # old code. Cinder doesn't allow disconnect/reconnect (you
4239                     # just delete the attachment and get a new one)
4240                     # attachments in the new attach code so we have to do
4241                     # a delete and create without a connector (reserve),
4242                     # in other words, beware
4243                     attachment_id = self.volume_api.attachment_create(
4244                         context, bdm.volume_id, instance.uuid)['id']
4245                     self.volume_api.attachment_delete(context,
4246                                                       bdm.attachment_id)
4247                     bdm.attachment_id = attachment_id
4248                     bdm.save()
4249 
4250                 else:
4251                     if connector is None:
4252                         connector = self.driver.get_volume_connector(instance)
4253                     self.volume_api.terminate_connection(context,
4254                                                          bdm.volume_id,
4255                                                          connector)
4256 
4257     @staticmethod
4258     def _set_instance_info(instance, instance_type):
4259         instance.instance_type_id = instance_type.id
4260         instance.memory_mb = instance_type.memory_mb
4261         instance.vcpus = instance_type.vcpus
4262         instance.root_gb = instance_type.root_gb
4263         instance.ephemeral_gb = instance_type.ephemeral_gb
4264         instance.flavor = instance_type
4265 
4266     def _finish_resize(self, context, instance, migration, disk_info,
4267                        image_meta, bdms):
4268         resize_instance = False
4269         old_instance_type_id = migration['old_instance_type_id']
4270         new_instance_type_id = migration['new_instance_type_id']
4271         old_instance_type = instance.get_flavor()
4272         # NOTE(mriedem): Get the old_vm_state so we know if we should
4273         # power on the instance. If old_vm_state is not set we need to default
4274         # to ACTIVE for backwards compatibility
4275         old_vm_state = instance.system_metadata.get('old_vm_state',
4276                                                     vm_states.ACTIVE)
4277         instance.old_flavor = old_instance_type
4278 
4279         if old_instance_type_id != new_instance_type_id:
4280             instance_type = instance.get_flavor('new')
4281             self._set_instance_info(instance, instance_type)
4282             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4283                 if old_instance_type[key] != instance_type[key]:
4284                     resize_instance = True
4285                     break
4286         instance.apply_migration_context()
4287 
4288         # NOTE(tr3buchet): setup networks on destination host
4289         self.network_api.setup_networks_on_host(context, instance,
4290                                                 migration['dest_compute'])
4291 
4292         migration_p = obj_base.obj_to_primitive(migration)
4293         self.network_api.migrate_instance_finish(context,
4294                                                  instance,
4295                                                  migration_p)
4296 
4297         network_info = self.network_api.get_instance_nw_info(context, instance)
4298 
4299         instance.task_state = task_states.RESIZE_FINISH
4300         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4301 
4302         self._notify_about_instance_usage(
4303             context, instance, "finish_resize.start",
4304             network_info=network_info)
4305         compute_utils.notify_about_instance_action(context, instance,
4306                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4307                phase=fields.NotificationPhase.START, bdms=bdms)
4308 
4309         block_device_info = self._get_instance_block_device_info(
4310             context, instance, refresh_conn_info=True, bdms=bdms)
4311 
4312         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4313         # automatically power on the instance after it's migrated
4314         power_on = old_vm_state != vm_states.STOPPED
4315 
4316         try:
4317             self.driver.finish_migration(context, migration, instance,
4318                                          disk_info,
4319                                          network_info,
4320                                          image_meta, resize_instance,
4321                                          block_device_info, power_on)
4322         except Exception:
4323             with excutils.save_and_reraise_exception():
4324                 if old_instance_type_id != new_instance_type_id:
4325                     self._set_instance_info(instance,
4326                                             old_instance_type)
4327 
4328         migration.status = 'finished'
4329         with migration.obj_as_admin():
4330             migration.save()
4331 
4332         instance.vm_state = vm_states.RESIZED
4333         instance.task_state = None
4334         instance.launched_at = timeutils.utcnow()
4335         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4336 
4337         return network_info
4338 
4339     @wrap_exception()
4340     @reverts_task_state
4341     @wrap_instance_event(prefix='compute')
4342     @wrap_instance_fault
4343     def finish_resize(self, context, disk_info, image, instance,
4344                       reservations, migration):
4345         """Completes the migration process.
4346 
4347         Sets up the newly transferred disk and turns on the instance at its
4348         new host machine.
4349 
4350         """
4351         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4352             context, instance.uuid)
4353 
4354         with self._error_out_instance_on_exception(context, instance), \
4355              errors_out_migration_ctxt(migration):
4356             image_meta = objects.ImageMeta.from_dict(image)
4357             network_info = self._finish_resize(context, instance, migration,
4358                                                disk_info, image_meta, bdms)
4359 
4360         self._update_scheduler_instance_info(context, instance)
4361         self._notify_about_instance_usage(
4362             context, instance, "finish_resize.end",
4363             network_info=network_info)
4364         compute_utils.notify_about_instance_action(context, instance,
4365                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4366                phase=fields.NotificationPhase.END, bdms=bdms)
4367 
4368     @wrap_exception()
4369     @wrap_instance_fault
4370     def add_fixed_ip_to_instance(self, context, network_id, instance):
4371         """Calls network_api to add new fixed_ip to instance
4372         then injects the new network info and resets instance networking.
4373 
4374         """
4375         self._notify_about_instance_usage(
4376                 context, instance, "create_ip.start")
4377 
4378         network_info = self.network_api.add_fixed_ip_to_instance(context,
4379                                                                  instance,
4380                                                                  network_id)
4381         self._inject_network_info(context, instance, network_info)
4382         self.reset_network(context, instance)
4383 
4384         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4385         instance.updated_at = timeutils.utcnow()
4386         instance.save()
4387 
4388         self._notify_about_instance_usage(
4389             context, instance, "create_ip.end", network_info=network_info)
4390 
4391     @wrap_exception()
4392     @wrap_instance_fault
4393     def remove_fixed_ip_from_instance(self, context, address, instance):
4394         """Calls network_api to remove existing fixed_ip from instance
4395         by injecting the altered network info and resetting
4396         instance networking.
4397         """
4398         self._notify_about_instance_usage(
4399                 context, instance, "delete_ip.start")
4400 
4401         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4402                                                                       instance,
4403                                                                       address)
4404         self._inject_network_info(context, instance, network_info)
4405         self.reset_network(context, instance)
4406 
4407         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4408         instance.updated_at = timeutils.utcnow()
4409         instance.save()
4410 
4411         self._notify_about_instance_usage(
4412             context, instance, "delete_ip.end", network_info=network_info)
4413 
4414     @wrap_exception()
4415     @reverts_task_state
4416     @wrap_instance_event(prefix='compute')
4417     @wrap_instance_fault
4418     def pause_instance(self, context, instance):
4419         """Pause an instance on this host."""
4420         context = context.elevated()
4421         LOG.info('Pausing', instance=instance)
4422         self._notify_about_instance_usage(context, instance, 'pause.start')
4423         compute_utils.notify_about_instance_action(context, instance,
4424                self.host, action=fields.NotificationAction.PAUSE,
4425                phase=fields.NotificationPhase.START)
4426         self.driver.pause(instance)
4427         instance.power_state = self._get_power_state(context, instance)
4428         instance.vm_state = vm_states.PAUSED
4429         instance.task_state = None
4430         instance.save(expected_task_state=task_states.PAUSING)
4431         self._notify_about_instance_usage(context, instance, 'pause.end')
4432         compute_utils.notify_about_instance_action(context, instance,
4433                self.host, action=fields.NotificationAction.PAUSE,
4434                phase=fields.NotificationPhase.END)
4435 
4436     @wrap_exception()
4437     @reverts_task_state
4438     @wrap_instance_event(prefix='compute')
4439     @wrap_instance_fault
4440     def unpause_instance(self, context, instance):
4441         """Unpause a paused instance on this host."""
4442         context = context.elevated()
4443         LOG.info('Unpausing', instance=instance)
4444         self._notify_about_instance_usage(context, instance, 'unpause.start')
4445         compute_utils.notify_about_instance_action(context, instance,
4446             self.host, action=fields.NotificationAction.UNPAUSE,
4447             phase=fields.NotificationPhase.START)
4448         self.driver.unpause(instance)
4449         instance.power_state = self._get_power_state(context, instance)
4450         instance.vm_state = vm_states.ACTIVE
4451         instance.task_state = None
4452         instance.save(expected_task_state=task_states.UNPAUSING)
4453         self._notify_about_instance_usage(context, instance, 'unpause.end')
4454         compute_utils.notify_about_instance_action(context, instance,
4455             self.host, action=fields.NotificationAction.UNPAUSE,
4456             phase=fields.NotificationPhase.END)
4457 
4458     @wrap_exception()
4459     def host_power_action(self, context, action):
4460         """Reboots, shuts down or powers up the host."""
4461         return self.driver.host_power_action(action)
4462 
4463     @wrap_exception()
4464     def host_maintenance_mode(self, context, host, mode):
4465         """Start/Stop host maintenance window. On start, it triggers
4466         guest VMs evacuation.
4467         """
4468         return self.driver.host_maintenance_mode(host, mode)
4469 
4470     @wrap_exception()
4471     def set_host_enabled(self, context, enabled):
4472         """Sets the specified host's ability to accept new instances."""
4473         return self.driver.set_host_enabled(enabled)
4474 
4475     @wrap_exception()
4476     def get_host_uptime(self, context):
4477         """Returns the result of calling "uptime" on the target host."""
4478         return self.driver.get_host_uptime()
4479 
4480     @wrap_exception()
4481     @wrap_instance_fault
4482     def get_diagnostics(self, context, instance):
4483         """Retrieve diagnostics for an instance on this host."""
4484         current_power_state = self._get_power_state(context, instance)
4485         if current_power_state == power_state.RUNNING:
4486             LOG.info("Retrieving diagnostics", instance=instance)
4487             return self.driver.get_diagnostics(instance)
4488         else:
4489             raise exception.InstanceInvalidState(
4490                 attr='power state',
4491                 instance_uuid=instance.uuid,
4492                 state=power_state.STATE_MAP[instance.power_state],
4493                 method='get_diagnostics')
4494 
4495     # TODO(alaski): Remove object_compat for RPC version 5.0
4496     @object_compat
4497     @wrap_exception()
4498     @wrap_instance_fault
4499     def get_instance_diagnostics(self, context, instance):
4500         """Retrieve diagnostics for an instance on this host."""
4501         current_power_state = self._get_power_state(context, instance)
4502         if current_power_state == power_state.RUNNING:
4503             LOG.info("Retrieving diagnostics", instance=instance)
4504             return self.driver.get_instance_diagnostics(instance)
4505         else:
4506             raise exception.InstanceInvalidState(
4507                 attr='power state',
4508                 instance_uuid=instance.uuid,
4509                 state=power_state.STATE_MAP[instance.power_state],
4510                 method='get_diagnostics')
4511 
4512     @wrap_exception()
4513     @reverts_task_state
4514     @wrap_instance_event(prefix='compute')
4515     @wrap_instance_fault
4516     def suspend_instance(self, context, instance):
4517         """Suspend the given instance."""
4518         context = context.elevated()
4519 
4520         # Store the old state
4521         instance.system_metadata['old_vm_state'] = instance.vm_state
4522         self._notify_about_instance_usage(context, instance, 'suspend.start')
4523         compute_utils.notify_about_instance_action(context, instance,
4524                 self.host, action=fields.NotificationAction.SUSPEND,
4525                 phase=fields.NotificationPhase.START)
4526         with self._error_out_instance_on_exception(context, instance,
4527              instance_state=instance.vm_state):
4528             self.driver.suspend(context, instance)
4529         instance.power_state = self._get_power_state(context, instance)
4530         instance.vm_state = vm_states.SUSPENDED
4531         instance.task_state = None
4532         instance.save(expected_task_state=task_states.SUSPENDING)
4533         self._notify_about_instance_usage(context, instance, 'suspend.end')
4534         compute_utils.notify_about_instance_action(context, instance,
4535                 self.host, action=fields.NotificationAction.SUSPEND,
4536                 phase=fields.NotificationPhase.END)
4537 
4538     @wrap_exception()
4539     @reverts_task_state
4540     @wrap_instance_event(prefix='compute')
4541     @wrap_instance_fault
4542     def resume_instance(self, context, instance):
4543         """Resume the given suspended instance."""
4544         context = context.elevated()
4545         LOG.info('Resuming', instance=instance)
4546 
4547         self._notify_about_instance_usage(context, instance, 'resume.start')
4548 
4549         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4550             context, instance.uuid)
4551         block_device_info = self._get_instance_block_device_info(
4552             context, instance, bdms=bdms)
4553 
4554         compute_utils.notify_about_instance_action(context, instance,
4555             self.host, action=fields.NotificationAction.RESUME,
4556             phase=fields.NotificationPhase.START, bdms=bdms)
4557 
4558         network_info = self.network_api.get_instance_nw_info(context, instance)
4559 
4560         with self._error_out_instance_on_exception(context, instance,
4561              instance_state=instance.vm_state):
4562             self.driver.resume(context, instance, network_info,
4563                                block_device_info)
4564 
4565         instance.power_state = self._get_power_state(context, instance)
4566 
4567         # We default to the ACTIVE state for backwards compatibility
4568         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4569                                                          vm_states.ACTIVE)
4570 
4571         instance.task_state = None
4572         instance.save(expected_task_state=task_states.RESUMING)
4573         self._notify_about_instance_usage(context, instance, 'resume.end')
4574         compute_utils.notify_about_instance_action(context, instance,
4575             self.host, action=fields.NotificationAction.RESUME,
4576             phase=fields.NotificationPhase.END, bdms=bdms)
4577 
4578     @wrap_exception()
4579     @reverts_task_state
4580     @wrap_instance_event(prefix='compute')
4581     @wrap_instance_fault
4582     def shelve_instance(self, context, instance, image_id,
4583                         clean_shutdown):
4584         """Shelve an instance.
4585 
4586         This should be used when you want to take a snapshot of the instance.
4587         It also adds system_metadata that can be used by a periodic task to
4588         offload the shelved instance after a period of time.
4589 
4590         :param context: request context
4591         :param instance: an Instance object
4592         :param image_id: an image id to snapshot to.
4593         :param clean_shutdown: give the GuestOS a chance to stop
4594         """
4595 
4596         @utils.synchronized(instance.uuid)
4597         def do_shelve_instance():
4598             self._shelve_instance(context, instance, image_id, clean_shutdown)
4599         do_shelve_instance()
4600 
4601     def _shelve_instance(self, context, instance, image_id,
4602                          clean_shutdown):
4603         LOG.info('Shelving', instance=instance)
4604         offload = CONF.shelved_offload_time == 0
4605         if offload:
4606             # Get the BDMs early so we can pass them into versioned
4607             # notifications since _shelve_offload_instance needs the
4608             # BDMs anyway.
4609             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4610                 context, instance.uuid)
4611         else:
4612             bdms = None
4613         compute_utils.notify_usage_exists(self.notifier, context, instance,
4614                                           current_period=True)
4615         self._notify_about_instance_usage(context, instance, 'shelve.start')
4616         compute_utils.notify_about_instance_action(context, instance,
4617                 self.host, action=fields.NotificationAction.SHELVE,
4618                 phase=fields.NotificationPhase.START, bdms=bdms)
4619 
4620         def update_task_state(task_state, expected_state=task_states.SHELVING):
4621             shelving_state_map = {
4622                     task_states.IMAGE_PENDING_UPLOAD:
4623                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4624                     task_states.IMAGE_UPLOADING:
4625                         task_states.SHELVING_IMAGE_UPLOADING,
4626                     task_states.SHELVING: task_states.SHELVING}
4627             task_state = shelving_state_map[task_state]
4628             expected_state = shelving_state_map[expected_state]
4629             instance.task_state = task_state
4630             instance.save(expected_task_state=expected_state)
4631 
4632         self._power_off_instance(context, instance, clean_shutdown)
4633         self.driver.snapshot(context, instance, image_id, update_task_state)
4634 
4635         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4636         instance.system_metadata['shelved_image_id'] = image_id
4637         instance.system_metadata['shelved_host'] = self.host
4638         instance.vm_state = vm_states.SHELVED
4639         instance.task_state = None
4640         if CONF.shelved_offload_time == 0:
4641             instance.task_state = task_states.SHELVING_OFFLOADING
4642         instance.power_state = self._get_power_state(context, instance)
4643         instance.save(expected_task_state=[
4644                 task_states.SHELVING,
4645                 task_states.SHELVING_IMAGE_UPLOADING])
4646 
4647         self._notify_about_instance_usage(context, instance, 'shelve.end')
4648         compute_utils.notify_about_instance_action(context, instance,
4649                 self.host, action=fields.NotificationAction.SHELVE,
4650                 phase=fields.NotificationPhase.END, bdms=bdms)
4651 
4652         if offload:
4653             self._shelve_offload_instance(context, instance,
4654                                           clean_shutdown=False, bdms=bdms)
4655 
4656     @wrap_exception()
4657     @reverts_task_state
4658     @wrap_instance_fault
4659     def shelve_offload_instance(self, context, instance, clean_shutdown):
4660         """Remove a shelved instance from the hypervisor.
4661 
4662         This frees up those resources for use by other instances, but may lead
4663         to slower unshelve times for this instance.  This method is used by
4664         volume backed instances since restoring them doesn't involve the
4665         potentially large download of an image.
4666 
4667         :param context: request context
4668         :param instance: nova.objects.instance.Instance
4669         :param clean_shutdown: give the GuestOS a chance to stop
4670         """
4671 
4672         @utils.synchronized(instance.uuid)
4673         def do_shelve_offload_instance():
4674             self._shelve_offload_instance(context, instance, clean_shutdown)
4675         do_shelve_offload_instance()
4676 
4677     def _shelve_offload_instance(self, context, instance, clean_shutdown,
4678                                  bdms=None):
4679         LOG.info('Shelve offloading', instance=instance)
4680         if bdms is None:
4681             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4682                 context, instance.uuid)
4683         self._notify_about_instance_usage(context, instance,
4684                 'shelve_offload.start')
4685         compute_utils.notify_about_instance_action(context, instance,
4686                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4687                 phase=fields.NotificationPhase.START, bdms=bdms)
4688 
4689         self._power_off_instance(context, instance, clean_shutdown)
4690         current_power_state = self._get_power_state(context, instance)
4691 
4692         self.network_api.cleanup_instance_network_on_host(context, instance,
4693                                                           instance.host)
4694         network_info = self.network_api.get_instance_nw_info(context, instance)
4695 
4696         block_device_info = self._get_instance_block_device_info(context,
4697                                                                  instance,
4698                                                                  bdms=bdms)
4699         self.driver.destroy(context, instance, network_info,
4700                 block_device_info)
4701 
4702         # the instance is going to be removed from the host so we want to
4703         # terminate all the connections with the volume server and the host
4704         self._terminate_volume_connections(context, instance, bdms)
4705 
4706         instance.power_state = current_power_state
4707         # NOTE(mriedem): The vm_state has to be set before updating the
4708         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4709         # values cannot be nulled out until after updating the resource tracker
4710         # though.
4711         instance.vm_state = vm_states.SHELVED_OFFLOADED
4712         instance.task_state = None
4713         instance.save(expected_task_state=[task_states.SHELVING,
4714                                            task_states.SHELVING_OFFLOADING])
4715 
4716         # NOTE(ndipanov): Free resources from the resource tracker
4717         self._update_resource_tracker(context, instance)
4718 
4719         rt = self._get_resource_tracker()
4720         rt.delete_allocation_for_shelve_offloaded_instance(instance)
4721 
4722         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4723         # instance, so ensure any calls result in errors
4724         self._nil_out_instance_obj_host_and_node(instance)
4725         instance.save(expected_task_state=None)
4726 
4727         self._delete_scheduler_instance_info(context, instance.uuid)
4728         self._notify_about_instance_usage(context, instance,
4729                 'shelve_offload.end')
4730         compute_utils.notify_about_instance_action(context, instance,
4731                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4732                 phase=fields.NotificationPhase.END, bdms=bdms)
4733 
4734     @wrap_exception()
4735     @reverts_task_state
4736     @wrap_instance_event(prefix='compute')
4737     @wrap_instance_fault
4738     def unshelve_instance(self, context, instance, image,
4739                           filter_properties, node):
4740         """Unshelve the instance.
4741 
4742         :param context: request context
4743         :param instance: a nova.objects.instance.Instance object
4744         :param image: an image to build from.  If None we assume a
4745             volume backed instance.
4746         :param filter_properties: dict containing limits, retry info etc.
4747         :param node: target compute node
4748         """
4749         if filter_properties is None:
4750             filter_properties = {}
4751 
4752         @utils.synchronized(instance.uuid)
4753         def do_unshelve_instance():
4754             self._unshelve_instance(context, instance, image,
4755                                     filter_properties, node)
4756         do_unshelve_instance()
4757 
4758     def _unshelve_instance_key_scrub(self, instance):
4759         """Remove data from the instance that may cause side effects."""
4760         cleaned_keys = dict(
4761                 key_data=instance.key_data,
4762                 auto_disk_config=instance.auto_disk_config)
4763         instance.key_data = None
4764         instance.auto_disk_config = False
4765         return cleaned_keys
4766 
4767     def _unshelve_instance_key_restore(self, instance, keys):
4768         """Restore previously scrubbed keys before saving the instance."""
4769         instance.update(keys)
4770 
4771     def _unshelve_instance(self, context, instance, image, filter_properties,
4772                            node):
4773         LOG.info('Unshelving', instance=instance)
4774         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4775                 context, instance.uuid)
4776 
4777         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4778         compute_utils.notify_about_instance_action(context, instance,
4779                 self.host, action=fields.NotificationAction.UNSHELVE,
4780                 phase=fields.NotificationPhase.START, bdms=bdms)
4781 
4782         instance.task_state = task_states.SPAWNING
4783         instance.save()
4784 
4785         block_device_info = self._prep_block_device(context, instance, bdms)
4786         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4787 
4788         if node is None:
4789             node = self._get_nodename(instance)
4790 
4791         rt = self._get_resource_tracker()
4792         limits = filter_properties.get('limits', {})
4793 
4794         allocations = self.reportclient.get_allocations_for_consumer(
4795             instance.uuid)
4796 
4797         shelved_image_ref = instance.image_ref
4798         if image:
4799             instance.image_ref = image['id']
4800             image_meta = objects.ImageMeta.from_dict(image)
4801         else:
4802             image_meta = objects.ImageMeta.from_dict(
4803                 utils.get_image_from_system_metadata(
4804                     instance.system_metadata))
4805 
4806         self.network_api.setup_instance_network_on_host(context, instance,
4807                                                         self.host)
4808         network_info = self.network_api.get_instance_nw_info(context, instance)
4809         try:
4810             with rt.instance_claim(context, instance, node, limits):
4811                 self.driver.spawn(context, instance, image_meta,
4812                                   injected_files=[],
4813                                   admin_password=None,
4814                                   allocations=allocations,
4815                                   network_info=network_info,
4816                                   block_device_info=block_device_info)
4817         except Exception:
4818             with excutils.save_and_reraise_exception(logger=LOG):
4819                 LOG.exception('Instance failed to spawn',
4820                               instance=instance)
4821                 # Cleanup allocations created by the scheduler on this host
4822                 # since we failed to spawn the instance. We do this both if
4823                 # the instance claim failed with ComputeResourcesUnavailable
4824                 # or if we did claim but the spawn failed, because aborting the
4825                 # instance claim will not remove the allocations.
4826                 rt.reportclient.delete_allocation_for_instance(instance.uuid)
4827                 # FIXME: Umm, shouldn't we be rolling back volume connections
4828                 # and port bindings?
4829 
4830         if image:
4831             instance.image_ref = shelved_image_ref
4832             self._delete_snapshot_of_shelved_instance(context, instance,
4833                                                       image['id'])
4834 
4835         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4836         self._update_instance_after_spawn(context, instance)
4837         # Delete system_metadata for a shelved instance
4838         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4839 
4840         instance.save(expected_task_state=task_states.SPAWNING)
4841         self._update_scheduler_instance_info(context, instance)
4842         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4843         compute_utils.notify_about_instance_action(context, instance,
4844                 self.host, action=fields.NotificationAction.UNSHELVE,
4845                 phase=fields.NotificationPhase.END, bdms=bdms)
4846 
4847     @messaging.expected_exceptions(NotImplementedError)
4848     @wrap_instance_fault
4849     def reset_network(self, context, instance):
4850         """Reset networking on the given instance."""
4851         LOG.debug('Reset network', instance=instance)
4852         self.driver.reset_network(instance)
4853 
4854     def _inject_network_info(self, context, instance, network_info):
4855         """Inject network info for the given instance."""
4856         LOG.debug('Inject network info', instance=instance)
4857         LOG.debug('network_info to inject: |%s|', network_info,
4858                   instance=instance)
4859 
4860         self.driver.inject_network_info(instance,
4861                                         network_info)
4862 
4863     @wrap_instance_fault
4864     def inject_network_info(self, context, instance):
4865         """Inject network info, but don't return the info."""
4866         network_info = self.network_api.get_instance_nw_info(context, instance)
4867         self._inject_network_info(context, instance, network_info)
4868 
4869     @messaging.expected_exceptions(NotImplementedError,
4870                                    exception.ConsoleNotAvailable,
4871                                    exception.InstanceNotFound)
4872     @wrap_exception()
4873     @wrap_instance_fault
4874     def get_console_output(self, context, instance, tail_length):
4875         """Send the console output for the given instance."""
4876         context = context.elevated()
4877         LOG.info("Get console output", instance=instance)
4878         output = self.driver.get_console_output(context, instance)
4879 
4880         if type(output) is six.text_type:
4881             output = six.b(output)
4882 
4883         if tail_length is not None:
4884             output = self._tail_log(output, tail_length)
4885 
4886         return output.decode('ascii', 'replace')
4887 
4888     def _tail_log(self, log, length):
4889         try:
4890             length = int(length)
4891         except ValueError:
4892             length = 0
4893 
4894         if length == 0:
4895             return b''
4896         else:
4897             return b'\n'.join(log.split(b'\n')[-int(length):])
4898 
4899     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4900                                    exception.InstanceNotReady,
4901                                    exception.InstanceNotFound,
4902                                    exception.ConsoleTypeUnavailable,
4903                                    NotImplementedError)
4904     @wrap_exception()
4905     @wrap_instance_fault
4906     def get_vnc_console(self, context, console_type, instance):
4907         """Return connection information for a vnc console."""
4908         context = context.elevated()
4909         LOG.debug("Getting vnc console", instance=instance)
4910         token = uuidutils.generate_uuid()
4911 
4912         if not CONF.vnc.enabled:
4913             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4914 
4915         if console_type == 'novnc':
4916             # For essex, novncproxy_base_url must include the full path
4917             # including the html file (like http://myhost/vnc_auto.html)
4918             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
4919         elif console_type == 'xvpvnc':
4920             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
4921         else:
4922             raise exception.ConsoleTypeInvalid(console_type=console_type)
4923 
4924         try:
4925             # Retrieve connect info from driver, and then decorate with our
4926             # access info token
4927             console = self.driver.get_vnc_console(context, instance)
4928             connect_info = console.get_connection_info(token, access_url)
4929         except exception.InstanceNotFound:
4930             if instance.vm_state != vm_states.BUILDING:
4931                 raise
4932             raise exception.InstanceNotReady(instance_id=instance.uuid)
4933 
4934         return connect_info
4935 
4936     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4937                                    exception.InstanceNotReady,
4938                                    exception.InstanceNotFound,
4939                                    exception.ConsoleTypeUnavailable,
4940                                    NotImplementedError)
4941     @wrap_exception()
4942     @wrap_instance_fault
4943     def get_spice_console(self, context, console_type, instance):
4944         """Return connection information for a spice console."""
4945         context = context.elevated()
4946         LOG.debug("Getting spice console", instance=instance)
4947         token = uuidutils.generate_uuid()
4948 
4949         if not CONF.spice.enabled:
4950             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4951 
4952         if console_type == 'spice-html5':
4953             # For essex, spicehtml5proxy_base_url must include the full path
4954             # including the html file (like http://myhost/spice_auto.html)
4955             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
4956                                           token)
4957         else:
4958             raise exception.ConsoleTypeInvalid(console_type=console_type)
4959 
4960         try:
4961             # Retrieve connect info from driver, and then decorate with our
4962             # access info token
4963             console = self.driver.get_spice_console(context, instance)
4964             connect_info = console.get_connection_info(token, access_url)
4965         except exception.InstanceNotFound:
4966             if instance.vm_state != vm_states.BUILDING:
4967                 raise
4968             raise exception.InstanceNotReady(instance_id=instance.uuid)
4969 
4970         return connect_info
4971 
4972     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4973                                    exception.InstanceNotReady,
4974                                    exception.InstanceNotFound,
4975                                    exception.ConsoleTypeUnavailable,
4976                                    NotImplementedError)
4977     @wrap_exception()
4978     @wrap_instance_fault
4979     def get_rdp_console(self, context, console_type, instance):
4980         """Return connection information for a RDP console."""
4981         context = context.elevated()
4982         LOG.debug("Getting RDP console", instance=instance)
4983         token = uuidutils.generate_uuid()
4984 
4985         if not CONF.rdp.enabled:
4986             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4987 
4988         if console_type == 'rdp-html5':
4989             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
4990                                           token)
4991         else:
4992             raise exception.ConsoleTypeInvalid(console_type=console_type)
4993 
4994         try:
4995             # Retrieve connect info from driver, and then decorate with our
4996             # access info token
4997             console = self.driver.get_rdp_console(context, instance)
4998             connect_info = console.get_connection_info(token, access_url)
4999         except exception.InstanceNotFound:
5000             if instance.vm_state != vm_states.BUILDING:
5001                 raise
5002             raise exception.InstanceNotReady(instance_id=instance.uuid)
5003 
5004         return connect_info
5005 
5006     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5007                                    exception.InstanceNotReady,
5008                                    exception.InstanceNotFound,
5009                                    exception.ConsoleTypeUnavailable,
5010                                    NotImplementedError)
5011     @wrap_exception()
5012     @wrap_instance_fault
5013     def get_mks_console(self, context, console_type, instance):
5014         """Return connection information for a MKS console."""
5015         context = context.elevated()
5016         LOG.debug("Getting MKS console", instance=instance)
5017         token = uuidutils.generate_uuid()
5018 
5019         if not CONF.mks.enabled:
5020             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5021 
5022         if console_type == 'webmks':
5023             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
5024                                           token)
5025         else:
5026             raise exception.ConsoleTypeInvalid(console_type=console_type)
5027 
5028         try:
5029             # Retrieve connect info from driver, and then decorate with our
5030             # access info token
5031             console = self.driver.get_mks_console(context, instance)
5032             connect_info = console.get_connection_info(token, access_url)
5033         except exception.InstanceNotFound:
5034             if instance.vm_state != vm_states.BUILDING:
5035                 raise
5036             raise exception.InstanceNotReady(instance_id=instance.uuid)
5037 
5038         return connect_info
5039 
5040     @messaging.expected_exceptions(
5041         exception.ConsoleTypeInvalid,
5042         exception.InstanceNotReady,
5043         exception.InstanceNotFound,
5044         exception.ConsoleTypeUnavailable,
5045         exception.SocketPortRangeExhaustedException,
5046         exception.ImageSerialPortNumberInvalid,
5047         exception.ImageSerialPortNumberExceedFlavorValue,
5048         NotImplementedError)
5049     @wrap_exception()
5050     @wrap_instance_fault
5051     def get_serial_console(self, context, console_type, instance):
5052         """Returns connection information for a serial console."""
5053 
5054         LOG.debug("Getting serial console", instance=instance)
5055 
5056         if not CONF.serial_console.enabled:
5057             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5058 
5059         context = context.elevated()
5060 
5061         token = uuidutils.generate_uuid()
5062         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
5063 
5064         try:
5065             # Retrieve connect info from driver, and then decorate with our
5066             # access info token
5067             console = self.driver.get_serial_console(context, instance)
5068             connect_info = console.get_connection_info(token, access_url)
5069         except exception.InstanceNotFound:
5070             if instance.vm_state != vm_states.BUILDING:
5071                 raise
5072             raise exception.InstanceNotReady(instance_id=instance.uuid)
5073 
5074         return connect_info
5075 
5076     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5077                                    exception.InstanceNotReady,
5078                                    exception.InstanceNotFound)
5079     @wrap_exception()
5080     @wrap_instance_fault
5081     def validate_console_port(self, ctxt, instance, port, console_type):
5082         if console_type == "spice-html5":
5083             console_info = self.driver.get_spice_console(ctxt, instance)
5084         elif console_type == "rdp-html5":
5085             console_info = self.driver.get_rdp_console(ctxt, instance)
5086         elif console_type == "serial":
5087             console_info = self.driver.get_serial_console(ctxt, instance)
5088         elif console_type == "webmks":
5089             console_info = self.driver.get_mks_console(ctxt, instance)
5090         else:
5091             console_info = self.driver.get_vnc_console(ctxt, instance)
5092 
5093         return console_info.port == port
5094 
5095     @wrap_exception()
5096     @reverts_task_state
5097     @wrap_instance_fault
5098     def reserve_block_device_name(self, context, instance, device,
5099                                   volume_id, disk_bus, device_type, tag=None):
5100         if (tag and not
5101                 self.driver.capabilities.get('supports_tagged_attach_volume',
5102                                              False)):
5103             raise exception.VolumeTaggedAttachNotSupported()
5104 
5105         @utils.synchronized(instance.uuid)
5106         def do_reserve():
5107             bdms = (
5108                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5109                     context, instance.uuid))
5110 
5111             # NOTE(ndipanov): We need to explicitly set all the fields on the
5112             #                 object so that obj_load_attr does not fail
5113             new_bdm = objects.BlockDeviceMapping(
5114                     context=context,
5115                     source_type='volume', destination_type='volume',
5116                     instance_uuid=instance.uuid, boot_index=None,
5117                     volume_id=volume_id,
5118                     device_name=device, guest_format=None,
5119                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5120 
5121             new_bdm.device_name = self._get_device_name_for_instance(
5122                     instance, bdms, new_bdm)
5123 
5124             # NOTE(vish): create bdm here to avoid race condition
5125             new_bdm.create()
5126             return new_bdm
5127 
5128         return do_reserve()
5129 
5130     @wrap_exception()
5131     @wrap_instance_event(prefix='compute')
5132     @wrap_instance_fault
5133     def attach_volume(self, context, instance, bdm):
5134         """Attach a volume to an instance."""
5135         driver_bdm = driver_block_device.convert_volume(bdm)
5136 
5137         @utils.synchronized(instance.uuid)
5138         def do_attach_volume(context, instance, driver_bdm):
5139             try:
5140                 return self._attach_volume(context, instance, driver_bdm)
5141             except Exception:
5142                 with excutils.save_and_reraise_exception():
5143                     bdm.destroy()
5144 
5145         do_attach_volume(context, instance, driver_bdm)
5146 
5147     def _attach_volume(self, context, instance, bdm):
5148         context = context.elevated()
5149         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5150                  {'volume_id': bdm.volume_id,
5151                   'mountpoint': bdm['mount_device']},
5152                  instance=instance)
5153         compute_utils.notify_about_volume_attach_detach(
5154             context, instance, self.host,
5155             action=fields.NotificationAction.VOLUME_ATTACH,
5156             phase=fields.NotificationPhase.START,
5157             volume_id=bdm.volume_id)
5158         try:
5159             bdm.attach(context, instance, self.volume_api, self.driver,
5160                        do_driver_attach=True)
5161         except Exception as e:
5162             with excutils.save_and_reraise_exception():
5163                 LOG.exception("Failed to attach %(volume_id)s "
5164                               "at %(mountpoint)s",
5165                               {'volume_id': bdm.volume_id,
5166                                'mountpoint': bdm['mount_device']},
5167                               instance=instance)
5168                 if bdm['attachment_id']:
5169                     self.volume_api.attachment_delete(context,
5170                                                       bdm['attachment_id'])
5171                 else:
5172                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5173                 compute_utils.notify_about_volume_attach_detach(
5174                     context, instance, self.host,
5175                     action=fields.NotificationAction.VOLUME_ATTACH,
5176                     phase=fields.NotificationPhase.ERROR,
5177                     exception=e,
5178                     volume_id=bdm.volume_id)
5179 
5180         info = {'volume_id': bdm.volume_id}
5181         self._notify_about_instance_usage(
5182             context, instance, "volume.attach", extra_usage_info=info)
5183         compute_utils.notify_about_volume_attach_detach(
5184             context, instance, self.host,
5185             action=fields.NotificationAction.VOLUME_ATTACH,
5186             phase=fields.NotificationPhase.END,
5187             volume_id=bdm.volume_id)
5188 
5189     def _notify_volume_usage_detach(self, context, instance, bdm):
5190         if CONF.volume_usage_poll_interval <= 0:
5191             return
5192 
5193         vol_stats = []
5194         mp = bdm.device_name
5195         # Handle bootable volumes which will not contain /dev/
5196         if '/dev/' in mp:
5197             mp = mp[5:]
5198         try:
5199             vol_stats = self.driver.block_stats(instance, mp)
5200         except NotImplementedError:
5201             return
5202 
5203         LOG.debug("Updating volume usage cache with totals", instance=instance)
5204         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5205         vol_usage = objects.VolumeUsage(context)
5206         vol_usage.volume_id = bdm.volume_id
5207         vol_usage.instance_uuid = instance.uuid
5208         vol_usage.project_id = instance.project_id
5209         vol_usage.user_id = instance.user_id
5210         vol_usage.availability_zone = instance.availability_zone
5211         vol_usage.curr_reads = rd_req
5212         vol_usage.curr_read_bytes = rd_bytes
5213         vol_usage.curr_writes = wr_req
5214         vol_usage.curr_write_bytes = wr_bytes
5215         vol_usage.save(update_totals=True)
5216         self.notifier.info(context, 'volume.usage',
5217                            compute_utils.usage_volume_info(vol_usage))
5218 
5219     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5220                        attachment_id=None):
5221         """Detach a volume from an instance.
5222 
5223         :param context: security context
5224         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5225         :param instance: the Instance object to detach the volume from
5226         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5227                             as deleted. Disabling this is useful for operations
5228                             like rebuild, when we don't want to destroy BDM
5229         :param attachment_id: The volume attachment_id for the given instance
5230                               and volume.
5231         """
5232         volume_id = bdm.volume_id
5233         compute_utils.notify_about_volume_attach_detach(
5234             context, instance, self.host,
5235             action=fields.NotificationAction.VOLUME_DETACH,
5236             phase=fields.NotificationPhase.START,
5237             volume_id=volume_id)
5238 
5239         self._notify_volume_usage_detach(context, instance, bdm)
5240 
5241         LOG.info('Detaching volume %(volume_id)s',
5242                  {'volume_id': volume_id}, instance=instance)
5243 
5244         driver_bdm = driver_block_device.convert_volume(bdm)
5245         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5246                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5247 
5248         info = dict(volume_id=volume_id)
5249         self._notify_about_instance_usage(
5250             context, instance, "volume.detach", extra_usage_info=info)
5251         compute_utils.notify_about_volume_attach_detach(
5252             context, instance, self.host,
5253             action=fields.NotificationAction.VOLUME_DETACH,
5254             phase=fields.NotificationPhase.END,
5255             volume_id=volume_id)
5256 
5257         if 'tag' in bdm and bdm.tag:
5258             self._delete_disk_metadata(instance, bdm)
5259         if destroy_bdm:
5260             bdm.destroy()
5261 
5262     def _delete_disk_metadata(self, instance, bdm):
5263         for device in instance.device_metadata.devices:
5264             if isinstance(device, objects.DiskMetadata):
5265                 if 'serial' in device:
5266                     if device.serial == bdm.volume_id:
5267                         instance.device_metadata.devices.remove(device)
5268                         instance.save()
5269                         break
5270                 else:
5271                     # NOTE(artom) We log the entire device object because all
5272                     # fields are nullable and may not be set
5273                     LOG.warning('Unable to determine whether to clean up '
5274                                 'device metadata for disk %s', device,
5275                                 instance=instance)
5276 
5277     @wrap_exception()
5278     @wrap_instance_event(prefix='compute')
5279     @wrap_instance_fault
5280     def detach_volume(self, context, volume_id, instance, attachment_id=None):
5281         """Detach a volume from an instance.
5282 
5283         :param context: security context
5284         :param volume_id: the volume id
5285         :param instance: the Instance object to detach the volume from
5286         :param attachment_id: The volume attachment_id for the given instance
5287                               and volume.
5288 
5289         """
5290         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5291                 context, volume_id, instance.uuid)
5292         self._detach_volume(context, bdm, instance,
5293                             attachment_id=attachment_id)
5294 
5295     def _init_volume_connection(self, context, new_volume_id,
5296                                 old_volume_id, connector, bdm,
5297                                 new_attachment_id):
5298 
5299         if new_attachment_id is None:
5300             # We're dealing with an old-style attachment so initialize the
5301             # connection so we can get the connection_info.
5302             new_cinfo = self.volume_api.initialize_connection(context,
5303                                                               new_volume_id,
5304                                                               connector)
5305         else:
5306             # This is a new style attachment and the API created the new
5307             # volume attachment and passed the id to the compute over RPC.
5308             # At this point we need to update the new volume attachment with
5309             # the host connector, which will give us back the new attachment
5310             # connection_info.
5311             new_cinfo = self.volume_api.attachment_update(
5312                 context, new_attachment_id, connector)['connection_info']
5313 
5314         old_cinfo = jsonutils.loads(bdm['connection_info'])
5315         if old_cinfo and 'serial' not in old_cinfo:
5316             old_cinfo['serial'] = old_volume_id
5317         # NOTE(lyarwood): serial is not always present in the returned
5318         # connection_info so set it if it is missing as we do in
5319         # DriverVolumeBlockDevice.attach().
5320         if 'serial' not in new_cinfo:
5321             new_cinfo['serial'] = new_volume_id
5322         return (old_cinfo, new_cinfo)
5323 
5324     def _swap_volume(self, context, instance, bdm, connector,
5325                      old_volume_id, new_volume_id, resize_to,
5326                      new_attachment_id, is_cinder_migration):
5327         mountpoint = bdm['device_name']
5328         failed = False
5329         new_cinfo = None
5330         try:
5331             old_cinfo, new_cinfo = self._init_volume_connection(
5332                 context, new_volume_id, old_volume_id, connector,
5333                 bdm, new_attachment_id)
5334             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5335             # currently implementing swap_volume, will modify the contents of
5336             # new_cinfo when connect_volume is called. This is then saved to
5337             # the BDM in swap_volume for future use outside of this flow.
5338             LOG.debug("swap_volume: Calling driver volume swap with "
5339                       "connection infos: new: %(new_cinfo)s; "
5340                       "old: %(old_cinfo)s",
5341                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo},
5342                       instance=instance)
5343             self.driver.swap_volume(old_cinfo, new_cinfo, instance, mountpoint,
5344                                     resize_to)
5345             if new_attachment_id:
5346                 self.volume_api.attachment_complete(context, new_attachment_id)
5347             LOG.debug("swap_volume: Driver volume swap returned, new "
5348                       "connection_info is now : %(new_cinfo)s",
5349                       {'new_cinfo': new_cinfo})
5350         except Exception as ex:
5351             failed = True
5352             with excutils.save_and_reraise_exception():
5353                 compute_utils.notify_about_volume_swap(
5354                     context, instance, self.host,
5355                     fields.NotificationAction.VOLUME_SWAP,
5356                     fields.NotificationPhase.ERROR,
5357                     old_volume_id, new_volume_id, ex)
5358                 if new_cinfo:
5359                     msg = ("Failed to swap volume %(old_volume_id)s "
5360                            "for %(new_volume_id)s")
5361                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5362                                         'new_volume_id': new_volume_id},
5363                                   instance=instance)
5364                 else:
5365                     msg = ("Failed to connect to volume %(volume_id)s "
5366                            "with volume at %(mountpoint)s")
5367                     LOG.exception(msg, {'volume_id': new_volume_id,
5368                                         'mountpoint': bdm['device_name']},
5369                                   instance=instance)
5370 
5371                 # The API marked the volume as 'detaching' for the old volume
5372                 # so we need to roll that back so the volume goes back to
5373                 # 'in-use' state.
5374                 self.volume_api.roll_detaching(context, old_volume_id)
5375 
5376                 if new_attachment_id is None:
5377                     # The API reserved the new volume so it would be in
5378                     # 'attaching' status, so we need to unreserve it so it
5379                     # goes back to 'available' status.
5380                     self.volume_api.unreserve_volume(context, new_volume_id)
5381                 else:
5382                     # This is a new style attachment for the new volume, which
5383                     # was created in the API. We just need to delete it here
5384                     # to put the new volume back into 'available' status.
5385                     self.volume_api.attachment_delete(
5386                         context, new_attachment_id)
5387         finally:
5388             # TODO(mriedem): This finally block is terribly confusing and is
5389             # trying to do too much. We should consider removing the finally
5390             # block and move whatever needs to happen on success and failure
5391             # into the blocks above for clarity, even if it means a bit of
5392             # redundant code.
5393             conn_volume = new_volume_id if failed else old_volume_id
5394             if new_cinfo:
5395                 LOG.debug("swap_volume: removing Cinder connection "
5396                           "for volume %(volume)s", {'volume': conn_volume},
5397                           instance=instance)
5398                 if bdm.attachment_id is None:
5399                     # This is the pre-3.44 flow for new-style volume
5400                     # attachments so just terminate the connection.
5401                     self.volume_api.terminate_connection(context,
5402                                                          conn_volume,
5403                                                          connector)
5404                 else:
5405                     # This is a new style volume attachment. If we failed, then
5406                     # the new attachment was already deleted above in the
5407                     # exception block and we have nothing more to do here. If
5408                     # swap_volume was successful in the driver, then we need to
5409                     # "detach" the original attachment by deleting it.
5410                     if not failed:
5411                         self.volume_api.attachment_delete(
5412                             context, bdm.attachment_id)
5413 
5414             # Need to make some decisions based on whether this was
5415             # a Cinder initiated migration or not. The callback to
5416             # migration completion isn't needed in the case of a
5417             # nova initiated simple swap of two volume
5418             # "volume-update" call so skip that. The new attachment
5419             # scenarios will give us a new attachment record and
5420             # that's what we want.
5421             if bdm.attachment_id and not is_cinder_migration:
5422                 # we don't callback to cinder
5423                 comp_ret = {'save_volume_id': new_volume_id}
5424             else:
5425                 # NOTE(lyarwood): The following call to
5426                 # os-migrate-volume-completion returns a dict containing
5427                 # save_volume_id, this volume id has two possible values :
5428                 # 1. old_volume_id if we are migrating (retyping) volumes
5429                 # 2. new_volume_id if we are swapping between two existing
5430                 #    volumes
5431                 # This volume id is later used to update the volume_id and
5432                 # connection_info['serial'] of the BDM.
5433                 comp_ret = self.volume_api.migrate_volume_completion(
5434                                                           context,
5435                                                           old_volume_id,
5436                                                           new_volume_id,
5437                                                           error=failed)
5438                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5439                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5440                           instance=instance)
5441 
5442         return (comp_ret, new_cinfo)
5443 
5444     @wrap_exception()
5445     @wrap_instance_event(prefix='compute')
5446     @wrap_instance_fault
5447     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
5448                     new_attachment_id=None):
5449         """Swap volume for an instance."""
5450         context = context.elevated()
5451 
5452         compute_utils.notify_about_volume_swap(
5453             context, instance, self.host,
5454             fields.NotificationAction.VOLUME_SWAP,
5455             fields.NotificationPhase.START,
5456             old_volume_id, new_volume_id)
5457 
5458         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5459                 context, old_volume_id, instance.uuid)
5460         connector = self.driver.get_volume_connector(instance)
5461 
5462         resize_to = 0
5463         old_volume = self.volume_api.get(context, old_volume_id)
5464         # Yes this is a tightly-coupled state check of what's going on inside
5465         # cinder, but we need this while we still support old (v1/v2) and
5466         # new style attachments (v3.44). Once we drop support for old style
5467         # attachments we could think about cleaning up the cinder-initiated
5468         # swap volume API flows.
5469         is_cinder_migration = (
5470             True if old_volume['status'] in ('retyping',
5471                                              'migrating') else False)
5472         old_vol_size = old_volume['size']
5473         new_vol_size = self.volume_api.get(context, new_volume_id)['size']
5474         if new_vol_size > old_vol_size:
5475             resize_to = new_vol_size
5476 
5477         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5478                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5479                  instance=instance)
5480         comp_ret, new_cinfo = self._swap_volume(context,
5481                                                 instance,
5482                                                 bdm,
5483                                                 connector,
5484                                                 old_volume_id,
5485                                                 new_volume_id,
5486                                                 resize_to,
5487                                                 new_attachment_id,
5488                                                 is_cinder_migration)
5489 
5490         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5491         # correct volume_id returned by Cinder.
5492         save_volume_id = comp_ret['save_volume_id']
5493         new_cinfo['serial'] = save_volume_id
5494         values = {
5495             'connection_info': jsonutils.dumps(new_cinfo),
5496             'source_type': 'volume',
5497             'destination_type': 'volume',
5498             'snapshot_id': None,
5499             'volume_id': save_volume_id,
5500             'no_device': None}
5501 
5502         if resize_to:
5503             values['volume_size'] = resize_to
5504 
5505         if new_attachment_id is not None:
5506             # This was a volume swap for a new-style attachment so we
5507             # need to update the BDM attachment_id for the new attachment.
5508             values['attachment_id'] = new_attachment_id
5509 
5510         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5511                   "%(updates)s", {'volume_id': bdm.volume_id,
5512                                   'updates': values},
5513                   instance=instance)
5514         bdm.update(values)
5515         bdm.save()
5516 
5517         compute_utils.notify_about_volume_swap(
5518             context, instance, self.host,
5519             fields.NotificationAction.VOLUME_SWAP,
5520             fields.NotificationPhase.END,
5521             old_volume_id, new_volume_id)
5522 
5523     @wrap_exception()
5524     def remove_volume_connection(self, context, volume_id, instance):
5525         """Remove the volume connection on this host
5526 
5527         Detach the volume from this instance on this host, and if this is
5528         the cinder v2 flow, call cinder to terminate the connection.
5529         """
5530         try:
5531             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5532                     context, volume_id, instance.uuid)
5533             driver_bdm = driver_block_device.convert_volume(bdm)
5534             driver_bdm.driver_detach(context, instance,
5535                                      self.volume_api, self.driver)
5536             if bdm.attachment_id is None:
5537                 # cinder v2 api flow
5538                 connector = self.driver.get_volume_connector(instance)
5539                 self.volume_api.terminate_connection(context, volume_id,
5540                                                      connector)
5541         except exception.NotFound:
5542             pass
5543 
5544     @wrap_exception()
5545     @wrap_instance_event(prefix='compute')
5546     @wrap_instance_fault
5547     def attach_interface(self, context, instance, network_id, port_id,
5548                          requested_ip, tag=None):
5549         """Use hotplug to add an network adapter to an instance."""
5550         if not self.driver.capabilities['supports_attach_interface']:
5551             raise exception.AttachInterfaceNotSupported(
5552                 instance_uuid=instance.uuid)
5553         if (tag and not
5554             self.driver.capabilities.get('supports_tagged_attach_interface',
5555                                          False)):
5556             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5557 
5558         compute_utils.notify_about_instance_action(
5559             context, instance, self.host,
5560             action=fields.NotificationAction.INTERFACE_ATTACH,
5561             phase=fields.NotificationPhase.START)
5562 
5563         bind_host_id = self.driver.network_binding_host_id(context, instance)
5564         network_info = self.network_api.allocate_port_for_instance(
5565             context, instance, port_id, network_id, requested_ip,
5566             bind_host_id=bind_host_id, tag=tag)
5567         if len(network_info) != 1:
5568             LOG.error('allocate_port_for_instance returned %(ports)s '
5569                       'ports', {'ports': len(network_info)})
5570             # TODO(elod.illes): an instance.interface_attach.error notification
5571             # should be sent here
5572             raise exception.InterfaceAttachFailed(
5573                     instance_uuid=instance.uuid)
5574         image_meta = objects.ImageMeta.from_instance(instance)
5575 
5576         try:
5577             self.driver.attach_interface(context, instance, image_meta,
5578                                          network_info[0])
5579         except exception.NovaException as ex:
5580             port_id = network_info[0].get('id')
5581             LOG.warning("attach interface failed , try to deallocate "
5582                         "port %(port_id)s, reason: %(msg)s",
5583                         {'port_id': port_id, 'msg': ex},
5584                         instance=instance)
5585             try:
5586                 self.network_api.deallocate_port_for_instance(
5587                     context, instance, port_id)
5588             except Exception:
5589                 LOG.warning("deallocate port %(port_id)s failed",
5590                             {'port_id': port_id}, instance=instance)
5591 
5592             compute_utils.notify_about_instance_action(
5593                 context, instance, self.host,
5594                 action=fields.NotificationAction.INTERFACE_ATTACH,
5595                 phase=fields.NotificationPhase.ERROR,
5596                 exception=ex)
5597 
5598             raise exception.InterfaceAttachFailed(
5599                 instance_uuid=instance.uuid)
5600 
5601         compute_utils.notify_about_instance_action(
5602             context, instance, self.host,
5603             action=fields.NotificationAction.INTERFACE_ATTACH,
5604             phase=fields.NotificationPhase.END)
5605 
5606         return network_info[0]
5607 
5608     @wrap_exception()
5609     @wrap_instance_event(prefix='compute')
5610     @wrap_instance_fault
5611     def detach_interface(self, context, instance, port_id):
5612         """Detach a network adapter from an instance."""
5613         network_info = instance.info_cache.network_info
5614         condemned = None
5615         for vif in network_info:
5616             if vif['id'] == port_id:
5617                 condemned = vif
5618                 break
5619         if condemned is None:
5620             raise exception.PortNotFound(_("Port %s is not "
5621                                            "attached") % port_id)
5622 
5623         compute_utils.notify_about_instance_action(
5624             context, instance, self.host,
5625             action=fields.NotificationAction.INTERFACE_DETACH,
5626             phase=fields.NotificationPhase.START)
5627 
5628         try:
5629             self.driver.detach_interface(context, instance, condemned)
5630         except exception.NovaException as ex:
5631             LOG.warning("Detach interface failed, port_id=%(port_id)s,"
5632                         " reason: %(msg)s",
5633                         {'port_id': port_id, 'msg': ex}, instance=instance)
5634             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5635         else:
5636             try:
5637                 self.network_api.deallocate_port_for_instance(
5638                     context, instance, port_id)
5639             except Exception as ex:
5640                 with excutils.save_and_reraise_exception():
5641                     # Since this is a cast operation, log the failure for
5642                     # triage.
5643                     LOG.warning('Failed to deallocate port %(port_id)s '
5644                                 'for instance. Error: %(error)s',
5645                                 {'port_id': port_id, 'error': ex},
5646                                 instance=instance)
5647 
5648         compute_utils.notify_about_instance_action(
5649             context, instance, self.host,
5650             action=fields.NotificationAction.INTERFACE_DETACH,
5651             phase=fields.NotificationPhase.END)
5652 
5653     def _get_compute_info(self, context, host):
5654         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5655             context, host)
5656 
5657     @wrap_exception()
5658     def check_instance_shared_storage(self, ctxt, instance, data):
5659         """Check if the instance files are shared
5660 
5661         :param ctxt: security context
5662         :param instance: dict of instance data
5663         :param data: result of driver.check_instance_shared_storage_local
5664 
5665         Returns True if instance disks located on shared storage and
5666         False otherwise.
5667         """
5668         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5669 
5670     @wrap_exception()
5671     @wrap_instance_event(prefix='compute')
5672     @wrap_instance_fault
5673     def check_can_live_migrate_destination(self, ctxt, instance,
5674                                            block_migration, disk_over_commit):
5675         """Check if it is possible to execute live migration.
5676 
5677         This runs checks on the destination host, and then calls
5678         back to the source host to check the results.
5679 
5680         :param context: security context
5681         :param instance: dict of instance data
5682         :param block_migration: if true, prepare for block migration
5683                                 if None, calculate it in driver
5684         :param disk_over_commit: if true, allow disk over commit
5685                                  if None, ignore disk usage checking
5686         :returns: a dict containing migration info
5687         """
5688         return self._do_check_can_live_migrate_destination(ctxt, instance,
5689                                                             block_migration,
5690                                                             disk_over_commit)
5691 
5692     def _do_check_can_live_migrate_destination(self, ctxt, instance,
5693                                                block_migration,
5694                                                disk_over_commit):
5695         src_compute_info = obj_base.obj_to_primitive(
5696             self._get_compute_info(ctxt, instance.host))
5697         dst_compute_info = obj_base.obj_to_primitive(
5698             self._get_compute_info(ctxt, CONF.host))
5699         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5700             instance, src_compute_info, dst_compute_info,
5701             block_migration, disk_over_commit)
5702         LOG.debug('destination check data is %s', dest_check_data)
5703         try:
5704             migrate_data = self.compute_rpcapi.\
5705                                 check_can_live_migrate_source(ctxt, instance,
5706                                                               dest_check_data)
5707         finally:
5708             self.driver.cleanup_live_migration_destination_check(ctxt,
5709                     dest_check_data)
5710         return migrate_data
5711 
5712     @wrap_exception()
5713     @wrap_instance_event(prefix='compute')
5714     @wrap_instance_fault
5715     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5716         """Check if it is possible to execute live migration.
5717 
5718         This checks if the live migration can succeed, based on the
5719         results from check_can_live_migrate_destination.
5720 
5721         :param ctxt: security context
5722         :param instance: dict of instance data
5723         :param dest_check_data: result of check_can_live_migrate_destination
5724         :returns: a dict containing migration info
5725         """
5726         is_volume_backed = compute_utils.is_volume_backed_instance(ctxt,
5727                                                                       instance)
5728         # TODO(tdurakov): remove dict to object conversion once RPC API version
5729         # is bumped to 5.x
5730         got_migrate_data_object = isinstance(dest_check_data,
5731                                              migrate_data_obj.LiveMigrateData)
5732         if not got_migrate_data_object:
5733             dest_check_data = \
5734                 migrate_data_obj.LiveMigrateData.detect_implementation(
5735                     dest_check_data)
5736         dest_check_data.is_volume_backed = is_volume_backed
5737         block_device_info = self._get_instance_block_device_info(
5738                             ctxt, instance, refresh_conn_info=False)
5739         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5740                                                            dest_check_data,
5741                                                            block_device_info)
5742         if not got_migrate_data_object:
5743             result = result.to_legacy_dict()
5744         LOG.debug('source check data is %s', result)
5745         return result
5746 
5747     @wrap_exception()
5748     @wrap_instance_event(prefix='compute')
5749     @wrap_instance_fault
5750     def pre_live_migration(self, context, instance, block_migration, disk,
5751                            migrate_data):
5752         """Preparations for live migration at dest host.
5753 
5754         :param context: security context
5755         :param instance: dict of instance data
5756         :param block_migration: if true, prepare for block migration
5757         :param disk: disk info of instance
5758         :param migrate_data: A dict or LiveMigrateData object holding data
5759                              required for live migration without shared
5760                              storage.
5761         :returns: migrate_data containing additional migration info
5762         """
5763         LOG.debug('pre_live_migration data is %s', migrate_data)
5764         # TODO(tdurakov): remove dict to object conversion once RPC API version
5765         # is bumped to 5.x
5766         got_migrate_data_object = isinstance(migrate_data,
5767                                              migrate_data_obj.LiveMigrateData)
5768         if not got_migrate_data_object:
5769             migrate_data = \
5770                 migrate_data_obj.LiveMigrateData.detect_implementation(
5771                     migrate_data)
5772 
5773         migrate_data.old_vol_attachment_ids = {}
5774         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5775             context, instance.uuid)
5776         try:
5777             connector = self.driver.get_volume_connector(instance)
5778             for bdm in bdms:
5779                 if bdm.is_volume and bdm.attachment_id is not None:
5780                     # This bdm uses the new cinder v3.44 API.
5781                     # We will create a new attachment for this
5782                     # volume on this migration destination host. The old
5783                     # attachment will be deleted on the source host
5784                     # when the migration succeeds. The old attachment_id
5785                     # is stored in dict with the key being the bdm.volume_id
5786                     # so it can be restored on rollback.
5787                     #
5788                     # Also note that attachment_update is not needed as we
5789                     # are providing the connector in the create call.
5790                     attach_ref = self.volume_api.attachment_create(
5791                         context, bdm.volume_id, bdm.instance_uuid,
5792                         connector=connector)
5793 
5794                     # save current attachment so we can detach it on success,
5795                     # or restore it on a rollback.
5796                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
5797                         bdm.attachment_id
5798 
5799                     # update the bdm with the new attachment_id.
5800                     bdm.attachment_id = attach_ref['id']
5801                     bdm.save()
5802         except Exception:
5803             # If we raise, migrate_data with the updated attachment ids
5804             # will not be returned to the source host for rollback.
5805             # So we need to rollback new attachments here.
5806             with excutils.save_and_reraise_exception():
5807                 old_attachments = migrate_data.old_vol_attachment_ids
5808                 for bdm in bdms:
5809                     if (bdm.is_volume and bdm.attachment_id is not None and
5810                             bdm.volume_id in old_attachments):
5811                         self.volume_api.attachment_delete(context,
5812                                                           bdm.attachment_id)
5813                         bdm.attachment_id = old_attachments[bdm.volume_id]
5814                         bdm.save()
5815 
5816         block_device_info = self._get_instance_block_device_info(
5817                             context, instance, refresh_conn_info=True,
5818                             bdms=bdms)
5819 
5820         network_info = self.network_api.get_instance_nw_info(context, instance)
5821         self._notify_about_instance_usage(
5822                      context, instance, "live_migration.pre.start",
5823                      network_info=network_info)
5824         compute_utils.notify_about_instance_action(
5825             context, instance, self.host,
5826             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
5827             phase=fields.NotificationPhase.START)
5828 
5829         migrate_data = self.driver.pre_live_migration(context,
5830                                        instance,
5831                                        block_device_info,
5832                                        network_info,
5833                                        disk,
5834                                        migrate_data)
5835         LOG.debug('driver pre_live_migration data is %s', migrate_data)
5836 
5837         # Volume connections are complete, tell cinder that all the
5838         # attachments have completed.
5839         for bdm in bdms:
5840             if bdm.is_volume and bdm.attachment_id is not None:
5841                 self.volume_api.attachment_complete(context,
5842                                                     bdm.attachment_id)
5843 
5844         # NOTE(tr3buchet): setup networks on destination host
5845         self.network_api.setup_networks_on_host(context, instance,
5846                                                          self.host)
5847 
5848         # Creating filters to hypervisors and firewalls.
5849         # An example is that nova-instance-instance-xxx,
5850         # which is written to libvirt.xml(Check "virsh nwfilter-list")
5851         # This nwfilter is necessary on the destination host.
5852         # In addition, this method is creating filtering rule
5853         # onto destination host.
5854         self.driver.ensure_filtering_rules_for_instance(instance,
5855                                             network_info)
5856 
5857         self._notify_about_instance_usage(
5858                      context, instance, "live_migration.pre.end",
5859                      network_info=network_info)
5860         compute_utils.notify_about_instance_action(
5861             context, instance, self.host,
5862             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
5863             phase=fields.NotificationPhase.END)
5864 
5865         # TODO(tdurakov): remove dict to object conversion once RPC API version
5866         # is bumped to 5.x
5867         if not got_migrate_data_object and migrate_data:
5868             migrate_data = migrate_data.to_legacy_dict(
5869                 pre_migration_result=True)
5870             migrate_data = migrate_data['pre_live_migration_result']
5871         LOG.debug('pre_live_migration result data is %s', migrate_data)
5872         return migrate_data
5873 
5874     def _do_live_migration(self, context, dest, instance, block_migration,
5875                            migration, migrate_data):
5876         # NOTE(danms): We should enhance the RT to account for migrations
5877         # and use the status field to denote when the accounting has been
5878         # done on source/destination. For now, this is just here for status
5879         # reporting
5880         self._set_migration_status(migration, 'preparing')
5881 
5882         got_migrate_data_object = isinstance(migrate_data,
5883                                              migrate_data_obj.LiveMigrateData)
5884         if not got_migrate_data_object:
5885             migrate_data = \
5886                 migrate_data_obj.LiveMigrateData.detect_implementation(
5887                     migrate_data)
5888 
5889         try:
5890             if ('block_migration' in migrate_data and
5891                     migrate_data.block_migration):
5892                 block_device_info = self._get_instance_block_device_info(
5893                     context, instance)
5894                 disk = self.driver.get_instance_disk_info(
5895                     instance, block_device_info=block_device_info)
5896             else:
5897                 disk = None
5898 
5899             migrate_data = self.compute_rpcapi.pre_live_migration(
5900                 context, instance,
5901                 block_migration, disk, dest, migrate_data)
5902         except Exception:
5903             with excutils.save_and_reraise_exception():
5904                 LOG.exception('Pre live migration failed at %s',
5905                               dest, instance=instance)
5906                 self._set_migration_status(migration, 'error')
5907                 # Make sure we set this for _rollback_live_migration()
5908                 # so it can find it, as expected if it was called later
5909                 migrate_data.migration = migration
5910                 self._rollback_live_migration(context, instance, dest,
5911                                               migrate_data)
5912 
5913         self._set_migration_status(migration, 'running')
5914 
5915         if migrate_data:
5916             migrate_data.migration = migration
5917         LOG.debug('live_migration data is %s', migrate_data)
5918         try:
5919             self.driver.live_migration(context, instance, dest,
5920                                        self._post_live_migration,
5921                                        self._rollback_live_migration,
5922                                        block_migration, migrate_data)
5923         except Exception:
5924             LOG.exception('Live migration failed.', instance=instance)
5925             with excutils.save_and_reraise_exception():
5926                 # Put instance and migration into error state,
5927                 # as its almost certainly too late to rollback
5928                 self._set_migration_status(migration, 'error')
5929                 # first refresh instance as it may have got updated by
5930                 # post_live_migration_at_destination
5931                 instance.refresh()
5932                 self._set_instance_obj_error_state(context, instance,
5933                                                    clean_task_state=True)
5934 
5935     @wrap_exception()
5936     @wrap_instance_event(prefix='compute')
5937     @wrap_instance_fault
5938     def live_migration(self, context, dest, instance, block_migration,
5939                        migration, migrate_data):
5940         """Executing live migration.
5941 
5942         :param context: security context
5943         :param dest: destination host
5944         :param instance: a nova.objects.instance.Instance object
5945         :param block_migration: if true, prepare for block migration
5946         :param migration: an nova.objects.Migration object
5947         :param migrate_data: implementation specific params
5948 
5949         """
5950         self._set_migration_status(migration, 'queued')
5951 
5952         def dispatch_live_migration(*args, **kwargs):
5953             with self._live_migration_semaphore:
5954                 self._do_live_migration(*args, **kwargs)
5955 
5956         # NOTE(danms): We spawn here to return the RPC worker thread back to
5957         # the pool. Since what follows could take a really long time, we don't
5958         # want to tie up RPC workers.
5959         utils.spawn_n(dispatch_live_migration,
5960                       context, dest, instance,
5961                       block_migration, migration,
5962                       migrate_data)
5963 
5964     # TODO(tdurakov): migration_id is used since 4.12 rpc api version
5965     # remove migration_id parameter when the compute RPC version
5966     # is bumped to 5.x.
5967     @wrap_exception()
5968     @wrap_instance_event(prefix='compute')
5969     @wrap_instance_fault
5970     def live_migration_force_complete(self, context, instance,
5971                                       migration_id=None):
5972         """Force live migration to complete.
5973 
5974         :param context: Security context
5975         :param instance: The instance that is being migrated
5976         :param migration_id: ID of ongoing migration; is currently not used,
5977         and isn't removed for backward compatibility
5978         """
5979 
5980         self._notify_about_instance_usage(
5981             context, instance, 'live.migration.force.complete.start')
5982         self.driver.live_migration_force_complete(instance)
5983         self._notify_about_instance_usage(
5984             context, instance, 'live.migration.force.complete.end')
5985 
5986     @wrap_exception()
5987     @wrap_instance_event(prefix='compute')
5988     @wrap_instance_fault
5989     def live_migration_abort(self, context, instance, migration_id):
5990         """Abort an in-progress live migration.
5991 
5992         :param context: Security context
5993         :param instance: The instance that is being migrated
5994         :param migration_id: ID of in-progress live migration
5995 
5996         """
5997         migration = objects.Migration.get_by_id(context, migration_id)
5998         if migration.status != 'running':
5999             raise exception.InvalidMigrationState(migration_id=migration_id,
6000                     instance_uuid=instance.uuid,
6001                     state=migration.status,
6002                     method='abort live migration')
6003 
6004         self._notify_about_instance_usage(
6005             context, instance, 'live.migration.abort.start')
6006         compute_utils.notify_about_instance_action(
6007             context, instance, self.host,
6008             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6009             phase=fields.NotificationPhase.START)
6010         self.driver.live_migration_abort(instance)
6011         self._notify_about_instance_usage(
6012             context, instance, 'live.migration.abort.end')
6013         compute_utils.notify_about_instance_action(
6014             context, instance, self.host,
6015             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6016             phase=fields.NotificationPhase.END)
6017 
6018     def _live_migration_cleanup_flags(self, migrate_data):
6019         """Determine whether disks or instance path need to be cleaned up after
6020         live migration (at source on success, at destination on rollback)
6021 
6022         Block migration needs empty image at destination host before migration
6023         starts, so if any failure occurs, any empty images has to be deleted.
6024 
6025         Also Volume backed live migration w/o shared storage needs to delete
6026         newly created instance-xxx dir on the destination as a part of its
6027         rollback process
6028 
6029         :param migrate_data: implementation specific data
6030         :returns: (bool, bool) -- do_cleanup, destroy_disks
6031         """
6032         # NOTE(pkoniszewski): block migration specific params are set inside
6033         # migrate_data objects for drivers that expose block live migration
6034         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6035         # cleanup is not needed.
6036         is_shared_block_storage = True
6037         is_shared_instance_path = True
6038         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6039             is_shared_block_storage = migrate_data.is_shared_block_storage
6040             is_shared_instance_path = migrate_data.is_shared_instance_path
6041         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6042             is_shared_block_storage = not migrate_data.block_migration
6043             is_shared_instance_path = not migrate_data.block_migration
6044         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6045             is_shared_instance_path = migrate_data.is_shared_instance_path
6046             is_shared_block_storage = migrate_data.is_shared_instance_path
6047 
6048         # No instance booting at source host, but instance dir
6049         # must be deleted for preparing next block migration
6050         # must be deleted for preparing next live migration w/o shared storage
6051         do_cleanup = not is_shared_instance_path
6052         destroy_disks = not is_shared_block_storage
6053 
6054         return (do_cleanup, destroy_disks)
6055 
6056     @wrap_exception()
6057     @wrap_instance_fault
6058     def _post_live_migration(self, ctxt, instance,
6059                             dest, block_migration=False, migrate_data=None):
6060         """Post operations for live migration.
6061 
6062         This method is called from live_migration
6063         and mainly updating database record.
6064 
6065         :param ctxt: security context
6066         :param instance: instance dict
6067         :param dest: destination host
6068         :param block_migration: if true, prepare for block migration
6069         :param migrate_data: if not None, it is a dict which has data
6070         required for live migration without shared storage
6071 
6072         """
6073         LOG.info('_post_live_migration() is started..',
6074                  instance=instance)
6075 
6076         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6077                 ctxt, instance.uuid)
6078 
6079         # Cleanup source host post live-migration
6080         block_device_info = self._get_instance_block_device_info(
6081                             ctxt, instance, bdms=bdms)
6082         self.driver.post_live_migration(ctxt, instance, block_device_info,
6083                                         migrate_data)
6084 
6085         # Detaching volumes.
6086         connector = self.driver.get_volume_connector(instance)
6087         for bdm in bdms:
6088             if bdm.is_volume:
6089                 if bdm.attachment_id is None:
6090                     # Prior to cinder v3.44:
6091                     # We don't want to actually mark the volume detached, or
6092                     # delete the bdm, just remove the connection from this
6093                     # host.
6094                     #
6095                     # remove the volume connection without detaching from
6096                     # hypervisor because the instance is not running anymore
6097                     # on the current host
6098                     self.volume_api.terminate_connection(ctxt, bdm.volume_id,
6099                                                          connector)
6100                 else:
6101                     # cinder v3.44 api flow - delete the old attachment
6102                     # for the source host
6103                     old_attachment_id = \
6104                         migrate_data.old_vol_attachment_ids[bdm.volume_id]
6105                     self.volume_api.attachment_delete(ctxt, old_attachment_id)
6106 
6107         # Releasing vlan.
6108         # (not necessary in current implementation?)
6109 
6110         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
6111 
6112         self._notify_about_instance_usage(ctxt, instance,
6113                                           "live_migration._post.start",
6114                                           network_info=network_info)
6115         # Releasing security group ingress rule.
6116         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
6117                   instance=instance)
6118         self.driver.unfilter_instance(instance,
6119                                       network_info)
6120 
6121         migration = {'source_compute': self.host,
6122                      'dest_compute': dest, }
6123         self.network_api.migrate_instance_start(ctxt,
6124                                                 instance,
6125                                                 migration)
6126 
6127         destroy_vifs = False
6128         try:
6129             self.driver.post_live_migration_at_source(ctxt, instance,
6130                                                       network_info)
6131         except NotImplementedError as ex:
6132             LOG.debug(ex, instance=instance)
6133             # For all hypervisors other than libvirt, there is a possibility
6134             # they are unplugging networks from source node in the cleanup
6135             # method
6136             destroy_vifs = True
6137 
6138         # NOTE(danms): Save source node before calling post method on
6139         # destination, which will update it
6140         source_node = instance.node
6141 
6142         # Define domain at destination host, without doing it,
6143         # pause/suspend/terminate do not work.
6144         post_at_dest_success = True
6145         try:
6146             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
6147                     instance, block_migration, dest)
6148         except Exception as error:
6149             post_at_dest_success = False
6150             # We don't want to break _post_live_migration() if
6151             # post_live_migration_at_destination() fails as it should never
6152             # affect cleaning up source node.
6153             LOG.exception("Post live migration at destination %s failed",
6154                           dest, instance=instance, error=error)
6155 
6156         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6157                 migrate_data)
6158 
6159         if do_cleanup:
6160             LOG.debug('Calling driver.cleanup from _post_live_migration',
6161                       instance=instance)
6162             self.driver.cleanup(ctxt, instance, network_info,
6163                                 destroy_disks=destroy_disks,
6164                                 migrate_data=migrate_data,
6165                                 destroy_vifs=destroy_vifs)
6166 
6167         self.instance_events.clear_events_for_instance(instance)
6168 
6169         # NOTE(timello): make sure we update available resources on source
6170         # host even before next periodic task.
6171         self.update_available_resource(ctxt)
6172 
6173         self._update_scheduler_instance_info(ctxt, instance)
6174         self._notify_about_instance_usage(ctxt, instance,
6175                                           "live_migration._post.end",
6176                                           network_info=network_info)
6177         if post_at_dest_success:
6178             LOG.info('Migrating instance to %s finished successfully.',
6179                      dest, instance=instance)
6180 
6181         self._clean_instance_console_tokens(ctxt, instance)
6182         if migrate_data and migrate_data.obj_attr_is_set('migration'):
6183             migrate_data.migration.status = 'completed'
6184             migrate_data.migration.save()
6185             migration = migrate_data.migration
6186             rc = self.scheduler_client.reportclient
6187             # Check to see if our migration has its own allocations
6188             allocs = rc.get_allocations_for_consumer(migration.uuid)
6189         else:
6190             # We didn't have data on a migration, which means we can't
6191             # look up to see if we had new-style migration-based
6192             # allocations. This should really only happen in cases of
6193             # a buggy virt driver or some really old component in the
6194             # system. Log a warning so we know it happened.
6195             allocs = None
6196             LOG.warning('Live migration ended with no migrate_data '
6197                         'record. Unable to clean up migration-based '
6198                         'allocations which is almost certainly not '
6199                         'an expected situation.')
6200 
6201         if allocs:
6202             # We had a migration-based allocation that we need to handle
6203             self._delete_allocation_after_move(instance,
6204                                                migrate_data.migration,
6205                                                instance.flavor,
6206                                                source_node)
6207         else:
6208             # No migration-based allocations, so do the old thing and
6209             # attempt to clean up any doubled per-instance allocation
6210             rt = self._get_resource_tracker()
6211             rt.delete_allocation_for_migrated_instance(
6212                 instance, source_node)
6213 
6214     def _consoles_enabled(self):
6215         """Returns whether a console is enable."""
6216         return (CONF.vnc.enabled or CONF.spice.enabled or
6217                 CONF.rdp.enabled or CONF.serial_console.enabled or
6218                 CONF.mks.enabled)
6219 
6220     def _clean_instance_console_tokens(self, ctxt, instance):
6221         """Clean console tokens stored for an instance."""
6222         # If the database backend isn't in use, don't bother trying to clean
6223         # tokens.
6224         if CONF.cells.enable:
6225             return
6226         if self._consoles_enabled():
6227             obj_console_connection.ConsoleConnection.\
6228                 clean_console_auths_for_instance(ctxt, instance.uuid)
6229 
6230     @wrap_exception()
6231     @wrap_instance_event(prefix='compute')
6232     @wrap_instance_fault
6233     def post_live_migration_at_destination(self, context, instance,
6234                                            block_migration):
6235         """Post operations for live migration .
6236 
6237         :param context: security context
6238         :param instance: Instance dict
6239         :param block_migration: if true, prepare for block migration
6240 
6241         """
6242         LOG.info('Post operation of migration started',
6243                  instance=instance)
6244 
6245         # NOTE(tr3buchet): setup networks on destination host
6246         #                  this is called a second time because
6247         #                  multi_host does not create the bridge in
6248         #                  plug_vifs
6249         self.network_api.setup_networks_on_host(context, instance,
6250                                                          self.host)
6251         migration = {'source_compute': instance.host,
6252                      'dest_compute': self.host, }
6253         self.network_api.migrate_instance_finish(context,
6254                                                  instance,
6255                                                  migration)
6256 
6257         network_info = self.network_api.get_instance_nw_info(context, instance)
6258         self._notify_about_instance_usage(
6259                      context, instance, "live_migration.post.dest.start",
6260                      network_info=network_info)
6261         block_device_info = self._get_instance_block_device_info(context,
6262                                                                  instance)
6263 
6264         try:
6265             self.driver.post_live_migration_at_destination(
6266                 context, instance, network_info, block_migration,
6267                 block_device_info)
6268         except Exception:
6269             with excutils.save_and_reraise_exception():
6270                 instance.vm_state = vm_states.ERROR
6271                 LOG.error('Unexpected error during post live migration at '
6272                           'destination host.', instance=instance)
6273         finally:
6274             # Restore instance state and update host
6275             current_power_state = self._get_power_state(context, instance)
6276             node_name = None
6277             prev_host = instance.host
6278             try:
6279                 compute_node = self._get_compute_info(context, self.host)
6280                 node_name = compute_node.hypervisor_hostname
6281             except exception.ComputeHostNotFound:
6282                 LOG.exception('Failed to get compute_info for %s', self.host)
6283             finally:
6284                 instance.host = self.host
6285                 instance.power_state = current_power_state
6286                 instance.task_state = None
6287                 instance.node = node_name
6288                 instance.progress = 0
6289                 instance.save(expected_task_state=task_states.MIGRATING)
6290 
6291         # NOTE(tr3buchet): tear down networks on source host
6292         self.network_api.setup_networks_on_host(context, instance,
6293                                                 prev_host, teardown=True)
6294         # NOTE(vish): this is necessary to update dhcp
6295         self.network_api.setup_networks_on_host(context, instance, self.host)
6296         self._notify_about_instance_usage(
6297                      context, instance, "live_migration.post.dest.end",
6298                      network_info=network_info)
6299 
6300     @wrap_exception()
6301     @wrap_instance_fault
6302     def _rollback_live_migration(self, context, instance,
6303                                  dest, migrate_data=None,
6304                                  migration_status='error'):
6305         """Recovers Instance/volume state from migrating -> running.
6306 
6307         :param context: security context
6308         :param instance: nova.objects.instance.Instance object
6309         :param dest:
6310             This method is called from live migration src host.
6311             This param specifies destination host.
6312         :param migrate_data:
6313             if not none, contains implementation specific data.
6314         :param migration_status:
6315             Contains the status we want to set for the migration object
6316 
6317         """
6318         # TODO(tdurakov): remove dict to object conversion once RPC API version
6319         # is bumped to 5.x
6320         if isinstance(migrate_data, dict):
6321             migration = migrate_data.pop('migration', None)
6322             migrate_data = \
6323                 migrate_data_obj.LiveMigrateData.detect_implementation(
6324                     migrate_data)
6325         elif (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
6326               migrate_data.obj_attr_is_set('migration')):
6327             migration = migrate_data.migration
6328         else:
6329             migration = None
6330 
6331         if migration:
6332             # Remove allocations created in Placement for the dest node.
6333             # If migration is None, we must be so old we don't have placement,
6334             # so no need to do something else.
6335             self._revert_allocation(context, instance, migration)
6336         else:
6337             LOG.error('Unable to revert allocations during live migration '
6338                       'rollback; compute driver did not provide migrate_data',
6339                       instance=instance)
6340 
6341         instance.task_state = None
6342         instance.progress = 0
6343         instance.save(expected_task_state=[task_states.MIGRATING])
6344 
6345         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
6346         self.network_api.setup_networks_on_host(context, instance, self.host)
6347 
6348         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6349                 context, instance.uuid)
6350         for bdm in bdms:
6351             if bdm.is_volume:
6352                 # remove the connection on the destination host
6353                 self.compute_rpcapi.remove_volume_connection(
6354                         context, instance, bdm.volume_id, dest)
6355 
6356                 if bdm.attachment_id:
6357                     # 3.44 cinder api flow. Set the bdm's
6358                     # attachment_id to the old attachment of the source
6359                     # host. If old_attachments is not there, then
6360                     # there was an error before the new attachment was made.
6361                     old_attachments = migrate_data.old_vol_attachment_ids \
6362                         if 'old_vol_attachment_ids' in migrate_data else None
6363                     if old_attachments and bdm.volume_id in old_attachments:
6364                         self.volume_api.attachment_delete(context,
6365                                                           bdm.attachment_id)
6366                         bdm.attachment_id = old_attachments[bdm.volume_id]
6367                         bdm.save()
6368 
6369         self._notify_about_instance_usage(context, instance,
6370                                           "live_migration._rollback.start")
6371         compute_utils.notify_about_instance_action(context, instance,
6372                 self.host,
6373                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6374                 phase=fields.NotificationPhase.START,
6375                 bdms=bdms)
6376 
6377         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6378                 migrate_data)
6379 
6380         if do_cleanup:
6381             self.compute_rpcapi.rollback_live_migration_at_destination(
6382                     context, instance, dest, destroy_disks=destroy_disks,
6383                     migrate_data=migrate_data)
6384 
6385         self._notify_about_instance_usage(context, instance,
6386                                           "live_migration._rollback.end")
6387         compute_utils.notify_about_instance_action(context, instance,
6388 
6389                 self.host,
6390                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6391                 phase=fields.NotificationPhase.END,
6392                 bdms=bdms)
6393 
6394         self._set_migration_status(migration, migration_status)
6395 
6396     @wrap_exception()
6397     @wrap_instance_event(prefix='compute')
6398     @wrap_instance_fault
6399     def rollback_live_migration_at_destination(self, context, instance,
6400                                                destroy_disks,
6401                                                migrate_data):
6402         """Cleaning up image directory that is created pre_live_migration.
6403 
6404         :param context: security context
6405         :param instance: a nova.objects.instance.Instance object sent over rpc
6406         :param destroy_disks: whether to destroy volumes or not
6407         :param migrate_data: contains migration info
6408         """
6409         network_info = self.network_api.get_instance_nw_info(context, instance)
6410         self._notify_about_instance_usage(
6411                       context, instance, "live_migration.rollback.dest.start",
6412                       network_info=network_info)
6413         try:
6414             # NOTE(tr3buchet): tear down networks on destination host
6415             self.network_api.setup_networks_on_host(context, instance,
6416                                                     self.host, teardown=True)
6417         except Exception:
6418             with excutils.save_and_reraise_exception():
6419                 # NOTE(tdurakov): even if teardown networks fails driver
6420                 # should try to rollback live migration on destination.
6421                 LOG.exception('An error occurred while deallocating network.',
6422                               instance=instance)
6423         finally:
6424             # always run this even if setup_networks_on_host fails
6425             # NOTE(vish): The mapping is passed in so the driver can disconnect
6426             #             from remote volumes if necessary
6427             block_device_info = self._get_instance_block_device_info(context,
6428                                                                      instance)
6429             # TODO(tdurakov): remove dict to object conversion once RPC API
6430             # version is bumped to 5.x
6431             if isinstance(migrate_data, dict):
6432                 migrate_data = \
6433                     migrate_data_obj.LiveMigrateData.detect_implementation(
6434                         migrate_data)
6435             self.driver.rollback_live_migration_at_destination(
6436                 context, instance, network_info, block_device_info,
6437                 destroy_disks=destroy_disks, migrate_data=migrate_data)
6438 
6439         self._notify_about_instance_usage(
6440                         context, instance, "live_migration.rollback.dest.end",
6441                         network_info=network_info)
6442 
6443     @periodic_task.periodic_task(
6444         spacing=CONF.heal_instance_info_cache_interval)
6445     def _heal_instance_info_cache(self, context):
6446         """Called periodically.  On every call, try to update the
6447         info_cache's network information for another instance by
6448         calling to the network manager.
6449 
6450         This is implemented by keeping a cache of uuids of instances
6451         that live on this host.  On each call, we pop one off of a
6452         list, pull the DB record, and try the call to the network API.
6453         If anything errors don't fail, as it's possible the instance
6454         has been deleted, etc.
6455         """
6456         heal_interval = CONF.heal_instance_info_cache_interval
6457         if not heal_interval:
6458             return
6459 
6460         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
6461         instance = None
6462 
6463         LOG.debug('Starting heal instance info cache')
6464 
6465         if not instance_uuids:
6466             # The list of instances to heal is empty so rebuild it
6467             LOG.debug('Rebuilding the list of instances to heal')
6468             db_instances = objects.InstanceList.get_by_host(
6469                 context, self.host, expected_attrs=[], use_slave=True)
6470             for inst in db_instances:
6471                 # We don't want to refresh the cache for instances
6472                 # which are building or deleting so don't put them
6473                 # in the list. If they are building they will get
6474                 # added to the list next time we build it.
6475                 if (inst.vm_state == vm_states.BUILDING):
6476                     LOG.debug('Skipping network cache update for instance '
6477                               'because it is Building.', instance=inst)
6478                     continue
6479                 if (inst.task_state == task_states.DELETING):
6480                     LOG.debug('Skipping network cache update for instance '
6481                               'because it is being deleted.', instance=inst)
6482                     continue
6483 
6484                 if not instance:
6485                     # Save the first one we find so we don't
6486                     # have to get it again
6487                     instance = inst
6488                 else:
6489                     instance_uuids.append(inst['uuid'])
6490 
6491             self._instance_uuids_to_heal = instance_uuids
6492         else:
6493             # Find the next valid instance on the list
6494             while instance_uuids:
6495                 try:
6496                     inst = objects.Instance.get_by_uuid(
6497                             context, instance_uuids.pop(0),
6498                             expected_attrs=['system_metadata', 'info_cache',
6499                                             'flavor'],
6500                             use_slave=True)
6501                 except exception.InstanceNotFound:
6502                     # Instance is gone.  Try to grab another.
6503                     continue
6504 
6505                 # Check the instance hasn't been migrated
6506                 if inst.host != self.host:
6507                     LOG.debug('Skipping network cache update for instance '
6508                               'because it has been migrated to another '
6509                               'host.', instance=inst)
6510                 # Check the instance isn't being deleting
6511                 elif inst.task_state == task_states.DELETING:
6512                     LOG.debug('Skipping network cache update for instance '
6513                               'because it is being deleted.', instance=inst)
6514                 else:
6515                     instance = inst
6516                     break
6517 
6518         if instance:
6519             # We have an instance now to refresh
6520             try:
6521                 # Call to network API to get instance info.. this will
6522                 # force an update to the instance's info_cache
6523                 self.network_api.get_instance_nw_info(context, instance)
6524                 LOG.debug('Updated the network info_cache for instance',
6525                           instance=instance)
6526             except exception.InstanceNotFound:
6527                 # Instance is gone.
6528                 LOG.debug('Instance no longer exists. Unable to refresh',
6529                           instance=instance)
6530                 return
6531             except exception.InstanceInfoCacheNotFound:
6532                 # InstanceInfoCache is gone.
6533                 LOG.debug('InstanceInfoCache no longer exists. '
6534                           'Unable to refresh', instance=instance)
6535             except Exception:
6536                 LOG.error('An error occurred while refreshing the network '
6537                           'cache.', instance=instance, exc_info=True)
6538         else:
6539             LOG.debug("Didn't find any instances for network info cache "
6540                       "update.")
6541 
6542     @periodic_task.periodic_task
6543     def _poll_rebooting_instances(self, context):
6544         if CONF.reboot_timeout > 0:
6545             filters = {'task_state':
6546                        [task_states.REBOOTING,
6547                         task_states.REBOOT_STARTED,
6548                         task_states.REBOOT_PENDING],
6549                        'host': self.host}
6550             rebooting = objects.InstanceList.get_by_filters(
6551                 context, filters, expected_attrs=[], use_slave=True)
6552 
6553             to_poll = []
6554             for instance in rebooting:
6555                 if timeutils.is_older_than(instance.updated_at,
6556                                            CONF.reboot_timeout):
6557                     to_poll.append(instance)
6558 
6559             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
6560 
6561     @periodic_task.periodic_task
6562     def _poll_rescued_instances(self, context):
6563         if CONF.rescue_timeout > 0:
6564             filters = {'vm_state': vm_states.RESCUED,
6565                        'host': self.host}
6566             rescued_instances = objects.InstanceList.get_by_filters(
6567                 context, filters, expected_attrs=["system_metadata"],
6568                 use_slave=True)
6569 
6570             to_unrescue = []
6571             for instance in rescued_instances:
6572                 if timeutils.is_older_than(instance.launched_at,
6573                                            CONF.rescue_timeout):
6574                     to_unrescue.append(instance)
6575 
6576             for instance in to_unrescue:
6577                 self.compute_api.unrescue(context, instance)
6578 
6579     @periodic_task.periodic_task
6580     def _poll_unconfirmed_resizes(self, context):
6581         if CONF.resize_confirm_window == 0:
6582             return
6583 
6584         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
6585                 context, CONF.resize_confirm_window, self.host,
6586                 use_slave=True)
6587 
6588         migrations_info = dict(migration_count=len(migrations),
6589                 confirm_window=CONF.resize_confirm_window)
6590 
6591         if migrations_info["migration_count"] > 0:
6592             LOG.info("Found %(migration_count)d unconfirmed migrations "
6593                      "older than %(confirm_window)d seconds",
6594                      migrations_info)
6595 
6596         def _set_migration_to_error(migration, reason, **kwargs):
6597             LOG.warning("Setting migration %(migration_id)s to error: "
6598                         "%(reason)s",
6599                         {'migration_id': migration['id'], 'reason': reason},
6600                         **kwargs)
6601             migration.status = 'error'
6602             with migration.obj_as_admin():
6603                 migration.save()
6604 
6605         for migration in migrations:
6606             instance_uuid = migration.instance_uuid
6607             LOG.info("Automatically confirming migration "
6608                      "%(migration_id)s for instance %(instance_uuid)s",
6609                      {'migration_id': migration.id,
6610                       'instance_uuid': instance_uuid})
6611             expected_attrs = ['metadata', 'system_metadata']
6612             try:
6613                 instance = objects.Instance.get_by_uuid(context,
6614                             instance_uuid, expected_attrs=expected_attrs,
6615                             use_slave=True)
6616             except exception.InstanceNotFound:
6617                 reason = (_("Instance %s not found") %
6618                           instance_uuid)
6619                 _set_migration_to_error(migration, reason)
6620                 continue
6621             if instance.vm_state == vm_states.ERROR:
6622                 reason = _("In ERROR state")
6623                 _set_migration_to_error(migration, reason,
6624                                         instance=instance)
6625                 continue
6626             # race condition: The instance in DELETING state should not be
6627             # set the migration state to error, otherwise the instance in
6628             # to be deleted which is in RESIZED state
6629             # will not be able to confirm resize
6630             if instance.task_state in [task_states.DELETING,
6631                                        task_states.SOFT_DELETING]:
6632                 msg = ("Instance being deleted or soft deleted during resize "
6633                        "confirmation. Skipping.")
6634                 LOG.debug(msg, instance=instance)
6635                 continue
6636 
6637             # race condition: This condition is hit when this method is
6638             # called between the save of the migration record with a status of
6639             # finished and the save of the instance object with a state of
6640             # RESIZED. The migration record should not be set to error.
6641             if instance.task_state == task_states.RESIZE_FINISH:
6642                 msg = ("Instance still resizing during resize "
6643                        "confirmation. Skipping.")
6644                 LOG.debug(msg, instance=instance)
6645                 continue
6646 
6647             vm_state = instance.vm_state
6648             task_state = instance.task_state
6649             if vm_state != vm_states.RESIZED or task_state is not None:
6650                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
6651                            "RESIZED/None") %
6652                           {'vm_state': vm_state,
6653                            'task_state': task_state})
6654                 _set_migration_to_error(migration, reason,
6655                                         instance=instance)
6656                 continue
6657             try:
6658                 self.compute_api.confirm_resize(context, instance,
6659                                                 migration=migration)
6660             except Exception as e:
6661                 LOG.info("Error auto-confirming resize: %s. "
6662                          "Will retry later.", e, instance=instance)
6663 
6664     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
6665     def _poll_shelved_instances(self, context):
6666 
6667         if CONF.shelved_offload_time <= 0:
6668             return
6669 
6670         filters = {'vm_state': vm_states.SHELVED,
6671                    'task_state': None,
6672                    'host': self.host}
6673         shelved_instances = objects.InstanceList.get_by_filters(
6674             context, filters=filters, expected_attrs=['system_metadata'],
6675             use_slave=True)
6676 
6677         to_gc = []
6678         for instance in shelved_instances:
6679             sys_meta = instance.system_metadata
6680             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
6681             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
6682                 to_gc.append(instance)
6683 
6684         for instance in to_gc:
6685             try:
6686                 instance.task_state = task_states.SHELVING_OFFLOADING
6687                 instance.save(expected_task_state=(None,))
6688                 self.shelve_offload_instance(context, instance,
6689                                              clean_shutdown=False)
6690             except Exception:
6691                 LOG.exception('Periodic task failed to offload instance.',
6692                               instance=instance)
6693 
6694     @periodic_task.periodic_task
6695     def _instance_usage_audit(self, context):
6696         if not CONF.instance_usage_audit:
6697             return
6698 
6699         begin, end = utils.last_completed_audit_period()
6700         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
6701                                self.host):
6702             return
6703 
6704         instances = objects.InstanceList.get_active_by_window_joined(
6705             context, begin, end, host=self.host,
6706             expected_attrs=['system_metadata', 'info_cache', 'metadata',
6707                             'flavor'],
6708             use_slave=True)
6709         num_instances = len(instances)
6710         errors = 0
6711         successes = 0
6712         LOG.info("Running instance usage audit for host %(host)s "
6713                  "from %(begin_time)s to %(end_time)s. "
6714                  "%(number_instances)s instances.",
6715                  {'host': self.host,
6716                   'begin_time': begin,
6717                   'end_time': end,
6718                   'number_instances': num_instances})
6719         start_time = time.time()
6720         task_log = objects.TaskLog(context)
6721         task_log.task_name = 'instance_usage_audit'
6722         task_log.period_beginning = begin
6723         task_log.period_ending = end
6724         task_log.host = self.host
6725         task_log.task_items = num_instances
6726         task_log.message = 'Instance usage audit started...'
6727         task_log.begin_task()
6728         for instance in instances:
6729             try:
6730                 compute_utils.notify_usage_exists(
6731                     self.notifier, context, instance,
6732                     ignore_missing_network_data=False)
6733                 successes += 1
6734             except Exception:
6735                 LOG.exception('Failed to generate usage '
6736                               'audit for instance '
6737                               'on host %s', self.host,
6738                               instance=instance)
6739                 errors += 1
6740         task_log.errors = errors
6741         task_log.message = (
6742             'Instance usage audit ran for host %s, %s instances in %s seconds.'
6743             % (self.host, num_instances, time.time() - start_time))
6744         task_log.end_task()
6745 
6746     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
6747     def _poll_bandwidth_usage(self, context):
6748 
6749         if not self._bw_usage_supported:
6750             return
6751 
6752         prev_time, start_time = utils.last_completed_audit_period()
6753 
6754         curr_time = time.time()
6755         if (curr_time - self._last_bw_usage_poll >
6756                 CONF.bandwidth_poll_interval):
6757             self._last_bw_usage_poll = curr_time
6758             LOG.info("Updating bandwidth usage cache")
6759             cells_update_interval = CONF.cells.bandwidth_update_interval
6760             if (cells_update_interval > 0 and
6761                    curr_time - self._last_bw_usage_cell_update >
6762                            cells_update_interval):
6763                 self._last_bw_usage_cell_update = curr_time
6764                 update_cells = True
6765             else:
6766                 update_cells = False
6767 
6768             instances = objects.InstanceList.get_by_host(context,
6769                                                               self.host,
6770                                                               use_slave=True)
6771             try:
6772                 bw_counters = self.driver.get_all_bw_counters(instances)
6773             except NotImplementedError:
6774                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
6775                 # implemented yet.  If they don't it doesn't break anything,
6776                 # they just don't get the info in the usage events.
6777                 # NOTE(PhilDay): Record that its not supported so we can
6778                 # skip fast on future calls rather than waste effort getting
6779                 # the list of instances.
6780                 LOG.info("Bandwidth usage not supported by hypervisor.")
6781                 self._bw_usage_supported = False
6782                 return
6783 
6784             refreshed = timeutils.utcnow()
6785             for bw_ctr in bw_counters:
6786                 # Allow switching of greenthreads between queries.
6787                 greenthread.sleep(0)
6788                 bw_in = 0
6789                 bw_out = 0
6790                 last_ctr_in = None
6791                 last_ctr_out = None
6792                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6793                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6794                     start_period=start_time, use_slave=True)
6795                 if usage:
6796                     bw_in = usage.bw_in
6797                     bw_out = usage.bw_out
6798                     last_ctr_in = usage.last_ctr_in
6799                     last_ctr_out = usage.last_ctr_out
6800                 else:
6801                     usage = (objects.BandwidthUsage.
6802                              get_by_instance_uuid_and_mac(
6803                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6804                         start_period=prev_time, use_slave=True))
6805                     if usage:
6806                         last_ctr_in = usage.last_ctr_in
6807                         last_ctr_out = usage.last_ctr_out
6808 
6809                 if last_ctr_in is not None:
6810                     if bw_ctr['bw_in'] < last_ctr_in:
6811                         # counter rollover
6812                         bw_in += bw_ctr['bw_in']
6813                     else:
6814                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6815 
6816                 if last_ctr_out is not None:
6817                     if bw_ctr['bw_out'] < last_ctr_out:
6818                         # counter rollover
6819                         bw_out += bw_ctr['bw_out']
6820                     else:
6821                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6822 
6823                 objects.BandwidthUsage(context=context).create(
6824                                               bw_ctr['uuid'],
6825                                               bw_ctr['mac_address'],
6826                                               bw_in,
6827                                               bw_out,
6828                                               bw_ctr['bw_in'],
6829                                               bw_ctr['bw_out'],
6830                                               start_period=start_time,
6831                                               last_refreshed=refreshed,
6832                                               update_cells=update_cells)
6833 
6834     def _get_host_volume_bdms(self, context, use_slave=False):
6835         """Return all block device mappings on a compute host."""
6836         compute_host_bdms = []
6837         instances = objects.InstanceList.get_by_host(context, self.host,
6838             use_slave=use_slave)
6839         for instance in instances:
6840             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6841                     context, instance.uuid, use_slave=use_slave)
6842             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6843             compute_host_bdms.append(dict(instance=instance,
6844                                           instance_bdms=instance_bdms))
6845 
6846         return compute_host_bdms
6847 
6848     def _update_volume_usage_cache(self, context, vol_usages):
6849         """Updates the volume usage cache table with a list of stats."""
6850         for usage in vol_usages:
6851             # Allow switching of greenthreads between queries.
6852             greenthread.sleep(0)
6853             vol_usage = objects.VolumeUsage(context)
6854             vol_usage.volume_id = usage['volume']
6855             vol_usage.instance_uuid = usage['instance'].uuid
6856             vol_usage.project_id = usage['instance'].project_id
6857             vol_usage.user_id = usage['instance'].user_id
6858             vol_usage.availability_zone = usage['instance'].availability_zone
6859             vol_usage.curr_reads = usage['rd_req']
6860             vol_usage.curr_read_bytes = usage['rd_bytes']
6861             vol_usage.curr_writes = usage['wr_req']
6862             vol_usage.curr_write_bytes = usage['wr_bytes']
6863             vol_usage.save()
6864             self.notifier.info(context, 'volume.usage',
6865                                compute_utils.usage_volume_info(vol_usage))
6866 
6867     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
6868     def _poll_volume_usage(self, context):
6869         if CONF.volume_usage_poll_interval == 0:
6870             return
6871 
6872         compute_host_bdms = self._get_host_volume_bdms(context,
6873                                                        use_slave=True)
6874         if not compute_host_bdms:
6875             return
6876 
6877         LOG.debug("Updating volume usage cache")
6878         try:
6879             vol_usages = self.driver.get_all_volume_usage(context,
6880                                                           compute_host_bdms)
6881         except NotImplementedError:
6882             return
6883 
6884         self._update_volume_usage_cache(context, vol_usages)
6885 
6886     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
6887                                  run_immediately=True)
6888     def _sync_power_states(self, context):
6889         """Align power states between the database and the hypervisor.
6890 
6891         To sync power state data we make a DB call to get the number of
6892         virtual machines known by the hypervisor and if the number matches the
6893         number of virtual machines known by the database, we proceed in a lazy
6894         loop, one database record at a time, checking if the hypervisor has the
6895         same power state as is in the database.
6896         """
6897         db_instances = objects.InstanceList.get_by_host(context, self.host,
6898                                                         expected_attrs=[],
6899                                                         use_slave=True)
6900 
6901         num_vm_instances = self.driver.get_num_instances()
6902         num_db_instances = len(db_instances)
6903 
6904         if num_vm_instances != num_db_instances:
6905             LOG.warning("While synchronizing instance power states, found "
6906                         "%(num_db_instances)s instances in the database "
6907                         "and %(num_vm_instances)s instances on the "
6908                         "hypervisor.",
6909                         {'num_db_instances': num_db_instances,
6910                          'num_vm_instances': num_vm_instances})
6911 
6912         def _sync(db_instance):
6913             # NOTE(melwitt): This must be synchronized as we query state from
6914             #                two separate sources, the driver and the database.
6915             #                They are set (in stop_instance) and read, in sync.
6916             @utils.synchronized(db_instance.uuid)
6917             def query_driver_power_state_and_sync():
6918                 self._query_driver_power_state_and_sync(context, db_instance)
6919 
6920             try:
6921                 query_driver_power_state_and_sync()
6922             except Exception:
6923                 LOG.exception("Periodic sync_power_state task had an "
6924                               "error while processing an instance.",
6925                               instance=db_instance)
6926 
6927             self._syncs_in_progress.pop(db_instance.uuid)
6928 
6929         for db_instance in db_instances:
6930             # process syncs asynchronously - don't want instance locking to
6931             # block entire periodic task thread
6932             uuid = db_instance.uuid
6933             if uuid in self._syncs_in_progress:
6934                 LOG.debug('Sync already in progress for %s', uuid)
6935             else:
6936                 LOG.debug('Triggering sync for uuid %s', uuid)
6937                 self._syncs_in_progress[uuid] = True
6938                 self._sync_power_pool.spawn_n(_sync, db_instance)
6939 
6940     def _query_driver_power_state_and_sync(self, context, db_instance):
6941         if db_instance.task_state is not None:
6942             LOG.info("During sync_power_state the instance has a "
6943                      "pending task (%(task)s). Skip.",
6944                      {'task': db_instance.task_state}, instance=db_instance)
6945             return
6946         # No pending tasks. Now try to figure out the real vm_power_state.
6947         try:
6948             vm_instance = self.driver.get_info(db_instance)
6949             vm_power_state = vm_instance.state
6950         except exception.InstanceNotFound:
6951             vm_power_state = power_state.NOSTATE
6952         # Note(maoy): the above get_info call might take a long time,
6953         # for example, because of a broken libvirt driver.
6954         try:
6955             self._sync_instance_power_state(context,
6956                                             db_instance,
6957                                             vm_power_state,
6958                                             use_slave=True)
6959         except exception.InstanceNotFound:
6960             # NOTE(hanlind): If the instance gets deleted during sync,
6961             # silently ignore.
6962             pass
6963 
6964     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
6965                                    use_slave=False):
6966         """Align instance power state between the database and hypervisor.
6967 
6968         If the instance is not found on the hypervisor, but is in the database,
6969         then a stop() API will be called on the instance.
6970         """
6971 
6972         # We re-query the DB to get the latest instance info to minimize
6973         # (not eliminate) race condition.
6974         db_instance.refresh(use_slave=use_slave)
6975         db_power_state = db_instance.power_state
6976         vm_state = db_instance.vm_state
6977 
6978         if self.host != db_instance.host:
6979             # on the sending end of nova-compute _sync_power_state
6980             # may have yielded to the greenthread performing a live
6981             # migration; this in turn has changed the resident-host
6982             # for the VM; However, the instance is still active, it
6983             # is just in the process of migrating to another host.
6984             # This implies that the compute source must relinquish
6985             # control to the compute destination.
6986             LOG.info("During the sync_power process the "
6987                      "instance has moved from "
6988                      "host %(src)s to host %(dst)s",
6989                      {'src': db_instance.host,
6990                       'dst': self.host},
6991                      instance=db_instance)
6992             return
6993         elif db_instance.task_state is not None:
6994             # on the receiving end of nova-compute, it could happen
6995             # that the DB instance already report the new resident
6996             # but the actual VM has not showed up on the hypervisor
6997             # yet. In this case, let's allow the loop to continue
6998             # and run the state sync in a later round
6999             LOG.info("During sync_power_state the instance has a "
7000                      "pending task (%(task)s). Skip.",
7001                      {'task': db_instance.task_state},
7002                      instance=db_instance)
7003             return
7004 
7005         orig_db_power_state = db_power_state
7006         if vm_power_state != db_power_state:
7007             LOG.info('During _sync_instance_power_state the DB '
7008                      'power_state (%(db_power_state)s) does not match '
7009                      'the vm_power_state from the hypervisor '
7010                      '(%(vm_power_state)s). Updating power_state in the '
7011                      'DB to match the hypervisor.',
7012                      {'db_power_state': db_power_state,
7013                       'vm_power_state': vm_power_state},
7014                      instance=db_instance)
7015             # power_state is always updated from hypervisor to db
7016             db_instance.power_state = vm_power_state
7017             db_instance.save()
7018             db_power_state = vm_power_state
7019 
7020         # Note(maoy): Now resolve the discrepancy between vm_state and
7021         # vm_power_state. We go through all possible vm_states.
7022         if vm_state in (vm_states.BUILDING,
7023                         vm_states.RESCUED,
7024                         vm_states.RESIZED,
7025                         vm_states.SUSPENDED,
7026                         vm_states.ERROR):
7027             # TODO(maoy): we ignore these vm_state for now.
7028             pass
7029         elif vm_state == vm_states.ACTIVE:
7030             # The only rational power state should be RUNNING
7031             if vm_power_state in (power_state.SHUTDOWN,
7032                                   power_state.CRASHED):
7033                 LOG.warning("Instance shutdown by itself. Calling the "
7034                             "stop API. Current vm_state: %(vm_state)s, "
7035                             "current task_state: %(task_state)s, "
7036                             "original DB power_state: %(db_power_state)s, "
7037                             "current VM power_state: %(vm_power_state)s",
7038                             {'vm_state': vm_state,
7039                              'task_state': db_instance.task_state,
7040                              'db_power_state': orig_db_power_state,
7041                              'vm_power_state': vm_power_state},
7042                             instance=db_instance)
7043                 try:
7044                     # Note(maoy): here we call the API instead of
7045                     # brutally updating the vm_state in the database
7046                     # to allow all the hooks and checks to be performed.
7047                     if db_instance.shutdown_terminate:
7048                         self.compute_api.delete(context, db_instance)
7049                     else:
7050                         self.compute_api.stop(context, db_instance)
7051                 except Exception:
7052                     # Note(maoy): there is no need to propagate the error
7053                     # because the same power_state will be retrieved next
7054                     # time and retried.
7055                     # For example, there might be another task scheduled.
7056                     LOG.exception("error during stop() in sync_power_state.",
7057                                   instance=db_instance)
7058             elif vm_power_state == power_state.SUSPENDED:
7059                 LOG.warning("Instance is suspended unexpectedly. Calling "
7060                             "the stop API.", instance=db_instance)
7061                 try:
7062                     self.compute_api.stop(context, db_instance)
7063                 except Exception:
7064                     LOG.exception("error during stop() in sync_power_state.",
7065                                   instance=db_instance)
7066             elif vm_power_state == power_state.PAUSED:
7067                 # Note(maoy): a VM may get into the paused state not only
7068                 # because the user request via API calls, but also
7069                 # due to (temporary) external instrumentations.
7070                 # Before the virt layer can reliably report the reason,
7071                 # we simply ignore the state discrepancy. In many cases,
7072                 # the VM state will go back to running after the external
7073                 # instrumentation is done. See bug 1097806 for details.
7074                 LOG.warning("Instance is paused unexpectedly. Ignore.",
7075                             instance=db_instance)
7076             elif vm_power_state == power_state.NOSTATE:
7077                 # Occasionally, depending on the status of the hypervisor,
7078                 # which could be restarting for example, an instance may
7079                 # not be found.  Therefore just log the condition.
7080                 LOG.warning("Instance is unexpectedly not found. Ignore.",
7081                             instance=db_instance)
7082         elif vm_state == vm_states.STOPPED:
7083             if vm_power_state not in (power_state.NOSTATE,
7084                                       power_state.SHUTDOWN,
7085                                       power_state.CRASHED):
7086                 LOG.warning("Instance is not stopped. Calling "
7087                             "the stop API. Current vm_state: %(vm_state)s,"
7088                             " current task_state: %(task_state)s, "
7089                             "original DB power_state: %(db_power_state)s, "
7090                             "current VM power_state: %(vm_power_state)s",
7091                             {'vm_state': vm_state,
7092                              'task_state': db_instance.task_state,
7093                              'db_power_state': orig_db_power_state,
7094                              'vm_power_state': vm_power_state},
7095                             instance=db_instance)
7096                 try:
7097                     # NOTE(russellb) Force the stop, because normally the
7098                     # compute API would not allow an attempt to stop a stopped
7099                     # instance.
7100                     self.compute_api.force_stop(context, db_instance)
7101                 except Exception:
7102                     LOG.exception("error during stop() in sync_power_state.",
7103                                   instance=db_instance)
7104         elif vm_state == vm_states.PAUSED:
7105             if vm_power_state in (power_state.SHUTDOWN,
7106                                   power_state.CRASHED):
7107                 LOG.warning("Paused instance shutdown by itself. Calling "
7108                             "the stop API.", instance=db_instance)
7109                 try:
7110                     self.compute_api.force_stop(context, db_instance)
7111                 except Exception:
7112                     LOG.exception("error during stop() in sync_power_state.",
7113                                   instance=db_instance)
7114         elif vm_state in (vm_states.SOFT_DELETED,
7115                           vm_states.DELETED):
7116             if vm_power_state not in (power_state.NOSTATE,
7117                                       power_state.SHUTDOWN):
7118                 # Note(maoy): this should be taken care of periodically in
7119                 # _cleanup_running_deleted_instances().
7120                 LOG.warning("Instance is not (soft-)deleted.",
7121                             instance=db_instance)
7122 
7123     @periodic_task.periodic_task
7124     def _reclaim_queued_deletes(self, context):
7125         """Reclaim instances that are queued for deletion."""
7126         interval = CONF.reclaim_instance_interval
7127         if interval <= 0:
7128             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
7129             return
7130 
7131         filters = {'vm_state': vm_states.SOFT_DELETED,
7132                    'task_state': None,
7133                    'host': self.host}
7134         instances = objects.InstanceList.get_by_filters(
7135             context, filters,
7136             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
7137             use_slave=True)
7138         for instance in instances:
7139             if self._deleted_old_enough(instance, interval):
7140                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7141                         context, instance.uuid)
7142                 LOG.info('Reclaiming deleted instance', instance=instance)
7143                 try:
7144                     self._delete_instance(context, instance, bdms)
7145                 except Exception as e:
7146                     LOG.warning("Periodic reclaim failed to delete "
7147                                 "instance: %s",
7148                                 e, instance=instance)
7149 
7150     def _get_nodename(self, instance, refresh=False):
7151         """Helper method to get the name of the first available node
7152         on this host. This method should not be used with any operations
7153         on ironic instances since it does not handle multiple nodes.
7154         """
7155         node = self.driver.get_available_nodes(refresh=refresh)[0]
7156         LOG.debug("No node specified, defaulting to %s", node,
7157                   instance=instance)
7158         return node
7159 
7160     def update_available_resource_for_node(self, context, nodename):
7161 
7162         rt = self._get_resource_tracker()
7163         try:
7164             rt.update_available_resource(context, nodename)
7165         except exception.ComputeHostNotFound:
7166             # NOTE(comstud): We can get to this case if a node was
7167             # marked 'deleted' in the DB and then re-added with a
7168             # different auto-increment id. The cached resource
7169             # tracker tried to update a deleted record and failed.
7170             # Don't add this resource tracker to the new dict, so
7171             # that this will resolve itself on the next run.
7172             LOG.info("Compute node '%s' not found in "
7173                      "update_available_resource.", nodename)
7174             # TODO(jaypipes): Yes, this is inefficient to throw away all of the
7175             # compute nodes to force a rebuild, but this is only temporary
7176             # until Ironic baremetal node resource providers are tracked
7177             # properly in the report client and this is a tiny edge case
7178             # anyway.
7179             self._resource_tracker = None
7180             return
7181         except Exception:
7182             LOG.exception("Error updating resources for node %(node)s.",
7183                           {'node': nodename})
7184 
7185     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
7186     def update_available_resource(self, context, startup=False):
7187         """See driver.get_available_resource()
7188 
7189         Periodic process that keeps that the compute host's understanding of
7190         resource availability and usage in sync with the underlying hypervisor.
7191 
7192         :param context: security context
7193         :param startup: True if this is being called when the nova-compute
7194             service is starting, False otherwise.
7195         """
7196 
7197         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
7198                                                             use_slave=True,
7199                                                             startup=startup)
7200         nodenames = set(self.driver.get_available_nodes())
7201         for nodename in nodenames:
7202             self.update_available_resource_for_node(context, nodename)
7203 
7204         # Delete orphan compute node not reported by driver but still in db
7205         for cn in compute_nodes_in_db:
7206             if cn.hypervisor_hostname not in nodenames:
7207                 LOG.info("Deleting orphan compute node %(id)s "
7208                          "hypervisor host is %(hh)s, "
7209                          "nodes are %(nodes)s",
7210                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
7211                           'nodes': nodenames})
7212                 cn.destroy()
7213                 # Delete the corresponding resource provider in placement,
7214                 # along with any associated allocations and inventory.
7215                 # TODO(cdent): Move use of reportclient into resource tracker.
7216                 self.scheduler_client.reportclient.delete_resource_provider(
7217                     context, cn, cascade=True)
7218 
7219     def _get_compute_nodes_in_db(self, context, use_slave=False,
7220                                  startup=False):
7221         try:
7222             return objects.ComputeNodeList.get_all_by_host(context, self.host,
7223                                                            use_slave=use_slave)
7224         except exception.NotFound:
7225             if startup:
7226                 LOG.warning(
7227                     "No compute node record found for host %s. If this is "
7228                     "the first time this service is starting on this "
7229                     "host, then you can ignore this warning.", self.host)
7230             else:
7231                 LOG.error("No compute node record for host %s", self.host)
7232             return []
7233 
7234     @periodic_task.periodic_task(
7235         spacing=CONF.running_deleted_instance_poll_interval)
7236     def _cleanup_running_deleted_instances(self, context):
7237         """Cleanup any instances which are erroneously still running after
7238         having been deleted.
7239 
7240         Valid actions to take are:
7241 
7242             1. noop - do nothing
7243             2. log - log which instances are erroneously running
7244             3. reap - shutdown and cleanup any erroneously running instances
7245             4. shutdown - power off *and disable* any erroneously running
7246                           instances
7247 
7248         The use-case for this cleanup task is: for various reasons, it may be
7249         possible for the database to show an instance as deleted but for that
7250         instance to still be running on a host machine (see bug
7251         https://bugs.launchpad.net/nova/+bug/911366).
7252 
7253         This cleanup task is a cross-hypervisor utility for finding these
7254         zombied instances and either logging the discrepancy (likely what you
7255         should do in production), or automatically reaping the instances (more
7256         appropriate for dev environments).
7257         """
7258         action = CONF.running_deleted_instance_action
7259 
7260         if action == "noop":
7261             return
7262 
7263         # NOTE(sirp): admin contexts don't ordinarily return deleted records
7264         with utils.temporary_mutation(context, read_deleted="yes"):
7265             for instance in self._running_deleted_instances(context):
7266                 if action == "log":
7267                     LOG.warning("Detected instance with name label "
7268                                 "'%s' which is marked as "
7269                                 "DELETED but still present on host.",
7270                                 instance.name, instance=instance)
7271 
7272                 elif action == 'shutdown':
7273                     LOG.info("Powering off instance with name label "
7274                              "'%s' which is marked as "
7275                              "DELETED but still present on host.",
7276                              instance.name, instance=instance)
7277                     try:
7278                         try:
7279                             # disable starting the instance
7280                             self.driver.set_bootable(instance, False)
7281                         except NotImplementedError:
7282                             LOG.debug("set_bootable is not implemented "
7283                                       "for the current driver")
7284                         # and power it off
7285                         self.driver.power_off(instance)
7286                     except Exception:
7287                         LOG.warning("Failed to power off instance",
7288                                     instance=instance, exc_info=True)
7289 
7290                 elif action == 'reap':
7291                     LOG.info("Destroying instance with name label "
7292                              "'%s' which is marked as "
7293                              "DELETED but still present on host.",
7294                              instance.name, instance=instance)
7295                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7296                         context, instance.uuid, use_slave=True)
7297                     self.instance_events.clear_events_for_instance(instance)
7298                     try:
7299                         self._shutdown_instance(context, instance, bdms,
7300                                                 notify=False)
7301                         self._cleanup_volumes(context, instance.uuid, bdms)
7302                     except Exception as e:
7303                         LOG.warning("Periodic cleanup failed to delete "
7304                                     "instance: %s",
7305                                     e, instance=instance)
7306                 else:
7307                     raise Exception(_("Unrecognized value '%s'"
7308                                       " for CONF.running_deleted_"
7309                                       "instance_action") % action)
7310 
7311     def _running_deleted_instances(self, context):
7312         """Returns a list of instances nova thinks is deleted,
7313         but the hypervisor thinks is still running.
7314         """
7315         timeout = CONF.running_deleted_instance_timeout
7316         filters = {'deleted': True,
7317                    'soft_deleted': False}
7318         instances = self._get_instances_on_driver(context, filters)
7319         return [i for i in instances if self._deleted_old_enough(i, timeout)]
7320 
7321     def _deleted_old_enough(self, instance, timeout):
7322         deleted_at = instance.deleted_at
7323         if deleted_at:
7324             deleted_at = deleted_at.replace(tzinfo=None)
7325         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
7326 
7327     @contextlib.contextmanager
7328     def _error_out_instance_on_exception(self, context, instance,
7329                                          instance_state=vm_states.ACTIVE):
7330         instance_uuid = instance.uuid
7331         try:
7332             yield
7333         except NotImplementedError as error:
7334             with excutils.save_and_reraise_exception():
7335                 LOG.info("Setting instance back to %(state)s after: "
7336                          "%(error)s",
7337                          {'state': instance_state, 'error': error},
7338                          instance_uuid=instance_uuid)
7339                 self._instance_update(context, instance,
7340                                       vm_state=instance_state,
7341                                       task_state=None)
7342         except exception.InstanceFaultRollback as error:
7343             LOG.info("Setting instance back to ACTIVE after: %s",
7344                      error, instance_uuid=instance_uuid)
7345             self._instance_update(context, instance,
7346                                   vm_state=vm_states.ACTIVE,
7347                                   task_state=None)
7348             raise error.inner_exception
7349         except Exception:
7350             LOG.exception('Setting instance vm_state to ERROR',
7351                           instance_uuid=instance_uuid)
7352             with excutils.save_and_reraise_exception():
7353                 self._set_instance_obj_error_state(context, instance)
7354 
7355     @wrap_exception()
7356     def add_aggregate_host(self, context, aggregate, host, slave_info):
7357         """Notify hypervisor of change (for hypervisor pools)."""
7358         try:
7359             self.driver.add_to_aggregate(context, aggregate, host,
7360                                          slave_info=slave_info)
7361         except NotImplementedError:
7362             LOG.debug('Hypervisor driver does not support '
7363                       'add_aggregate_host')
7364         except exception.AggregateError:
7365             with excutils.save_and_reraise_exception():
7366                 self.driver.undo_aggregate_operation(
7367                                     context,
7368                                     aggregate.delete_host,
7369                                     aggregate, host)
7370 
7371     @wrap_exception()
7372     def remove_aggregate_host(self, context, host, slave_info, aggregate):
7373         """Removes a host from a physical hypervisor pool."""
7374         try:
7375             self.driver.remove_from_aggregate(context, aggregate, host,
7376                                               slave_info=slave_info)
7377         except NotImplementedError:
7378             LOG.debug('Hypervisor driver does not support '
7379                       'remove_aggregate_host')
7380         except (exception.AggregateError,
7381                 exception.InvalidAggregateAction) as e:
7382             with excutils.save_and_reraise_exception():
7383                 self.driver.undo_aggregate_operation(
7384                                     context,
7385                                     aggregate.add_host,
7386                                     aggregate, host,
7387                                     isinstance(e, exception.AggregateError))
7388 
7389     def _process_instance_event(self, instance, event):
7390         _event = self.instance_events.pop_instance_event(instance, event)
7391         if _event:
7392             LOG.debug('Processing event %(event)s',
7393                       {'event': event.key}, instance=instance)
7394             _event.send(event)
7395         else:
7396             # If it's a network-vif-unplugged event and the instance is being
7397             # deleted then we don't need to make this a warning as it's
7398             # expected. There are other things which could trigger this like
7399             # detaching an interface, but we don't have a task state for that.
7400             if (event.name == 'network-vif-unplugged' and
7401                     instance.task_state == task_states.DELETING):
7402                 LOG.debug('Received event %s for instance which is being '
7403                           'deleted.', event.key, instance=instance)
7404             else:
7405                 LOG.warning('Received unexpected event %(event)s for '
7406                             'instance with vm_state %(vm_state)s and '
7407                             'task_state %(task_state)s.',
7408                             {'event': event.key,
7409                              'vm_state': instance.vm_state,
7410                              'task_state': instance.task_state},
7411                             instance=instance)
7412 
7413     def _process_instance_vif_deleted_event(self, context, instance,
7414                                             deleted_vif_id):
7415         # If an attached port is deleted by neutron, it needs to
7416         # be detached from the instance.
7417         # And info cache needs to be updated.
7418         network_info = instance.info_cache.network_info
7419         for index, vif in enumerate(network_info):
7420             if vif['id'] == deleted_vif_id:
7421                 LOG.info('Neutron deleted interface %(intf)s; '
7422                          'detaching it from the instance and '
7423                          'deleting it from the info cache',
7424                          {'intf': vif['id']},
7425                          instance=instance)
7426                 del network_info[index]
7427                 base_net_api.update_instance_cache_with_nw_info(
7428                                  self.network_api, context,
7429                                  instance,
7430                                  nw_info=network_info)
7431                 try:
7432                     self.driver.detach_interface(context, instance, vif)
7433                 except NotImplementedError:
7434                     # Not all virt drivers support attach/detach of interfaces
7435                     # yet (like Ironic), so just ignore this.
7436                     pass
7437                 except exception.NovaException as ex:
7438                     LOG.warning("Detach interface failed, "
7439                                 "port_id=%(port_id)s, reason: %(msg)s",
7440                                 {'port_id': deleted_vif_id, 'msg': ex},
7441                                 instance=instance)
7442                 break
7443 
7444     @wrap_instance_event(prefix='compute')
7445     @wrap_instance_fault
7446     def extend_volume(self, context, instance, extended_volume_id):
7447 
7448         # If an attached volume is extended by cinder, it needs to
7449         # be extended by virt driver so host can detect its new size.
7450         # And bdm needs to be updated.
7451         LOG.debug('Handling volume-extended event for volume %(vol)s',
7452                   {'vol': extended_volume_id}, instance=instance)
7453 
7454         try:
7455             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
7456                    context, extended_volume_id, instance.uuid)
7457         except exception.NotFound:
7458             LOG.warning('Extend volume failed, '
7459                         'volume %(vol)s is not attached to instance.',
7460                         {'vol': extended_volume_id},
7461                         instance=instance)
7462             return
7463 
7464         LOG.info('Cinder extended volume %(vol)s; '
7465                  'extending it to detect new size',
7466                  {'vol': extended_volume_id},
7467                  instance=instance)
7468         volume = self.volume_api.get(context, bdm.volume_id)
7469 
7470         if bdm.connection_info is None:
7471             LOG.warning('Extend volume failed, '
7472                         'attached volume %(vol)s has no connection_info',
7473                         {'vol': extended_volume_id},
7474                         instance=instance)
7475             return
7476 
7477         connection_info = jsonutils.loads(bdm.connection_info)
7478         bdm.volume_size = volume['size']
7479         bdm.save()
7480 
7481         if not self.driver.capabilities.get('supports_extend_volume', False):
7482             raise exception.ExtendVolumeNotSupported()
7483 
7484         try:
7485             self.driver.extend_volume(connection_info,
7486                                       instance)
7487         except Exception as ex:
7488             LOG.warning('Extend volume failed, '
7489                         'volume_id=%(volume_id)s, reason: %(msg)s',
7490                         {'volume_id': extended_volume_id, 'msg': ex},
7491                         instance=instance)
7492             raise
7493 
7494     @wrap_exception()
7495     def external_instance_event(self, context, instances, events):
7496         # NOTE(danms): Some event types are handled by the manager, such
7497         # as when we're asked to update the instance's info_cache. If it's
7498         # not one of those, look for some thread(s) waiting for the event and
7499         # unblock them if so.
7500         for event in events:
7501             instance = [inst for inst in instances
7502                         if inst.uuid == event.instance_uuid][0]
7503             LOG.debug('Received event %(event)s',
7504                       {'event': event.key},
7505                       instance=instance)
7506             if event.name == 'network-changed':
7507                 try:
7508                     self.network_api.get_instance_nw_info(context, instance)
7509                 except exception.NotFound as e:
7510                     LOG.info('Failed to process external instance event '
7511                              '%(event)s due to: %(error)s',
7512                              {'event': event.key, 'error': six.text_type(e)},
7513                              instance=instance)
7514             elif event.name == 'network-vif-deleted':
7515                 try:
7516                     self._process_instance_vif_deleted_event(context,
7517                                                              instance,
7518                                                              event.tag)
7519                 except exception.NotFound as e:
7520                     LOG.info('Failed to process external instance event '
7521                              '%(event)s due to: %(error)s',
7522                              {'event': event.key, 'error': six.text_type(e)},
7523                              instance=instance)
7524             elif event.name == 'volume-extended':
7525                 self.extend_volume(context, instance, event.tag)
7526             else:
7527                 self._process_instance_event(instance, event)
7528 
7529     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
7530                                  external_process_ok=True)
7531     def _run_image_cache_manager_pass(self, context):
7532         """Run a single pass of the image cache manager."""
7533 
7534         if not self.driver.capabilities["has_imagecache"]:
7535             return
7536 
7537         # Determine what other nodes use this storage
7538         storage_users.register_storage_use(CONF.instances_path, CONF.host)
7539         nodes = storage_users.get_storage_users(CONF.instances_path)
7540 
7541         # Filter all_instances to only include those nodes which share this
7542         # storage path.
7543         # TODO(mikal): this should be further refactored so that the cache
7544         # cleanup code doesn't know what those instances are, just a remote
7545         # count, and then this logic should be pushed up the stack.
7546         filters = {'deleted': False,
7547                    'soft_deleted': True,
7548                    'host': nodes}
7549         filtered_instances = objects.InstanceList.get_by_filters(context,
7550                                  filters, expected_attrs=[], use_slave=True)
7551 
7552         self.driver.manage_image_cache(context, filtered_instances)
7553 
7554     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7555     def _run_pending_deletes(self, context):
7556         """Retry any pending instance file deletes."""
7557         LOG.debug('Cleaning up deleted instances')
7558         filters = {'deleted': True,
7559                    'soft_deleted': False,
7560                    'host': CONF.host,
7561                    'cleaned': False}
7562         attrs = ['system_metadata']
7563         with utils.temporary_mutation(context, read_deleted='yes'):
7564             instances = objects.InstanceList.get_by_filters(
7565                 context, filters, expected_attrs=attrs, use_slave=True)
7566         LOG.debug('There are %d instances to clean', len(instances))
7567 
7568         # TODO(raj_singh): Remove this if condition when min value is
7569         # introduced to "maximum_instance_delete_attempts" cfg option.
7570         if CONF.maximum_instance_delete_attempts < 1:
7571             LOG.warning('Future versions of Nova will restrict the '
7572                         '"maximum_instance_delete_attempts" config option '
7573                         'to values >=1. Update your configuration file to '
7574                         'mitigate future upgrade issues.')
7575 
7576         for instance in instances:
7577             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
7578             LOG.debug('Instance has had %(attempts)s of %(max)s '
7579                       'cleanup attempts',
7580                       {'attempts': attempts,
7581                        'max': CONF.maximum_instance_delete_attempts},
7582                       instance=instance)
7583             if attempts < CONF.maximum_instance_delete_attempts:
7584                 success = self.driver.delete_instance_files(instance)
7585 
7586                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
7587                 if success:
7588                     instance.cleaned = True
7589                 with utils.temporary_mutation(context, read_deleted='yes'):
7590                     instance.save()
7591 
7592     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7593     def _cleanup_incomplete_migrations(self, context):
7594         """Delete instance files on failed resize/revert-resize operation
7595 
7596         During resize/revert-resize operation, if that instance gets deleted
7597         in-between then instance files might remain either on source or
7598         destination compute node because of race condition.
7599         """
7600         LOG.debug('Cleaning up deleted instances with incomplete migration ')
7601         migration_filters = {'host': CONF.host,
7602                              'status': 'error'}
7603         migrations = objects.MigrationList.get_by_filters(context,
7604                                                           migration_filters)
7605 
7606         if not migrations:
7607             return
7608 
7609         inst_uuid_from_migrations = set([migration.instance_uuid for migration
7610                                          in migrations])
7611 
7612         inst_filters = {'deleted': True, 'soft_deleted': False,
7613                         'uuid': inst_uuid_from_migrations}
7614         attrs = ['info_cache', 'security_groups', 'system_metadata']
7615         with utils.temporary_mutation(context, read_deleted='yes'):
7616             instances = objects.InstanceList.get_by_filters(
7617                 context, inst_filters, expected_attrs=attrs, use_slave=True)
7618 
7619         for instance in instances:
7620             if instance.host != CONF.host:
7621                 for migration in migrations:
7622                     if instance.uuid == migration.instance_uuid:
7623                         # Delete instance files if not cleanup properly either
7624                         # from the source or destination compute nodes when
7625                         # the instance is deleted during resizing.
7626                         self.driver.delete_instance_files(instance)
7627                         try:
7628                             migration.status = 'failed'
7629                             with migration.obj_as_admin():
7630                                 migration.save()
7631                         except exception.MigrationNotFound:
7632                             LOG.warning("Migration %s is not found.",
7633                                         migration.id,
7634                                         instance=instance)
7635                         break
7636 
7637     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7638                                    exception.QemuGuestAgentNotEnabled,
7639                                    exception.NovaException,
7640                                    NotImplementedError)
7641     @wrap_exception()
7642     def quiesce_instance(self, context, instance):
7643         """Quiesce an instance on this host."""
7644         context = context.elevated()
7645         image_meta = objects.ImageMeta.from_instance(instance)
7646         self.driver.quiesce(context, instance, image_meta)
7647 
7648     def _wait_for_snapshots_completion(self, context, mapping):
7649         for mapping_dict in mapping:
7650             if mapping_dict.get('source_type') == 'snapshot':
7651 
7652                 def _wait_snapshot():
7653                     snapshot = self.volume_api.get_snapshot(
7654                         context, mapping_dict['snapshot_id'])
7655                     if snapshot.get('status') != 'creating':
7656                         raise loopingcall.LoopingCallDone()
7657 
7658                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
7659                 timer.start(interval=0.5).wait()
7660 
7661     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7662                                    exception.QemuGuestAgentNotEnabled,
7663                                    exception.NovaException,
7664                                    NotImplementedError)
7665     @wrap_exception()
7666     def unquiesce_instance(self, context, instance, mapping=None):
7667         """Unquiesce an instance on this host.
7668 
7669         If snapshots' image mapping is provided, it waits until snapshots are
7670         completed before unqueiscing.
7671         """
7672         context = context.elevated()
7673         if mapping:
7674             try:
7675                 self._wait_for_snapshots_completion(context, mapping)
7676             except Exception as error:
7677                 LOG.exception("Exception while waiting completion of "
7678                               "volume snapshots: %s",
7679                               error, instance=instance)
7680         image_meta = objects.ImageMeta.from_instance(instance)
7681         self.driver.unquiesce(context, instance, image_meta)
7682 
7683     @periodic_task.periodic_task(spacing=CONF.console_auth_cleanup_interval,
7684                                  run_immediately=True)
7685     def _cleanup_expired_console_auth_tokens(self, context):
7686         """Remove expired console auth tokens for this host.
7687 
7688         Console authorization tokens and their connection data are stored
7689         in the database when a user asks for a console connection to an
7690         instance. After a time they expire. We periodically remove any expired
7691         tokens from the database.
7692         """
7693         # If the database backend isn't in use, don't bother looking for
7694         # expired tokens.
7695         if not CONF.cells.enable:
7696             obj_console_connection.ConsoleConnection.\
7697                 clean_expired_console_auths_for_host(context, self.host)
