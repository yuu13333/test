Please review the code below to detect security defects. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are found, please state '''No security defects are detected in the code'''.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 from cursive import exception as cursive_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 from keystoneauth1 import exceptions as keystone_exception
44 from oslo_log import log as logging
45 import oslo_messaging as messaging
46 from oslo_serialization import jsonutils
47 from oslo_service import loopingcall
48 from oslo_service import periodic_task
49 from oslo_utils import excutils
50 from oslo_utils import strutils
51 from oslo_utils import timeutils
52 from oslo_utils import uuidutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova.console import rpcapi as console_rpcapi
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova import image
77 from nova import manager
78 from nova import network
79 from nova.network import base_api as base_net_api
80 from nova.network import model as network_model
81 from nova.network.security_group import openstack_driver
82 from nova import objects
83 from nova.objects import base as obj_base
84 from nova.objects import fields
85 from nova.objects import instance as obj_instance
86 from nova.objects import migrate_data as migrate_data_obj
87 from nova.pci import whitelist
88 from nova import rpc
89 from nova import safe_utils
90 from nova.scheduler import client as scheduler_client
91 from nova.scheduler import utils as scheduler_utils
92 from nova import utils
93 from nova.virt import block_device as driver_block_device
94 from nova.virt import configdrive
95 from nova.virt import driver
96 from nova.virt import event as virtevent
97 from nova.virt import storage_users
98 from nova.virt import virtapi
99 from nova.volume import cinder
100 
101 CONF = nova.conf.CONF
102 
103 LOG = logging.getLogger(__name__)
104 
105 get_notifier = functools.partial(rpc.get_notifier, service='compute')
106 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
107                                    get_notifier=get_notifier,
108                                    binary='nova-compute')
109 
110 
111 @contextlib.contextmanager
112 def errors_out_migration_ctxt(migration):
113     """Context manager to error out migration on failure."""
114 
115     try:
116         yield
117     except Exception:
118         with excutils.save_and_reraise_exception():
119             if migration:
120                 # We may have been passed None for our migration if we're
121                 # receiving from an older client. The migration will be
122                 # errored via the legacy path.
123                 migration.status = 'error'
124                 try:
125                     with migration.obj_as_admin():
126                         migration.save()
127                 except Exception:
128                     LOG.debug(
129                         'Error setting migration status for instance %s.',
130                         migration.instance_uuid, exc_info=True)
131 
132 
133 @utils.expects_func_args('migration')
134 def errors_out_migration(function):
135     """Decorator to error out migration on failure."""
136 
137     @functools.wraps(function)
138     def decorated_function(self, context, *args, **kwargs):
139         wrapped_func = safe_utils.get_wrapped_function(function)
140         keyed_args = inspect.getcallargs(wrapped_func, self, context,
141                                          *args, **kwargs)
142         migration = keyed_args['migration']
143         with errors_out_migration_ctxt(migration):
144             return function(self, context, *args, **kwargs)
145 
146     return decorated_function
147 
148 
149 @utils.expects_func_args('instance')
150 def reverts_task_state(function):
151     """Decorator to revert task_state on failure."""
152 
153     @functools.wraps(function)
154     def decorated_function(self, context, *args, **kwargs):
155         try:
156             return function(self, context, *args, **kwargs)
157         except exception.UnexpectedTaskStateError as e:
158             # Note(maoy): unexpected task state means the current
159             # task is preempted. Do not clear task state in this
160             # case.
161             with excutils.save_and_reraise_exception():
162                 LOG.info("Task possibly preempted: %s",
163                          e.format_message())
164         except Exception:
165             with excutils.save_and_reraise_exception():
166                 wrapped_func = safe_utils.get_wrapped_function(function)
167                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
168                                                  *args, **kwargs)
169                 # NOTE(mriedem): 'instance' must be in keyed_args because we
170                 # have utils.expects_func_args('instance') decorating this
171                 # method.
172                 instance = keyed_args['instance']
173                 original_task_state = instance.task_state
174                 try:
175                     self._instance_update(context, instance, task_state=None)
176                     LOG.info("Successfully reverted task state from %s on "
177                              "failure for instance.",
178                              original_task_state, instance=instance)
179                 except exception.InstanceNotFound:
180                     # We might delete an instance that failed to build shortly
181                     # after it errored out this is an expected case and we
182                     # should not trace on it.
183                     pass
184                 except Exception as e:
185                     LOG.warning("Failed to revert task state for instance. "
186                                 "Error: %s", e, instance=instance)
187 
188     return decorated_function
189 
190 
191 @utils.expects_func_args('instance')
192 def wrap_instance_fault(function):
193     """Wraps a method to catch exceptions related to instances.
194 
195     This decorator wraps a method to catch any exceptions having to do with
196     an instance that may get thrown. It then logs an instance fault in the db.
197     """
198 
199     @functools.wraps(function)
200     def decorated_function(self, context, *args, **kwargs):
201         try:
202             return function(self, context, *args, **kwargs)
203         except exception.InstanceNotFound:
204             raise
205         except Exception as e:
206             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
207             # we will get a KeyError exception which will cover up the real
208             # exception. So, we update kwargs with the values from args first.
209             # then, we can get 'instance' from kwargs easily.
210             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
211 
212             with excutils.save_and_reraise_exception():
213                 compute_utils.add_instance_fault_from_exc(context,
214                         kwargs['instance'], e, sys.exc_info())
215 
216     return decorated_function
217 
218 
219 @utils.expects_func_args('image_id', 'instance')
220 def delete_image_on_error(function):
221     """Used for snapshot related method to ensure the image created in
222     compute.api is deleted when an error occurs.
223     """
224 
225     @functools.wraps(function)
226     def decorated_function(self, context, image_id, instance,
227                            *args, **kwargs):
228         try:
229             return function(self, context, image_id, instance,
230                             *args, **kwargs)
231         except Exception:
232             with excutils.save_and_reraise_exception():
233                 LOG.debug("Cleaning up image %s", image_id,
234                           exc_info=True, instance=instance)
235                 try:
236                     self.image_api.delete(context, image_id)
237                 except exception.ImageNotFound:
238                     # Since we're trying to cleanup an image, we don't care if
239                     # if it's already gone.
240                     pass
241                 except Exception:
242                     LOG.exception("Error while trying to clean up image %s",
243                                   image_id, instance=instance)
244 
245     return decorated_function
246 
247 
248 # TODO(danms): Remove me after Icehouse
249 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
250 # NOTE(mikal): if the method being decorated has more than one decorator, then
251 # put this one first. Otherwise the various exception handling decorators do
252 # not function correctly.
253 def object_compat(function):
254     """Wraps a method that expects a new-world instance
255 
256     This provides compatibility for callers passing old-style dict
257     instances.
258     """
259 
260     @functools.wraps(function)
261     def decorated_function(self, context, *args, **kwargs):
262         def _load_instance(instance_or_dict):
263             if isinstance(instance_or_dict, dict):
264                 # try to get metadata and system_metadata for most cases but
265                 # only attempt to load those if the db instance already has
266                 # those fields joined
267                 metas = [meta for meta in ('metadata', 'system_metadata')
268                          if meta in instance_or_dict]
269                 instance = objects.Instance._from_db_object(
270                     context, objects.Instance(), instance_or_dict,
271                     expected_attrs=metas)
272                 instance._context = context
273                 return instance
274             return instance_or_dict
275 
276         try:
277             kwargs['instance'] = _load_instance(kwargs['instance'])
278         except KeyError:
279             args = (_load_instance(args[0]),) + args[1:]
280 
281         migration = kwargs.get('migration')
282         if isinstance(migration, dict):
283             migration = objects.Migration._from_db_object(
284                     context.elevated(), objects.Migration(),
285                     migration)
286             kwargs['migration'] = migration
287 
288         return function(self, context, *args, **kwargs)
289 
290     return decorated_function
291 
292 
293 class InstanceEvents(object):
294     def __init__(self):
295         self._events = {}
296 
297     @staticmethod
298     def _lock_name(instance):
299         return '%s-%s' % (instance.uuid, 'events')
300 
301     def prepare_for_instance_event(self, instance, event_name):
302         """Prepare to receive an event for an instance.
303 
304         This will register an event for the given instance that we will
305         wait on later. This should be called before initiating whatever
306         action will trigger the event. The resulting eventlet.event.Event
307         object should be wait()'d on to ensure completion.
308 
309         :param instance: the instance for which the event will be generated
310         :param event_name: the name of the event we're expecting
311         :returns: an event object that should be wait()'d on
312         """
313         if self._events is None:
314             # NOTE(danms): We really should have a more specific error
315             # here, but this is what we use for our default error case
316             raise exception.NovaException('In shutdown, no new events '
317                                           'can be scheduled')
318 
319         @utils.synchronized(self._lock_name(instance))
320         def _create_or_get_event():
321             instance_events = self._events.setdefault(instance.uuid, {})
322             return instance_events.setdefault(event_name,
323                                               eventlet.event.Event())
324         LOG.debug('Preparing to wait for external event %(event)s',
325                   {'event': event_name}, instance=instance)
326         return _create_or_get_event()
327 
328     def pop_instance_event(self, instance, event):
329         """Remove a pending event from the wait list.
330 
331         This will remove a pending event from the wait list so that it
332         can be used to signal the waiters to wake up.
333 
334         :param instance: the instance for which the event was generated
335         :param event: the nova.objects.external_event.InstanceExternalEvent
336                       that describes the event
337         :returns: the eventlet.event.Event object on which the waiters
338                   are blocked
339         """
340         no_events_sentinel = object()
341         no_matching_event_sentinel = object()
342 
343         @utils.synchronized(self._lock_name(instance))
344         def _pop_event():
345             if not self._events:
346                 LOG.debug('Unexpected attempt to pop events during shutdown',
347                           instance=instance)
348                 return no_events_sentinel
349             events = self._events.get(instance.uuid)
350             if not events:
351                 return no_events_sentinel
352             _event = events.pop(event.key, None)
353             if not events:
354                 del self._events[instance.uuid]
355             if _event is None:
356                 return no_matching_event_sentinel
357             return _event
358 
359         result = _pop_event()
360         if result is no_events_sentinel:
361             LOG.debug('No waiting events found dispatching %(event)s',
362                       {'event': event.key},
363                       instance=instance)
364             return None
365         elif result is no_matching_event_sentinel:
366             LOG.debug('No event matching %(event)s in %(events)s',
367                       {'event': event.key,
368                        'events': self._events.get(instance.uuid, {}).keys()},
369                       instance=instance)
370             return None
371         else:
372             return result
373 
374     def clear_events_for_instance(self, instance):
375         """Remove all pending events for an instance.
376 
377         This will remove all events currently pending for an instance
378         and return them (indexed by event name).
379 
380         :param instance: the instance for which events should be purged
381         :returns: a dictionary of {event_name: eventlet.event.Event}
382         """
383         @utils.synchronized(self._lock_name(instance))
384         def _clear_events():
385             if self._events is None:
386                 LOG.debug('Unexpected attempt to clear events during shutdown',
387                           instance=instance)
388                 return dict()
389             return self._events.pop(instance.uuid, {})
390         return _clear_events()
391 
392     def cancel_all_events(self):
393         if self._events is None:
394             LOG.debug('Unexpected attempt to cancel events during shutdown.')
395             return
396         our_events = self._events
397         # NOTE(danms): Block new events
398         self._events = None
399 
400         for instance_uuid, events in our_events.items():
401             for event_name, eventlet_event in events.items():
402                 LOG.debug('Canceling in-flight event %(event)s for '
403                           'instance %(instance_uuid)s',
404                           {'event': event_name,
405                            'instance_uuid': instance_uuid})
406                 name, tag = event_name.rsplit('-', 1)
407                 event = objects.InstanceExternalEvent(
408                     instance_uuid=instance_uuid,
409                     name=name, status='failed',
410                     tag=tag, data={})
411                 eventlet_event.send(event)
412 
413 
414 class ComputeVirtAPI(virtapi.VirtAPI):
415     def __init__(self, compute):
416         super(ComputeVirtAPI, self).__init__()
417         self._compute = compute
418 
419     def _default_error_callback(self, event_name, instance):
420         raise exception.NovaException(_('Instance event failed'))
421 
422     @contextlib.contextmanager
423     def wait_for_instance_event(self, instance, event_names, deadline=300,
424                                 error_callback=None):
425         """Plan to wait for some events, run some code, then wait.
426 
427         This context manager will first create plans to wait for the
428         provided event_names, yield, and then wait for all the scheduled
429         events to complete.
430 
431         Note that this uses an eventlet.timeout.Timeout to bound the
432         operation, so callers should be prepared to catch that
433         failure and handle that situation appropriately.
434 
435         If the event is not received by the specified timeout deadline,
436         eventlet.timeout.Timeout is raised.
437 
438         If the event is received but did not have a 'completed'
439         status, a NovaException is raised.  If an error_callback is
440         provided, instead of raising an exception as detailed above
441         for the failure case, the callback will be called with the
442         event_name and instance, and can return True to continue
443         waiting for the rest of the events, False to stop processing,
444         or raise an exception which will bubble up to the waiter.
445 
446         :param instance: The instance for which an event is expected
447         :param event_names: A list of event names. Each element can be a
448                             string event name or tuple of strings to
449                             indicate (name, tag).
450         :param deadline: Maximum number of seconds we should wait for all
451                          of the specified events to arrive.
452         :param error_callback: A function to be called if an event arrives
453 
454         """
455 
456         if error_callback is None:
457             error_callback = self._default_error_callback
458         events = {}
459         for event_name in event_names:
460             if isinstance(event_name, tuple):
461                 name, tag = event_name
462                 event_name = objects.InstanceExternalEvent.make_key(
463                     name, tag)
464             try:
465                 events[event_name] = (
466                     self._compute.instance_events.prepare_for_instance_event(
467                         instance, event_name))
468             except exception.NovaException:
469                 error_callback(event_name, instance)
470                 # NOTE(danms): Don't wait for any of the events. They
471                 # should all be canceled and fired immediately below,
472                 # but don't stick around if not.
473                 deadline = 0
474         yield
475         with eventlet.timeout.Timeout(deadline):
476             for event_name, event in events.items():
477                 actual_event = event.wait()
478                 if actual_event.status == 'completed':
479                     continue
480                 decision = error_callback(event_name, instance)
481                 if decision is False:
482                     break
483 
484 
485 class ComputeManager(manager.Manager):
486     """Manages the running instances from creation to destruction."""
487 
488     target = messaging.Target(version='4.19')
489 
490     # How long to wait in seconds before re-issuing a shutdown
491     # signal to an instance during power off.  The overall
492     # time to wait is set by CONF.shutdown_timeout.
493     SHUTDOWN_RETRY_INTERVAL = 10
494 
495     def __init__(self, compute_driver=None, *args, **kwargs):
496         """Load configuration options and connect to the hypervisor."""
497         self.virtapi = ComputeVirtAPI(self)
498         self.network_api = network.API()
499         self.volume_api = cinder.API()
500         self.image_api = image.API()
501         self._last_host_check = 0
502         self._last_bw_usage_poll = 0
503         self._bw_usage_supported = True
504         self._last_bw_usage_cell_update = 0
505         self.compute_api = compute.API()
506         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
507         self.conductor_api = conductor.API()
508         self.compute_task_api = conductor.ComputeTaskAPI()
509         self.is_neutron_security_groups = (
510             openstack_driver.is_neutron_security_groups())
511         self.cells_rpcapi = cells_rpcapi.CellsAPI()
512         self.scheduler_client = scheduler_client.SchedulerClient()
513         self.reportclient = self.scheduler_client.reportclient
514         self._resource_tracker = None
515         self.instance_events = InstanceEvents()
516         self._sync_power_pool = eventlet.GreenPool(
517             size=CONF.sync_power_state_pool_size)
518         self._syncs_in_progress = {}
519         self.send_instance_updates = (
520             CONF.filter_scheduler.track_instance_changes)
521         if CONF.max_concurrent_builds != 0:
522             self._build_semaphore = eventlet.semaphore.Semaphore(
523                 CONF.max_concurrent_builds)
524         else:
525             self._build_semaphore = compute_utils.UnlimitedSemaphore()
526         if max(CONF.max_concurrent_live_migrations, 0) != 0:
527             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
528                 CONF.max_concurrent_live_migrations)
529         else:
530             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
531         self._failed_builds = 0
532 
533         super(ComputeManager, self).__init__(service_name="compute",
534                                              *args, **kwargs)
535 
536         # NOTE(russellb) Load the driver last.  It may call back into the
537         # compute manager via the virtapi, so we want it to be fully
538         # initialized before that happens.
539         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
540         self.use_legacy_block_device_info = \
541                             self.driver.need_legacy_block_device_info
542 
543     def reset(self):
544         LOG.info('Reloading compute RPC API')
545         compute_rpcapi.LAST_VERSION = None
546         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
547 
548     def _get_resource_tracker(self):
549         if not self._resource_tracker:
550             rt = resource_tracker.ResourceTracker(self.host, self.driver)
551             self._resource_tracker = rt
552         return self._resource_tracker
553 
554     def _update_resource_tracker(self, context, instance):
555         """Let the resource tracker know that an instance has changed state."""
556 
557         if instance.host == self.host:
558             rt = self._get_resource_tracker()
559             rt.update_usage(context, instance, instance.node)
560 
561     def _instance_update(self, context, instance, **kwargs):
562         """Update an instance in the database using kwargs as value."""
563 
564         for k, v in kwargs.items():
565             setattr(instance, k, v)
566         instance.save()
567         self._update_resource_tracker(context, instance)
568 
569     def _nil_out_instance_obj_host_and_node(self, instance):
570         # NOTE(jwcroppe): We don't do instance.save() here for performance
571         # reasons; a call to this is expected to be immediately followed by
572         # another call that does instance.save(), thus avoiding two writes
573         # to the database layer.
574         instance.host = None
575         instance.node = None
576 
577     def _set_instance_obj_error_state(self, context, instance,
578                                       clean_task_state=False):
579         try:
580             instance.vm_state = vm_states.ERROR
581             if clean_task_state:
582                 instance.task_state = None
583             instance.save()
584         except exception.InstanceNotFound:
585             LOG.debug('Instance has been destroyed from under us while '
586                       'trying to set it to ERROR', instance=instance)
587 
588     def _get_instances_on_driver(self, context, filters=None):
589         """Return a list of instance records for the instances found
590         on the hypervisor which satisfy the specified filters. If filters=None
591         return a list of instance records for all the instances found on the
592         hypervisor.
593         """
594         if not filters:
595             filters = {}
596         try:
597             driver_uuids = self.driver.list_instance_uuids()
598             if len(driver_uuids) == 0:
599                 # Short circuit, don't waste a DB call
600                 return objects.InstanceList()
601             filters['uuid'] = driver_uuids
602             local_instances = objects.InstanceList.get_by_filters(
603                 context, filters, use_slave=True)
604             return local_instances
605         except NotImplementedError:
606             pass
607 
608         # The driver doesn't support uuids listing, so we'll have
609         # to brute force.
610         driver_instances = self.driver.list_instances()
611         # NOTE(mjozefcz): In this case we need to apply host filter.
612         # Without this all instance data would be fetched from db.
613         filters['host'] = self.host
614         instances = objects.InstanceList.get_by_filters(context, filters,
615                                                         use_slave=True)
616         name_map = {instance.name: instance for instance in instances}
617         local_instances = []
618         for driver_instance in driver_instances:
619             instance = name_map.get(driver_instance)
620             if not instance:
621                 continue
622             local_instances.append(instance)
623         return local_instances
624 
625     def _destroy_evacuated_instances(self, context):
626         """Destroys evacuated instances.
627 
628         While nova-compute was down, the instances running on it could be
629         evacuated to another host. This method looks for evacuation migration
630         records where this is the source host and which were either started
631         (accepted) or complete (done). From those migration records, local
632         instances reported by the hypervisor are compared to the instances
633         for the migration records and those local guests are destroyed, along
634         with instance allocation records in Placement for this node.
635         """
636         filters = {
637             'source_compute': self.host,
638             # NOTE(mriedem): Migration records that have been accepted are
639             # included in case the source node comes back up while instances
640             # are being evacuated to another host. We don't want the same
641             # instance being reported from multiple hosts.
642             'status': ['accepted', 'done'],
643             'migration_type': 'evacuation',
644         }
645         with utils.temporary_mutation(context, read_deleted='yes'):
646             evacuations = objects.MigrationList.get_by_filters(context,
647                                                                filters)
648         if not evacuations:
649             return
650         evacuations = {mig.instance_uuid: mig for mig in evacuations}
651 
652         local_instances = self._get_instances_on_driver(context)
653         evacuated = [inst for inst in local_instances
654                      if inst.uuid in evacuations]
655 
656         # NOTE(gibi): We are called from init_host and at this point the
657         # compute_nodes of the resource tracker has not been populated yet so
658         # we cannot rely on the resource tracker here.
659         compute_nodes = {}
660 
661         for instance in evacuated:
662             migration = evacuations[instance.uuid]
663             LOG.info('Deleting instance as it has been evacuated from '
664                      'this host', instance=instance)
665             try:
666                 network_info = self.network_api.get_instance_nw_info(
667                     context, instance)
668                 bdi = self._get_instance_block_device_info(context,
669                                                            instance)
670                 destroy_disks = not (self._is_instance_storage_shared(
671                     context, instance))
672             except exception.InstanceNotFound:
673                 network_info = network_model.NetworkInfo()
674                 bdi = {}
675                 LOG.info('Instance has been marked deleted already, '
676                          'removing it from the hypervisor.',
677                          instance=instance)
678                 # always destroy disks if the instance was deleted
679                 destroy_disks = True
680             self.driver.destroy(context, instance,
681                                 network_info,
682                                 bdi, destroy_disks)
683 
684             # delete the allocation of the evacuated instance from this host
685             if migration.source_node not in compute_nodes:
686                 try:
687                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
688                         context, self.host, migration.source_node).uuid
689                     compute_nodes[migration.source_node] = cn_uuid
690                 except exception.ComputeHostNotFound:
691                     LOG.error("Failed to clean allocation of evacuated "
692                               "instance as the source node %s is not found",
693                               migration.source_node, instance=instance)
694                     continue
695             cn_uuid = compute_nodes[migration.source_node]
696 
697             my_resources = scheduler_utils.resources_from_flavor(
698                 instance, instance.flavor)
699             res = self.reportclient.remove_provider_from_instance_allocation(
700                 instance.uuid, cn_uuid, instance.user_id,
701                 instance.project_id, my_resources)
702             if not res:
703                 LOG.error("Failed to clean allocation of evacuated instance "
704                           "on the source node %s",
705                           cn_uuid, instance=instance)
706 
707             migration.status = 'completed'
708             migration.save()
709 
710     def _is_instance_storage_shared(self, context, instance, host=None):
711         shared_storage = True
712         data = None
713         try:
714             data = self.driver.check_instance_shared_storage_local(context,
715                                                        instance)
716             if data:
717                 shared_storage = (self.compute_rpcapi.
718                                   check_instance_shared_storage(context,
719                                   instance, data, host=host))
720         except NotImplementedError:
721             LOG.debug('Hypervisor driver does not support '
722                       'instance shared storage check, '
723                       'assuming it\'s not on shared storage',
724                       instance=instance)
725             shared_storage = False
726         except Exception:
727             LOG.exception('Failed to check if instance shared',
728                           instance=instance)
729         finally:
730             if data:
731                 self.driver.check_instance_shared_storage_cleanup(context,
732                                                                   data)
733         return shared_storage
734 
735     def _complete_partial_deletion(self, context, instance):
736         """Complete deletion for instances in DELETED status but not marked as
737         deleted in the DB
738         """
739         system_meta = instance.system_metadata
740         instance.destroy()
741         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
742                 context, instance.uuid)
743         self._complete_deletion(context,
744                                 instance,
745                                 bdms,
746                                 system_meta)
747 
748     def _complete_deletion(self, context, instance, bdms,
749                            system_meta):
750         self._update_resource_tracker(context, instance)
751 
752         rt = self._get_resource_tracker()
753         rt.reportclient.delete_allocation_for_instance(instance.uuid)
754 
755         self._notify_about_instance_usage(context, instance, "delete.end",
756                 system_metadata=system_meta)
757         compute_utils.notify_about_instance_action(context, instance,
758                 self.host, action=fields.NotificationAction.DELETE,
759                 phase=fields.NotificationPhase.END, bdms=bdms)
760         self._delete_scheduler_instance_info(context, instance.uuid)
761 
762     def _init_instance(self, context, instance):
763         """Initialize this instance during service init."""
764 
765         # NOTE(danms): If the instance appears to not be owned by this
766         # host, it may have been evacuated away, but skipped by the
767         # evacuation cleanup code due to configuration. Thus, if that
768         # is a possibility, don't touch the instance in any way, but
769         # log the concern. This will help avoid potential issues on
770         # startup due to misconfiguration.
771         if instance.host != self.host:
772             LOG.warning('Instance %(uuid)s appears to not be owned '
773                         'by this host, but by %(host)s. Startup '
774                         'processing is being skipped.',
775                         {'uuid': instance.uuid,
776                          'host': instance.host})
777             return
778 
779         # Instances that are shut down, or in an error state can not be
780         # initialized and are not attempted to be recovered. The exception
781         # to this are instances that are in RESIZE_MIGRATING or DELETING,
782         # which are dealt with further down.
783         if (instance.vm_state == vm_states.SOFT_DELETED or
784             (instance.vm_state == vm_states.ERROR and
785             instance.task_state not in
786             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
787             LOG.debug("Instance is in %s state.",
788                       instance.vm_state, instance=instance)
789             return
790 
791         if instance.vm_state == vm_states.DELETED:
792             try:
793                 self._complete_partial_deletion(context, instance)
794             except Exception:
795                 # we don't want that an exception blocks the init_host
796                 LOG.exception('Failed to complete a deletion',
797                               instance=instance)
798             return
799 
800         if (instance.vm_state == vm_states.BUILDING or
801             instance.task_state in [task_states.SCHEDULING,
802                                     task_states.BLOCK_DEVICE_MAPPING,
803                                     task_states.NETWORKING,
804                                     task_states.SPAWNING]):
805             # NOTE(dave-mcnally) compute stopped before instance was fully
806             # spawned so set to ERROR state. This is safe to do as the state
807             # may be set by the api but the host is not so if we get here the
808             # instance has already been scheduled to this particular host.
809             LOG.debug("Instance failed to spawn correctly, "
810                       "setting to ERROR state", instance=instance)
811             instance.task_state = None
812             instance.vm_state = vm_states.ERROR
813             instance.save()
814             return
815 
816         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
817             instance.task_state in [task_states.REBUILDING,
818                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
819                                     task_states.REBUILD_SPAWNING]):
820             # NOTE(jichenjc) compute stopped before instance was fully
821             # spawned so set to ERROR state. This is consistent to BUILD
822             LOG.debug("Instance failed to rebuild correctly, "
823                       "setting to ERROR state", instance=instance)
824             instance.task_state = None
825             instance.vm_state = vm_states.ERROR
826             instance.save()
827             return
828 
829         if (instance.vm_state != vm_states.ERROR and
830             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
831                                     task_states.IMAGE_PENDING_UPLOAD,
832                                     task_states.IMAGE_UPLOADING,
833                                     task_states.IMAGE_SNAPSHOT]):
834             LOG.debug("Instance in transitional state %s at start-up "
835                       "clearing task state",
836                       instance.task_state, instance=instance)
837             try:
838                 self._post_interrupted_snapshot_cleanup(context, instance)
839             except Exception:
840                 # we don't want that an exception blocks the init_host
841                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
842             instance.task_state = None
843             instance.save()
844 
845         if (instance.vm_state != vm_states.ERROR and
846             instance.task_state in [task_states.RESIZE_PREP]):
847             LOG.debug("Instance in transitional state %s at start-up "
848                       "clearing task state",
849                       instance['task_state'], instance=instance)
850             instance.task_state = None
851             instance.save()
852 
853         if instance.task_state == task_states.DELETING:
854             try:
855                 LOG.info('Service started deleting the instance during '
856                          'the previous run, but did not finish. Restarting'
857                          ' the deletion now.', instance=instance)
858                 instance.obj_load_attr('metadata')
859                 instance.obj_load_attr('system_metadata')
860                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
861                         context, instance.uuid)
862                 self._delete_instance(context, instance, bdms)
863             except Exception:
864                 # we don't want that an exception blocks the init_host
865                 LOG.exception('Failed to complete a deletion',
866                               instance=instance)
867                 self._set_instance_obj_error_state(context, instance)
868             return
869 
870         current_power_state = self._get_power_state(context, instance)
871         try_reboot, reboot_type = self._retry_reboot(context, instance,
872                                                      current_power_state)
873 
874         if try_reboot:
875             LOG.debug("Instance in transitional state (%(task_state)s) at "
876                       "start-up and power state is (%(power_state)s), "
877                       "triggering reboot",
878                       {'task_state': instance.task_state,
879                        'power_state': current_power_state},
880                       instance=instance)
881 
882             # NOTE(mikal): if the instance was doing a soft reboot that got as
883             # far as shutting down the instance but not as far as starting it
884             # again, then we've just become a hard reboot. That means the
885             # task state for the instance needs to change so that we're in one
886             # of the expected task states for a hard reboot.
887             if (instance.task_state in task_states.soft_reboot_states and
888                 reboot_type == 'HARD'):
889                 instance.task_state = task_states.REBOOT_PENDING_HARD
890                 instance.save()
891 
892             self.reboot_instance(context, instance, block_device_info=None,
893                                  reboot_type=reboot_type)
894             return
895 
896         elif (current_power_state == power_state.RUNNING and
897               instance.task_state in [task_states.REBOOT_STARTED,
898                                       task_states.REBOOT_STARTED_HARD,
899                                       task_states.PAUSING,
900                                       task_states.UNPAUSING]):
901             LOG.warning("Instance in transitional state "
902                         "(%(task_state)s) at start-up and power state "
903                         "is (%(power_state)s), clearing task state",
904                         {'task_state': instance.task_state,
905                          'power_state': current_power_state},
906                         instance=instance)
907             instance.task_state = None
908             instance.vm_state = vm_states.ACTIVE
909             instance.save()
910         elif (current_power_state == power_state.PAUSED and
911               instance.task_state == task_states.UNPAUSING):
912             LOG.warning("Instance in transitional state "
913                         "(%(task_state)s) at start-up and power state "
914                         "is (%(power_state)s), clearing task state "
915                         "and unpausing the instance",
916                         {'task_state': instance.task_state,
917                          'power_state': current_power_state},
918                         instance=instance)
919             try:
920                 self.unpause_instance(context, instance)
921             except NotImplementedError:
922                 # Some virt driver didn't support pause and unpause
923                 pass
924             except Exception:
925                 LOG.exception('Failed to unpause instance', instance=instance)
926             return
927 
928         if instance.task_state == task_states.POWERING_OFF:
929             try:
930                 LOG.debug("Instance in transitional state %s at start-up "
931                           "retrying stop request",
932                           instance.task_state, instance=instance)
933                 self.stop_instance(context, instance, True)
934             except Exception:
935                 # we don't want that an exception blocks the init_host
936                 LOG.exception('Failed to stop instance', instance=instance)
937             return
938 
939         if instance.task_state == task_states.POWERING_ON:
940             try:
941                 LOG.debug("Instance in transitional state %s at start-up "
942                           "retrying start request",
943                           instance.task_state, instance=instance)
944                 self.start_instance(context, instance)
945             except Exception:
946                 # we don't want that an exception blocks the init_host
947                 LOG.exception('Failed to start instance', instance=instance)
948             return
949 
950         net_info = instance.get_network_info()
951         try:
952             self.driver.plug_vifs(instance, net_info)
953         except NotImplementedError as e:
954             LOG.debug(e, instance=instance)
955         except exception.VirtualInterfacePlugException:
956             # we don't want an exception to block the init_host
957             LOG.exception("Vifs plug failed", instance=instance)
958             self._set_instance_obj_error_state(context, instance)
959             return
960 
961         if instance.task_state == task_states.RESIZE_MIGRATING:
962             # We crashed during resize/migration, so roll back for safety
963             try:
964                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
965                 # not in system_metadata we default to True for backwards
966                 # compatibility
967                 power_on = (instance.system_metadata.get('old_vm_state') !=
968                             vm_states.STOPPED)
969 
970                 block_dev_info = self._get_instance_block_device_info(context,
971                                                                       instance)
972 
973                 self.driver.finish_revert_migration(context,
974                     instance, net_info, block_dev_info, power_on)
975 
976             except Exception:
977                 LOG.exception('Failed to revert crashed migration',
978                               instance=instance)
979             finally:
980                 LOG.info('Instance found in migrating state during '
981                          'startup. Resetting task_state',
982                          instance=instance)
983                 instance.task_state = None
984                 instance.save()
985         if instance.task_state == task_states.MIGRATING:
986             # Live migration did not complete, but instance is on this
987             # host, so reset the state.
988             instance.task_state = None
989             instance.save(expected_task_state=[task_states.MIGRATING])
990 
991         db_state = instance.power_state
992         drv_state = self._get_power_state(context, instance)
993         expect_running = (db_state == power_state.RUNNING and
994                           drv_state != db_state)
995 
996         LOG.debug('Current state is %(drv_state)s, state in DB is '
997                   '%(db_state)s.',
998                   {'drv_state': drv_state, 'db_state': db_state},
999                   instance=instance)
1000 
1001         if expect_running and CONF.resume_guests_state_on_host_boot:
1002             self._resume_guests_state(context, instance, net_info)
1003         elif drv_state == power_state.RUNNING:
1004             # VMwareAPI drivers will raise an exception
1005             try:
1006                 self.driver.ensure_filtering_rules_for_instance(
1007                                        instance, net_info)
1008             except NotImplementedError:
1009                 LOG.debug('Hypervisor driver does not support '
1010                           'firewall rules', instance=instance)
1011 
1012     def _resume_guests_state(self, context, instance, net_info):
1013         LOG.info('Rebooting instance after nova-compute restart.',
1014                  instance=instance)
1015         block_device_info = \
1016             self._get_instance_block_device_info(context, instance)
1017 
1018         try:
1019             self.driver.resume_state_on_host_boot(
1020                 context, instance, net_info, block_device_info)
1021         except NotImplementedError:
1022             LOG.warning('Hypervisor driver does not support '
1023                         'resume guests', instance=instance)
1024         except Exception:
1025             # NOTE(vish): The instance failed to resume, so we set the
1026             #             instance to error and attempt to continue.
1027             LOG.warning('Failed to resume instance',
1028                         instance=instance)
1029             self._set_instance_obj_error_state(context, instance)
1030 
1031     def _retry_reboot(self, context, instance, current_power_state):
1032         current_task_state = instance.task_state
1033         retry_reboot = False
1034         reboot_type = compute_utils.get_reboot_type(current_task_state,
1035                                                     current_power_state)
1036 
1037         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1038                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1039         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1040                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1041         started_not_running = (current_task_state in
1042                                [task_states.REBOOT_STARTED,
1043                                 task_states.REBOOT_STARTED_HARD] and
1044                                current_power_state != power_state.RUNNING)
1045 
1046         if pending_soft or pending_hard or started_not_running:
1047             retry_reboot = True
1048 
1049         return retry_reboot, reboot_type
1050 
1051     def handle_lifecycle_event(self, event):
1052         LOG.info("VM %(state)s (Lifecycle Event)",
1053                  {'state': event.get_name()},
1054                  instance_uuid=event.get_instance_uuid())
1055         context = nova.context.get_admin_context(read_deleted='yes')
1056         instance = objects.Instance.get_by_uuid(context,
1057                                                 event.get_instance_uuid(),
1058                                                 expected_attrs=[])
1059         vm_power_state = None
1060         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1061             vm_power_state = power_state.SHUTDOWN
1062         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1063             vm_power_state = power_state.RUNNING
1064         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1065             vm_power_state = power_state.PAUSED
1066         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1067             vm_power_state = power_state.RUNNING
1068         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1069             vm_power_state = power_state.SUSPENDED
1070         else:
1071             LOG.warning("Unexpected power state %d", event.get_transition())
1072 
1073         # Note(lpetrut): The event may be delayed, thus not reflecting
1074         # the current instance power state. In that case, ignore the event.
1075         current_power_state = self._get_power_state(context, instance)
1076         if current_power_state == vm_power_state:
1077             LOG.debug('Synchronizing instance power state after lifecycle '
1078                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1079                       'current task_state: %(task_state)s, current DB '
1080                       'power_state: %(db_power_state)s, VM power_state: '
1081                       '%(vm_power_state)s',
1082                       {'event': event.get_name(),
1083                        'vm_state': instance.vm_state,
1084                        'task_state': instance.task_state,
1085                        'db_power_state': instance.power_state,
1086                        'vm_power_state': vm_power_state},
1087                       instance_uuid=instance.uuid)
1088             self._sync_instance_power_state(context,
1089                                             instance,
1090                                             vm_power_state)
1091 
1092     def handle_events(self, event):
1093         if isinstance(event, virtevent.LifecycleEvent):
1094             try:
1095                 self.handle_lifecycle_event(event)
1096             except exception.InstanceNotFound:
1097                 LOG.debug("Event %s arrived for non-existent instance. The "
1098                           "instance was probably deleted.", event)
1099         else:
1100             LOG.debug("Ignoring event %s", event)
1101 
1102     def init_virt_events(self):
1103         if CONF.workarounds.handle_virt_lifecycle_events:
1104             self.driver.register_event_listener(self.handle_events)
1105         else:
1106             # NOTE(mriedem): If the _sync_power_states periodic task is
1107             # disabled we should emit a warning in the logs.
1108             if CONF.sync_power_state_interval < 0:
1109                 LOG.warning('Instance lifecycle events from the compute '
1110                             'driver have been disabled. Note that lifecycle '
1111                             'changes to an instance outside of the compute '
1112                             'service will not be synchronized '
1113                             'automatically since the _sync_power_states '
1114                             'periodic task is also disabled.')
1115             else:
1116                 LOG.info('Instance lifecycle events from the compute '
1117                          'driver have been disabled. Note that lifecycle '
1118                          'changes to an instance outside of the compute '
1119                          'service will only be synchronized by the '
1120                          '_sync_power_states periodic task.')
1121 
1122     def init_host(self):
1123         """Initialization for a standalone compute service."""
1124 
1125         if CONF.pci.passthrough_whitelist:
1126             # Simply loading the PCI passthrough whitelist will do a bunch of
1127             # validation that would otherwise wait until the PciDevTracker is
1128             # constructed when updating available resources for the compute
1129             # node(s) in the resource tracker, effectively killing that task.
1130             # So load up the whitelist when starting the compute service to
1131             # flush any invalid configuration early so we can kill the service
1132             # if the configuration is wrong.
1133             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1134 
1135         # NOTE(sbauza): We want the compute node to hard fail if it won't be
1136         # able to provide its resources to the placement API, or it will not
1137         # be able to be eligible as a destination.
1138         if CONF.placement.os_region_name is None:
1139             raise exception.PlacementNotConfigured()
1140 
1141         self.driver.init_host(host=self.host)
1142         context = nova.context.get_admin_context()
1143         instances = objects.InstanceList.get_by_host(
1144             context, self.host, expected_attrs=['info_cache', 'metadata'])
1145 
1146         if CONF.defer_iptables_apply:
1147             self.driver.filter_defer_apply_on()
1148 
1149         self.init_virt_events()
1150 
1151         try:
1152             # checking that instance was not already evacuated to other host
1153             self._destroy_evacuated_instances(context)
1154             for instance in instances:
1155                 self._init_instance(context, instance)
1156         finally:
1157             if CONF.defer_iptables_apply:
1158                 self.driver.filter_defer_apply_off()
1159             if instances:
1160                 # We only send the instance info to the scheduler on startup
1161                 # if there is anything to send, otherwise this host might
1162                 # not be mapped yet in a cell and the scheduler may have
1163                 # issues dealing with the information. Later changes to
1164                 # instances on this host will update the scheduler, or the
1165                 # _sync_scheduler_instance_info periodic task will.
1166                 self._update_scheduler_instance_info(context, instances)
1167 
1168     def cleanup_host(self):
1169         self.driver.register_event_listener(None)
1170         self.instance_events.cancel_all_events()
1171         self.driver.cleanup_host(host=self.host)
1172 
1173     def pre_start_hook(self):
1174         """After the service is initialized, but before we fully bring
1175         the service up by listening on RPC queues, make sure to update
1176         our available resources (and indirectly our available nodes).
1177         """
1178         self.update_available_resource(nova.context.get_admin_context(),
1179                                        startup=True)
1180 
1181     def _get_power_state(self, context, instance):
1182         """Retrieve the power state for the given instance."""
1183         LOG.debug('Checking state', instance=instance)
1184         try:
1185             return self.driver.get_info(instance).state
1186         except exception.InstanceNotFound:
1187             return power_state.NOSTATE
1188 
1189     def get_console_topic(self, context):
1190         """Retrieves the console host for a project on this host.
1191 
1192         Currently this is just set in the flags for each compute host.
1193 
1194         """
1195         # TODO(mdragon): perhaps make this variable by console_type?
1196         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1197 
1198     @wrap_exception()
1199     def get_console_pool_info(self, context, console_type):
1200         return self.driver.get_console_pool_info(console_type)
1201 
1202     # NOTE(hanlind): This and the virt method it calls can be removed in
1203     # version 5.0 of the RPC API
1204     @wrap_exception()
1205     def refresh_security_group_rules(self, context, security_group_id):
1206         """Tell the virtualization driver to refresh security group rules.
1207 
1208         Passes straight through to the virtualization driver.
1209 
1210         """
1211         return self.driver.refresh_security_group_rules(security_group_id)
1212 
1213     # TODO(alaski): Remove object_compat for RPC version 5.0
1214     @object_compat
1215     @wrap_exception()
1216     def refresh_instance_security_rules(self, context, instance):
1217         """Tell the virtualization driver to refresh security rules for
1218         an instance.
1219 
1220         Passes straight through to the virtualization driver.
1221 
1222         Synchronize the call because we may still be in the middle of
1223         creating the instance.
1224         """
1225         @utils.synchronized(instance.uuid)
1226         def _sync_refresh():
1227             try:
1228                 return self.driver.refresh_instance_security_rules(instance)
1229             except NotImplementedError:
1230                 LOG.debug('Hypervisor driver does not support '
1231                           'security groups.', instance=instance)
1232 
1233         return _sync_refresh()
1234 
1235     def _await_block_device_map_created(self, context, vol_id):
1236         # TODO(yamahata): creating volume simultaneously
1237         #                 reduces creation time?
1238         # TODO(yamahata): eliminate dumb polling
1239         start = time.time()
1240         retries = CONF.block_device_allocate_retries
1241         if retries < 0:
1242             LOG.warning("Treating negative config value (%(retries)s) for "
1243                         "'block_device_retries' as 0.",
1244                         {'retries': retries})
1245         # (1) treat  negative config value as 0
1246         # (2) the configured value is 0, one attempt should be made
1247         # (3) the configured value is > 0, then the total number attempts
1248         #      is (retries + 1)
1249         attempts = 1
1250         if retries >= 1:
1251             attempts = retries + 1
1252         for attempt in range(1, attempts + 1):
1253             volume = self.volume_api.get(context, vol_id)
1254             volume_status = volume['status']
1255             if volume_status not in ['creating', 'downloading']:
1256                 if volume_status == 'available':
1257                     return attempt
1258                 LOG.warning("Volume id: %(vol_id)s finished being "
1259                             "created but its status is %(vol_status)s.",
1260                             {'vol_id': vol_id,
1261                              'vol_status': volume_status})
1262                 break
1263             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1264         raise exception.VolumeNotCreated(volume_id=vol_id,
1265                                          seconds=int(time.time() - start),
1266                                          attempts=attempt,
1267                                          volume_status=volume_status)
1268 
1269     def _decode_files(self, injected_files):
1270         """Base64 decode the list of files to inject."""
1271         if not injected_files:
1272             return []
1273 
1274         def _decode(f):
1275             path, contents = f
1276             # Py3 raises binascii.Error instead of TypeError as in Py27
1277             try:
1278                 decoded = base64.b64decode(contents)
1279                 return path, decoded
1280             except (TypeError, binascii.Error):
1281                 raise exception.Base64Exception(path=path)
1282 
1283         return [_decode(f) for f in injected_files]
1284 
1285     def _validate_instance_group_policy(self, context, instance,
1286                                         scheduler_hints):
1287         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1288         # However, there is a race condition with the enforcement of
1289         # the policy.  Since more than one instance may be scheduled at the
1290         # same time, it's possible that more than one instance with an
1291         # anti-affinity policy may end up here.  It's also possible that
1292         # multiple instances with an affinity policy could end up on different
1293         # hosts.  This is a validation step to make sure that starting the
1294         # instance here doesn't violate the policy.
1295         group_hint = scheduler_hints.get('group')
1296         if not group_hint:
1297             return
1298 
1299         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1300         # to check the type on the value and pull the single entry out. The
1301         # API request schema validates that the 'group' hint is a single value.
1302         if isinstance(group_hint, list):
1303             group_hint = group_hint[0]
1304 
1305         @utils.synchronized(group_hint)
1306         def _do_validation(context, instance, group_hint):
1307             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1308             if 'anti-affinity' in group.policies:
1309                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1310                 if self.host in group_hosts:
1311                     msg = _("Anti-affinity instance group policy "
1312                             "was violated.")
1313                     raise exception.RescheduledException(
1314                             instance_uuid=instance.uuid,
1315                             reason=msg)
1316             elif 'affinity' in group.policies:
1317                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1318                 if group_hosts and self.host not in group_hosts:
1319                     msg = _("Affinity instance group policy was violated.")
1320                     raise exception.RescheduledException(
1321                             instance_uuid=instance.uuid,
1322                             reason=msg)
1323 
1324         if not CONF.workarounds.disable_group_policy_check_upcall:
1325             _do_validation(context, instance, group_hint)
1326 
1327     def _log_original_error(self, exc_info, instance_uuid):
1328         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1329                   exc_info=exc_info)
1330 
1331     def _reschedule(self, context, request_spec, filter_properties,
1332             instance, reschedule_method, method_args, task_state,
1333             exc_info=None):
1334         """Attempt to re-schedule a compute operation."""
1335 
1336         instance_uuid = instance.uuid
1337         retry = filter_properties.get('retry')
1338         if not retry:
1339             # no retry information, do not reschedule.
1340             LOG.debug("Retry info not present, will not reschedule",
1341                       instance_uuid=instance_uuid)
1342             return
1343 
1344         if not request_spec:
1345             LOG.debug("No request spec, will not reschedule",
1346                       instance_uuid=instance_uuid)
1347             return
1348 
1349         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1350                   {'method': reschedule_method.__name__,
1351                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1352 
1353         # reset the task state:
1354         self._instance_update(context, instance, task_state=task_state)
1355 
1356         if exc_info:
1357             # stringify to avoid circular ref problem in json serialization:
1358             retry['exc'] = traceback.format_exception_only(exc_info[0],
1359                                     exc_info[1])
1360 
1361         reschedule_method(context, *method_args)
1362         return True
1363 
1364     @periodic_task.periodic_task
1365     def _check_instance_build_time(self, context):
1366         """Ensure that instances are not stuck in build."""
1367         timeout = CONF.instance_build_timeout
1368         if timeout == 0:
1369             return
1370 
1371         filters = {'vm_state': vm_states.BUILDING,
1372                    'host': self.host}
1373 
1374         building_insts = objects.InstanceList.get_by_filters(context,
1375                            filters, expected_attrs=[], use_slave=True)
1376 
1377         for instance in building_insts:
1378             if timeutils.is_older_than(instance.created_at, timeout):
1379                 self._set_instance_obj_error_state(context, instance)
1380                 LOG.warning("Instance build timed out. Set to error "
1381                             "state.", instance=instance)
1382 
1383     def _check_instance_exists(self, context, instance):
1384         """Ensure an instance with the same name is not already present."""
1385         if self.driver.instance_exists(instance):
1386             raise exception.InstanceExists(name=instance.name)
1387 
1388     def _allocate_network_async(self, context, instance, requested_networks,
1389                                 macs, security_groups, is_vpn):
1390         """Method used to allocate networks in the background.
1391 
1392         Broken out for testing.
1393         """
1394         # First check to see if we're specifically not supposed to allocate
1395         # networks because if so, we can exit early.
1396         if requested_networks and requested_networks.no_allocate:
1397             LOG.debug("Not allocating networking since 'none' was specified.",
1398                       instance=instance)
1399             return network_model.NetworkInfo([])
1400 
1401         LOG.debug("Allocating IP information in the background.",
1402                   instance=instance)
1403         retries = CONF.network_allocate_retries
1404         attempts = retries + 1
1405         retry_time = 1
1406         bind_host_id = self.driver.network_binding_host_id(context, instance)
1407         for attempt in range(1, attempts + 1):
1408             try:
1409                 nwinfo = self.network_api.allocate_for_instance(
1410                         context, instance, vpn=is_vpn,
1411                         requested_networks=requested_networks,
1412                         macs=macs,
1413                         security_groups=security_groups,
1414                         bind_host_id=bind_host_id)
1415                 LOG.debug('Instance network_info: |%s|', nwinfo,
1416                           instance=instance)
1417                 instance.system_metadata['network_allocated'] = 'True'
1418                 # NOTE(JoshNang) do not save the instance here, as it can cause
1419                 # races. The caller shares a reference to instance and waits
1420                 # for this async greenthread to finish before calling
1421                 # instance.save().
1422                 return nwinfo
1423             except Exception:
1424                 exc_info = sys.exc_info()
1425                 log_info = {'attempt': attempt,
1426                             'attempts': attempts}
1427                 if attempt == attempts:
1428                     LOG.exception('Instance failed network setup '
1429                                   'after %(attempts)d attempt(s)',
1430                                   log_info)
1431                     six.reraise(*exc_info)
1432                 LOG.warning('Instance failed network setup '
1433                             '(attempt %(attempt)d of %(attempts)d)',
1434                             log_info, instance=instance)
1435                 time.sleep(retry_time)
1436                 retry_time *= 2
1437                 if retry_time > 30:
1438                     retry_time = 30
1439         # Not reached.
1440 
1441     def _build_networks_for_instance(self, context, instance,
1442             requested_networks, security_groups):
1443 
1444         # If we're here from a reschedule the network may already be allocated.
1445         if strutils.bool_from_string(
1446                 instance.system_metadata.get('network_allocated', 'False')):
1447             # NOTE(alex_xu): The network_allocated is True means the network
1448             # resource already allocated at previous scheduling, and the
1449             # network setup is cleanup at previous. After rescheduling, the
1450             # network resource need setup on the new host.
1451             self.network_api.setup_instance_network_on_host(
1452                 context, instance, instance.host)
1453             return self.network_api.get_instance_nw_info(context, instance)
1454 
1455         if not self.is_neutron_security_groups:
1456             security_groups = []
1457 
1458         macs = self.driver.macs_for_instance(instance)
1459         network_info = self._allocate_network(context, instance,
1460                 requested_networks, macs, security_groups)
1461 
1462         return network_info
1463 
1464     def _allocate_network(self, context, instance, requested_networks, macs,
1465                           security_groups):
1466         """Start network allocation asynchronously.  Return an instance
1467         of NetworkInfoAsyncWrapper that can be used to retrieve the
1468         allocated networks when the operation has finished.
1469         """
1470         # NOTE(comstud): Since we're allocating networks asynchronously,
1471         # this task state has little meaning, as we won't be in this
1472         # state for very long.
1473         instance.vm_state = vm_states.BUILDING
1474         instance.task_state = task_states.NETWORKING
1475         instance.save(expected_task_state=[None])
1476 
1477         is_vpn = False
1478         return network_model.NetworkInfoAsyncWrapper(
1479                 self._allocate_network_async, context, instance,
1480                 requested_networks, macs, security_groups, is_vpn)
1481 
1482     def _default_root_device_name(self, instance, image_meta, root_bdm):
1483         try:
1484             return self.driver.default_root_device_name(instance,
1485                                                         image_meta,
1486                                                         root_bdm)
1487         except NotImplementedError:
1488             return compute_utils.get_next_device_name(instance, [])
1489 
1490     def _default_device_names_for_instance(self, instance,
1491                                            root_device_name,
1492                                            *block_device_lists):
1493         try:
1494             self.driver.default_device_names_for_instance(instance,
1495                                                           root_device_name,
1496                                                           *block_device_lists)
1497         except NotImplementedError:
1498             compute_utils.default_device_names_for_instance(
1499                 instance, root_device_name, *block_device_lists)
1500 
1501     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1502         # NOTE(ndipanov): Copy obj to avoid changing the original
1503         block_device_obj = block_device_obj.obj_clone()
1504         try:
1505             return self.driver.get_device_name_for_instance(
1506                 instance, bdms, block_device_obj)
1507         except NotImplementedError:
1508             return compute_utils.get_device_name_for_instance(
1509                 instance, bdms, block_device_obj.get("device_name"))
1510 
1511     def _default_block_device_names(self, instance, image_meta, block_devices):
1512         """Verify that all the devices have the device_name set. If not,
1513         provide a default name.
1514 
1515         It also ensures that there is a root_device_name and is set to the
1516         first block device in the boot sequence (boot_index=0).
1517         """
1518         root_bdm = block_device.get_root_bdm(block_devices)
1519         if not root_bdm:
1520             return
1521 
1522         # Get the root_device_name from the root BDM or the instance
1523         root_device_name = None
1524         update_root_bdm = False
1525 
1526         if root_bdm.device_name:
1527             root_device_name = root_bdm.device_name
1528             instance.root_device_name = root_device_name
1529         elif instance.root_device_name:
1530             root_device_name = instance.root_device_name
1531             root_bdm.device_name = root_device_name
1532             update_root_bdm = True
1533         else:
1534             root_device_name = self._default_root_device_name(instance,
1535                                                               image_meta,
1536                                                               root_bdm)
1537 
1538             instance.root_device_name = root_device_name
1539             root_bdm.device_name = root_device_name
1540             update_root_bdm = True
1541 
1542         if update_root_bdm:
1543             root_bdm.save()
1544 
1545         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1546                             block_devices))
1547         swap = list(filter(block_device.new_format_is_swap,
1548                       block_devices))
1549         block_device_mapping = list(filter(
1550               driver_block_device.is_block_device_mapping, block_devices))
1551 
1552         self._default_device_names_for_instance(instance,
1553                                                 root_device_name,
1554                                                 ephemerals,
1555                                                 swap,
1556                                                 block_device_mapping)
1557 
1558     def _block_device_info_to_legacy(self, block_device_info):
1559         """Convert BDI to the old format for drivers that need it."""
1560 
1561         if self.use_legacy_block_device_info:
1562             ephemerals = driver_block_device.legacy_block_devices(
1563                 driver.block_device_info_get_ephemerals(block_device_info))
1564             mapping = driver_block_device.legacy_block_devices(
1565                 driver.block_device_info_get_mapping(block_device_info))
1566             swap = block_device_info['swap']
1567             if swap:
1568                 swap = swap.legacy()
1569 
1570             block_device_info.update({
1571                 'ephemerals': ephemerals,
1572                 'swap': swap,
1573                 'block_device_mapping': mapping})
1574 
1575     def _add_missing_dev_names(self, bdms, instance):
1576         for bdm in bdms:
1577             if bdm.device_name is not None:
1578                 continue
1579 
1580             device_name = self._get_device_name_for_instance(instance,
1581                                                              bdms, bdm)
1582             values = {'device_name': device_name}
1583             bdm.update(values)
1584             bdm.save()
1585 
1586     def _prep_block_device(self, context, instance, bdms):
1587         """Set up the block device for an instance with error logging."""
1588         try:
1589             self._add_missing_dev_names(bdms, instance)
1590             block_device_info = driver.get_block_device_info(instance, bdms)
1591             mapping = driver.block_device_info_get_mapping(block_device_info)
1592             driver_block_device.attach_block_devices(
1593                 mapping, context, instance, self.volume_api, self.driver,
1594                 wait_func=self._await_block_device_map_created)
1595 
1596             self._block_device_info_to_legacy(block_device_info)
1597             return block_device_info
1598 
1599         except exception.OverQuota as e:
1600             LOG.warning('Failed to create block device for instance due'
1601                         ' to exceeding volume related resource quota.'
1602                         ' Error: %s', e.message, instance=instance)
1603             raise
1604 
1605         except Exception as ex:
1606             LOG.exception('Instance failed block device setup',
1607                           instance=instance)
1608             # InvalidBDM will eventually result in a BuildAbortException when
1609             # booting from volume, and will be recorded as an instance fault.
1610             # Maintain the original exception message which most likely has
1611             # useful details which the standard InvalidBDM error message lacks.
1612             raise exception.InvalidBDM(six.text_type(ex))
1613 
1614     def _update_instance_after_spawn(self, context, instance):
1615         instance.power_state = self._get_power_state(context, instance)
1616         instance.vm_state = vm_states.ACTIVE
1617         instance.task_state = None
1618         instance.launched_at = timeutils.utcnow()
1619         configdrive.update_instance(instance)
1620 
1621     def _update_scheduler_instance_info(self, context, instance):
1622         """Sends an InstanceList with created or updated Instance objects to
1623         the Scheduler client.
1624 
1625         In the case of init_host, the value passed will already be an
1626         InstanceList. Other calls will send individual Instance objects that
1627         have been created or resized. In this case, we create an InstanceList
1628         object containing that Instance.
1629         """
1630         if not self.send_instance_updates:
1631             return
1632         if isinstance(instance, obj_instance.Instance):
1633             instance = objects.InstanceList(objects=[instance])
1634         context = context.elevated()
1635         self.scheduler_client.update_instance_info(context, self.host,
1636                                                    instance)
1637 
1638     def _delete_scheduler_instance_info(self, context, instance_uuid):
1639         """Sends the uuid of the deleted Instance to the Scheduler client."""
1640         if not self.send_instance_updates:
1641             return
1642         context = context.elevated()
1643         self.scheduler_client.delete_instance_info(context, self.host,
1644                                                    instance_uuid)
1645 
1646     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1647     def _sync_scheduler_instance_info(self, context):
1648         if not self.send_instance_updates:
1649             return
1650         context = context.elevated()
1651         instances = objects.InstanceList.get_by_host(context, self.host,
1652                                                      expected_attrs=[],
1653                                                      use_slave=True)
1654         uuids = [instance.uuid for instance in instances]
1655         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1656 
1657     def _notify_about_instance_usage(self, context, instance, event_suffix,
1658                                      network_info=None, system_metadata=None,
1659                                      extra_usage_info=None, fault=None):
1660         compute_utils.notify_about_instance_usage(
1661             self.notifier, context, instance, event_suffix,
1662             network_info=network_info,
1663             system_metadata=system_metadata,
1664             extra_usage_info=extra_usage_info, fault=fault)
1665 
1666     def _deallocate_network(self, context, instance,
1667                             requested_networks=None):
1668         # If we were told not to allocate networks let's save ourselves
1669         # the trouble of calling the network API.
1670         if requested_networks and requested_networks.no_allocate:
1671             LOG.debug("Skipping network deallocation for instance since "
1672                       "networking was not requested.", instance=instance)
1673             return
1674 
1675         LOG.debug('Deallocating network for instance', instance=instance)
1676         with timeutils.StopWatch() as timer:
1677             self.network_api.deallocate_for_instance(
1678                 context, instance, requested_networks=requested_networks)
1679         # nova-network does an rpc call so we're OK tracking time spent here
1680         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1681                  timer.elapsed(), instance=instance)
1682 
1683     def _get_instance_block_device_info(self, context, instance,
1684                                         refresh_conn_info=False,
1685                                         bdms=None):
1686         """Transform block devices to the driver block_device format."""
1687 
1688         if not bdms:
1689             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1690                     context, instance.uuid)
1691         block_device_info = driver.get_block_device_info(instance, bdms)
1692 
1693         if not refresh_conn_info:
1694             # if the block_device_mapping has no value in connection_info
1695             # (returned as None), don't include in the mapping
1696             block_device_info['block_device_mapping'] = [
1697                 bdm for bdm in driver.block_device_info_get_mapping(
1698                                     block_device_info)
1699                 if bdm.get('connection_info')]
1700         else:
1701             driver_block_device.refresh_conn_infos(
1702                 driver.block_device_info_get_mapping(block_device_info),
1703                 context, instance, self.volume_api, self.driver)
1704 
1705         self._block_device_info_to_legacy(block_device_info)
1706 
1707         return block_device_info
1708 
1709     def _build_failed(self):
1710         self._failed_builds += 1
1711         limit = CONF.compute.consecutive_build_service_disable_threshold
1712         if limit and self._failed_builds >= limit:
1713             # NOTE(danms): If we're doing a bunch of parallel builds,
1714             # it is possible (although not likely) that we have already
1715             # failed N-1 builds before this and we race with a successful
1716             # build and disable ourselves here when we might've otherwise
1717             # not.
1718             LOG.error('Disabling service due to %(fails)i '
1719                       'consecutive build failures',
1720                       {'fails': self._failed_builds})
1721             ctx = nova.context.get_admin_context()
1722             service = objects.Service.get_by_compute_host(ctx, CONF.host)
1723             service.disabled = True
1724             service.disabled_reason = (
1725                 'Auto-disabled due to %i build failures' % self._failed_builds)
1726             service.save()
1727             # NOTE(danms): Reset our counter now so that when the admin
1728             # re-enables us we can start fresh
1729             self._failed_builds = 0
1730         elif self._failed_builds > 1:
1731             LOG.warning('%(fails)i consecutive build failures',
1732                         {'fails': self._failed_builds})
1733 
1734     @wrap_exception()
1735     @reverts_task_state
1736     @wrap_instance_fault
1737     def build_and_run_instance(self, context, instance, image, request_spec,
1738                      filter_properties, admin_password=None,
1739                      injected_files=None, requested_networks=None,
1740                      security_groups=None, block_device_mapping=None,
1741                      node=None, limits=None, host_list=None):
1742 
1743         @utils.synchronized(instance.uuid)
1744         def _locked_do_build_and_run_instance(*args, **kwargs):
1745             # NOTE(danms): We grab the semaphore with the instance uuid
1746             # locked because we could wait in line to build this instance
1747             # for a while and we want to make sure that nothing else tries
1748             # to do anything with this instance while we wait.
1749             with self._build_semaphore:
1750                 try:
1751                     result = self._do_build_and_run_instance(*args, **kwargs)
1752                 except Exception:
1753                     # NOTE(mriedem): This should really only happen if
1754                     # _decode_files in _do_build_and_run_instance fails, and
1755                     # that's before a guest is spawned so it's OK to remove
1756                     # allocations for the instance for this node from Placement
1757                     # below as there is no guest consuming resources anyway.
1758                     # The _decode_files case could be handled more specifically
1759                     # but that's left for another day.
1760                     result = build_results.FAILED
1761                     raise
1762                 finally:
1763                     if result == build_results.FAILED:
1764                         # Remove the allocation records from Placement for the
1765                         # instance if the build failed. The instance.host is
1766                         # likely set to None in _do_build_and_run_instance
1767                         # which means if the user deletes the instance, it
1768                         # will be deleted in the API, not the compute service.
1769                         # Setting the instance.host to None in
1770                         # _do_build_and_run_instance means that the
1771                         # ResourceTracker will no longer consider this instance
1772                         # to be claiming resources against it, so we want to
1773                         # reflect that same thing in Placement.  No need to
1774                         # call this for a reschedule, as the allocations will
1775                         # have already been removed in
1776                         # self._do_build_and_run_instance().
1777                         self._delete_allocation_for_instance(instance.uuid)
1778 
1779                     if result in (build_results.FAILED,
1780                                   build_results.RESCHEDULED):
1781                         self._build_failed()
1782                     else:
1783                         self._failed_builds = 0
1784 
1785         # NOTE(danms): We spawn here to return the RPC worker thread back to
1786         # the pool. Since what follows could take a really long time, we don't
1787         # want to tie up RPC workers.
1788         utils.spawn_n(_locked_do_build_and_run_instance,
1789                       context, instance, image, request_spec,
1790                       filter_properties, admin_password, injected_files,
1791                       requested_networks, security_groups,
1792                       block_device_mapping, node, limits, host_list)
1793 
1794     def _delete_allocation_for_instance(self, instance_uuid):
1795         rt = self._get_resource_tracker()
1796         rt.reportclient.delete_allocation_for_instance(instance_uuid)
1797 
1798     def _check_device_tagging(self, requested_networks, block_device_mapping):
1799         tagging_requested = False
1800         if requested_networks:
1801             for net in requested_networks:
1802                 if 'tag' in net and net.tag is not None:
1803                     tagging_requested = True
1804                     break
1805         if block_device_mapping and not tagging_requested:
1806             for bdm in block_device_mapping:
1807                 if 'tag' in bdm and bdm.tag is not None:
1808                     tagging_requested = True
1809                     break
1810         if (tagging_requested and
1811                 not self.driver.capabilities.get('supports_device_tagging')):
1812             raise exception.BuildAbortException('Attempt to boot guest with '
1813                                                 'tagged devices on host that '
1814                                                 'does not support tagging.')
1815 
1816     @hooks.add_hook('build_instance')
1817     @wrap_exception()
1818     @reverts_task_state
1819     @wrap_instance_event(prefix='compute')
1820     @wrap_instance_fault
1821     def _do_build_and_run_instance(self, context, instance, image,
1822             request_spec, filter_properties, admin_password, injected_files,
1823             requested_networks, security_groups, block_device_mapping,
1824             node=None, limits=None, host_list=None):
1825 
1826         try:
1827             LOG.debug('Starting instance...', instance=instance)
1828             instance.vm_state = vm_states.BUILDING
1829             instance.task_state = None
1830             instance.save(expected_task_state=
1831                     (task_states.SCHEDULING, None))
1832         except exception.InstanceNotFound:
1833             msg = 'Instance disappeared before build.'
1834             LOG.debug(msg, instance=instance)
1835             return build_results.FAILED
1836         except exception.UnexpectedTaskStateError as e:
1837             LOG.debug(e.format_message(), instance=instance)
1838             return build_results.FAILED
1839 
1840         # b64 decode the files to inject:
1841         decoded_files = self._decode_files(injected_files)
1842 
1843         if limits is None:
1844             limits = {}
1845 
1846         if node is None:
1847             node = self._get_nodename(instance, refresh=True)
1848 
1849         try:
1850             with timeutils.StopWatch() as timer:
1851                 self._build_and_run_instance(context, instance, image,
1852                         decoded_files, admin_password, requested_networks,
1853                         security_groups, block_device_mapping, node, limits,
1854                         filter_properties, request_spec)
1855             LOG.info('Took %0.2f seconds to build instance.',
1856                      timer.elapsed(), instance=instance)
1857             return build_results.ACTIVE
1858         except exception.RescheduledException as e:
1859             retry = filter_properties.get('retry')
1860             if not retry:
1861                 # no retry information, do not reschedule.
1862                 LOG.debug("Retry info not present, will not reschedule",
1863                     instance=instance)
1864                 self._cleanup_allocated_networks(context, instance,
1865                     requested_networks)
1866                 self._cleanup_volumes(context, instance.uuid,
1867                     block_device_mapping, raise_exc=False)
1868                 compute_utils.add_instance_fault_from_exc(context,
1869                         instance, e, sys.exc_info(),
1870                         fault_message=e.kwargs['reason'])
1871                 self._nil_out_instance_obj_host_and_node(instance)
1872                 self._set_instance_obj_error_state(context, instance,
1873                                                    clean_task_state=True)
1874                 return build_results.FAILED
1875             LOG.debug(e.format_message(), instance=instance)
1876             # This will be used for logging the exception
1877             retry['exc'] = traceback.format_exception(*sys.exc_info())
1878             # This will be used for setting the instance fault message
1879             retry['exc_reason'] = e.kwargs['reason']
1880             # NOTE(comstud): Deallocate networks if the driver wants
1881             # us to do so.
1882             # NOTE(vladikr): SR-IOV ports should be deallocated to
1883             # allow new sriov pci devices to be allocated on a new host.
1884             # Otherwise, if devices with pci addresses are already allocated
1885             # on the destination host, the instance will fail to spawn.
1886             # info_cache.network_info should be present at this stage.
1887             if (self.driver.deallocate_networks_on_reschedule(instance) or
1888                 self.deallocate_sriov_ports_on_reschedule(instance)):
1889                 self._cleanup_allocated_networks(context, instance,
1890                         requested_networks)
1891             else:
1892                 # NOTE(alex_xu): Network already allocated and we don't
1893                 # want to deallocate them before rescheduling. But we need
1894                 # to cleanup those network resources setup on this host before
1895                 # rescheduling.
1896                 self.network_api.cleanup_instance_network_on_host(
1897                     context, instance, self.host)
1898 
1899             self._nil_out_instance_obj_host_and_node(instance)
1900             instance.task_state = task_states.SCHEDULING
1901             instance.save()
1902             # The instance will have already claimed resources from this host
1903             # before this build was attempted. Now that it has failed, we need
1904             # to unclaim those resources before casting to the conductor, so
1905             # that if there are alternate hosts available for a retry, it can
1906             # claim resources on that new host for the instance.
1907             self._delete_allocation_for_instance(instance.uuid)
1908 
1909             self.compute_task_api.build_instances(context, [instance],
1910                     image, filter_properties, admin_password,
1911                     injected_files, requested_networks, security_groups,
1912                     block_device_mapping, request_spec=request_spec,
1913                     host_lists=[host_list])
1914             return build_results.RESCHEDULED
1915         except (exception.InstanceNotFound,
1916                 exception.UnexpectedDeletingTaskStateError):
1917             msg = 'Instance disappeared during build.'
1918             LOG.debug(msg, instance=instance)
1919             self._cleanup_allocated_networks(context, instance,
1920                     requested_networks)
1921             return build_results.FAILED
1922         except exception.BuildAbortException as e:
1923             LOG.exception(e.format_message(), instance=instance)
1924             self._cleanup_allocated_networks(context, instance,
1925                     requested_networks)
1926             self._cleanup_volumes(context, instance.uuid,
1927                     block_device_mapping, raise_exc=False)
1928             compute_utils.add_instance_fault_from_exc(context, instance,
1929                     e, sys.exc_info())
1930             self._nil_out_instance_obj_host_and_node(instance)
1931             self._set_instance_obj_error_state(context, instance,
1932                                                clean_task_state=True)
1933             return build_results.FAILED
1934         except Exception as e:
1935             # Should not reach here.
1936             LOG.exception('Unexpected build failure, not rescheduling build.',
1937                           instance=instance)
1938             self._cleanup_allocated_networks(context, instance,
1939                     requested_networks)
1940             self._cleanup_volumes(context, instance.uuid,
1941                     block_device_mapping, raise_exc=False)
1942             compute_utils.add_instance_fault_from_exc(context, instance,
1943                     e, sys.exc_info())
1944             self._nil_out_instance_obj_host_and_node(instance)
1945             self._set_instance_obj_error_state(context, instance,
1946                                                clean_task_state=True)
1947             return build_results.FAILED
1948 
1949     def deallocate_sriov_ports_on_reschedule(self, instance):
1950         """Determine if networks are needed to be deallocated before reschedule
1951 
1952         Check the cached network info for any assigned SR-IOV ports.
1953         SR-IOV ports should be deallocated prior to rescheduling
1954         in order to allow new sriov pci devices to be allocated on a new host.
1955         """
1956         info_cache = instance.info_cache
1957 
1958         def _has_sriov_port(vif):
1959             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1960 
1961         if (info_cache and info_cache.network_info):
1962             for vif in info_cache.network_info:
1963                 if _has_sriov_port(vif):
1964                     return True
1965         return False
1966 
1967     @staticmethod
1968     def _get_scheduler_hints(filter_properties, request_spec=None):
1969         """Helper method to get scheduler hints.
1970 
1971         This method prefers to get the hints out of the request spec, but that
1972         might not be provided. Conductor will pass request_spec down to the
1973         first compute chosen for a build but older computes will not pass
1974         the request_spec to conductor's build_instances method for a
1975         a reschedule, so if we're on a host via a retry, request_spec may not
1976         be provided so we need to fallback to use the filter_properties
1977         to get scheduler hints.
1978         """
1979         hints = {}
1980         if request_spec is not None and 'scheduler_hints' in request_spec:
1981             hints = request_spec.scheduler_hints
1982         if not hints:
1983             hints = filter_properties.get('scheduler_hints') or {}
1984         return hints
1985 
1986     def _build_and_run_instance(self, context, instance, image, injected_files,
1987             admin_password, requested_networks, security_groups,
1988             block_device_mapping, node, limits, filter_properties,
1989             request_spec=None):
1990 
1991         image_name = image.get('name')
1992         self._notify_about_instance_usage(context, instance, 'create.start',
1993                 extra_usage_info={'image_name': image_name})
1994         compute_utils.notify_about_instance_create(
1995             context, instance, self.host,
1996             phase=fields.NotificationPhase.START,
1997             bdms=block_device_mapping)
1998 
1999         # NOTE(mikal): cache the keystone roles associated with the instance
2000         # at boot time for later reference
2001         instance.system_metadata.update(
2002             {'boot_roles': ','.join(context.roles)})
2003 
2004         self._check_device_tagging(requested_networks, block_device_mapping)
2005 
2006         try:
2007             scheduler_hints = self._get_scheduler_hints(filter_properties,
2008                                                         request_spec)
2009             rt = self._get_resource_tracker()
2010             with rt.instance_claim(context, instance, node, limits):
2011                 # NOTE(russellb) It's important that this validation be done
2012                 # *after* the resource tracker instance claim, as that is where
2013                 # the host is set on the instance.
2014                 self._validate_instance_group_policy(context, instance,
2015                                                      scheduler_hints)
2016                 image_meta = objects.ImageMeta.from_dict(image)
2017                 with self._build_resources(context, instance,
2018                         requested_networks, security_groups, image_meta,
2019                         block_device_mapping) as resources:
2020                     instance.vm_state = vm_states.BUILDING
2021                     instance.task_state = task_states.SPAWNING
2022                     # NOTE(JoshNang) This also saves the changes to the
2023                     # instance from _allocate_network_async, as they aren't
2024                     # saved in that function to prevent races.
2025                     instance.save(expected_task_state=
2026                             task_states.BLOCK_DEVICE_MAPPING)
2027                     block_device_info = resources['block_device_info']
2028                     network_info = resources['network_info']
2029                     allocs = resources['allocations']
2030                     LOG.debug('Start spawning the instance on the hypervisor.',
2031                               instance=instance)
2032                     with timeutils.StopWatch() as timer:
2033                         self.driver.spawn(context, instance, image_meta,
2034                                           injected_files, admin_password,
2035                                           allocs, network_info=network_info,
2036                                           block_device_info=block_device_info)
2037                     LOG.info('Took %0.2f seconds to spawn the instance on '
2038                              'the hypervisor.', timer.elapsed(),
2039                              instance=instance)
2040         except (exception.InstanceNotFound,
2041                 exception.UnexpectedDeletingTaskStateError) as e:
2042             with excutils.save_and_reraise_exception():
2043                 self._notify_about_instance_usage(context, instance,
2044                     'create.error', fault=e)
2045                 compute_utils.notify_about_instance_create(
2046                     context, instance, self.host,
2047                     phase=fields.NotificationPhase.ERROR, exception=e,
2048                     bdms=block_device_mapping)
2049         except exception.ComputeResourcesUnavailable as e:
2050             LOG.debug(e.format_message(), instance=instance)
2051             self._notify_about_instance_usage(context, instance,
2052                     'create.error', fault=e)
2053             compute_utils.notify_about_instance_create(
2054                     context, instance, self.host,
2055                     phase=fields.NotificationPhase.ERROR, exception=e,
2056                     bdms=block_device_mapping)
2057             raise exception.RescheduledException(
2058                     instance_uuid=instance.uuid, reason=e.format_message())
2059         except exception.BuildAbortException as e:
2060             with excutils.save_and_reraise_exception():
2061                 LOG.debug(e.format_message(), instance=instance)
2062                 self._notify_about_instance_usage(context, instance,
2063                     'create.error', fault=e)
2064                 compute_utils.notify_about_instance_create(
2065                     context, instance, self.host,
2066                     phase=fields.NotificationPhase.ERROR, exception=e,
2067                     bdms=block_device_mapping)
2068         except (exception.FixedIpLimitExceeded,
2069                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2070             LOG.warning('No more network or fixed IP to be allocated',
2071                         instance=instance)
2072             self._notify_about_instance_usage(context, instance,
2073                     'create.error', fault=e)
2074             compute_utils.notify_about_instance_create(
2075                     context, instance, self.host,
2076                     phase=fields.NotificationPhase.ERROR, exception=e,
2077                     bdms=block_device_mapping)
2078             msg = _('Failed to allocate the network(s) with error %s, '
2079                     'not rescheduling.') % e.format_message()
2080             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2081                     reason=msg)
2082         except (exception.VirtualInterfaceCreateException,
2083                 exception.VirtualInterfaceMacAddressException,
2084                 exception.FixedIpInvalidOnHost,
2085                 exception.UnableToAutoAllocateNetwork) as e:
2086             LOG.exception('Failed to allocate network(s)',
2087                           instance=instance)
2088             self._notify_about_instance_usage(context, instance,
2089                     'create.error', fault=e)
2090             compute_utils.notify_about_instance_create(
2091                     context, instance, self.host,
2092                     phase=fields.NotificationPhase.ERROR, exception=e,
2093                     bdms=block_device_mapping)
2094             msg = _('Failed to allocate the network(s), not rescheduling.')
2095             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2096                     reason=msg)
2097         except (exception.FlavorDiskTooSmall,
2098                 exception.FlavorMemoryTooSmall,
2099                 exception.ImageNotActive,
2100                 exception.ImageUnacceptable,
2101                 exception.InvalidDiskInfo,
2102                 exception.InvalidDiskFormat,
2103                 cursive_exception.SignatureVerificationError,
2104                 exception.VolumeEncryptionNotSupported,
2105                 exception.InvalidInput) as e:
2106             self._notify_about_instance_usage(context, instance,
2107                     'create.error', fault=e)
2108             compute_utils.notify_about_instance_create(
2109                     context, instance, self.host,
2110                     phase=fields.NotificationPhase.ERROR, exception=e,
2111                     bdms=block_device_mapping)
2112             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2113                     reason=e.format_message())
2114         except Exception as e:
2115             self._notify_about_instance_usage(context, instance,
2116                     'create.error', fault=e)
2117             compute_utils.notify_about_instance_create(
2118                     context, instance, self.host,
2119                     phase=fields.NotificationPhase.ERROR, exception=e,
2120                     bdms=block_device_mapping)
2121             raise exception.RescheduledException(
2122                     instance_uuid=instance.uuid, reason=six.text_type(e))
2123 
2124         # NOTE(alaski): This is only useful during reschedules, remove it now.
2125         instance.system_metadata.pop('network_allocated', None)
2126 
2127         # If CONF.default_access_ip_network_name is set, grab the
2128         # corresponding network and set the access ip values accordingly.
2129         network_name = CONF.default_access_ip_network_name
2130         if (network_name and not instance.access_ip_v4 and
2131                 not instance.access_ip_v6):
2132             # Note that when there are multiple ips to choose from, an
2133             # arbitrary one will be chosen.
2134             for vif in network_info:
2135                 if vif['network']['label'] == network_name:
2136                     for ip in vif.fixed_ips():
2137                         if not instance.access_ip_v4 and ip['version'] == 4:
2138                             instance.access_ip_v4 = ip['address']
2139                         if not instance.access_ip_v6 and ip['version'] == 6:
2140                             instance.access_ip_v6 = ip['address']
2141                     break
2142 
2143         self._update_instance_after_spawn(context, instance)
2144 
2145         try:
2146             instance.save(expected_task_state=task_states.SPAWNING)
2147         except (exception.InstanceNotFound,
2148                 exception.UnexpectedDeletingTaskStateError) as e:
2149             with excutils.save_and_reraise_exception():
2150                 self._notify_about_instance_usage(context, instance,
2151                     'create.error', fault=e)
2152                 compute_utils.notify_about_instance_create(
2153                     context, instance, self.host,
2154                     phase=fields.NotificationPhase.ERROR, exception=e,
2155                     bdms=block_device_mapping)
2156 
2157         self._update_scheduler_instance_info(context, instance)
2158         self._notify_about_instance_usage(context, instance, 'create.end',
2159                 extra_usage_info={'message': _('Success')},
2160                 network_info=network_info)
2161         compute_utils.notify_about_instance_create(context, instance,
2162                 self.host, phase=fields.NotificationPhase.END,
2163                 bdms=block_device_mapping)
2164 
2165     @contextlib.contextmanager
2166     def _build_resources(self, context, instance, requested_networks,
2167                          security_groups, image_meta, block_device_mapping):
2168         resources = {}
2169         network_info = None
2170         try:
2171             LOG.debug('Start building networks asynchronously for instance.',
2172                       instance=instance)
2173             network_info = self._build_networks_for_instance(context, instance,
2174                     requested_networks, security_groups)
2175             resources['network_info'] = network_info
2176         except (exception.InstanceNotFound,
2177                 exception.UnexpectedDeletingTaskStateError):
2178             raise
2179         except exception.UnexpectedTaskStateError as e:
2180             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2181                     reason=e.format_message())
2182         except Exception:
2183             # Because this allocation is async any failures are likely to occur
2184             # when the driver accesses network_info during spawn().
2185             LOG.exception('Failed to allocate network(s)',
2186                           instance=instance)
2187             msg = _('Failed to allocate the network(s), not rescheduling.')
2188             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2189                     reason=msg)
2190 
2191         try:
2192             # Verify that all the BDMs have a device_name set and assign a
2193             # default to the ones missing it with the help of the driver.
2194             self._default_block_device_names(instance, image_meta,
2195                                              block_device_mapping)
2196 
2197             LOG.debug('Start building block device mappings for instance.',
2198                       instance=instance)
2199             instance.vm_state = vm_states.BUILDING
2200             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2201             instance.save()
2202 
2203             block_device_info = self._prep_block_device(context, instance,
2204                     block_device_mapping)
2205             resources['block_device_info'] = block_device_info
2206         except (exception.InstanceNotFound,
2207                 exception.UnexpectedDeletingTaskStateError):
2208             with excutils.save_and_reraise_exception():
2209                 # Make sure the async call finishes
2210                 if network_info is not None:
2211                     network_info.wait(do_raise=False)
2212         except (exception.UnexpectedTaskStateError,
2213                 exception.OverQuota, exception.InvalidBDM) as e:
2214             # Make sure the async call finishes
2215             if network_info is not None:
2216                 network_info.wait(do_raise=False)
2217             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2218                     reason=e.format_message())
2219         except Exception:
2220             LOG.exception('Failure prepping block device',
2221                           instance=instance)
2222             # Make sure the async call finishes
2223             if network_info is not None:
2224                 network_info.wait(do_raise=False)
2225             msg = _('Failure prepping block device.')
2226             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2227                     reason=msg)
2228 
2229         try:
2230             resources['allocations'] = (
2231                 self.reportclient.get_allocations_for_consumer(instance.uuid))
2232         except Exception:
2233             LOG.exception('Failure retrieving placement allocations',
2234                           instance=instance)
2235             # Make sure the async call finishes
2236             if network_info is not None:
2237                 network_info.wait(do_raise=False)
2238             msg = _('Failure retrieving placement allocations')
2239             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2240                                                 reason=msg)
2241 
2242         try:
2243             yield resources
2244         except Exception as exc:
2245             with excutils.save_and_reraise_exception() as ctxt:
2246                 if not isinstance(exc, (
2247                         exception.InstanceNotFound,
2248                         exception.UnexpectedDeletingTaskStateError)):
2249                     LOG.exception('Instance failed to spawn',
2250                                   instance=instance)
2251                 # Make sure the async call finishes
2252                 if network_info is not None:
2253                     network_info.wait(do_raise=False)
2254                 # if network_info is empty we're likely here because of
2255                 # network allocation failure. Since nothing can be reused on
2256                 # rescheduling it's better to deallocate network to eliminate
2257                 # the chance of orphaned ports in neutron
2258                 deallocate_networks = False if network_info else True
2259                 try:
2260                     self._shutdown_instance(context, instance,
2261                             block_device_mapping, requested_networks,
2262                             try_deallocate_networks=deallocate_networks)
2263                 except Exception as exc2:
2264                     ctxt.reraise = False
2265                     LOG.warning('Could not clean up failed build,'
2266                                 ' not rescheduling. Error: %s',
2267                                 six.text_type(exc2))
2268                     raise exception.BuildAbortException(
2269                             instance_uuid=instance.uuid,
2270                             reason=six.text_type(exc))
2271 
2272     def _cleanup_allocated_networks(self, context, instance,
2273             requested_networks):
2274         try:
2275             self._deallocate_network(context, instance, requested_networks)
2276         except Exception:
2277             LOG.exception('Failed to deallocate networks', instance=instance)
2278             return
2279 
2280         instance.system_metadata['network_allocated'] = 'False'
2281         try:
2282             instance.save()
2283         except exception.InstanceNotFound:
2284             # NOTE(alaski): It's possible that we're cleaning up the networks
2285             # because the instance was deleted.  If that's the case then this
2286             # exception will be raised by instance.save()
2287             pass
2288 
2289     def _try_deallocate_network(self, context, instance,
2290                                 requested_networks=None):
2291         try:
2292             # tear down allocated network structure
2293             self._deallocate_network(context, instance, requested_networks)
2294         except Exception as ex:
2295             with excutils.save_and_reraise_exception():
2296                 LOG.error('Failed to deallocate network for instance. '
2297                           'Error: %s', ex, instance=instance)
2298                 self._set_instance_obj_error_state(context, instance)
2299 
2300     def _get_power_off_values(self, context, instance, clean_shutdown):
2301         """Get the timing configuration for powering down this instance."""
2302         if clean_shutdown:
2303             timeout = compute_utils.get_value_from_system_metadata(instance,
2304                           key='image_os_shutdown_timeout', type=int,
2305                           default=CONF.shutdown_timeout)
2306             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2307         else:
2308             timeout = 0
2309             retry_interval = 0
2310 
2311         return timeout, retry_interval
2312 
2313     def _power_off_instance(self, context, instance, clean_shutdown=True):
2314         """Power off an instance on this host."""
2315         timeout, retry_interval = self._get_power_off_values(context,
2316                                         instance, clean_shutdown)
2317         self.driver.power_off(instance, timeout, retry_interval)
2318 
2319     def _shutdown_instance(self, context, instance,
2320                            bdms, requested_networks=None, notify=True,
2321                            try_deallocate_networks=True):
2322         """Shutdown an instance on this host.
2323 
2324         :param:context: security context
2325         :param:instance: a nova.objects.Instance object
2326         :param:bdms: the block devices for the instance to be torn
2327                      down
2328         :param:requested_networks: the networks on which the instance
2329                                    has ports
2330         :param:notify: true if a final usage notification should be
2331                        emitted
2332         :param:try_deallocate_networks: false if we should avoid
2333                                         trying to teardown networking
2334         """
2335         context = context.elevated()
2336         LOG.info('Terminating instance', instance=instance)
2337 
2338         if notify:
2339             self._notify_about_instance_usage(context, instance,
2340                                               "shutdown.start")
2341             compute_utils.notify_about_instance_action(context, instance,
2342                     self.host, action=fields.NotificationAction.SHUTDOWN,
2343                     phase=fields.NotificationPhase.START, bdms=bdms)
2344 
2345         network_info = instance.get_network_info()
2346 
2347         # NOTE(vish) get bdms before destroying the instance
2348         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2349         block_device_info = self._get_instance_block_device_info(
2350             context, instance, bdms=bdms)
2351 
2352         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2353         #                want to keep ip allocated for certain failures
2354         timer = timeutils.StopWatch()
2355         try:
2356             LOG.debug('Start destroying the instance on the hypervisor.',
2357                       instance=instance)
2358             timer.start()
2359             self.driver.destroy(context, instance, network_info,
2360                     block_device_info)
2361             LOG.info('Took %0.2f seconds to destroy the instance on the '
2362                      'hypervisor.', timer.elapsed(), instance=instance)
2363         except exception.InstancePowerOffFailure:
2364             # if the instance can't power off, don't release the ip
2365             with excutils.save_and_reraise_exception():
2366                 pass
2367         except Exception:
2368             with excutils.save_and_reraise_exception():
2369                 # deallocate ip and fail without proceeding to
2370                 # volume api calls, preserving current behavior
2371                 if try_deallocate_networks:
2372                     self._try_deallocate_network(context, instance,
2373                                                  requested_networks)
2374 
2375         if try_deallocate_networks:
2376             self._try_deallocate_network(context, instance, requested_networks)
2377 
2378         timer.restart()
2379         for bdm in vol_bdms:
2380             try:
2381                 if bdm.attachment_id:
2382                     self.volume_api.attachment_delete(context,
2383                                                       bdm.attachment_id)
2384                 else:
2385                     # NOTE(vish): actual driver detach done in driver.destroy,
2386                     #             so just tell cinder that we are done with it.
2387                     connector = self.driver.get_volume_connector(instance)
2388                     self.volume_api.terminate_connection(context,
2389                                                          bdm.volume_id,
2390                                                          connector)
2391                     self.volume_api.detach(context, bdm.volume_id,
2392                                            instance.uuid)
2393 
2394             except exception.VolumeAttachmentNotFound as exc:
2395                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2396                           instance=instance)
2397             except exception.DiskNotFound as exc:
2398                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2399                           instance=instance)
2400             except exception.VolumeNotFound as exc:
2401                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2402                           instance=instance)
2403             except (cinder_exception.EndpointNotFound,
2404                     keystone_exception.EndpointNotFound) as exc:
2405                 LOG.warning('Ignoring EndpointNotFound for '
2406                             'volume %(volume_id)s: %(exc)s',
2407                             {'exc': exc, 'volume_id': bdm.volume_id},
2408                             instance=instance)
2409             except cinder_exception.ClientException as exc:
2410                 LOG.warning('Ignoring unknown cinder exception for '
2411                             'volume %(volume_id)s: %(exc)s',
2412                             {'exc': exc, 'volume_id': bdm.volume_id},
2413                             instance=instance)
2414             except Exception as exc:
2415                 LOG.warning('Ignoring unknown exception for '
2416                             'volume %(volume_id)s: %(exc)s',
2417                             {'exc': exc, 'volume_id': bdm.volume_id},
2418                             instance=instance)
2419         if vol_bdms:
2420             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2421                      'for instance.',
2422                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2423                      instance=instance)
2424 
2425         if notify:
2426             self._notify_about_instance_usage(context, instance,
2427                                               "shutdown.end")
2428             compute_utils.notify_about_instance_action(context, instance,
2429                     self.host, action=fields.NotificationAction.SHUTDOWN,
2430                     phase=fields.NotificationPhase.END, bdms=bdms)
2431 
2432     def _cleanup_volumes(self, context, instance_uuid, bdms, raise_exc=True):
2433         exc_info = None
2434 
2435         for bdm in bdms:
2436             LOG.debug("terminating bdm %s", bdm,
2437                       instance_uuid=instance_uuid)
2438             if bdm.volume_id and bdm.delete_on_termination:
2439                 try:
2440                     self.volume_api.delete(context, bdm.volume_id)
2441                 except Exception as exc:
2442                     exc_info = sys.exc_info()
2443                     LOG.warning('Failed to delete volume: %(volume_id)s '
2444                                 'due to %(exc)s',
2445                                 {'volume_id': bdm.volume_id, 'exc': exc})
2446         if exc_info is not None and raise_exc:
2447             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2448 
2449     @hooks.add_hook("delete_instance")
2450     def _delete_instance(self, context, instance, bdms):
2451         """Delete an instance on this host.
2452 
2453         :param context: nova request context
2454         :param instance: nova.objects.instance.Instance object
2455         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2456         """
2457         events = self.instance_events.clear_events_for_instance(instance)
2458         if events:
2459             LOG.debug('Events pending at deletion: %(events)s',
2460                       {'events': ','.join(events.keys())},
2461                       instance=instance)
2462         self._notify_about_instance_usage(context, instance,
2463                                           "delete.start")
2464         compute_utils.notify_about_instance_action(context, instance,
2465                 self.host, action=fields.NotificationAction.DELETE,
2466                 phase=fields.NotificationPhase.START, bdms=bdms)
2467 
2468         self._shutdown_instance(context, instance, bdms)
2469         # NOTE(dims): instance.info_cache.delete() should be called after
2470         # _shutdown_instance in the compute manager as shutdown calls
2471         # deallocate_for_instance so the info_cache is still needed
2472         # at this point.
2473         if instance.info_cache is not None:
2474             instance.info_cache.delete()
2475         else:
2476             # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2477             # is None. When the root cause that instance.info_cache becomes
2478             # None is fixed, the log level should be reconsidered.
2479             LOG.warning("Info cache for instance could not be found. "
2480                         "Ignore.", instance=instance)
2481 
2482         # NOTE(vish): We have already deleted the instance, so we have
2483         #             to ignore problems cleaning up the volumes. It
2484         #             would be nice to let the user know somehow that
2485         #             the volume deletion failed, but it is not
2486         #             acceptable to have an instance that can not be
2487         #             deleted. Perhaps this could be reworked in the
2488         #             future to set an instance fault the first time
2489         #             and to only ignore the failure if the instance
2490         #             is already in ERROR.
2491         self._cleanup_volumes(context, instance.uuid, bdms,
2492                 raise_exc=False)
2493         # if a delete task succeeded, always update vm state and task
2494         # state without expecting task state to be DELETING
2495         instance.vm_state = vm_states.DELETED
2496         instance.task_state = None
2497         instance.power_state = power_state.NOSTATE
2498         instance.terminated_at = timeutils.utcnow()
2499         instance.save()
2500         system_meta = instance.system_metadata
2501         instance.destroy()
2502 
2503         self._complete_deletion(context,
2504                                 instance,
2505                                 bdms,
2506                                 system_meta)
2507 
2508     @wrap_exception()
2509     @reverts_task_state
2510     @wrap_instance_event(prefix='compute')
2511     @wrap_instance_fault
2512     def terminate_instance(self, context, instance, bdms, reservations):
2513         """Terminate an instance on this host."""
2514         @utils.synchronized(instance.uuid)
2515         def do_terminate_instance(instance, bdms):
2516             # NOTE(mriedem): If we are deleting the instance while it was
2517             # booting from volume, we could be racing with a database update of
2518             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2519             # to compute here, the BDMs may be stale at this point. So check
2520             # for any volume BDMs that don't have volume_id set and if we
2521             # detect that, we need to refresh the BDM list before proceeding.
2522             # TODO(mriedem): Move this into _delete_instance and make the bdms
2523             # parameter optional.
2524             for bdm in list(bdms):
2525                 if bdm.is_volume and not bdm.volume_id:
2526                     LOG.debug('There are potentially stale BDMs during '
2527                               'delete, refreshing the BlockDeviceMappingList.',
2528                               instance=instance)
2529                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2530                         context, instance.uuid)
2531                     break
2532             try:
2533                 self._delete_instance(context, instance, bdms)
2534             except exception.InstanceNotFound:
2535                 LOG.info("Instance disappeared during terminate",
2536                          instance=instance)
2537             except Exception:
2538                 # As we're trying to delete always go to Error if something
2539                 # goes wrong that _delete_instance can't handle.
2540                 with excutils.save_and_reraise_exception():
2541                     LOG.exception('Setting instance vm_state to ERROR',
2542                                   instance=instance)
2543                     self._set_instance_obj_error_state(context, instance)
2544 
2545         do_terminate_instance(instance, bdms)
2546 
2547     # NOTE(johannes): This is probably better named power_off_instance
2548     # so it matches the driver method, but because of other issues, we
2549     # can't use that name in grizzly.
2550     @wrap_exception()
2551     @reverts_task_state
2552     @wrap_instance_event(prefix='compute')
2553     @wrap_instance_fault
2554     def stop_instance(self, context, instance, clean_shutdown):
2555         """Stopping an instance on this host."""
2556 
2557         @utils.synchronized(instance.uuid)
2558         def do_stop_instance():
2559             current_power_state = self._get_power_state(context, instance)
2560             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2561                       'current task_state: %(task_state)s, current DB '
2562                       'power_state: %(db_power_state)s, current VM '
2563                       'power_state: %(current_power_state)s',
2564                       {'vm_state': instance.vm_state,
2565                        'task_state': instance.task_state,
2566                        'db_power_state': instance.power_state,
2567                        'current_power_state': current_power_state},
2568                       instance_uuid=instance.uuid)
2569 
2570             # NOTE(mriedem): If the instance is already powered off, we are
2571             # possibly tearing down and racing with other operations, so we can
2572             # expect the task_state to be None if something else updates the
2573             # instance and we're not locking it.
2574             expected_task_state = [task_states.POWERING_OFF]
2575             # The list of power states is from _sync_instance_power_state.
2576             if current_power_state in (power_state.NOSTATE,
2577                                        power_state.SHUTDOWN,
2578                                        power_state.CRASHED):
2579                 LOG.info('Instance is already powered off in the '
2580                          'hypervisor when stop is called.',
2581                          instance=instance)
2582                 expected_task_state.append(None)
2583 
2584             self._notify_about_instance_usage(context, instance,
2585                                               "power_off.start")
2586 
2587             compute_utils.notify_about_instance_action(context, instance,
2588                         self.host, action=fields.NotificationAction.POWER_OFF,
2589                         phase=fields.NotificationPhase.START)
2590 
2591             self._power_off_instance(context, instance, clean_shutdown)
2592             instance.power_state = self._get_power_state(context, instance)
2593             instance.vm_state = vm_states.STOPPED
2594             instance.task_state = None
2595             instance.save(expected_task_state=expected_task_state)
2596             self._notify_about_instance_usage(context, instance,
2597                                               "power_off.end")
2598 
2599             compute_utils.notify_about_instance_action(context, instance,
2600                         self.host, action=fields.NotificationAction.POWER_OFF,
2601                         phase=fields.NotificationPhase.END)
2602 
2603         do_stop_instance()
2604 
2605     def _power_on(self, context, instance):
2606         network_info = self.network_api.get_instance_nw_info(context, instance)
2607         block_device_info = self._get_instance_block_device_info(context,
2608                                                                  instance)
2609         self.driver.power_on(context, instance,
2610                              network_info,
2611                              block_device_info)
2612 
2613     def _delete_snapshot_of_shelved_instance(self, context, instance,
2614                                              snapshot_id):
2615         """Delete snapshot of shelved instance."""
2616         try:
2617             self.image_api.delete(context, snapshot_id)
2618         except (exception.ImageNotFound,
2619                 exception.ImageNotAuthorized) as exc:
2620             LOG.warning("Failed to delete snapshot "
2621                         "from shelved instance (%s).",
2622                         exc.format_message(), instance=instance)
2623         except Exception:
2624             LOG.exception("Something wrong happened when trying to "
2625                           "delete snapshot from shelved instance.",
2626                           instance=instance)
2627 
2628     # NOTE(johannes): This is probably better named power_on_instance
2629     # so it matches the driver method, but because of other issues, we
2630     # can't use that name in grizzly.
2631     @wrap_exception()
2632     @reverts_task_state
2633     @wrap_instance_event(prefix='compute')
2634     @wrap_instance_fault
2635     def start_instance(self, context, instance):
2636         """Starting an instance on this host."""
2637         self._notify_about_instance_usage(context, instance, "power_on.start")
2638         compute_utils.notify_about_instance_action(context, instance,
2639             self.host, action=fields.NotificationAction.POWER_ON,
2640             phase=fields.NotificationPhase.START)
2641         self._power_on(context, instance)
2642         instance.power_state = self._get_power_state(context, instance)
2643         instance.vm_state = vm_states.ACTIVE
2644         instance.task_state = None
2645 
2646         # Delete an image(VM snapshot) for a shelved instance
2647         snapshot_id = instance.system_metadata.get('shelved_image_id')
2648         if snapshot_id:
2649             self._delete_snapshot_of_shelved_instance(context, instance,
2650                                                       snapshot_id)
2651 
2652         # Delete system_metadata for a shelved instance
2653         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2654 
2655         instance.save(expected_task_state=task_states.POWERING_ON)
2656         self._notify_about_instance_usage(context, instance, "power_on.end")
2657         compute_utils.notify_about_instance_action(context, instance,
2658             self.host, action=fields.NotificationAction.POWER_ON,
2659             phase=fields.NotificationPhase.END)
2660 
2661     @messaging.expected_exceptions(NotImplementedError,
2662                                    exception.TriggerCrashDumpNotSupported,
2663                                    exception.InstanceNotRunning)
2664     @wrap_exception()
2665     @wrap_instance_event(prefix='compute')
2666     @wrap_instance_fault
2667     def trigger_crash_dump(self, context, instance):
2668         """Trigger crash dump in an instance."""
2669 
2670         self._notify_about_instance_usage(context, instance,
2671                                           "trigger_crash_dump.start")
2672         compute_utils.notify_about_instance_action(context, instance,
2673                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2674                 phase=fields.NotificationPhase.START)
2675 
2676         # This method does not change task_state and power_state because the
2677         # effect of a trigger depends on user's configuration.
2678         self.driver.trigger_crash_dump(instance)
2679 
2680         self._notify_about_instance_usage(context, instance,
2681                                           "trigger_crash_dump.end")
2682         compute_utils.notify_about_instance_action(context, instance,
2683                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2684                 phase=fields.NotificationPhase.END)
2685 
2686     @wrap_exception()
2687     @reverts_task_state
2688     @wrap_instance_event(prefix='compute')
2689     @wrap_instance_fault
2690     def soft_delete_instance(self, context, instance, reservations):
2691         """Soft delete an instance on this host."""
2692         with compute_utils.notify_about_instance_delete(
2693                 self.notifier, context, instance, 'soft_delete'):
2694             compute_utils.notify_about_instance_action(context, instance,
2695                 self.host, action=fields.NotificationAction.SOFT_DELETE,
2696                 phase=fields.NotificationPhase.START)
2697             try:
2698                 self.driver.soft_delete(instance)
2699             except NotImplementedError:
2700                 # Fallback to just powering off the instance if the
2701                 # hypervisor doesn't implement the soft_delete method
2702                 self.driver.power_off(instance)
2703             instance.power_state = self._get_power_state(context, instance)
2704             instance.vm_state = vm_states.SOFT_DELETED
2705             instance.task_state = None
2706             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2707             compute_utils.notify_about_instance_action(
2708                 context, instance, self.host,
2709                 action=fields.NotificationAction.SOFT_DELETE,
2710                 phase=fields.NotificationPhase.END)
2711 
2712     @wrap_exception()
2713     @reverts_task_state
2714     @wrap_instance_event(prefix='compute')
2715     @wrap_instance_fault
2716     def restore_instance(self, context, instance):
2717         """Restore a soft-deleted instance on this host."""
2718         self._notify_about_instance_usage(context, instance, "restore.start")
2719         compute_utils.notify_about_instance_action(context, instance,
2720             self.host, action=fields.NotificationAction.RESTORE,
2721             phase=fields.NotificationPhase.START)
2722         try:
2723             self.driver.restore(instance)
2724         except NotImplementedError:
2725             # Fallback to just powering on the instance if the hypervisor
2726             # doesn't implement the restore method
2727             self._power_on(context, instance)
2728         instance.power_state = self._get_power_state(context, instance)
2729         instance.vm_state = vm_states.ACTIVE
2730         instance.task_state = None
2731         instance.save(expected_task_state=task_states.RESTORING)
2732         self._notify_about_instance_usage(context, instance, "restore.end")
2733         compute_utils.notify_about_instance_action(context, instance,
2734             self.host, action=fields.NotificationAction.RESTORE,
2735             phase=fields.NotificationPhase.END)
2736 
2737     @staticmethod
2738     def _set_migration_status(migration, status):
2739         """Set the status, and guard against a None being passed in.
2740 
2741         This is useful as some of the compute RPC calls will not pass
2742         a migration object in older versions. The check can be removed when
2743         we move past 4.x major version of the RPC API.
2744         """
2745         if migration:
2746             migration.status = status
2747             migration.save()
2748 
2749     def _rebuild_default_impl(self, context, instance, image_meta,
2750                               injected_files, admin_password, allocations,
2751                               bdms, detach_block_devices, attach_block_devices,
2752                               network_info=None,
2753                               recreate=False, block_device_info=None,
2754                               preserve_ephemeral=False):
2755         if preserve_ephemeral:
2756             # The default code path does not support preserving ephemeral
2757             # partitions.
2758             raise exception.PreserveEphemeralNotSupported()
2759 
2760         if recreate:
2761             detach_block_devices(context, bdms)
2762         else:
2763             self._power_off_instance(context, instance, clean_shutdown=True)
2764             detach_block_devices(context, bdms)
2765             self.driver.destroy(context, instance,
2766                                 network_info=network_info,
2767                                 block_device_info=block_device_info)
2768 
2769         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2770         instance.save(expected_task_state=[task_states.REBUILDING])
2771 
2772         new_block_device_info = attach_block_devices(context, instance, bdms)
2773 
2774         instance.task_state = task_states.REBUILD_SPAWNING
2775         instance.save(
2776             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2777 
2778         with instance.mutated_migration_context():
2779             self.driver.spawn(context, instance, image_meta, injected_files,
2780                               admin_password, allocations,
2781                               network_info=network_info,
2782                               block_device_info=new_block_device_info)
2783 
2784     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
2785         self._notify_about_instance_usage(context, instance,
2786                                           'rebuild.error', fault=error)
2787         compute_utils.notify_about_instance_action(
2788             context, instance, self.host,
2789             action=fields.NotificationAction.REBUILD,
2790             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms)
2791 
2792     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2793     @wrap_exception()
2794     @reverts_task_state
2795     @wrap_instance_event(prefix='compute')
2796     @wrap_instance_fault
2797     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2798                          injected_files, new_pass, orig_sys_metadata,
2799                          bdms, recreate, on_shared_storage=None,
2800                          preserve_ephemeral=False, migration=None,
2801                          scheduled_node=None, limits=None):
2802         """Destroy and re-make this instance.
2803 
2804         A 'rebuild' effectively purges all existing data from the system and
2805         remakes the VM with given 'metadata' and 'personalities'.
2806 
2807         :param context: `nova.RequestContext` object
2808         :param instance: Instance object
2809         :param orig_image_ref: Original image_ref before rebuild
2810         :param image_ref: New image_ref for rebuild
2811         :param injected_files: Files to inject
2812         :param new_pass: password to set on rebuilt instance
2813         :param orig_sys_metadata: instance system metadata from pre-rebuild
2814         :param bdms: block-device-mappings to use for rebuild
2815         :param recreate: True if the instance is being recreated (e.g. the
2816             hypervisor it was on failed) - cleanup of old state will be
2817             skipped.
2818         :param on_shared_storage: True if instance files on shared storage.
2819                                   If not provided then information from the
2820                                   driver will be used to decide if the instance
2821                                   files are available or not on the target host
2822         :param preserve_ephemeral: True if the default ephemeral storage
2823                                    partition must be preserved on rebuild
2824         :param migration: a Migration object if one was created for this
2825                           rebuild operation (if it's a part of evacuate)
2826         :param scheduled_node: A node of the host chosen by the scheduler. If a
2827                                host was specified by the user, this will be
2828                                None
2829         :param limits: Overcommit limits set by the scheduler. If a host was
2830                        specified by the user, this will be None
2831         """
2832         context = context.elevated()
2833 
2834         LOG.info("Rebuilding instance", instance=instance)
2835 
2836         # NOTE(gyee): there are three possible scenarios.
2837         #
2838         #   1. instance is being rebuilt on the same node. In this case,
2839         #      recreate should be False and scheduled_node should be None.
2840         #   2. instance is being rebuilt on a node chosen by the
2841         #      scheduler (i.e. evacuate). In this case, scheduled_node should
2842         #      be specified and recreate should be True.
2843         #   3. instance is being rebuilt on a node chosen by the user. (i.e.
2844         #      force evacuate). In this case, scheduled_node is not specified
2845         #      and recreate is set to True.
2846         #
2847         # For scenarios #2 and #3, we must do rebuild claim as server is
2848         # being evacuated to a different node.
2849         rt = self._get_resource_tracker()
2850         if recreate or scheduled_node is not None:
2851             rebuild_claim = rt.rebuild_claim
2852         else:
2853             rebuild_claim = claims.NopClaim
2854 
2855         image_meta = {}
2856         if image_ref:
2857             image_meta = self.image_api.get(context, image_ref)
2858 
2859         # NOTE(mriedem): On a recreate (evacuate), we need to update
2860         # the instance's host and node properties to reflect it's
2861         # destination node for the recreate.
2862         if not scheduled_node:
2863             if recreate:
2864                 try:
2865                     compute_node = self._get_compute_info(context, self.host)
2866                     scheduled_node = compute_node.hypervisor_hostname
2867                 except exception.ComputeHostNotFound:
2868                     LOG.exception('Failed to get compute_info for %s',
2869                                   self.host)
2870             else:
2871                 scheduled_node = instance.node
2872 
2873         with self._error_out_instance_on_exception(context, instance):
2874             try:
2875                 claim_ctxt = rebuild_claim(
2876                     context, instance, scheduled_node,
2877                     limits=limits, image_meta=image_meta,
2878                     migration=migration)
2879                 self._do_rebuild_instance_with_claim(
2880                     claim_ctxt, context, instance, orig_image_ref,
2881                     image_ref, injected_files, new_pass, orig_sys_metadata,
2882                     bdms, recreate, on_shared_storage, preserve_ephemeral)
2883             except exception.ComputeResourcesUnavailable as e:
2884                 LOG.debug("Could not rebuild instance on this host, not "
2885                           "enough resources available.", instance=instance)
2886 
2887                 # NOTE(ndipanov): We just abort the build for now and leave a
2888                 # migration record for potential cleanup later
2889                 self._set_migration_status(migration, 'failed')
2890                 # Since the claim failed, we need to remove the allocation
2891                 # created against the destination node. Note that we can only
2892                 # get here when evacuating to a destination node. Rebuilding
2893                 # on the same host (not evacuate) uses the NopClaim which will
2894                 # not raise ComputeResourcesUnavailable.
2895                 rt.delete_allocation_for_evacuated_instance(
2896                     instance, scheduled_node, node_type='destination')
2897                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2898                 raise exception.BuildAbortException(
2899                     instance_uuid=instance.uuid, reason=e.format_message())
2900             except (exception.InstanceNotFound,
2901                     exception.UnexpectedDeletingTaskStateError) as e:
2902                 LOG.debug('Instance was deleted while rebuilding',
2903                           instance=instance)
2904                 self._set_migration_status(migration, 'failed')
2905                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2906             except Exception as e:
2907                 self._set_migration_status(migration, 'failed')
2908                 if recreate or scheduled_node is not None:
2909                     rt.delete_allocation_for_evacuated_instance(
2910                         instance, scheduled_node, node_type='destination')
2911                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2912                 raise
2913             else:
2914                 instance.apply_migration_context()
2915                 # NOTE (ndipanov): This save will now update the host and node
2916                 # attributes making sure that next RT pass is consistent since
2917                 # it will be based on the instance and not the migration DB
2918                 # entry.
2919                 instance.host = self.host
2920                 instance.node = scheduled_node
2921                 instance.save()
2922                 instance.drop_migration_context()
2923 
2924                 # NOTE (ndipanov): Mark the migration as done only after we
2925                 # mark the instance as belonging to this host.
2926                 self._set_migration_status(migration, 'done')
2927 
2928     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2929         """Helper to avoid deep nesting in the top-level method."""
2930 
2931         with claim_context:
2932             self._do_rebuild_instance(*args, **kwargs)
2933 
2934     @staticmethod
2935     def _get_image_name(image_meta):
2936         if image_meta.obj_attr_is_set("name"):
2937             return image_meta.name
2938         else:
2939             return ''
2940 
2941     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2942                              image_ref, injected_files, new_pass,
2943                              orig_sys_metadata, bdms, recreate,
2944                              on_shared_storage, preserve_ephemeral):
2945         orig_vm_state = instance.vm_state
2946 
2947         if recreate:
2948             if not self.driver.capabilities["supports_recreate"]:
2949                 raise exception.InstanceRecreateNotSupported
2950 
2951             self._check_instance_exists(context, instance)
2952 
2953             if on_shared_storage is None:
2954                 LOG.debug('on_shared_storage is not provided, using driver'
2955                             'information to decide if the instance needs to'
2956                             'be recreated')
2957                 on_shared_storage = self.driver.instance_on_disk(instance)
2958 
2959             elif (on_shared_storage !=
2960                     self.driver.instance_on_disk(instance)):
2961                 # To cover case when admin expects that instance files are
2962                 # on shared storage, but not accessible and vice versa
2963                 raise exception.InvalidSharedStorage(
2964                         _("Invalid state of instance files on shared"
2965                             " storage"))
2966 
2967             if on_shared_storage:
2968                 LOG.info('disk on shared storage, recreating using'
2969                          ' existing disk')
2970             else:
2971                 image_ref = orig_image_ref = instance.image_ref
2972                 LOG.info("disk not on shared storage, rebuilding from:"
2973                          " '%s'", str(image_ref))
2974 
2975         if image_ref:
2976             image_meta = objects.ImageMeta.from_image_ref(
2977                 context, self.image_api, image_ref)
2978         else:
2979             image_meta = instance.image_meta
2980 
2981         # This instance.exists message should contain the original
2982         # image_ref, not the new one.  Since the DB has been updated
2983         # to point to the new one... we have to override it.
2984         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
2985                                                                context)
2986         extra_usage_info = {'image_ref_url': orig_image_ref_url}
2987         compute_utils.notify_usage_exists(
2988                 self.notifier, context, instance,
2989                 current_period=True, system_metadata=orig_sys_metadata,
2990                 extra_usage_info=extra_usage_info)
2991 
2992         # This message should contain the new image_ref
2993         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
2994         self._notify_about_instance_usage(context, instance,
2995                 "rebuild.start", extra_usage_info=extra_usage_info)
2996         # NOTE: image_name is not included in the versioned notification
2997         # because we already provide the image_uuid in the notification
2998         # payload and the image details can be looked up via the uuid.
2999         compute_utils.notify_about_instance_action(
3000             context, instance, self.host,
3001             action=fields.NotificationAction.REBUILD,
3002             phase=fields.NotificationPhase.START,
3003             bdms=bdms)
3004 
3005         instance.power_state = self._get_power_state(context, instance)
3006         instance.task_state = task_states.REBUILDING
3007         instance.save(expected_task_state=[task_states.REBUILDING])
3008 
3009         if recreate:
3010             self.network_api.setup_networks_on_host(
3011                     context, instance, self.host)
3012             # For nova-network this is needed to move floating IPs
3013             # For neutron this updates the host in the port binding
3014             # TODO(cfriesen): this network_api call and the one above
3015             # are so similar, we should really try to unify them.
3016             self.network_api.setup_instance_network_on_host(
3017                     context, instance, self.host)
3018 
3019         allocations = self.reportclient.get_allocations_for_consumer(
3020             instance.uuid)
3021 
3022         network_info = instance.get_network_info()
3023         if bdms is None:
3024             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3025                     context, instance.uuid)
3026 
3027         block_device_info = \
3028             self._get_instance_block_device_info(
3029                     context, instance, bdms=bdms)
3030 
3031         def detach_block_devices(context, bdms):
3032             for bdm in bdms:
3033                 if bdm.is_volume:
3034                     # NOTE (ildikov): Having the attachment_id set in the BDM
3035                     # means that it's the new Cinder attach/detach flow
3036                     # (available from v3.44). In that case we explicitly
3037                     # attach and detach the volumes through attachment level
3038                     # operations. In this scenario _detach_volume will delete
3039                     # the existing attachment which would make the volume
3040                     # status change to 'in-use' if we don't pre-create another
3041                     # empty attachment before deleting the old one.
3042                     attachment_id = None
3043                     if bdm.attachment_id:
3044                         attachment_id = self.volume_api.attachment_create(
3045                             context, bdm['volume_id'], instance.uuid)['id']
3046                     self._detach_volume(context, bdm, instance,
3047                                         destroy_bdm=False)
3048                     if attachment_id:
3049                         bdm.attachment_id = attachment_id
3050                         bdm.save()
3051 
3052         files = self._decode_files(injected_files)
3053 
3054         kwargs = dict(
3055             context=context,
3056             instance=instance,
3057             image_meta=image_meta,
3058             injected_files=files,
3059             admin_password=new_pass,
3060             allocations=allocations,
3061             bdms=bdms,
3062             detach_block_devices=detach_block_devices,
3063             attach_block_devices=self._prep_block_device,
3064             block_device_info=block_device_info,
3065             network_info=network_info,
3066             preserve_ephemeral=preserve_ephemeral,
3067             recreate=recreate)
3068         try:
3069             with instance.mutated_migration_context():
3070                 self.driver.rebuild(**kwargs)
3071         except NotImplementedError:
3072             # NOTE(rpodolyaka): driver doesn't provide specialized version
3073             # of rebuild, fall back to the default implementation
3074             self._rebuild_default_impl(**kwargs)
3075         self._update_instance_after_spawn(context, instance)
3076         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3077 
3078         if orig_vm_state == vm_states.STOPPED:
3079             LOG.info("bringing vm to original state: '%s'",
3080                      orig_vm_state, instance=instance)
3081             instance.vm_state = vm_states.ACTIVE
3082             instance.task_state = task_states.POWERING_OFF
3083             instance.progress = 0
3084             instance.save()
3085             self.stop_instance(context, instance, False)
3086         self._update_scheduler_instance_info(context, instance)
3087         self._notify_about_instance_usage(
3088                 context, instance, "rebuild.end",
3089                 network_info=network_info,
3090                 extra_usage_info=extra_usage_info)
3091         compute_utils.notify_about_instance_action(
3092             context, instance, self.host,
3093             action=fields.NotificationAction.REBUILD,
3094             phase=fields.NotificationPhase.END,
3095             bdms=bdms)
3096 
3097     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3098                                      block_device_info):
3099         """Handle cases where the virt-layer had to detach non-working volumes
3100         in order to complete an operation.
3101         """
3102         for bdm in block_device_info['block_device_mapping']:
3103             if bdm.get('mount_device') in bad_devices:
3104                 try:
3105                     volume_id = bdm['connection_info']['data']['volume_id']
3106                 except KeyError:
3107                     continue
3108 
3109                 # NOTE(sirp): ideally we'd just call
3110                 # `compute_api.detach_volume` here but since that hits the
3111                 # DB directly, that's off limits from within the
3112                 # compute-manager.
3113                 #
3114                 # API-detach
3115                 LOG.info("Detaching from volume api: %s", volume_id)
3116                 self.volume_api.begin_detaching(context, volume_id)
3117 
3118                 # Manager-detach
3119                 self.detach_volume(context, volume_id, instance)
3120 
3121     @wrap_exception()
3122     @reverts_task_state
3123     @wrap_instance_event(prefix='compute')
3124     @wrap_instance_fault
3125     def reboot_instance(self, context, instance, block_device_info,
3126                         reboot_type):
3127         """Reboot an instance on this host."""
3128         # acknowledge the request made it to the manager
3129         if reboot_type == "SOFT":
3130             instance.task_state = task_states.REBOOT_PENDING
3131             expected_states = task_states.soft_reboot_states
3132         else:
3133             instance.task_state = task_states.REBOOT_PENDING_HARD
3134             expected_states = task_states.hard_reboot_states
3135 
3136         context = context.elevated()
3137         LOG.info("Rebooting instance", instance=instance)
3138 
3139         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3140             context, instance.uuid)
3141         block_device_info = self._get_instance_block_device_info(
3142             context, instance, bdms=bdms)
3143 
3144         network_info = self.network_api.get_instance_nw_info(context, instance)
3145 
3146         self._notify_about_instance_usage(context, instance, "reboot.start")
3147         compute_utils.notify_about_instance_action(
3148             context, instance, self.host,
3149             action=fields.NotificationAction.REBOOT,
3150             phase=fields.NotificationPhase.START,
3151             bdms=bdms
3152         )
3153 
3154         instance.power_state = self._get_power_state(context, instance)
3155         instance.save(expected_task_state=expected_states)
3156 
3157         if instance.power_state != power_state.RUNNING:
3158             state = instance.power_state
3159             running = power_state.RUNNING
3160             LOG.warning('trying to reboot a non-running instance:'
3161                         ' (state: %(state)s expected: %(running)s)',
3162                         {'state': state, 'running': running},
3163                         instance=instance)
3164 
3165         def bad_volumes_callback(bad_devices):
3166             self._handle_bad_volumes_detached(
3167                     context, instance, bad_devices, block_device_info)
3168 
3169         try:
3170             # Don't change it out of rescue mode
3171             if instance.vm_state == vm_states.RESCUED:
3172                 new_vm_state = vm_states.RESCUED
3173             else:
3174                 new_vm_state = vm_states.ACTIVE
3175             new_power_state = None
3176             if reboot_type == "SOFT":
3177                 instance.task_state = task_states.REBOOT_STARTED
3178                 expected_state = task_states.REBOOT_PENDING
3179             else:
3180                 instance.task_state = task_states.REBOOT_STARTED_HARD
3181                 expected_state = task_states.REBOOT_PENDING_HARD
3182             instance.save(expected_task_state=expected_state)
3183             self.driver.reboot(context, instance,
3184                                network_info,
3185                                reboot_type,
3186                                block_device_info=block_device_info,
3187                                bad_volumes_callback=bad_volumes_callback)
3188 
3189         except Exception as error:
3190             with excutils.save_and_reraise_exception() as ctxt:
3191                 exc_info = sys.exc_info()
3192                 # if the reboot failed but the VM is running don't
3193                 # put it into an error state
3194                 new_power_state = self._get_power_state(context, instance)
3195                 if new_power_state == power_state.RUNNING:
3196                     LOG.warning('Reboot failed but instance is running',
3197                                 instance=instance)
3198                     compute_utils.add_instance_fault_from_exc(context,
3199                             instance, error, exc_info)
3200                     self._notify_about_instance_usage(context, instance,
3201                             'reboot.error', fault=error)
3202                     compute_utils.notify_about_instance_action(
3203                         context, instance, self.host,
3204                         action=fields.NotificationAction.REBOOT,
3205                         phase=fields.NotificationPhase.ERROR,
3206                         exception=error, bdms=bdms
3207                     )
3208                     ctxt.reraise = False
3209                 else:
3210                     LOG.error('Cannot reboot instance: %s', error,
3211                               instance=instance)
3212                     self._set_instance_obj_error_state(context, instance)
3213 
3214         if not new_power_state:
3215             new_power_state = self._get_power_state(context, instance)
3216         try:
3217             instance.power_state = new_power_state
3218             instance.vm_state = new_vm_state
3219             instance.task_state = None
3220             instance.save()
3221         except exception.InstanceNotFound:
3222             LOG.warning("Instance disappeared during reboot",
3223                         instance=instance)
3224 
3225         self._notify_about_instance_usage(context, instance, "reboot.end")
3226         compute_utils.notify_about_instance_action(
3227             context, instance, self.host,
3228             action=fields.NotificationAction.REBOOT,
3229             phase=fields.NotificationPhase.END,
3230             bdms=bdms
3231         )
3232 
3233     @delete_image_on_error
3234     def _do_snapshot_instance(self, context, image_id, instance):
3235         self._snapshot_instance(context, image_id, instance,
3236                                 task_states.IMAGE_BACKUP)
3237 
3238     @wrap_exception()
3239     @reverts_task_state
3240     @wrap_instance_event(prefix='compute')
3241     @wrap_instance_fault
3242     def backup_instance(self, context, image_id, instance, backup_type,
3243                         rotation):
3244         """Backup an instance on this host.
3245 
3246         :param backup_type: daily | weekly
3247         :param rotation: int representing how many backups to keep around
3248         """
3249         self._do_snapshot_instance(context, image_id, instance)
3250         self._rotate_backups(context, instance, backup_type, rotation)
3251 
3252     @wrap_exception()
3253     @reverts_task_state
3254     @wrap_instance_event(prefix='compute')
3255     @wrap_instance_fault
3256     @delete_image_on_error
3257     def snapshot_instance(self, context, image_id, instance):
3258         """Snapshot an instance on this host.
3259 
3260         :param context: security context
3261         :param image_id: glance.db.sqlalchemy.models.Image.Id
3262         :param instance: a nova.objects.instance.Instance object
3263         """
3264         # NOTE(dave-mcnally) the task state will already be set by the api
3265         # but if the compute manager has crashed/been restarted prior to the
3266         # request getting here the task state may have been cleared so we set
3267         # it again and things continue normally
3268         try:
3269             instance.task_state = task_states.IMAGE_SNAPSHOT
3270             instance.save(
3271                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3272         except exception.InstanceNotFound:
3273             # possibility instance no longer exists, no point in continuing
3274             LOG.debug("Instance not found, could not set state %s "
3275                       "for instance.",
3276                       task_states.IMAGE_SNAPSHOT, instance=instance)
3277             return
3278 
3279         except exception.UnexpectedDeletingTaskStateError:
3280             LOG.debug("Instance being deleted, snapshot cannot continue",
3281                       instance=instance)
3282             return
3283 
3284         self._snapshot_instance(context, image_id, instance,
3285                                 task_states.IMAGE_SNAPSHOT)
3286 
3287     def _snapshot_instance(self, context, image_id, instance,
3288                            expected_task_state):
3289         context = context.elevated()
3290 
3291         instance.power_state = self._get_power_state(context, instance)
3292         try:
3293             instance.save()
3294 
3295             LOG.info('instance snapshotting', instance=instance)
3296 
3297             if instance.power_state != power_state.RUNNING:
3298                 state = instance.power_state
3299                 running = power_state.RUNNING
3300                 LOG.warning('trying to snapshot a non-running instance: '
3301                             '(state: %(state)s expected: %(running)s)',
3302                             {'state': state, 'running': running},
3303                             instance=instance)
3304 
3305             self._notify_about_instance_usage(
3306                 context, instance, "snapshot.start")
3307             compute_utils.notify_about_instance_snapshot(context, instance,
3308                 self.host, phase=fields.NotificationPhase.START,
3309                 snapshot_image_id=image_id)
3310 
3311             def update_task_state(task_state,
3312                                   expected_state=expected_task_state):
3313                 instance.task_state = task_state
3314                 instance.save(expected_task_state=expected_state)
3315 
3316             self.driver.snapshot(context, instance, image_id,
3317                                  update_task_state)
3318 
3319             instance.task_state = None
3320             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3321 
3322             self._notify_about_instance_usage(context, instance,
3323                                               "snapshot.end")
3324             compute_utils.notify_about_instance_snapshot(context, instance,
3325                 self.host, phase=fields.NotificationPhase.END,
3326                 snapshot_image_id=image_id)
3327         except (exception.InstanceNotFound,
3328                 exception.UnexpectedDeletingTaskStateError):
3329             # the instance got deleted during the snapshot
3330             # Quickly bail out of here
3331             msg = 'Instance disappeared during snapshot'
3332             LOG.debug(msg, instance=instance)
3333             try:
3334                 image = self.image_api.get(context, image_id)
3335                 if image['status'] != 'active':
3336                     self.image_api.delete(context, image_id)
3337             except Exception:
3338                 LOG.warning("Error while trying to clean up image %s",
3339                             image_id, instance=instance)
3340         except exception.ImageNotFound:
3341             instance.task_state = None
3342             instance.save()
3343             LOG.warning("Image not found during snapshot", instance=instance)
3344 
3345     def _post_interrupted_snapshot_cleanup(self, context, instance):
3346         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3347 
3348     @messaging.expected_exceptions(NotImplementedError)
3349     @wrap_exception()
3350     def volume_snapshot_create(self, context, instance, volume_id,
3351                                create_info):
3352         self.driver.volume_snapshot_create(context, instance, volume_id,
3353                                            create_info)
3354 
3355     @messaging.expected_exceptions(NotImplementedError)
3356     @wrap_exception()
3357     def volume_snapshot_delete(self, context, instance, volume_id,
3358                                snapshot_id, delete_info):
3359         self.driver.volume_snapshot_delete(context, instance, volume_id,
3360                                            snapshot_id, delete_info)
3361 
3362     @wrap_instance_fault
3363     def _rotate_backups(self, context, instance, backup_type, rotation):
3364         """Delete excess backups associated to an instance.
3365 
3366         Instances are allowed a fixed number of backups (the rotation number);
3367         this method deletes the oldest backups that exceed the rotation
3368         threshold.
3369 
3370         :param context: security context
3371         :param instance: Instance dict
3372         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3373         :param rotation: int representing how many backups to keep around;
3374             None if rotation shouldn't be used (as in the case of snapshots)
3375         """
3376         filters = {'property-image_type': 'backup',
3377                    'property-backup_type': backup_type,
3378                    'property-instance_uuid': instance.uuid}
3379 
3380         images = self.image_api.get_all(context, filters=filters,
3381                                         sort_key='created_at', sort_dir='desc')
3382         num_images = len(images)
3383         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3384                   {'num_images': num_images, 'rotation': rotation},
3385                   instance=instance)
3386 
3387         if num_images > rotation:
3388             # NOTE(sirp): this deletes all backups that exceed the rotation
3389             # limit
3390             excess = len(images) - rotation
3391             LOG.debug("Rotating out %d backups", excess,
3392                       instance=instance)
3393             for i in range(excess):
3394                 image = images.pop()
3395                 image_id = image['id']
3396                 LOG.debug("Deleting image %s", image_id,
3397                           instance=instance)
3398                 try:
3399                     self.image_api.delete(context, image_id)
3400                 except exception.ImageNotFound:
3401                     LOG.info("Failed to find image %(image_id)s to "
3402                              "delete", {'image_id': image_id},
3403                              instance=instance)
3404 
3405     @wrap_exception()
3406     @reverts_task_state
3407     @wrap_instance_event(prefix='compute')
3408     @wrap_instance_fault
3409     def set_admin_password(self, context, instance, new_pass):
3410         """Set the root/admin password for an instance on this host.
3411 
3412         This is generally only called by API password resets after an
3413         image has been built.
3414 
3415         @param context: Nova auth context.
3416         @param instance: Nova instance object.
3417         @param new_pass: The admin password for the instance.
3418         """
3419 
3420         context = context.elevated()
3421         if new_pass is None:
3422             # Generate a random password
3423             new_pass = utils.generate_password()
3424 
3425         current_power_state = self._get_power_state(context, instance)
3426         expected_state = power_state.RUNNING
3427 
3428         if current_power_state != expected_state:
3429             instance.task_state = None
3430             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3431             _msg = _('instance %s is not running') % instance.uuid
3432             raise exception.InstancePasswordSetFailed(
3433                 instance=instance.uuid, reason=_msg)
3434 
3435         try:
3436             self.driver.set_admin_password(instance, new_pass)
3437             LOG.info("Admin password set", instance=instance)
3438             instance.task_state = None
3439             instance.save(
3440                 expected_task_state=task_states.UPDATING_PASSWORD)
3441         except exception.InstanceAgentNotEnabled:
3442             with excutils.save_and_reraise_exception():
3443                 LOG.debug('Guest agent is not enabled for the instance.',
3444                           instance=instance)
3445                 instance.task_state = None
3446                 instance.save(
3447                     expected_task_state=task_states.UPDATING_PASSWORD)
3448         except exception.SetAdminPasswdNotSupported:
3449             with excutils.save_and_reraise_exception():
3450                 LOG.info('set_admin_password is not supported '
3451                          'by this driver or guest instance.',
3452                          instance=instance)
3453                 instance.task_state = None
3454                 instance.save(
3455                     expected_task_state=task_states.UPDATING_PASSWORD)
3456         except NotImplementedError:
3457             LOG.warning('set_admin_password is not implemented '
3458                         'by this driver or guest instance.',
3459                         instance=instance)
3460             instance.task_state = None
3461             instance.save(
3462                 expected_task_state=task_states.UPDATING_PASSWORD)
3463             raise NotImplementedError(_('set_admin_password is not '
3464                                         'implemented by this driver or guest '
3465                                         'instance.'))
3466         except exception.UnexpectedTaskStateError:
3467             # interrupted by another (most likely delete) task
3468             # do not retry
3469             raise
3470         except Exception:
3471             # Catch all here because this could be anything.
3472             LOG.exception('set_admin_password failed', instance=instance)
3473             self._set_instance_obj_error_state(context, instance)
3474             # We create a new exception here so that we won't
3475             # potentially reveal password information to the
3476             # API caller.  The real exception is logged above
3477             _msg = _('error setting admin password')
3478             raise exception.InstancePasswordSetFailed(
3479                 instance=instance.uuid, reason=_msg)
3480 
3481     @wrap_exception()
3482     @reverts_task_state
3483     @wrap_instance_fault
3484     def inject_file(self, context, path, file_contents, instance):
3485         """Write a file to the specified path in an instance on this host."""
3486         # NOTE(russellb) Remove this method, as well as the underlying virt
3487         # driver methods, when the compute rpc interface is bumped to 4.x
3488         # as it is no longer used.
3489         context = context.elevated()
3490         current_power_state = self._get_power_state(context, instance)
3491         expected_state = power_state.RUNNING
3492         if current_power_state != expected_state:
3493             LOG.warning('trying to inject a file into a non-running '
3494                         '(state: %(current_state)s expected: '
3495                         '%(expected_state)s)',
3496                         {'current_state': current_power_state,
3497                          'expected_state': expected_state},
3498                         instance=instance)
3499         LOG.info('injecting file to %s', path, instance=instance)
3500         self.driver.inject_file(instance, path, file_contents)
3501 
3502     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3503         """Determine what image should be used to boot the rescue VM."""
3504         # 1. If rescue_image_ref is passed in, use that for rescue.
3505         # 2. Else, use the base image associated with instance's current image.
3506         #       The idea here is to provide the customer with a rescue
3507         #       environment which they are familiar with.
3508         #       So, if they built their instance off of a Debian image,
3509         #       their rescue VM will also be Debian.
3510         # 3. As a last resort, use instance's current image.
3511         if not rescue_image_ref:
3512             system_meta = utils.instance_sys_meta(instance)
3513             rescue_image_ref = system_meta.get('image_base_image_ref')
3514 
3515         if not rescue_image_ref:
3516             LOG.warning('Unable to find a different image to use for '
3517                         'rescue VM, using instance\'s current image',
3518                         instance=instance)
3519             rescue_image_ref = instance.image_ref
3520 
3521         return objects.ImageMeta.from_image_ref(
3522             context, self.image_api, rescue_image_ref)
3523 
3524     @wrap_exception()
3525     @reverts_task_state
3526     @wrap_instance_event(prefix='compute')
3527     @wrap_instance_fault
3528     def rescue_instance(self, context, instance, rescue_password,
3529                         rescue_image_ref, clean_shutdown):
3530         context = context.elevated()
3531         LOG.info('Rescuing', instance=instance)
3532 
3533         admin_password = (rescue_password if rescue_password else
3534                       utils.generate_password())
3535 
3536         network_info = self.network_api.get_instance_nw_info(context, instance)
3537 
3538         rescue_image_meta = self._get_rescue_image(context, instance,
3539                                                    rescue_image_ref)
3540 
3541         extra_usage_info = {'rescue_image_name':
3542                             self._get_image_name(rescue_image_meta)}
3543         self._notify_about_instance_usage(context, instance,
3544                 "rescue.start", extra_usage_info=extra_usage_info,
3545                 network_info=network_info)
3546 
3547         try:
3548             self._power_off_instance(context, instance, clean_shutdown)
3549 
3550             self.driver.rescue(context, instance,
3551                                network_info,
3552                                rescue_image_meta, admin_password)
3553         except Exception as e:
3554             LOG.exception("Error trying to Rescue Instance",
3555                           instance=instance)
3556             self._set_instance_obj_error_state(context, instance)
3557             raise exception.InstanceNotRescuable(
3558                 instance_id=instance.uuid,
3559                 reason=_("Driver Error: %s") % e)
3560 
3561         compute_utils.notify_usage_exists(self.notifier, context, instance,
3562                                           current_period=True)
3563 
3564         instance.vm_state = vm_states.RESCUED
3565         instance.task_state = None
3566         instance.power_state = self._get_power_state(context, instance)
3567         instance.launched_at = timeutils.utcnow()
3568         instance.save(expected_task_state=task_states.RESCUING)
3569 
3570         self._notify_about_instance_usage(context, instance,
3571                 "rescue.end", extra_usage_info=extra_usage_info,
3572                 network_info=network_info)
3573 
3574     @wrap_exception()
3575     @reverts_task_state
3576     @wrap_instance_event(prefix='compute')
3577     @wrap_instance_fault
3578     def unrescue_instance(self, context, instance):
3579         context = context.elevated()
3580         LOG.info('Unrescuing', instance=instance)
3581 
3582         network_info = self.network_api.get_instance_nw_info(context, instance)
3583         self._notify_about_instance_usage(context, instance,
3584                 "unrescue.start", network_info=network_info)
3585         with self._error_out_instance_on_exception(context, instance):
3586             self.driver.unrescue(instance,
3587                                  network_info)
3588 
3589         instance.vm_state = vm_states.ACTIVE
3590         instance.task_state = None
3591         instance.power_state = self._get_power_state(context, instance)
3592         instance.save(expected_task_state=task_states.UNRESCUING)
3593 
3594         self._notify_about_instance_usage(context,
3595                                           instance,
3596                                           "unrescue.end",
3597                                           network_info=network_info)
3598 
3599     @wrap_exception()
3600     @wrap_instance_fault
3601     def change_instance_metadata(self, context, diff, instance):
3602         """Update the metadata published to the instance."""
3603         LOG.debug("Changing instance metadata according to %r",
3604                   diff, instance=instance)
3605         self.driver.change_instance_metadata(context, instance, diff)
3606 
3607     @wrap_exception()
3608     @wrap_instance_event(prefix='compute')
3609     @wrap_instance_fault
3610     def confirm_resize(self, context, instance, reservations, migration):
3611         """Confirms a migration/resize and deletes the 'old' instance.
3612 
3613         This is called from the API and runs on the source host.
3614 
3615         Nothing needs to happen on the destination host at this point since
3616         the instance is already running there. This routine just cleans up the
3617         source host.
3618         """
3619         @utils.synchronized(instance.uuid)
3620         def do_confirm_resize(context, instance, migration_id):
3621             # NOTE(wangpan): Get the migration status from db, if it has been
3622             #                confirmed, we do nothing and return here
3623             LOG.debug("Going to confirm migration %s", migration_id,
3624                       instance=instance)
3625             try:
3626                 # TODO(russellb) Why are we sending the migration object just
3627                 # to turn around and look it up from the db again?
3628                 migration = objects.Migration.get_by_id(
3629                                     context.elevated(), migration_id)
3630             except exception.MigrationNotFound:
3631                 LOG.error("Migration %s is not found during confirmation",
3632                           migration_id, instance=instance)
3633                 return
3634 
3635             if migration.status == 'confirmed':
3636                 LOG.info("Migration %s is already confirmed",
3637                          migration_id, instance=instance)
3638                 return
3639             elif migration.status not in ('finished', 'confirming'):
3640                 LOG.warning("Unexpected confirmation status '%(status)s' "
3641                             "of migration %(id)s, exit confirmation process",
3642                             {"status": migration.status, "id": migration_id},
3643                             instance=instance)
3644                 return
3645 
3646             # NOTE(wangpan): Get the instance from db, if it has been
3647             #                deleted, we do nothing and return here
3648             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3649             try:
3650                 instance = objects.Instance.get_by_uuid(
3651                         context, instance.uuid,
3652                         expected_attrs=expected_attrs)
3653             except exception.InstanceNotFound:
3654                 LOG.info("Instance is not found during confirmation",
3655                          instance=instance)
3656                 return
3657 
3658             self._confirm_resize(context, instance, migration=migration)
3659 
3660         do_confirm_resize(context, instance, migration.id)
3661 
3662     def _confirm_resize(self, context, instance, migration=None):
3663         """Destroys the source instance."""
3664         self._notify_about_instance_usage(context, instance,
3665                                           "resize.confirm.start")
3666 
3667         with self._error_out_instance_on_exception(context, instance):
3668             # NOTE(danms): delete stashed migration information
3669             old_instance_type = instance.old_flavor
3670             instance.old_flavor = None
3671             instance.new_flavor = None
3672             instance.system_metadata.pop('old_vm_state', None)
3673             instance.save()
3674 
3675             # NOTE(tr3buchet): tear down networks on source host
3676             self.network_api.setup_networks_on_host(context, instance,
3677                                migration.source_compute, teardown=True)
3678 
3679             network_info = self.network_api.get_instance_nw_info(context,
3680                                                                  instance)
3681             # TODO(mriedem): Get BDMs here and pass them to the driver.
3682             self.driver.confirm_migration(context, migration, instance,
3683                                           network_info)
3684 
3685             migration.status = 'confirmed'
3686             with migration.obj_as_admin():
3687                 migration.save()
3688 
3689             rt = self._get_resource_tracker()
3690             rt.drop_move_claim(context, instance, migration.source_node,
3691                                old_instance_type, prefix='old_')
3692             self._delete_allocation_after_move(instance, migration,
3693                                                old_instance_type,
3694                                                migration.source_node)
3695             instance.drop_migration_context()
3696 
3697             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3698             # might have manually powered up the instance to confirm the
3699             # resize/migrate, so we need to check the current power state
3700             # on the instance and set the vm_state appropriately. We default
3701             # to ACTIVE because if the power state is not SHUTDOWN, we
3702             # assume _sync_instance_power_state will clean it up.
3703             p_state = instance.power_state
3704             vm_state = None
3705             if p_state == power_state.SHUTDOWN:
3706                 vm_state = vm_states.STOPPED
3707                 LOG.debug("Resized/migrated instance is powered off. "
3708                           "Setting vm_state to '%s'.", vm_state,
3709                           instance=instance)
3710             else:
3711                 vm_state = vm_states.ACTIVE
3712 
3713             instance.vm_state = vm_state
3714             instance.task_state = None
3715             instance.save(expected_task_state=[None, task_states.DELETING])
3716 
3717             self._notify_about_instance_usage(
3718                 context, instance, "resize.confirm.end",
3719                 network_info=network_info)
3720 
3721     def _delete_allocation_after_move(self, instance, migration, flavor,
3722                                       nodename):
3723         rt = self._get_resource_tracker()
3724         cn_uuid = rt.get_node_uuid(nodename)
3725 
3726         if migration.source_node == nodename:
3727             if migration.status in ('confirmed', 'completed'):
3728                 # NOTE(danms): We're finishing on the source node, so try to
3729                 # delete the allocation based on the migration uuid
3730                 deleted = self.reportclient.delete_allocation_for_instance(
3731                     migration.uuid)
3732                 if deleted:
3733                     LOG.info(_('Source node %(node)s confirmed migration '
3734                                '%(mig)s; deleted migration-based '
3735                                'allocation'),
3736                              {'node': nodename, 'mig': migration.uuid})
3737                     # NOTE(danms): We succeeded, which means we do not
3738                     # need to do the complex double allocation dance
3739                     return
3740             else:
3741                 # We're reverting (or failed) on the source, so we
3742                 # need to check if our migration holds a claim and if
3743                 # so, avoid doing the legacy behavior below.
3744                 mig_allocs = (
3745                     self.reportclient.get_allocations_for_consumer_by_provider(
3746                         cn_uuid, migration.uuid))
3747                 if mig_allocs:
3748                     LOG.info(_('Source node %(node)s reverted migration '
3749                                '%(mig)s; not deleting migration-based '
3750                                'allocation'),
3751                              {'node': nodename, 'mig': migration.uuid})
3752                     return
3753         elif migration.dest_node == nodename:
3754             # NOTE(danms): We're reverting on the destination node
3755             # (and we must not be doing a same-host migration if we
3756             # made it past the check above), so we need to check to
3757             # see if the source did migration-based allocation
3758             # accounting
3759             allocs = (
3760                 self.reportclient.get_allocations_for_consumer_by_provider(
3761                     cn_uuid, migration.uuid))
3762             if allocs:
3763                 # NOTE(danms): The source did migration-based allocation
3764                 # accounting, so we should let the source node rejigger
3765                 # the allocations in finish_resize_revert()
3766                 LOG.info(_('Destination node %(node)s reverted migration '
3767                            '%(mig)s; not deleting migration-based '
3768                            'allocation'),
3769                          {'node': nodename, 'mig': migration.uuid})
3770                 return
3771 
3772         # TODO(danms): Remove below this line when we remove compatibility
3773         # for double-accounting migrations (likely rocky)
3774         LOG.info(_('Doing legacy allocation math for migration %(mig)s after '
3775                    'instance move'),
3776                  {'mig': migration.uuid},
3777                  instance=instance)
3778 
3779         # NOTE(jaypipes): This sucks, but due to the fact that confirm_resize()
3780         # only runs on the source host and revert_resize() runs on the
3781         # destination host, we need to do this here. Basically, what we're
3782         # doing here is grabbing the existing allocations for this instance
3783         # from the placement API, dropping the resources in the doubled-up
3784         # allocation set that refer to the source host UUID and calling PUT
3785         # /allocations back to the placement API. The allocation that gets
3786         # PUT'd back to placement will only include the destination host and
3787         # any shared providers in the case of a confirm_resize operation and
3788         # the source host and shared providers for a revert_resize operation..
3789         my_resources = scheduler_utils.resources_from_flavor(instance, flavor)
3790         res = self.reportclient.remove_provider_from_instance_allocation(
3791             instance.uuid, cn_uuid, instance.user_id,
3792             instance.project_id, my_resources)
3793         if not res:
3794             LOG.error("Failed to save manipulated allocation",
3795                       instance=instance)
3796 
3797     @wrap_exception()
3798     @reverts_task_state
3799     @wrap_instance_event(prefix='compute')
3800     @errors_out_migration
3801     @wrap_instance_fault
3802     def revert_resize(self, context, instance, migration, reservations):
3803         """Destroys the new instance on the destination machine.
3804 
3805         Reverts the model changes, and powers on the old instance on the
3806         source machine.
3807 
3808         """
3809         # NOTE(comstud): A revert_resize is essentially a resize back to
3810         # the old size, so we need to send a usage event here.
3811         compute_utils.notify_usage_exists(self.notifier, context, instance,
3812                                           current_period=True)
3813 
3814         with self._error_out_instance_on_exception(context, instance):
3815             # NOTE(tr3buchet): tear down networks on destination host
3816             self.network_api.setup_networks_on_host(context, instance,
3817                                                     teardown=True)
3818 
3819             migration_p = obj_base.obj_to_primitive(migration)
3820             self.network_api.migrate_instance_start(context,
3821                                                     instance,
3822                                                     migration_p)
3823 
3824             network_info = self.network_api.get_instance_nw_info(context,
3825                                                                  instance)
3826             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3827                     context, instance.uuid)
3828             block_device_info = self._get_instance_block_device_info(
3829                                 context, instance, bdms=bdms)
3830 
3831             destroy_disks = not self._is_instance_storage_shared(
3832                 context, instance, host=migration.source_compute)
3833             self.driver.destroy(context, instance, network_info,
3834                                 block_device_info, destroy_disks)
3835 
3836             self._terminate_volume_connections(context, instance, bdms)
3837 
3838             migration.status = 'reverted'
3839             with migration.obj_as_admin():
3840                 migration.save()
3841 
3842             # NOTE(ndipanov): We need to do this here because dropping the
3843             # claim means we lose the migration_context data. We really should
3844             # fix this by moving the drop_move_claim call to the
3845             # finish_revert_resize method as this is racy (revert is dropped,
3846             # but instance resources will be tracked with the new flavor until
3847             # it gets rolled back in finish_revert_resize, which is
3848             # potentially wrong for a period of time).
3849             instance.revert_migration_context()
3850             instance.save()
3851 
3852             rt = self._get_resource_tracker()
3853             rt.drop_move_claim(context, instance, instance.node)
3854             self._delete_allocation_after_move(instance, migration,
3855                                                instance.flavor,
3856                                                instance.node)
3857 
3858             # RPC cast back to the source host to finish the revert there.
3859             self.compute_rpcapi.finish_revert_resize(context, instance,
3860                     migration, migration.source_compute)
3861 
3862     @wrap_exception()
3863     @reverts_task_state
3864     @wrap_instance_event(prefix='compute')
3865     @errors_out_migration
3866     @wrap_instance_fault
3867     def finish_revert_resize(self, context, instance, reservations, migration):
3868         """Finishes the second half of reverting a resize on the source host.
3869 
3870         Bring the original source instance state back (active/shutoff) and
3871         revert the resized attributes in the database.
3872 
3873         """
3874         with self._error_out_instance_on_exception(context, instance):
3875             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3876                 context, instance.uuid)
3877             self._notify_about_instance_usage(
3878                     context, instance, "resize.revert.start")
3879             compute_utils.notify_about_instance_action(context, instance,
3880                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
3881                     phase=fields.NotificationPhase.START, bdms=bdms)
3882 
3883             # NOTE(mriedem): delete stashed old_vm_state information; we
3884             # default to ACTIVE for backwards compatibility if old_vm_state
3885             # is not set
3886             old_vm_state = instance.system_metadata.pop('old_vm_state',
3887                                                         vm_states.ACTIVE)
3888 
3889             self._set_instance_info(instance, instance.old_flavor)
3890             instance.old_flavor = None
3891             instance.new_flavor = None
3892             instance.host = migration.source_compute
3893             instance.node = migration.source_node
3894             instance.save()
3895 
3896             self._revert_allocation(context, instance, migration)
3897 
3898             self.network_api.setup_networks_on_host(context, instance,
3899                                                     migration.source_compute)
3900             migration_p = obj_base.obj_to_primitive(migration)
3901             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
3902             # source host temporarily. "network_api.migrate_instance_finish"
3903             # will setup the network for the instance on the destination host.
3904             # For revert resize, the instance will back to the source host, the
3905             # setup of the network for instance should be on the source host.
3906             # So set the migration_p['dest_compute'] to source host at here.
3907             migration_p['dest_compute'] = migration.source_compute
3908             self.network_api.migrate_instance_finish(context,
3909                                                      instance,
3910                                                      migration_p)
3911             network_info = self.network_api.get_instance_nw_info(context,
3912                                                                  instance)
3913 
3914             # revert_resize deleted any volume attachments for the instance
3915             # and created new ones to be used on this host, but we
3916             # have to update those attachments with the host connector so the
3917             # BDM.connection_info will get set in the call to
3918             # _get_instance_block_device_info below with refresh_conn_info=True
3919             # and then the volumes can be re-connected via the driver on this
3920             # host.
3921             self._update_volume_attachments(context, instance, bdms)
3922 
3923             block_device_info = self._get_instance_block_device_info(
3924                     context, instance, refresh_conn_info=True, bdms=bdms)
3925 
3926             power_on = old_vm_state != vm_states.STOPPED
3927             self.driver.finish_revert_migration(context, instance,
3928                                        network_info,
3929                                        block_device_info, power_on)
3930 
3931             instance.drop_migration_context()
3932             instance.launched_at = timeutils.utcnow()
3933             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
3934 
3935             # Complete any volume attachments so the volumes are in-use.
3936             self._complete_volume_attachments(context, bdms)
3937 
3938             # if the original vm state was STOPPED, set it back to STOPPED
3939             LOG.info("Updating instance to original state: '%s'",
3940                      old_vm_state, instance=instance)
3941             if power_on:
3942                 instance.vm_state = vm_states.ACTIVE
3943                 instance.task_state = None
3944                 instance.save()
3945             else:
3946                 instance.task_state = task_states.POWERING_OFF
3947                 instance.save()
3948                 self.stop_instance(context, instance=instance,
3949                                    clean_shutdown=True)
3950 
3951             self._notify_about_instance_usage(
3952                     context, instance, "resize.revert.end")
3953             compute_utils.notify_about_instance_action(context, instance,
3954                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
3955                     phase=fields.NotificationPhase.END, bdms=bdms)
3956 
3957     def _revert_allocation(self, context, instance, migration):
3958         """Revert an allocation that is held by migration to our instance."""
3959 
3960         # Fetch the original allocation that the instance had on the source
3961         # node, which are now held by the migration
3962         orig_alloc = self.reportclient.get_allocations_for_consumer(
3963             migration.uuid)
3964         if not orig_alloc:
3965             # NOTE(danms): This migration did not do per-migration allocation
3966             # accounting, so nothing to do here.
3967             LOG.info('Old-style migration %(mig)s is being reverted; '
3968                      'no migration claims found on original node '
3969                      'to swap.',
3970                      {'mig': migration.uuid},
3971                      instance=instance)
3972             return False
3973 
3974         if len(orig_alloc) > 1:
3975             # NOTE(danms): This may change later if we have other allocations
3976             # against other providers that need to be held by the migration
3977             # as well. Perhaps something like shared storage resources that
3978             # will actually be duplicated during a resize type operation.
3979             LOG.error('New-style migration %(mig)s has allocations against '
3980                       'more than one provider %(rps)s. This should not be '
3981                       'possible, but reverting it anyway.',
3982                       {'mig': migration.uuid,
3983                        'rps': ','.join(orig_alloc.keys())},
3984                       instance=instance)
3985 
3986         # We only have a claim against one provider, it is the source node
3987         cn_uuid = list(orig_alloc.keys())[0]
3988 
3989         # Get just the resources part of the one allocation we need below
3990         orig_alloc = orig_alloc[cn_uuid].get('resources', {})
3991 
3992         # FIXME(danms): This method is flawed in that it asssumes allocations
3993         # against only one provider. So, this may overwite allocations against
3994         # a shared provider, if we had one.
3995         LOG.info('Swapping old allocation on %(node)s held by migration '
3996                  '%(mig)s for instance',
3997                  {'node': cn_uuid, 'mig': migration.uuid},
3998                  instance=instance)
3999         # TODO(cdent): Should we be doing anything with return values here?
4000         self.reportclient.set_and_clear_allocations(
4001             cn_uuid, instance.uuid, orig_alloc, instance.project_id,
4002             instance.user_id, consumer_to_clear=migration.uuid)
4003         return True
4004 
4005     def _prep_resize(self, context, image, instance, instance_type,
4006                      filter_properties, node, migration, clean_shutdown=True):
4007 
4008         if not filter_properties:
4009             filter_properties = {}
4010 
4011         if not instance.host:
4012             self._set_instance_obj_error_state(context, instance)
4013             msg = _('Instance has no source host')
4014             raise exception.MigrationError(reason=msg)
4015 
4016         same_host = instance.host == self.host
4017         # if the flavor IDs match, it's migrate; otherwise resize
4018         if same_host and instance_type.id == instance['instance_type_id']:
4019             # check driver whether support migrate to same host
4020             if not self.driver.capabilities['supports_migrate_to_same_host']:
4021                 raise exception.UnableToMigrateToSelf(
4022                     instance_id=instance.uuid, host=self.host)
4023 
4024         # NOTE(danms): Stash the new instance_type to avoid having to
4025         # look it up in the database later
4026         instance.new_flavor = instance_type
4027         # NOTE(mriedem): Stash the old vm_state so we can set the
4028         # resized/reverted instance back to the same state later.
4029         vm_state = instance.vm_state
4030         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4031         instance.system_metadata['old_vm_state'] = vm_state
4032         instance.save()
4033 
4034         limits = filter_properties.get('limits', {})
4035         rt = self._get_resource_tracker()
4036         with rt.resize_claim(context, instance, instance_type, node,
4037                              migration, image_meta=image,
4038                              limits=limits) as claim:
4039             LOG.info('Migrating', instance=instance)
4040             # RPC cast to the source host to start the actual resize/migration.
4041             self.compute_rpcapi.resize_instance(
4042                     context, instance, claim.migration, image,
4043                     instance_type, clean_shutdown)
4044 
4045     @wrap_exception()
4046     @reverts_task_state
4047     @wrap_instance_event(prefix='compute')
4048     @wrap_instance_fault
4049     def prep_resize(self, context, image, instance, instance_type,
4050                     reservations, request_spec, filter_properties, node,
4051                     clean_shutdown, migration=None):
4052         """Initiates the process of moving a running instance to another host.
4053 
4054         Possibly changes the VCPU, RAM and disk size in the process.
4055 
4056         This is initiated from conductor and runs on the destination host.
4057 
4058         The main purpose of this method is performing some checks on the
4059         destination host and making a claim for resources. If the claim fails
4060         then a reschedule to another host may be attempted which involves
4061         calling back to conductor to start the process over again.
4062         """
4063         if node is None:
4064             node = self._get_nodename(instance, refresh=True)
4065 
4066         # NOTE(melwitt): Remove this in version 5.0 of the RPC API
4067         # Code downstream may expect extra_specs to be populated since it
4068         # is receiving an object, so lookup the flavor to ensure this.
4069         if not isinstance(instance_type, objects.Flavor):
4070             instance_type = objects.Flavor.get_by_id(context,
4071                                                      instance_type['id'])
4072         with self._error_out_instance_on_exception(context, instance), \
4073                  errors_out_migration_ctxt(migration):
4074             compute_utils.notify_usage_exists(self.notifier, context, instance,
4075                                               current_period=True)
4076             self._notify_about_instance_usage(
4077                     context, instance, "resize.prep.start")
4078             failed = False
4079             try:
4080                 self._prep_resize(context, image, instance,
4081                                   instance_type, filter_properties,
4082                                   node, migration, clean_shutdown)
4083             except Exception:
4084                 failed = True
4085                 # try to re-schedule the resize elsewhere:
4086                 exc_info = sys.exc_info()
4087                 if migration:
4088                     # Need to revert first to avoid a race on the retry
4089                     self._revert_allocation(context, instance, migration)
4090                 self._reschedule_resize_or_reraise(context, image, instance,
4091                         exc_info, instance_type, request_spec,
4092                         filter_properties)
4093             finally:
4094                 if failed:
4095                     # Since we hit a failure, we're either rescheduling or dead
4096                     # and either way we need to cleanup any allocations created
4097                     # by the scheduler for the destination node.
4098                     if migration and not self._revert_allocation(
4099                             context, instance, migration):
4100                         # We did not do a migration-based
4101                         # allocation. Note that for a resize to the
4102                         # same host, the scheduler will merge the
4103                         # flavors, so here we'd be subtracting the new
4104                         # flavor from the allocated resources on this
4105                         # node.
4106                         # FIXME(danms): Remove this in Rocky
4107                         rt = self._get_resource_tracker()
4108                         rt.delete_allocation_for_failed_resize(
4109                             instance, node, instance_type)
4110 
4111                 extra_usage_info = dict(
4112                         new_instance_type=instance_type.name,
4113                         new_instance_type_id=instance_type.id)
4114 
4115                 self._notify_about_instance_usage(
4116                     context, instance, "resize.prep.end",
4117                     extra_usage_info=extra_usage_info)
4118 
4119     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
4120             instance_type, request_spec, filter_properties):
4121         """Try to re-schedule the resize or re-raise the original error to
4122         error out the instance.
4123         """
4124         if not request_spec:
4125             request_spec = {}
4126         if not filter_properties:
4127             filter_properties = {}
4128 
4129         rescheduled = False
4130         instance_uuid = instance.uuid
4131 
4132         try:
4133             reschedule_method = self.compute_task_api.resize_instance
4134             scheduler_hint = dict(filter_properties=filter_properties)
4135             method_args = (instance, None, scheduler_hint, instance_type)
4136             task_state = task_states.RESIZE_PREP
4137 
4138             rescheduled = self._reschedule(context, request_spec,
4139                     filter_properties, instance, reschedule_method,
4140                     method_args, task_state, exc_info)
4141         except Exception as error:
4142             rescheduled = False
4143             LOG.exception("Error trying to reschedule",
4144                           instance_uuid=instance_uuid)
4145             compute_utils.add_instance_fault_from_exc(context,
4146                     instance, error,
4147                     exc_info=sys.exc_info())
4148             self._notify_about_instance_usage(context, instance,
4149                     'resize.error', fault=error)
4150             compute_utils.notify_about_instance_action(
4151                 context, instance, self.host,
4152                 action=fields.NotificationAction.RESIZE,
4153                 phase=fields.NotificationPhase.ERROR,
4154                 exception=error)
4155         if rescheduled:
4156             self._log_original_error(exc_info, instance_uuid)
4157             compute_utils.add_instance_fault_from_exc(context,
4158                     instance, exc_info[1], exc_info=exc_info)
4159             self._notify_about_instance_usage(context, instance,
4160                     'resize.error', fault=exc_info[1])
4161             compute_utils.notify_about_instance_action(
4162                 context, instance, self.host,
4163                 action=fields.NotificationAction.RESIZE,
4164                 phase=fields.NotificationPhase.ERROR,
4165                 exception=exc_info[1])
4166         else:
4167             # not re-scheduling
4168             six.reraise(*exc_info)
4169 
4170     @wrap_exception()
4171     @reverts_task_state
4172     @wrap_instance_event(prefix='compute')
4173     @wrap_instance_fault
4174     def resize_instance(self, context, instance, image,
4175                         reservations, migration, instance_type,
4176                         clean_shutdown):
4177         """Starts the migration of a running instance to another host.
4178 
4179         This is initiated from the destination host's ``prep_resize`` routine
4180         and runs on the source host.
4181         """
4182         with self._error_out_instance_on_exception(context, instance), \
4183              errors_out_migration_ctxt(migration):
4184             # TODO(chaochin) Remove this until v5 RPC API
4185             # Code downstream may expect extra_specs to be populated since it
4186             # is receiving an object, so lookup the flavor to ensure this.
4187             if (not instance_type or
4188                 not isinstance(instance_type, objects.Flavor)):
4189                 instance_type = objects.Flavor.get_by_id(
4190                     context, migration['new_instance_type_id'])
4191 
4192             network_info = self.network_api.get_instance_nw_info(context,
4193                                                                  instance)
4194 
4195             migration.status = 'migrating'
4196             with migration.obj_as_admin():
4197                 migration.save()
4198 
4199             instance.task_state = task_states.RESIZE_MIGRATING
4200             instance.save(expected_task_state=task_states.RESIZE_PREP)
4201 
4202             self._notify_about_instance_usage(
4203                 context, instance, "resize.start", network_info=network_info)
4204 
4205             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4206                     context, instance.uuid)
4207 
4208             compute_utils.notify_about_instance_action(context, instance,
4209                    self.host, action=fields.NotificationAction.RESIZE,
4210                    phase=fields.NotificationPhase.START, bdms=bdms)
4211 
4212             block_device_info = self._get_instance_block_device_info(
4213                                 context, instance, bdms=bdms)
4214 
4215             timeout, retry_interval = self._get_power_off_values(context,
4216                                             instance, clean_shutdown)
4217             disk_info = self.driver.migrate_disk_and_power_off(
4218                     context, instance, migration.dest_host,
4219                     instance_type, network_info,
4220                     block_device_info,
4221                     timeout, retry_interval)
4222 
4223             self._terminate_volume_connections(context, instance, bdms)
4224 
4225             migration_p = obj_base.obj_to_primitive(migration)
4226             self.network_api.migrate_instance_start(context,
4227                                                     instance,
4228                                                     migration_p)
4229 
4230             migration.status = 'post-migrating'
4231             with migration.obj_as_admin():
4232                 migration.save()
4233 
4234             instance.host = migration.dest_compute
4235             instance.node = migration.dest_node
4236             instance.task_state = task_states.RESIZE_MIGRATED
4237             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4238 
4239             # RPC cast to the destination host to finish the resize/migration.
4240             self.compute_rpcapi.finish_resize(context, instance,
4241                     migration, image, disk_info, migration.dest_compute)
4242 
4243         self._notify_about_instance_usage(context, instance, "resize.end",
4244                                           network_info=network_info)
4245 
4246         compute_utils.notify_about_instance_action(context, instance,
4247                self.host, action=fields.NotificationAction.RESIZE,
4248                phase=fields.NotificationPhase.END, bdms=bdms)
4249         self.instance_events.clear_events_for_instance(instance)
4250 
4251     def _terminate_volume_connections(self, context, instance, bdms):
4252         connector = None
4253         for bdm in bdms:
4254             if bdm.is_volume:
4255                 if bdm.attachment_id:
4256                     # NOTE(jdg): So here's the thing, the idea behind the new
4257                     # attach API's was to have a new code fork/path that we
4258                     # followed, we're not going to do that so we have to do
4259                     # some extra work in here to make it *behave* just like the
4260                     # old code. Cinder doesn't allow disconnect/reconnect (you
4261                     # just delete the attachment and get a new one)
4262                     # attachments in the new attach code so we have to do
4263                     # a delete and create without a connector (reserve),
4264                     # in other words, beware
4265                     attachment_id = self.volume_api.attachment_create(
4266                         context, bdm.volume_id, instance.uuid)['id']
4267                     self.volume_api.attachment_delete(context,
4268                                                       bdm.attachment_id)
4269                     bdm.attachment_id = attachment_id
4270                     bdm.save()
4271 
4272                 else:
4273                     if connector is None:
4274                         connector = self.driver.get_volume_connector(instance)
4275                     self.volume_api.terminate_connection(context,
4276                                                          bdm.volume_id,
4277                                                          connector)
4278 
4279     @staticmethod
4280     def _set_instance_info(instance, instance_type):
4281         instance.instance_type_id = instance_type.id
4282         instance.memory_mb = instance_type.memory_mb
4283         instance.vcpus = instance_type.vcpus
4284         instance.root_gb = instance_type.root_gb
4285         instance.ephemeral_gb = instance_type.ephemeral_gb
4286         instance.flavor = instance_type
4287 
4288     def _update_volume_attachments(self, context, instance, bdms):
4289         """Updates volume attachments using the virt driver host connector.
4290 
4291         :param context: nova.context.RequestContext - user request context
4292         :param instance: nova.objects.Instance
4293         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4294                      device mappings for the given instance
4295         """
4296         if bdms:
4297             connector = None
4298             for bdm in bdms:
4299                 if bdm.is_volume and bdm.attachment_id:
4300                     if connector is None:
4301                         connector = self.driver.get_volume_connector(instance)
4302                     self.volume_api.attachment_update(
4303                         context, bdm.attachment_id, connector, bdm.device_name)
4304 
4305     def _complete_volume_attachments(self, context, bdms):
4306         """Completes volume attachments for the instance
4307 
4308         :param context: nova.context.RequestContext - user request context
4309         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4310                      device mappings for the given instance
4311         """
4312         if bdms:
4313             for bdm in bdms:
4314                 if bdm.is_volume and bdm.attachment_id:
4315                     self.volume_api.attachment_complete(
4316                         context, bdm.attachment_id)
4317 
4318     def _finish_resize(self, context, instance, migration, disk_info,
4319                        image_meta, bdms):
4320         resize_instance = False
4321         old_instance_type_id = migration['old_instance_type_id']
4322         new_instance_type_id = migration['new_instance_type_id']
4323         old_instance_type = instance.get_flavor()
4324         # NOTE(mriedem): Get the old_vm_state so we know if we should
4325         # power on the instance. If old_vm_state is not set we need to default
4326         # to ACTIVE for backwards compatibility
4327         old_vm_state = instance.system_metadata.get('old_vm_state',
4328                                                     vm_states.ACTIVE)
4329         instance.old_flavor = old_instance_type
4330 
4331         if old_instance_type_id != new_instance_type_id:
4332             instance_type = instance.get_flavor('new')
4333             self._set_instance_info(instance, instance_type)
4334             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4335                 if old_instance_type[key] != instance_type[key]:
4336                     resize_instance = True
4337                     break
4338         instance.apply_migration_context()
4339 
4340         # NOTE(tr3buchet): setup networks on destination host
4341         self.network_api.setup_networks_on_host(context, instance,
4342                                                 migration['dest_compute'])
4343 
4344         migration_p = obj_base.obj_to_primitive(migration)
4345         self.network_api.migrate_instance_finish(context,
4346                                                  instance,
4347                                                  migration_p)
4348 
4349         network_info = self.network_api.get_instance_nw_info(context, instance)
4350 
4351         instance.task_state = task_states.RESIZE_FINISH
4352         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4353 
4354         self._notify_about_instance_usage(
4355             context, instance, "finish_resize.start",
4356             network_info=network_info)
4357         compute_utils.notify_about_instance_action(context, instance,
4358                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4359                phase=fields.NotificationPhase.START, bdms=bdms)
4360 
4361         # We need to update any volume attachments using the destination
4362         # host connector so that we can update the BDM.connection_info
4363         # before calling driver.finish_migration otherwise the driver
4364         # won't know how to connect the volumes to this host.
4365         # Note that _get_instance_block_device_info with
4366         # refresh_conn_info=True will update the BDM.connection_info value
4367         # in the database so we must do this before calling that method.
4368         self._update_volume_attachments(context, instance, bdms)
4369 
4370         block_device_info = self._get_instance_block_device_info(
4371             context, instance, refresh_conn_info=True, bdms=bdms)
4372 
4373         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4374         # automatically power on the instance after it's migrated
4375         power_on = old_vm_state != vm_states.STOPPED
4376 
4377         try:
4378             self.driver.finish_migration(context, migration, instance,
4379                                          disk_info,
4380                                          network_info,
4381                                          image_meta, resize_instance,
4382                                          block_device_info, power_on)
4383         except Exception:
4384             with excutils.save_and_reraise_exception():
4385                 if old_instance_type_id != new_instance_type_id:
4386                     self._set_instance_info(instance,
4387                                             old_instance_type)
4388 
4389         # Now complete any volume attachments that were previously updated.
4390         self._complete_volume_attachments(context, bdms)
4391 
4392         migration.status = 'finished'
4393         with migration.obj_as_admin():
4394             migration.save()
4395 
4396         instance.vm_state = vm_states.RESIZED
4397         instance.task_state = None
4398         instance.launched_at = timeutils.utcnow()
4399         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4400 
4401         return network_info
4402 
4403     @wrap_exception()
4404     @reverts_task_state
4405     @wrap_instance_event(prefix='compute')
4406     @wrap_instance_fault
4407     def finish_resize(self, context, disk_info, image, instance,
4408                       reservations, migration):
4409         """Completes the migration process.
4410 
4411         Sets up the newly transferred disk and turns on the instance at its
4412         new host machine.
4413 
4414         """
4415         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4416             context, instance.uuid)
4417 
4418         with self._error_out_instance_on_exception(context, instance), \
4419              errors_out_migration_ctxt(migration):
4420             image_meta = objects.ImageMeta.from_dict(image)
4421             network_info = self._finish_resize(context, instance, migration,
4422                                                disk_info, image_meta, bdms)
4423 
4424         self._update_scheduler_instance_info(context, instance)
4425         self._notify_about_instance_usage(
4426             context, instance, "finish_resize.end",
4427             network_info=network_info)
4428         compute_utils.notify_about_instance_action(context, instance,
4429                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4430                phase=fields.NotificationPhase.END, bdms=bdms)
4431 
4432     @wrap_exception()
4433     @wrap_instance_fault
4434     def add_fixed_ip_to_instance(self, context, network_id, instance):
4435         """Calls network_api to add new fixed_ip to instance
4436         then injects the new network info and resets instance networking.
4437 
4438         """
4439         self._notify_about_instance_usage(
4440                 context, instance, "create_ip.start")
4441 
4442         network_info = self.network_api.add_fixed_ip_to_instance(context,
4443                                                                  instance,
4444                                                                  network_id)
4445         self._inject_network_info(context, instance, network_info)
4446         self.reset_network(context, instance)
4447 
4448         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4449         instance.updated_at = timeutils.utcnow()
4450         instance.save()
4451 
4452         self._notify_about_instance_usage(
4453             context, instance, "create_ip.end", network_info=network_info)
4454 
4455     @wrap_exception()
4456     @wrap_instance_fault
4457     def remove_fixed_ip_from_instance(self, context, address, instance):
4458         """Calls network_api to remove existing fixed_ip from instance
4459         by injecting the altered network info and resetting
4460         instance networking.
4461         """
4462         self._notify_about_instance_usage(
4463                 context, instance, "delete_ip.start")
4464 
4465         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4466                                                                       instance,
4467                                                                       address)
4468         self._inject_network_info(context, instance, network_info)
4469         self.reset_network(context, instance)
4470 
4471         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4472         instance.updated_at = timeutils.utcnow()
4473         instance.save()
4474 
4475         self._notify_about_instance_usage(
4476             context, instance, "delete_ip.end", network_info=network_info)
4477 
4478     @wrap_exception()
4479     @reverts_task_state
4480     @wrap_instance_event(prefix='compute')
4481     @wrap_instance_fault
4482     def pause_instance(self, context, instance):
4483         """Pause an instance on this host."""
4484         context = context.elevated()
4485         LOG.info('Pausing', instance=instance)
4486         self._notify_about_instance_usage(context, instance, 'pause.start')
4487         compute_utils.notify_about_instance_action(context, instance,
4488                self.host, action=fields.NotificationAction.PAUSE,
4489                phase=fields.NotificationPhase.START)
4490         self.driver.pause(instance)
4491         instance.power_state = self._get_power_state(context, instance)
4492         instance.vm_state = vm_states.PAUSED
4493         instance.task_state = None
4494         instance.save(expected_task_state=task_states.PAUSING)
4495         self._notify_about_instance_usage(context, instance, 'pause.end')
4496         compute_utils.notify_about_instance_action(context, instance,
4497                self.host, action=fields.NotificationAction.PAUSE,
4498                phase=fields.NotificationPhase.END)
4499 
4500     @wrap_exception()
4501     @reverts_task_state
4502     @wrap_instance_event(prefix='compute')
4503     @wrap_instance_fault
4504     def unpause_instance(self, context, instance):
4505         """Unpause a paused instance on this host."""
4506         context = context.elevated()
4507         LOG.info('Unpausing', instance=instance)
4508         self._notify_about_instance_usage(context, instance, 'unpause.start')
4509         compute_utils.notify_about_instance_action(context, instance,
4510             self.host, action=fields.NotificationAction.UNPAUSE,
4511             phase=fields.NotificationPhase.START)
4512         self.driver.unpause(instance)
4513         instance.power_state = self._get_power_state(context, instance)
4514         instance.vm_state = vm_states.ACTIVE
4515         instance.task_state = None
4516         instance.save(expected_task_state=task_states.UNPAUSING)
4517         self._notify_about_instance_usage(context, instance, 'unpause.end')
4518         compute_utils.notify_about_instance_action(context, instance,
4519             self.host, action=fields.NotificationAction.UNPAUSE,
4520             phase=fields.NotificationPhase.END)
4521 
4522     @wrap_exception()
4523     def host_power_action(self, context, action):
4524         """Reboots, shuts down or powers up the host."""
4525         return self.driver.host_power_action(action)
4526 
4527     @wrap_exception()
4528     def host_maintenance_mode(self, context, host, mode):
4529         """Start/Stop host maintenance window. On start, it triggers
4530         guest VMs evacuation.
4531         """
4532         return self.driver.host_maintenance_mode(host, mode)
4533 
4534     @wrap_exception()
4535     def set_host_enabled(self, context, enabled):
4536         """Sets the specified host's ability to accept new instances."""
4537         return self.driver.set_host_enabled(enabled)
4538 
4539     @wrap_exception()
4540     def get_host_uptime(self, context):
4541         """Returns the result of calling "uptime" on the target host."""
4542         return self.driver.get_host_uptime()
4543 
4544     @wrap_exception()
4545     @wrap_instance_fault
4546     def get_diagnostics(self, context, instance):
4547         """Retrieve diagnostics for an instance on this host."""
4548         current_power_state = self._get_power_state(context, instance)
4549         if current_power_state == power_state.RUNNING:
4550             LOG.info("Retrieving diagnostics", instance=instance)
4551             return self.driver.get_diagnostics(instance)
4552         else:
4553             raise exception.InstanceInvalidState(
4554                 attr='power state',
4555                 instance_uuid=instance.uuid,
4556                 state=power_state.STATE_MAP[instance.power_state],
4557                 method='get_diagnostics')
4558 
4559     # TODO(alaski): Remove object_compat for RPC version 5.0
4560     @object_compat
4561     @wrap_exception()
4562     @wrap_instance_fault
4563     def get_instance_diagnostics(self, context, instance):
4564         """Retrieve diagnostics for an instance on this host."""
4565         current_power_state = self._get_power_state(context, instance)
4566         if current_power_state == power_state.RUNNING:
4567             LOG.info("Retrieving diagnostics", instance=instance)
4568             return self.driver.get_instance_diagnostics(instance)
4569         else:
4570             raise exception.InstanceInvalidState(
4571                 attr='power state',
4572                 instance_uuid=instance.uuid,
4573                 state=power_state.STATE_MAP[instance.power_state],
4574                 method='get_diagnostics')
4575 
4576     @wrap_exception()
4577     @reverts_task_state
4578     @wrap_instance_event(prefix='compute')
4579     @wrap_instance_fault
4580     def suspend_instance(self, context, instance):
4581         """Suspend the given instance."""
4582         context = context.elevated()
4583 
4584         # Store the old state
4585         instance.system_metadata['old_vm_state'] = instance.vm_state
4586         self._notify_about_instance_usage(context, instance, 'suspend.start')
4587         compute_utils.notify_about_instance_action(context, instance,
4588                 self.host, action=fields.NotificationAction.SUSPEND,
4589                 phase=fields.NotificationPhase.START)
4590         with self._error_out_instance_on_exception(context, instance,
4591              instance_state=instance.vm_state):
4592             self.driver.suspend(context, instance)
4593         instance.power_state = self._get_power_state(context, instance)
4594         instance.vm_state = vm_states.SUSPENDED
4595         instance.task_state = None
4596         instance.save(expected_task_state=task_states.SUSPENDING)
4597         self._notify_about_instance_usage(context, instance, 'suspend.end')
4598         compute_utils.notify_about_instance_action(context, instance,
4599                 self.host, action=fields.NotificationAction.SUSPEND,
4600                 phase=fields.NotificationPhase.END)
4601 
4602     @wrap_exception()
4603     @reverts_task_state
4604     @wrap_instance_event(prefix='compute')
4605     @wrap_instance_fault
4606     def resume_instance(self, context, instance):
4607         """Resume the given suspended instance."""
4608         context = context.elevated()
4609         LOG.info('Resuming', instance=instance)
4610 
4611         self._notify_about_instance_usage(context, instance, 'resume.start')
4612 
4613         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4614             context, instance.uuid)
4615         block_device_info = self._get_instance_block_device_info(
4616             context, instance, bdms=bdms)
4617 
4618         compute_utils.notify_about_instance_action(context, instance,
4619             self.host, action=fields.NotificationAction.RESUME,
4620             phase=fields.NotificationPhase.START, bdms=bdms)
4621 
4622         network_info = self.network_api.get_instance_nw_info(context, instance)
4623 
4624         with self._error_out_instance_on_exception(context, instance,
4625              instance_state=instance.vm_state):
4626             self.driver.resume(context, instance, network_info,
4627                                block_device_info)
4628 
4629         instance.power_state = self._get_power_state(context, instance)
4630 
4631         # We default to the ACTIVE state for backwards compatibility
4632         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4633                                                          vm_states.ACTIVE)
4634 
4635         instance.task_state = None
4636         instance.save(expected_task_state=task_states.RESUMING)
4637         self._notify_about_instance_usage(context, instance, 'resume.end')
4638         compute_utils.notify_about_instance_action(context, instance,
4639             self.host, action=fields.NotificationAction.RESUME,
4640             phase=fields.NotificationPhase.END, bdms=bdms)
4641 
4642     @wrap_exception()
4643     @reverts_task_state
4644     @wrap_instance_event(prefix='compute')
4645     @wrap_instance_fault
4646     def shelve_instance(self, context, instance, image_id,
4647                         clean_shutdown):
4648         """Shelve an instance.
4649 
4650         This should be used when you want to take a snapshot of the instance.
4651         It also adds system_metadata that can be used by a periodic task to
4652         offload the shelved instance after a period of time.
4653 
4654         :param context: request context
4655         :param instance: an Instance object
4656         :param image_id: an image id to snapshot to.
4657         :param clean_shutdown: give the GuestOS a chance to stop
4658         """
4659 
4660         @utils.synchronized(instance.uuid)
4661         def do_shelve_instance():
4662             self._shelve_instance(context, instance, image_id, clean_shutdown)
4663         do_shelve_instance()
4664 
4665     def _shelve_instance(self, context, instance, image_id,
4666                          clean_shutdown):
4667         LOG.info('Shelving', instance=instance)
4668         offload = CONF.shelved_offload_time == 0
4669         if offload:
4670             # Get the BDMs early so we can pass them into versioned
4671             # notifications since _shelve_offload_instance needs the
4672             # BDMs anyway.
4673             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4674                 context, instance.uuid)
4675         else:
4676             bdms = None
4677         compute_utils.notify_usage_exists(self.notifier, context, instance,
4678                                           current_period=True)
4679         self._notify_about_instance_usage(context, instance, 'shelve.start')
4680         compute_utils.notify_about_instance_action(context, instance,
4681                 self.host, action=fields.NotificationAction.SHELVE,
4682                 phase=fields.NotificationPhase.START, bdms=bdms)
4683 
4684         def update_task_state(task_state, expected_state=task_states.SHELVING):
4685             shelving_state_map = {
4686                     task_states.IMAGE_PENDING_UPLOAD:
4687                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4688                     task_states.IMAGE_UPLOADING:
4689                         task_states.SHELVING_IMAGE_UPLOADING,
4690                     task_states.SHELVING: task_states.SHELVING}
4691             task_state = shelving_state_map[task_state]
4692             expected_state = shelving_state_map[expected_state]
4693             instance.task_state = task_state
4694             instance.save(expected_task_state=expected_state)
4695 
4696         self._power_off_instance(context, instance, clean_shutdown)
4697         self.driver.snapshot(context, instance, image_id, update_task_state)
4698 
4699         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4700         instance.system_metadata['shelved_image_id'] = image_id
4701         instance.system_metadata['shelved_host'] = self.host
4702         instance.vm_state = vm_states.SHELVED
4703         instance.task_state = None
4704         if CONF.shelved_offload_time == 0:
4705             instance.task_state = task_states.SHELVING_OFFLOADING
4706         instance.power_state = self._get_power_state(context, instance)
4707         instance.save(expected_task_state=[
4708                 task_states.SHELVING,
4709                 task_states.SHELVING_IMAGE_UPLOADING])
4710 
4711         self._notify_about_instance_usage(context, instance, 'shelve.end')
4712         compute_utils.notify_about_instance_action(context, instance,
4713                 self.host, action=fields.NotificationAction.SHELVE,
4714                 phase=fields.NotificationPhase.END, bdms=bdms)
4715 
4716         if offload:
4717             self._shelve_offload_instance(context, instance,
4718                                           clean_shutdown=False, bdms=bdms)
4719 
4720     @wrap_exception()
4721     @reverts_task_state
4722     @wrap_instance_event(prefix='compute')
4723     @wrap_instance_fault
4724     def shelve_offload_instance(self, context, instance, clean_shutdown):
4725         """Remove a shelved instance from the hypervisor.
4726 
4727         This frees up those resources for use by other instances, but may lead
4728         to slower unshelve times for this instance.  This method is used by
4729         volume backed instances since restoring them doesn't involve the
4730         potentially large download of an image.
4731 
4732         :param context: request context
4733         :param instance: nova.objects.instance.Instance
4734         :param clean_shutdown: give the GuestOS a chance to stop
4735         """
4736 
4737         @utils.synchronized(instance.uuid)
4738         def do_shelve_offload_instance():
4739             self._shelve_offload_instance(context, instance, clean_shutdown)
4740         do_shelve_offload_instance()
4741 
4742     def _shelve_offload_instance(self, context, instance, clean_shutdown,
4743                                  bdms=None):
4744         LOG.info('Shelve offloading', instance=instance)
4745         if bdms is None:
4746             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4747                 context, instance.uuid)
4748         self._notify_about_instance_usage(context, instance,
4749                 'shelve_offload.start')
4750         compute_utils.notify_about_instance_action(context, instance,
4751                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4752                 phase=fields.NotificationPhase.START, bdms=bdms)
4753 
4754         self._power_off_instance(context, instance, clean_shutdown)
4755         current_power_state = self._get_power_state(context, instance)
4756 
4757         self.network_api.cleanup_instance_network_on_host(context, instance,
4758                                                           instance.host)
4759         network_info = self.network_api.get_instance_nw_info(context, instance)
4760 
4761         block_device_info = self._get_instance_block_device_info(context,
4762                                                                  instance,
4763                                                                  bdms=bdms)
4764         self.driver.destroy(context, instance, network_info,
4765                 block_device_info)
4766 
4767         # the instance is going to be removed from the host so we want to
4768         # terminate all the connections with the volume server and the host
4769         self._terminate_volume_connections(context, instance, bdms)
4770 
4771         instance.power_state = current_power_state
4772         # NOTE(mriedem): The vm_state has to be set before updating the
4773         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4774         # values cannot be nulled out until after updating the resource tracker
4775         # though.
4776         instance.vm_state = vm_states.SHELVED_OFFLOADED
4777         instance.task_state = None
4778         instance.save(expected_task_state=[task_states.SHELVING,
4779                                            task_states.SHELVING_OFFLOADING])
4780 
4781         # NOTE(ndipanov): Free resources from the resource tracker
4782         self._update_resource_tracker(context, instance)
4783 
4784         rt = self._get_resource_tracker()
4785         rt.delete_allocation_for_shelve_offloaded_instance(instance)
4786 
4787         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4788         # instance, so ensure any calls result in errors
4789         self._nil_out_instance_obj_host_and_node(instance)
4790         instance.save(expected_task_state=None)
4791 
4792         self._delete_scheduler_instance_info(context, instance.uuid)
4793         self._notify_about_instance_usage(context, instance,
4794                 'shelve_offload.end')
4795         compute_utils.notify_about_instance_action(context, instance,
4796                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4797                 phase=fields.NotificationPhase.END, bdms=bdms)
4798 
4799     @wrap_exception()
4800     @reverts_task_state
4801     @wrap_instance_event(prefix='compute')
4802     @wrap_instance_fault
4803     def unshelve_instance(self, context, instance, image,
4804                           filter_properties, node):
4805         """Unshelve the instance.
4806 
4807         :param context: request context
4808         :param instance: a nova.objects.instance.Instance object
4809         :param image: an image to build from.  If None we assume a
4810             volume backed instance.
4811         :param filter_properties: dict containing limits, retry info etc.
4812         :param node: target compute node
4813         """
4814         if filter_properties is None:
4815             filter_properties = {}
4816 
4817         @utils.synchronized(instance.uuid)
4818         def do_unshelve_instance():
4819             self._unshelve_instance(context, instance, image,
4820                                     filter_properties, node)
4821         do_unshelve_instance()
4822 
4823     def _unshelve_instance_key_scrub(self, instance):
4824         """Remove data from the instance that may cause side effects."""
4825         cleaned_keys = dict(
4826                 key_data=instance.key_data,
4827                 auto_disk_config=instance.auto_disk_config)
4828         instance.key_data = None
4829         instance.auto_disk_config = False
4830         return cleaned_keys
4831 
4832     def _unshelve_instance_key_restore(self, instance, keys):
4833         """Restore previously scrubbed keys before saving the instance."""
4834         instance.update(keys)
4835 
4836     def _unshelve_instance(self, context, instance, image, filter_properties,
4837                            node):
4838         LOG.info('Unshelving', instance=instance)
4839         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4840                 context, instance.uuid)
4841 
4842         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4843         compute_utils.notify_about_instance_action(context, instance,
4844                 self.host, action=fields.NotificationAction.UNSHELVE,
4845                 phase=fields.NotificationPhase.START, bdms=bdms)
4846 
4847         instance.task_state = task_states.SPAWNING
4848         instance.save()
4849 
4850         block_device_info = self._prep_block_device(context, instance, bdms)
4851         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4852 
4853         if node is None:
4854             node = self._get_nodename(instance)
4855 
4856         rt = self._get_resource_tracker()
4857         limits = filter_properties.get('limits', {})
4858 
4859         allocations = self.reportclient.get_allocations_for_consumer(
4860             instance.uuid)
4861 
4862         shelved_image_ref = instance.image_ref
4863         if image:
4864             instance.image_ref = image['id']
4865             image_meta = objects.ImageMeta.from_dict(image)
4866         else:
4867             image_meta = objects.ImageMeta.from_dict(
4868                 utils.get_image_from_system_metadata(
4869                     instance.system_metadata))
4870 
4871         self.network_api.setup_instance_network_on_host(context, instance,
4872                                                         self.host)
4873         network_info = self.network_api.get_instance_nw_info(context, instance)
4874         try:
4875             with rt.instance_claim(context, instance, node, limits):
4876                 self.driver.spawn(context, instance, image_meta,
4877                                   injected_files=[],
4878                                   admin_password=None,
4879                                   allocations=allocations,
4880                                   network_info=network_info,
4881                                   block_device_info=block_device_info)
4882         except Exception:
4883             with excutils.save_and_reraise_exception(logger=LOG):
4884                 LOG.exception('Instance failed to spawn',
4885                               instance=instance)
4886                 # Cleanup allocations created by the scheduler on this host
4887                 # since we failed to spawn the instance. We do this both if
4888                 # the instance claim failed with ComputeResourcesUnavailable
4889                 # or if we did claim but the spawn failed, because aborting the
4890                 # instance claim will not remove the allocations.
4891                 rt.reportclient.delete_allocation_for_instance(instance.uuid)
4892                 # FIXME: Umm, shouldn't we be rolling back volume connections
4893                 # and port bindings?
4894 
4895         if image:
4896             instance.image_ref = shelved_image_ref
4897             self._delete_snapshot_of_shelved_instance(context, instance,
4898                                                       image['id'])
4899 
4900         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4901         self._update_instance_after_spawn(context, instance)
4902         # Delete system_metadata for a shelved instance
4903         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4904 
4905         instance.save(expected_task_state=task_states.SPAWNING)
4906         self._update_scheduler_instance_info(context, instance)
4907         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4908         compute_utils.notify_about_instance_action(context, instance,
4909                 self.host, action=fields.NotificationAction.UNSHELVE,
4910                 phase=fields.NotificationPhase.END, bdms=bdms)
4911 
4912     @messaging.expected_exceptions(NotImplementedError)
4913     @wrap_instance_fault
4914     def reset_network(self, context, instance):
4915         """Reset networking on the given instance."""
4916         LOG.debug('Reset network', instance=instance)
4917         self.driver.reset_network(instance)
4918 
4919     def _inject_network_info(self, context, instance, network_info):
4920         """Inject network info for the given instance."""
4921         LOG.debug('Inject network info', instance=instance)
4922         LOG.debug('network_info to inject: |%s|', network_info,
4923                   instance=instance)
4924 
4925         self.driver.inject_network_info(instance,
4926                                         network_info)
4927 
4928     @wrap_instance_fault
4929     def inject_network_info(self, context, instance):
4930         """Inject network info, but don't return the info."""
4931         network_info = self.network_api.get_instance_nw_info(context, instance)
4932         self._inject_network_info(context, instance, network_info)
4933 
4934     @messaging.expected_exceptions(NotImplementedError,
4935                                    exception.ConsoleNotAvailable,
4936                                    exception.InstanceNotFound)
4937     @wrap_exception()
4938     @wrap_instance_fault
4939     def get_console_output(self, context, instance, tail_length):
4940         """Send the console output for the given instance."""
4941         context = context.elevated()
4942         LOG.info("Get console output", instance=instance)
4943         output = self.driver.get_console_output(context, instance)
4944 
4945         if type(output) is six.text_type:
4946             output = six.b(output)
4947 
4948         if tail_length is not None:
4949             output = self._tail_log(output, tail_length)
4950 
4951         return output.decode('ascii', 'replace')
4952 
4953     def _tail_log(self, log, length):
4954         try:
4955             length = int(length)
4956         except ValueError:
4957             length = 0
4958 
4959         if length == 0:
4960             return b''
4961         else:
4962             return b'\n'.join(log.split(b'\n')[-int(length):])
4963 
4964     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4965                                    exception.InstanceNotReady,
4966                                    exception.InstanceNotFound,
4967                                    exception.ConsoleTypeUnavailable,
4968                                    NotImplementedError)
4969     @wrap_exception()
4970     @wrap_instance_fault
4971     def get_vnc_console(self, context, console_type, instance):
4972         """Return connection information for a vnc console."""
4973         context = context.elevated()
4974         LOG.debug("Getting vnc console", instance=instance)
4975         token = uuidutils.generate_uuid()
4976 
4977         if not CONF.vnc.enabled:
4978             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4979 
4980         if console_type == 'novnc':
4981             # For essex, novncproxy_base_url must include the full path
4982             # including the html file (like http://myhost/vnc_auto.html)
4983             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
4984         elif console_type == 'xvpvnc':
4985             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
4986         else:
4987             raise exception.ConsoleTypeInvalid(console_type=console_type)
4988 
4989         try:
4990             # Retrieve connect info from driver, and then decorate with our
4991             # access info token
4992             console = self.driver.get_vnc_console(context, instance)
4993             connect_info = console.get_connection_info(token, access_url)
4994         except exception.InstanceNotFound:
4995             if instance.vm_state != vm_states.BUILDING:
4996                 raise
4997             raise exception.InstanceNotReady(instance_id=instance.uuid)
4998 
4999         return connect_info
5000 
5001     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5002                                    exception.InstanceNotReady,
5003                                    exception.InstanceNotFound,
5004                                    exception.ConsoleTypeUnavailable,
5005                                    NotImplementedError)
5006     @wrap_exception()
5007     @wrap_instance_fault
5008     def get_spice_console(self, context, console_type, instance):
5009         """Return connection information for a spice console."""
5010         context = context.elevated()
5011         LOG.debug("Getting spice console", instance=instance)
5012         token = uuidutils.generate_uuid()
5013 
5014         if not CONF.spice.enabled:
5015             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5016 
5017         if console_type == 'spice-html5':
5018             # For essex, spicehtml5proxy_base_url must include the full path
5019             # including the html file (like http://myhost/spice_auto.html)
5020             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
5021                                           token)
5022         else:
5023             raise exception.ConsoleTypeInvalid(console_type=console_type)
5024 
5025         try:
5026             # Retrieve connect info from driver, and then decorate with our
5027             # access info token
5028             console = self.driver.get_spice_console(context, instance)
5029             connect_info = console.get_connection_info(token, access_url)
5030         except exception.InstanceNotFound:
5031             if instance.vm_state != vm_states.BUILDING:
5032                 raise
5033             raise exception.InstanceNotReady(instance_id=instance.uuid)
5034 
5035         return connect_info
5036 
5037     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5038                                    exception.InstanceNotReady,
5039                                    exception.InstanceNotFound,
5040                                    exception.ConsoleTypeUnavailable,
5041                                    NotImplementedError)
5042     @wrap_exception()
5043     @wrap_instance_fault
5044     def get_rdp_console(self, context, console_type, instance):
5045         """Return connection information for a RDP console."""
5046         context = context.elevated()
5047         LOG.debug("Getting RDP console", instance=instance)
5048         token = uuidutils.generate_uuid()
5049 
5050         if not CONF.rdp.enabled:
5051             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5052 
5053         if console_type == 'rdp-html5':
5054             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
5055                                           token)
5056         else:
5057             raise exception.ConsoleTypeInvalid(console_type=console_type)
5058 
5059         try:
5060             # Retrieve connect info from driver, and then decorate with our
5061             # access info token
5062             console = self.driver.get_rdp_console(context, instance)
5063             connect_info = console.get_connection_info(token, access_url)
5064         except exception.InstanceNotFound:
5065             if instance.vm_state != vm_states.BUILDING:
5066                 raise
5067             raise exception.InstanceNotReady(instance_id=instance.uuid)
5068 
5069         return connect_info
5070 
5071     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5072                                    exception.InstanceNotReady,
5073                                    exception.InstanceNotFound,
5074                                    exception.ConsoleTypeUnavailable,
5075                                    NotImplementedError)
5076     @wrap_exception()
5077     @wrap_instance_fault
5078     def get_mks_console(self, context, console_type, instance):
5079         """Return connection information for a MKS console."""
5080         context = context.elevated()
5081         LOG.debug("Getting MKS console", instance=instance)
5082         token = uuidutils.generate_uuid()
5083 
5084         if not CONF.mks.enabled:
5085             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5086 
5087         if console_type == 'webmks':
5088             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
5089                                           token)
5090         else:
5091             raise exception.ConsoleTypeInvalid(console_type=console_type)
5092 
5093         try:
5094             # Retrieve connect info from driver, and then decorate with our
5095             # access info token
5096             console = self.driver.get_mks_console(context, instance)
5097             connect_info = console.get_connection_info(token, access_url)
5098         except exception.InstanceNotFound:
5099             if instance.vm_state != vm_states.BUILDING:
5100                 raise
5101             raise exception.InstanceNotReady(instance_id=instance.uuid)
5102 
5103         return connect_info
5104 
5105     @messaging.expected_exceptions(
5106         exception.ConsoleTypeInvalid,
5107         exception.InstanceNotReady,
5108         exception.InstanceNotFound,
5109         exception.ConsoleTypeUnavailable,
5110         exception.SocketPortRangeExhaustedException,
5111         exception.ImageSerialPortNumberInvalid,
5112         exception.ImageSerialPortNumberExceedFlavorValue,
5113         NotImplementedError)
5114     @wrap_exception()
5115     @wrap_instance_fault
5116     def get_serial_console(self, context, console_type, instance):
5117         """Returns connection information for a serial console."""
5118 
5119         LOG.debug("Getting serial console", instance=instance)
5120 
5121         if not CONF.serial_console.enabled:
5122             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5123 
5124         context = context.elevated()
5125 
5126         token = uuidutils.generate_uuid()
5127         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
5128 
5129         try:
5130             # Retrieve connect info from driver, and then decorate with our
5131             # access info token
5132             console = self.driver.get_serial_console(context, instance)
5133             connect_info = console.get_connection_info(token, access_url)
5134         except exception.InstanceNotFound:
5135             if instance.vm_state != vm_states.BUILDING:
5136                 raise
5137             raise exception.InstanceNotReady(instance_id=instance.uuid)
5138 
5139         return connect_info
5140 
5141     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5142                                    exception.InstanceNotReady,
5143                                    exception.InstanceNotFound)
5144     @wrap_exception()
5145     @wrap_instance_fault
5146     def validate_console_port(self, ctxt, instance, port, console_type):
5147         if console_type == "spice-html5":
5148             console_info = self.driver.get_spice_console(ctxt, instance)
5149         elif console_type == "rdp-html5":
5150             console_info = self.driver.get_rdp_console(ctxt, instance)
5151         elif console_type == "serial":
5152             console_info = self.driver.get_serial_console(ctxt, instance)
5153         elif console_type == "webmks":
5154             console_info = self.driver.get_mks_console(ctxt, instance)
5155         else:
5156             console_info = self.driver.get_vnc_console(ctxt, instance)
5157 
5158         return console_info.port == port
5159 
5160     @wrap_exception()
5161     @reverts_task_state
5162     @wrap_instance_fault
5163     def reserve_block_device_name(self, context, instance, device,
5164                                   volume_id, disk_bus, device_type, tag=None):
5165         if (tag and not
5166                 self.driver.capabilities.get('supports_tagged_attach_volume',
5167                                              False)):
5168             raise exception.VolumeTaggedAttachNotSupported()
5169 
5170         @utils.synchronized(instance.uuid)
5171         def do_reserve():
5172             bdms = (
5173                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5174                     context, instance.uuid))
5175 
5176             # NOTE(ndipanov): We need to explicitly set all the fields on the
5177             #                 object so that obj_load_attr does not fail
5178             new_bdm = objects.BlockDeviceMapping(
5179                     context=context,
5180                     source_type='volume', destination_type='volume',
5181                     instance_uuid=instance.uuid, boot_index=None,
5182                     volume_id=volume_id,
5183                     device_name=device, guest_format=None,
5184                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5185 
5186             new_bdm.device_name = self._get_device_name_for_instance(
5187                     instance, bdms, new_bdm)
5188 
5189             # NOTE(vish): create bdm here to avoid race condition
5190             new_bdm.create()
5191             return new_bdm
5192 
5193         return do_reserve()
5194 
5195     @wrap_exception()
5196     @wrap_instance_event(prefix='compute')
5197     @wrap_instance_fault
5198     def attach_volume(self, context, instance, bdm):
5199         """Attach a volume to an instance."""
5200         driver_bdm = driver_block_device.convert_volume(bdm)
5201 
5202         @utils.synchronized(instance.uuid)
5203         def do_attach_volume(context, instance, driver_bdm):
5204             try:
5205                 return self._attach_volume(context, instance, driver_bdm)
5206             except Exception:
5207                 with excutils.save_and_reraise_exception():
5208                     bdm.destroy()
5209 
5210         do_attach_volume(context, instance, driver_bdm)
5211 
5212     def _attach_volume(self, context, instance, bdm):
5213         context = context.elevated()
5214         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5215                  {'volume_id': bdm.volume_id,
5216                   'mountpoint': bdm['mount_device']},
5217                  instance=instance)
5218         compute_utils.notify_about_volume_attach_detach(
5219             context, instance, self.host,
5220             action=fields.NotificationAction.VOLUME_ATTACH,
5221             phase=fields.NotificationPhase.START,
5222             volume_id=bdm.volume_id)
5223         try:
5224             bdm.attach(context, instance, self.volume_api, self.driver,
5225                        do_driver_attach=True)
5226         except Exception as e:
5227             with excutils.save_and_reraise_exception():
5228                 LOG.exception("Failed to attach %(volume_id)s "
5229                               "at %(mountpoint)s",
5230                               {'volume_id': bdm.volume_id,
5231                                'mountpoint': bdm['mount_device']},
5232                               instance=instance)
5233                 if bdm['attachment_id']:
5234                     self.volume_api.attachment_delete(context,
5235                                                       bdm['attachment_id'])
5236                 else:
5237                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5238                 compute_utils.notify_about_volume_attach_detach(
5239                     context, instance, self.host,
5240                     action=fields.NotificationAction.VOLUME_ATTACH,
5241                     phase=fields.NotificationPhase.ERROR,
5242                     exception=e,
5243                     volume_id=bdm.volume_id)
5244 
5245         info = {'volume_id': bdm.volume_id}
5246         self._notify_about_instance_usage(
5247             context, instance, "volume.attach", extra_usage_info=info)
5248         compute_utils.notify_about_volume_attach_detach(
5249             context, instance, self.host,
5250             action=fields.NotificationAction.VOLUME_ATTACH,
5251             phase=fields.NotificationPhase.END,
5252             volume_id=bdm.volume_id)
5253 
5254     def _notify_volume_usage_detach(self, context, instance, bdm):
5255         if CONF.volume_usage_poll_interval <= 0:
5256             return
5257 
5258         vol_stats = []
5259         mp = bdm.device_name
5260         # Handle bootable volumes which will not contain /dev/
5261         if '/dev/' in mp:
5262             mp = mp[5:]
5263         try:
5264             vol_stats = self.driver.block_stats(instance, mp)
5265         except NotImplementedError:
5266             return
5267 
5268         LOG.debug("Updating volume usage cache with totals", instance=instance)
5269         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5270         vol_usage = objects.VolumeUsage(context)
5271         vol_usage.volume_id = bdm.volume_id
5272         vol_usage.instance_uuid = instance.uuid
5273         vol_usage.project_id = instance.project_id
5274         vol_usage.user_id = instance.user_id
5275         vol_usage.availability_zone = instance.availability_zone
5276         vol_usage.curr_reads = rd_req
5277         vol_usage.curr_read_bytes = rd_bytes
5278         vol_usage.curr_writes = wr_req
5279         vol_usage.curr_write_bytes = wr_bytes
5280         vol_usage.save(update_totals=True)
5281         self.notifier.info(context, 'volume.usage',
5282                            compute_utils.usage_volume_info(vol_usage))
5283 
5284     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5285                        attachment_id=None):
5286         """Detach a volume from an instance.
5287 
5288         :param context: security context
5289         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5290         :param instance: the Instance object to detach the volume from
5291         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5292                             as deleted. Disabling this is useful for operations
5293                             like rebuild, when we don't want to destroy BDM
5294         :param attachment_id: The volume attachment_id for the given instance
5295                               and volume.
5296         """
5297         volume_id = bdm.volume_id
5298         compute_utils.notify_about_volume_attach_detach(
5299             context, instance, self.host,
5300             action=fields.NotificationAction.VOLUME_DETACH,
5301             phase=fields.NotificationPhase.START,
5302             volume_id=volume_id)
5303 
5304         self._notify_volume_usage_detach(context, instance, bdm)
5305 
5306         LOG.info('Detaching volume %(volume_id)s',
5307                  {'volume_id': volume_id}, instance=instance)
5308 
5309         driver_bdm = driver_block_device.convert_volume(bdm)
5310         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5311                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5312 
5313         info = dict(volume_id=volume_id)
5314         self._notify_about_instance_usage(
5315             context, instance, "volume.detach", extra_usage_info=info)
5316         compute_utils.notify_about_volume_attach_detach(
5317             context, instance, self.host,
5318             action=fields.NotificationAction.VOLUME_DETACH,
5319             phase=fields.NotificationPhase.END,
5320             volume_id=volume_id)
5321 
5322         if 'tag' in bdm and bdm.tag:
5323             self._delete_disk_metadata(instance, bdm)
5324         if destroy_bdm:
5325             bdm.destroy()
5326 
5327     def _delete_disk_metadata(self, instance, bdm):
5328         for device in instance.device_metadata.devices:
5329             if isinstance(device, objects.DiskMetadata):
5330                 if 'serial' in device:
5331                     if device.serial == bdm.volume_id:
5332                         instance.device_metadata.devices.remove(device)
5333                         instance.save()
5334                         break
5335                 else:
5336                     # NOTE(artom) We log the entire device object because all
5337                     # fields are nullable and may not be set
5338                     LOG.warning('Unable to determine whether to clean up '
5339                                 'device metadata for disk %s', device,
5340                                 instance=instance)
5341 
5342     @wrap_exception()
5343     @wrap_instance_event(prefix='compute')
5344     @wrap_instance_fault
5345     def detach_volume(self, context, volume_id, instance, attachment_id=None):
5346         """Detach a volume from an instance.
5347 
5348         :param context: security context
5349         :param volume_id: the volume id
5350         :param instance: the Instance object to detach the volume from
5351         :param attachment_id: The volume attachment_id for the given instance
5352                               and volume.
5353 
5354         """
5355         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5356                 context, volume_id, instance.uuid)
5357         self._detach_volume(context, bdm, instance,
5358                             attachment_id=attachment_id)
5359 
5360     def _init_volume_connection(self, context, new_volume_id,
5361                                 old_volume_id, connector, bdm,
5362                                 new_attachment_id, mountpoint):
5363 
5364         if new_attachment_id is None:
5365             # We're dealing with an old-style attachment so initialize the
5366             # connection so we can get the connection_info.
5367             new_cinfo = self.volume_api.initialize_connection(context,
5368                                                               new_volume_id,
5369                                                               connector)
5370         else:
5371             # This is a new style attachment and the API created the new
5372             # volume attachment and passed the id to the compute over RPC.
5373             # At this point we need to update the new volume attachment with
5374             # the host connector, which will give us back the new attachment
5375             # connection_info.
5376             new_cinfo = self.volume_api.attachment_update(
5377                 context, new_attachment_id, connector,
5378                 mountpoint)['connection_info']
5379 
5380         old_cinfo = jsonutils.loads(bdm['connection_info'])
5381         if old_cinfo and 'serial' not in old_cinfo:
5382             old_cinfo['serial'] = old_volume_id
5383         # NOTE(lyarwood): serial is not always present in the returned
5384         # connection_info so set it if it is missing as we do in
5385         # DriverVolumeBlockDevice.attach().
5386         if 'serial' not in new_cinfo:
5387             new_cinfo['serial'] = new_volume_id
5388         return (old_cinfo, new_cinfo)
5389 
5390     def _swap_volume(self, context, instance, bdm, connector,
5391                      old_volume_id, new_volume_id, resize_to,
5392                      new_attachment_id, is_cinder_migration):
5393         mountpoint = bdm['device_name']
5394         failed = False
5395         new_cinfo = None
5396         try:
5397             old_cinfo, new_cinfo = self._init_volume_connection(
5398                 context, new_volume_id, old_volume_id, connector,
5399                 bdm, new_attachment_id, mountpoint)
5400             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5401             # currently implementing swap_volume, will modify the contents of
5402             # new_cinfo when connect_volume is called. This is then saved to
5403             # the BDM in swap_volume for future use outside of this flow.
5404             LOG.debug("swap_volume: Calling driver volume swap with "
5405                       "connection infos: new: %(new_cinfo)s; "
5406                       "old: %(old_cinfo)s",
5407                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo},
5408                       instance=instance)
5409             self.driver.swap_volume(old_cinfo, new_cinfo, instance, mountpoint,
5410                                     resize_to)
5411             if new_attachment_id:
5412                 self.volume_api.attachment_complete(context, new_attachment_id)
5413             LOG.debug("swap_volume: Driver volume swap returned, new "
5414                       "connection_info is now : %(new_cinfo)s",
5415                       {'new_cinfo': new_cinfo})
5416         except Exception as ex:
5417             failed = True
5418             with excutils.save_and_reraise_exception():
5419                 compute_utils.notify_about_volume_swap(
5420                     context, instance, self.host,
5421                     fields.NotificationAction.VOLUME_SWAP,
5422                     fields.NotificationPhase.ERROR,
5423                     old_volume_id, new_volume_id, ex)
5424                 if new_cinfo:
5425                     msg = ("Failed to swap volume %(old_volume_id)s "
5426                            "for %(new_volume_id)s")
5427                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5428                                         'new_volume_id': new_volume_id},
5429                                   instance=instance)
5430                 else:
5431                     msg = ("Failed to connect to volume %(volume_id)s "
5432                            "with volume at %(mountpoint)s")
5433                     LOG.exception(msg, {'volume_id': new_volume_id,
5434                                         'mountpoint': bdm['device_name']},
5435                                   instance=instance)
5436 
5437                 # The API marked the volume as 'detaching' for the old volume
5438                 # so we need to roll that back so the volume goes back to
5439                 # 'in-use' state.
5440                 self.volume_api.roll_detaching(context, old_volume_id)
5441 
5442                 if new_attachment_id is None:
5443                     # The API reserved the new volume so it would be in
5444                     # 'attaching' status, so we need to unreserve it so it
5445                     # goes back to 'available' status.
5446                     self.volume_api.unreserve_volume(context, new_volume_id)
5447                 else:
5448                     # This is a new style attachment for the new volume, which
5449                     # was created in the API. We just need to delete it here
5450                     # to put the new volume back into 'available' status.
5451                     self.volume_api.attachment_delete(
5452                         context, new_attachment_id)
5453         finally:
5454             # TODO(mriedem): This finally block is terribly confusing and is
5455             # trying to do too much. We should consider removing the finally
5456             # block and move whatever needs to happen on success and failure
5457             # into the blocks above for clarity, even if it means a bit of
5458             # redundant code.
5459             conn_volume = new_volume_id if failed else old_volume_id
5460             if new_cinfo:
5461                 LOG.debug("swap_volume: removing Cinder connection "
5462                           "for volume %(volume)s", {'volume': conn_volume},
5463                           instance=instance)
5464                 if bdm.attachment_id is None:
5465                     # This is the pre-3.44 flow for new-style volume
5466                     # attachments so just terminate the connection.
5467                     self.volume_api.terminate_connection(context,
5468                                                          conn_volume,
5469                                                          connector)
5470                 else:
5471                     # This is a new style volume attachment. If we failed, then
5472                     # the new attachment was already deleted above in the
5473                     # exception block and we have nothing more to do here. If
5474                     # swap_volume was successful in the driver, then we need to
5475                     # "detach" the original attachment by deleting it.
5476                     if not failed:
5477                         self.volume_api.attachment_delete(
5478                             context, bdm.attachment_id)
5479 
5480             # Need to make some decisions based on whether this was
5481             # a Cinder initiated migration or not. The callback to
5482             # migration completion isn't needed in the case of a
5483             # nova initiated simple swap of two volume
5484             # "volume-update" call so skip that. The new attachment
5485             # scenarios will give us a new attachment record and
5486             # that's what we want.
5487             if bdm.attachment_id and not is_cinder_migration:
5488                 # we don't callback to cinder
5489                 comp_ret = {'save_volume_id': new_volume_id}
5490             else:
5491                 # NOTE(lyarwood): The following call to
5492                 # os-migrate-volume-completion returns a dict containing
5493                 # save_volume_id, this volume id has two possible values :
5494                 # 1. old_volume_id if we are migrating (retyping) volumes
5495                 # 2. new_volume_id if we are swapping between two existing
5496                 #    volumes
5497                 # This volume id is later used to update the volume_id and
5498                 # connection_info['serial'] of the BDM.
5499                 comp_ret = self.volume_api.migrate_volume_completion(
5500                                                           context,
5501                                                           old_volume_id,
5502                                                           new_volume_id,
5503                                                           error=failed)
5504                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5505                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5506                           instance=instance)
5507 
5508         return (comp_ret, new_cinfo)
5509 
5510     @wrap_exception()
5511     @wrap_instance_event(prefix='compute')
5512     @wrap_instance_fault
5513     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
5514                     new_attachment_id=None):
5515         """Swap volume for an instance."""
5516         context = context.elevated()
5517 
5518         compute_utils.notify_about_volume_swap(
5519             context, instance, self.host,
5520             fields.NotificationAction.VOLUME_SWAP,
5521             fields.NotificationPhase.START,
5522             old_volume_id, new_volume_id)
5523 
5524         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5525                 context, old_volume_id, instance.uuid)
5526         connector = self.driver.get_volume_connector(instance)
5527 
5528         resize_to = 0
5529         old_volume = self.volume_api.get(context, old_volume_id)
5530         # Yes this is a tightly-coupled state check of what's going on inside
5531         # cinder, but we need this while we still support old (v1/v2) and
5532         # new style attachments (v3.44). Once we drop support for old style
5533         # attachments we could think about cleaning up the cinder-initiated
5534         # swap volume API flows.
5535         is_cinder_migration = (
5536             True if old_volume['status'] in ('retyping',
5537                                              'migrating') else False)
5538         old_vol_size = old_volume['size']
5539         new_vol_size = self.volume_api.get(context, new_volume_id)['size']
5540         if new_vol_size > old_vol_size:
5541             resize_to = new_vol_size
5542 
5543         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5544                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5545                  instance=instance)
5546         comp_ret, new_cinfo = self._swap_volume(context,
5547                                                 instance,
5548                                                 bdm,
5549                                                 connector,
5550                                                 old_volume_id,
5551                                                 new_volume_id,
5552                                                 resize_to,
5553                                                 new_attachment_id,
5554                                                 is_cinder_migration)
5555 
5556         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5557         # correct volume_id returned by Cinder.
5558         save_volume_id = comp_ret['save_volume_id']
5559         new_cinfo['serial'] = save_volume_id
5560         values = {
5561             'connection_info': jsonutils.dumps(new_cinfo),
5562             'source_type': 'volume',
5563             'destination_type': 'volume',
5564             'snapshot_id': None,
5565             'volume_id': save_volume_id,
5566             'no_device': None}
5567 
5568         if resize_to:
5569             values['volume_size'] = resize_to
5570 
5571         if new_attachment_id is not None:
5572             # This was a volume swap for a new-style attachment so we
5573             # need to update the BDM attachment_id for the new attachment.
5574             values['attachment_id'] = new_attachment_id
5575 
5576         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5577                   "%(updates)s", {'volume_id': bdm.volume_id,
5578                                   'updates': values},
5579                   instance=instance)
5580         bdm.update(values)
5581         bdm.save()
5582 
5583         compute_utils.notify_about_volume_swap(
5584             context, instance, self.host,
5585             fields.NotificationAction.VOLUME_SWAP,
5586             fields.NotificationPhase.END,
5587             old_volume_id, new_volume_id)
5588 
5589     @wrap_exception()
5590     def remove_volume_connection(self, context, volume_id, instance):
5591         """Remove the volume connection on this host
5592 
5593         Detach the volume from this instance on this host, and if this is
5594         the cinder v2 flow, call cinder to terminate the connection.
5595         """
5596         try:
5597             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5598                     context, volume_id, instance.uuid)
5599             driver_bdm = driver_block_device.convert_volume(bdm)
5600             driver_bdm.driver_detach(context, instance,
5601                                      self.volume_api, self.driver)
5602             if bdm.attachment_id is None:
5603                 # cinder v2 api flow
5604                 connector = self.driver.get_volume_connector(instance)
5605                 self.volume_api.terminate_connection(context, volume_id,
5606                                                      connector)
5607         except exception.NotFound:
5608             pass
5609 
5610     @wrap_exception()
5611     @wrap_instance_event(prefix='compute')
5612     @wrap_instance_fault
5613     def attach_interface(self, context, instance, network_id, port_id,
5614                          requested_ip, tag=None):
5615         """Use hotplug to add an network adapter to an instance."""
5616         if not self.driver.capabilities['supports_attach_interface']:
5617             raise exception.AttachInterfaceNotSupported(
5618                 instance_uuid=instance.uuid)
5619         if (tag and not
5620             self.driver.capabilities.get('supports_tagged_attach_interface',
5621                                          False)):
5622             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5623 
5624         compute_utils.notify_about_instance_action(
5625             context, instance, self.host,
5626             action=fields.NotificationAction.INTERFACE_ATTACH,
5627             phase=fields.NotificationPhase.START)
5628 
5629         bind_host_id = self.driver.network_binding_host_id(context, instance)
5630         network_info = self.network_api.allocate_port_for_instance(
5631             context, instance, port_id, network_id, requested_ip,
5632             bind_host_id=bind_host_id, tag=tag)
5633         if len(network_info) != 1:
5634             LOG.error('allocate_port_for_instance returned %(ports)s '
5635                       'ports', {'ports': len(network_info)})
5636             # TODO(elod.illes): an instance.interface_attach.error notification
5637             # should be sent here
5638             raise exception.InterfaceAttachFailed(
5639                     instance_uuid=instance.uuid)
5640         image_meta = objects.ImageMeta.from_instance(instance)
5641 
5642         try:
5643             self.driver.attach_interface(context, instance, image_meta,
5644                                          network_info[0])
5645         except exception.NovaException as ex:
5646             port_id = network_info[0].get('id')
5647             LOG.warning("attach interface failed , try to deallocate "
5648                         "port %(port_id)s, reason: %(msg)s",
5649                         {'port_id': port_id, 'msg': ex},
5650                         instance=instance)
5651             try:
5652                 self.network_api.deallocate_port_for_instance(
5653                     context, instance, port_id)
5654             except Exception:
5655                 LOG.warning("deallocate port %(port_id)s failed",
5656                             {'port_id': port_id}, instance=instance)
5657 
5658             compute_utils.notify_about_instance_action(
5659                 context, instance, self.host,
5660                 action=fields.NotificationAction.INTERFACE_ATTACH,
5661                 phase=fields.NotificationPhase.ERROR,
5662                 exception=ex)
5663 
5664             raise exception.InterfaceAttachFailed(
5665                 instance_uuid=instance.uuid)
5666 
5667         compute_utils.notify_about_instance_action(
5668             context, instance, self.host,
5669             action=fields.NotificationAction.INTERFACE_ATTACH,
5670             phase=fields.NotificationPhase.END)
5671 
5672         return network_info[0]
5673 
5674     @wrap_exception()
5675     @wrap_instance_event(prefix='compute')
5676     @wrap_instance_fault
5677     def detach_interface(self, context, instance, port_id):
5678         """Detach a network adapter from an instance."""
5679         network_info = instance.info_cache.network_info
5680         condemned = None
5681         for vif in network_info:
5682             if vif['id'] == port_id:
5683                 condemned = vif
5684                 break
5685         if condemned is None:
5686             raise exception.PortNotFound(_("Port %s is not "
5687                                            "attached") % port_id)
5688 
5689         compute_utils.notify_about_instance_action(
5690             context, instance, self.host,
5691             action=fields.NotificationAction.INTERFACE_DETACH,
5692             phase=fields.NotificationPhase.START)
5693 
5694         try:
5695             self.driver.detach_interface(context, instance, condemned)
5696         except exception.NovaException as ex:
5697             LOG.warning("Detach interface failed, port_id=%(port_id)s,"
5698                         " reason: %(msg)s",
5699                         {'port_id': port_id, 'msg': ex}, instance=instance)
5700             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5701         else:
5702             try:
5703                 self.network_api.deallocate_port_for_instance(
5704                     context, instance, port_id)
5705             except Exception as ex:
5706                 with excutils.save_and_reraise_exception():
5707                     # Since this is a cast operation, log the failure for
5708                     # triage.
5709                     LOG.warning('Failed to deallocate port %(port_id)s '
5710                                 'for instance. Error: %(error)s',
5711                                 {'port_id': port_id, 'error': ex},
5712                                 instance=instance)
5713 
5714         compute_utils.notify_about_instance_action(
5715             context, instance, self.host,
5716             action=fields.NotificationAction.INTERFACE_DETACH,
5717             phase=fields.NotificationPhase.END)
5718 
5719     def _get_compute_info(self, context, host):
5720         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5721             context, host)
5722 
5723     @wrap_exception()
5724     def check_instance_shared_storage(self, ctxt, instance, data):
5725         """Check if the instance files are shared
5726 
5727         :param ctxt: security context
5728         :param instance: dict of instance data
5729         :param data: result of driver.check_instance_shared_storage_local
5730 
5731         Returns True if instance disks located on shared storage and
5732         False otherwise.
5733         """
5734         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5735 
5736     @wrap_exception()
5737     @wrap_instance_event(prefix='compute')
5738     @wrap_instance_fault
5739     def check_can_live_migrate_destination(self, ctxt, instance,
5740                                            block_migration, disk_over_commit):
5741         """Check if it is possible to execute live migration.
5742 
5743         This runs checks on the destination host, and then calls
5744         back to the source host to check the results.
5745 
5746         :param context: security context
5747         :param instance: dict of instance data
5748         :param block_migration: if true, prepare for block migration
5749                                 if None, calculate it in driver
5750         :param disk_over_commit: if true, allow disk over commit
5751                                  if None, ignore disk usage checking
5752         :returns: a dict containing migration info
5753         """
5754         return self._do_check_can_live_migrate_destination(ctxt, instance,
5755                                                             block_migration,
5756                                                             disk_over_commit)
5757 
5758     def _do_check_can_live_migrate_destination(self, ctxt, instance,
5759                                                block_migration,
5760                                                disk_over_commit):
5761         src_compute_info = obj_base.obj_to_primitive(
5762             self._get_compute_info(ctxt, instance.host))
5763         dst_compute_info = obj_base.obj_to_primitive(
5764             self._get_compute_info(ctxt, CONF.host))
5765         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5766             instance, src_compute_info, dst_compute_info,
5767             block_migration, disk_over_commit)
5768         LOG.debug('destination check data is %s', dest_check_data)
5769         try:
5770             migrate_data = self.compute_rpcapi.\
5771                                 check_can_live_migrate_source(ctxt, instance,
5772                                                               dest_check_data)
5773         finally:
5774             self.driver.cleanup_live_migration_destination_check(ctxt,
5775                     dest_check_data)
5776         return migrate_data
5777 
5778     @wrap_exception()
5779     @wrap_instance_event(prefix='compute')
5780     @wrap_instance_fault
5781     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5782         """Check if it is possible to execute live migration.
5783 
5784         This checks if the live migration can succeed, based on the
5785         results from check_can_live_migrate_destination.
5786 
5787         :param ctxt: security context
5788         :param instance: dict of instance data
5789         :param dest_check_data: result of check_can_live_migrate_destination
5790         :returns: a dict containing migration info
5791         """
5792         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5793             ctxt, instance.uuid)
5794         is_volume_backed = compute_utils.is_volume_backed_instance(
5795             ctxt, instance, bdms)
5796         # TODO(tdurakov): remove dict to object conversion once RPC API version
5797         # is bumped to 5.x
5798         got_migrate_data_object = isinstance(dest_check_data,
5799                                              migrate_data_obj.LiveMigrateData)
5800         if not got_migrate_data_object:
5801             dest_check_data = \
5802                 migrate_data_obj.LiveMigrateData.detect_implementation(
5803                     dest_check_data)
5804         dest_check_data.is_volume_backed = is_volume_backed
5805         block_device_info = self._get_instance_block_device_info(
5806                             ctxt, instance, refresh_conn_info=False, bdms=bdms)
5807         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5808                                                            dest_check_data,
5809                                                            block_device_info)
5810         if not got_migrate_data_object:
5811             result = result.to_legacy_dict()
5812         LOG.debug('source check data is %s', result)
5813         return result
5814 
5815     @wrap_exception()
5816     @wrap_instance_event(prefix='compute')
5817     @wrap_instance_fault
5818     def pre_live_migration(self, context, instance, block_migration, disk,
5819                            migrate_data):
5820         """Preparations for live migration at dest host.
5821 
5822         :param context: security context
5823         :param instance: dict of instance data
5824         :param block_migration: if true, prepare for block migration
5825         :param disk: disk info of instance
5826         :param migrate_data: A dict or LiveMigrateData object holding data
5827                              required for live migration without shared
5828                              storage.
5829         :returns: migrate_data containing additional migration info
5830         """
5831         LOG.debug('pre_live_migration data is %s', migrate_data)
5832         # TODO(tdurakov): remove dict to object conversion once RPC API version
5833         # is bumped to 5.x
5834         got_migrate_data_object = isinstance(migrate_data,
5835                                              migrate_data_obj.LiveMigrateData)
5836         if not got_migrate_data_object:
5837             migrate_data = \
5838                 migrate_data_obj.LiveMigrateData.detect_implementation(
5839                     migrate_data)
5840 
5841         migrate_data.old_vol_attachment_ids = {}
5842         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5843             context, instance.uuid)
5844         try:
5845             connector = self.driver.get_volume_connector(instance)
5846             for bdm in bdms:
5847                 if bdm.is_volume and bdm.attachment_id is not None:
5848                     # This bdm uses the new cinder v3.44 API.
5849                     # We will create a new attachment for this
5850                     # volume on this migration destination host. The old
5851                     # attachment will be deleted on the source host
5852                     # when the migration succeeds. The old attachment_id
5853                     # is stored in dict with the key being the bdm.volume_id
5854                     # so it can be restored on rollback.
5855                     #
5856                     # Also note that attachment_update is not needed as we
5857                     # are providing the connector in the create call.
5858                     attach_ref = self.volume_api.attachment_create(
5859                         context, bdm.volume_id, bdm.instance_uuid,
5860                         connector=connector, mountpoint=bdm.device_name)
5861 
5862                     # save current attachment so we can detach it on success,
5863                     # or restore it on a rollback.
5864                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
5865                         bdm.attachment_id
5866 
5867                     # update the bdm with the new attachment_id.
5868                     bdm.attachment_id = attach_ref['id']
5869                     bdm.save()
5870         except Exception:
5871             # If we raise, migrate_data with the updated attachment ids
5872             # will not be returned to the source host for rollback.
5873             # So we need to rollback new attachments here.
5874             with excutils.save_and_reraise_exception():
5875                 old_attachments = migrate_data.old_vol_attachment_ids
5876                 for bdm in bdms:
5877                     if (bdm.is_volume and bdm.attachment_id is not None and
5878                             bdm.volume_id in old_attachments):
5879                         self.volume_api.attachment_delete(context,
5880                                                           bdm.attachment_id)
5881                         bdm.attachment_id = old_attachments[bdm.volume_id]
5882                         bdm.save()
5883 
5884         block_device_info = self._get_instance_block_device_info(
5885                             context, instance, refresh_conn_info=True,
5886                             bdms=bdms)
5887 
5888         network_info = self.network_api.get_instance_nw_info(context, instance)
5889         self._notify_about_instance_usage(
5890                      context, instance, "live_migration.pre.start",
5891                      network_info=network_info)
5892         compute_utils.notify_about_instance_action(
5893             context, instance, self.host,
5894             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
5895             phase=fields.NotificationPhase.START)
5896 
5897         migrate_data = self.driver.pre_live_migration(context,
5898                                        instance,
5899                                        block_device_info,
5900                                        network_info,
5901                                        disk,
5902                                        migrate_data)
5903         LOG.debug('driver pre_live_migration data is %s', migrate_data)
5904 
5905         # Volume connections are complete, tell cinder that all the
5906         # attachments have completed.
5907         for bdm in bdms:
5908             if bdm.is_volume and bdm.attachment_id is not None:
5909                 self.volume_api.attachment_complete(context,
5910                                                     bdm.attachment_id)
5911 
5912         # NOTE(tr3buchet): setup networks on destination host
5913         self.network_api.setup_networks_on_host(context, instance,
5914                                                          self.host)
5915 
5916         # Creating filters to hypervisors and firewalls.
5917         # An example is that nova-instance-instance-xxx,
5918         # which is written to libvirt.xml(Check "virsh nwfilter-list")
5919         # This nwfilter is necessary on the destination host.
5920         # In addition, this method is creating filtering rule
5921         # onto destination host.
5922         self.driver.ensure_filtering_rules_for_instance(instance,
5923                                             network_info)
5924 
5925         self._notify_about_instance_usage(
5926                      context, instance, "live_migration.pre.end",
5927                      network_info=network_info)
5928         compute_utils.notify_about_instance_action(
5929             context, instance, self.host,
5930             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
5931             phase=fields.NotificationPhase.END)
5932 
5933         # TODO(tdurakov): remove dict to object conversion once RPC API version
5934         # is bumped to 5.x
5935         if not got_migrate_data_object and migrate_data:
5936             migrate_data = migrate_data.to_legacy_dict(
5937                 pre_migration_result=True)
5938             migrate_data = migrate_data['pre_live_migration_result']
5939         LOG.debug('pre_live_migration result data is %s', migrate_data)
5940         return migrate_data
5941 
5942     def _do_live_migration(self, context, dest, instance, block_migration,
5943                            migration, migrate_data):
5944         # NOTE(danms): We should enhance the RT to account for migrations
5945         # and use the status field to denote when the accounting has been
5946         # done on source/destination. For now, this is just here for status
5947         # reporting
5948         self._set_migration_status(migration, 'preparing')
5949 
5950         got_migrate_data_object = isinstance(migrate_data,
5951                                              migrate_data_obj.LiveMigrateData)
5952         if not got_migrate_data_object:
5953             migrate_data = \
5954                 migrate_data_obj.LiveMigrateData.detect_implementation(
5955                     migrate_data)
5956 
5957         try:
5958             if ('block_migration' in migrate_data and
5959                     migrate_data.block_migration):
5960                 block_device_info = self._get_instance_block_device_info(
5961                     context, instance)
5962                 disk = self.driver.get_instance_disk_info(
5963                     instance, block_device_info=block_device_info)
5964             else:
5965                 disk = None
5966 
5967             migrate_data = self.compute_rpcapi.pre_live_migration(
5968                 context, instance,
5969                 block_migration, disk, dest, migrate_data)
5970         except Exception:
5971             with excutils.save_and_reraise_exception():
5972                 LOG.exception('Pre live migration failed at %s',
5973                               dest, instance=instance)
5974                 self._set_migration_status(migration, 'error')
5975                 # Make sure we set this for _rollback_live_migration()
5976                 # so it can find it, as expected if it was called later
5977                 migrate_data.migration = migration
5978                 self._rollback_live_migration(context, instance, dest,
5979                                               migrate_data)
5980 
5981         self._set_migration_status(migration, 'running')
5982 
5983         if migrate_data:
5984             migrate_data.migration = migration
5985         LOG.debug('live_migration data is %s', migrate_data)
5986         try:
5987             self.driver.live_migration(context, instance, dest,
5988                                        self._post_live_migration,
5989                                        self._rollback_live_migration,
5990                                        block_migration, migrate_data)
5991         except Exception:
5992             LOG.exception('Live migration failed.', instance=instance)
5993             with excutils.save_and_reraise_exception():
5994                 # Put instance and migration into error state,
5995                 # as its almost certainly too late to rollback
5996                 self._set_migration_status(migration, 'error')
5997                 # first refresh instance as it may have got updated by
5998                 # post_live_migration_at_destination
5999                 instance.refresh()
6000                 self._set_instance_obj_error_state(context, instance,
6001                                                    clean_task_state=True)
6002 
6003     @wrap_exception()
6004     @wrap_instance_event(prefix='compute')
6005     @wrap_instance_fault
6006     def live_migration(self, context, dest, instance, block_migration,
6007                        migration, migrate_data):
6008         """Executing live migration.
6009 
6010         :param context: security context
6011         :param dest: destination host
6012         :param instance: a nova.objects.instance.Instance object
6013         :param block_migration: if true, prepare for block migration
6014         :param migration: an nova.objects.Migration object
6015         :param migrate_data: implementation specific params
6016 
6017         """
6018         self._set_migration_status(migration, 'queued')
6019 
6020         def dispatch_live_migration(*args, **kwargs):
6021             with self._live_migration_semaphore:
6022                 self._do_live_migration(*args, **kwargs)
6023 
6024         # NOTE(danms): We spawn here to return the RPC worker thread back to
6025         # the pool. Since what follows could take a really long time, we don't
6026         # want to tie up RPC workers.
6027         utils.spawn_n(dispatch_live_migration,
6028                       context, dest, instance,
6029                       block_migration, migration,
6030                       migrate_data)
6031 
6032     # TODO(tdurakov): migration_id is used since 4.12 rpc api version
6033     # remove migration_id parameter when the compute RPC version
6034     # is bumped to 5.x.
6035     @wrap_exception()
6036     @wrap_instance_event(prefix='compute')
6037     @wrap_instance_fault
6038     def live_migration_force_complete(self, context, instance,
6039                                       migration_id=None):
6040         """Force live migration to complete.
6041 
6042         :param context: Security context
6043         :param instance: The instance that is being migrated
6044         :param migration_id: ID of ongoing migration; is currently not used,
6045         and isn't removed for backward compatibility
6046         """
6047 
6048         self._notify_about_instance_usage(
6049             context, instance, 'live.migration.force.complete.start')
6050         self.driver.live_migration_force_complete(instance)
6051         self._notify_about_instance_usage(
6052             context, instance, 'live.migration.force.complete.end')
6053 
6054     @wrap_exception()
6055     @wrap_instance_event(prefix='compute')
6056     @wrap_instance_fault
6057     def live_migration_abort(self, context, instance, migration_id):
6058         """Abort an in-progress live migration.
6059 
6060         :param context: Security context
6061         :param instance: The instance that is being migrated
6062         :param migration_id: ID of in-progress live migration
6063 
6064         """
6065         migration = objects.Migration.get_by_id(context, migration_id)
6066         if migration.status != 'running':
6067             raise exception.InvalidMigrationState(migration_id=migration_id,
6068                     instance_uuid=instance.uuid,
6069                     state=migration.status,
6070                     method='abort live migration')
6071 
6072         self._notify_about_instance_usage(
6073             context, instance, 'live.migration.abort.start')
6074         compute_utils.notify_about_instance_action(
6075             context, instance, self.host,
6076             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6077             phase=fields.NotificationPhase.START)
6078         self.driver.live_migration_abort(instance)
6079         self._notify_about_instance_usage(
6080             context, instance, 'live.migration.abort.end')
6081         compute_utils.notify_about_instance_action(
6082             context, instance, self.host,
6083             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6084             phase=fields.NotificationPhase.END)
6085 
6086     def _live_migration_cleanup_flags(self, migrate_data):
6087         """Determine whether disks or instance path need to be cleaned up after
6088         live migration (at source on success, at destination on rollback)
6089 
6090         Block migration needs empty image at destination host before migration
6091         starts, so if any failure occurs, any empty images has to be deleted.
6092 
6093         Also Volume backed live migration w/o shared storage needs to delete
6094         newly created instance-xxx dir on the destination as a part of its
6095         rollback process
6096 
6097         :param migrate_data: implementation specific data
6098         :returns: (bool, bool) -- do_cleanup, destroy_disks
6099         """
6100         # NOTE(pkoniszewski): block migration specific params are set inside
6101         # migrate_data objects for drivers that expose block live migration
6102         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6103         # cleanup is not needed.
6104         is_shared_block_storage = True
6105         is_shared_instance_path = True
6106         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6107             is_shared_block_storage = migrate_data.is_shared_block_storage
6108             is_shared_instance_path = migrate_data.is_shared_instance_path
6109         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6110             is_shared_block_storage = not migrate_data.block_migration
6111             is_shared_instance_path = not migrate_data.block_migration
6112         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6113             is_shared_instance_path = migrate_data.is_shared_instance_path
6114             is_shared_block_storage = migrate_data.is_shared_instance_path
6115 
6116         # No instance booting at source host, but instance dir
6117         # must be deleted for preparing next block migration
6118         # must be deleted for preparing next live migration w/o shared storage
6119         do_cleanup = not is_shared_instance_path
6120         destroy_disks = not is_shared_block_storage
6121 
6122         return (do_cleanup, destroy_disks)
6123 
6124     @wrap_exception()
6125     @wrap_instance_fault
6126     def _post_live_migration(self, ctxt, instance,
6127                             dest, block_migration=False, migrate_data=None):
6128         """Post operations for live migration.
6129 
6130         This method is called from live_migration
6131         and mainly updating database record.
6132 
6133         :param ctxt: security context
6134         :param instance: instance dict
6135         :param dest: destination host
6136         :param block_migration: if true, prepare for block migration
6137         :param migrate_data: if not None, it is a dict which has data
6138         required for live migration without shared storage
6139 
6140         """
6141         LOG.info('_post_live_migration() is started..',
6142                  instance=instance)
6143 
6144         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6145                 ctxt, instance.uuid)
6146 
6147         # Cleanup source host post live-migration
6148         block_device_info = self._get_instance_block_device_info(
6149                             ctxt, instance, bdms=bdms)
6150         self.driver.post_live_migration(ctxt, instance, block_device_info,
6151                                         migrate_data)
6152 
6153         # Detaching volumes.
6154         connector = self.driver.get_volume_connector(instance)
6155         for bdm in bdms:
6156             if bdm.is_volume:
6157                 if bdm.attachment_id is None:
6158                     # Prior to cinder v3.44:
6159                     # We don't want to actually mark the volume detached, or
6160                     # delete the bdm, just remove the connection from this
6161                     # host.
6162                     #
6163                     # remove the volume connection without detaching from
6164                     # hypervisor because the instance is not running anymore
6165                     # on the current host
6166                     self.volume_api.terminate_connection(ctxt, bdm.volume_id,
6167                                                          connector)
6168                 else:
6169                     # cinder v3.44 api flow - delete the old attachment
6170                     # for the source host
6171                     old_attachment_id = \
6172                         migrate_data.old_vol_attachment_ids[bdm.volume_id]
6173                     self.volume_api.attachment_delete(ctxt, old_attachment_id)
6174 
6175         # Releasing vlan.
6176         # (not necessary in current implementation?)
6177 
6178         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
6179 
6180         self._notify_about_instance_usage(ctxt, instance,
6181                                           "live_migration._post.start",
6182                                           network_info=network_info)
6183         # Releasing security group ingress rule.
6184         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
6185                   instance=instance)
6186         self.driver.unfilter_instance(instance,
6187                                       network_info)
6188 
6189         migration = {'source_compute': self.host,
6190                      'dest_compute': dest, }
6191         self.network_api.migrate_instance_start(ctxt,
6192                                                 instance,
6193                                                 migration)
6194 
6195         destroy_vifs = False
6196         try:
6197             self.driver.post_live_migration_at_source(ctxt, instance,
6198                                                       network_info)
6199         except NotImplementedError as ex:
6200             LOG.debug(ex, instance=instance)
6201             # For all hypervisors other than libvirt, there is a possibility
6202             # they are unplugging networks from source node in the cleanup
6203             # method
6204             destroy_vifs = True
6205 
6206         # NOTE(danms): Save source node before calling post method on
6207         # destination, which will update it
6208         source_node = instance.node
6209 
6210         # Define domain at destination host, without doing it,
6211         # pause/suspend/terminate do not work.
6212         post_at_dest_success = True
6213         try:
6214             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
6215                     instance, block_migration, dest)
6216         except Exception as error:
6217             post_at_dest_success = False
6218             # We don't want to break _post_live_migration() if
6219             # post_live_migration_at_destination() fails as it should never
6220             # affect cleaning up source node.
6221             LOG.exception("Post live migration at destination %s failed",
6222                           dest, instance=instance, error=error)
6223 
6224         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6225                 migrate_data)
6226 
6227         if do_cleanup:
6228             LOG.debug('Calling driver.cleanup from _post_live_migration',
6229                       instance=instance)
6230             self.driver.cleanup(ctxt, instance, network_info,
6231                                 destroy_disks=destroy_disks,
6232                                 migrate_data=migrate_data,
6233                                 destroy_vifs=destroy_vifs)
6234 
6235         self.instance_events.clear_events_for_instance(instance)
6236 
6237         # NOTE(timello): make sure we update available resources on source
6238         # host even before next periodic task.
6239         self.update_available_resource(ctxt)
6240 
6241         self._update_scheduler_instance_info(ctxt, instance)
6242         self._notify_about_instance_usage(ctxt, instance,
6243                                           "live_migration._post.end",
6244                                           network_info=network_info)
6245         if post_at_dest_success:
6246             LOG.info('Migrating instance to %s finished successfully.',
6247                      dest, instance=instance)
6248 
6249         if migrate_data and migrate_data.obj_attr_is_set('migration'):
6250             migrate_data.migration.status = 'completed'
6251             migrate_data.migration.save()
6252             migration = migrate_data.migration
6253             rc = self.scheduler_client.reportclient
6254             # Check to see if our migration has its own allocations
6255             allocs = rc.get_allocations_for_consumer(migration.uuid)
6256         else:
6257             # We didn't have data on a migration, which means we can't
6258             # look up to see if we had new-style migration-based
6259             # allocations. This should really only happen in cases of
6260             # a buggy virt driver or some really old component in the
6261             # system. Log a warning so we know it happened.
6262             allocs = None
6263             LOG.warning('Live migration ended with no migrate_data '
6264                         'record. Unable to clean up migration-based '
6265                         'allocations which is almost certainly not '
6266                         'an expected situation.')
6267 
6268         if allocs:
6269             # We had a migration-based allocation that we need to handle
6270             self._delete_allocation_after_move(instance,
6271                                                migrate_data.migration,
6272                                                instance.flavor,
6273                                                source_node)
6274         else:
6275             # No migration-based allocations, so do the old thing and
6276             # attempt to clean up any doubled per-instance allocation
6277             rt = self._get_resource_tracker()
6278             rt.delete_allocation_for_migrated_instance(
6279                 instance, source_node)
6280 
6281     def _consoles_enabled(self):
6282         """Returns whether a console is enable."""
6283         return (CONF.vnc.enabled or CONF.spice.enabled or
6284                 CONF.rdp.enabled or CONF.serial_console.enabled or
6285                 CONF.mks.enabled)
6286 
6287     @wrap_exception()
6288     @wrap_instance_event(prefix='compute')
6289     @wrap_instance_fault
6290     def post_live_migration_at_destination(self, context, instance,
6291                                            block_migration):
6292         """Post operations for live migration .
6293 
6294         :param context: security context
6295         :param instance: Instance dict
6296         :param block_migration: if true, prepare for block migration
6297 
6298         """
6299         LOG.info('Post operation of migration started',
6300                  instance=instance)
6301 
6302         # NOTE(tr3buchet): setup networks on destination host
6303         #                  this is called a second time because
6304         #                  multi_host does not create the bridge in
6305         #                  plug_vifs
6306         self.network_api.setup_networks_on_host(context, instance,
6307                                                          self.host)
6308         migration = {'source_compute': instance.host,
6309                      'dest_compute': self.host, }
6310         self.network_api.migrate_instance_finish(context,
6311                                                  instance,
6312                                                  migration)
6313 
6314         network_info = self.network_api.get_instance_nw_info(context, instance)
6315         self._notify_about_instance_usage(
6316                      context, instance, "live_migration.post.dest.start",
6317                      network_info=network_info)
6318         block_device_info = self._get_instance_block_device_info(context,
6319                                                                  instance)
6320 
6321         try:
6322             self.driver.post_live_migration_at_destination(
6323                 context, instance, network_info, block_migration,
6324                 block_device_info)
6325         except Exception:
6326             with excutils.save_and_reraise_exception():
6327                 instance.vm_state = vm_states.ERROR
6328                 LOG.error('Unexpected error during post live migration at '
6329                           'destination host.', instance=instance)
6330         finally:
6331             # Restore instance state and update host
6332             current_power_state = self._get_power_state(context, instance)
6333             node_name = None
6334             prev_host = instance.host
6335             try:
6336                 compute_node = self._get_compute_info(context, self.host)
6337                 node_name = compute_node.hypervisor_hostname
6338             except exception.ComputeHostNotFound:
6339                 LOG.exception('Failed to get compute_info for %s', self.host)
6340             finally:
6341                 instance.host = self.host
6342                 instance.power_state = current_power_state
6343                 instance.task_state = None
6344                 instance.node = node_name
6345                 instance.progress = 0
6346                 instance.save(expected_task_state=task_states.MIGRATING)
6347 
6348         # NOTE(tr3buchet): tear down networks on source host
6349         self.network_api.setup_networks_on_host(context, instance,
6350                                                 prev_host, teardown=True)
6351         # NOTE(vish): this is necessary to update dhcp
6352         self.network_api.setup_networks_on_host(context, instance, self.host)
6353         self._notify_about_instance_usage(
6354                      context, instance, "live_migration.post.dest.end",
6355                      network_info=network_info)
6356 
6357     @wrap_exception()
6358     @wrap_instance_fault
6359     def _rollback_live_migration(self, context, instance,
6360                                  dest, migrate_data=None,
6361                                  migration_status='error'):
6362         """Recovers Instance/volume state from migrating -> running.
6363 
6364         :param context: security context
6365         :param instance: nova.objects.instance.Instance object
6366         :param dest:
6367             This method is called from live migration src host.
6368             This param specifies destination host.
6369         :param migrate_data:
6370             if not none, contains implementation specific data.
6371         :param migration_status:
6372             Contains the status we want to set for the migration object
6373 
6374         """
6375         # TODO(tdurakov): remove dict to object conversion once RPC API version
6376         # is bumped to 5.x
6377         if isinstance(migrate_data, dict):
6378             migration = migrate_data.pop('migration', None)
6379             migrate_data = \
6380                 migrate_data_obj.LiveMigrateData.detect_implementation(
6381                     migrate_data)
6382         elif (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
6383               migrate_data.obj_attr_is_set('migration')):
6384             migration = migrate_data.migration
6385         else:
6386             migration = None
6387 
6388         if migration:
6389             # Remove allocations created in Placement for the dest node.
6390             # If migration is None, we must be so old we don't have placement,
6391             # so no need to do something else.
6392             self._revert_allocation(context, instance, migration)
6393         else:
6394             LOG.error('Unable to revert allocations during live migration '
6395                       'rollback; compute driver did not provide migrate_data',
6396                       instance=instance)
6397 
6398         instance.task_state = None
6399         instance.progress = 0
6400         instance.save(expected_task_state=[task_states.MIGRATING])
6401 
6402         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
6403         self.network_api.setup_networks_on_host(context, instance, self.host)
6404 
6405         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6406                 context, instance.uuid)
6407         for bdm in bdms:
6408             if bdm.is_volume:
6409                 # remove the connection on the destination host
6410                 self.compute_rpcapi.remove_volume_connection(
6411                         context, instance, bdm.volume_id, dest)
6412 
6413                 if bdm.attachment_id:
6414                     # 3.44 cinder api flow. Set the bdm's
6415                     # attachment_id to the old attachment of the source
6416                     # host. If old_attachments is not there, then
6417                     # there was an error before the new attachment was made.
6418                     old_attachments = migrate_data.old_vol_attachment_ids \
6419                         if 'old_vol_attachment_ids' in migrate_data else None
6420                     if old_attachments and bdm.volume_id in old_attachments:
6421                         self.volume_api.attachment_delete(context,
6422                                                           bdm.attachment_id)
6423                         bdm.attachment_id = old_attachments[bdm.volume_id]
6424                         bdm.save()
6425 
6426         self._notify_about_instance_usage(context, instance,
6427                                           "live_migration._rollback.start")
6428         compute_utils.notify_about_instance_action(context, instance,
6429                 self.host,
6430                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6431                 phase=fields.NotificationPhase.START,
6432                 bdms=bdms)
6433 
6434         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6435                 migrate_data)
6436 
6437         if do_cleanup:
6438             self.compute_rpcapi.rollback_live_migration_at_destination(
6439                     context, instance, dest, destroy_disks=destroy_disks,
6440                     migrate_data=migrate_data)
6441 
6442         self._notify_about_instance_usage(context, instance,
6443                                           "live_migration._rollback.end")
6444         compute_utils.notify_about_instance_action(context, instance,
6445 
6446                 self.host,
6447                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6448                 phase=fields.NotificationPhase.END,
6449                 bdms=bdms)
6450 
6451         self._set_migration_status(migration, migration_status)
6452 
6453     @wrap_exception()
6454     @wrap_instance_event(prefix='compute')
6455     @wrap_instance_fault
6456     def rollback_live_migration_at_destination(self, context, instance,
6457                                                destroy_disks,
6458                                                migrate_data):
6459         """Cleaning up image directory that is created pre_live_migration.
6460 
6461         :param context: security context
6462         :param instance: a nova.objects.instance.Instance object sent over rpc
6463         :param destroy_disks: whether to destroy volumes or not
6464         :param migrate_data: contains migration info
6465         """
6466         network_info = self.network_api.get_instance_nw_info(context, instance)
6467         self._notify_about_instance_usage(
6468                       context, instance, "live_migration.rollback.dest.start",
6469                       network_info=network_info)
6470         try:
6471             # NOTE(tr3buchet): tear down networks on destination host
6472             self.network_api.setup_networks_on_host(context, instance,
6473                                                     self.host, teardown=True)
6474         except Exception:
6475             with excutils.save_and_reraise_exception():
6476                 # NOTE(tdurakov): even if teardown networks fails driver
6477                 # should try to rollback live migration on destination.
6478                 LOG.exception('An error occurred while deallocating network.',
6479                               instance=instance)
6480         finally:
6481             # always run this even if setup_networks_on_host fails
6482             # NOTE(vish): The mapping is passed in so the driver can disconnect
6483             #             from remote volumes if necessary
6484             block_device_info = self._get_instance_block_device_info(context,
6485                                                                      instance)
6486             # TODO(tdurakov): remove dict to object conversion once RPC API
6487             # version is bumped to 5.x
6488             if isinstance(migrate_data, dict):
6489                 migrate_data = \
6490                     migrate_data_obj.LiveMigrateData.detect_implementation(
6491                         migrate_data)
6492             self.driver.rollback_live_migration_at_destination(
6493                 context, instance, network_info, block_device_info,
6494                 destroy_disks=destroy_disks, migrate_data=migrate_data)
6495 
6496         self._notify_about_instance_usage(
6497                         context, instance, "live_migration.rollback.dest.end",
6498                         network_info=network_info)
6499 
6500     @periodic_task.periodic_task(
6501         spacing=CONF.heal_instance_info_cache_interval)
6502     def _heal_instance_info_cache(self, context):
6503         """Called periodically.  On every call, try to update the
6504         info_cache's network information for another instance by
6505         calling to the network manager.
6506 
6507         This is implemented by keeping a cache of uuids of instances
6508         that live on this host.  On each call, we pop one off of a
6509         list, pull the DB record, and try the call to the network API.
6510         If anything errors don't fail, as it's possible the instance
6511         has been deleted, etc.
6512         """
6513         heal_interval = CONF.heal_instance_info_cache_interval
6514         if not heal_interval:
6515             return
6516 
6517         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
6518         instance = None
6519 
6520         LOG.debug('Starting heal instance info cache')
6521 
6522         if not instance_uuids:
6523             # The list of instances to heal is empty so rebuild it
6524             LOG.debug('Rebuilding the list of instances to heal')
6525             db_instances = objects.InstanceList.get_by_host(
6526                 context, self.host, expected_attrs=[], use_slave=True)
6527             for inst in db_instances:
6528                 # We don't want to refresh the cache for instances
6529                 # which are building or deleting so don't put them
6530                 # in the list. If they are building they will get
6531                 # added to the list next time we build it.
6532                 if (inst.vm_state == vm_states.BUILDING):
6533                     LOG.debug('Skipping network cache update for instance '
6534                               'because it is Building.', instance=inst)
6535                     continue
6536                 if (inst.task_state == task_states.DELETING):
6537                     LOG.debug('Skipping network cache update for instance '
6538                               'because it is being deleted.', instance=inst)
6539                     continue
6540 
6541                 if not instance:
6542                     # Save the first one we find so we don't
6543                     # have to get it again
6544                     instance = inst
6545                 else:
6546                     instance_uuids.append(inst['uuid'])
6547 
6548             self._instance_uuids_to_heal = instance_uuids
6549         else:
6550             # Find the next valid instance on the list
6551             while instance_uuids:
6552                 try:
6553                     inst = objects.Instance.get_by_uuid(
6554                             context, instance_uuids.pop(0),
6555                             expected_attrs=['system_metadata', 'info_cache',
6556                                             'flavor'],
6557                             use_slave=True)
6558                 except exception.InstanceNotFound:
6559                     # Instance is gone.  Try to grab another.
6560                     continue
6561 
6562                 # Check the instance hasn't been migrated
6563                 if inst.host != self.host:
6564                     LOG.debug('Skipping network cache update for instance '
6565                               'because it has been migrated to another '
6566                               'host.', instance=inst)
6567                 # Check the instance isn't being deleting
6568                 elif inst.task_state == task_states.DELETING:
6569                     LOG.debug('Skipping network cache update for instance '
6570                               'because it is being deleted.', instance=inst)
6571                 else:
6572                     instance = inst
6573                     break
6574 
6575         if instance:
6576             # We have an instance now to refresh
6577             try:
6578                 # Call to network API to get instance info.. this will
6579                 # force an update to the instance's info_cache
6580                 self.network_api.get_instance_nw_info(context, instance)
6581                 LOG.debug('Updated the network info_cache for instance',
6582                           instance=instance)
6583             except exception.InstanceNotFound:
6584                 # Instance is gone.
6585                 LOG.debug('Instance no longer exists. Unable to refresh',
6586                           instance=instance)
6587                 return
6588             except exception.InstanceInfoCacheNotFound:
6589                 # InstanceInfoCache is gone.
6590                 LOG.debug('InstanceInfoCache no longer exists. '
6591                           'Unable to refresh', instance=instance)
6592             except Exception:
6593                 LOG.error('An error occurred while refreshing the network '
6594                           'cache.', instance=instance, exc_info=True)
6595         else:
6596             LOG.debug("Didn't find any instances for network info cache "
6597                       "update.")
6598 
6599     @periodic_task.periodic_task
6600     def _poll_rebooting_instances(self, context):
6601         if CONF.reboot_timeout > 0:
6602             filters = {'task_state':
6603                        [task_states.REBOOTING,
6604                         task_states.REBOOT_STARTED,
6605                         task_states.REBOOT_PENDING],
6606                        'host': self.host}
6607             rebooting = objects.InstanceList.get_by_filters(
6608                 context, filters, expected_attrs=[], use_slave=True)
6609 
6610             to_poll = []
6611             for instance in rebooting:
6612                 if timeutils.is_older_than(instance.updated_at,
6613                                            CONF.reboot_timeout):
6614                     to_poll.append(instance)
6615 
6616             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
6617 
6618     @periodic_task.periodic_task
6619     def _poll_rescued_instances(self, context):
6620         if CONF.rescue_timeout > 0:
6621             filters = {'vm_state': vm_states.RESCUED,
6622                        'host': self.host}
6623             rescued_instances = objects.InstanceList.get_by_filters(
6624                 context, filters, expected_attrs=["system_metadata"],
6625                 use_slave=True)
6626 
6627             to_unrescue = []
6628             for instance in rescued_instances:
6629                 if timeutils.is_older_than(instance.launched_at,
6630                                            CONF.rescue_timeout):
6631                     to_unrescue.append(instance)
6632 
6633             for instance in to_unrescue:
6634                 self.compute_api.unrescue(context, instance)
6635 
6636     @periodic_task.periodic_task
6637     def _poll_unconfirmed_resizes(self, context):
6638         if CONF.resize_confirm_window == 0:
6639             return
6640 
6641         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
6642                 context, CONF.resize_confirm_window, self.host,
6643                 use_slave=True)
6644 
6645         migrations_info = dict(migration_count=len(migrations),
6646                 confirm_window=CONF.resize_confirm_window)
6647 
6648         if migrations_info["migration_count"] > 0:
6649             LOG.info("Found %(migration_count)d unconfirmed migrations "
6650                      "older than %(confirm_window)d seconds",
6651                      migrations_info)
6652 
6653         def _set_migration_to_error(migration, reason, **kwargs):
6654             LOG.warning("Setting migration %(migration_id)s to error: "
6655                         "%(reason)s",
6656                         {'migration_id': migration['id'], 'reason': reason},
6657                         **kwargs)
6658             migration.status = 'error'
6659             with migration.obj_as_admin():
6660                 migration.save()
6661 
6662         for migration in migrations:
6663             instance_uuid = migration.instance_uuid
6664             LOG.info("Automatically confirming migration "
6665                      "%(migration_id)s for instance %(instance_uuid)s",
6666                      {'migration_id': migration.id,
6667                       'instance_uuid': instance_uuid})
6668             expected_attrs = ['metadata', 'system_metadata']
6669             try:
6670                 instance = objects.Instance.get_by_uuid(context,
6671                             instance_uuid, expected_attrs=expected_attrs,
6672                             use_slave=True)
6673             except exception.InstanceNotFound:
6674                 reason = (_("Instance %s not found") %
6675                           instance_uuid)
6676                 _set_migration_to_error(migration, reason)
6677                 continue
6678             if instance.vm_state == vm_states.ERROR:
6679                 reason = _("In ERROR state")
6680                 _set_migration_to_error(migration, reason,
6681                                         instance=instance)
6682                 continue
6683             # race condition: The instance in DELETING state should not be
6684             # set the migration state to error, otherwise the instance in
6685             # to be deleted which is in RESIZED state
6686             # will not be able to confirm resize
6687             if instance.task_state in [task_states.DELETING,
6688                                        task_states.SOFT_DELETING]:
6689                 msg = ("Instance being deleted or soft deleted during resize "
6690                        "confirmation. Skipping.")
6691                 LOG.debug(msg, instance=instance)
6692                 continue
6693 
6694             # race condition: This condition is hit when this method is
6695             # called between the save of the migration record with a status of
6696             # finished and the save of the instance object with a state of
6697             # RESIZED. The migration record should not be set to error.
6698             if instance.task_state == task_states.RESIZE_FINISH:
6699                 msg = ("Instance still resizing during resize "
6700                        "confirmation. Skipping.")
6701                 LOG.debug(msg, instance=instance)
6702                 continue
6703 
6704             vm_state = instance.vm_state
6705             task_state = instance.task_state
6706             if vm_state != vm_states.RESIZED or task_state is not None:
6707                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
6708                            "RESIZED/None") %
6709                           {'vm_state': vm_state,
6710                            'task_state': task_state})
6711                 _set_migration_to_error(migration, reason,
6712                                         instance=instance)
6713                 continue
6714             try:
6715                 self.compute_api.confirm_resize(context, instance,
6716                                                 migration=migration)
6717             except Exception as e:
6718                 LOG.info("Error auto-confirming resize: %s. "
6719                          "Will retry later.", e, instance=instance)
6720 
6721     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
6722     def _poll_shelved_instances(self, context):
6723 
6724         if CONF.shelved_offload_time <= 0:
6725             return
6726 
6727         filters = {'vm_state': vm_states.SHELVED,
6728                    'task_state': None,
6729                    'host': self.host}
6730         shelved_instances = objects.InstanceList.get_by_filters(
6731             context, filters=filters, expected_attrs=['system_metadata'],
6732             use_slave=True)
6733 
6734         to_gc = []
6735         for instance in shelved_instances:
6736             sys_meta = instance.system_metadata
6737             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
6738             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
6739                 to_gc.append(instance)
6740 
6741         @wrap_exception()
6742         @reverts_task_state
6743         @wrap_instance_fault
6744         def shelve_offload_instance(_self, ctxt, instance):
6745 
6746             @utils.synchronized(instance.uuid)
6747             def do_shelve_offload_instance():
6748                 self._shelve_offload_instance(ctxt, instance,
6749                                               clean_shutdown=False)
6750             do_shelve_offload_instance()
6751 
6752         for instance in to_gc:
6753             try:
6754                 instance.task_state = task_states.SHELVING_OFFLOADING
6755                 instance.save(expected_task_state=(None,))
6756                 # NOTE(Kevin Zheng): We use the _shelve_offload_instance
6757                 # method to avoid issues with instance actions/events since
6758                 # the context used in this periodic task will not have a
6759                 # valid request ID. The inner method used here uses the same
6760                 # exception and fault handlers and locking scheme as the
6761                 # top-level shelve_offload_instance method
6762                 # NOTE(mriedem): This looks weird, but we need to pass self
6763                 # through to the inner method for the decorators to work
6764                 # properly.
6765                 shelve_offload_instance(self, context, instance)
6766             except Exception:
6767                 LOG.exception('Periodic task failed to offload instance.',
6768                               instance=instance)
6769 
6770     @periodic_task.periodic_task
6771     def _instance_usage_audit(self, context):
6772         if not CONF.instance_usage_audit:
6773             return
6774 
6775         begin, end = utils.last_completed_audit_period()
6776         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
6777                                self.host):
6778             return
6779 
6780         instances = objects.InstanceList.get_active_by_window_joined(
6781             context, begin, end, host=self.host,
6782             expected_attrs=['system_metadata', 'info_cache', 'metadata',
6783                             'flavor'],
6784             use_slave=True)
6785         num_instances = len(instances)
6786         errors = 0
6787         successes = 0
6788         LOG.info("Running instance usage audit for host %(host)s "
6789                  "from %(begin_time)s to %(end_time)s. "
6790                  "%(number_instances)s instances.",
6791                  {'host': self.host,
6792                   'begin_time': begin,
6793                   'end_time': end,
6794                   'number_instances': num_instances})
6795         start_time = time.time()
6796         task_log = objects.TaskLog(context)
6797         task_log.task_name = 'instance_usage_audit'
6798         task_log.period_beginning = begin
6799         task_log.period_ending = end
6800         task_log.host = self.host
6801         task_log.task_items = num_instances
6802         task_log.message = 'Instance usage audit started...'
6803         task_log.begin_task()
6804         for instance in instances:
6805             try:
6806                 compute_utils.notify_usage_exists(
6807                     self.notifier, context, instance,
6808                     ignore_missing_network_data=False)
6809                 successes += 1
6810             except Exception:
6811                 LOG.exception('Failed to generate usage '
6812                               'audit for instance '
6813                               'on host %s', self.host,
6814                               instance=instance)
6815                 errors += 1
6816         task_log.errors = errors
6817         task_log.message = (
6818             'Instance usage audit ran for host %s, %s instances in %s seconds.'
6819             % (self.host, num_instances, time.time() - start_time))
6820         task_log.end_task()
6821 
6822     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
6823     def _poll_bandwidth_usage(self, context):
6824 
6825         if not self._bw_usage_supported:
6826             return
6827 
6828         prev_time, start_time = utils.last_completed_audit_period()
6829 
6830         curr_time = time.time()
6831         if (curr_time - self._last_bw_usage_poll >
6832                 CONF.bandwidth_poll_interval):
6833             self._last_bw_usage_poll = curr_time
6834             LOG.info("Updating bandwidth usage cache")
6835             cells_update_interval = CONF.cells.bandwidth_update_interval
6836             if (cells_update_interval > 0 and
6837                    curr_time - self._last_bw_usage_cell_update >
6838                            cells_update_interval):
6839                 self._last_bw_usage_cell_update = curr_time
6840                 update_cells = True
6841             else:
6842                 update_cells = False
6843 
6844             instances = objects.InstanceList.get_by_host(context,
6845                                                               self.host,
6846                                                               use_slave=True)
6847             try:
6848                 bw_counters = self.driver.get_all_bw_counters(instances)
6849             except NotImplementedError:
6850                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
6851                 # implemented yet.  If they don't it doesn't break anything,
6852                 # they just don't get the info in the usage events.
6853                 # NOTE(PhilDay): Record that its not supported so we can
6854                 # skip fast on future calls rather than waste effort getting
6855                 # the list of instances.
6856                 LOG.info("Bandwidth usage not supported by hypervisor.")
6857                 self._bw_usage_supported = False
6858                 return
6859 
6860             refreshed = timeutils.utcnow()
6861             for bw_ctr in bw_counters:
6862                 # Allow switching of greenthreads between queries.
6863                 greenthread.sleep(0)
6864                 bw_in = 0
6865                 bw_out = 0
6866                 last_ctr_in = None
6867                 last_ctr_out = None
6868                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6869                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6870                     start_period=start_time, use_slave=True)
6871                 if usage:
6872                     bw_in = usage.bw_in
6873                     bw_out = usage.bw_out
6874                     last_ctr_in = usage.last_ctr_in
6875                     last_ctr_out = usage.last_ctr_out
6876                 else:
6877                     usage = (objects.BandwidthUsage.
6878                              get_by_instance_uuid_and_mac(
6879                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6880                         start_period=prev_time, use_slave=True))
6881                     if usage:
6882                         last_ctr_in = usage.last_ctr_in
6883                         last_ctr_out = usage.last_ctr_out
6884 
6885                 if last_ctr_in is not None:
6886                     if bw_ctr['bw_in'] < last_ctr_in:
6887                         # counter rollover
6888                         bw_in += bw_ctr['bw_in']
6889                     else:
6890                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6891 
6892                 if last_ctr_out is not None:
6893                     if bw_ctr['bw_out'] < last_ctr_out:
6894                         # counter rollover
6895                         bw_out += bw_ctr['bw_out']
6896                     else:
6897                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6898 
6899                 objects.BandwidthUsage(context=context).create(
6900                                               bw_ctr['uuid'],
6901                                               bw_ctr['mac_address'],
6902                                               bw_in,
6903                                               bw_out,
6904                                               bw_ctr['bw_in'],
6905                                               bw_ctr['bw_out'],
6906                                               start_period=start_time,
6907                                               last_refreshed=refreshed,
6908                                               update_cells=update_cells)
6909 
6910     def _get_host_volume_bdms(self, context, use_slave=False):
6911         """Return all block device mappings on a compute host."""
6912         compute_host_bdms = []
6913         instances = objects.InstanceList.get_by_host(context, self.host,
6914             use_slave=use_slave)
6915         for instance in instances:
6916             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6917                     context, instance.uuid, use_slave=use_slave)
6918             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6919             compute_host_bdms.append(dict(instance=instance,
6920                                           instance_bdms=instance_bdms))
6921 
6922         return compute_host_bdms
6923 
6924     def _update_volume_usage_cache(self, context, vol_usages):
6925         """Updates the volume usage cache table with a list of stats."""
6926         for usage in vol_usages:
6927             # Allow switching of greenthreads between queries.
6928             greenthread.sleep(0)
6929             vol_usage = objects.VolumeUsage(context)
6930             vol_usage.volume_id = usage['volume']
6931             vol_usage.instance_uuid = usage['instance'].uuid
6932             vol_usage.project_id = usage['instance'].project_id
6933             vol_usage.user_id = usage['instance'].user_id
6934             vol_usage.availability_zone = usage['instance'].availability_zone
6935             vol_usage.curr_reads = usage['rd_req']
6936             vol_usage.curr_read_bytes = usage['rd_bytes']
6937             vol_usage.curr_writes = usage['wr_req']
6938             vol_usage.curr_write_bytes = usage['wr_bytes']
6939             vol_usage.save()
6940             self.notifier.info(context, 'volume.usage',
6941                                compute_utils.usage_volume_info(vol_usage))
6942 
6943     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
6944     def _poll_volume_usage(self, context):
6945         if CONF.volume_usage_poll_interval == 0:
6946             return
6947 
6948         compute_host_bdms = self._get_host_volume_bdms(context,
6949                                                        use_slave=True)
6950         if not compute_host_bdms:
6951             return
6952 
6953         LOG.debug("Updating volume usage cache")
6954         try:
6955             vol_usages = self.driver.get_all_volume_usage(context,
6956                                                           compute_host_bdms)
6957         except NotImplementedError:
6958             return
6959 
6960         self._update_volume_usage_cache(context, vol_usages)
6961 
6962     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
6963                                  run_immediately=True)
6964     def _sync_power_states(self, context):
6965         """Align power states between the database and the hypervisor.
6966 
6967         To sync power state data we make a DB call to get the number of
6968         virtual machines known by the hypervisor and if the number matches the
6969         number of virtual machines known by the database, we proceed in a lazy
6970         loop, one database record at a time, checking if the hypervisor has the
6971         same power state as is in the database.
6972         """
6973         db_instances = objects.InstanceList.get_by_host(context, self.host,
6974                                                         expected_attrs=[],
6975                                                         use_slave=True)
6976 
6977         num_vm_instances = self.driver.get_num_instances()
6978         num_db_instances = len(db_instances)
6979 
6980         if num_vm_instances != num_db_instances:
6981             LOG.warning("While synchronizing instance power states, found "
6982                         "%(num_db_instances)s instances in the database "
6983                         "and %(num_vm_instances)s instances on the "
6984                         "hypervisor.",
6985                         {'num_db_instances': num_db_instances,
6986                          'num_vm_instances': num_vm_instances})
6987 
6988         def _sync(db_instance):
6989             # NOTE(melwitt): This must be synchronized as we query state from
6990             #                two separate sources, the driver and the database.
6991             #                They are set (in stop_instance) and read, in sync.
6992             @utils.synchronized(db_instance.uuid)
6993             def query_driver_power_state_and_sync():
6994                 self._query_driver_power_state_and_sync(context, db_instance)
6995 
6996             try:
6997                 query_driver_power_state_and_sync()
6998             except Exception:
6999                 LOG.exception("Periodic sync_power_state task had an "
7000                               "error while processing an instance.",
7001                               instance=db_instance)
7002 
7003             self._syncs_in_progress.pop(db_instance.uuid)
7004 
7005         for db_instance in db_instances:
7006             # process syncs asynchronously - don't want instance locking to
7007             # block entire periodic task thread
7008             uuid = db_instance.uuid
7009             if uuid in self._syncs_in_progress:
7010                 LOG.debug('Sync already in progress for %s', uuid)
7011             else:
7012                 LOG.debug('Triggering sync for uuid %s', uuid)
7013                 self._syncs_in_progress[uuid] = True
7014                 self._sync_power_pool.spawn_n(_sync, db_instance)
7015 
7016     def _query_driver_power_state_and_sync(self, context, db_instance):
7017         if db_instance.task_state is not None:
7018             LOG.info("During sync_power_state the instance has a "
7019                      "pending task (%(task)s). Skip.",
7020                      {'task': db_instance.task_state}, instance=db_instance)
7021             return
7022         # No pending tasks. Now try to figure out the real vm_power_state.
7023         try:
7024             vm_instance = self.driver.get_info(db_instance)
7025             vm_power_state = vm_instance.state
7026         except exception.InstanceNotFound:
7027             vm_power_state = power_state.NOSTATE
7028         # Note(maoy): the above get_info call might take a long time,
7029         # for example, because of a broken libvirt driver.
7030         try:
7031             self._sync_instance_power_state(context,
7032                                             db_instance,
7033                                             vm_power_state,
7034                                             use_slave=True)
7035         except exception.InstanceNotFound:
7036             # NOTE(hanlind): If the instance gets deleted during sync,
7037             # silently ignore.
7038             pass
7039 
7040     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
7041                                    use_slave=False):
7042         """Align instance power state between the database and hypervisor.
7043 
7044         If the instance is not found on the hypervisor, but is in the database,
7045         then a stop() API will be called on the instance.
7046         """
7047 
7048         # We re-query the DB to get the latest instance info to minimize
7049         # (not eliminate) race condition.
7050         db_instance.refresh(use_slave=use_slave)
7051         db_power_state = db_instance.power_state
7052         vm_state = db_instance.vm_state
7053 
7054         if self.host != db_instance.host:
7055             # on the sending end of nova-compute _sync_power_state
7056             # may have yielded to the greenthread performing a live
7057             # migration; this in turn has changed the resident-host
7058             # for the VM; However, the instance is still active, it
7059             # is just in the process of migrating to another host.
7060             # This implies that the compute source must relinquish
7061             # control to the compute destination.
7062             LOG.info("During the sync_power process the "
7063                      "instance has moved from "
7064                      "host %(src)s to host %(dst)s",
7065                      {'src': db_instance.host,
7066                       'dst': self.host},
7067                      instance=db_instance)
7068             return
7069         elif db_instance.task_state is not None:
7070             # on the receiving end of nova-compute, it could happen
7071             # that the DB instance already report the new resident
7072             # but the actual VM has not showed up on the hypervisor
7073             # yet. In this case, let's allow the loop to continue
7074             # and run the state sync in a later round
7075             LOG.info("During sync_power_state the instance has a "
7076                      "pending task (%(task)s). Skip.",
7077                      {'task': db_instance.task_state},
7078                      instance=db_instance)
7079             return
7080 
7081         orig_db_power_state = db_power_state
7082         if vm_power_state != db_power_state:
7083             LOG.info('During _sync_instance_power_state the DB '
7084                      'power_state (%(db_power_state)s) does not match '
7085                      'the vm_power_state from the hypervisor '
7086                      '(%(vm_power_state)s). Updating power_state in the '
7087                      'DB to match the hypervisor.',
7088                      {'db_power_state': db_power_state,
7089                       'vm_power_state': vm_power_state},
7090                      instance=db_instance)
7091             # power_state is always updated from hypervisor to db
7092             db_instance.power_state = vm_power_state
7093             db_instance.save()
7094             db_power_state = vm_power_state
7095 
7096         # Note(maoy): Now resolve the discrepancy between vm_state and
7097         # vm_power_state. We go through all possible vm_states.
7098         if vm_state in (vm_states.BUILDING,
7099                         vm_states.RESCUED,
7100                         vm_states.RESIZED,
7101                         vm_states.SUSPENDED,
7102                         vm_states.ERROR):
7103             # TODO(maoy): we ignore these vm_state for now.
7104             pass
7105         elif vm_state == vm_states.ACTIVE:
7106             # The only rational power state should be RUNNING
7107             if vm_power_state in (power_state.SHUTDOWN,
7108                                   power_state.CRASHED):
7109                 LOG.warning("Instance shutdown by itself. Calling the "
7110                             "stop API. Current vm_state: %(vm_state)s, "
7111                             "current task_state: %(task_state)s, "
7112                             "original DB power_state: %(db_power_state)s, "
7113                             "current VM power_state: %(vm_power_state)s",
7114                             {'vm_state': vm_state,
7115                              'task_state': db_instance.task_state,
7116                              'db_power_state': orig_db_power_state,
7117                              'vm_power_state': vm_power_state},
7118                             instance=db_instance)
7119                 try:
7120                     # Note(maoy): here we call the API instead of
7121                     # brutally updating the vm_state in the database
7122                     # to allow all the hooks and checks to be performed.
7123                     if db_instance.shutdown_terminate:
7124                         self.compute_api.delete(context, db_instance)
7125                     else:
7126                         self.compute_api.stop(context, db_instance)
7127                 except Exception:
7128                     # Note(maoy): there is no need to propagate the error
7129                     # because the same power_state will be retrieved next
7130                     # time and retried.
7131                     # For example, there might be another task scheduled.
7132                     LOG.exception("error during stop() in sync_power_state.",
7133                                   instance=db_instance)
7134             elif vm_power_state == power_state.SUSPENDED:
7135                 LOG.warning("Instance is suspended unexpectedly. Calling "
7136                             "the stop API.", instance=db_instance)
7137                 try:
7138                     self.compute_api.stop(context, db_instance)
7139                 except Exception:
7140                     LOG.exception("error during stop() in sync_power_state.",
7141                                   instance=db_instance)
7142             elif vm_power_state == power_state.PAUSED:
7143                 # Note(maoy): a VM may get into the paused state not only
7144                 # because the user request via API calls, but also
7145                 # due to (temporary) external instrumentations.
7146                 # Before the virt layer can reliably report the reason,
7147                 # we simply ignore the state discrepancy. In many cases,
7148                 # the VM state will go back to running after the external
7149                 # instrumentation is done. See bug 1097806 for details.
7150                 LOG.warning("Instance is paused unexpectedly. Ignore.",
7151                             instance=db_instance)
7152             elif vm_power_state == power_state.NOSTATE:
7153                 # Occasionally, depending on the status of the hypervisor,
7154                 # which could be restarting for example, an instance may
7155                 # not be found.  Therefore just log the condition.
7156                 LOG.warning("Instance is unexpectedly not found. Ignore.",
7157                             instance=db_instance)
7158         elif vm_state == vm_states.STOPPED:
7159             if vm_power_state not in (power_state.NOSTATE,
7160                                       power_state.SHUTDOWN,
7161                                       power_state.CRASHED):
7162                 LOG.warning("Instance is not stopped. Calling "
7163                             "the stop API. Current vm_state: %(vm_state)s,"
7164                             " current task_state: %(task_state)s, "
7165                             "original DB power_state: %(db_power_state)s, "
7166                             "current VM power_state: %(vm_power_state)s",
7167                             {'vm_state': vm_state,
7168                              'task_state': db_instance.task_state,
7169                              'db_power_state': orig_db_power_state,
7170                              'vm_power_state': vm_power_state},
7171                             instance=db_instance)
7172                 try:
7173                     # NOTE(russellb) Force the stop, because normally the
7174                     # compute API would not allow an attempt to stop a stopped
7175                     # instance.
7176                     self.compute_api.force_stop(context, db_instance)
7177                 except Exception:
7178                     LOG.exception("error during stop() in sync_power_state.",
7179                                   instance=db_instance)
7180         elif vm_state == vm_states.PAUSED:
7181             if vm_power_state in (power_state.SHUTDOWN,
7182                                   power_state.CRASHED):
7183                 LOG.warning("Paused instance shutdown by itself. Calling "
7184                             "the stop API.", instance=db_instance)
7185                 try:
7186                     self.compute_api.force_stop(context, db_instance)
7187                 except Exception:
7188                     LOG.exception("error during stop() in sync_power_state.",
7189                                   instance=db_instance)
7190         elif vm_state in (vm_states.SOFT_DELETED,
7191                           vm_states.DELETED):
7192             if vm_power_state not in (power_state.NOSTATE,
7193                                       power_state.SHUTDOWN):
7194                 # Note(maoy): this should be taken care of periodically in
7195                 # _cleanup_running_deleted_instances().
7196                 LOG.warning("Instance is not (soft-)deleted.",
7197                             instance=db_instance)
7198 
7199     @periodic_task.periodic_task
7200     def _reclaim_queued_deletes(self, context):
7201         """Reclaim instances that are queued for deletion."""
7202         interval = CONF.reclaim_instance_interval
7203         if interval <= 0:
7204             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
7205             return
7206 
7207         filters = {'vm_state': vm_states.SOFT_DELETED,
7208                    'task_state': None,
7209                    'host': self.host}
7210         instances = objects.InstanceList.get_by_filters(
7211             context, filters,
7212             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
7213             use_slave=True)
7214         for instance in instances:
7215             if self._deleted_old_enough(instance, interval):
7216                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7217                         context, instance.uuid)
7218                 LOG.info('Reclaiming deleted instance', instance=instance)
7219                 try:
7220                     self._delete_instance(context, instance, bdms)
7221                 except Exception as e:
7222                     LOG.warning("Periodic reclaim failed to delete "
7223                                 "instance: %s",
7224                                 e, instance=instance)
7225 
7226     def _get_nodename(self, instance, refresh=False):
7227         """Helper method to get the name of the first available node
7228         on this host. This method should not be used with any operations
7229         on ironic instances since it does not handle multiple nodes.
7230         """
7231         node = self.driver.get_available_nodes(refresh=refresh)[0]
7232         LOG.debug("No node specified, defaulting to %s", node,
7233                   instance=instance)
7234         return node
7235 
7236     def update_available_resource_for_node(self, context, nodename):
7237 
7238         rt = self._get_resource_tracker()
7239         try:
7240             rt.update_available_resource(context, nodename)
7241         except exception.ComputeHostNotFound:
7242             # NOTE(comstud): We can get to this case if a node was
7243             # marked 'deleted' in the DB and then re-added with a
7244             # different auto-increment id. The cached resource
7245             # tracker tried to update a deleted record and failed.
7246             # Don't add this resource tracker to the new dict, so
7247             # that this will resolve itself on the next run.
7248             LOG.info("Compute node '%s' not found in "
7249                      "update_available_resource.", nodename)
7250             # TODO(jaypipes): Yes, this is inefficient to throw away all of the
7251             # compute nodes to force a rebuild, but this is only temporary
7252             # until Ironic baremetal node resource providers are tracked
7253             # properly in the report client and this is a tiny edge case
7254             # anyway.
7255             self._resource_tracker = None
7256             return
7257         except Exception:
7258             LOG.exception("Error updating resources for node %(node)s.",
7259                           {'node': nodename})
7260 
7261     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
7262     def update_available_resource(self, context, startup=False):
7263         """See driver.get_available_resource()
7264 
7265         Periodic process that keeps that the compute host's understanding of
7266         resource availability and usage in sync with the underlying hypervisor.
7267 
7268         :param context: security context
7269         :param startup: True if this is being called when the nova-compute
7270             service is starting, False otherwise.
7271         """
7272 
7273         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
7274                                                             use_slave=True,
7275                                                             startup=startup)
7276         nodenames = set(self.driver.get_available_nodes())
7277         for nodename in nodenames:
7278             self.update_available_resource_for_node(context, nodename)
7279 
7280         # Delete orphan compute node not reported by driver but still in db
7281         for cn in compute_nodes_in_db:
7282             if cn.hypervisor_hostname not in nodenames:
7283                 LOG.info("Deleting orphan compute node %(id)s "
7284                          "hypervisor host is %(hh)s, "
7285                          "nodes are %(nodes)s",
7286                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
7287                           'nodes': nodenames})
7288                 cn.destroy()
7289                 # Delete the corresponding resource provider in placement,
7290                 # along with any associated allocations and inventory.
7291                 # TODO(cdent): Move use of reportclient into resource tracker.
7292                 self.scheduler_client.reportclient.delete_resource_provider(
7293                     context, cn, cascade=True)
7294 
7295     def _get_compute_nodes_in_db(self, context, use_slave=False,
7296                                  startup=False):
7297         try:
7298             return objects.ComputeNodeList.get_all_by_host(context, self.host,
7299                                                            use_slave=use_slave)
7300         except exception.NotFound:
7301             if startup:
7302                 LOG.warning(
7303                     "No compute node record found for host %s. If this is "
7304                     "the first time this service is starting on this "
7305                     "host, then you can ignore this warning.", self.host)
7306             else:
7307                 LOG.error("No compute node record for host %s", self.host)
7308             return []
7309 
7310     @periodic_task.periodic_task(
7311         spacing=CONF.running_deleted_instance_poll_interval)
7312     def _cleanup_running_deleted_instances(self, context):
7313         """Cleanup any instances which are erroneously still running after
7314         having been deleted.
7315 
7316         Valid actions to take are:
7317 
7318             1. noop - do nothing
7319             2. log - log which instances are erroneously running
7320             3. reap - shutdown and cleanup any erroneously running instances
7321             4. shutdown - power off *and disable* any erroneously running
7322                           instances
7323 
7324         The use-case for this cleanup task is: for various reasons, it may be
7325         possible for the database to show an instance as deleted but for that
7326         instance to still be running on a host machine (see bug
7327         https://bugs.launchpad.net/nova/+bug/911366).
7328 
7329         This cleanup task is a cross-hypervisor utility for finding these
7330         zombied instances and either logging the discrepancy (likely what you
7331         should do in production), or automatically reaping the instances (more
7332         appropriate for dev environments).
7333         """
7334         action = CONF.running_deleted_instance_action
7335 
7336         if action == "noop":
7337             return
7338 
7339         # NOTE(sirp): admin contexts don't ordinarily return deleted records
7340         with utils.temporary_mutation(context, read_deleted="yes"):
7341             for instance in self._running_deleted_instances(context):
7342                 if action == "log":
7343                     LOG.warning("Detected instance with name label "
7344                                 "'%s' which is marked as "
7345                                 "DELETED but still present on host.",
7346                                 instance.name, instance=instance)
7347 
7348                 elif action == 'shutdown':
7349                     LOG.info("Powering off instance with name label "
7350                              "'%s' which is marked as "
7351                              "DELETED but still present on host.",
7352                              instance.name, instance=instance)
7353                     try:
7354                         try:
7355                             # disable starting the instance
7356                             self.driver.set_bootable(instance, False)
7357                         except NotImplementedError:
7358                             LOG.debug("set_bootable is not implemented "
7359                                       "for the current driver")
7360                         # and power it off
7361                         self.driver.power_off(instance)
7362                     except Exception:
7363                         LOG.warning("Failed to power off instance",
7364                                     instance=instance, exc_info=True)
7365 
7366                 elif action == 'reap':
7367                     LOG.info("Destroying instance with name label "
7368                              "'%s' which is marked as "
7369                              "DELETED but still present on host.",
7370                              instance.name, instance=instance)
7371                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7372                         context, instance.uuid, use_slave=True)
7373                     self.instance_events.clear_events_for_instance(instance)
7374                     try:
7375                         self._shutdown_instance(context, instance, bdms,
7376                                                 notify=False)
7377                         self._cleanup_volumes(context, instance.uuid, bdms)
7378                     except Exception as e:
7379                         LOG.warning("Periodic cleanup failed to delete "
7380                                     "instance: %s",
7381                                     e, instance=instance)
7382                 else:
7383                     raise Exception(_("Unrecognized value '%s'"
7384                                       " for CONF.running_deleted_"
7385                                       "instance_action") % action)
7386 
7387     def _running_deleted_instances(self, context):
7388         """Returns a list of instances nova thinks is deleted,
7389         but the hypervisor thinks is still running.
7390         """
7391         timeout = CONF.running_deleted_instance_timeout
7392         filters = {'deleted': True,
7393                    'soft_deleted': False}
7394         instances = self._get_instances_on_driver(context, filters)
7395         return [i for i in instances if self._deleted_old_enough(i, timeout)]
7396 
7397     def _deleted_old_enough(self, instance, timeout):
7398         deleted_at = instance.deleted_at
7399         if deleted_at:
7400             deleted_at = deleted_at.replace(tzinfo=None)
7401         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
7402 
7403     @contextlib.contextmanager
7404     def _error_out_instance_on_exception(self, context, instance,
7405                                          instance_state=vm_states.ACTIVE):
7406         instance_uuid = instance.uuid
7407         try:
7408             yield
7409         except NotImplementedError as error:
7410             with excutils.save_and_reraise_exception():
7411                 LOG.info("Setting instance back to %(state)s after: "
7412                          "%(error)s",
7413                          {'state': instance_state, 'error': error},
7414                          instance_uuid=instance_uuid)
7415                 self._instance_update(context, instance,
7416                                       vm_state=instance_state,
7417                                       task_state=None)
7418         except exception.InstanceFaultRollback as error:
7419             LOG.info("Setting instance back to ACTIVE after: %s",
7420                      error, instance_uuid=instance_uuid)
7421             self._instance_update(context, instance,
7422                                   vm_state=vm_states.ACTIVE,
7423                                   task_state=None)
7424             raise error.inner_exception
7425         except Exception:
7426             LOG.exception('Setting instance vm_state to ERROR',
7427                           instance_uuid=instance_uuid)
7428             with excutils.save_and_reraise_exception():
7429                 self._set_instance_obj_error_state(context, instance)
7430 
7431     @wrap_exception()
7432     def add_aggregate_host(self, context, aggregate, host, slave_info):
7433         """Notify hypervisor of change (for hypervisor pools)."""
7434         try:
7435             self.driver.add_to_aggregate(context, aggregate, host,
7436                                          slave_info=slave_info)
7437         except NotImplementedError:
7438             LOG.debug('Hypervisor driver does not support '
7439                       'add_aggregate_host')
7440         except exception.AggregateError:
7441             with excutils.save_and_reraise_exception():
7442                 self.driver.undo_aggregate_operation(
7443                                     context,
7444                                     aggregate.delete_host,
7445                                     aggregate, host)
7446 
7447     @wrap_exception()
7448     def remove_aggregate_host(self, context, host, slave_info, aggregate):
7449         """Removes a host from a physical hypervisor pool."""
7450         try:
7451             self.driver.remove_from_aggregate(context, aggregate, host,
7452                                               slave_info=slave_info)
7453         except NotImplementedError:
7454             LOG.debug('Hypervisor driver does not support '
7455                       'remove_aggregate_host')
7456         except (exception.AggregateError,
7457                 exception.InvalidAggregateAction) as e:
7458             with excutils.save_and_reraise_exception():
7459                 self.driver.undo_aggregate_operation(
7460                                     context,
7461                                     aggregate.add_host,
7462                                     aggregate, host,
7463                                     isinstance(e, exception.AggregateError))
7464 
7465     def _process_instance_event(self, instance, event):
7466         _event = self.instance_events.pop_instance_event(instance, event)
7467         if _event:
7468             LOG.debug('Processing event %(event)s',
7469                       {'event': event.key}, instance=instance)
7470             _event.send(event)
7471         else:
7472             # If it's a network-vif-unplugged event and the instance is being
7473             # deleted then we don't need to make this a warning as it's
7474             # expected. There are other things which could trigger this like
7475             # detaching an interface, but we don't have a task state for that.
7476             if (event.name == 'network-vif-unplugged' and
7477                     instance.task_state == task_states.DELETING):
7478                 LOG.debug('Received event %s for instance which is being '
7479                           'deleted.', event.key, instance=instance)
7480             else:
7481                 LOG.warning('Received unexpected event %(event)s for '
7482                             'instance with vm_state %(vm_state)s and '
7483                             'task_state %(task_state)s.',
7484                             {'event': event.key,
7485                              'vm_state': instance.vm_state,
7486                              'task_state': instance.task_state},
7487                             instance=instance)
7488 
7489     def _process_instance_vif_deleted_event(self, context, instance,
7490                                             deleted_vif_id):
7491         # If an attached port is deleted by neutron, it needs to
7492         # be detached from the instance.
7493         # And info cache needs to be updated.
7494         network_info = instance.info_cache.network_info
7495         for index, vif in enumerate(network_info):
7496             if vif['id'] == deleted_vif_id:
7497                 LOG.info('Neutron deleted interface %(intf)s; '
7498                          'detaching it from the instance and '
7499                          'deleting it from the info cache',
7500                          {'intf': vif['id']},
7501                          instance=instance)
7502                 del network_info[index]
7503                 base_net_api.update_instance_cache_with_nw_info(
7504                                  self.network_api, context,
7505                                  instance,
7506                                  nw_info=network_info)
7507                 try:
7508                     self.driver.detach_interface(context, instance, vif)
7509                 except NotImplementedError:
7510                     # Not all virt drivers support attach/detach of interfaces
7511                     # yet (like Ironic), so just ignore this.
7512                     pass
7513                 except exception.NovaException as ex:
7514                     LOG.warning("Detach interface failed, "
7515                                 "port_id=%(port_id)s, reason: %(msg)s",
7516                                 {'port_id': deleted_vif_id, 'msg': ex},
7517                                 instance=instance)
7518                 break
7519 
7520     @wrap_instance_event(prefix='compute')
7521     @wrap_instance_fault
7522     def extend_volume(self, context, instance, extended_volume_id):
7523 
7524         # If an attached volume is extended by cinder, it needs to
7525         # be extended by virt driver so host can detect its new size.
7526         # And bdm needs to be updated.
7527         LOG.debug('Handling volume-extended event for volume %(vol)s',
7528                   {'vol': extended_volume_id}, instance=instance)
7529 
7530         try:
7531             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
7532                    context, extended_volume_id, instance.uuid)
7533         except exception.NotFound:
7534             LOG.warning('Extend volume failed, '
7535                         'volume %(vol)s is not attached to instance.',
7536                         {'vol': extended_volume_id},
7537                         instance=instance)
7538             return
7539 
7540         LOG.info('Cinder extended volume %(vol)s; '
7541                  'extending it to detect new size',
7542                  {'vol': extended_volume_id},
7543                  instance=instance)
7544         volume = self.volume_api.get(context, bdm.volume_id)
7545 
7546         if bdm.connection_info is None:
7547             LOG.warning('Extend volume failed, '
7548                         'attached volume %(vol)s has no connection_info',
7549                         {'vol': extended_volume_id},
7550                         instance=instance)
7551             return
7552 
7553         connection_info = jsonutils.loads(bdm.connection_info)
7554         bdm.volume_size = volume['size']
7555         bdm.save()
7556 
7557         if not self.driver.capabilities.get('supports_extend_volume', False):
7558             raise exception.ExtendVolumeNotSupported()
7559 
7560         try:
7561             self.driver.extend_volume(connection_info,
7562                                       instance)
7563         except Exception as ex:
7564             LOG.warning('Extend volume failed, '
7565                         'volume_id=%(volume_id)s, reason: %(msg)s',
7566                         {'volume_id': extended_volume_id, 'msg': ex},
7567                         instance=instance)
7568             raise
7569 
7570     @wrap_exception()
7571     def external_instance_event(self, context, instances, events):
7572         # NOTE(danms): Some event types are handled by the manager, such
7573         # as when we're asked to update the instance's info_cache. If it's
7574         # not one of those, look for some thread(s) waiting for the event and
7575         # unblock them if so.
7576         for event in events:
7577             instance = [inst for inst in instances
7578                         if inst.uuid == event.instance_uuid][0]
7579             LOG.debug('Received event %(event)s',
7580                       {'event': event.key},
7581                       instance=instance)
7582             if event.name == 'network-changed':
7583                 try:
7584                     self.network_api.get_instance_nw_info(context, instance)
7585                 except exception.NotFound as e:
7586                     LOG.info('Failed to process external instance event '
7587                              '%(event)s due to: %(error)s',
7588                              {'event': event.key, 'error': six.text_type(e)},
7589                              instance=instance)
7590             elif event.name == 'network-vif-deleted':
7591                 try:
7592                     self._process_instance_vif_deleted_event(context,
7593                                                              instance,
7594                                                              event.tag)
7595                 except exception.NotFound as e:
7596                     LOG.info('Failed to process external instance event '
7597                              '%(event)s due to: %(error)s',
7598                              {'event': event.key, 'error': six.text_type(e)},
7599                              instance=instance)
7600             elif event.name == 'volume-extended':
7601                 self.extend_volume(context, instance, event.tag)
7602             else:
7603                 self._process_instance_event(instance, event)
7604 
7605     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
7606                                  external_process_ok=True)
7607     def _run_image_cache_manager_pass(self, context):
7608         """Run a single pass of the image cache manager."""
7609 
7610         if not self.driver.capabilities["has_imagecache"]:
7611             return
7612 
7613         # Determine what other nodes use this storage
7614         storage_users.register_storage_use(CONF.instances_path, CONF.host)
7615         nodes = storage_users.get_storage_users(CONF.instances_path)
7616 
7617         # Filter all_instances to only include those nodes which share this
7618         # storage path.
7619         # TODO(mikal): this should be further refactored so that the cache
7620         # cleanup code doesn't know what those instances are, just a remote
7621         # count, and then this logic should be pushed up the stack.
7622         filters = {'deleted': False,
7623                    'soft_deleted': True,
7624                    'host': nodes}
7625         filtered_instances = objects.InstanceList.get_by_filters(context,
7626                                  filters, expected_attrs=[], use_slave=True)
7627 
7628         self.driver.manage_image_cache(context, filtered_instances)
7629 
7630     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7631     def _run_pending_deletes(self, context):
7632         """Retry any pending instance file deletes."""
7633         LOG.debug('Cleaning up deleted instances')
7634         filters = {'deleted': True,
7635                    'soft_deleted': False,
7636                    'host': CONF.host,
7637                    'cleaned': False}
7638         attrs = ['system_metadata']
7639         with utils.temporary_mutation(context, read_deleted='yes'):
7640             instances = objects.InstanceList.get_by_filters(
7641                 context, filters, expected_attrs=attrs, use_slave=True)
7642         LOG.debug('There are %d instances to clean', len(instances))
7643 
7644         # TODO(raj_singh): Remove this if condition when min value is
7645         # introduced to "maximum_instance_delete_attempts" cfg option.
7646         if CONF.maximum_instance_delete_attempts < 1:
7647             LOG.warning('Future versions of Nova will restrict the '
7648                         '"maximum_instance_delete_attempts" config option '
7649                         'to values >=1. Update your configuration file to '
7650                         'mitigate future upgrade issues.')
7651 
7652         for instance in instances:
7653             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
7654             LOG.debug('Instance has had %(attempts)s of %(max)s '
7655                       'cleanup attempts',
7656                       {'attempts': attempts,
7657                        'max': CONF.maximum_instance_delete_attempts},
7658                       instance=instance)
7659             if attempts < CONF.maximum_instance_delete_attempts:
7660                 success = self.driver.delete_instance_files(instance)
7661 
7662                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
7663                 if success:
7664                     instance.cleaned = True
7665                 with utils.temporary_mutation(context, read_deleted='yes'):
7666                     instance.save()
7667 
7668     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7669     def _cleanup_incomplete_migrations(self, context):
7670         """Delete instance files on failed resize/revert-resize operation
7671 
7672         During resize/revert-resize operation, if that instance gets deleted
7673         in-between then instance files might remain either on source or
7674         destination compute node because of race condition.
7675         """
7676         LOG.debug('Cleaning up deleted instances with incomplete migration ')
7677         migration_filters = {'host': CONF.host,
7678                              'status': 'error'}
7679         migrations = objects.MigrationList.get_by_filters(context,
7680                                                           migration_filters)
7681 
7682         if not migrations:
7683             return
7684 
7685         inst_uuid_from_migrations = set([migration.instance_uuid for migration
7686                                          in migrations])
7687 
7688         inst_filters = {'deleted': True, 'soft_deleted': False,
7689                         'uuid': inst_uuid_from_migrations}
7690         attrs = ['info_cache', 'security_groups', 'system_metadata']
7691         with utils.temporary_mutation(context, read_deleted='yes'):
7692             instances = objects.InstanceList.get_by_filters(
7693                 context, inst_filters, expected_attrs=attrs, use_slave=True)
7694 
7695         for instance in instances:
7696             if instance.host != CONF.host:
7697                 for migration in migrations:
7698                     if instance.uuid == migration.instance_uuid:
7699                         # Delete instance files if not cleanup properly either
7700                         # from the source or destination compute nodes when
7701                         # the instance is deleted during resizing.
7702                         self.driver.delete_instance_files(instance)
7703                         try:
7704                             migration.status = 'failed'
7705                             with migration.obj_as_admin():
7706                                 migration.save()
7707                         except exception.MigrationNotFound:
7708                             LOG.warning("Migration %s is not found.",
7709                                         migration.id,
7710                                         instance=instance)
7711                         break
7712 
7713     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7714                                    exception.QemuGuestAgentNotEnabled,
7715                                    exception.NovaException,
7716                                    NotImplementedError)
7717     @wrap_exception()
7718     def quiesce_instance(self, context, instance):
7719         """Quiesce an instance on this host."""
7720         context = context.elevated()
7721         image_meta = objects.ImageMeta.from_instance(instance)
7722         self.driver.quiesce(context, instance, image_meta)
7723 
7724     def _wait_for_snapshots_completion(self, context, mapping):
7725         for mapping_dict in mapping:
7726             if mapping_dict.get('source_type') == 'snapshot':
7727 
7728                 def _wait_snapshot():
7729                     snapshot = self.volume_api.get_snapshot(
7730                         context, mapping_dict['snapshot_id'])
7731                     if snapshot.get('status') != 'creating':
7732                         raise loopingcall.LoopingCallDone()
7733 
7734                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
7735                 timer.start(interval=0.5).wait()
7736 
7737     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7738                                    exception.QemuGuestAgentNotEnabled,
7739                                    exception.NovaException,
7740                                    NotImplementedError)
7741     @wrap_exception()
7742     def unquiesce_instance(self, context, instance, mapping=None):
7743         """Unquiesce an instance on this host.
7744 
7745         If snapshots' image mapping is provided, it waits until snapshots are
7746         completed before unqueiscing.
7747         """
7748         context = context.elevated()
7749         if mapping:
7750             try:
7751                 self._wait_for_snapshots_completion(context, mapping)
7752             except Exception as error:
7753                 LOG.exception("Exception while waiting completion of "
7754                               "volume snapshots: %s",
7755                               error, instance=instance)
7756         image_meta = objects.ImageMeta.from_instance(instance)
7757         self.driver.unquiesce(context, instance, image_meta)
