Please review the code below to detect security defects. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are found, please state '''No security defects are detected in the code'''.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 from cursive import exception as cursive_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 from keystoneauth1 import exceptions as keystone_exception
44 from oslo_log import log as logging
45 import oslo_messaging as messaging
46 from oslo_serialization import jsonutils
47 from oslo_service import loopingcall
48 from oslo_service import periodic_task
49 from oslo_utils import excutils
50 from oslo_utils import strutils
51 from oslo_utils import timeutils
52 from oslo_utils import uuidutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova.console import rpcapi as console_rpcapi
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova import image
77 from nova import manager
78 from nova import network
79 from nova.network import base_api as base_net_api
80 from nova.network import model as network_model
81 from nova.network.security_group import openstack_driver
82 from nova import objects
83 from nova.objects import base as obj_base
84 from nova.objects import fields
85 from nova.objects import instance as obj_instance
86 from nova.objects import migrate_data as migrate_data_obj
87 from nova.pci import whitelist
88 from nova import rpc
89 from nova import safe_utils
90 from nova.scheduler import client as scheduler_client
91 from nova.scheduler import utils as scheduler_utils
92 from nova import utils
93 from nova.virt import block_device as driver_block_device
94 from nova.virt import configdrive
95 from nova.virt import driver
96 from nova.virt import event as virtevent
97 from nova.virt import storage_users
98 from nova.virt import virtapi
99 from nova.volume import cinder
100 
101 CONF = nova.conf.CONF
102 
103 LOG = logging.getLogger(__name__)
104 
105 get_notifier = functools.partial(rpc.get_notifier, service='compute')
106 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
107                                    get_notifier=get_notifier,
108                                    binary='nova-compute')
109 
110 
111 @contextlib.contextmanager
112 def errors_out_migration_ctxt(migration):
113     """Context manager to error out migration on failure."""
114 
115     try:
116         yield
117     except Exception:
118         with excutils.save_and_reraise_exception():
119             if migration:
120                 # We may have been passed None for our migration if we're
121                 # receiving from an older client. The migration will be
122                 # errored via the legacy path.
123                 migration.status = 'error'
124                 try:
125                     with migration.obj_as_admin():
126                         migration.save()
127                 except Exception:
128                     LOG.debug(
129                         'Error setting migration status for instance %s.',
130                         migration.instance_uuid, exc_info=True)
131 
132 
133 @utils.expects_func_args('migration')
134 def errors_out_migration(function):
135     """Decorator to error out migration on failure."""
136 
137     @functools.wraps(function)
138     def decorated_function(self, context, *args, **kwargs):
139         wrapped_func = safe_utils.get_wrapped_function(function)
140         keyed_args = inspect.getcallargs(wrapped_func, self, context,
141                                          *args, **kwargs)
142         migration = keyed_args['migration']
143         with errors_out_migration_ctxt(migration):
144             return function(self, context, *args, **kwargs)
145 
146     return decorated_function
147 
148 
149 @utils.expects_func_args('instance')
150 def reverts_task_state(function):
151     """Decorator to revert task_state on failure."""
152 
153     @functools.wraps(function)
154     def decorated_function(self, context, *args, **kwargs):
155         try:
156             return function(self, context, *args, **kwargs)
157         except exception.UnexpectedTaskStateError as e:
158             # Note(maoy): unexpected task state means the current
159             # task is preempted. Do not clear task state in this
160             # case.
161             with excutils.save_and_reraise_exception():
162                 LOG.info("Task possibly preempted: %s",
163                          e.format_message())
164         except Exception:
165             with excutils.save_and_reraise_exception():
166                 wrapped_func = safe_utils.get_wrapped_function(function)
167                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
168                                                  *args, **kwargs)
169                 # NOTE(mriedem): 'instance' must be in keyed_args because we
170                 # have utils.expects_func_args('instance') decorating this
171                 # method.
172                 instance = keyed_args['instance']
173                 original_task_state = instance.task_state
174                 try:
175                     self._instance_update(context, instance, task_state=None)
176                     LOG.info("Successfully reverted task state from %s on "
177                              "failure for instance.",
178                              original_task_state, instance=instance)
179                 except exception.InstanceNotFound:
180                     # We might delete an instance that failed to build shortly
181                     # after it errored out this is an expected case and we
182                     # should not trace on it.
183                     pass
184                 except Exception as e:
185                     LOG.warning("Failed to revert task state for instance. "
186                                 "Error: %s", e, instance=instance)
187 
188     return decorated_function
189 
190 
191 @utils.expects_func_args('instance')
192 def wrap_instance_fault(function):
193     """Wraps a method to catch exceptions related to instances.
194 
195     This decorator wraps a method to catch any exceptions having to do with
196     an instance that may get thrown. It then logs an instance fault in the db.
197     """
198 
199     @functools.wraps(function)
200     def decorated_function(self, context, *args, **kwargs):
201         try:
202             return function(self, context, *args, **kwargs)
203         except exception.InstanceNotFound:
204             raise
205         except Exception as e:
206             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
207             # we will get a KeyError exception which will cover up the real
208             # exception. So, we update kwargs with the values from args first.
209             # then, we can get 'instance' from kwargs easily.
210             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
211 
212             with excutils.save_and_reraise_exception():
213                 compute_utils.add_instance_fault_from_exc(context,
214                         kwargs['instance'], e, sys.exc_info())
215 
216     return decorated_function
217 
218 
219 @utils.expects_func_args('image_id', 'instance')
220 def delete_image_on_error(function):
221     """Used for snapshot related method to ensure the image created in
222     compute.api is deleted when an error occurs.
223     """
224 
225     @functools.wraps(function)
226     def decorated_function(self, context, image_id, instance,
227                            *args, **kwargs):
228         try:
229             return function(self, context, image_id, instance,
230                             *args, **kwargs)
231         except Exception:
232             with excutils.save_and_reraise_exception():
233                 LOG.debug("Cleaning up image %s", image_id,
234                           exc_info=True, instance=instance)
235                 try:
236                     self.image_api.delete(context, image_id)
237                 except exception.ImageNotFound:
238                     # Since we're trying to cleanup an image, we don't care if
239                     # if it's already gone.
240                     pass
241                 except Exception:
242                     LOG.exception("Error while trying to clean up image %s",
243                                   image_id, instance=instance)
244 
245     return decorated_function
246 
247 
248 # TODO(danms): Remove me after Icehouse
249 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
250 # NOTE(mikal): if the method being decorated has more than one decorator, then
251 # put this one first. Otherwise the various exception handling decorators do
252 # not function correctly.
253 def object_compat(function):
254     """Wraps a method that expects a new-world instance
255 
256     This provides compatibility for callers passing old-style dict
257     instances.
258     """
259 
260     @functools.wraps(function)
261     def decorated_function(self, context, *args, **kwargs):
262         def _load_instance(instance_or_dict):
263             if isinstance(instance_or_dict, dict):
264                 # try to get metadata and system_metadata for most cases but
265                 # only attempt to load those if the db instance already has
266                 # those fields joined
267                 metas = [meta for meta in ('metadata', 'system_metadata')
268                          if meta in instance_or_dict]
269                 instance = objects.Instance._from_db_object(
270                     context, objects.Instance(), instance_or_dict,
271                     expected_attrs=metas)
272                 instance._context = context
273                 return instance
274             return instance_or_dict
275 
276         try:
277             kwargs['instance'] = _load_instance(kwargs['instance'])
278         except KeyError:
279             args = (_load_instance(args[0]),) + args[1:]
280 
281         migration = kwargs.get('migration')
282         if isinstance(migration, dict):
283             migration = objects.Migration._from_db_object(
284                     context.elevated(), objects.Migration(),
285                     migration)
286             kwargs['migration'] = migration
287 
288         return function(self, context, *args, **kwargs)
289 
290     return decorated_function
291 
292 
293 class InstanceEvents(object):
294     def __init__(self):
295         self._events = {}
296 
297     @staticmethod
298     def _lock_name(instance):
299         return '%s-%s' % (instance.uuid, 'events')
300 
301     def prepare_for_instance_event(self, instance, name, tag):
302         """Prepare to receive an event for an instance.
303 
304         This will register an event for the given instance that we will
305         wait on later. This should be called before initiating whatever
306         action will trigger the event. The resulting eventlet.event.Event
307         object should be wait()'d on to ensure completion.
308 
309         :param instance: the instance for which the event will be generated
310         :param name: the name of the event we're expecting
311         :param tag: the tag associated with the event we're expecting
312         :returns: an event object that should be wait()'d on
313         """
314         if self._events is None:
315             # NOTE(danms): We really should have a more specific error
316             # here, but this is what we use for our default error case
317             raise exception.NovaException('In shutdown, no new events '
318                                           'can be scheduled')
319 
320         @utils.synchronized(self._lock_name(instance))
321         def _create_or_get_event():
322             instance_events = self._events.setdefault(instance.uuid, {})
323             return instance_events.setdefault((name, tag),
324                                               eventlet.event.Event())
325         LOG.debug('Preparing to wait for external event %(name)s-%(tag)s',
326                   {'name': name, 'tag': tag}, instance=instance)
327         return _create_or_get_event()
328 
329     def pop_instance_event(self, instance, event):
330         """Remove a pending event from the wait list.
331 
332         This will remove a pending event from the wait list so that it
333         can be used to signal the waiters to wake up.
334 
335         :param instance: the instance for which the event was generated
336         :param event: the nova.objects.external_event.InstanceExternalEvent
337                       that describes the event
338         :returns: the eventlet.event.Event object on which the waiters
339                   are blocked
340         """
341         no_events_sentinel = object()
342         no_matching_event_sentinel = object()
343 
344         @utils.synchronized(self._lock_name(instance))
345         def _pop_event():
346             if self._events is None:
347                 LOG.debug('Unexpected attempt to pop events during shutdown',
348                           instance=instance)
349                 return no_events_sentinel
350             events = self._events.get(instance.uuid)
351             if not events:
352                 return no_events_sentinel
353             _event = events.pop((event.name, event.tag), None)
354             if not events:
355                 del self._events[instance.uuid]
356             if _event is None:
357                 return no_matching_event_sentinel
358             return _event
359 
360         result = _pop_event()
361         if result is no_events_sentinel:
362             LOG.debug('No waiting events found dispatching %(event)s',
363                       {'event': event.key},
364                       instance=instance)
365             return None
366         elif result is no_matching_event_sentinel:
367             LOG.debug('No event matching %(event)s in %(events)s',
368                       {'event': event.key,
369                        'events': self._events.get(instance.uuid, {}).keys()},
370                       instance=instance)
371             return None
372         else:
373             return result
374 
375     def clear_events_for_instance(self, instance):
376         """Remove all pending events for an instance.
377 
378         This will remove all events currently pending for an instance
379         and return them (indexed by event name).
380 
381         :param instance: the instance for which events should be purged
382         :returns: a dictionary of {event_name: eventlet.event.Event}
383         """
384         @utils.synchronized(self._lock_name(instance))
385         def _clear_events():
386             if self._events is None:
387                 LOG.debug('Unexpected attempt to clear events during shutdown',
388                           instance=instance)
389                 return dict()
390             # NOTE(danms): We have historically returned the raw internal
391             # format here, which is {event.key: [events, ...])} so just
392             # trivially convert it here.
393             return {'%s-%s' % k: e
394                     for k, e in self._events.pop(instance.uuid, {}).items()}
395         return _clear_events()
396 
397     def cancel_all_events(self):
398         if self._events is None:
399             LOG.debug('Unexpected attempt to cancel events during shutdown.')
400             return
401         our_events = self._events
402         # NOTE(danms): Block new events
403         self._events = None
404 
405         for instance_uuid, events in our_events.items():
406             for (name, tag), eventlet_event in events.items():
407                 LOG.debug('Canceling in-flight event %(name)s-%(tag)s for '
408                           'instance %(instance_uuid)s',
409                           {'name': name,
410                            'tag': tag,
411                            'instance_uuid': instance_uuid})
412                 event = objects.InstanceExternalEvent(
413                     instance_uuid=instance_uuid,
414                     name=name, status='failed',
415                     tag=tag, data={})
416                 eventlet_event.send(event)
417 
418 
419 class ComputeVirtAPI(virtapi.VirtAPI):
420     def __init__(self, compute):
421         super(ComputeVirtAPI, self).__init__()
422         self._compute = compute
423 
424     def _default_error_callback(self, event_name, instance):
425         raise exception.NovaException(_('Instance event failed'))
426 
427     @contextlib.contextmanager
428     def wait_for_instance_event(self, instance, event_names, deadline=300,
429                                 error_callback=None):
430         """Plan to wait for some events, run some code, then wait.
431 
432         This context manager will first create plans to wait for the
433         provided event_names, yield, and then wait for all the scheduled
434         events to complete.
435 
436         Note that this uses an eventlet.timeout.Timeout to bound the
437         operation, so callers should be prepared to catch that
438         failure and handle that situation appropriately.
439 
440         If the event is not received by the specified timeout deadline,
441         eventlet.timeout.Timeout is raised.
442 
443         If the event is received but did not have a 'completed'
444         status, a NovaException is raised.  If an error_callback is
445         provided, instead of raising an exception as detailed above
446         for the failure case, the callback will be called with the
447         event_name and instance, and can return True to continue
448         waiting for the rest of the events, False to stop processing,
449         or raise an exception which will bubble up to the waiter.
450 
451         :param instance: The instance for which an event is expected
452         :param event_names: A list of event names. Each element is a
453                             tuple of strings to indicate (name, tag),
454                             where name is required, but tag may be None.
455         :param deadline: Maximum number of seconds we should wait for all
456                          of the specified events to arrive.
457         :param error_callback: A function to be called if an event arrives
458 
459         """
460 
461         if error_callback is None:
462             error_callback = self._default_error_callback
463         events = {}
464         for event_name in event_names:
465             name, tag = event_name
466             event_name = objects.InstanceExternalEvent.make_key(name, tag)
467             try:
468                 events[event_name] = (
469                     self._compute.instance_events.prepare_for_instance_event(
470                         instance, name, tag))
471             except exception.NovaException:
472                 error_callback(event_name, instance)
473                 # NOTE(danms): Don't wait for any of the events. They
474                 # should all be canceled and fired immediately below,
475                 # but don't stick around if not.
476                 deadline = 0
477         yield
478         with eventlet.timeout.Timeout(deadline):
479             for event_name, event in events.items():
480                 actual_event = event.wait()
481                 if actual_event.status == 'completed':
482                     continue
483                 decision = error_callback(event_name, instance)
484                 if decision is False:
485                     break
486 
487 
488 class ComputeManager(manager.Manager):
489     """Manages the running instances from creation to destruction."""
490 
491     target = messaging.Target(version='5.0')
492 
493     def __init__(self, compute_driver=None, *args, **kwargs):
494         """Load configuration options and connect to the hypervisor."""
495         self.virtapi = ComputeVirtAPI(self)
496         self.network_api = network.API()
497         self.volume_api = cinder.API()
498         self.image_api = image.API()
499         self._last_host_check = 0
500         self._last_bw_usage_poll = 0
501         self._bw_usage_supported = True
502         self._last_bw_usage_cell_update = 0
503         self.compute_api = compute.API()
504         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
505         self.conductor_api = conductor.API()
506         self.compute_task_api = conductor.ComputeTaskAPI()
507         self.is_neutron_security_groups = (
508             openstack_driver.is_neutron_security_groups())
509         self.cells_rpcapi = cells_rpcapi.CellsAPI()
510         self.scheduler_client = scheduler_client.SchedulerClient()
511         self.reportclient = self.scheduler_client.reportclient
512         self._resource_tracker = None
513         self.instance_events = InstanceEvents()
514         self._sync_power_pool = eventlet.GreenPool(
515             size=CONF.sync_power_state_pool_size)
516         self._syncs_in_progress = {}
517         self.send_instance_updates = (
518             CONF.filter_scheduler.track_instance_changes)
519         if CONF.max_concurrent_builds != 0:
520             self._build_semaphore = eventlet.semaphore.Semaphore(
521                 CONF.max_concurrent_builds)
522         else:
523             self._build_semaphore = compute_utils.UnlimitedSemaphore()
524         if max(CONF.max_concurrent_live_migrations, 0) != 0:
525             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
526                 CONF.max_concurrent_live_migrations)
527         else:
528             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
529         self._failed_builds = 0
530 
531         super(ComputeManager, self).__init__(service_name="compute",
532                                              *args, **kwargs)
533 
534         # NOTE(russellb) Load the driver last.  It may call back into the
535         # compute manager via the virtapi, so we want it to be fully
536         # initialized before that happens.
537         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
538         self.use_legacy_block_device_info = \
539                             self.driver.need_legacy_block_device_info
540 
541     def reset(self):
542         LOG.info('Reloading compute RPC API')
543         compute_rpcapi.LAST_VERSION = None
544         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
545 
546     def _get_resource_tracker(self):
547         if not self._resource_tracker:
548             rt = resource_tracker.ResourceTracker(self.host, self.driver)
549             self._resource_tracker = rt
550         return self._resource_tracker
551 
552     def _update_resource_tracker(self, context, instance):
553         """Let the resource tracker know that an instance has changed state."""
554 
555         if instance.host == self.host:
556             rt = self._get_resource_tracker()
557             rt.update_usage(context, instance, instance.node)
558 
559     def _instance_update(self, context, instance, **kwargs):
560         """Update an instance in the database using kwargs as value."""
561 
562         for k, v in kwargs.items():
563             setattr(instance, k, v)
564         instance.save()
565         self._update_resource_tracker(context, instance)
566 
567     def _nil_out_instance_obj_host_and_node(self, instance):
568         # NOTE(jwcroppe): We don't do instance.save() here for performance
569         # reasons; a call to this is expected to be immediately followed by
570         # another call that does instance.save(), thus avoiding two writes
571         # to the database layer.
572         instance.host = None
573         instance.node = None
574 
575     def _set_instance_obj_error_state(self, context, instance,
576                                       clean_task_state=False):
577         try:
578             instance.vm_state = vm_states.ERROR
579             if clean_task_state:
580                 instance.task_state = None
581             instance.save()
582         except exception.InstanceNotFound:
583             LOG.debug('Instance has been destroyed from under us while '
584                       'trying to set it to ERROR', instance=instance)
585 
586     def _get_instances_on_driver(self, context, filters=None):
587         """Return a list of instance records for the instances found
588         on the hypervisor which satisfy the specified filters. If filters=None
589         return a list of instance records for all the instances found on the
590         hypervisor.
591         """
592         if not filters:
593             filters = {}
594         try:
595             driver_uuids = self.driver.list_instance_uuids()
596             if len(driver_uuids) == 0:
597                 # Short circuit, don't waste a DB call
598                 return objects.InstanceList()
599             filters['uuid'] = driver_uuids
600             local_instances = objects.InstanceList.get_by_filters(
601                 context, filters, use_slave=True)
602             return local_instances
603         except NotImplementedError:
604             pass
605 
606         # The driver doesn't support uuids listing, so we'll have
607         # to brute force.
608         driver_instances = self.driver.list_instances()
609         # NOTE(mjozefcz): In this case we need to apply host filter.
610         # Without this all instance data would be fetched from db.
611         filters['host'] = self.host
612         instances = objects.InstanceList.get_by_filters(context, filters,
613                                                         use_slave=True)
614         name_map = {instance.name: instance for instance in instances}
615         local_instances = []
616         for driver_instance in driver_instances:
617             instance = name_map.get(driver_instance)
618             if not instance:
619                 continue
620             local_instances.append(instance)
621         return local_instances
622 
623     def _destroy_evacuated_instances(self, context):
624         """Destroys evacuated instances.
625 
626         While nova-compute was down, the instances running on it could be
627         evacuated to another host. This method looks for evacuation migration
628         records where this is the source host and which were either started
629         (accepted) or complete (done). From those migration records, local
630         instances reported by the hypervisor are compared to the instances
631         for the migration records and those local guests are destroyed, along
632         with instance allocation records in Placement for this node.
633         """
634         filters = {
635             'source_compute': self.host,
636             # NOTE(mriedem): Migration records that have been accepted are
637             # included in case the source node comes back up while instances
638             # are being evacuated to another host. We don't want the same
639             # instance being reported from multiple hosts.
640             'status': ['accepted', 'done'],
641             'migration_type': 'evacuation',
642         }
643         with utils.temporary_mutation(context, read_deleted='yes'):
644             evacuations = objects.MigrationList.get_by_filters(context,
645                                                                filters)
646         if not evacuations:
647             return
648         evacuations = {mig.instance_uuid: mig for mig in evacuations}
649 
650         local_instances = self._get_instances_on_driver(context)
651         evacuated = [inst for inst in local_instances
652                      if inst.uuid in evacuations]
653 
654         # NOTE(gibi): We are called from init_host and at this point the
655         # compute_nodes of the resource tracker has not been populated yet so
656         # we cannot rely on the resource tracker here.
657         compute_nodes = {}
658 
659         for instance in evacuated:
660             migration = evacuations[instance.uuid]
661             LOG.info('Deleting instance as it has been evacuated from '
662                      'this host', instance=instance)
663             try:
664                 network_info = self.network_api.get_instance_nw_info(
665                     context, instance)
666                 bdi = self._get_instance_block_device_info(context,
667                                                            instance)
668                 destroy_disks = not (self._is_instance_storage_shared(
669                     context, instance))
670             except exception.InstanceNotFound:
671                 network_info = network_model.NetworkInfo()
672                 bdi = {}
673                 LOG.info('Instance has been marked deleted already, '
674                          'removing it from the hypervisor.',
675                          instance=instance)
676                 # always destroy disks if the instance was deleted
677                 destroy_disks = True
678             self.driver.destroy(context, instance,
679                                 network_info,
680                                 bdi, destroy_disks)
681 
682             # delete the allocation of the evacuated instance from this host
683             if migration.source_node not in compute_nodes:
684                 try:
685                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
686                         context, self.host, migration.source_node).uuid
687                     compute_nodes[migration.source_node] = cn_uuid
688                 except exception.ComputeHostNotFound:
689                     LOG.error("Failed to clean allocation of evacuated "
690                               "instance as the source node %s is not found",
691                               migration.source_node, instance=instance)
692                     continue
693             cn_uuid = compute_nodes[migration.source_node]
694 
695             if not scheduler_utils.remove_allocation_from_compute(
696                     context, instance, cn_uuid, self.reportclient):
697                 LOG.error("Failed to clean allocation of evacuated instance "
698                           "on the source node %s",
699                           cn_uuid, instance=instance)
700 
701             migration.status = 'completed'
702             migration.save()
703 
704     def _is_instance_storage_shared(self, context, instance, host=None):
705         shared_storage = True
706         data = None
707         try:
708             data = self.driver.check_instance_shared_storage_local(context,
709                                                        instance)
710             if data:
711                 shared_storage = (self.compute_rpcapi.
712                                   check_instance_shared_storage(context,
713                                   instance, data, host=host))
714         except NotImplementedError:
715             LOG.debug('Hypervisor driver does not support '
716                       'instance shared storage check, '
717                       'assuming it\'s not on shared storage',
718                       instance=instance)
719             shared_storage = False
720         except Exception:
721             LOG.exception('Failed to check if instance shared',
722                           instance=instance)
723         finally:
724             if data:
725                 self.driver.check_instance_shared_storage_cleanup(context,
726                                                                   data)
727         return shared_storage
728 
729     def _complete_partial_deletion(self, context, instance):
730         """Complete deletion for instances in DELETED status but not marked as
731         deleted in the DB
732         """
733         system_meta = instance.system_metadata
734         instance.destroy()
735         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
736                 context, instance.uuid)
737         self._complete_deletion(context,
738                                 instance,
739                                 bdms,
740                                 system_meta)
741 
742     def _complete_deletion(self, context, instance, bdms,
743                            system_meta):
744         self._update_resource_tracker(context, instance)
745 
746         rt = self._get_resource_tracker()
747         rt.reportclient.delete_allocation_for_instance(context, instance.uuid)
748 
749         self._notify_about_instance_usage(context, instance, "delete.end",
750                 system_metadata=system_meta)
751         compute_utils.notify_about_instance_action(context, instance,
752                 self.host, action=fields.NotificationAction.DELETE,
753                 phase=fields.NotificationPhase.END, bdms=bdms)
754         self._delete_scheduler_instance_info(context, instance.uuid)
755 
756     def _init_instance(self, context, instance):
757         """Initialize this instance during service init."""
758 
759         # NOTE(danms): If the instance appears to not be owned by this
760         # host, it may have been evacuated away, but skipped by the
761         # evacuation cleanup code due to configuration. Thus, if that
762         # is a possibility, don't touch the instance in any way, but
763         # log the concern. This will help avoid potential issues on
764         # startup due to misconfiguration.
765         if instance.host != self.host:
766             LOG.warning('Instance %(uuid)s appears to not be owned '
767                         'by this host, but by %(host)s. Startup '
768                         'processing is being skipped.',
769                         {'uuid': instance.uuid,
770                          'host': instance.host})
771             return
772 
773         # Instances that are shut down, or in an error state can not be
774         # initialized and are not attempted to be recovered. The exception
775         # to this are instances that are in RESIZE_MIGRATING or DELETING,
776         # which are dealt with further down.
777         if (instance.vm_state == vm_states.SOFT_DELETED or
778             (instance.vm_state == vm_states.ERROR and
779             instance.task_state not in
780             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
781             LOG.debug("Instance is in %s state.",
782                       instance.vm_state, instance=instance)
783             return
784 
785         if instance.vm_state == vm_states.DELETED:
786             try:
787                 self._complete_partial_deletion(context, instance)
788             except Exception:
789                 # we don't want that an exception blocks the init_host
790                 LOG.exception('Failed to complete a deletion',
791                               instance=instance)
792             return
793 
794         if (instance.vm_state == vm_states.BUILDING or
795             instance.task_state in [task_states.SCHEDULING,
796                                     task_states.BLOCK_DEVICE_MAPPING,
797                                     task_states.NETWORKING,
798                                     task_states.SPAWNING]):
799             # NOTE(dave-mcnally) compute stopped before instance was fully
800             # spawned so set to ERROR state. This is safe to do as the state
801             # may be set by the api but the host is not so if we get here the
802             # instance has already been scheduled to this particular host.
803             LOG.debug("Instance failed to spawn correctly, "
804                       "setting to ERROR state", instance=instance)
805             instance.task_state = None
806             instance.vm_state = vm_states.ERROR
807             instance.save()
808             return
809 
810         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
811             instance.task_state in [task_states.REBUILDING,
812                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
813                                     task_states.REBUILD_SPAWNING]):
814             # NOTE(jichenjc) compute stopped before instance was fully
815             # spawned so set to ERROR state. This is consistent to BUILD
816             LOG.debug("Instance failed to rebuild correctly, "
817                       "setting to ERROR state", instance=instance)
818             instance.task_state = None
819             instance.vm_state = vm_states.ERROR
820             instance.save()
821             return
822 
823         if (instance.vm_state != vm_states.ERROR and
824             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
825                                     task_states.IMAGE_PENDING_UPLOAD,
826                                     task_states.IMAGE_UPLOADING,
827                                     task_states.IMAGE_SNAPSHOT]):
828             LOG.debug("Instance in transitional state %s at start-up "
829                       "clearing task state",
830                       instance.task_state, instance=instance)
831             try:
832                 self._post_interrupted_snapshot_cleanup(context, instance)
833             except Exception:
834                 # we don't want that an exception blocks the init_host
835                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
836             instance.task_state = None
837             instance.save()
838 
839         if (instance.vm_state != vm_states.ERROR and
840             instance.task_state in [task_states.RESIZE_PREP]):
841             LOG.debug("Instance in transitional state %s at start-up "
842                       "clearing task state",
843                       instance['task_state'], instance=instance)
844             instance.task_state = None
845             instance.save()
846 
847         if instance.task_state == task_states.DELETING:
848             try:
849                 LOG.info('Service started deleting the instance during '
850                          'the previous run, but did not finish. Restarting'
851                          ' the deletion now.', instance=instance)
852                 instance.obj_load_attr('metadata')
853                 instance.obj_load_attr('system_metadata')
854                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
855                         context, instance.uuid)
856                 self._delete_instance(context, instance, bdms)
857             except Exception:
858                 # we don't want that an exception blocks the init_host
859                 LOG.exception('Failed to complete a deletion',
860                               instance=instance)
861                 self._set_instance_obj_error_state(context, instance)
862             return
863 
864         current_power_state = self._get_power_state(context, instance)
865         try_reboot, reboot_type = self._retry_reboot(context, instance,
866                                                      current_power_state)
867 
868         if try_reboot:
869             LOG.debug("Instance in transitional state (%(task_state)s) at "
870                       "start-up and power state is (%(power_state)s), "
871                       "triggering reboot",
872                       {'task_state': instance.task_state,
873                        'power_state': current_power_state},
874                       instance=instance)
875 
876             # NOTE(mikal): if the instance was doing a soft reboot that got as
877             # far as shutting down the instance but not as far as starting it
878             # again, then we've just become a hard reboot. That means the
879             # task state for the instance needs to change so that we're in one
880             # of the expected task states for a hard reboot.
881             if (instance.task_state in task_states.soft_reboot_states and
882                 reboot_type == 'HARD'):
883                 instance.task_state = task_states.REBOOT_PENDING_HARD
884                 instance.save()
885 
886             self.reboot_instance(context, instance, block_device_info=None,
887                                  reboot_type=reboot_type)
888             return
889 
890         elif (current_power_state == power_state.RUNNING and
891               instance.task_state in [task_states.REBOOT_STARTED,
892                                       task_states.REBOOT_STARTED_HARD,
893                                       task_states.PAUSING,
894                                       task_states.UNPAUSING]):
895             LOG.warning("Instance in transitional state "
896                         "(%(task_state)s) at start-up and power state "
897                         "is (%(power_state)s), clearing task state",
898                         {'task_state': instance.task_state,
899                          'power_state': current_power_state},
900                         instance=instance)
901             instance.task_state = None
902             instance.vm_state = vm_states.ACTIVE
903             instance.save()
904         elif (current_power_state == power_state.PAUSED and
905               instance.task_state == task_states.UNPAUSING):
906             LOG.warning("Instance in transitional state "
907                         "(%(task_state)s) at start-up and power state "
908                         "is (%(power_state)s), clearing task state "
909                         "and unpausing the instance",
910                         {'task_state': instance.task_state,
911                          'power_state': current_power_state},
912                         instance=instance)
913             try:
914                 self.unpause_instance(context, instance)
915             except NotImplementedError:
916                 # Some virt driver didn't support pause and unpause
917                 pass
918             except Exception:
919                 LOG.exception('Failed to unpause instance', instance=instance)
920             return
921 
922         if instance.task_state == task_states.POWERING_OFF:
923             try:
924                 LOG.debug("Instance in transitional state %s at start-up "
925                           "retrying stop request",
926                           instance.task_state, instance=instance)
927                 self.stop_instance(context, instance, True)
928             except Exception:
929                 # we don't want that an exception blocks the init_host
930                 LOG.exception('Failed to stop instance', instance=instance)
931             return
932 
933         if instance.task_state == task_states.POWERING_ON:
934             try:
935                 LOG.debug("Instance in transitional state %s at start-up "
936                           "retrying start request",
937                           instance.task_state, instance=instance)
938                 self.start_instance(context, instance)
939             except Exception:
940                 # we don't want that an exception blocks the init_host
941                 LOG.exception('Failed to start instance', instance=instance)
942             return
943 
944         net_info = instance.get_network_info()
945         try:
946             self.driver.plug_vifs(instance, net_info)
947         except NotImplementedError as e:
948             LOG.debug(e, instance=instance)
949         except exception.VirtualInterfacePlugException:
950             # we don't want an exception to block the init_host
951             LOG.exception("Vifs plug failed", instance=instance)
952             self._set_instance_obj_error_state(context, instance)
953             return
954 
955         if instance.task_state == task_states.RESIZE_MIGRATING:
956             # We crashed during resize/migration, so roll back for safety
957             try:
958                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
959                 # not in system_metadata we default to True for backwards
960                 # compatibility
961                 power_on = (instance.system_metadata.get('old_vm_state') !=
962                             vm_states.STOPPED)
963 
964                 block_dev_info = self._get_instance_block_device_info(context,
965                                                                       instance)
966 
967                 self.driver.finish_revert_migration(context,
968                     instance, net_info, block_dev_info, power_on)
969 
970             except Exception:
971                 LOG.exception('Failed to revert crashed migration',
972                               instance=instance)
973             finally:
974                 LOG.info('Instance found in migrating state during '
975                          'startup. Resetting task_state',
976                          instance=instance)
977                 instance.task_state = None
978                 instance.save()
979         if instance.task_state == task_states.MIGRATING:
980             # Live migration did not complete, but instance is on this
981             # host, so reset the state.
982             instance.task_state = None
983             instance.save(expected_task_state=[task_states.MIGRATING])
984 
985         db_state = instance.power_state
986         drv_state = self._get_power_state(context, instance)
987         expect_running = (db_state == power_state.RUNNING and
988                           drv_state != db_state)
989 
990         LOG.debug('Current state is %(drv_state)s, state in DB is '
991                   '%(db_state)s.',
992                   {'drv_state': drv_state, 'db_state': db_state},
993                   instance=instance)
994 
995         if expect_running and CONF.resume_guests_state_on_host_boot:
996             self._resume_guests_state(context, instance, net_info)
997         elif drv_state == power_state.RUNNING:
998             # VMwareAPI drivers will raise an exception
999             try:
1000                 self.driver.ensure_filtering_rules_for_instance(
1001                                        instance, net_info)
1002             except NotImplementedError:
1003                 LOG.debug('Hypervisor driver does not support '
1004                           'firewall rules', instance=instance)
1005 
1006     def _resume_guests_state(self, context, instance, net_info):
1007         LOG.info('Rebooting instance after nova-compute restart.',
1008                  instance=instance)
1009         block_device_info = \
1010             self._get_instance_block_device_info(context, instance)
1011 
1012         try:
1013             self.driver.resume_state_on_host_boot(
1014                 context, instance, net_info, block_device_info)
1015         except NotImplementedError:
1016             LOG.warning('Hypervisor driver does not support '
1017                         'resume guests', instance=instance)
1018         except Exception:
1019             # NOTE(vish): The instance failed to resume, so we set the
1020             #             instance to error and attempt to continue.
1021             LOG.warning('Failed to resume instance',
1022                         instance=instance)
1023             self._set_instance_obj_error_state(context, instance)
1024 
1025     def _retry_reboot(self, context, instance, current_power_state):
1026         current_task_state = instance.task_state
1027         retry_reboot = False
1028         reboot_type = compute_utils.get_reboot_type(current_task_state,
1029                                                     current_power_state)
1030 
1031         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1032                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1033         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1034                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1035         started_not_running = (current_task_state in
1036                                [task_states.REBOOT_STARTED,
1037                                 task_states.REBOOT_STARTED_HARD] and
1038                                current_power_state != power_state.RUNNING)
1039 
1040         if pending_soft or pending_hard or started_not_running:
1041             retry_reboot = True
1042 
1043         return retry_reboot, reboot_type
1044 
1045     def handle_lifecycle_event(self, event):
1046         LOG.info("VM %(state)s (Lifecycle Event)",
1047                  {'state': event.get_name()},
1048                  instance_uuid=event.get_instance_uuid())
1049         context = nova.context.get_admin_context(read_deleted='yes')
1050         instance = objects.Instance.get_by_uuid(context,
1051                                                 event.get_instance_uuid(),
1052                                                 expected_attrs=[])
1053         vm_power_state = None
1054         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1055             vm_power_state = power_state.SHUTDOWN
1056         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1057             vm_power_state = power_state.RUNNING
1058         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1059             vm_power_state = power_state.PAUSED
1060         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1061             vm_power_state = power_state.RUNNING
1062         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1063             vm_power_state = power_state.SUSPENDED
1064         else:
1065             LOG.warning("Unexpected power state %d", event.get_transition())
1066 
1067         # Note(lpetrut): The event may be delayed, thus not reflecting
1068         # the current instance power state. In that case, ignore the event.
1069         current_power_state = self._get_power_state(context, instance)
1070         if current_power_state == vm_power_state:
1071             LOG.debug('Synchronizing instance power state after lifecycle '
1072                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1073                       'current task_state: %(task_state)s, current DB '
1074                       'power_state: %(db_power_state)s, VM power_state: '
1075                       '%(vm_power_state)s',
1076                       {'event': event.get_name(),
1077                        'vm_state': instance.vm_state,
1078                        'task_state': instance.task_state,
1079                        'db_power_state': instance.power_state,
1080                        'vm_power_state': vm_power_state},
1081                       instance_uuid=instance.uuid)
1082             self._sync_instance_power_state(context,
1083                                             instance,
1084                                             vm_power_state)
1085 
1086     def handle_events(self, event):
1087         if isinstance(event, virtevent.LifecycleEvent):
1088             try:
1089                 self.handle_lifecycle_event(event)
1090             except exception.InstanceNotFound:
1091                 LOG.debug("Event %s arrived for non-existent instance. The "
1092                           "instance was probably deleted.", event)
1093         else:
1094             LOG.debug("Ignoring event %s", event)
1095 
1096     def init_virt_events(self):
1097         if CONF.workarounds.handle_virt_lifecycle_events:
1098             self.driver.register_event_listener(self.handle_events)
1099         else:
1100             # NOTE(mriedem): If the _sync_power_states periodic task is
1101             # disabled we should emit a warning in the logs.
1102             if CONF.sync_power_state_interval < 0:
1103                 LOG.warning('Instance lifecycle events from the compute '
1104                             'driver have been disabled. Note that lifecycle '
1105                             'changes to an instance outside of the compute '
1106                             'service will not be synchronized '
1107                             'automatically since the _sync_power_states '
1108                             'periodic task is also disabled.')
1109             else:
1110                 LOG.info('Instance lifecycle events from the compute '
1111                          'driver have been disabled. Note that lifecycle '
1112                          'changes to an instance outside of the compute '
1113                          'service will only be synchronized by the '
1114                          '_sync_power_states periodic task.')
1115 
1116     def init_host(self):
1117         """Initialization for a standalone compute service."""
1118 
1119         if CONF.pci.passthrough_whitelist:
1120             # Simply loading the PCI passthrough whitelist will do a bunch of
1121             # validation that would otherwise wait until the PciDevTracker is
1122             # constructed when updating available resources for the compute
1123             # node(s) in the resource tracker, effectively killing that task.
1124             # So load up the whitelist when starting the compute service to
1125             # flush any invalid configuration early so we can kill the service
1126             # if the configuration is wrong.
1127             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1128 
1129         self.driver.init_host(host=self.host)
1130         context = nova.context.get_admin_context()
1131         instances = objects.InstanceList.get_by_host(
1132             context, self.host, expected_attrs=['info_cache', 'metadata'])
1133 
1134         if CONF.defer_iptables_apply:
1135             self.driver.filter_defer_apply_on()
1136 
1137         self.init_virt_events()
1138 
1139         try:
1140             # checking that instance was not already evacuated to other host
1141             self._destroy_evacuated_instances(context)
1142             for instance in instances:
1143                 self._init_instance(context, instance)
1144         finally:
1145             if CONF.defer_iptables_apply:
1146                 self.driver.filter_defer_apply_off()
1147             if instances:
1148                 # We only send the instance info to the scheduler on startup
1149                 # if there is anything to send, otherwise this host might
1150                 # not be mapped yet in a cell and the scheduler may have
1151                 # issues dealing with the information. Later changes to
1152                 # instances on this host will update the scheduler, or the
1153                 # _sync_scheduler_instance_info periodic task will.
1154                 self._update_scheduler_instance_info(context, instances)
1155 
1156     def cleanup_host(self):
1157         self.driver.register_event_listener(None)
1158         self.instance_events.cancel_all_events()
1159         self.driver.cleanup_host(host=self.host)
1160 
1161     def pre_start_hook(self):
1162         """After the service is initialized, but before we fully bring
1163         the service up by listening on RPC queues, make sure to update
1164         our available resources (and indirectly our available nodes).
1165         """
1166         self.update_available_resource(nova.context.get_admin_context(),
1167                                        startup=True)
1168 
1169     def _get_power_state(self, context, instance):
1170         """Retrieve the power state for the given instance."""
1171         LOG.debug('Checking state', instance=instance)
1172         try:
1173             return self.driver.get_info(instance).state
1174         except exception.InstanceNotFound:
1175             return power_state.NOSTATE
1176 
1177     def get_console_topic(self, context):
1178         """Retrieves the console host for a project on this host.
1179 
1180         Currently this is just set in the flags for each compute host.
1181 
1182         """
1183         # TODO(mdragon): perhaps make this variable by console_type?
1184         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1185 
1186     @wrap_exception()
1187     def get_console_pool_info(self, context, console_type):
1188         return self.driver.get_console_pool_info(console_type)
1189 
1190     @wrap_exception()
1191     def refresh_instance_security_rules(self, context, instance):
1192         """Tell the virtualization driver to refresh security rules for
1193         an instance.
1194 
1195         Passes straight through to the virtualization driver.
1196 
1197         Synchronize the call because we may still be in the middle of
1198         creating the instance.
1199         """
1200         @utils.synchronized(instance.uuid)
1201         def _sync_refresh():
1202             try:
1203                 return self.driver.refresh_instance_security_rules(instance)
1204             except NotImplementedError:
1205                 LOG.debug('Hypervisor driver does not support '
1206                           'security groups.', instance=instance)
1207 
1208         return _sync_refresh()
1209 
1210     def _await_block_device_map_created(self, context, vol_id):
1211         # TODO(yamahata): creating volume simultaneously
1212         #                 reduces creation time?
1213         # TODO(yamahata): eliminate dumb polling
1214         start = time.time()
1215         retries = CONF.block_device_allocate_retries
1216         if retries < 0:
1217             LOG.warning("Treating negative config value (%(retries)s) for "
1218                         "'block_device_retries' as 0.",
1219                         {'retries': retries})
1220         # (1) treat  negative config value as 0
1221         # (2) the configured value is 0, one attempt should be made
1222         # (3) the configured value is > 0, then the total number attempts
1223         #      is (retries + 1)
1224         attempts = 1
1225         if retries >= 1:
1226             attempts = retries + 1
1227         for attempt in range(1, attempts + 1):
1228             volume = self.volume_api.get(context, vol_id)
1229             volume_status = volume['status']
1230             if volume_status not in ['creating', 'downloading']:
1231                 if volume_status == 'available':
1232                     return attempt
1233                 LOG.warning("Volume id: %(vol_id)s finished being "
1234                             "created but its status is %(vol_status)s.",
1235                             {'vol_id': vol_id,
1236                              'vol_status': volume_status})
1237                 break
1238             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1239         raise exception.VolumeNotCreated(volume_id=vol_id,
1240                                          seconds=int(time.time() - start),
1241                                          attempts=attempt,
1242                                          volume_status=volume_status)
1243 
1244     def _decode_files(self, injected_files):
1245         """Base64 decode the list of files to inject."""
1246         if not injected_files:
1247             return []
1248 
1249         def _decode(f):
1250             path, contents = f
1251             # Py3 raises binascii.Error instead of TypeError as in Py27
1252             try:
1253                 decoded = base64.b64decode(contents)
1254                 return path, decoded
1255             except (TypeError, binascii.Error):
1256                 raise exception.Base64Exception(path=path)
1257 
1258         return [_decode(f) for f in injected_files]
1259 
1260     def _validate_instance_group_policy(self, context, instance,
1261                                         scheduler_hints):
1262         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1263         # However, there is a race condition with the enforcement of
1264         # the policy.  Since more than one instance may be scheduled at the
1265         # same time, it's possible that more than one instance with an
1266         # anti-affinity policy may end up here.  It's also possible that
1267         # multiple instances with an affinity policy could end up on different
1268         # hosts.  This is a validation step to make sure that starting the
1269         # instance here doesn't violate the policy.
1270         group_hint = scheduler_hints.get('group')
1271         if not group_hint:
1272             return
1273 
1274         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1275         # to check the type on the value and pull the single entry out. The
1276         # API request schema validates that the 'group' hint is a single value.
1277         if isinstance(group_hint, list):
1278             group_hint = group_hint[0]
1279 
1280         @utils.synchronized(group_hint)
1281         def _do_validation(context, instance, group_hint):
1282             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1283             if 'anti-affinity' in group.policies:
1284                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1285                 if self.host in group_hosts:
1286                     msg = _("Anti-affinity instance group policy "
1287                             "was violated.")
1288                     raise exception.RescheduledException(
1289                             instance_uuid=instance.uuid,
1290                             reason=msg)
1291             elif 'affinity' in group.policies:
1292                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1293                 if group_hosts and self.host not in group_hosts:
1294                     msg = _("Affinity instance group policy was violated.")
1295                     raise exception.RescheduledException(
1296                             instance_uuid=instance.uuid,
1297                             reason=msg)
1298 
1299         if not CONF.workarounds.disable_group_policy_check_upcall:
1300             _do_validation(context, instance, group_hint)
1301 
1302     def _log_original_error(self, exc_info, instance_uuid):
1303         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1304                   exc_info=exc_info)
1305 
1306     def _reschedule(self, context, request_spec, filter_properties,
1307             instance, reschedule_method, method_args, task_state,
1308             exc_info=None, host_list=None):
1309         """Attempt to re-schedule a compute operation."""
1310 
1311         instance_uuid = instance.uuid
1312         retry = filter_properties.get('retry')
1313         if not retry:
1314             # no retry information, do not reschedule.
1315             LOG.debug("Retry info not present, will not reschedule",
1316                       instance_uuid=instance_uuid)
1317             return
1318 
1319         if not request_spec:
1320             LOG.debug("No request spec, will not reschedule",
1321                       instance_uuid=instance_uuid)
1322             return
1323 
1324         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1325                   {'method': reschedule_method.__name__,
1326                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1327 
1328         # reset the task state:
1329         self._instance_update(context, instance, task_state=task_state)
1330 
1331         if exc_info:
1332             # stringify to avoid circular ref problem in json serialization:
1333             retry['exc'] = traceback.format_exception_only(exc_info[0],
1334                                     exc_info[1])
1335 
1336         reschedule_method(context, *method_args, host_list=host_list)
1337         return True
1338 
1339     @periodic_task.periodic_task
1340     def _check_instance_build_time(self, context):
1341         """Ensure that instances are not stuck in build."""
1342         timeout = CONF.instance_build_timeout
1343         if timeout == 0:
1344             return
1345 
1346         filters = {'vm_state': vm_states.BUILDING,
1347                    'host': self.host}
1348 
1349         building_insts = objects.InstanceList.get_by_filters(context,
1350                            filters, expected_attrs=[], use_slave=True)
1351 
1352         for instance in building_insts:
1353             if timeutils.is_older_than(instance.created_at, timeout):
1354                 self._set_instance_obj_error_state(context, instance)
1355                 LOG.warning("Instance build timed out. Set to error "
1356                             "state.", instance=instance)
1357 
1358     def _check_instance_exists(self, context, instance):
1359         """Ensure an instance with the same name is not already present."""
1360         if self.driver.instance_exists(instance):
1361             raise exception.InstanceExists(name=instance.name)
1362 
1363     def _allocate_network_async(self, context, instance, requested_networks,
1364                                 macs, security_groups, is_vpn):
1365         """Method used to allocate networks in the background.
1366 
1367         Broken out for testing.
1368         """
1369         # First check to see if we're specifically not supposed to allocate
1370         # networks because if so, we can exit early.
1371         if requested_networks and requested_networks.no_allocate:
1372             LOG.debug("Not allocating networking since 'none' was specified.",
1373                       instance=instance)
1374             return network_model.NetworkInfo([])
1375 
1376         LOG.debug("Allocating IP information in the background.",
1377                   instance=instance)
1378         retries = CONF.network_allocate_retries
1379         attempts = retries + 1
1380         retry_time = 1
1381         bind_host_id = self.driver.network_binding_host_id(context, instance)
1382         for attempt in range(1, attempts + 1):
1383             try:
1384                 nwinfo = self.network_api.allocate_for_instance(
1385                         context, instance, vpn=is_vpn,
1386                         requested_networks=requested_networks,
1387                         macs=macs,
1388                         security_groups=security_groups,
1389                         bind_host_id=bind_host_id)
1390                 LOG.debug('Instance network_info: |%s|', nwinfo,
1391                           instance=instance)
1392                 instance.system_metadata['network_allocated'] = 'True'
1393                 # NOTE(JoshNang) do not save the instance here, as it can cause
1394                 # races. The caller shares a reference to instance and waits
1395                 # for this async greenthread to finish before calling
1396                 # instance.save().
1397                 return nwinfo
1398             except Exception:
1399                 exc_info = sys.exc_info()
1400                 log_info = {'attempt': attempt,
1401                             'attempts': attempts}
1402                 if attempt == attempts:
1403                     LOG.exception('Instance failed network setup '
1404                                   'after %(attempts)d attempt(s)',
1405                                   log_info)
1406                     six.reraise(*exc_info)
1407                 LOG.warning('Instance failed network setup '
1408                             '(attempt %(attempt)d of %(attempts)d)',
1409                             log_info, instance=instance)
1410                 time.sleep(retry_time)
1411                 retry_time *= 2
1412                 if retry_time > 30:
1413                     retry_time = 30
1414         # Not reached.
1415 
1416     def _build_networks_for_instance(self, context, instance,
1417             requested_networks, security_groups):
1418 
1419         # If we're here from a reschedule the network may already be allocated.
1420         if strutils.bool_from_string(
1421                 instance.system_metadata.get('network_allocated', 'False')):
1422             # NOTE(alex_xu): The network_allocated is True means the network
1423             # resource already allocated at previous scheduling, and the
1424             # network setup is cleanup at previous. After rescheduling, the
1425             # network resource need setup on the new host.
1426             self.network_api.setup_instance_network_on_host(
1427                 context, instance, instance.host)
1428             return self.network_api.get_instance_nw_info(context, instance)
1429 
1430         if not self.is_neutron_security_groups:
1431             security_groups = []
1432 
1433         macs = self.driver.macs_for_instance(instance)
1434         network_info = self._allocate_network(context, instance,
1435                 requested_networks, macs, security_groups)
1436 
1437         return network_info
1438 
1439     def _allocate_network(self, context, instance, requested_networks, macs,
1440                           security_groups):
1441         """Start network allocation asynchronously.  Return an instance
1442         of NetworkInfoAsyncWrapper that can be used to retrieve the
1443         allocated networks when the operation has finished.
1444         """
1445         # NOTE(comstud): Since we're allocating networks asynchronously,
1446         # this task state has little meaning, as we won't be in this
1447         # state for very long.
1448         instance.vm_state = vm_states.BUILDING
1449         instance.task_state = task_states.NETWORKING
1450         instance.save(expected_task_state=[None])
1451 
1452         is_vpn = False
1453         return network_model.NetworkInfoAsyncWrapper(
1454                 self._allocate_network_async, context, instance,
1455                 requested_networks, macs, security_groups, is_vpn)
1456 
1457     def _default_root_device_name(self, instance, image_meta, root_bdm):
1458         try:
1459             return self.driver.default_root_device_name(instance,
1460                                                         image_meta,
1461                                                         root_bdm)
1462         except NotImplementedError:
1463             return compute_utils.get_next_device_name(instance, [])
1464 
1465     def _default_device_names_for_instance(self, instance,
1466                                            root_device_name,
1467                                            *block_device_lists):
1468         try:
1469             self.driver.default_device_names_for_instance(instance,
1470                                                           root_device_name,
1471                                                           *block_device_lists)
1472         except NotImplementedError:
1473             compute_utils.default_device_names_for_instance(
1474                 instance, root_device_name, *block_device_lists)
1475 
1476     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1477         # NOTE(ndipanov): Copy obj to avoid changing the original
1478         block_device_obj = block_device_obj.obj_clone()
1479         try:
1480             return self.driver.get_device_name_for_instance(
1481                 instance, bdms, block_device_obj)
1482         except NotImplementedError:
1483             return compute_utils.get_device_name_for_instance(
1484                 instance, bdms, block_device_obj.get("device_name"))
1485 
1486     def _default_block_device_names(self, instance, image_meta, block_devices):
1487         """Verify that all the devices have the device_name set. If not,
1488         provide a default name.
1489 
1490         It also ensures that there is a root_device_name and is set to the
1491         first block device in the boot sequence (boot_index=0).
1492         """
1493         root_bdm = block_device.get_root_bdm(block_devices)
1494         if not root_bdm:
1495             return
1496 
1497         # Get the root_device_name from the root BDM or the instance
1498         root_device_name = None
1499         update_root_bdm = False
1500 
1501         if root_bdm.device_name:
1502             root_device_name = root_bdm.device_name
1503             instance.root_device_name = root_device_name
1504         elif instance.root_device_name:
1505             root_device_name = instance.root_device_name
1506             root_bdm.device_name = root_device_name
1507             update_root_bdm = True
1508         else:
1509             root_device_name = self._default_root_device_name(instance,
1510                                                               image_meta,
1511                                                               root_bdm)
1512 
1513             instance.root_device_name = root_device_name
1514             root_bdm.device_name = root_device_name
1515             update_root_bdm = True
1516 
1517         if update_root_bdm:
1518             root_bdm.save()
1519 
1520         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1521                             block_devices))
1522         swap = list(filter(block_device.new_format_is_swap,
1523                       block_devices))
1524         block_device_mapping = list(filter(
1525               driver_block_device.is_block_device_mapping, block_devices))
1526 
1527         self._default_device_names_for_instance(instance,
1528                                                 root_device_name,
1529                                                 ephemerals,
1530                                                 swap,
1531                                                 block_device_mapping)
1532 
1533     def _block_device_info_to_legacy(self, block_device_info):
1534         """Convert BDI to the old format for drivers that need it."""
1535 
1536         if self.use_legacy_block_device_info:
1537             ephemerals = driver_block_device.legacy_block_devices(
1538                 driver.block_device_info_get_ephemerals(block_device_info))
1539             mapping = driver_block_device.legacy_block_devices(
1540                 driver.block_device_info_get_mapping(block_device_info))
1541             swap = block_device_info['swap']
1542             if swap:
1543                 swap = swap.legacy()
1544 
1545             block_device_info.update({
1546                 'ephemerals': ephemerals,
1547                 'swap': swap,
1548                 'block_device_mapping': mapping})
1549 
1550     def _add_missing_dev_names(self, bdms, instance):
1551         for bdm in bdms:
1552             if bdm.device_name is not None:
1553                 continue
1554 
1555             device_name = self._get_device_name_for_instance(instance,
1556                                                              bdms, bdm)
1557             values = {'device_name': device_name}
1558             bdm.update(values)
1559             bdm.save()
1560 
1561     def _prep_block_device(self, context, instance, bdms):
1562         """Set up the block device for an instance with error logging."""
1563         try:
1564             self._add_missing_dev_names(bdms, instance)
1565             block_device_info = driver.get_block_device_info(instance, bdms)
1566             mapping = driver.block_device_info_get_mapping(block_device_info)
1567             driver_block_device.attach_block_devices(
1568                 mapping, context, instance, self.volume_api, self.driver,
1569                 wait_func=self._await_block_device_map_created)
1570 
1571             self._block_device_info_to_legacy(block_device_info)
1572             return block_device_info
1573 
1574         except exception.OverQuota as e:
1575             LOG.warning('Failed to create block device for instance due'
1576                         ' to exceeding volume related resource quota.'
1577                         ' Error: %s', e.message, instance=instance)
1578             raise
1579 
1580         except Exception as ex:
1581             LOG.exception('Instance failed block device setup',
1582                           instance=instance)
1583             # InvalidBDM will eventually result in a BuildAbortException when
1584             # booting from volume, and will be recorded as an instance fault.
1585             # Maintain the original exception message which most likely has
1586             # useful details which the standard InvalidBDM error message lacks.
1587             raise exception.InvalidBDM(six.text_type(ex))
1588 
1589     def _update_instance_after_spawn(self, context, instance):
1590         instance.power_state = self._get_power_state(context, instance)
1591         instance.vm_state = vm_states.ACTIVE
1592         instance.task_state = None
1593         instance.launched_at = timeutils.utcnow()
1594         configdrive.update_instance(instance)
1595 
1596     def _update_scheduler_instance_info(self, context, instance):
1597         """Sends an InstanceList with created or updated Instance objects to
1598         the Scheduler client.
1599 
1600         In the case of init_host, the value passed will already be an
1601         InstanceList. Other calls will send individual Instance objects that
1602         have been created or resized. In this case, we create an InstanceList
1603         object containing that Instance.
1604         """
1605         if not self.send_instance_updates:
1606             return
1607         if isinstance(instance, obj_instance.Instance):
1608             instance = objects.InstanceList(objects=[instance])
1609         context = context.elevated()
1610         self.scheduler_client.update_instance_info(context, self.host,
1611                                                    instance)
1612 
1613     def _delete_scheduler_instance_info(self, context, instance_uuid):
1614         """Sends the uuid of the deleted Instance to the Scheduler client."""
1615         if not self.send_instance_updates:
1616             return
1617         context = context.elevated()
1618         self.scheduler_client.delete_instance_info(context, self.host,
1619                                                    instance_uuid)
1620 
1621     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1622     def _sync_scheduler_instance_info(self, context):
1623         if not self.send_instance_updates:
1624             return
1625         context = context.elevated()
1626         instances = objects.InstanceList.get_by_host(context, self.host,
1627                                                      expected_attrs=[],
1628                                                      use_slave=True)
1629         uuids = [instance.uuid for instance in instances]
1630         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1631 
1632     def _notify_about_instance_usage(self, context, instance, event_suffix,
1633                                      network_info=None, system_metadata=None,
1634                                      extra_usage_info=None, fault=None):
1635         compute_utils.notify_about_instance_usage(
1636             self.notifier, context, instance, event_suffix,
1637             network_info=network_info,
1638             system_metadata=system_metadata,
1639             extra_usage_info=extra_usage_info, fault=fault)
1640 
1641     def _deallocate_network(self, context, instance,
1642                             requested_networks=None):
1643         # If we were told not to allocate networks let's save ourselves
1644         # the trouble of calling the network API.
1645         if requested_networks and requested_networks.no_allocate:
1646             LOG.debug("Skipping network deallocation for instance since "
1647                       "networking was not requested.", instance=instance)
1648             return
1649 
1650         LOG.debug('Deallocating network for instance', instance=instance)
1651         with timeutils.StopWatch() as timer:
1652             self.network_api.deallocate_for_instance(
1653                 context, instance, requested_networks=requested_networks)
1654         # nova-network does an rpc call so we're OK tracking time spent here
1655         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1656                  timer.elapsed(), instance=instance)
1657 
1658     def _get_instance_block_device_info(self, context, instance,
1659                                         refresh_conn_info=False,
1660                                         bdms=None):
1661         """Transform block devices to the driver block_device format."""
1662 
1663         if not bdms:
1664             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1665                     context, instance.uuid)
1666         block_device_info = driver.get_block_device_info(instance, bdms)
1667 
1668         if not refresh_conn_info:
1669             # if the block_device_mapping has no value in connection_info
1670             # (returned as None), don't include in the mapping
1671             block_device_info['block_device_mapping'] = [
1672                 bdm for bdm in driver.block_device_info_get_mapping(
1673                                     block_device_info)
1674                 if bdm.get('connection_info')]
1675         else:
1676             driver_block_device.refresh_conn_infos(
1677                 driver.block_device_info_get_mapping(block_device_info),
1678                 context, instance, self.volume_api, self.driver)
1679 
1680         self._block_device_info_to_legacy(block_device_info)
1681 
1682         return block_device_info
1683 
1684     def _build_failed(self):
1685         self._failed_builds += 1
1686         limit = CONF.compute.consecutive_build_service_disable_threshold
1687         if limit and self._failed_builds >= limit:
1688             # NOTE(danms): If we're doing a bunch of parallel builds,
1689             # it is possible (although not likely) that we have already
1690             # failed N-1 builds before this and we race with a successful
1691             # build and disable ourselves here when we might've otherwise
1692             # not.
1693             LOG.error('Disabling service due to %(fails)i '
1694                       'consecutive build failures',
1695                       {'fails': self._failed_builds})
1696             ctx = nova.context.get_admin_context()
1697             service = objects.Service.get_by_compute_host(ctx, CONF.host)
1698             service.disabled = True
1699             service.disabled_reason = (
1700                 'Auto-disabled due to %i build failures' % self._failed_builds)
1701             service.save()
1702             # NOTE(danms): Reset our counter now so that when the admin
1703             # re-enables us we can start fresh
1704             self._failed_builds = 0
1705         elif self._failed_builds > 1:
1706             LOG.warning('%(fails)i consecutive build failures',
1707                         {'fails': self._failed_builds})
1708 
1709     @wrap_exception()
1710     @reverts_task_state
1711     @wrap_instance_fault
1712     def build_and_run_instance(self, context, instance, image, request_spec,
1713                      filter_properties, admin_password=None,
1714                      injected_files=None, requested_networks=None,
1715                      security_groups=None, block_device_mapping=None,
1716                      node=None, limits=None, host_list=None):
1717 
1718         @utils.synchronized(instance.uuid)
1719         def _locked_do_build_and_run_instance(*args, **kwargs):
1720             # NOTE(danms): We grab the semaphore with the instance uuid
1721             # locked because we could wait in line to build this instance
1722             # for a while and we want to make sure that nothing else tries
1723             # to do anything with this instance while we wait.
1724             with self._build_semaphore:
1725                 try:
1726                     result = self._do_build_and_run_instance(*args, **kwargs)
1727                 except Exception:
1728                     # NOTE(mriedem): This should really only happen if
1729                     # _decode_files in _do_build_and_run_instance fails, and
1730                     # that's before a guest is spawned so it's OK to remove
1731                     # allocations for the instance for this node from Placement
1732                     # below as there is no guest consuming resources anyway.
1733                     # The _decode_files case could be handled more specifically
1734                     # but that's left for another day.
1735                     result = build_results.FAILED
1736                     raise
1737                 finally:
1738                     if result == build_results.FAILED:
1739                         # Remove the allocation records from Placement for the
1740                         # instance if the build failed. The instance.host is
1741                         # likely set to None in _do_build_and_run_instance
1742                         # which means if the user deletes the instance, it
1743                         # will be deleted in the API, not the compute service.
1744                         # Setting the instance.host to None in
1745                         # _do_build_and_run_instance means that the
1746                         # ResourceTracker will no longer consider this instance
1747                         # to be claiming resources against it, so we want to
1748                         # reflect that same thing in Placement.  No need to
1749                         # call this for a reschedule, as the allocations will
1750                         # have already been removed in
1751                         # self._do_build_and_run_instance().
1752                         self._delete_allocation_for_instance(context,
1753                                                              instance.uuid)
1754 
1755                     if result in (build_results.FAILED,
1756                                   build_results.RESCHEDULED):
1757                         self._build_failed()
1758                     else:
1759                         self._failed_builds = 0
1760 
1761         # NOTE(danms): We spawn here to return the RPC worker thread back to
1762         # the pool. Since what follows could take a really long time, we don't
1763         # want to tie up RPC workers.
1764         utils.spawn_n(_locked_do_build_and_run_instance,
1765                       context, instance, image, request_spec,
1766                       filter_properties, admin_password, injected_files,
1767                       requested_networks, security_groups,
1768                       block_device_mapping, node, limits, host_list)
1769 
1770     def _delete_allocation_for_instance(self, context, instance_uuid):
1771         rt = self._get_resource_tracker()
1772         rt.reportclient.delete_allocation_for_instance(context, instance_uuid)
1773 
1774     def _check_device_tagging(self, requested_networks, block_device_mapping):
1775         tagging_requested = False
1776         if requested_networks:
1777             for net in requested_networks:
1778                 if 'tag' in net and net.tag is not None:
1779                     tagging_requested = True
1780                     break
1781         if block_device_mapping and not tagging_requested:
1782             for bdm in block_device_mapping:
1783                 if 'tag' in bdm and bdm.tag is not None:
1784                     tagging_requested = True
1785                     break
1786         if (tagging_requested and
1787                 not self.driver.capabilities.get('supports_device_tagging',
1788                                                  False)):
1789             raise exception.BuildAbortException('Attempt to boot guest with '
1790                                                 'tagged devices on host that '
1791                                                 'does not support tagging.')
1792 
1793     @hooks.add_hook('build_instance')
1794     @wrap_exception()
1795     @reverts_task_state
1796     @wrap_instance_event(prefix='compute')
1797     @wrap_instance_fault
1798     def _do_build_and_run_instance(self, context, instance, image,
1799             request_spec, filter_properties, admin_password, injected_files,
1800             requested_networks, security_groups, block_device_mapping,
1801             node=None, limits=None, host_list=None):
1802 
1803         try:
1804             LOG.debug('Starting instance...', instance=instance)
1805             instance.vm_state = vm_states.BUILDING
1806             instance.task_state = None
1807             instance.save(expected_task_state=
1808                     (task_states.SCHEDULING, None))
1809         except exception.InstanceNotFound:
1810             msg = 'Instance disappeared before build.'
1811             LOG.debug(msg, instance=instance)
1812             return build_results.FAILED
1813         except exception.UnexpectedTaskStateError as e:
1814             LOG.debug(e.format_message(), instance=instance)
1815             return build_results.FAILED
1816 
1817         # b64 decode the files to inject:
1818         decoded_files = self._decode_files(injected_files)
1819 
1820         if limits is None:
1821             limits = {}
1822 
1823         if node is None:
1824             node = self._get_nodename(instance, refresh=True)
1825 
1826         try:
1827             with timeutils.StopWatch() as timer:
1828                 self._build_and_run_instance(context, instance, image,
1829                         decoded_files, admin_password, requested_networks,
1830                         security_groups, block_device_mapping, node, limits,
1831                         filter_properties, request_spec)
1832             LOG.info('Took %0.2f seconds to build instance.',
1833                      timer.elapsed(), instance=instance)
1834             return build_results.ACTIVE
1835         except exception.RescheduledException as e:
1836             retry = filter_properties.get('retry')
1837             if not retry:
1838                 # no retry information, do not reschedule.
1839                 LOG.debug("Retry info not present, will not reschedule",
1840                     instance=instance)
1841                 self._cleanup_allocated_networks(context, instance,
1842                     requested_networks)
1843                 self._cleanup_volumes(context, instance,
1844                     block_device_mapping, raise_exc=False)
1845                 compute_utils.add_instance_fault_from_exc(context,
1846                         instance, e, sys.exc_info(),
1847                         fault_message=e.kwargs['reason'])
1848                 self._nil_out_instance_obj_host_and_node(instance)
1849                 self._set_instance_obj_error_state(context, instance,
1850                                                    clean_task_state=True)
1851                 return build_results.FAILED
1852             LOG.debug(e.format_message(), instance=instance)
1853             # This will be used for logging the exception
1854             retry['exc'] = traceback.format_exception(*sys.exc_info())
1855             # This will be used for setting the instance fault message
1856             retry['exc_reason'] = e.kwargs['reason']
1857             # NOTE(comstud): Deallocate networks if the driver wants
1858             # us to do so.
1859             # NOTE(mriedem): Always deallocate networking when using Neutron.
1860             # This is to unbind any ports that the user supplied in the server
1861             # create request, or delete any ports that nova created which were
1862             # meant to be bound to this host. This check intentionally bypasses
1863             # the result of deallocate_networks_on_reschedule because the
1864             # default value in the driver is False, but that method was really
1865             # only meant for Ironic and should be removed when nova-network is
1866             # removed (since is_neutron() will then always be True).
1867             # NOTE(vladikr): SR-IOV ports should be deallocated to
1868             # allow new sriov pci devices to be allocated on a new host.
1869             # Otherwise, if devices with pci addresses are already allocated
1870             # on the destination host, the instance will fail to spawn.
1871             # info_cache.network_info should be present at this stage.
1872             if (self.driver.deallocate_networks_on_reschedule(instance) or
1873                 utils.is_neutron() or
1874                 self.deallocate_sriov_ports_on_reschedule(instance)):
1875                 self._cleanup_allocated_networks(context, instance,
1876                         requested_networks)
1877             else:
1878                 # NOTE(alex_xu): Network already allocated and we don't
1879                 # want to deallocate them before rescheduling. But we need
1880                 # to cleanup those network resources setup on this host before
1881                 # rescheduling.
1882                 self.network_api.cleanup_instance_network_on_host(
1883                     context, instance, self.host)
1884 
1885             self._nil_out_instance_obj_host_and_node(instance)
1886             instance.task_state = task_states.SCHEDULING
1887             instance.save()
1888             # The instance will have already claimed resources from this host
1889             # before this build was attempted. Now that it has failed, we need
1890             # to unclaim those resources before casting to the conductor, so
1891             # that if there are alternate hosts available for a retry, it can
1892             # claim resources on that new host for the instance.
1893             self._delete_allocation_for_instance(context, instance.uuid)
1894 
1895             self.compute_task_api.build_instances(context, [instance],
1896                     image, filter_properties, admin_password,
1897                     injected_files, requested_networks, security_groups,
1898                     block_device_mapping, request_spec=request_spec,
1899                     host_lists=[host_list])
1900             return build_results.RESCHEDULED
1901         except (exception.InstanceNotFound,
1902                 exception.UnexpectedDeletingTaskStateError):
1903             msg = 'Instance disappeared during build.'
1904             LOG.debug(msg, instance=instance)
1905             self._cleanup_allocated_networks(context, instance,
1906                     requested_networks)
1907             return build_results.FAILED
1908         except exception.BuildAbortException as e:
1909             LOG.error(e.format_message(), instance=instance)
1910             self._cleanup_allocated_networks(context, instance,
1911                     requested_networks)
1912             self._cleanup_volumes(context, instance,
1913                     block_device_mapping, raise_exc=False)
1914             compute_utils.add_instance_fault_from_exc(context, instance,
1915                     e, sys.exc_info())
1916             self._nil_out_instance_obj_host_and_node(instance)
1917             self._set_instance_obj_error_state(context, instance,
1918                                                clean_task_state=True)
1919             return build_results.FAILED
1920         except Exception as e:
1921             # Should not reach here.
1922             LOG.exception('Unexpected build failure, not rescheduling build.',
1923                           instance=instance)
1924             self._cleanup_allocated_networks(context, instance,
1925                     requested_networks)
1926             self._cleanup_volumes(context, instance,
1927                     block_device_mapping, raise_exc=False)
1928             compute_utils.add_instance_fault_from_exc(context, instance,
1929                     e, sys.exc_info())
1930             self._nil_out_instance_obj_host_and_node(instance)
1931             self._set_instance_obj_error_state(context, instance,
1932                                                clean_task_state=True)
1933             return build_results.FAILED
1934 
1935     def deallocate_sriov_ports_on_reschedule(self, instance):
1936         """Determine if networks are needed to be deallocated before reschedule
1937 
1938         Check the cached network info for any assigned SR-IOV ports.
1939         SR-IOV ports should be deallocated prior to rescheduling
1940         in order to allow new sriov pci devices to be allocated on a new host.
1941         """
1942         info_cache = instance.info_cache
1943 
1944         def _has_sriov_port(vif):
1945             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1946 
1947         if (info_cache and info_cache.network_info):
1948             for vif in info_cache.network_info:
1949                 if _has_sriov_port(vif):
1950                     return True
1951         return False
1952 
1953     @staticmethod
1954     def _get_scheduler_hints(filter_properties, request_spec=None):
1955         """Helper method to get scheduler hints.
1956 
1957         This method prefers to get the hints out of the request spec, but that
1958         might not be provided. Conductor will pass request_spec down to the
1959         first compute chosen for a build but older computes will not pass
1960         the request_spec to conductor's build_instances method for a
1961         a reschedule, so if we're on a host via a retry, request_spec may not
1962         be provided so we need to fallback to use the filter_properties
1963         to get scheduler hints.
1964         """
1965         hints = {}
1966         if request_spec is not None and 'scheduler_hints' in request_spec:
1967             hints = request_spec.scheduler_hints
1968         if not hints:
1969             hints = filter_properties.get('scheduler_hints') or {}
1970         return hints
1971 
1972     def _build_and_run_instance(self, context, instance, image, injected_files,
1973             admin_password, requested_networks, security_groups,
1974             block_device_mapping, node, limits, filter_properties,
1975             request_spec=None):
1976 
1977         image_name = image.get('name')
1978         self._notify_about_instance_usage(context, instance, 'create.start',
1979                 extra_usage_info={'image_name': image_name})
1980         compute_utils.notify_about_instance_create(
1981             context, instance, self.host,
1982             phase=fields.NotificationPhase.START,
1983             bdms=block_device_mapping)
1984 
1985         # NOTE(mikal): cache the keystone roles associated with the instance
1986         # at boot time for later reference
1987         instance.system_metadata.update(
1988             {'boot_roles': ','.join(context.roles)})
1989 
1990         self._check_device_tagging(requested_networks, block_device_mapping)
1991 
1992         try:
1993             scheduler_hints = self._get_scheduler_hints(filter_properties,
1994                                                         request_spec)
1995             rt = self._get_resource_tracker()
1996             with rt.instance_claim(context, instance, node, limits):
1997                 # Perform any driver preparation work for the driver.
1998                 self.driver.prepare_for_spawn(instance)
1999 
2000                 # NOTE(russellb) It's important that this validation be done
2001                 # *after* the resource tracker instance claim, as that is where
2002                 # the host is set on the instance.
2003                 self._validate_instance_group_policy(context, instance,
2004                                                      scheduler_hints)
2005                 image_meta = objects.ImageMeta.from_dict(image)
2006                 with self._build_resources(context, instance,
2007                         requested_networks, security_groups, image_meta,
2008                         block_device_mapping) as resources:
2009                     instance.vm_state = vm_states.BUILDING
2010                     instance.task_state = task_states.SPAWNING
2011                     # NOTE(JoshNang) This also saves the changes to the
2012                     # instance from _allocate_network_async, as they aren't
2013                     # saved in that function to prevent races.
2014                     instance.save(expected_task_state=
2015                             task_states.BLOCK_DEVICE_MAPPING)
2016                     block_device_info = resources['block_device_info']
2017                     network_info = resources['network_info']
2018                     allocs = resources['allocations']
2019                     LOG.debug('Start spawning the instance on the hypervisor.',
2020                               instance=instance)
2021                     with timeutils.StopWatch() as timer:
2022                         self.driver.spawn(context, instance, image_meta,
2023                                           injected_files, admin_password,
2024                                           allocs, network_info=network_info,
2025                                           block_device_info=block_device_info)
2026                     LOG.info('Took %0.2f seconds to spawn the instance on '
2027                              'the hypervisor.', timer.elapsed(),
2028                              instance=instance)
2029         except (exception.InstanceNotFound,
2030                 exception.UnexpectedDeletingTaskStateError) as e:
2031             with excutils.save_and_reraise_exception():
2032                 self._notify_about_instance_usage(context, instance,
2033                     'create.error', fault=e)
2034                 compute_utils.notify_about_instance_create(
2035                     context, instance, self.host,
2036                     phase=fields.NotificationPhase.ERROR, exception=e,
2037                     bdms=block_device_mapping)
2038         except exception.ComputeResourcesUnavailable as e:
2039             LOG.debug(e.format_message(), instance=instance)
2040             self._notify_about_instance_usage(context, instance,
2041                     'create.error', fault=e)
2042             compute_utils.notify_about_instance_create(
2043                     context, instance, self.host,
2044                     phase=fields.NotificationPhase.ERROR, exception=e,
2045                     bdms=block_device_mapping)
2046             raise exception.RescheduledException(
2047                     instance_uuid=instance.uuid, reason=e.format_message())
2048         except exception.BuildAbortException as e:
2049             with excutils.save_and_reraise_exception():
2050                 LOG.debug(e.format_message(), instance=instance)
2051                 self._notify_about_instance_usage(context, instance,
2052                     'create.error', fault=e)
2053                 compute_utils.notify_about_instance_create(
2054                     context, instance, self.host,
2055                     phase=fields.NotificationPhase.ERROR, exception=e,
2056                     bdms=block_device_mapping)
2057                 self.driver.failed_spawn_cleanup(instance)
2058         except (exception.FixedIpLimitExceeded,
2059                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2060             LOG.warning('No more network or fixed IP to be allocated',
2061                         instance=instance)
2062             self._notify_about_instance_usage(context, instance,
2063                     'create.error', fault=e)
2064             compute_utils.notify_about_instance_create(
2065                     context, instance, self.host,
2066                     phase=fields.NotificationPhase.ERROR, exception=e,
2067                     bdms=block_device_mapping)
2068             self.driver.failed_spawn_cleanup(instance)
2069             msg = _('Failed to allocate the network(s) with error %s, '
2070                     'not rescheduling.') % e.format_message()
2071             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2072                     reason=msg)
2073         except (exception.VirtualInterfaceCreateException,
2074                 exception.VirtualInterfaceMacAddressException,
2075                 exception.FixedIpInvalidOnHost,
2076                 exception.UnableToAutoAllocateNetwork) as e:
2077             LOG.exception('Failed to allocate network(s)',
2078                           instance=instance)
2079             self._notify_about_instance_usage(context, instance,
2080                     'create.error', fault=e)
2081             compute_utils.notify_about_instance_create(
2082                     context, instance, self.host,
2083                     phase=fields.NotificationPhase.ERROR, exception=e,
2084                     bdms=block_device_mapping)
2085             self.driver.failed_spawn_cleanup(instance)
2086             msg = _('Failed to allocate the network(s), not rescheduling.')
2087             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2088                     reason=msg)
2089         except (exception.FlavorDiskTooSmall,
2090                 exception.FlavorMemoryTooSmall,
2091                 exception.ImageNotActive,
2092                 exception.ImageUnacceptable,
2093                 exception.InvalidDiskInfo,
2094                 exception.InvalidDiskFormat,
2095                 cursive_exception.SignatureVerificationError,
2096                 exception.VolumeEncryptionNotSupported,
2097                 exception.InvalidInput) as e:
2098             self._notify_about_instance_usage(context, instance,
2099                     'create.error', fault=e)
2100             compute_utils.notify_about_instance_create(
2101                     context, instance, self.host,
2102                     phase=fields.NotificationPhase.ERROR, exception=e,
2103                     bdms=block_device_mapping)
2104             self.driver.failed_spawn_cleanup(instance)
2105             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2106                     reason=e.format_message())
2107         except Exception as e:
2108             self._notify_about_instance_usage(context, instance,
2109                     'create.error', fault=e)
2110             compute_utils.notify_about_instance_create(
2111                     context, instance, self.host,
2112                     phase=fields.NotificationPhase.ERROR, exception=e,
2113                     bdms=block_device_mapping)
2114             self.driver.failed_spawn_cleanup(instance)
2115             raise exception.RescheduledException(
2116                     instance_uuid=instance.uuid, reason=six.text_type(e))
2117 
2118         # NOTE(alaski): This is only useful during reschedules, remove it now.
2119         instance.system_metadata.pop('network_allocated', None)
2120 
2121         # If CONF.default_access_ip_network_name is set, grab the
2122         # corresponding network and set the access ip values accordingly.
2123         network_name = CONF.default_access_ip_network_name
2124         if (network_name and not instance.access_ip_v4 and
2125                 not instance.access_ip_v6):
2126             # Note that when there are multiple ips to choose from, an
2127             # arbitrary one will be chosen.
2128             for vif in network_info:
2129                 if vif['network']['label'] == network_name:
2130                     for ip in vif.fixed_ips():
2131                         if not instance.access_ip_v4 and ip['version'] == 4:
2132                             instance.access_ip_v4 = ip['address']
2133                         if not instance.access_ip_v6 and ip['version'] == 6:
2134                             instance.access_ip_v6 = ip['address']
2135                     break
2136 
2137         self._update_instance_after_spawn(context, instance)
2138 
2139         try:
2140             instance.save(expected_task_state=task_states.SPAWNING)
2141         except (exception.InstanceNotFound,
2142                 exception.UnexpectedDeletingTaskStateError) as e:
2143             with excutils.save_and_reraise_exception():
2144                 self._notify_about_instance_usage(context, instance,
2145                     'create.error', fault=e)
2146                 compute_utils.notify_about_instance_create(
2147                     context, instance, self.host,
2148                     phase=fields.NotificationPhase.ERROR, exception=e,
2149                     bdms=block_device_mapping)
2150 
2151         self._update_scheduler_instance_info(context, instance)
2152         self._notify_about_instance_usage(context, instance, 'create.end',
2153                 extra_usage_info={'message': _('Success')},
2154                 network_info=network_info)
2155         compute_utils.notify_about_instance_create(context, instance,
2156                 self.host, phase=fields.NotificationPhase.END,
2157                 bdms=block_device_mapping)
2158 
2159     @contextlib.contextmanager
2160     def _build_resources(self, context, instance, requested_networks,
2161                          security_groups, image_meta, block_device_mapping):
2162         resources = {}
2163         network_info = None
2164         try:
2165             LOG.debug('Start building networks asynchronously for instance.',
2166                       instance=instance)
2167             network_info = self._build_networks_for_instance(context, instance,
2168                     requested_networks, security_groups)
2169             resources['network_info'] = network_info
2170         except (exception.InstanceNotFound,
2171                 exception.UnexpectedDeletingTaskStateError):
2172             raise
2173         except exception.UnexpectedTaskStateError as e:
2174             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2175                     reason=e.format_message())
2176         except Exception:
2177             # Because this allocation is async any failures are likely to occur
2178             # when the driver accesses network_info during spawn().
2179             LOG.exception('Failed to allocate network(s)',
2180                           instance=instance)
2181             msg = _('Failed to allocate the network(s), not rescheduling.')
2182             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2183                     reason=msg)
2184 
2185         try:
2186             # Depending on a virt driver, some network configuration is
2187             # necessary before preparing block devices.
2188             self.driver.prepare_networks_before_block_device_mapping(
2189                 instance, network_info)
2190 
2191             # Verify that all the BDMs have a device_name set and assign a
2192             # default to the ones missing it with the help of the driver.
2193             self._default_block_device_names(instance, image_meta,
2194                                              block_device_mapping)
2195 
2196             LOG.debug('Start building block device mappings for instance.',
2197                       instance=instance)
2198             instance.vm_state = vm_states.BUILDING
2199             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2200             instance.save()
2201 
2202             block_device_info = self._prep_block_device(context, instance,
2203                     block_device_mapping)
2204             resources['block_device_info'] = block_device_info
2205         except (exception.InstanceNotFound,
2206                 exception.UnexpectedDeletingTaskStateError):
2207             with excutils.save_and_reraise_exception():
2208                 # Make sure the async call finishes
2209                 if network_info is not None:
2210                     network_info.wait(do_raise=False)
2211                     self.driver.clean_networks_preparation(instance,
2212                                                            network_info)
2213         except (exception.UnexpectedTaskStateError,
2214                 exception.OverQuota, exception.InvalidBDM) as e:
2215             # Make sure the async call finishes
2216             if network_info is not None:
2217                 network_info.wait(do_raise=False)
2218                 self.driver.clean_networks_preparation(instance, network_info)
2219             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2220                     reason=e.format_message())
2221         except Exception:
2222             LOG.exception('Failure prepping block device',
2223                           instance=instance)
2224             # Make sure the async call finishes
2225             if network_info is not None:
2226                 network_info.wait(do_raise=False)
2227                 self.driver.clean_networks_preparation(instance, network_info)
2228             msg = _('Failure prepping block device.')
2229             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2230                     reason=msg)
2231 
2232         try:
2233             resources['allocations'] = (
2234                 self.reportclient.get_allocations_for_consumer(context,
2235                                                                instance.uuid))
2236         except Exception:
2237             LOG.exception('Failure retrieving placement allocations',
2238                           instance=instance)
2239             # Make sure the async call finishes
2240             if network_info is not None:
2241                 network_info.wait(do_raise=False)
2242             msg = _('Failure retrieving placement allocations')
2243             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2244                                                 reason=msg)
2245 
2246         try:
2247             yield resources
2248         except Exception as exc:
2249             with excutils.save_and_reraise_exception() as ctxt:
2250                 if not isinstance(exc, (
2251                         exception.InstanceNotFound,
2252                         exception.UnexpectedDeletingTaskStateError)):
2253                     LOG.exception('Instance failed to spawn',
2254                                   instance=instance)
2255                 # Make sure the async call finishes
2256                 if network_info is not None:
2257                     network_info.wait(do_raise=False)
2258                 # if network_info is empty we're likely here because of
2259                 # network allocation failure. Since nothing can be reused on
2260                 # rescheduling it's better to deallocate network to eliminate
2261                 # the chance of orphaned ports in neutron
2262                 deallocate_networks = False if network_info else True
2263                 try:
2264                     self._shutdown_instance(context, instance,
2265                             block_device_mapping, requested_networks,
2266                             try_deallocate_networks=deallocate_networks)
2267                 except Exception as exc2:
2268                     ctxt.reraise = False
2269                     LOG.warning('Could not clean up failed build,'
2270                                 ' not rescheduling. Error: %s',
2271                                 six.text_type(exc2))
2272                     raise exception.BuildAbortException(
2273                             instance_uuid=instance.uuid,
2274                             reason=six.text_type(exc))
2275 
2276     def _cleanup_allocated_networks(self, context, instance,
2277             requested_networks):
2278         try:
2279             self._deallocate_network(context, instance, requested_networks)
2280         except Exception:
2281             LOG.exception('Failed to deallocate networks', instance=instance)
2282             return
2283 
2284         instance.system_metadata['network_allocated'] = 'False'
2285         try:
2286             instance.save()
2287         except exception.InstanceNotFound:
2288             # NOTE(alaski): It's possible that we're cleaning up the networks
2289             # because the instance was deleted.  If that's the case then this
2290             # exception will be raised by instance.save()
2291             pass
2292 
2293     def _try_deallocate_network(self, context, instance,
2294                                 requested_networks=None):
2295         try:
2296             # tear down allocated network structure
2297             self._deallocate_network(context, instance, requested_networks)
2298         except Exception as ex:
2299             with excutils.save_and_reraise_exception():
2300                 LOG.error('Failed to deallocate network for instance. '
2301                           'Error: %s', ex, instance=instance)
2302                 self._set_instance_obj_error_state(context, instance)
2303 
2304     def _get_power_off_values(self, context, instance, clean_shutdown):
2305         """Get the timing configuration for powering down this instance."""
2306         if clean_shutdown:
2307             timeout = compute_utils.get_value_from_system_metadata(instance,
2308                           key='image_os_shutdown_timeout', type=int,
2309                           default=CONF.shutdown_timeout)
2310             retry_interval = CONF.compute.shutdown_retry_interval
2311         else:
2312             timeout = 0
2313             retry_interval = 0
2314 
2315         return timeout, retry_interval
2316 
2317     def _power_off_instance(self, context, instance, clean_shutdown=True):
2318         """Power off an instance on this host."""
2319         timeout, retry_interval = self._get_power_off_values(context,
2320                                         instance, clean_shutdown)
2321         self.driver.power_off(instance, timeout, retry_interval)
2322 
2323     def _shutdown_instance(self, context, instance,
2324                            bdms, requested_networks=None, notify=True,
2325                            try_deallocate_networks=True):
2326         """Shutdown an instance on this host.
2327 
2328         :param:context: security context
2329         :param:instance: a nova.objects.Instance object
2330         :param:bdms: the block devices for the instance to be torn
2331                      down
2332         :param:requested_networks: the networks on which the instance
2333                                    has ports
2334         :param:notify: true if a final usage notification should be
2335                        emitted
2336         :param:try_deallocate_networks: false if we should avoid
2337                                         trying to teardown networking
2338         """
2339         context = context.elevated()
2340         LOG.info('Terminating instance', instance=instance)
2341 
2342         if notify:
2343             self._notify_about_instance_usage(context, instance,
2344                                               "shutdown.start")
2345             compute_utils.notify_about_instance_action(context, instance,
2346                     self.host, action=fields.NotificationAction.SHUTDOWN,
2347                     phase=fields.NotificationPhase.START, bdms=bdms)
2348 
2349         network_info = instance.get_network_info()
2350 
2351         # NOTE(vish) get bdms before destroying the instance
2352         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2353         block_device_info = self._get_instance_block_device_info(
2354             context, instance, bdms=bdms)
2355 
2356         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2357         #                want to keep ip allocated for certain failures
2358         try:
2359             LOG.debug('Start destroying the instance on the hypervisor.',
2360                       instance=instance)
2361             with timeutils.StopWatch() as timer:
2362                 self.driver.destroy(context, instance, network_info,
2363                                     block_device_info)
2364             LOG.info('Took %0.2f seconds to destroy the instance on the '
2365                      'hypervisor.', timer.elapsed(), instance=instance)
2366         except exception.InstancePowerOffFailure:
2367             # if the instance can't power off, don't release the ip
2368             with excutils.save_and_reraise_exception():
2369                 pass
2370         except Exception:
2371             with excutils.save_and_reraise_exception():
2372                 # deallocate ip and fail without proceeding to
2373                 # volume api calls, preserving current behavior
2374                 if try_deallocate_networks:
2375                     self._try_deallocate_network(context, instance,
2376                                                  requested_networks)
2377 
2378         if try_deallocate_networks:
2379             self._try_deallocate_network(context, instance, requested_networks)
2380 
2381         timer.restart()
2382         for bdm in vol_bdms:
2383             try:
2384                 if bdm.attachment_id:
2385                     self.volume_api.attachment_delete(context,
2386                                                       bdm.attachment_id)
2387                 else:
2388                     # NOTE(vish): actual driver detach done in driver.destroy,
2389                     #             so just tell cinder that we are done with it.
2390                     connector = self.driver.get_volume_connector(instance)
2391                     self.volume_api.terminate_connection(context,
2392                                                          bdm.volume_id,
2393                                                          connector)
2394                     self.volume_api.detach(context, bdm.volume_id,
2395                                            instance.uuid)
2396 
2397             except exception.VolumeAttachmentNotFound as exc:
2398                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2399                           instance=instance)
2400             except exception.DiskNotFound as exc:
2401                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2402                           instance=instance)
2403             except exception.VolumeNotFound as exc:
2404                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2405                           instance=instance)
2406             except (cinder_exception.EndpointNotFound,
2407                     keystone_exception.EndpointNotFound) as exc:
2408                 LOG.warning('Ignoring EndpointNotFound for '
2409                             'volume %(volume_id)s: %(exc)s',
2410                             {'exc': exc, 'volume_id': bdm.volume_id},
2411                             instance=instance)
2412             except cinder_exception.ClientException as exc:
2413                 LOG.warning('Ignoring unknown cinder exception for '
2414                             'volume %(volume_id)s: %(exc)s',
2415                             {'exc': exc, 'volume_id': bdm.volume_id},
2416                             instance=instance)
2417             except Exception as exc:
2418                 LOG.warning('Ignoring unknown exception for '
2419                             'volume %(volume_id)s: %(exc)s',
2420                             {'exc': exc, 'volume_id': bdm.volume_id},
2421                             instance=instance)
2422         if vol_bdms:
2423             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2424                      'for instance.',
2425                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2426                      instance=instance)
2427 
2428         if notify:
2429             self._notify_about_instance_usage(context, instance,
2430                                               "shutdown.end")
2431             compute_utils.notify_about_instance_action(context, instance,
2432                     self.host, action=fields.NotificationAction.SHUTDOWN,
2433                     phase=fields.NotificationPhase.END, bdms=bdms)
2434 
2435     def _cleanup_volumes(self, context, instance, bdms, raise_exc=True,
2436                          detach=True):
2437         exc_info = None
2438         for bdm in bdms:
2439             if detach and bdm.volume_id:
2440                 try:
2441                     LOG.debug("Detaching volume: %s", bdm.volume_id,
2442                               instance_uuid=instance.uuid)
2443                     destroy = bdm.delete_on_termination
2444                     self._detach_volume(context, bdm, instance,
2445                                         destroy_bdm=destroy)
2446                 except Exception as exc:
2447                     exc_info = sys.exc_info()
2448                     LOG.warning('Failed to detach volume: %(volume_id)s '
2449                                 'due to %(exc)s',
2450                                 {'volume_id': bdm.volume_id, 'exc': exc})
2451 
2452             if bdm.volume_id and bdm.delete_on_termination:
2453                 try:
2454                     LOG.debug("Deleting volume: %s", bdm.volume_id,
2455                               instance_uuid=instance.uuid)
2456                     self.volume_api.delete(context, bdm.volume_id)
2457                 except Exception as exc:
2458                     exc_info = sys.exc_info()
2459                     LOG.warning('Failed to delete volume: %(volume_id)s '
2460                                 'due to %(exc)s',
2461                                 {'volume_id': bdm.volume_id, 'exc': exc})
2462         if exc_info is not None and raise_exc:
2463             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2464 
2465     @hooks.add_hook("delete_instance")
2466     def _delete_instance(self, context, instance, bdms):
2467         """Delete an instance on this host.
2468 
2469         :param context: nova request context
2470         :param instance: nova.objects.instance.Instance object
2471         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2472         """
2473         events = self.instance_events.clear_events_for_instance(instance)
2474         if events:
2475             LOG.debug('Events pending at deletion: %(events)s',
2476                       {'events': ','.join(events.keys())},
2477                       instance=instance)
2478         self._notify_about_instance_usage(context, instance,
2479                                           "delete.start")
2480         compute_utils.notify_about_instance_action(context, instance,
2481                 self.host, action=fields.NotificationAction.DELETE,
2482                 phase=fields.NotificationPhase.START, bdms=bdms)
2483 
2484         self._shutdown_instance(context, instance, bdms)
2485         # NOTE(dims): instance.info_cache.delete() should be called after
2486         # _shutdown_instance in the compute manager as shutdown calls
2487         # deallocate_for_instance so the info_cache is still needed
2488         # at this point.
2489         if instance.info_cache is not None:
2490             instance.info_cache.delete()
2491         else:
2492             # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2493             # is None. When the root cause that instance.info_cache becomes
2494             # None is fixed, the log level should be reconsidered.
2495             LOG.warning("Info cache for instance could not be found. "
2496                         "Ignore.", instance=instance)
2497 
2498         # NOTE(vish): We have already deleted the instance, so we have
2499         #             to ignore problems cleaning up the volumes. It
2500         #             would be nice to let the user know somehow that
2501         #             the volume deletion failed, but it is not
2502         #             acceptable to have an instance that can not be
2503         #             deleted. Perhaps this could be reworked in the
2504         #             future to set an instance fault the first time
2505         #             and to only ignore the failure if the instance
2506         #             is already in ERROR.
2507 
2508         # NOTE(ameeda): The volumes already detached during the above
2509         #               _shutdown_instance() call and this is why
2510         #               detach is not requested from _cleanup_volumes()
2511         #               in this case
2512 
2513         self._cleanup_volumes(context, instance, bdms,
2514                 raise_exc=False, detach=False)
2515         # if a delete task succeeded, always update vm state and task
2516         # state without expecting task state to be DELETING
2517         instance.vm_state = vm_states.DELETED
2518         instance.task_state = None
2519         instance.power_state = power_state.NOSTATE
2520         instance.terminated_at = timeutils.utcnow()
2521         instance.save()
2522         system_meta = instance.system_metadata
2523         instance.destroy()
2524 
2525         self._complete_deletion(context,
2526                                 instance,
2527                                 bdms,
2528                                 system_meta)
2529 
2530     @wrap_exception()
2531     @reverts_task_state
2532     @wrap_instance_event(prefix='compute')
2533     @wrap_instance_fault
2534     def terminate_instance(self, context, instance, bdms):
2535         """Terminate an instance on this host."""
2536         @utils.synchronized(instance.uuid)
2537         def do_terminate_instance(instance, bdms):
2538             # NOTE(mriedem): If we are deleting the instance while it was
2539             # booting from volume, we could be racing with a database update of
2540             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2541             # to compute here, the BDMs may be stale at this point. So check
2542             # for any volume BDMs that don't have volume_id set and if we
2543             # detect that, we need to refresh the BDM list before proceeding.
2544             # TODO(mriedem): Move this into _delete_instance and make the bdms
2545             # parameter optional.
2546             for bdm in list(bdms):
2547                 if bdm.is_volume and not bdm.volume_id:
2548                     LOG.debug('There are potentially stale BDMs during '
2549                               'delete, refreshing the BlockDeviceMappingList.',
2550                               instance=instance)
2551                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2552                         context, instance.uuid)
2553                     break
2554             try:
2555                 self._delete_instance(context, instance, bdms)
2556             except exception.InstanceNotFound:
2557                 LOG.info("Instance disappeared during terminate",
2558                          instance=instance)
2559             except Exception:
2560                 # As we're trying to delete always go to Error if something
2561                 # goes wrong that _delete_instance can't handle.
2562                 with excutils.save_and_reraise_exception():
2563                     LOG.exception('Setting instance vm_state to ERROR',
2564                                   instance=instance)
2565                     self._set_instance_obj_error_state(context, instance)
2566 
2567         do_terminate_instance(instance, bdms)
2568 
2569     # NOTE(johannes): This is probably better named power_off_instance
2570     # so it matches the driver method, but because of other issues, we
2571     # can't use that name in grizzly.
2572     @wrap_exception()
2573     @reverts_task_state
2574     @wrap_instance_event(prefix='compute')
2575     @wrap_instance_fault
2576     def stop_instance(self, context, instance, clean_shutdown):
2577         """Stopping an instance on this host."""
2578 
2579         @utils.synchronized(instance.uuid)
2580         def do_stop_instance():
2581             current_power_state = self._get_power_state(context, instance)
2582             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2583                       'current task_state: %(task_state)s, current DB '
2584                       'power_state: %(db_power_state)s, current VM '
2585                       'power_state: %(current_power_state)s',
2586                       {'vm_state': instance.vm_state,
2587                        'task_state': instance.task_state,
2588                        'db_power_state': instance.power_state,
2589                        'current_power_state': current_power_state},
2590                       instance_uuid=instance.uuid)
2591 
2592             # NOTE(mriedem): If the instance is already powered off, we are
2593             # possibly tearing down and racing with other operations, so we can
2594             # expect the task_state to be None if something else updates the
2595             # instance and we're not locking it.
2596             expected_task_state = [task_states.POWERING_OFF]
2597             # The list of power states is from _sync_instance_power_state.
2598             if current_power_state in (power_state.NOSTATE,
2599                                        power_state.SHUTDOWN,
2600                                        power_state.CRASHED):
2601                 LOG.info('Instance is already powered off in the '
2602                          'hypervisor when stop is called.',
2603                          instance=instance)
2604                 expected_task_state.append(None)
2605 
2606             self._notify_about_instance_usage(context, instance,
2607                                               "power_off.start")
2608 
2609             compute_utils.notify_about_instance_action(context, instance,
2610                         self.host, action=fields.NotificationAction.POWER_OFF,
2611                         phase=fields.NotificationPhase.START)
2612 
2613             self._power_off_instance(context, instance, clean_shutdown)
2614             instance.power_state = self._get_power_state(context, instance)
2615             instance.vm_state = vm_states.STOPPED
2616             instance.task_state = None
2617             instance.save(expected_task_state=expected_task_state)
2618             self._notify_about_instance_usage(context, instance,
2619                                               "power_off.end")
2620 
2621             compute_utils.notify_about_instance_action(context, instance,
2622                         self.host, action=fields.NotificationAction.POWER_OFF,
2623                         phase=fields.NotificationPhase.END)
2624 
2625         do_stop_instance()
2626 
2627     def _power_on(self, context, instance):
2628         network_info = self.network_api.get_instance_nw_info(context, instance)
2629         block_device_info = self._get_instance_block_device_info(context,
2630                                                                  instance)
2631         self.driver.power_on(context, instance,
2632                              network_info,
2633                              block_device_info)
2634 
2635     def _delete_snapshot_of_shelved_instance(self, context, instance,
2636                                              snapshot_id):
2637         """Delete snapshot of shelved instance."""
2638         try:
2639             self.image_api.delete(context, snapshot_id)
2640         except (exception.ImageNotFound,
2641                 exception.ImageNotAuthorized) as exc:
2642             LOG.warning("Failed to delete snapshot "
2643                         "from shelved instance (%s).",
2644                         exc.format_message(), instance=instance)
2645         except Exception:
2646             LOG.exception("Something wrong happened when trying to "
2647                           "delete snapshot from shelved instance.",
2648                           instance=instance)
2649 
2650     # NOTE(johannes): This is probably better named power_on_instance
2651     # so it matches the driver method, but because of other issues, we
2652     # can't use that name in grizzly.
2653     @wrap_exception()
2654     @reverts_task_state
2655     @wrap_instance_event(prefix='compute')
2656     @wrap_instance_fault
2657     def start_instance(self, context, instance):
2658         """Starting an instance on this host."""
2659         self._notify_about_instance_usage(context, instance, "power_on.start")
2660         compute_utils.notify_about_instance_action(context, instance,
2661             self.host, action=fields.NotificationAction.POWER_ON,
2662             phase=fields.NotificationPhase.START)
2663         self._power_on(context, instance)
2664         instance.power_state = self._get_power_state(context, instance)
2665         instance.vm_state = vm_states.ACTIVE
2666         instance.task_state = None
2667 
2668         # Delete an image(VM snapshot) for a shelved instance
2669         snapshot_id = instance.system_metadata.get('shelved_image_id')
2670         if snapshot_id:
2671             self._delete_snapshot_of_shelved_instance(context, instance,
2672                                                       snapshot_id)
2673 
2674         # Delete system_metadata for a shelved instance
2675         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2676 
2677         instance.save(expected_task_state=task_states.POWERING_ON)
2678         self._notify_about_instance_usage(context, instance, "power_on.end")
2679         compute_utils.notify_about_instance_action(context, instance,
2680             self.host, action=fields.NotificationAction.POWER_ON,
2681             phase=fields.NotificationPhase.END)
2682 
2683     @messaging.expected_exceptions(NotImplementedError,
2684                                    exception.TriggerCrashDumpNotSupported,
2685                                    exception.InstanceNotRunning)
2686     @wrap_exception()
2687     @wrap_instance_event(prefix='compute')
2688     @wrap_instance_fault
2689     def trigger_crash_dump(self, context, instance):
2690         """Trigger crash dump in an instance."""
2691 
2692         self._notify_about_instance_usage(context, instance,
2693                                           "trigger_crash_dump.start")
2694         compute_utils.notify_about_instance_action(context, instance,
2695                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2696                 phase=fields.NotificationPhase.START)
2697 
2698         # This method does not change task_state and power_state because the
2699         # effect of a trigger depends on user's configuration.
2700         self.driver.trigger_crash_dump(instance)
2701 
2702         self._notify_about_instance_usage(context, instance,
2703                                           "trigger_crash_dump.end")
2704         compute_utils.notify_about_instance_action(context, instance,
2705                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2706                 phase=fields.NotificationPhase.END)
2707 
2708     @wrap_exception()
2709     @reverts_task_state
2710     @wrap_instance_event(prefix='compute')
2711     @wrap_instance_fault
2712     def soft_delete_instance(self, context, instance):
2713         """Soft delete an instance on this host."""
2714         with compute_utils.notify_about_instance_delete(
2715                 self.notifier, context, instance, 'soft_delete'):
2716             compute_utils.notify_about_instance_action(context, instance,
2717                 self.host, action=fields.NotificationAction.SOFT_DELETE,
2718                 phase=fields.NotificationPhase.START)
2719             try:
2720                 self.driver.soft_delete(instance)
2721             except NotImplementedError:
2722                 # Fallback to just powering off the instance if the
2723                 # hypervisor doesn't implement the soft_delete method
2724                 self.driver.power_off(instance)
2725             instance.power_state = self._get_power_state(context, instance)
2726             instance.vm_state = vm_states.SOFT_DELETED
2727             instance.task_state = None
2728             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2729             compute_utils.notify_about_instance_action(
2730                 context, instance, self.host,
2731                 action=fields.NotificationAction.SOFT_DELETE,
2732                 phase=fields.NotificationPhase.END)
2733 
2734     @wrap_exception()
2735     @reverts_task_state
2736     @wrap_instance_event(prefix='compute')
2737     @wrap_instance_fault
2738     def restore_instance(self, context, instance):
2739         """Restore a soft-deleted instance on this host."""
2740         self._notify_about_instance_usage(context, instance, "restore.start")
2741         compute_utils.notify_about_instance_action(context, instance,
2742             self.host, action=fields.NotificationAction.RESTORE,
2743             phase=fields.NotificationPhase.START)
2744         try:
2745             self.driver.restore(instance)
2746         except NotImplementedError:
2747             # Fallback to just powering on the instance if the hypervisor
2748             # doesn't implement the restore method
2749             self._power_on(context, instance)
2750         instance.power_state = self._get_power_state(context, instance)
2751         instance.vm_state = vm_states.ACTIVE
2752         instance.task_state = None
2753         instance.save(expected_task_state=task_states.RESTORING)
2754         self._notify_about_instance_usage(context, instance, "restore.end")
2755         compute_utils.notify_about_instance_action(context, instance,
2756             self.host, action=fields.NotificationAction.RESTORE,
2757             phase=fields.NotificationPhase.END)
2758 
2759     @staticmethod
2760     def _set_migration_status(migration, status):
2761         """Set the status, and guard against a None being passed in.
2762 
2763         This is useful as some of the compute RPC calls will not pass
2764         a migration object in older versions. The check can be removed when
2765         we move past 4.x major version of the RPC API.
2766         """
2767         if migration:
2768             migration.status = status
2769             migration.save()
2770 
2771     def _rebuild_default_impl(self, context, instance, image_meta,
2772                               injected_files, admin_password, allocations,
2773                               bdms, detach_block_devices, attach_block_devices,
2774                               network_info=None,
2775                               recreate=False, block_device_info=None,
2776                               preserve_ephemeral=False):
2777         if preserve_ephemeral:
2778             # The default code path does not support preserving ephemeral
2779             # partitions.
2780             raise exception.PreserveEphemeralNotSupported()
2781 
2782         if recreate:
2783             detach_block_devices(context, bdms)
2784         else:
2785             self._power_off_instance(context, instance, clean_shutdown=True)
2786             detach_block_devices(context, bdms)
2787             self.driver.destroy(context, instance,
2788                                 network_info=network_info,
2789                                 block_device_info=block_device_info)
2790 
2791         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2792         instance.save(expected_task_state=[task_states.REBUILDING])
2793 
2794         new_block_device_info = attach_block_devices(context, instance, bdms)
2795 
2796         instance.task_state = task_states.REBUILD_SPAWNING
2797         instance.save(
2798             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2799 
2800         with instance.mutated_migration_context():
2801             self.driver.spawn(context, instance, image_meta, injected_files,
2802                               admin_password, allocations,
2803                               network_info=network_info,
2804                               block_device_info=new_block_device_info)
2805 
2806     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
2807         self._notify_about_instance_usage(context, instance,
2808                                           'rebuild.error', fault=error)
2809         compute_utils.notify_about_instance_action(
2810             context, instance, self.host,
2811             action=fields.NotificationAction.REBUILD,
2812             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms)
2813 
2814     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2815     @wrap_exception()
2816     @reverts_task_state
2817     @wrap_instance_event(prefix='compute')
2818     @wrap_instance_fault
2819     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2820                          injected_files, new_pass, orig_sys_metadata,
2821                          bdms, recreate, on_shared_storage,
2822                          preserve_ephemeral, migration,
2823                          scheduled_node, limits, request_spec):
2824         """Destroy and re-make this instance.
2825 
2826         A 'rebuild' effectively purges all existing data from the system and
2827         remakes the VM with given 'metadata' and 'personalities'.
2828 
2829         :param context: `nova.RequestContext` object
2830         :param instance: Instance object
2831         :param orig_image_ref: Original image_ref before rebuild
2832         :param image_ref: New image_ref for rebuild
2833         :param injected_files: Files to inject
2834         :param new_pass: password to set on rebuilt instance
2835         :param orig_sys_metadata: instance system metadata from pre-rebuild
2836         :param bdms: block-device-mappings to use for rebuild
2837         :param recreate: True if the instance is being recreated (e.g. the
2838             hypervisor it was on failed) - cleanup of old state will be
2839             skipped.
2840         :param on_shared_storage: True if instance files on shared storage.
2841                                   If not provided then information from the
2842                                   driver will be used to decide if the instance
2843                                   files are available or not on the target host
2844         :param preserve_ephemeral: True if the default ephemeral storage
2845                                    partition must be preserved on rebuild
2846         :param migration: a Migration object if one was created for this
2847                           rebuild operation (if it's a part of evacuate)
2848         :param scheduled_node: A node of the host chosen by the scheduler. If a
2849                                host was specified by the user, this will be
2850                                None
2851         :param limits: Overcommit limits set by the scheduler. If a host was
2852                        specified by the user, this will be None
2853         :param request_spec: a RequestSpec object used to schedule the instance
2854 
2855         """
2856         # recreate=True means the instance is being evacuated from a failed
2857         # host to a new destination host (this host). The 'recreate' variable
2858         # name is confusing, so rename it to evacuate here at the top, which
2859         # is simpler than renaming a parameter in an RPC versioned method.
2860         evacuate = recreate
2861         context = context.elevated()
2862 
2863         if evacuate:
2864             LOG.info("Evacuating instance", instance=instance)
2865         else:
2866             LOG.info("Rebuilding instance", instance=instance)
2867 
2868         rt = self._get_resource_tracker()
2869         if evacuate:
2870             # This is an evacuation to a new host, so we need to perform a
2871             # resource claim.
2872             rebuild_claim = rt.rebuild_claim
2873         else:
2874             # This is a rebuild to the same host, so we don't need to make
2875             # a claim since the instance is already on this host.
2876             rebuild_claim = claims.NopClaim
2877 
2878         image_meta = {}
2879         if image_ref:
2880             image_meta = self.image_api.get(context, image_ref)
2881 
2882         # NOTE(mriedem): On an evacuate, we need to update
2883         # the instance's host and node properties to reflect it's
2884         # destination node for the evacuate.
2885         if not scheduled_node:
2886             if evacuate:
2887                 try:
2888                     compute_node = self._get_compute_info(context, self.host)
2889                     scheduled_node = compute_node.hypervisor_hostname
2890                 except exception.ComputeHostNotFound:
2891                     LOG.exception('Failed to get compute_info for %s',
2892                                   self.host)
2893             else:
2894                 scheduled_node = instance.node
2895 
2896         with self._error_out_instance_on_exception(context, instance):
2897             try:
2898                 claim_ctxt = rebuild_claim(
2899                     context, instance, scheduled_node,
2900                     limits=limits, image_meta=image_meta,
2901                     migration=migration)
2902                 self._do_rebuild_instance_with_claim(
2903                     claim_ctxt, context, instance, orig_image_ref,
2904                     image_ref, injected_files, new_pass, orig_sys_metadata,
2905                     bdms, evacuate, on_shared_storage, preserve_ephemeral,
2906                     migration, request_spec)
2907             except (exception.ComputeResourcesUnavailable,
2908                     exception.RescheduledException) as e:
2909                 if isinstance(e, exception.ComputeResourcesUnavailable):
2910                     LOG.debug("Could not rebuild instance on this host, not "
2911                               "enough resources available.", instance=instance)
2912                 else:
2913                     # RescheduledException is raised by the late server group
2914                     # policy check during evacuation if a parallel scheduling
2915                     # violated the policy.
2916                     # We catch the RescheduledException here but we don't have
2917                     # the plumbing to do an actual reschedule so we abort the
2918                     # operation.
2919                     LOG.debug("Could not rebuild instance on this host, "
2920                               "late server group check failed.",
2921                               instance=instance)
2922                 # NOTE(ndipanov): We just abort the build for now and leave a
2923                 # migration record for potential cleanup later
2924                 self._set_migration_status(migration, 'failed')
2925                 # Since the claim failed, we need to remove the allocation
2926                 # created against the destination node. Note that we can only
2927                 # get here when evacuating to a destination node. Rebuilding
2928                 # on the same host (not evacuate) uses the NopClaim which will
2929                 # not raise ComputeResourcesUnavailable.
2930                 rt.delete_allocation_for_evacuated_instance(
2931                     context, instance, scheduled_node, node_type='destination')
2932                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2933                 raise exception.BuildAbortException(
2934                     instance_uuid=instance.uuid, reason=e.format_message())
2935             except (exception.InstanceNotFound,
2936                     exception.UnexpectedDeletingTaskStateError) as e:
2937                 LOG.debug('Instance was deleted while rebuilding',
2938                           instance=instance)
2939                 self._set_migration_status(migration, 'failed')
2940                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2941             except Exception as e:
2942                 self._set_migration_status(migration, 'failed')
2943                 if evacuate or scheduled_node is not None:
2944                     rt.delete_allocation_for_evacuated_instance(
2945                         context, instance, scheduled_node,
2946                         node_type='destination')
2947                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2948                 raise
2949             else:
2950                 instance.apply_migration_context()
2951                 # NOTE (ndipanov): This save will now update the host and node
2952                 # attributes making sure that next RT pass is consistent since
2953                 # it will be based on the instance and not the migration DB
2954                 # entry.
2955                 instance.host = self.host
2956                 instance.node = scheduled_node
2957                 instance.save()
2958                 instance.drop_migration_context()
2959 
2960                 # NOTE (ndipanov): Mark the migration as done only after we
2961                 # mark the instance as belonging to this host.
2962                 self._set_migration_status(migration, 'done')
2963 
2964     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2965         """Helper to avoid deep nesting in the top-level method."""
2966 
2967         with claim_context:
2968             self._do_rebuild_instance(*args, **kwargs)
2969 
2970     @staticmethod
2971     def _get_image_name(image_meta):
2972         if image_meta.obj_attr_is_set("name"):
2973             return image_meta.name
2974         else:
2975             return ''
2976 
2977     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2978                              image_ref, injected_files, new_pass,
2979                              orig_sys_metadata, bdms, evacuate,
2980                              on_shared_storage, preserve_ephemeral,
2981                              migration, request_spec):
2982         orig_vm_state = instance.vm_state
2983 
2984         if evacuate:
2985             if request_spec:
2986                 # NOTE(gibi): Do a late check of server group policy as
2987                 # parallel scheduling could violate such policy. This will
2988                 # cause the evacuate to fail as rebuild does not implement
2989                 # reschedule.
2990                 hints = self._get_scheduler_hints({}, request_spec)
2991                 self._validate_instance_group_policy(context, instance, hints)
2992 
2993             # TODO(mriedem): Rename the supports_recreate driver capability
2994             # to supports_evacuate.
2995             if not self.driver.capabilities.get("supports_recreate", False):
2996                 raise exception.InstanceRecreateNotSupported
2997 
2998             self._check_instance_exists(context, instance)
2999 
3000             if on_shared_storage is None:
3001                 LOG.debug('on_shared_storage is not provided, using driver '
3002                           'information to decide if the instance needs to '
3003                           'be evacuated')
3004                 on_shared_storage = self.driver.instance_on_disk(instance)
3005 
3006             elif (on_shared_storage !=
3007                     self.driver.instance_on_disk(instance)):
3008                 # To cover case when admin expects that instance files are
3009                 # on shared storage, but not accessible and vice versa
3010                 raise exception.InvalidSharedStorage(
3011                         _("Invalid state of instance files on shared"
3012                             " storage"))
3013 
3014             if on_shared_storage:
3015                 LOG.info('disk on shared storage, evacuating using'
3016                          ' existing disk')
3017             else:
3018                 image_ref = orig_image_ref = instance.image_ref
3019                 LOG.info("disk not on shared storage, evacuating from:"
3020                          " '%s'", str(image_ref))
3021 
3022         if image_ref:
3023             image_meta = objects.ImageMeta.from_image_ref(
3024                 context, self.image_api, image_ref)
3025         else:
3026             image_meta = instance.image_meta
3027 
3028         # This instance.exists message should contain the original
3029         # image_ref, not the new one.  Since the DB has been updated
3030         # to point to the new one... we have to override it.
3031         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
3032                                                                context)
3033         extra_usage_info = {'image_ref_url': orig_image_ref_url}
3034         compute_utils.notify_usage_exists(
3035                 self.notifier, context, instance,
3036                 current_period=True, system_metadata=orig_sys_metadata,
3037                 extra_usage_info=extra_usage_info)
3038 
3039         # This message should contain the new image_ref
3040         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
3041         self._notify_about_instance_usage(context, instance,
3042                 "rebuild.start", extra_usage_info=extra_usage_info)
3043         # NOTE: image_name is not included in the versioned notification
3044         # because we already provide the image_uuid in the notification
3045         # payload and the image details can be looked up via the uuid.
3046         compute_utils.notify_about_instance_action(
3047             context, instance, self.host,
3048             action=fields.NotificationAction.REBUILD,
3049             phase=fields.NotificationPhase.START,
3050             bdms=bdms)
3051 
3052         instance.power_state = self._get_power_state(context, instance)
3053         instance.task_state = task_states.REBUILDING
3054         instance.save(expected_task_state=[task_states.REBUILDING])
3055 
3056         if evacuate:
3057             self.network_api.setup_networks_on_host(
3058                     context, instance, self.host)
3059             # For nova-network this is needed to move floating IPs
3060             # For neutron this updates the host in the port binding
3061             # TODO(cfriesen): this network_api call and the one above
3062             # are so similar, we should really try to unify them.
3063             self.network_api.setup_instance_network_on_host(
3064                     context, instance, self.host, migration)
3065 
3066         allocations = self.reportclient.get_allocations_for_consumer(
3067             context, instance.uuid)
3068 
3069         network_info = instance.get_network_info()
3070         if bdms is None:
3071             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3072                     context, instance.uuid)
3073 
3074         block_device_info = \
3075             self._get_instance_block_device_info(
3076                     context, instance, bdms=bdms)
3077 
3078         def detach_block_devices(context, bdms):
3079             for bdm in bdms:
3080                 if bdm.is_volume:
3081                     # NOTE (ildikov): Having the attachment_id set in the BDM
3082                     # means that it's the new Cinder attach/detach flow
3083                     # (available from v3.44). In that case we explicitly
3084                     # attach and detach the volumes through attachment level
3085                     # operations. In this scenario _detach_volume will delete
3086                     # the existing attachment which would make the volume
3087                     # status change to 'available' if we don't pre-create
3088                     # another empty attachment before deleting the old one.
3089                     attachment_id = None
3090                     if bdm.attachment_id:
3091                         attachment_id = self.volume_api.attachment_create(
3092                             context, bdm['volume_id'], instance.uuid)['id']
3093                     self._detach_volume(context, bdm, instance,
3094                                         destroy_bdm=False)
3095                     if attachment_id:
3096                         bdm.attachment_id = attachment_id
3097                         bdm.save()
3098 
3099         files = self._decode_files(injected_files)
3100 
3101         # TODO(mriedem): Rename recreate->evacuate in the driver rebuild
3102         # method signature.
3103         kwargs = dict(
3104             context=context,
3105             instance=instance,
3106             image_meta=image_meta,
3107             injected_files=files,
3108             admin_password=new_pass,
3109             allocations=allocations,
3110             bdms=bdms,
3111             detach_block_devices=detach_block_devices,
3112             attach_block_devices=self._prep_block_device,
3113             block_device_info=block_device_info,
3114             network_info=network_info,
3115             preserve_ephemeral=preserve_ephemeral,
3116             recreate=evacuate)
3117         try:
3118             with instance.mutated_migration_context():
3119                 self.driver.rebuild(**kwargs)
3120         except NotImplementedError:
3121             # NOTE(rpodolyaka): driver doesn't provide specialized version
3122             # of rebuild, fall back to the default implementation
3123             self._rebuild_default_impl(**kwargs)
3124         self._update_instance_after_spawn(context, instance)
3125         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3126 
3127         if orig_vm_state == vm_states.STOPPED:
3128             LOG.info("bringing vm to original state: '%s'",
3129                      orig_vm_state, instance=instance)
3130             instance.vm_state = vm_states.ACTIVE
3131             instance.task_state = task_states.POWERING_OFF
3132             instance.progress = 0
3133             instance.save()
3134             self.stop_instance(context, instance, False)
3135         self._update_scheduler_instance_info(context, instance)
3136         self._notify_about_instance_usage(
3137                 context, instance, "rebuild.end",
3138                 network_info=network_info,
3139                 extra_usage_info=extra_usage_info)
3140         compute_utils.notify_about_instance_action(
3141             context, instance, self.host,
3142             action=fields.NotificationAction.REBUILD,
3143             phase=fields.NotificationPhase.END,
3144             bdms=bdms)
3145 
3146     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3147                                      block_device_info):
3148         """Handle cases where the virt-layer had to detach non-working volumes
3149         in order to complete an operation.
3150         """
3151         for bdm in block_device_info['block_device_mapping']:
3152             if bdm.get('mount_device') in bad_devices:
3153                 try:
3154                     volume_id = bdm['connection_info']['data']['volume_id']
3155                 except KeyError:
3156                     continue
3157 
3158                 # NOTE(sirp): ideally we'd just call
3159                 # `compute_api.detach_volume` here but since that hits the
3160                 # DB directly, that's off limits from within the
3161                 # compute-manager.
3162                 #
3163                 # API-detach
3164                 LOG.info("Detaching from volume api: %s", volume_id)
3165                 self.volume_api.begin_detaching(context, volume_id)
3166 
3167                 # Manager-detach
3168                 self.detach_volume(context, volume_id, instance)
3169 
3170     @wrap_exception()
3171     @reverts_task_state
3172     @wrap_instance_event(prefix='compute')
3173     @wrap_instance_fault
3174     def reboot_instance(self, context, instance, block_device_info,
3175                         reboot_type):
3176         """Reboot an instance on this host."""
3177         # acknowledge the request made it to the manager
3178         if reboot_type == "SOFT":
3179             instance.task_state = task_states.REBOOT_PENDING
3180             expected_states = task_states.soft_reboot_states
3181         else:
3182             instance.task_state = task_states.REBOOT_PENDING_HARD
3183             expected_states = task_states.hard_reboot_states
3184 
3185         context = context.elevated()
3186         LOG.info("Rebooting instance", instance=instance)
3187 
3188         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3189             context, instance.uuid)
3190         block_device_info = self._get_instance_block_device_info(
3191             context, instance, bdms=bdms)
3192 
3193         network_info = self.network_api.get_instance_nw_info(context, instance)
3194 
3195         self._notify_about_instance_usage(context, instance, "reboot.start")
3196         compute_utils.notify_about_instance_action(
3197             context, instance, self.host,
3198             action=fields.NotificationAction.REBOOT,
3199             phase=fields.NotificationPhase.START,
3200             bdms=bdms
3201         )
3202 
3203         instance.power_state = self._get_power_state(context, instance)
3204         instance.save(expected_task_state=expected_states)
3205 
3206         if instance.power_state != power_state.RUNNING:
3207             state = instance.power_state
3208             running = power_state.RUNNING
3209             LOG.warning('trying to reboot a non-running instance:'
3210                         ' (state: %(state)s expected: %(running)s)',
3211                         {'state': state, 'running': running},
3212                         instance=instance)
3213 
3214         def bad_volumes_callback(bad_devices):
3215             self._handle_bad_volumes_detached(
3216                     context, instance, bad_devices, block_device_info)
3217 
3218         try:
3219             # Don't change it out of rescue mode
3220             if instance.vm_state == vm_states.RESCUED:
3221                 new_vm_state = vm_states.RESCUED
3222             else:
3223                 new_vm_state = vm_states.ACTIVE
3224             new_power_state = None
3225             if reboot_type == "SOFT":
3226                 instance.task_state = task_states.REBOOT_STARTED
3227                 expected_state = task_states.REBOOT_PENDING
3228             else:
3229                 instance.task_state = task_states.REBOOT_STARTED_HARD
3230                 expected_state = task_states.REBOOT_PENDING_HARD
3231             instance.save(expected_task_state=expected_state)
3232             self.driver.reboot(context, instance,
3233                                network_info,
3234                                reboot_type,
3235                                block_device_info=block_device_info,
3236                                bad_volumes_callback=bad_volumes_callback)
3237 
3238         except Exception as error:
3239             with excutils.save_and_reraise_exception() as ctxt:
3240                 exc_info = sys.exc_info()
3241                 # if the reboot failed but the VM is running don't
3242                 # put it into an error state
3243                 new_power_state = self._get_power_state(context, instance)
3244                 if new_power_state == power_state.RUNNING:
3245                     LOG.warning('Reboot failed but instance is running',
3246                                 instance=instance)
3247                     compute_utils.add_instance_fault_from_exc(context,
3248                             instance, error, exc_info)
3249                     self._notify_about_instance_usage(context, instance,
3250                             'reboot.error', fault=error)
3251                     compute_utils.notify_about_instance_action(
3252                         context, instance, self.host,
3253                         action=fields.NotificationAction.REBOOT,
3254                         phase=fields.NotificationPhase.ERROR,
3255                         exception=error, bdms=bdms
3256                     )
3257                     ctxt.reraise = False
3258                 else:
3259                     LOG.error('Cannot reboot instance: %s', error,
3260                               instance=instance)
3261                     self._set_instance_obj_error_state(context, instance)
3262 
3263         if not new_power_state:
3264             new_power_state = self._get_power_state(context, instance)
3265         try:
3266             instance.power_state = new_power_state
3267             instance.vm_state = new_vm_state
3268             instance.task_state = None
3269             instance.save()
3270         except exception.InstanceNotFound:
3271             LOG.warning("Instance disappeared during reboot",
3272                         instance=instance)
3273 
3274         self._notify_about_instance_usage(context, instance, "reboot.end")
3275         compute_utils.notify_about_instance_action(
3276             context, instance, self.host,
3277             action=fields.NotificationAction.REBOOT,
3278             phase=fields.NotificationPhase.END,
3279             bdms=bdms
3280         )
3281 
3282     @delete_image_on_error
3283     def _do_snapshot_instance(self, context, image_id, instance):
3284         self._snapshot_instance(context, image_id, instance,
3285                                 task_states.IMAGE_BACKUP)
3286 
3287     @wrap_exception()
3288     @reverts_task_state
3289     @wrap_instance_event(prefix='compute')
3290     @wrap_instance_fault
3291     def backup_instance(self, context, image_id, instance, backup_type,
3292                         rotation):
3293         """Backup an instance on this host.
3294 
3295         :param backup_type: daily | weekly
3296         :param rotation: int representing how many backups to keep around
3297         """
3298         self._do_snapshot_instance(context, image_id, instance)
3299         self._rotate_backups(context, instance, backup_type, rotation)
3300 
3301     @wrap_exception()
3302     @reverts_task_state
3303     @wrap_instance_event(prefix='compute')
3304     @wrap_instance_fault
3305     @delete_image_on_error
3306     def snapshot_instance(self, context, image_id, instance):
3307         """Snapshot an instance on this host.
3308 
3309         :param context: security context
3310         :param image_id: glance.db.sqlalchemy.models.Image.Id
3311         :param instance: a nova.objects.instance.Instance object
3312         """
3313         # NOTE(dave-mcnally) the task state will already be set by the api
3314         # but if the compute manager has crashed/been restarted prior to the
3315         # request getting here the task state may have been cleared so we set
3316         # it again and things continue normally
3317         try:
3318             instance.task_state = task_states.IMAGE_SNAPSHOT
3319             instance.save(
3320                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3321         except exception.InstanceNotFound:
3322             # possibility instance no longer exists, no point in continuing
3323             LOG.debug("Instance not found, could not set state %s "
3324                       "for instance.",
3325                       task_states.IMAGE_SNAPSHOT, instance=instance)
3326             return
3327 
3328         except exception.UnexpectedDeletingTaskStateError:
3329             LOG.debug("Instance being deleted, snapshot cannot continue",
3330                       instance=instance)
3331             return
3332 
3333         self._snapshot_instance(context, image_id, instance,
3334                                 task_states.IMAGE_SNAPSHOT)
3335 
3336     def _snapshot_instance(self, context, image_id, instance,
3337                            expected_task_state):
3338         context = context.elevated()
3339 
3340         instance.power_state = self._get_power_state(context, instance)
3341         try:
3342             instance.save()
3343 
3344             LOG.info('instance snapshotting', instance=instance)
3345 
3346             if instance.power_state != power_state.RUNNING:
3347                 state = instance.power_state
3348                 running = power_state.RUNNING
3349                 LOG.warning('trying to snapshot a non-running instance: '
3350                             '(state: %(state)s expected: %(running)s)',
3351                             {'state': state, 'running': running},
3352                             instance=instance)
3353 
3354             self._notify_about_instance_usage(
3355                 context, instance, "snapshot.start")
3356             compute_utils.notify_about_instance_snapshot(context, instance,
3357                 self.host, phase=fields.NotificationPhase.START,
3358                 snapshot_image_id=image_id)
3359 
3360             def update_task_state(task_state,
3361                                   expected_state=expected_task_state):
3362                 instance.task_state = task_state
3363                 instance.save(expected_task_state=expected_state)
3364 
3365             with timeutils.StopWatch() as timer:
3366                 self.driver.snapshot(context, instance, image_id,
3367                                      update_task_state)
3368             LOG.info('Took %0.2f seconds to snapshot the instance on '
3369                      'the hypervisor.', timer.elapsed(), instance=instance)
3370 
3371             instance.task_state = None
3372             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3373 
3374             self._notify_about_instance_usage(context, instance,
3375                                               "snapshot.end")
3376             compute_utils.notify_about_instance_snapshot(context, instance,
3377                 self.host, phase=fields.NotificationPhase.END,
3378                 snapshot_image_id=image_id)
3379         except (exception.InstanceNotFound,
3380                 exception.UnexpectedDeletingTaskStateError):
3381             # the instance got deleted during the snapshot
3382             # Quickly bail out of here
3383             msg = 'Instance disappeared during snapshot'
3384             LOG.debug(msg, instance=instance)
3385             try:
3386                 image = self.image_api.get(context, image_id)
3387                 if image['status'] != 'active':
3388                     self.image_api.delete(context, image_id)
3389             except Exception:
3390                 LOG.warning("Error while trying to clean up image %s",
3391                             image_id, instance=instance)
3392         except exception.ImageNotFound:
3393             instance.task_state = None
3394             instance.save()
3395             LOG.warning("Image not found during snapshot", instance=instance)
3396 
3397     def _post_interrupted_snapshot_cleanup(self, context, instance):
3398         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3399 
3400     @messaging.expected_exceptions(NotImplementedError)
3401     @wrap_exception()
3402     def volume_snapshot_create(self, context, instance, volume_id,
3403                                create_info):
3404         self.driver.volume_snapshot_create(context, instance, volume_id,
3405                                            create_info)
3406 
3407     @messaging.expected_exceptions(NotImplementedError)
3408     @wrap_exception()
3409     def volume_snapshot_delete(self, context, instance, volume_id,
3410                                snapshot_id, delete_info):
3411         self.driver.volume_snapshot_delete(context, instance, volume_id,
3412                                            snapshot_id, delete_info)
3413 
3414     @wrap_instance_fault
3415     def _rotate_backups(self, context, instance, backup_type, rotation):
3416         """Delete excess backups associated to an instance.
3417 
3418         Instances are allowed a fixed number of backups (the rotation number);
3419         this method deletes the oldest backups that exceed the rotation
3420         threshold.
3421 
3422         :param context: security context
3423         :param instance: Instance dict
3424         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3425         :param rotation: int representing how many backups to keep around;
3426             None if rotation shouldn't be used (as in the case of snapshots)
3427         """
3428         filters = {'property-image_type': 'backup',
3429                    'property-backup_type': backup_type,
3430                    'property-instance_uuid': instance.uuid}
3431 
3432         images = self.image_api.get_all(context, filters=filters,
3433                                         sort_key='created_at', sort_dir='desc')
3434         num_images = len(images)
3435         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3436                   {'num_images': num_images, 'rotation': rotation},
3437                   instance=instance)
3438 
3439         if num_images > rotation:
3440             # NOTE(sirp): this deletes all backups that exceed the rotation
3441             # limit
3442             excess = len(images) - rotation
3443             LOG.debug("Rotating out %d backups", excess,
3444                       instance=instance)
3445             for i in range(excess):
3446                 image = images.pop()
3447                 image_id = image['id']
3448                 LOG.debug("Deleting image %s", image_id,
3449                           instance=instance)
3450                 try:
3451                     self.image_api.delete(context, image_id)
3452                 except exception.ImageNotFound:
3453                     LOG.info("Failed to find image %(image_id)s to "
3454                              "delete", {'image_id': image_id},
3455                              instance=instance)
3456                 except (exception.ImageDeleteConflict, Exception) as exc:
3457                     LOG.info("Failed to delete image %(image_id)s during "
3458                              "deleting excess backups. "
3459                              "Continuing for next image.. %(exc)s",
3460                              {'image_id': image_id, 'exc': exc},
3461                              instance=instance)
3462 
3463     @wrap_exception()
3464     @reverts_task_state
3465     @wrap_instance_event(prefix='compute')
3466     @wrap_instance_fault
3467     def set_admin_password(self, context, instance, new_pass):
3468         """Set the root/admin password for an instance on this host.
3469 
3470         This is generally only called by API password resets after an
3471         image has been built.
3472 
3473         @param context: Nova auth context.
3474         @param instance: Nova instance object.
3475         @param new_pass: The admin password for the instance.
3476         """
3477 
3478         context = context.elevated()
3479         if new_pass is None:
3480             # Generate a random password
3481             new_pass = utils.generate_password()
3482 
3483         current_power_state = self._get_power_state(context, instance)
3484         expected_state = power_state.RUNNING
3485 
3486         if current_power_state != expected_state:
3487             instance.task_state = None
3488             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3489             _msg = _('instance %s is not running') % instance.uuid
3490             raise exception.InstancePasswordSetFailed(
3491                 instance=instance.uuid, reason=_msg)
3492 
3493         try:
3494             self.driver.set_admin_password(instance, new_pass)
3495             LOG.info("Admin password set", instance=instance)
3496             instance.task_state = None
3497             instance.save(
3498                 expected_task_state=task_states.UPDATING_PASSWORD)
3499         except exception.InstanceAgentNotEnabled:
3500             with excutils.save_and_reraise_exception():
3501                 LOG.debug('Guest agent is not enabled for the instance.',
3502                           instance=instance)
3503                 instance.task_state = None
3504                 instance.save(
3505                     expected_task_state=task_states.UPDATING_PASSWORD)
3506         except exception.SetAdminPasswdNotSupported:
3507             with excutils.save_and_reraise_exception():
3508                 LOG.info('set_admin_password is not supported '
3509                          'by this driver or guest instance.',
3510                          instance=instance)
3511                 instance.task_state = None
3512                 instance.save(
3513                     expected_task_state=task_states.UPDATING_PASSWORD)
3514         except NotImplementedError:
3515             LOG.warning('set_admin_password is not implemented '
3516                         'by this driver or guest instance.',
3517                         instance=instance)
3518             instance.task_state = None
3519             instance.save(
3520                 expected_task_state=task_states.UPDATING_PASSWORD)
3521             raise NotImplementedError(_('set_admin_password is not '
3522                                         'implemented by this driver or guest '
3523                                         'instance.'))
3524         except exception.UnexpectedTaskStateError:
3525             # interrupted by another (most likely delete) task
3526             # do not retry
3527             raise
3528         except Exception:
3529             # Catch all here because this could be anything.
3530             LOG.exception('set_admin_password failed', instance=instance)
3531             self._set_instance_obj_error_state(context, instance)
3532             # We create a new exception here so that we won't
3533             # potentially reveal password information to the
3534             # API caller.  The real exception is logged above
3535             _msg = _('error setting admin password')
3536             raise exception.InstancePasswordSetFailed(
3537                 instance=instance.uuid, reason=_msg)
3538 
3539     @wrap_exception()
3540     @reverts_task_state
3541     @wrap_instance_fault
3542     def inject_file(self, context, path, file_contents, instance):
3543         """Write a file to the specified path in an instance on this host."""
3544         # NOTE(russellb) Remove this method, as well as the underlying virt
3545         # driver methods, when the compute rpc interface is bumped to 4.x
3546         # as it is no longer used.
3547         context = context.elevated()
3548         current_power_state = self._get_power_state(context, instance)
3549         expected_state = power_state.RUNNING
3550         if current_power_state != expected_state:
3551             LOG.warning('trying to inject a file into a non-running '
3552                         '(state: %(current_state)s expected: '
3553                         '%(expected_state)s)',
3554                         {'current_state': current_power_state,
3555                          'expected_state': expected_state},
3556                         instance=instance)
3557         LOG.info('injecting file to %s', path, instance=instance)
3558         self.driver.inject_file(instance, path, file_contents)
3559 
3560     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3561         """Determine what image should be used to boot the rescue VM."""
3562         # 1. If rescue_image_ref is passed in, use that for rescue.
3563         # 2. Else, use the base image associated with instance's current image.
3564         #       The idea here is to provide the customer with a rescue
3565         #       environment which they are familiar with.
3566         #       So, if they built their instance off of a Debian image,
3567         #       their rescue VM will also be Debian.
3568         # 3. As a last resort, use instance's current image.
3569         if not rescue_image_ref:
3570             system_meta = utils.instance_sys_meta(instance)
3571             rescue_image_ref = system_meta.get('image_base_image_ref')
3572 
3573         if not rescue_image_ref:
3574             LOG.warning('Unable to find a different image to use for '
3575                         'rescue VM, using instance\'s current image',
3576                         instance=instance)
3577             rescue_image_ref = instance.image_ref
3578 
3579         return objects.ImageMeta.from_image_ref(
3580             context, self.image_api, rescue_image_ref)
3581 
3582     @wrap_exception()
3583     @reverts_task_state
3584     @wrap_instance_event(prefix='compute')
3585     @wrap_instance_fault
3586     def rescue_instance(self, context, instance, rescue_password,
3587                         rescue_image_ref, clean_shutdown):
3588         context = context.elevated()
3589         LOG.info('Rescuing', instance=instance)
3590 
3591         admin_password = (rescue_password if rescue_password else
3592                       utils.generate_password())
3593 
3594         network_info = self.network_api.get_instance_nw_info(context, instance)
3595 
3596         rescue_image_meta = self._get_rescue_image(context, instance,
3597                                                    rescue_image_ref)
3598 
3599         extra_usage_info = {'rescue_image_name':
3600                             self._get_image_name(rescue_image_meta)}
3601         self._notify_about_instance_usage(context, instance,
3602                 "rescue.start", extra_usage_info=extra_usage_info,
3603                 network_info=network_info)
3604         compute_utils.notify_about_instance_rescue_action(
3605             context, instance, self.host, rescue_image_ref,
3606             phase=fields.NotificationPhase.START)
3607 
3608         try:
3609             self._power_off_instance(context, instance, clean_shutdown)
3610 
3611             self.driver.rescue(context, instance,
3612                                network_info,
3613                                rescue_image_meta, admin_password)
3614         except Exception as e:
3615             LOG.exception("Error trying to Rescue Instance",
3616                           instance=instance)
3617             self._set_instance_obj_error_state(context, instance)
3618             raise exception.InstanceNotRescuable(
3619                 instance_id=instance.uuid,
3620                 reason=_("Driver Error: %s") % e)
3621 
3622         compute_utils.notify_usage_exists(self.notifier, context, instance,
3623                                           current_period=True)
3624 
3625         instance.vm_state = vm_states.RESCUED
3626         instance.task_state = None
3627         instance.power_state = self._get_power_state(context, instance)
3628         instance.launched_at = timeutils.utcnow()
3629         instance.save(expected_task_state=task_states.RESCUING)
3630 
3631         self._notify_about_instance_usage(context, instance,
3632                 "rescue.end", extra_usage_info=extra_usage_info,
3633                 network_info=network_info)
3634         compute_utils.notify_about_instance_rescue_action(
3635             context, instance, self.host, rescue_image_ref,
3636             phase=fields.NotificationPhase.END)
3637 
3638     @wrap_exception()
3639     @reverts_task_state
3640     @wrap_instance_event(prefix='compute')
3641     @wrap_instance_fault
3642     def unrescue_instance(self, context, instance):
3643         context = context.elevated()
3644         LOG.info('Unrescuing', instance=instance)
3645 
3646         network_info = self.network_api.get_instance_nw_info(context, instance)
3647         self._notify_about_instance_usage(context, instance,
3648                 "unrescue.start", network_info=network_info)
3649         compute_utils.notify_about_instance_action(context, instance,
3650             self.host, action=fields.NotificationAction.UNRESCUE,
3651             phase=fields.NotificationPhase.START)
3652 
3653         with self._error_out_instance_on_exception(context, instance):
3654             self.driver.unrescue(instance,
3655                                  network_info)
3656 
3657         instance.vm_state = vm_states.ACTIVE
3658         instance.task_state = None
3659         instance.power_state = self._get_power_state(context, instance)
3660         instance.save(expected_task_state=task_states.UNRESCUING)
3661 
3662         self._notify_about_instance_usage(context,
3663                                           instance,
3664                                           "unrescue.end",
3665                                           network_info=network_info)
3666         compute_utils.notify_about_instance_action(context, instance,
3667             self.host, action=fields.NotificationAction.UNRESCUE,
3668             phase=fields.NotificationPhase.END)
3669 
3670     @wrap_exception()
3671     @wrap_instance_fault
3672     def change_instance_metadata(self, context, diff, instance):
3673         """Update the metadata published to the instance."""
3674         LOG.debug("Changing instance metadata according to %r",
3675                   diff, instance=instance)
3676         self.driver.change_instance_metadata(context, instance, diff)
3677 
3678     @wrap_exception()
3679     @wrap_instance_event(prefix='compute')
3680     @wrap_instance_fault
3681     def confirm_resize(self, context, instance, migration):
3682         """Confirms a migration/resize and deletes the 'old' instance.
3683 
3684         This is called from the API and runs on the source host.
3685 
3686         Nothing needs to happen on the destination host at this point since
3687         the instance is already running there. This routine just cleans up the
3688         source host.
3689         """
3690         @utils.synchronized(instance.uuid)
3691         def do_confirm_resize(context, instance, migration_id):
3692             # NOTE(wangpan): Get the migration status from db, if it has been
3693             #                confirmed, we do nothing and return here
3694             LOG.debug("Going to confirm migration %s", migration_id,
3695                       instance=instance)
3696             try:
3697                 # TODO(russellb) Why are we sending the migration object just
3698                 # to turn around and look it up from the db again?
3699                 migration = objects.Migration.get_by_id(
3700                                     context.elevated(), migration_id)
3701             except exception.MigrationNotFound:
3702                 LOG.error("Migration %s is not found during confirmation",
3703                           migration_id, instance=instance)
3704                 return
3705 
3706             if migration.status == 'confirmed':
3707                 LOG.info("Migration %s is already confirmed",
3708                          migration_id, instance=instance)
3709                 return
3710             elif migration.status not in ('finished', 'confirming'):
3711                 LOG.warning("Unexpected confirmation status '%(status)s' "
3712                             "of migration %(id)s, exit confirmation process",
3713                             {"status": migration.status, "id": migration_id},
3714                             instance=instance)
3715                 return
3716 
3717             # NOTE(wangpan): Get the instance from db, if it has been
3718             #                deleted, we do nothing and return here
3719             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3720             try:
3721                 instance = objects.Instance.get_by_uuid(
3722                         context, instance.uuid,
3723                         expected_attrs=expected_attrs)
3724             except exception.InstanceNotFound:
3725                 LOG.info("Instance is not found during confirmation",
3726                          instance=instance)
3727                 return
3728 
3729             self._confirm_resize(context, instance, migration=migration)
3730 
3731         do_confirm_resize(context, instance, migration.id)
3732 
3733     def _confirm_resize(self, context, instance, migration=None):
3734         """Destroys the source instance."""
3735         self._notify_about_instance_usage(context, instance,
3736                                           "resize.confirm.start")
3737         compute_utils.notify_about_instance_action(context, instance,
3738             self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3739             phase=fields.NotificationPhase.START)
3740 
3741         with self._error_out_instance_on_exception(context, instance):
3742             # NOTE(danms): delete stashed migration information
3743             old_instance_type = instance.old_flavor
3744             instance.old_flavor = None
3745             instance.new_flavor = None
3746             instance.system_metadata.pop('old_vm_state', None)
3747             instance.save()
3748 
3749             # NOTE(tr3buchet): tear down networks on source host
3750             self.network_api.setup_networks_on_host(context, instance,
3751                                migration.source_compute, teardown=True)
3752 
3753             network_info = self.network_api.get_instance_nw_info(context,
3754                                                                  instance)
3755             # TODO(mriedem): Get BDMs here and pass them to the driver.
3756             self.driver.confirm_migration(context, migration, instance,
3757                                           network_info)
3758 
3759             migration.status = 'confirmed'
3760             with migration.obj_as_admin():
3761                 migration.save()
3762 
3763             rt = self._get_resource_tracker()
3764             rt.drop_move_claim(context, instance, migration.source_node,
3765                                old_instance_type, prefix='old_')
3766             self._delete_allocation_after_move(context, instance, migration,
3767                                                old_instance_type,
3768                                                migration.source_node)
3769             instance.drop_migration_context()
3770 
3771             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3772             # might have manually powered up the instance to confirm the
3773             # resize/migrate, so we need to check the current power state
3774             # on the instance and set the vm_state appropriately. We default
3775             # to ACTIVE because if the power state is not SHUTDOWN, we
3776             # assume _sync_instance_power_state will clean it up.
3777             p_state = instance.power_state
3778             vm_state = None
3779             if p_state == power_state.SHUTDOWN:
3780                 vm_state = vm_states.STOPPED
3781                 LOG.debug("Resized/migrated instance is powered off. "
3782                           "Setting vm_state to '%s'.", vm_state,
3783                           instance=instance)
3784             else:
3785                 vm_state = vm_states.ACTIVE
3786 
3787             instance.vm_state = vm_state
3788             instance.task_state = None
3789             instance.save(expected_task_state=[None, task_states.DELETING])
3790 
3791             self._notify_about_instance_usage(
3792                 context, instance, "resize.confirm.end",
3793                 network_info=network_info)
3794             compute_utils.notify_about_instance_action(context, instance,
3795                    self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3796                    phase=fields.NotificationPhase.END)
3797 
3798     def _delete_allocation_after_move(self, context, instance, migration,
3799                                       flavor, nodename):
3800         rt = self._get_resource_tracker()
3801         cn_uuid = rt.get_node_uuid(nodename)
3802 
3803         if migration.source_node == nodename:
3804             if migration.status in ('confirmed', 'completed'):
3805                 # NOTE(danms): We're finishing on the source node, so try to
3806                 # delete the allocation based on the migration uuid
3807                 deleted = self.reportclient.delete_allocation_for_instance(
3808                     context, migration.uuid)
3809                 if deleted:
3810                     LOG.info(_('Source node %(node)s confirmed migration '
3811                                '%(mig)s; deleted migration-based '
3812                                'allocation'),
3813                              {'node': nodename, 'mig': migration.uuid})
3814                     # NOTE(danms): We succeeded, which means we do not
3815                     # need to do the complex double allocation dance
3816                     return
3817             else:
3818                 # We're reverting (or failed) on the source, so we
3819                 # need to check if our migration holds a claim and if
3820                 # so, avoid doing the legacy behavior below.
3821                 mig_allocs = (
3822                     self.reportclient.get_allocations_for_consumer_by_provider(
3823                         context, cn_uuid, migration.uuid))
3824                 if mig_allocs:
3825                     LOG.info(_('Source node %(node)s reverted migration '
3826                                '%(mig)s; not deleting migration-based '
3827                                'allocation'),
3828                              {'node': nodename, 'mig': migration.uuid})
3829                     return
3830         elif migration.dest_node == nodename:
3831             # NOTE(danms): We're reverting on the destination node
3832             # (and we must not be doing a same-host migration if we
3833             # made it past the check above), so we need to check to
3834             # see if the source did migration-based allocation
3835             # accounting
3836             allocs = (
3837                 self.reportclient.get_allocations_for_consumer_by_provider(
3838                     context, cn_uuid, migration.uuid))
3839             if allocs:
3840                 # NOTE(danms): The source did migration-based allocation
3841                 # accounting, so we should let the source node rejigger
3842                 # the allocations in finish_resize_revert()
3843                 LOG.info(_('Destination node %(node)s reverted migration '
3844                            '%(mig)s; not deleting migration-based '
3845                            'allocation'),
3846                          {'node': nodename, 'mig': migration.uuid})
3847                 return
3848 
3849         # TODO(danms): Remove below this line when we remove compatibility
3850         # for double-accounting migrations (likely rocky)
3851         LOG.info(_('Doing legacy allocation math for migration %(mig)s after '
3852                    'instance move'),
3853                  {'mig': migration.uuid},
3854                  instance=instance)
3855 
3856         # NOTE(jaypipes): This sucks, but due to the fact that confirm_resize()
3857         # only runs on the source host and revert_resize() runs on the
3858         # destination host, we need to do this here. Basically, what we're
3859         # doing here is grabbing the existing allocations for this instance
3860         # from the placement API, dropping the resources in the doubled-up
3861         # allocation set that refer to the source host UUID and calling PUT
3862         # /allocations back to the placement API. The allocation that gets
3863         # PUT'd back to placement will only include the destination host and
3864         # any shared providers in the case of a confirm_resize operation and
3865         # the source host and shared providers for a revert_resize operation..
3866         if not scheduler_utils.remove_allocation_from_compute(
3867                 context, instance, cn_uuid, self.reportclient, flavor):
3868             LOG.error("Failed to save manipulated allocation",
3869                       instance=instance)
3870 
3871     @wrap_exception()
3872     @reverts_task_state
3873     @wrap_instance_event(prefix='compute')
3874     @errors_out_migration
3875     @wrap_instance_fault
3876     def revert_resize(self, context, instance, migration):
3877         """Destroys the new instance on the destination machine.
3878 
3879         Reverts the model changes, and powers on the old instance on the
3880         source machine.
3881 
3882         """
3883         # NOTE(comstud): A revert_resize is essentially a resize back to
3884         # the old size, so we need to send a usage event here.
3885         compute_utils.notify_usage_exists(self.notifier, context, instance,
3886                                           current_period=True)
3887 
3888         with self._error_out_instance_on_exception(context, instance):
3889             # NOTE(tr3buchet): tear down networks on destination host
3890             self.network_api.setup_networks_on_host(context, instance,
3891                                                     teardown=True)
3892 
3893             migration_p = obj_base.obj_to_primitive(migration)
3894             self.network_api.migrate_instance_start(context,
3895                                                     instance,
3896                                                     migration_p)
3897 
3898             network_info = self.network_api.get_instance_nw_info(context,
3899                                                                  instance)
3900             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3901                     context, instance.uuid)
3902             block_device_info = self._get_instance_block_device_info(
3903                                 context, instance, bdms=bdms)
3904 
3905             destroy_disks = not self._is_instance_storage_shared(
3906                 context, instance, host=migration.source_compute)
3907             self.driver.destroy(context, instance, network_info,
3908                                 block_device_info, destroy_disks)
3909 
3910             self._terminate_volume_connections(context, instance, bdms)
3911 
3912             migration.status = 'reverted'
3913             with migration.obj_as_admin():
3914                 migration.save()
3915 
3916             # NOTE(ndipanov): We need to do this here because dropping the
3917             # claim means we lose the migration_context data. We really should
3918             # fix this by moving the drop_move_claim call to the
3919             # finish_revert_resize method as this is racy (revert is dropped,
3920             # but instance resources will be tracked with the new flavor until
3921             # it gets rolled back in finish_revert_resize, which is
3922             # potentially wrong for a period of time).
3923             instance.revert_migration_context()
3924             instance.save()
3925 
3926             rt = self._get_resource_tracker()
3927             rt.drop_move_claim(context, instance, instance.node)
3928             self._delete_allocation_after_move(context, instance, migration,
3929                                                instance.flavor,
3930                                                instance.node)
3931 
3932             # RPC cast back to the source host to finish the revert there.
3933             self.compute_rpcapi.finish_revert_resize(context, instance,
3934                     migration, migration.source_compute)
3935 
3936     @wrap_exception()
3937     @reverts_task_state
3938     @wrap_instance_event(prefix='compute')
3939     @errors_out_migration
3940     @wrap_instance_fault
3941     def finish_revert_resize(self, context, instance, migration):
3942         """Finishes the second half of reverting a resize on the source host.
3943 
3944         Bring the original source instance state back (active/shutoff) and
3945         revert the resized attributes in the database.
3946 
3947         """
3948         with self._error_out_instance_on_exception(context, instance):
3949             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3950                 context, instance.uuid)
3951             self._notify_about_instance_usage(
3952                     context, instance, "resize.revert.start")
3953             compute_utils.notify_about_instance_action(context, instance,
3954                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
3955                     phase=fields.NotificationPhase.START, bdms=bdms)
3956 
3957             # NOTE(mriedem): delete stashed old_vm_state information; we
3958             # default to ACTIVE for backwards compatibility if old_vm_state
3959             # is not set
3960             old_vm_state = instance.system_metadata.pop('old_vm_state',
3961                                                         vm_states.ACTIVE)
3962 
3963             self._set_instance_info(instance, instance.old_flavor)
3964             instance.old_flavor = None
3965             instance.new_flavor = None
3966             instance.host = migration.source_compute
3967             instance.node = migration.source_node
3968             instance.save()
3969 
3970             self._revert_allocation(context, instance, migration)
3971 
3972             self.network_api.setup_networks_on_host(context, instance,
3973                                                     migration.source_compute)
3974             migration_p = obj_base.obj_to_primitive(migration)
3975             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
3976             # source host temporarily. "network_api.migrate_instance_finish"
3977             # will setup the network for the instance on the destination host.
3978             # For revert resize, the instance will back to the source host, the
3979             # setup of the network for instance should be on the source host.
3980             # So set the migration_p['dest_compute'] to source host at here.
3981             migration_p['dest_compute'] = migration.source_compute
3982             self.network_api.migrate_instance_finish(context,
3983                                                      instance,
3984                                                      migration_p)
3985             network_info = self.network_api.get_instance_nw_info(context,
3986                                                                  instance)
3987 
3988             # revert_resize deleted any volume attachments for the instance
3989             # and created new ones to be used on this host, but we
3990             # have to update those attachments with the host connector so the
3991             # BDM.connection_info will get set in the call to
3992             # _get_instance_block_device_info below with refresh_conn_info=True
3993             # and then the volumes can be re-connected via the driver on this
3994             # host.
3995             self._update_volume_attachments(context, instance, bdms)
3996 
3997             block_device_info = self._get_instance_block_device_info(
3998                     context, instance, refresh_conn_info=True, bdms=bdms)
3999 
4000             power_on = old_vm_state != vm_states.STOPPED
4001             self.driver.finish_revert_migration(context, instance,
4002                                        network_info,
4003                                        block_device_info, power_on)
4004 
4005             instance.drop_migration_context()
4006             instance.launched_at = timeutils.utcnow()
4007             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
4008 
4009             # Complete any volume attachments so the volumes are in-use.
4010             self._complete_volume_attachments(context, bdms)
4011 
4012             # if the original vm state was STOPPED, set it back to STOPPED
4013             LOG.info("Updating instance to original state: '%s'",
4014                      old_vm_state, instance=instance)
4015             if power_on:
4016                 instance.vm_state = vm_states.ACTIVE
4017                 instance.task_state = None
4018                 instance.save()
4019             else:
4020                 instance.task_state = task_states.POWERING_OFF
4021                 instance.save()
4022                 self.stop_instance(context, instance=instance,
4023                                    clean_shutdown=True)
4024 
4025             self._notify_about_instance_usage(
4026                     context, instance, "resize.revert.end")
4027             compute_utils.notify_about_instance_action(context, instance,
4028                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4029                     phase=fields.NotificationPhase.END, bdms=bdms)
4030 
4031     def _revert_allocation(self, context, instance, migration):
4032         """Revert an allocation that is held by migration to our instance."""
4033 
4034         # Fetch the original allocation that the instance had on the source
4035         # node, which are now held by the migration
4036         orig_alloc = self.reportclient.get_allocations_for_consumer(
4037             context, migration.uuid)
4038         if not orig_alloc:
4039             # NOTE(danms): This migration did not do per-migration allocation
4040             # accounting, so nothing to do here.
4041             LOG.info('Old-style migration %(mig)s is being reverted; '
4042                      'no migration claims found on original node '
4043                      'to swap.',
4044                      {'mig': migration.uuid},
4045                      instance=instance)
4046             return False
4047 
4048         if len(orig_alloc) > 1:
4049             # NOTE(danms): This may change later if we have other allocations
4050             # against other providers that need to be held by the migration
4051             # as well. Perhaps something like shared storage resources that
4052             # will actually be duplicated during a resize type operation.
4053             LOG.error('New-style migration %(mig)s has allocations against '
4054                       'more than one provider %(rps)s. This should not be '
4055                       'possible, but reverting it anyway.',
4056                       {'mig': migration.uuid,
4057                        'rps': ','.join(orig_alloc.keys())},
4058                       instance=instance)
4059 
4060         # We only have a claim against one provider, it is the source node
4061         cn_uuid = list(orig_alloc.keys())[0]
4062 
4063         # Get just the resources part of the one allocation we need below
4064         orig_alloc = orig_alloc[cn_uuid].get('resources', {})
4065 
4066         # FIXME(danms): This method is flawed in that it asssumes allocations
4067         # against only one provider. So, this may overwite allocations against
4068         # a shared provider, if we had one.
4069         LOG.info('Swapping old allocation on %(node)s held by migration '
4070                  '%(mig)s for instance',
4071                  {'node': cn_uuid, 'mig': migration.uuid},
4072                  instance=instance)
4073         # TODO(cdent): Should we be doing anything with return values here?
4074         self.reportclient.set_and_clear_allocations(
4075             context, cn_uuid, instance.uuid, orig_alloc, instance.project_id,
4076             instance.user_id, consumer_to_clear=migration.uuid)
4077         return True
4078 
4079     def _prep_resize(self, context, image, instance, instance_type,
4080                      filter_properties, node, migration, clean_shutdown=True):
4081 
4082         if not filter_properties:
4083             filter_properties = {}
4084 
4085         if not instance.host:
4086             self._set_instance_obj_error_state(context, instance)
4087             msg = _('Instance has no source host')
4088             raise exception.MigrationError(reason=msg)
4089 
4090         same_host = instance.host == self.host
4091         # if the flavor IDs match, it's migrate; otherwise resize
4092         if same_host and instance_type.id == instance['instance_type_id']:
4093             # check driver whether support migrate to same host
4094             if not self.driver.capabilities.get(
4095                     'supports_migrate_to_same_host', False):
4096                 raise exception.UnableToMigrateToSelf(
4097                     instance_id=instance.uuid, host=self.host)
4098 
4099         # NOTE(danms): Stash the new instance_type to avoid having to
4100         # look it up in the database later
4101         instance.new_flavor = instance_type
4102         # NOTE(mriedem): Stash the old vm_state so we can set the
4103         # resized/reverted instance back to the same state later.
4104         vm_state = instance.vm_state
4105         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4106         instance.system_metadata['old_vm_state'] = vm_state
4107         instance.save()
4108 
4109         limits = filter_properties.get('limits', {})
4110         rt = self._get_resource_tracker()
4111         with rt.resize_claim(context, instance, instance_type, node,
4112                              migration, image_meta=image,
4113                              limits=limits) as claim:
4114             LOG.info('Migrating', instance=instance)
4115             # RPC cast to the source host to start the actual resize/migration.
4116             self.compute_rpcapi.resize_instance(
4117                     context, instance, claim.migration, image,
4118                     instance_type, clean_shutdown)
4119 
4120     @wrap_exception()
4121     @reverts_task_state
4122     @wrap_instance_event(prefix='compute')
4123     @wrap_instance_fault
4124     def prep_resize(self, context, image, instance, instance_type,
4125                     request_spec, filter_properties, node,
4126                     clean_shutdown, migration, host_list):
4127         """Initiates the process of moving a running instance to another host.
4128 
4129         Possibly changes the VCPU, RAM and disk size in the process.
4130 
4131         This is initiated from conductor and runs on the destination host.
4132 
4133         The main purpose of this method is performing some checks on the
4134         destination host and making a claim for resources. If the claim fails
4135         then a reschedule to another host may be attempted which involves
4136         calling back to conductor to start the process over again.
4137         """
4138         if node is None:
4139             node = self._get_nodename(instance, refresh=True)
4140 
4141         with self._error_out_instance_on_exception(context, instance), \
4142                  errors_out_migration_ctxt(migration):
4143             compute_utils.notify_usage_exists(self.notifier, context, instance,
4144                                               current_period=True)
4145             self._notify_about_instance_usage(
4146                     context, instance, "resize.prep.start")
4147             compute_utils.notify_about_resize_prep_instance(
4148                 context, instance, self.host,
4149                 fields.NotificationPhase.START, instance_type)
4150             try:
4151                 self._prep_resize(context, image, instance,
4152                                   instance_type, filter_properties,
4153                                   node, migration, clean_shutdown)
4154             except Exception:
4155                 # Since we hit a failure, we're either rescheduling or dead
4156                 # and either way we need to cleanup any allocations created
4157                 # by the scheduler for the destination node.
4158                 if migration and not self._revert_allocation(
4159                         context, instance, migration):
4160                     # We did not do a migration-based
4161                     # allocation. Note that for a resize to the
4162                     # same host, the scheduler will merge the
4163                     # flavors, so here we'd be subtracting the new
4164                     # flavor from the allocated resources on this
4165                     # node.
4166                     # FIXME(danms): Remove this in Rocky
4167                     rt = self._get_resource_tracker()
4168                     rt.delete_allocation_for_failed_resize(
4169                         instance, node, instance_type)
4170                 # try to re-schedule the resize elsewhere:
4171                 exc_info = sys.exc_info()
4172                 self._reschedule_resize_or_reraise(context, image, instance,
4173                         exc_info, instance_type, request_spec,
4174                         filter_properties, host_list)
4175             finally:
4176                 extra_usage_info = dict(
4177                         new_instance_type=instance_type.name,
4178                         new_instance_type_id=instance_type.id)
4179 
4180                 self._notify_about_instance_usage(
4181                     context, instance, "resize.prep.end",
4182                     extra_usage_info=extra_usage_info)
4183                 compute_utils.notify_about_resize_prep_instance(
4184                     context, instance, self.host,
4185                     fields.NotificationPhase.END, instance_type)
4186 
4187     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
4188             instance_type, request_spec, filter_properties, host_list):
4189         """Try to re-schedule the resize or re-raise the original error to
4190         error out the instance.
4191         """
4192         if not request_spec:
4193             request_spec = {}
4194         if not filter_properties:
4195             filter_properties = {}
4196 
4197         rescheduled = False
4198         instance_uuid = instance.uuid
4199 
4200         try:
4201             reschedule_method = self.compute_task_api.resize_instance
4202             scheduler_hint = dict(filter_properties=filter_properties)
4203             method_args = (instance, None, scheduler_hint, instance_type)
4204             task_state = task_states.RESIZE_PREP
4205 
4206             rescheduled = self._reschedule(context, request_spec,
4207                     filter_properties, instance, reschedule_method,
4208                     method_args, task_state, exc_info, host_list=host_list)
4209         except Exception as error:
4210             rescheduled = False
4211             LOG.exception("Error trying to reschedule",
4212                           instance_uuid=instance_uuid)
4213             compute_utils.add_instance_fault_from_exc(context,
4214                     instance, error,
4215                     exc_info=sys.exc_info())
4216             self._notify_about_instance_usage(context, instance,
4217                     'resize.error', fault=error)
4218             compute_utils.notify_about_instance_action(
4219                 context, instance, self.host,
4220                 action=fields.NotificationAction.RESIZE,
4221                 phase=fields.NotificationPhase.ERROR,
4222                 exception=error)
4223         if rescheduled:
4224             self._log_original_error(exc_info, instance_uuid)
4225             compute_utils.add_instance_fault_from_exc(context,
4226                     instance, exc_info[1], exc_info=exc_info)
4227             self._notify_about_instance_usage(context, instance,
4228                     'resize.error', fault=exc_info[1])
4229             compute_utils.notify_about_instance_action(
4230                 context, instance, self.host,
4231                 action=fields.NotificationAction.RESIZE,
4232                 phase=fields.NotificationPhase.ERROR,
4233                 exception=exc_info[1])
4234         else:
4235             # not re-scheduling
4236             six.reraise(*exc_info)
4237 
4238     @wrap_exception()
4239     @reverts_task_state
4240     @wrap_instance_event(prefix='compute')
4241     @wrap_instance_fault
4242     def resize_instance(self, context, instance, image,
4243                         migration, instance_type, clean_shutdown):
4244         """Starts the migration of a running instance to another host.
4245 
4246         This is initiated from the destination host's ``prep_resize`` routine
4247         and runs on the source host.
4248         """
4249         try:
4250             self._resize_instance(context, instance, image, migration,
4251                                   instance_type, clean_shutdown)
4252         except Exception:
4253             with excutils.save_and_reraise_exception():
4254                 self._revert_allocation(context, instance, migration)
4255 
4256     def _resize_instance(self, context, instance, image,
4257                          migration, instance_type, clean_shutdown):
4258         with self._error_out_instance_on_exception(context, instance), \
4259              errors_out_migration_ctxt(migration):
4260             network_info = self.network_api.get_instance_nw_info(context,
4261                                                                  instance)
4262 
4263             migration.status = 'migrating'
4264             with migration.obj_as_admin():
4265                 migration.save()
4266 
4267             instance.task_state = task_states.RESIZE_MIGRATING
4268             instance.save(expected_task_state=task_states.RESIZE_PREP)
4269 
4270             self._notify_about_instance_usage(
4271                 context, instance, "resize.start", network_info=network_info)
4272 
4273             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4274                     context, instance.uuid)
4275 
4276             compute_utils.notify_about_instance_action(context, instance,
4277                    self.host, action=fields.NotificationAction.RESIZE,
4278                    phase=fields.NotificationPhase.START, bdms=bdms)
4279 
4280             block_device_info = self._get_instance_block_device_info(
4281                                 context, instance, bdms=bdms)
4282 
4283             timeout, retry_interval = self._get_power_off_values(context,
4284                                             instance, clean_shutdown)
4285             disk_info = self.driver.migrate_disk_and_power_off(
4286                     context, instance, migration.dest_host,
4287                     instance_type, network_info,
4288                     block_device_info,
4289                     timeout, retry_interval)
4290 
4291             self._terminate_volume_connections(context, instance, bdms)
4292 
4293             migration_p = obj_base.obj_to_primitive(migration)
4294             self.network_api.migrate_instance_start(context,
4295                                                     instance,
4296                                                     migration_p)
4297 
4298             migration.status = 'post-migrating'
4299             with migration.obj_as_admin():
4300                 migration.save()
4301 
4302             instance.host = migration.dest_compute
4303             instance.node = migration.dest_node
4304             instance.task_state = task_states.RESIZE_MIGRATED
4305             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4306 
4307             # RPC cast to the destination host to finish the resize/migration.
4308             self.compute_rpcapi.finish_resize(context, instance,
4309                     migration, image, disk_info, migration.dest_compute)
4310 
4311         self._notify_about_instance_usage(context, instance, "resize.end",
4312                                           network_info=network_info)
4313 
4314         compute_utils.notify_about_instance_action(context, instance,
4315                self.host, action=fields.NotificationAction.RESIZE,
4316                phase=fields.NotificationPhase.END, bdms=bdms)
4317         self.instance_events.clear_events_for_instance(instance)
4318 
4319     def _terminate_volume_connections(self, context, instance, bdms):
4320         connector = None
4321         for bdm in bdms:
4322             if bdm.is_volume:
4323                 if bdm.attachment_id:
4324                     # NOTE(jdg): So here's the thing, the idea behind the new
4325                     # attach API's was to have a new code fork/path that we
4326                     # followed, we're not going to do that so we have to do
4327                     # some extra work in here to make it *behave* just like the
4328                     # old code. Cinder doesn't allow disconnect/reconnect (you
4329                     # just delete the attachment and get a new one)
4330                     # attachments in the new attach code so we have to do
4331                     # a delete and create without a connector (reserve),
4332                     # in other words, beware
4333                     attachment_id = self.volume_api.attachment_create(
4334                         context, bdm.volume_id, instance.uuid)['id']
4335                     self.volume_api.attachment_delete(context,
4336                                                       bdm.attachment_id)
4337                     bdm.attachment_id = attachment_id
4338                     bdm.save()
4339 
4340                 else:
4341                     if connector is None:
4342                         connector = self.driver.get_volume_connector(instance)
4343                     self.volume_api.terminate_connection(context,
4344                                                          bdm.volume_id,
4345                                                          connector)
4346 
4347     @staticmethod
4348     def _set_instance_info(instance, instance_type):
4349         instance.instance_type_id = instance_type.id
4350         instance.memory_mb = instance_type.memory_mb
4351         instance.vcpus = instance_type.vcpus
4352         instance.root_gb = instance_type.root_gb
4353         instance.ephemeral_gb = instance_type.ephemeral_gb
4354         instance.flavor = instance_type
4355 
4356     def _update_volume_attachments(self, context, instance, bdms):
4357         """Updates volume attachments using the virt driver host connector.
4358 
4359         :param context: nova.context.RequestContext - user request context
4360         :param instance: nova.objects.Instance
4361         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4362                      device mappings for the given instance
4363         """
4364         if bdms:
4365             connector = None
4366             for bdm in bdms:
4367                 if bdm.is_volume and bdm.attachment_id:
4368                     if connector is None:
4369                         connector = self.driver.get_volume_connector(instance)
4370                     self.volume_api.attachment_update(
4371                         context, bdm.attachment_id, connector, bdm.device_name)
4372 
4373     def _complete_volume_attachments(self, context, bdms):
4374         """Completes volume attachments for the instance
4375 
4376         :param context: nova.context.RequestContext - user request context
4377         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4378                      device mappings for the given instance
4379         """
4380         if bdms:
4381             for bdm in bdms:
4382                 if bdm.is_volume and bdm.attachment_id:
4383                     self.volume_api.attachment_complete(
4384                         context, bdm.attachment_id)
4385 
4386     def _finish_resize(self, context, instance, migration, disk_info,
4387                        image_meta, bdms):
4388         resize_instance = False
4389         old_instance_type_id = migration['old_instance_type_id']
4390         new_instance_type_id = migration['new_instance_type_id']
4391         old_instance_type = instance.get_flavor()
4392         # NOTE(mriedem): Get the old_vm_state so we know if we should
4393         # power on the instance. If old_vm_state is not set we need to default
4394         # to ACTIVE for backwards compatibility
4395         old_vm_state = instance.system_metadata.get('old_vm_state',
4396                                                     vm_states.ACTIVE)
4397         instance.old_flavor = old_instance_type
4398 
4399         if old_instance_type_id != new_instance_type_id:
4400             instance_type = instance.get_flavor('new')
4401             self._set_instance_info(instance, instance_type)
4402             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4403                 if old_instance_type[key] != instance_type[key]:
4404                     resize_instance = True
4405                     break
4406         instance.apply_migration_context()
4407 
4408         # NOTE(tr3buchet): setup networks on destination host
4409         self.network_api.setup_networks_on_host(context, instance,
4410                                                 migration['dest_compute'])
4411 
4412         migration_p = obj_base.obj_to_primitive(migration)
4413         self.network_api.migrate_instance_finish(context,
4414                                                  instance,
4415                                                  migration_p)
4416 
4417         network_info = self.network_api.get_instance_nw_info(context, instance)
4418 
4419         instance.task_state = task_states.RESIZE_FINISH
4420         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4421 
4422         self._notify_about_instance_usage(
4423             context, instance, "finish_resize.start",
4424             network_info=network_info)
4425         compute_utils.notify_about_instance_action(context, instance,
4426                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4427                phase=fields.NotificationPhase.START, bdms=bdms)
4428 
4429         # We need to update any volume attachments using the destination
4430         # host connector so that we can update the BDM.connection_info
4431         # before calling driver.finish_migration otherwise the driver
4432         # won't know how to connect the volumes to this host.
4433         # Note that _get_instance_block_device_info with
4434         # refresh_conn_info=True will update the BDM.connection_info value
4435         # in the database so we must do this before calling that method.
4436         self._update_volume_attachments(context, instance, bdms)
4437 
4438         block_device_info = self._get_instance_block_device_info(
4439             context, instance, refresh_conn_info=True, bdms=bdms)
4440 
4441         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4442         # automatically power on the instance after it's migrated
4443         power_on = old_vm_state != vm_states.STOPPED
4444 
4445         try:
4446             self.driver.finish_migration(context, migration, instance,
4447                                          disk_info,
4448                                          network_info,
4449                                          image_meta, resize_instance,
4450                                          block_device_info, power_on)
4451         except Exception:
4452             with excutils.save_and_reraise_exception():
4453                 if old_instance_type_id != new_instance_type_id:
4454                     self._set_instance_info(instance,
4455                                             old_instance_type)
4456 
4457         # Now complete any volume attachments that were previously updated.
4458         self._complete_volume_attachments(context, bdms)
4459 
4460         migration.status = 'finished'
4461         with migration.obj_as_admin():
4462             migration.save()
4463 
4464         instance.vm_state = vm_states.RESIZED
4465         instance.task_state = None
4466         instance.launched_at = timeutils.utcnow()
4467         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4468 
4469         return network_info
4470 
4471     @wrap_exception()
4472     @reverts_task_state
4473     @wrap_instance_event(prefix='compute')
4474     @wrap_instance_fault
4475     def finish_resize(self, context, disk_info, image, instance,
4476                       migration):
4477         """Completes the migration process.
4478 
4479         Sets up the newly transferred disk and turns on the instance at its
4480         new host machine.
4481 
4482         """
4483         try:
4484             self._finish_resize_helper(context, disk_info, image, instance,
4485                                        migration)
4486         except Exception:
4487             with excutils.save_and_reraise_exception():
4488                 self._revert_allocation(context, instance, migration)
4489 
4490     def _finish_resize_helper(self, context, disk_info, image, instance,
4491                               migration):
4492         """Completes the migration process.
4493 
4494         The caller must revert the instance's allocations if the migration
4495         process failed.
4496         """
4497         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4498             context, instance.uuid)
4499 
4500         with self._error_out_instance_on_exception(context, instance), \
4501              errors_out_migration_ctxt(migration):
4502             image_meta = objects.ImageMeta.from_dict(image)
4503             network_info = self._finish_resize(context, instance, migration,
4504                                                disk_info, image_meta, bdms)
4505 
4506         self._update_scheduler_instance_info(context, instance)
4507         self._notify_about_instance_usage(
4508             context, instance, "finish_resize.end",
4509             network_info=network_info)
4510         compute_utils.notify_about_instance_action(context, instance,
4511                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4512                phase=fields.NotificationPhase.END, bdms=bdms)
4513 
4514     @wrap_exception()
4515     @wrap_instance_fault
4516     def add_fixed_ip_to_instance(self, context, network_id, instance):
4517         """Calls network_api to add new fixed_ip to instance
4518         then injects the new network info and resets instance networking.
4519 
4520         """
4521         self._notify_about_instance_usage(
4522                 context, instance, "create_ip.start")
4523 
4524         network_info = self.network_api.add_fixed_ip_to_instance(context,
4525                                                                  instance,
4526                                                                  network_id)
4527         self._inject_network_info(context, instance, network_info)
4528         self.reset_network(context, instance)
4529 
4530         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4531         instance.updated_at = timeutils.utcnow()
4532         instance.save()
4533 
4534         self._notify_about_instance_usage(
4535             context, instance, "create_ip.end", network_info=network_info)
4536 
4537     @wrap_exception()
4538     @wrap_instance_fault
4539     def remove_fixed_ip_from_instance(self, context, address, instance):
4540         """Calls network_api to remove existing fixed_ip from instance
4541         by injecting the altered network info and resetting
4542         instance networking.
4543         """
4544         self._notify_about_instance_usage(
4545                 context, instance, "delete_ip.start")
4546 
4547         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4548                                                                       instance,
4549                                                                       address)
4550         self._inject_network_info(context, instance, network_info)
4551         self.reset_network(context, instance)
4552 
4553         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4554         instance.updated_at = timeutils.utcnow()
4555         instance.save()
4556 
4557         self._notify_about_instance_usage(
4558             context, instance, "delete_ip.end", network_info=network_info)
4559 
4560     @wrap_exception()
4561     @reverts_task_state
4562     @wrap_instance_event(prefix='compute')
4563     @wrap_instance_fault
4564     def pause_instance(self, context, instance):
4565         """Pause an instance on this host."""
4566         context = context.elevated()
4567         LOG.info('Pausing', instance=instance)
4568         self._notify_about_instance_usage(context, instance, 'pause.start')
4569         compute_utils.notify_about_instance_action(context, instance,
4570                self.host, action=fields.NotificationAction.PAUSE,
4571                phase=fields.NotificationPhase.START)
4572         self.driver.pause(instance)
4573         instance.power_state = self._get_power_state(context, instance)
4574         instance.vm_state = vm_states.PAUSED
4575         instance.task_state = None
4576         instance.save(expected_task_state=task_states.PAUSING)
4577         self._notify_about_instance_usage(context, instance, 'pause.end')
4578         compute_utils.notify_about_instance_action(context, instance,
4579                self.host, action=fields.NotificationAction.PAUSE,
4580                phase=fields.NotificationPhase.END)
4581 
4582     @wrap_exception()
4583     @reverts_task_state
4584     @wrap_instance_event(prefix='compute')
4585     @wrap_instance_fault
4586     def unpause_instance(self, context, instance):
4587         """Unpause a paused instance on this host."""
4588         context = context.elevated()
4589         LOG.info('Unpausing', instance=instance)
4590         self._notify_about_instance_usage(context, instance, 'unpause.start')
4591         compute_utils.notify_about_instance_action(context, instance,
4592             self.host, action=fields.NotificationAction.UNPAUSE,
4593             phase=fields.NotificationPhase.START)
4594         self.driver.unpause(instance)
4595         instance.power_state = self._get_power_state(context, instance)
4596         instance.vm_state = vm_states.ACTIVE
4597         instance.task_state = None
4598         instance.save(expected_task_state=task_states.UNPAUSING)
4599         self._notify_about_instance_usage(context, instance, 'unpause.end')
4600         compute_utils.notify_about_instance_action(context, instance,
4601             self.host, action=fields.NotificationAction.UNPAUSE,
4602             phase=fields.NotificationPhase.END)
4603 
4604     @wrap_exception()
4605     def host_power_action(self, context, action):
4606         """Reboots, shuts down or powers up the host."""
4607         return self.driver.host_power_action(action)
4608 
4609     @wrap_exception()
4610     def host_maintenance_mode(self, context, host, mode):
4611         """Start/Stop host maintenance window. On start, it triggers
4612         guest VMs evacuation.
4613         """
4614         return self.driver.host_maintenance_mode(host, mode)
4615 
4616     @wrap_exception()
4617     def set_host_enabled(self, context, enabled):
4618         """Sets the specified host's ability to accept new instances."""
4619         return self.driver.set_host_enabled(enabled)
4620 
4621     @wrap_exception()
4622     def get_host_uptime(self, context):
4623         """Returns the result of calling "uptime" on the target host."""
4624         return self.driver.get_host_uptime()
4625 
4626     @wrap_exception()
4627     @wrap_instance_fault
4628     def get_diagnostics(self, context, instance):
4629         """Retrieve diagnostics for an instance on this host."""
4630         current_power_state = self._get_power_state(context, instance)
4631         if current_power_state == power_state.RUNNING:
4632             LOG.info("Retrieving diagnostics", instance=instance)
4633             return self.driver.get_diagnostics(instance)
4634         else:
4635             raise exception.InstanceInvalidState(
4636                 attr='power state',
4637                 instance_uuid=instance.uuid,
4638                 state=power_state.STATE_MAP[instance.power_state],
4639                 method='get_diagnostics')
4640 
4641     @wrap_exception()
4642     @wrap_instance_fault
4643     def get_instance_diagnostics(self, context, instance):
4644         """Retrieve diagnostics for an instance on this host."""
4645         current_power_state = self._get_power_state(context, instance)
4646         if current_power_state == power_state.RUNNING:
4647             LOG.info("Retrieving diagnostics", instance=instance)
4648             return self.driver.get_instance_diagnostics(instance)
4649         else:
4650             raise exception.InstanceInvalidState(
4651                 attr='power state',
4652                 instance_uuid=instance.uuid,
4653                 state=power_state.STATE_MAP[instance.power_state],
4654                 method='get_diagnostics')
4655 
4656     @wrap_exception()
4657     @reverts_task_state
4658     @wrap_instance_event(prefix='compute')
4659     @wrap_instance_fault
4660     def suspend_instance(self, context, instance):
4661         """Suspend the given instance."""
4662         context = context.elevated()
4663 
4664         # Store the old state
4665         instance.system_metadata['old_vm_state'] = instance.vm_state
4666         self._notify_about_instance_usage(context, instance, 'suspend.start')
4667         compute_utils.notify_about_instance_action(context, instance,
4668                 self.host, action=fields.NotificationAction.SUSPEND,
4669                 phase=fields.NotificationPhase.START)
4670         with self._error_out_instance_on_exception(context, instance,
4671              instance_state=instance.vm_state):
4672             self.driver.suspend(context, instance)
4673         instance.power_state = self._get_power_state(context, instance)
4674         instance.vm_state = vm_states.SUSPENDED
4675         instance.task_state = None
4676         instance.save(expected_task_state=task_states.SUSPENDING)
4677         self._notify_about_instance_usage(context, instance, 'suspend.end')
4678         compute_utils.notify_about_instance_action(context, instance,
4679                 self.host, action=fields.NotificationAction.SUSPEND,
4680                 phase=fields.NotificationPhase.END)
4681 
4682     @wrap_exception()
4683     @reverts_task_state
4684     @wrap_instance_event(prefix='compute')
4685     @wrap_instance_fault
4686     def resume_instance(self, context, instance):
4687         """Resume the given suspended instance."""
4688         context = context.elevated()
4689         LOG.info('Resuming', instance=instance)
4690 
4691         self._notify_about_instance_usage(context, instance, 'resume.start')
4692 
4693         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4694             context, instance.uuid)
4695         block_device_info = self._get_instance_block_device_info(
4696             context, instance, bdms=bdms)
4697 
4698         compute_utils.notify_about_instance_action(context, instance,
4699             self.host, action=fields.NotificationAction.RESUME,
4700             phase=fields.NotificationPhase.START, bdms=bdms)
4701 
4702         network_info = self.network_api.get_instance_nw_info(context, instance)
4703 
4704         with self._error_out_instance_on_exception(context, instance,
4705              instance_state=instance.vm_state):
4706             self.driver.resume(context, instance, network_info,
4707                                block_device_info)
4708 
4709         instance.power_state = self._get_power_state(context, instance)
4710 
4711         # We default to the ACTIVE state for backwards compatibility
4712         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4713                                                          vm_states.ACTIVE)
4714 
4715         instance.task_state = None
4716         instance.save(expected_task_state=task_states.RESUMING)
4717         self._notify_about_instance_usage(context, instance, 'resume.end')
4718         compute_utils.notify_about_instance_action(context, instance,
4719             self.host, action=fields.NotificationAction.RESUME,
4720             phase=fields.NotificationPhase.END, bdms=bdms)
4721 
4722     @wrap_exception()
4723     @reverts_task_state
4724     @wrap_instance_event(prefix='compute')
4725     @wrap_instance_fault
4726     def shelve_instance(self, context, instance, image_id,
4727                         clean_shutdown):
4728         """Shelve an instance.
4729 
4730         This should be used when you want to take a snapshot of the instance.
4731         It also adds system_metadata that can be used by a periodic task to
4732         offload the shelved instance after a period of time.
4733 
4734         :param context: request context
4735         :param instance: an Instance object
4736         :param image_id: an image id to snapshot to.
4737         :param clean_shutdown: give the GuestOS a chance to stop
4738         """
4739 
4740         @utils.synchronized(instance.uuid)
4741         def do_shelve_instance():
4742             self._shelve_instance(context, instance, image_id, clean_shutdown)
4743         do_shelve_instance()
4744 
4745     def _shelve_instance(self, context, instance, image_id,
4746                          clean_shutdown):
4747         LOG.info('Shelving', instance=instance)
4748         offload = CONF.shelved_offload_time == 0
4749         if offload:
4750             # Get the BDMs early so we can pass them into versioned
4751             # notifications since _shelve_offload_instance needs the
4752             # BDMs anyway.
4753             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4754                 context, instance.uuid)
4755         else:
4756             bdms = None
4757         compute_utils.notify_usage_exists(self.notifier, context, instance,
4758                                           current_period=True)
4759         self._notify_about_instance_usage(context, instance, 'shelve.start')
4760         compute_utils.notify_about_instance_action(context, instance,
4761                 self.host, action=fields.NotificationAction.SHELVE,
4762                 phase=fields.NotificationPhase.START, bdms=bdms)
4763 
4764         def update_task_state(task_state, expected_state=task_states.SHELVING):
4765             shelving_state_map = {
4766                     task_states.IMAGE_PENDING_UPLOAD:
4767                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4768                     task_states.IMAGE_UPLOADING:
4769                         task_states.SHELVING_IMAGE_UPLOADING,
4770                     task_states.SHELVING: task_states.SHELVING}
4771             task_state = shelving_state_map[task_state]
4772             expected_state = shelving_state_map[expected_state]
4773             instance.task_state = task_state
4774             instance.save(expected_task_state=expected_state)
4775 
4776         self._power_off_instance(context, instance, clean_shutdown)
4777         self.driver.snapshot(context, instance, image_id, update_task_state)
4778 
4779         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4780         instance.system_metadata['shelved_image_id'] = image_id
4781         instance.system_metadata['shelved_host'] = self.host
4782         instance.vm_state = vm_states.SHELVED
4783         instance.task_state = None
4784         if CONF.shelved_offload_time == 0:
4785             instance.task_state = task_states.SHELVING_OFFLOADING
4786         instance.power_state = self._get_power_state(context, instance)
4787         instance.save(expected_task_state=[
4788                 task_states.SHELVING,
4789                 task_states.SHELVING_IMAGE_UPLOADING])
4790 
4791         self._notify_about_instance_usage(context, instance, 'shelve.end')
4792         compute_utils.notify_about_instance_action(context, instance,
4793                 self.host, action=fields.NotificationAction.SHELVE,
4794                 phase=fields.NotificationPhase.END, bdms=bdms)
4795 
4796         if offload:
4797             self._shelve_offload_instance(context, instance,
4798                                           clean_shutdown=False, bdms=bdms)
4799 
4800     @wrap_exception()
4801     @reverts_task_state
4802     @wrap_instance_event(prefix='compute')
4803     @wrap_instance_fault
4804     def shelve_offload_instance(self, context, instance, clean_shutdown):
4805         """Remove a shelved instance from the hypervisor.
4806 
4807         This frees up those resources for use by other instances, but may lead
4808         to slower unshelve times for this instance.  This method is used by
4809         volume backed instances since restoring them doesn't involve the
4810         potentially large download of an image.
4811 
4812         :param context: request context
4813         :param instance: nova.objects.instance.Instance
4814         :param clean_shutdown: give the GuestOS a chance to stop
4815         """
4816 
4817         @utils.synchronized(instance.uuid)
4818         def do_shelve_offload_instance():
4819             self._shelve_offload_instance(context, instance, clean_shutdown)
4820         do_shelve_offload_instance()
4821 
4822     def _shelve_offload_instance(self, context, instance, clean_shutdown,
4823                                  bdms=None):
4824         LOG.info('Shelve offloading', instance=instance)
4825         if bdms is None:
4826             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4827                 context, instance.uuid)
4828         self._notify_about_instance_usage(context, instance,
4829                 'shelve_offload.start')
4830         compute_utils.notify_about_instance_action(context, instance,
4831                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4832                 phase=fields.NotificationPhase.START, bdms=bdms)
4833 
4834         self._power_off_instance(context, instance, clean_shutdown)
4835         current_power_state = self._get_power_state(context, instance)
4836 
4837         self.network_api.cleanup_instance_network_on_host(context, instance,
4838                                                           instance.host)
4839         network_info = self.network_api.get_instance_nw_info(context, instance)
4840 
4841         block_device_info = self._get_instance_block_device_info(context,
4842                                                                  instance,
4843                                                                  bdms=bdms)
4844         self.driver.destroy(context, instance, network_info,
4845                 block_device_info)
4846 
4847         # the instance is going to be removed from the host so we want to
4848         # terminate all the connections with the volume server and the host
4849         self._terminate_volume_connections(context, instance, bdms)
4850 
4851         instance.power_state = current_power_state
4852         # NOTE(mriedem): The vm_state has to be set before updating the
4853         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4854         # values cannot be nulled out until after updating the resource tracker
4855         # though.
4856         instance.vm_state = vm_states.SHELVED_OFFLOADED
4857         instance.task_state = None
4858         instance.save(expected_task_state=[task_states.SHELVING,
4859                                            task_states.SHELVING_OFFLOADING])
4860 
4861         # NOTE(ndipanov): Free resources from the resource tracker
4862         self._update_resource_tracker(context, instance)
4863 
4864         rt = self._get_resource_tracker()
4865         rt.delete_allocation_for_shelve_offloaded_instance(context, instance)
4866 
4867         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4868         # instance, so ensure any calls result in errors
4869         self._nil_out_instance_obj_host_and_node(instance)
4870         instance.save(expected_task_state=None)
4871 
4872         self._delete_scheduler_instance_info(context, instance.uuid)
4873         self._notify_about_instance_usage(context, instance,
4874                 'shelve_offload.end')
4875         compute_utils.notify_about_instance_action(context, instance,
4876                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4877                 phase=fields.NotificationPhase.END, bdms=bdms)
4878 
4879     @wrap_exception()
4880     @reverts_task_state
4881     @wrap_instance_event(prefix='compute')
4882     @wrap_instance_fault
4883     def unshelve_instance(self, context, instance, image,
4884                           filter_properties, node):
4885         """Unshelve the instance.
4886 
4887         :param context: request context
4888         :param instance: a nova.objects.instance.Instance object
4889         :param image: an image to build from.  If None we assume a
4890             volume backed instance.
4891         :param filter_properties: dict containing limits, retry info etc.
4892         :param node: target compute node
4893         """
4894         if filter_properties is None:
4895             filter_properties = {}
4896 
4897         @utils.synchronized(instance.uuid)
4898         def do_unshelve_instance():
4899             self._unshelve_instance(context, instance, image,
4900                                     filter_properties, node)
4901         do_unshelve_instance()
4902 
4903     def _unshelve_instance_key_scrub(self, instance):
4904         """Remove data from the instance that may cause side effects."""
4905         cleaned_keys = dict(
4906                 key_data=instance.key_data,
4907                 auto_disk_config=instance.auto_disk_config)
4908         instance.key_data = None
4909         instance.auto_disk_config = False
4910         return cleaned_keys
4911 
4912     def _unshelve_instance_key_restore(self, instance, keys):
4913         """Restore previously scrubbed keys before saving the instance."""
4914         instance.update(keys)
4915 
4916     def _unshelve_instance(self, context, instance, image, filter_properties,
4917                            node):
4918         LOG.info('Unshelving', instance=instance)
4919         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4920                 context, instance.uuid)
4921 
4922         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4923         compute_utils.notify_about_instance_action(context, instance,
4924                 self.host, action=fields.NotificationAction.UNSHELVE,
4925                 phase=fields.NotificationPhase.START, bdms=bdms)
4926 
4927         instance.task_state = task_states.SPAWNING
4928         instance.save()
4929 
4930         block_device_info = self._prep_block_device(context, instance, bdms)
4931         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4932 
4933         if node is None:
4934             node = self._get_nodename(instance)
4935 
4936         rt = self._get_resource_tracker()
4937         limits = filter_properties.get('limits', {})
4938 
4939         allocations = self.reportclient.get_allocations_for_consumer(
4940             context, instance.uuid)
4941 
4942         shelved_image_ref = instance.image_ref
4943         if image:
4944             instance.image_ref = image['id']
4945             image_meta = objects.ImageMeta.from_dict(image)
4946         else:
4947             image_meta = objects.ImageMeta.from_dict(
4948                 utils.get_image_from_system_metadata(
4949                     instance.system_metadata))
4950 
4951         self.network_api.setup_instance_network_on_host(context, instance,
4952                                                         self.host)
4953         network_info = self.network_api.get_instance_nw_info(context, instance)
4954         try:
4955             with rt.instance_claim(context, instance, node, limits):
4956                 self.driver.spawn(context, instance, image_meta,
4957                                   injected_files=[],
4958                                   admin_password=None,
4959                                   allocations=allocations,
4960                                   network_info=network_info,
4961                                   block_device_info=block_device_info)
4962         except Exception:
4963             with excutils.save_and_reraise_exception(logger=LOG):
4964                 LOG.exception('Instance failed to spawn',
4965                               instance=instance)
4966                 # Cleanup allocations created by the scheduler on this host
4967                 # since we failed to spawn the instance. We do this both if
4968                 # the instance claim failed with ComputeResourcesUnavailable
4969                 # or if we did claim but the spawn failed, because aborting the
4970                 # instance claim will not remove the allocations.
4971                 rt.reportclient.delete_allocation_for_instance(context,
4972                                                                instance.uuid)
4973                 # FIXME: Umm, shouldn't we be rolling back port bindings too?
4974                 self._terminate_volume_connections(context, instance, bdms)
4975                 # The reverts_task_state decorator on unshelve_instance will
4976                 # eventually save these updates.
4977                 self._nil_out_instance_obj_host_and_node(instance)
4978 
4979         if image:
4980             instance.image_ref = shelved_image_ref
4981             self._delete_snapshot_of_shelved_instance(context, instance,
4982                                                       image['id'])
4983 
4984         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4985         self._update_instance_after_spawn(context, instance)
4986         # Delete system_metadata for a shelved instance
4987         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4988 
4989         instance.save(expected_task_state=task_states.SPAWNING)
4990         self._update_scheduler_instance_info(context, instance)
4991         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4992         compute_utils.notify_about_instance_action(context, instance,
4993                 self.host, action=fields.NotificationAction.UNSHELVE,
4994                 phase=fields.NotificationPhase.END, bdms=bdms)
4995 
4996     @messaging.expected_exceptions(NotImplementedError)
4997     @wrap_instance_fault
4998     def reset_network(self, context, instance):
4999         """Reset networking on the given instance."""
5000         LOG.debug('Reset network', instance=instance)
5001         self.driver.reset_network(instance)
5002 
5003     def _inject_network_info(self, context, instance, network_info):
5004         """Inject network info for the given instance."""
5005         LOG.debug('Inject network info', instance=instance)
5006         LOG.debug('network_info to inject: |%s|', network_info,
5007                   instance=instance)
5008 
5009         self.driver.inject_network_info(instance,
5010                                         network_info)
5011 
5012     @wrap_instance_fault
5013     def inject_network_info(self, context, instance):
5014         """Inject network info, but don't return the info."""
5015         network_info = self.network_api.get_instance_nw_info(context, instance)
5016         self._inject_network_info(context, instance, network_info)
5017 
5018     @messaging.expected_exceptions(NotImplementedError,
5019                                    exception.ConsoleNotAvailable,
5020                                    exception.InstanceNotFound)
5021     @wrap_exception()
5022     @wrap_instance_fault
5023     def get_console_output(self, context, instance, tail_length):
5024         """Send the console output for the given instance."""
5025         context = context.elevated()
5026         LOG.info("Get console output", instance=instance)
5027         output = self.driver.get_console_output(context, instance)
5028 
5029         if type(output) is six.text_type:
5030             output = six.b(output)
5031 
5032         if tail_length is not None:
5033             output = self._tail_log(output, tail_length)
5034 
5035         return output.decode('ascii', 'replace')
5036 
5037     def _tail_log(self, log, length):
5038         try:
5039             length = int(length)
5040         except ValueError:
5041             length = 0
5042 
5043         if length == 0:
5044             return b''
5045         else:
5046             return b'\n'.join(log.split(b'\n')[-int(length):])
5047 
5048     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5049                                    exception.InstanceNotReady,
5050                                    exception.InstanceNotFound,
5051                                    exception.ConsoleTypeUnavailable,
5052                                    NotImplementedError)
5053     @wrap_exception()
5054     @wrap_instance_fault
5055     def get_vnc_console(self, context, console_type, instance):
5056         """Return connection information for a vnc console."""
5057         context = context.elevated()
5058         LOG.debug("Getting vnc console", instance=instance)
5059         token = uuidutils.generate_uuid()
5060 
5061         if not CONF.vnc.enabled:
5062             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5063 
5064         if console_type == 'novnc':
5065             # For essex, novncproxy_base_url must include the full path
5066             # including the html file (like http://myhost/vnc_auto.html)
5067             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
5068         elif console_type == 'xvpvnc':
5069             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
5070         else:
5071             raise exception.ConsoleTypeInvalid(console_type=console_type)
5072 
5073         try:
5074             # Retrieve connect info from driver, and then decorate with our
5075             # access info token
5076             console = self.driver.get_vnc_console(context, instance)
5077             connect_info = console.get_connection_info(token, access_url)
5078         except exception.InstanceNotFound:
5079             if instance.vm_state != vm_states.BUILDING:
5080                 raise
5081             raise exception.InstanceNotReady(instance_id=instance.uuid)
5082 
5083         return connect_info
5084 
5085     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5086                                    exception.InstanceNotReady,
5087                                    exception.InstanceNotFound,
5088                                    exception.ConsoleTypeUnavailable,
5089                                    NotImplementedError)
5090     @wrap_exception()
5091     @wrap_instance_fault
5092     def get_spice_console(self, context, console_type, instance):
5093         """Return connection information for a spice console."""
5094         context = context.elevated()
5095         LOG.debug("Getting spice console", instance=instance)
5096         token = uuidutils.generate_uuid()
5097 
5098         if not CONF.spice.enabled:
5099             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5100 
5101         if console_type == 'spice-html5':
5102             # For essex, spicehtml5proxy_base_url must include the full path
5103             # including the html file (like http://myhost/spice_auto.html)
5104             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
5105                                           token)
5106         else:
5107             raise exception.ConsoleTypeInvalid(console_type=console_type)
5108 
5109         try:
5110             # Retrieve connect info from driver, and then decorate with our
5111             # access info token
5112             console = self.driver.get_spice_console(context, instance)
5113             connect_info = console.get_connection_info(token, access_url)
5114         except exception.InstanceNotFound:
5115             if instance.vm_state != vm_states.BUILDING:
5116                 raise
5117             raise exception.InstanceNotReady(instance_id=instance.uuid)
5118 
5119         return connect_info
5120 
5121     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5122                                    exception.InstanceNotReady,
5123                                    exception.InstanceNotFound,
5124                                    exception.ConsoleTypeUnavailable,
5125                                    NotImplementedError)
5126     @wrap_exception()
5127     @wrap_instance_fault
5128     def get_rdp_console(self, context, console_type, instance):
5129         """Return connection information for a RDP console."""
5130         context = context.elevated()
5131         LOG.debug("Getting RDP console", instance=instance)
5132         token = uuidutils.generate_uuid()
5133 
5134         if not CONF.rdp.enabled:
5135             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5136 
5137         if console_type == 'rdp-html5':
5138             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
5139                                           token)
5140         else:
5141             raise exception.ConsoleTypeInvalid(console_type=console_type)
5142 
5143         try:
5144             # Retrieve connect info from driver, and then decorate with our
5145             # access info token
5146             console = self.driver.get_rdp_console(context, instance)
5147             connect_info = console.get_connection_info(token, access_url)
5148         except exception.InstanceNotFound:
5149             if instance.vm_state != vm_states.BUILDING:
5150                 raise
5151             raise exception.InstanceNotReady(instance_id=instance.uuid)
5152 
5153         return connect_info
5154 
5155     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5156                                    exception.InstanceNotReady,
5157                                    exception.InstanceNotFound,
5158                                    exception.ConsoleTypeUnavailable,
5159                                    NotImplementedError)
5160     @wrap_exception()
5161     @wrap_instance_fault
5162     def get_mks_console(self, context, console_type, instance):
5163         """Return connection information for a MKS console."""
5164         context = context.elevated()
5165         LOG.debug("Getting MKS console", instance=instance)
5166         token = uuidutils.generate_uuid()
5167 
5168         if not CONF.mks.enabled:
5169             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5170 
5171         if console_type == 'webmks':
5172             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
5173                                           token)
5174         else:
5175             raise exception.ConsoleTypeInvalid(console_type=console_type)
5176 
5177         try:
5178             # Retrieve connect info from driver, and then decorate with our
5179             # access info token
5180             console = self.driver.get_mks_console(context, instance)
5181             connect_info = console.get_connection_info(token, access_url)
5182         except exception.InstanceNotFound:
5183             if instance.vm_state != vm_states.BUILDING:
5184                 raise
5185             raise exception.InstanceNotReady(instance_id=instance.uuid)
5186 
5187         return connect_info
5188 
5189     @messaging.expected_exceptions(
5190         exception.ConsoleTypeInvalid,
5191         exception.InstanceNotReady,
5192         exception.InstanceNotFound,
5193         exception.ConsoleTypeUnavailable,
5194         exception.SocketPortRangeExhaustedException,
5195         exception.ImageSerialPortNumberInvalid,
5196         exception.ImageSerialPortNumberExceedFlavorValue,
5197         NotImplementedError)
5198     @wrap_exception()
5199     @wrap_instance_fault
5200     def get_serial_console(self, context, console_type, instance):
5201         """Returns connection information for a serial console."""
5202 
5203         LOG.debug("Getting serial console", instance=instance)
5204 
5205         if not CONF.serial_console.enabled:
5206             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5207 
5208         context = context.elevated()
5209 
5210         token = uuidutils.generate_uuid()
5211         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
5212 
5213         try:
5214             # Retrieve connect info from driver, and then decorate with our
5215             # access info token
5216             console = self.driver.get_serial_console(context, instance)
5217             connect_info = console.get_connection_info(token, access_url)
5218         except exception.InstanceNotFound:
5219             if instance.vm_state != vm_states.BUILDING:
5220                 raise
5221             raise exception.InstanceNotReady(instance_id=instance.uuid)
5222 
5223         return connect_info
5224 
5225     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5226                                    exception.InstanceNotReady,
5227                                    exception.InstanceNotFound)
5228     @wrap_exception()
5229     @wrap_instance_fault
5230     def validate_console_port(self, ctxt, instance, port, console_type):
5231         if console_type == "spice-html5":
5232             console_info = self.driver.get_spice_console(ctxt, instance)
5233         elif console_type == "rdp-html5":
5234             console_info = self.driver.get_rdp_console(ctxt, instance)
5235         elif console_type == "serial":
5236             console_info = self.driver.get_serial_console(ctxt, instance)
5237         elif console_type == "webmks":
5238             console_info = self.driver.get_mks_console(ctxt, instance)
5239         else:
5240             console_info = self.driver.get_vnc_console(ctxt, instance)
5241 
5242         return console_info.port == port
5243 
5244     @wrap_exception()
5245     @reverts_task_state
5246     @wrap_instance_fault
5247     def reserve_block_device_name(self, context, instance, device,
5248                                   volume_id, disk_bus, device_type, tag,
5249                                   multiattach):
5250         if (tag and not
5251                 self.driver.capabilities.get('supports_tagged_attach_volume',
5252                                              False)):
5253             raise exception.VolumeTaggedAttachNotSupported()
5254 
5255         if (multiattach and not
5256                 self.driver.capabilities.get('supports_multiattach', False)):
5257             raise exception.MultiattachNotSupportedByVirtDriver(
5258                 volume_id=volume_id)
5259 
5260         @utils.synchronized(instance.uuid)
5261         def do_reserve():
5262             bdms = (
5263                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5264                     context, instance.uuid))
5265 
5266             # NOTE(ndipanov): We need to explicitly set all the fields on the
5267             #                 object so that obj_load_attr does not fail
5268             new_bdm = objects.BlockDeviceMapping(
5269                     context=context,
5270                     source_type='volume', destination_type='volume',
5271                     instance_uuid=instance.uuid, boot_index=None,
5272                     volume_id=volume_id,
5273                     device_name=device, guest_format=None,
5274                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5275 
5276             new_bdm.device_name = self._get_device_name_for_instance(
5277                     instance, bdms, new_bdm)
5278 
5279             # NOTE(vish): create bdm here to avoid race condition
5280             new_bdm.create()
5281             return new_bdm
5282 
5283         return do_reserve()
5284 
5285     @wrap_exception()
5286     @wrap_instance_event(prefix='compute')
5287     @wrap_instance_fault
5288     def attach_volume(self, context, instance, bdm):
5289         """Attach a volume to an instance."""
5290         driver_bdm = driver_block_device.convert_volume(bdm)
5291 
5292         @utils.synchronized(instance.uuid)
5293         def do_attach_volume(context, instance, driver_bdm):
5294             try:
5295                 return self._attach_volume(context, instance, driver_bdm)
5296             except Exception:
5297                 with excutils.save_and_reraise_exception():
5298                     bdm.destroy()
5299 
5300         do_attach_volume(context, instance, driver_bdm)
5301 
5302     def _attach_volume(self, context, instance, bdm):
5303         context = context.elevated()
5304         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5305                  {'volume_id': bdm.volume_id,
5306                   'mountpoint': bdm['mount_device']},
5307                  instance=instance)
5308         compute_utils.notify_about_volume_attach_detach(
5309             context, instance, self.host,
5310             action=fields.NotificationAction.VOLUME_ATTACH,
5311             phase=fields.NotificationPhase.START,
5312             volume_id=bdm.volume_id)
5313         try:
5314             bdm.attach(context, instance, self.volume_api, self.driver,
5315                        do_driver_attach=True)
5316         except Exception as e:
5317             with excutils.save_and_reraise_exception():
5318                 LOG.exception("Failed to attach %(volume_id)s "
5319                               "at %(mountpoint)s",
5320                               {'volume_id': bdm.volume_id,
5321                                'mountpoint': bdm['mount_device']},
5322                               instance=instance)
5323                 if bdm['attachment_id']:
5324                     self.volume_api.attachment_delete(context,
5325                                                       bdm['attachment_id'])
5326                 else:
5327                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5328                 compute_utils.notify_about_volume_attach_detach(
5329                     context, instance, self.host,
5330                     action=fields.NotificationAction.VOLUME_ATTACH,
5331                     phase=fields.NotificationPhase.ERROR,
5332                     exception=e,
5333                     volume_id=bdm.volume_id)
5334 
5335         info = {'volume_id': bdm.volume_id}
5336         self._notify_about_instance_usage(
5337             context, instance, "volume.attach", extra_usage_info=info)
5338         compute_utils.notify_about_volume_attach_detach(
5339             context, instance, self.host,
5340             action=fields.NotificationAction.VOLUME_ATTACH,
5341             phase=fields.NotificationPhase.END,
5342             volume_id=bdm.volume_id)
5343 
5344     def _notify_volume_usage_detach(self, context, instance, bdm):
5345         if CONF.volume_usage_poll_interval <= 0:
5346             return
5347 
5348         vol_stats = []
5349         mp = bdm.device_name
5350         # Handle bootable volumes which will not contain /dev/
5351         if '/dev/' in mp:
5352             mp = mp[5:]
5353         try:
5354             vol_stats = self.driver.block_stats(instance, mp)
5355         except NotImplementedError:
5356             return
5357 
5358         LOG.debug("Updating volume usage cache with totals", instance=instance)
5359         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5360         vol_usage = objects.VolumeUsage(context)
5361         vol_usage.volume_id = bdm.volume_id
5362         vol_usage.instance_uuid = instance.uuid
5363         vol_usage.project_id = instance.project_id
5364         vol_usage.user_id = instance.user_id
5365         vol_usage.availability_zone = instance.availability_zone
5366         vol_usage.curr_reads = rd_req
5367         vol_usage.curr_read_bytes = rd_bytes
5368         vol_usage.curr_writes = wr_req
5369         vol_usage.curr_write_bytes = wr_bytes
5370         vol_usage.save(update_totals=True)
5371         self.notifier.info(context, 'volume.usage',
5372                            compute_utils.usage_volume_info(vol_usage))
5373 
5374     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5375                        attachment_id=None):
5376         """Detach a volume from an instance.
5377 
5378         :param context: security context
5379         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5380         :param instance: the Instance object to detach the volume from
5381         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5382                             as deleted. Disabling this is useful for operations
5383                             like rebuild, when we don't want to destroy BDM
5384         :param attachment_id: The volume attachment_id for the given instance
5385                               and volume.
5386         """
5387         volume_id = bdm.volume_id
5388         compute_utils.notify_about_volume_attach_detach(
5389             context, instance, self.host,
5390             action=fields.NotificationAction.VOLUME_DETACH,
5391             phase=fields.NotificationPhase.START,
5392             volume_id=volume_id)
5393 
5394         self._notify_volume_usage_detach(context, instance, bdm)
5395 
5396         LOG.info('Detaching volume %(volume_id)s',
5397                  {'volume_id': volume_id}, instance=instance)
5398 
5399         driver_bdm = driver_block_device.convert_volume(bdm)
5400         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5401                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5402 
5403         info = dict(volume_id=volume_id)
5404         self._notify_about_instance_usage(
5405             context, instance, "volume.detach", extra_usage_info=info)
5406         compute_utils.notify_about_volume_attach_detach(
5407             context, instance, self.host,
5408             action=fields.NotificationAction.VOLUME_DETACH,
5409             phase=fields.NotificationPhase.END,
5410             volume_id=volume_id)
5411 
5412         if 'tag' in bdm and bdm.tag:
5413             self._delete_disk_metadata(instance, bdm)
5414         if destroy_bdm:
5415             bdm.destroy()
5416 
5417     def _delete_disk_metadata(self, instance, bdm):
5418         for device in instance.device_metadata.devices:
5419             if isinstance(device, objects.DiskMetadata):
5420                 if 'serial' in device:
5421                     if device.serial == bdm.volume_id:
5422                         instance.device_metadata.devices.remove(device)
5423                         instance.save()
5424                         break
5425                 else:
5426                     # NOTE(artom) We log the entire device object because all
5427                     # fields are nullable and may not be set
5428                     LOG.warning('Unable to determine whether to clean up '
5429                                 'device metadata for disk %s', device,
5430                                 instance=instance)
5431 
5432     @wrap_exception()
5433     @wrap_instance_event(prefix='compute')
5434     @wrap_instance_fault
5435     def detach_volume(self, context, volume_id, instance, attachment_id):
5436         """Detach a volume from an instance.
5437 
5438         :param context: security context
5439         :param volume_id: the volume id
5440         :param instance: the Instance object to detach the volume from
5441         :param attachment_id: The volume attachment_id for the given instance
5442                               and volume.
5443 
5444         """
5445         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5446                 context, volume_id, instance.uuid)
5447         self._detach_volume(context, bdm, instance,
5448                             attachment_id=attachment_id)
5449 
5450     def _init_volume_connection(self, context, new_volume,
5451                                 old_volume_id, connector, bdm,
5452                                 new_attachment_id, mountpoint):
5453         new_volume_id = new_volume['id']
5454         if new_attachment_id is None:
5455             # We're dealing with an old-style attachment so initialize the
5456             # connection so we can get the connection_info.
5457             new_cinfo = self.volume_api.initialize_connection(context,
5458                                                               new_volume_id,
5459                                                               connector)
5460         else:
5461             # Check for multiattach on the new volume and if True, check to
5462             # see if the virt driver supports multiattach.
5463             # TODO(mriedem): This is copied from DriverVolumeBlockDevice
5464             # and should be consolidated into some common code at some point.
5465             vol_multiattach = new_volume.get('multiattach', False)
5466             virt_multiattach = self.driver.capabilities.get(
5467                 'supports_multiattach', False)
5468             if vol_multiattach and not virt_multiattach:
5469                 raise exception.MultiattachNotSupportedByVirtDriver(
5470                     volume_id=new_volume_id)
5471 
5472             # This is a new style attachment and the API created the new
5473             # volume attachment and passed the id to the compute over RPC.
5474             # At this point we need to update the new volume attachment with
5475             # the host connector, which will give us back the new attachment
5476             # connection_info.
5477             new_cinfo = self.volume_api.attachment_update(
5478                 context, new_attachment_id, connector,
5479                 mountpoint)['connection_info']
5480 
5481             if vol_multiattach:
5482                 # This will be used by the volume driver to determine the
5483                 # proper disk configuration.
5484                 new_cinfo['multiattach'] = True
5485 
5486         old_cinfo = jsonutils.loads(bdm['connection_info'])
5487         if old_cinfo and 'serial' not in old_cinfo:
5488             old_cinfo['serial'] = old_volume_id
5489         # NOTE(lyarwood): serial is not always present in the returned
5490         # connection_info so set it if it is missing as we do in
5491         # DriverVolumeBlockDevice.attach().
5492         if 'serial' not in new_cinfo:
5493             new_cinfo['serial'] = new_volume_id
5494         return (old_cinfo, new_cinfo)
5495 
5496     def _swap_volume(self, context, instance, bdm, connector,
5497                      old_volume_id, new_volume, resize_to,
5498                      new_attachment_id, is_cinder_migration):
5499         new_volume_id = new_volume['id']
5500         mountpoint = bdm['device_name']
5501         failed = False
5502         new_cinfo = None
5503         try:
5504             old_cinfo, new_cinfo = self._init_volume_connection(
5505                 context, new_volume, old_volume_id, connector,
5506                 bdm, new_attachment_id, mountpoint)
5507             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5508             # currently implementing swap_volume, will modify the contents of
5509             # new_cinfo when connect_volume is called. This is then saved to
5510             # the BDM in swap_volume for future use outside of this flow.
5511             msg = ("swap_volume: Calling driver volume swap with "
5512                    "connection infos: new: %(new_cinfo)s; "
5513                    "old: %(old_cinfo)s" %
5514                    {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo})
5515             # Both new and old info might contain password
5516             LOG.debug(strutils.mask_password(msg), instance=instance)
5517 
5518             self.driver.swap_volume(context, old_cinfo, new_cinfo, instance,
5519                                     mountpoint, resize_to)
5520             if new_attachment_id:
5521                 self.volume_api.attachment_complete(context, new_attachment_id)
5522             msg = ("swap_volume: Driver volume swap returned, new "
5523                    "connection_info is now : %(new_cinfo)s" %
5524                    {'new_cinfo': new_cinfo})
5525             LOG.debug(strutils.mask_password(msg))
5526         except Exception as ex:
5527             failed = True
5528             with excutils.save_and_reraise_exception():
5529                 compute_utils.notify_about_volume_swap(
5530                     context, instance, self.host,
5531                     fields.NotificationPhase.ERROR,
5532                     old_volume_id, new_volume_id, ex)
5533                 if new_cinfo:
5534                     msg = ("Failed to swap volume %(old_volume_id)s "
5535                            "for %(new_volume_id)s")
5536                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5537                                         'new_volume_id': new_volume_id},
5538                                   instance=instance)
5539                 else:
5540                     msg = ("Failed to connect to volume %(volume_id)s "
5541                            "with volume at %(mountpoint)s")
5542                     LOG.exception(msg, {'volume_id': new_volume_id,
5543                                         'mountpoint': bdm['device_name']},
5544                                   instance=instance)
5545 
5546                 # The API marked the volume as 'detaching' for the old volume
5547                 # so we need to roll that back so the volume goes back to
5548                 # 'in-use' state.
5549                 self.volume_api.roll_detaching(context, old_volume_id)
5550 
5551                 if new_attachment_id is None:
5552                     # The API reserved the new volume so it would be in
5553                     # 'attaching' status, so we need to unreserve it so it
5554                     # goes back to 'available' status.
5555                     self.volume_api.unreserve_volume(context, new_volume_id)
5556                 else:
5557                     # This is a new style attachment for the new volume, which
5558                     # was created in the API. We just need to delete it here
5559                     # to put the new volume back into 'available' status.
5560                     self.volume_api.attachment_delete(
5561                         context, new_attachment_id)
5562         finally:
5563             # TODO(mriedem): This finally block is terribly confusing and is
5564             # trying to do too much. We should consider removing the finally
5565             # block and move whatever needs to happen on success and failure
5566             # into the blocks above for clarity, even if it means a bit of
5567             # redundant code.
5568             conn_volume = new_volume_id if failed else old_volume_id
5569             if new_cinfo:
5570                 LOG.debug("swap_volume: removing Cinder connection "
5571                           "for volume %(volume)s", {'volume': conn_volume},
5572                           instance=instance)
5573                 if bdm.attachment_id is None:
5574                     # This is the pre-3.44 flow for new-style volume
5575                     # attachments so just terminate the connection.
5576                     self.volume_api.terminate_connection(context,
5577                                                          conn_volume,
5578                                                          connector)
5579                 else:
5580                     # This is a new style volume attachment. If we failed, then
5581                     # the new attachment was already deleted above in the
5582                     # exception block and we have nothing more to do here. If
5583                     # swap_volume was successful in the driver, then we need to
5584                     # "detach" the original attachment by deleting it.
5585                     if not failed:
5586                         self.volume_api.attachment_delete(
5587                             context, bdm.attachment_id)
5588 
5589             # Need to make some decisions based on whether this was
5590             # a Cinder initiated migration or not. The callback to
5591             # migration completion isn't needed in the case of a
5592             # nova initiated simple swap of two volume
5593             # "volume-update" call so skip that. The new attachment
5594             # scenarios will give us a new attachment record and
5595             # that's what we want.
5596             if bdm.attachment_id and not is_cinder_migration:
5597                 # we don't callback to cinder
5598                 comp_ret = {'save_volume_id': new_volume_id}
5599             else:
5600                 # NOTE(lyarwood): The following call to
5601                 # os-migrate-volume-completion returns a dict containing
5602                 # save_volume_id, this volume id has two possible values :
5603                 # 1. old_volume_id if we are migrating (retyping) volumes
5604                 # 2. new_volume_id if we are swapping between two existing
5605                 #    volumes
5606                 # This volume id is later used to update the volume_id and
5607                 # connection_info['serial'] of the BDM.
5608                 comp_ret = self.volume_api.migrate_volume_completion(
5609                                                           context,
5610                                                           old_volume_id,
5611                                                           new_volume_id,
5612                                                           error=failed)
5613                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5614                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5615                           instance=instance)
5616 
5617         return (comp_ret, new_cinfo)
5618 
5619     @wrap_exception()
5620     @wrap_instance_event(prefix='compute')
5621     @wrap_instance_fault
5622     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
5623                     new_attachment_id):
5624         """Swap volume for an instance."""
5625         context = context.elevated()
5626 
5627         compute_utils.notify_about_volume_swap(
5628             context, instance, self.host,
5629             fields.NotificationPhase.START,
5630             old_volume_id, new_volume_id)
5631 
5632         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5633                 context, old_volume_id, instance.uuid)
5634         connector = self.driver.get_volume_connector(instance)
5635 
5636         resize_to = 0
5637         old_volume = self.volume_api.get(context, old_volume_id)
5638         # Yes this is a tightly-coupled state check of what's going on inside
5639         # cinder, but we need this while we still support old (v1/v2) and
5640         # new style attachments (v3.44). Once we drop support for old style
5641         # attachments we could think about cleaning up the cinder-initiated
5642         # swap volume API flows.
5643         is_cinder_migration = (
5644             True if old_volume['status'] in ('retyping',
5645                                              'migrating') else False)
5646         old_vol_size = old_volume['size']
5647         new_volume = self.volume_api.get(context, new_volume_id)
5648         new_vol_size = new_volume['size']
5649         if new_vol_size > old_vol_size:
5650             resize_to = new_vol_size
5651 
5652         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5653                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5654                  instance=instance)
5655         comp_ret, new_cinfo = self._swap_volume(context,
5656                                                 instance,
5657                                                 bdm,
5658                                                 connector,
5659                                                 old_volume_id,
5660                                                 new_volume,
5661                                                 resize_to,
5662                                                 new_attachment_id,
5663                                                 is_cinder_migration)
5664 
5665         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5666         # correct volume_id returned by Cinder.
5667         save_volume_id = comp_ret['save_volume_id']
5668         new_cinfo['serial'] = save_volume_id
5669         values = {
5670             'connection_info': jsonutils.dumps(new_cinfo),
5671             'source_type': 'volume',
5672             'destination_type': 'volume',
5673             'snapshot_id': None,
5674             'volume_id': save_volume_id,
5675             'no_device': None}
5676 
5677         if resize_to:
5678             values['volume_size'] = resize_to
5679 
5680         if new_attachment_id is not None:
5681             # This was a volume swap for a new-style attachment so we
5682             # need to update the BDM attachment_id for the new attachment.
5683             values['attachment_id'] = new_attachment_id
5684 
5685         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5686                   "%(updates)s", {'volume_id': bdm.volume_id,
5687                                   'updates': values},
5688                   instance=instance)
5689         bdm.update(values)
5690         bdm.save()
5691 
5692         compute_utils.notify_about_volume_swap(
5693             context, instance, self.host,
5694             fields.NotificationPhase.END,
5695             old_volume_id, new_volume_id)
5696 
5697     @wrap_exception()
5698     def remove_volume_connection(self, context, volume_id, instance):
5699         """Remove the volume connection on this host
5700 
5701         Detach the volume from this instance on this host, and if this is
5702         the cinder v2 flow, call cinder to terminate the connection.
5703         """
5704         try:
5705             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5706                     context, volume_id, instance.uuid)
5707             driver_bdm = driver_block_device.convert_volume(bdm)
5708             driver_bdm.driver_detach(context, instance,
5709                                      self.volume_api, self.driver)
5710             if bdm.attachment_id is None:
5711                 # cinder v2 api flow
5712                 connector = self.driver.get_volume_connector(instance)
5713                 self.volume_api.terminate_connection(context, volume_id,
5714                                                      connector)
5715         except exception.NotFound:
5716             pass
5717 
5718     @wrap_exception()
5719     @wrap_instance_event(prefix='compute')
5720     @wrap_instance_fault
5721     def attach_interface(self, context, instance, network_id, port_id,
5722                          requested_ip, tag):
5723         """Use hotplug to add an network adapter to an instance."""
5724         if not self.driver.capabilities.get('supports_attach_interface',
5725                                             False):
5726             raise exception.AttachInterfaceNotSupported(
5727                 instance_uuid=instance.uuid)
5728         if (tag and not
5729             self.driver.capabilities.get('supports_tagged_attach_interface',
5730                                          False)):
5731             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5732 
5733         compute_utils.notify_about_instance_action(
5734             context, instance, self.host,
5735             action=fields.NotificationAction.INTERFACE_ATTACH,
5736             phase=fields.NotificationPhase.START)
5737 
5738         bind_host_id = self.driver.network_binding_host_id(context, instance)
5739         network_info = self.network_api.allocate_port_for_instance(
5740             context, instance, port_id, network_id, requested_ip,
5741             bind_host_id=bind_host_id, tag=tag)
5742         if len(network_info) != 1:
5743             LOG.error('allocate_port_for_instance returned %(ports)s '
5744                       'ports', {'ports': len(network_info)})
5745             # TODO(elod.illes): an instance.interface_attach.error notification
5746             # should be sent here
5747             raise exception.InterfaceAttachFailed(
5748                     instance_uuid=instance.uuid)
5749         image_meta = objects.ImageMeta.from_instance(instance)
5750 
5751         try:
5752             self.driver.attach_interface(context, instance, image_meta,
5753                                          network_info[0])
5754         except exception.NovaException as ex:
5755             port_id = network_info[0].get('id')
5756             LOG.warning("attach interface failed , try to deallocate "
5757                         "port %(port_id)s, reason: %(msg)s",
5758                         {'port_id': port_id, 'msg': ex},
5759                         instance=instance)
5760             try:
5761                 self.network_api.deallocate_port_for_instance(
5762                     context, instance, port_id)
5763             except Exception:
5764                 LOG.warning("deallocate port %(port_id)s failed",
5765                             {'port_id': port_id}, instance=instance)
5766 
5767             compute_utils.notify_about_instance_action(
5768                 context, instance, self.host,
5769                 action=fields.NotificationAction.INTERFACE_ATTACH,
5770                 phase=fields.NotificationPhase.ERROR,
5771                 exception=ex)
5772 
5773             raise exception.InterfaceAttachFailed(
5774                 instance_uuid=instance.uuid)
5775 
5776         compute_utils.notify_about_instance_action(
5777             context, instance, self.host,
5778             action=fields.NotificationAction.INTERFACE_ATTACH,
5779             phase=fields.NotificationPhase.END)
5780 
5781         return network_info[0]
5782 
5783     @wrap_exception()
5784     @wrap_instance_event(prefix='compute')
5785     @wrap_instance_fault
5786     def detach_interface(self, context, instance, port_id):
5787         """Detach a network adapter from an instance."""
5788         network_info = instance.info_cache.network_info
5789         condemned = None
5790         for vif in network_info:
5791             if vif['id'] == port_id:
5792                 condemned = vif
5793                 break
5794         if condemned is None:
5795             raise exception.PortNotFound(_("Port %s is not "
5796                                            "attached") % port_id)
5797 
5798         compute_utils.notify_about_instance_action(
5799             context, instance, self.host,
5800             action=fields.NotificationAction.INTERFACE_DETACH,
5801             phase=fields.NotificationPhase.START)
5802 
5803         try:
5804             self.driver.detach_interface(context, instance, condemned)
5805         except exception.NovaException as ex:
5806             # If the instance was deleted before the interface was detached,
5807             # just log it at debug.
5808             log_level = (logging.DEBUG
5809                          if isinstance(ex, exception.InstanceNotFound)
5810                          else logging.WARNING)
5811             LOG.log(log_level,
5812                     "Detach interface failed, port_id=%(port_id)s, reason: "
5813                     "%(msg)s", {'port_id': port_id, 'msg': ex},
5814                     instance=instance)
5815             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5816         else:
5817             try:
5818                 self.network_api.deallocate_port_for_instance(
5819                     context, instance, port_id)
5820             except Exception as ex:
5821                 with excutils.save_and_reraise_exception():
5822                     # Since this is a cast operation, log the failure for
5823                     # triage.
5824                     LOG.warning('Failed to deallocate port %(port_id)s '
5825                                 'for instance. Error: %(error)s',
5826                                 {'port_id': port_id, 'error': ex},
5827                                 instance=instance)
5828 
5829         compute_utils.notify_about_instance_action(
5830             context, instance, self.host,
5831             action=fields.NotificationAction.INTERFACE_DETACH,
5832             phase=fields.NotificationPhase.END)
5833 
5834     def _get_compute_info(self, context, host):
5835         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5836             context, host)
5837 
5838     @wrap_exception()
5839     def check_instance_shared_storage(self, ctxt, instance, data):
5840         """Check if the instance files are shared
5841 
5842         :param ctxt: security context
5843         :param instance: dict of instance data
5844         :param data: result of driver.check_instance_shared_storage_local
5845 
5846         Returns True if instance disks located on shared storage and
5847         False otherwise.
5848         """
5849         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5850 
5851     @wrap_exception()
5852     @wrap_instance_event(prefix='compute')
5853     @wrap_instance_fault
5854     def check_can_live_migrate_destination(self, ctxt, instance,
5855                                            block_migration, disk_over_commit):
5856         """Check if it is possible to execute live migration.
5857 
5858         This runs checks on the destination host, and then calls
5859         back to the source host to check the results.
5860 
5861         :param context: security context
5862         :param instance: dict of instance data
5863         :param block_migration: if true, prepare for block migration
5864                                 if None, calculate it in driver
5865         :param disk_over_commit: if true, allow disk over commit
5866                                  if None, ignore disk usage checking
5867         :returns: a dict containing migration info
5868         """
5869         src_compute_info = obj_base.obj_to_primitive(
5870             self._get_compute_info(ctxt, instance.host))
5871         dst_compute_info = obj_base.obj_to_primitive(
5872             self._get_compute_info(ctxt, CONF.host))
5873         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5874             instance, src_compute_info, dst_compute_info,
5875             block_migration, disk_over_commit)
5876         LOG.debug('destination check data is %s', dest_check_data)
5877         try:
5878             migrate_data = self.compute_rpcapi.\
5879                                 check_can_live_migrate_source(ctxt, instance,
5880                                                               dest_check_data)
5881         finally:
5882             self.driver.cleanup_live_migration_destination_check(ctxt,
5883                     dest_check_data)
5884         return migrate_data
5885 
5886     @wrap_exception()
5887     @wrap_instance_event(prefix='compute')
5888     @wrap_instance_fault
5889     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5890         """Check if it is possible to execute live migration.
5891 
5892         This checks if the live migration can succeed, based on the
5893         results from check_can_live_migrate_destination.
5894 
5895         :param ctxt: security context
5896         :param instance: dict of instance data
5897         :param dest_check_data: result of check_can_live_migrate_destination
5898         :returns: a dict containing migration info
5899         """
5900         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5901             ctxt, instance.uuid)
5902         is_volume_backed = compute_utils.is_volume_backed_instance(
5903             ctxt, instance, bdms)
5904         dest_check_data.is_volume_backed = is_volume_backed
5905         block_device_info = self._get_instance_block_device_info(
5906                             ctxt, instance, refresh_conn_info=False, bdms=bdms)
5907         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5908                                                            dest_check_data,
5909                                                            block_device_info)
5910         LOG.debug('source check data is %s', result)
5911         return result
5912 
5913     @wrap_exception()
5914     @wrap_instance_event(prefix='compute')
5915     @wrap_instance_fault
5916     def pre_live_migration(self, context, instance, block_migration, disk,
5917                            migrate_data):
5918         """Preparations for live migration at dest host.
5919 
5920         :param context: security context
5921         :param instance: dict of instance data
5922         :param block_migration: if true, prepare for block migration
5923         :param disk: disk info of instance
5924         :param migrate_data: A dict or LiveMigrateData object holding data
5925                              required for live migration without shared
5926                              storage.
5927         :returns: migrate_data containing additional migration info
5928         """
5929         LOG.debug('pre_live_migration data is %s', migrate_data)
5930 
5931         migrate_data.old_vol_attachment_ids = {}
5932         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5933             context, instance.uuid)
5934         try:
5935             connector = self.driver.get_volume_connector(instance)
5936             for bdm in bdms:
5937                 if bdm.is_volume and bdm.attachment_id is not None:
5938                     # This bdm uses the new cinder v3.44 API.
5939                     # We will create a new attachment for this
5940                     # volume on this migration destination host. The old
5941                     # attachment will be deleted on the source host
5942                     # when the migration succeeds. The old attachment_id
5943                     # is stored in dict with the key being the bdm.volume_id
5944                     # so it can be restored on rollback.
5945                     #
5946                     # Also note that attachment_update is not needed as we
5947                     # are providing the connector in the create call.
5948                     attach_ref = self.volume_api.attachment_create(
5949                         context, bdm.volume_id, bdm.instance_uuid,
5950                         connector=connector, mountpoint=bdm.device_name)
5951 
5952                     # save current attachment so we can detach it on success,
5953                     # or restore it on a rollback.
5954                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
5955                         bdm.attachment_id
5956 
5957                     # update the bdm with the new attachment_id.
5958                     bdm.attachment_id = attach_ref['id']
5959                     bdm.save()
5960         except Exception:
5961             # If we raise, migrate_data with the updated attachment ids
5962             # will not be returned to the source host for rollback.
5963             # So we need to rollback new attachments here.
5964             with excutils.save_and_reraise_exception():
5965                 old_attachments = migrate_data.old_vol_attachment_ids
5966                 for bdm in bdms:
5967                     if (bdm.is_volume and bdm.attachment_id is not None and
5968                             bdm.volume_id in old_attachments):
5969                         self.volume_api.attachment_delete(context,
5970                                                           bdm.attachment_id)
5971                         bdm.attachment_id = old_attachments[bdm.volume_id]
5972                         bdm.save()
5973 
5974         block_device_info = self._get_instance_block_device_info(
5975                             context, instance, refresh_conn_info=True,
5976                             bdms=bdms)
5977 
5978         network_info = self.network_api.get_instance_nw_info(context, instance)
5979         self._notify_about_instance_usage(
5980                      context, instance, "live_migration.pre.start",
5981                      network_info=network_info)
5982         compute_utils.notify_about_instance_action(
5983             context, instance, self.host,
5984             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
5985             phase=fields.NotificationPhase.START)
5986 
5987         migrate_data = self.driver.pre_live_migration(context,
5988                                        instance,
5989                                        block_device_info,
5990                                        network_info,
5991                                        disk,
5992                                        migrate_data)
5993         LOG.debug('driver pre_live_migration data is %s', migrate_data)
5994 
5995         # Volume connections are complete, tell cinder that all the
5996         # attachments have completed.
5997         for bdm in bdms:
5998             if bdm.is_volume and bdm.attachment_id is not None:
5999                 self.volume_api.attachment_complete(context,
6000                                                     bdm.attachment_id)
6001 
6002         # NOTE(tr3buchet): setup networks on destination host
6003         self.network_api.setup_networks_on_host(context, instance,
6004                                                          self.host)
6005 
6006         # Creating filters to hypervisors and firewalls.
6007         # An example is that nova-instance-instance-xxx,
6008         # which is written to libvirt.xml(Check "virsh nwfilter-list")
6009         # This nwfilter is necessary on the destination host.
6010         # In addition, this method is creating filtering rule
6011         # onto destination host.
6012         self.driver.ensure_filtering_rules_for_instance(instance,
6013                                             network_info)
6014 
6015         self._notify_about_instance_usage(
6016                      context, instance, "live_migration.pre.end",
6017                      network_info=network_info)
6018         compute_utils.notify_about_instance_action(
6019             context, instance, self.host,
6020             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6021             phase=fields.NotificationPhase.END)
6022 
6023         LOG.debug('pre_live_migration result data is %s', migrate_data)
6024         return migrate_data
6025 
6026     def _do_live_migration(self, context, dest, instance, block_migration,
6027                            migration, migrate_data):
6028         # NOTE(danms): We should enhance the RT to account for migrations
6029         # and use the status field to denote when the accounting has been
6030         # done on source/destination. For now, this is just here for status
6031         # reporting
6032         self._set_migration_status(migration, 'preparing')
6033 
6034         try:
6035             if ('block_migration' in migrate_data and
6036                     migrate_data.block_migration):
6037                 block_device_info = self._get_instance_block_device_info(
6038                     context, instance)
6039                 disk = self.driver.get_instance_disk_info(
6040                     instance, block_device_info=block_device_info)
6041             else:
6042                 disk = None
6043 
6044             migrate_data = self.compute_rpcapi.pre_live_migration(
6045                 context, instance,
6046                 block_migration, disk, dest, migrate_data)
6047         except Exception:
6048             with excutils.save_and_reraise_exception():
6049                 LOG.exception('Pre live migration failed at %s',
6050                               dest, instance=instance)
6051                 self._set_migration_status(migration, 'error')
6052                 # Make sure we set this for _rollback_live_migration()
6053                 # so it can find it, as expected if it was called later
6054                 migrate_data.migration = migration
6055                 self._rollback_live_migration(context, instance, dest,
6056                                               migrate_data)
6057 
6058         self._set_migration_status(migration, 'running')
6059 
6060         if migrate_data:
6061             migrate_data.migration = migration
6062         LOG.debug('live_migration data is %s', migrate_data)
6063         try:
6064             self.driver.live_migration(context, instance, dest,
6065                                        self._post_live_migration,
6066                                        self._rollback_live_migration,
6067                                        block_migration, migrate_data)
6068         except Exception:
6069             LOG.exception('Live migration failed.', instance=instance)
6070             with excutils.save_and_reraise_exception():
6071                 # Put instance and migration into error state,
6072                 # as its almost certainly too late to rollback
6073                 self._set_migration_status(migration, 'error')
6074                 # first refresh instance as it may have got updated by
6075                 # post_live_migration_at_destination
6076                 instance.refresh()
6077                 self._set_instance_obj_error_state(context, instance,
6078                                                    clean_task_state=True)
6079 
6080     @wrap_exception()
6081     @wrap_instance_event(prefix='compute')
6082     @wrap_instance_fault
6083     def live_migration(self, context, dest, instance, block_migration,
6084                        migration, migrate_data):
6085         """Executing live migration.
6086 
6087         :param context: security context
6088         :param dest: destination host
6089         :param instance: a nova.objects.instance.Instance object
6090         :param block_migration: if true, prepare for block migration
6091         :param migration: an nova.objects.Migration object
6092         :param migrate_data: implementation specific params
6093 
6094         """
6095         self._set_migration_status(migration, 'queued')
6096 
6097         def dispatch_live_migration(*args, **kwargs):
6098             with self._live_migration_semaphore:
6099                 self._do_live_migration(*args, **kwargs)
6100 
6101         # NOTE(danms): We spawn here to return the RPC worker thread back to
6102         # the pool. Since what follows could take a really long time, we don't
6103         # want to tie up RPC workers.
6104         utils.spawn_n(dispatch_live_migration,
6105                       context, dest, instance,
6106                       block_migration, migration,
6107                       migrate_data)
6108 
6109     @wrap_exception()
6110     @wrap_instance_event(prefix='compute')
6111     @wrap_instance_fault
6112     def live_migration_force_complete(self, context, instance):
6113         """Force live migration to complete.
6114 
6115         :param context: Security context
6116         :param instance: The instance that is being migrated
6117         """
6118 
6119         self._notify_about_instance_usage(
6120             context, instance, 'live.migration.force.complete.start')
6121         self.driver.live_migration_force_complete(instance)
6122         self._notify_about_instance_usage(
6123             context, instance, 'live.migration.force.complete.end')
6124 
6125     @wrap_exception()
6126     @wrap_instance_event(prefix='compute')
6127     @wrap_instance_fault
6128     def live_migration_abort(self, context, instance, migration_id):
6129         """Abort an in-progress live migration.
6130 
6131         :param context: Security context
6132         :param instance: The instance that is being migrated
6133         :param migration_id: ID of in-progress live migration
6134 
6135         """
6136         migration = objects.Migration.get_by_id(context, migration_id)
6137         if migration.status != 'running':
6138             raise exception.InvalidMigrationState(migration_id=migration_id,
6139                     instance_uuid=instance.uuid,
6140                     state=migration.status,
6141                     method='abort live migration')
6142 
6143         self._notify_about_instance_usage(
6144             context, instance, 'live.migration.abort.start')
6145         compute_utils.notify_about_instance_action(
6146             context, instance, self.host,
6147             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6148             phase=fields.NotificationPhase.START)
6149         self.driver.live_migration_abort(instance)
6150         self._notify_about_instance_usage(
6151             context, instance, 'live.migration.abort.end')
6152         compute_utils.notify_about_instance_action(
6153             context, instance, self.host,
6154             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6155             phase=fields.NotificationPhase.END)
6156 
6157     def _live_migration_cleanup_flags(self, migrate_data):
6158         """Determine whether disks or instance path need to be cleaned up after
6159         live migration (at source on success, at destination on rollback)
6160 
6161         Block migration needs empty image at destination host before migration
6162         starts, so if any failure occurs, any empty images has to be deleted.
6163 
6164         Also Volume backed live migration w/o shared storage needs to delete
6165         newly created instance-xxx dir on the destination as a part of its
6166         rollback process
6167 
6168         :param migrate_data: implementation specific data
6169         :returns: (bool, bool) -- do_cleanup, destroy_disks
6170         """
6171         # NOTE(pkoniszewski): block migration specific params are set inside
6172         # migrate_data objects for drivers that expose block live migration
6173         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6174         # cleanup is not needed.
6175         is_shared_block_storage = True
6176         is_shared_instance_path = True
6177         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6178             is_shared_block_storage = migrate_data.is_shared_block_storage
6179             is_shared_instance_path = migrate_data.is_shared_instance_path
6180         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6181             is_shared_block_storage = not migrate_data.block_migration
6182             is_shared_instance_path = not migrate_data.block_migration
6183         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6184             is_shared_instance_path = migrate_data.is_shared_instance_path
6185             is_shared_block_storage = migrate_data.is_shared_instance_path
6186 
6187         # No instance booting at source host, but instance dir
6188         # must be deleted for preparing next block migration
6189         # must be deleted for preparing next live migration w/o shared storage
6190         do_cleanup = not is_shared_instance_path
6191         destroy_disks = not is_shared_block_storage
6192 
6193         return (do_cleanup, destroy_disks)
6194 
6195     @wrap_exception()
6196     @wrap_instance_fault
6197     def _post_live_migration(self, ctxt, instance,
6198                             dest, block_migration=False, migrate_data=None):
6199         """Post operations for live migration.
6200 
6201         This method is called from live_migration
6202         and mainly updating database record.
6203 
6204         :param ctxt: security context
6205         :param instance: instance dict
6206         :param dest: destination host
6207         :param block_migration: if true, prepare for block migration
6208         :param migrate_data: if not None, it is a dict which has data
6209         required for live migration without shared storage
6210 
6211         """
6212         LOG.info('_post_live_migration() is started..',
6213                  instance=instance)
6214 
6215         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6216                 ctxt, instance.uuid)
6217 
6218         # Cleanup source host post live-migration
6219         block_device_info = self._get_instance_block_device_info(
6220                             ctxt, instance, bdms=bdms)
6221         self.driver.post_live_migration(ctxt, instance, block_device_info,
6222                                         migrate_data)
6223 
6224         # Detaching volumes.
6225         connector = self.driver.get_volume_connector(instance)
6226         for bdm in bdms:
6227             if bdm.is_volume:
6228                 if bdm.attachment_id is None:
6229                     # Prior to cinder v3.44:
6230                     # We don't want to actually mark the volume detached, or
6231                     # delete the bdm, just remove the connection from this
6232                     # host.
6233                     #
6234                     # remove the volume connection without detaching from
6235                     # hypervisor because the instance is not running anymore
6236                     # on the current host
6237                     self.volume_api.terminate_connection(ctxt, bdm.volume_id,
6238                                                          connector)
6239                 else:
6240                     # cinder v3.44 api flow - delete the old attachment
6241                     # for the source host
6242                     old_attachment_id = \
6243                         migrate_data.old_vol_attachment_ids[bdm.volume_id]
6244                     self.volume_api.attachment_delete(ctxt, old_attachment_id)
6245 
6246         # Releasing vlan.
6247         # (not necessary in current implementation?)
6248 
6249         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
6250 
6251         self._notify_about_instance_usage(ctxt, instance,
6252                                           "live_migration._post.start",
6253                                           network_info=network_info)
6254         # Releasing security group ingress rule.
6255         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
6256                   instance=instance)
6257         self.driver.unfilter_instance(instance,
6258                                       network_info)
6259 
6260         migration = {'source_compute': self.host,
6261                      'dest_compute': dest, }
6262         self.network_api.migrate_instance_start(ctxt,
6263                                                 instance,
6264                                                 migration)
6265 
6266         destroy_vifs = False
6267         try:
6268             self.driver.post_live_migration_at_source(ctxt, instance,
6269                                                       network_info)
6270         except NotImplementedError as ex:
6271             LOG.debug(ex, instance=instance)
6272             # For all hypervisors other than libvirt, there is a possibility
6273             # they are unplugging networks from source node in the cleanup
6274             # method
6275             destroy_vifs = True
6276 
6277         # NOTE(danms): Save source node before calling post method on
6278         # destination, which will update it
6279         source_node = instance.node
6280 
6281         # Define domain at destination host, without doing it,
6282         # pause/suspend/terminate do not work.
6283         post_at_dest_success = True
6284         try:
6285             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
6286                     instance, block_migration, dest)
6287         except Exception as error:
6288             post_at_dest_success = False
6289             # We don't want to break _post_live_migration() if
6290             # post_live_migration_at_destination() fails as it should never
6291             # affect cleaning up source node.
6292             LOG.exception("Post live migration at destination %s failed",
6293                           dest, instance=instance, error=error)
6294 
6295         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6296                 migrate_data)
6297 
6298         if do_cleanup:
6299             LOG.debug('Calling driver.cleanup from _post_live_migration',
6300                       instance=instance)
6301             self.driver.cleanup(ctxt, instance, network_info,
6302                                 destroy_disks=destroy_disks,
6303                                 migrate_data=migrate_data,
6304                                 destroy_vifs=destroy_vifs)
6305 
6306         self.instance_events.clear_events_for_instance(instance)
6307 
6308         # NOTE(timello): make sure we update available resources on source
6309         # host even before next periodic task.
6310         self.update_available_resource(ctxt)
6311 
6312         self._update_scheduler_instance_info(ctxt, instance)
6313         self._notify_about_instance_usage(ctxt, instance,
6314                                           "live_migration._post.end",
6315                                           network_info=network_info)
6316         if post_at_dest_success:
6317             LOG.info('Migrating instance to %s finished successfully.',
6318                      dest, instance=instance)
6319 
6320         if migrate_data and migrate_data.obj_attr_is_set('migration'):
6321             migrate_data.migration.status = 'completed'
6322             migrate_data.migration.save()
6323             migration = migrate_data.migration
6324             rc = self.scheduler_client.reportclient
6325             # Check to see if our migration has its own allocations
6326             allocs = rc.get_allocations_for_consumer(ctxt, migration.uuid)
6327         else:
6328             # We didn't have data on a migration, which means we can't
6329             # look up to see if we had new-style migration-based
6330             # allocations. This should really only happen in cases of
6331             # a buggy virt driver or some really old component in the
6332             # system. Log a warning so we know it happened.
6333             allocs = None
6334             LOG.warning('Live migration ended with no migrate_data '
6335                         'record. Unable to clean up migration-based '
6336                         'allocations which is almost certainly not '
6337                         'an expected situation.')
6338 
6339         if allocs:
6340             # We had a migration-based allocation that we need to handle
6341             self._delete_allocation_after_move(ctxt,
6342                                                instance,
6343                                                migrate_data.migration,
6344                                                instance.flavor,
6345                                                source_node)
6346         else:
6347             # No migration-based allocations, so do the old thing and
6348             # attempt to clean up any doubled per-instance allocation
6349             rt = self._get_resource_tracker()
6350             rt.delete_allocation_for_migrated_instance(
6351                 ctxt, instance, source_node)
6352 
6353     def _consoles_enabled(self):
6354         """Returns whether a console is enable."""
6355         return (CONF.vnc.enabled or CONF.spice.enabled or
6356                 CONF.rdp.enabled or CONF.serial_console.enabled or
6357                 CONF.mks.enabled)
6358 
6359     @wrap_exception()
6360     @wrap_instance_event(prefix='compute')
6361     @wrap_instance_fault
6362     def post_live_migration_at_destination(self, context, instance,
6363                                            block_migration):
6364         """Post operations for live migration .
6365 
6366         :param context: security context
6367         :param instance: Instance dict
6368         :param block_migration: if true, prepare for block migration
6369 
6370         """
6371         LOG.info('Post operation of migration started',
6372                  instance=instance)
6373 
6374         # NOTE(tr3buchet): setup networks on destination host
6375         #                  this is called a second time because
6376         #                  multi_host does not create the bridge in
6377         #                  plug_vifs
6378         self.network_api.setup_networks_on_host(context, instance,
6379                                                          self.host)
6380         migration = {'source_compute': instance.host,
6381                      'dest_compute': self.host, }
6382         self.network_api.migrate_instance_finish(context,
6383                                                  instance,
6384                                                  migration)
6385 
6386         network_info = self.network_api.get_instance_nw_info(context, instance)
6387         self._notify_about_instance_usage(
6388                      context, instance, "live_migration.post.dest.start",
6389                      network_info=network_info)
6390         compute_utils.notify_about_instance_action(context, instance,
6391                 self.host,
6392                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6393                 phase=fields.NotificationPhase.START)
6394         block_device_info = self._get_instance_block_device_info(context,
6395                                                                  instance)
6396 
6397         try:
6398             self.driver.post_live_migration_at_destination(
6399                 context, instance, network_info, block_migration,
6400                 block_device_info)
6401         except Exception:
6402             with excutils.save_and_reraise_exception():
6403                 instance.vm_state = vm_states.ERROR
6404                 LOG.error('Unexpected error during post live migration at '
6405                           'destination host.', instance=instance)
6406         finally:
6407             # Restore instance state and update host
6408             current_power_state = self._get_power_state(context, instance)
6409             node_name = None
6410             prev_host = instance.host
6411             try:
6412                 compute_node = self._get_compute_info(context, self.host)
6413                 node_name = compute_node.hypervisor_hostname
6414             except exception.ComputeHostNotFound:
6415                 LOG.exception('Failed to get compute_info for %s', self.host)
6416             finally:
6417                 instance.host = self.host
6418                 instance.power_state = current_power_state
6419                 instance.task_state = None
6420                 instance.node = node_name
6421                 instance.progress = 0
6422                 instance.save(expected_task_state=task_states.MIGRATING)
6423 
6424         # NOTE(tr3buchet): tear down networks on source host
6425         self.network_api.setup_networks_on_host(context, instance,
6426                                                 prev_host, teardown=True)
6427         # NOTE(vish): this is necessary to update dhcp
6428         self.network_api.setup_networks_on_host(context, instance, self.host)
6429         self._notify_about_instance_usage(
6430                      context, instance, "live_migration.post.dest.end",
6431                      network_info=network_info)
6432         compute_utils.notify_about_instance_action(context, instance,
6433                 self.host,
6434                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6435                 phase=fields.NotificationPhase.END)
6436 
6437     @wrap_exception()
6438     @wrap_instance_fault
6439     def _rollback_live_migration(self, context, instance,
6440                                  dest, migrate_data=None,
6441                                  migration_status='error'):
6442         """Recovers Instance/volume state from migrating -> running.
6443 
6444         :param context: security context
6445         :param instance: nova.objects.instance.Instance object
6446         :param dest:
6447             This method is called from live migration src host.
6448             This param specifies destination host.
6449         :param migrate_data:
6450             if not none, contains implementation specific data.
6451         :param migration_status:
6452             Contains the status we want to set for the migration object
6453 
6454         """
6455         if (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
6456               migrate_data.obj_attr_is_set('migration')):
6457             migration = migrate_data.migration
6458         else:
6459             migration = None
6460 
6461         if migration:
6462             # Remove allocations created in Placement for the dest node.
6463             # If migration is None, we must be so old we don't have placement,
6464             # so no need to do something else.
6465             self._revert_allocation(context, instance, migration)
6466         else:
6467             LOG.error('Unable to revert allocations during live migration '
6468                       'rollback; compute driver did not provide migrate_data',
6469                       instance=instance)
6470 
6471         instance.task_state = None
6472         instance.progress = 0
6473         instance.save(expected_task_state=[task_states.MIGRATING])
6474 
6475         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
6476         self.network_api.setup_networks_on_host(context, instance, self.host)
6477 
6478         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6479                 context, instance.uuid)
6480         for bdm in bdms:
6481             if bdm.is_volume:
6482                 # remove the connection on the destination host
6483                 self.compute_rpcapi.remove_volume_connection(
6484                         context, instance, bdm.volume_id, dest)
6485 
6486                 if bdm.attachment_id:
6487                     # 3.44 cinder api flow. Set the bdm's
6488                     # attachment_id to the old attachment of the source
6489                     # host. If old_attachments is not there, then
6490                     # there was an error before the new attachment was made.
6491                     old_attachments = migrate_data.old_vol_attachment_ids \
6492                         if 'old_vol_attachment_ids' in migrate_data else None
6493                     if old_attachments and bdm.volume_id in old_attachments:
6494                         self.volume_api.attachment_delete(context,
6495                                                           bdm.attachment_id)
6496                         bdm.attachment_id = old_attachments[bdm.volume_id]
6497                         bdm.save()
6498 
6499         self._notify_about_instance_usage(context, instance,
6500                                           "live_migration._rollback.start")
6501         compute_utils.notify_about_instance_action(context, instance,
6502                 self.host,
6503                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6504                 phase=fields.NotificationPhase.START,
6505                 bdms=bdms)
6506 
6507         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6508                 migrate_data)
6509 
6510         if do_cleanup:
6511             self.compute_rpcapi.rollback_live_migration_at_destination(
6512                     context, instance, dest, destroy_disks=destroy_disks,
6513                     migrate_data=migrate_data)
6514         elif utils.is_neutron():
6515             # The port binding profiles need to be cleaned up.
6516             with errors_out_migration_ctxt(migration):
6517                 try:
6518                     self.network_api.setup_networks_on_host(
6519                         context, instance, teardown=True)
6520                 except Exception:
6521                     with excutils.save_and_reraise_exception():
6522                         LOG.exception(
6523                             'An error occurred while cleaning up networking '
6524                             'during live migration rollback.',
6525                             instance=instance)
6526 
6527         self._notify_about_instance_usage(context, instance,
6528                                           "live_migration._rollback.end")
6529         compute_utils.notify_about_instance_action(context, instance,
6530 
6531                 self.host,
6532                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6533                 phase=fields.NotificationPhase.END,
6534                 bdms=bdms)
6535 
6536         self._set_migration_status(migration, migration_status)
6537 
6538     @wrap_exception()
6539     @wrap_instance_event(prefix='compute')
6540     @wrap_instance_fault
6541     def rollback_live_migration_at_destination(self, context, instance,
6542                                                destroy_disks,
6543                                                migrate_data):
6544         """Cleaning up image directory that is created pre_live_migration.
6545 
6546         :param context: security context
6547         :param instance: a nova.objects.instance.Instance object sent over rpc
6548         :param destroy_disks: whether to destroy volumes or not
6549         :param migrate_data: contains migration info
6550         """
6551         network_info = self.network_api.get_instance_nw_info(context, instance)
6552         self._notify_about_instance_usage(
6553                       context, instance, "live_migration.rollback.dest.start",
6554                       network_info=network_info)
6555         try:
6556             # NOTE(tr3buchet): tear down networks on destination host
6557             self.network_api.setup_networks_on_host(context, instance,
6558                                                     self.host, teardown=True)
6559         except Exception:
6560             with excutils.save_and_reraise_exception():
6561                 # NOTE(tdurakov): even if teardown networks fails driver
6562                 # should try to rollback live migration on destination.
6563                 LOG.exception('An error occurred while deallocating network.',
6564                               instance=instance)
6565         finally:
6566             # always run this even if setup_networks_on_host fails
6567             # NOTE(vish): The mapping is passed in so the driver can disconnect
6568             #             from remote volumes if necessary
6569             block_device_info = self._get_instance_block_device_info(context,
6570                                                                      instance)
6571             self.driver.rollback_live_migration_at_destination(
6572                 context, instance, network_info, block_device_info,
6573                 destroy_disks=destroy_disks, migrate_data=migrate_data)
6574 
6575         self._notify_about_instance_usage(
6576                         context, instance, "live_migration.rollback.dest.end",
6577                         network_info=network_info)
6578 
6579     @periodic_task.periodic_task(
6580         spacing=CONF.heal_instance_info_cache_interval)
6581     def _heal_instance_info_cache(self, context):
6582         """Called periodically.  On every call, try to update the
6583         info_cache's network information for another instance by
6584         calling to the network manager.
6585 
6586         This is implemented by keeping a cache of uuids of instances
6587         that live on this host.  On each call, we pop one off of a
6588         list, pull the DB record, and try the call to the network API.
6589         If anything errors don't fail, as it's possible the instance
6590         has been deleted, etc.
6591         """
6592         heal_interval = CONF.heal_instance_info_cache_interval
6593         if not heal_interval:
6594             return
6595 
6596         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
6597         instance = None
6598 
6599         LOG.debug('Starting heal instance info cache')
6600 
6601         if not instance_uuids:
6602             # The list of instances to heal is empty so rebuild it
6603             LOG.debug('Rebuilding the list of instances to heal')
6604             db_instances = objects.InstanceList.get_by_host(
6605                 context, self.host, expected_attrs=[], use_slave=True)
6606             for inst in db_instances:
6607                 # We don't want to refresh the cache for instances
6608                 # which are building or deleting so don't put them
6609                 # in the list. If they are building they will get
6610                 # added to the list next time we build it.
6611                 if (inst.vm_state == vm_states.BUILDING):
6612                     LOG.debug('Skipping network cache update for instance '
6613                               'because it is Building.', instance=inst)
6614                     continue
6615                 if (inst.task_state == task_states.DELETING):
6616                     LOG.debug('Skipping network cache update for instance '
6617                               'because it is being deleted.', instance=inst)
6618                     continue
6619 
6620                 if not instance:
6621                     # Save the first one we find so we don't
6622                     # have to get it again
6623                     instance = inst
6624                 else:
6625                     instance_uuids.append(inst['uuid'])
6626 
6627             self._instance_uuids_to_heal = instance_uuids
6628         else:
6629             # Find the next valid instance on the list
6630             while instance_uuids:
6631                 try:
6632                     inst = objects.Instance.get_by_uuid(
6633                             context, instance_uuids.pop(0),
6634                             expected_attrs=['system_metadata', 'info_cache',
6635                                             'flavor'],
6636                             use_slave=True)
6637                 except exception.InstanceNotFound:
6638                     # Instance is gone.  Try to grab another.
6639                     continue
6640 
6641                 # Check the instance hasn't been migrated
6642                 if inst.host != self.host:
6643                     LOG.debug('Skipping network cache update for instance '
6644                               'because it has been migrated to another '
6645                               'host.', instance=inst)
6646                 # Check the instance isn't being deleting
6647                 elif inst.task_state == task_states.DELETING:
6648                     LOG.debug('Skipping network cache update for instance '
6649                               'because it is being deleted.', instance=inst)
6650                 else:
6651                     instance = inst
6652                     break
6653 
6654         if instance:
6655             # We have an instance now to refresh
6656             try:
6657                 # Call to network API to get instance info.. this will
6658                 # force an update to the instance's info_cache
6659                 self.network_api.get_instance_nw_info(context, instance)
6660                 LOG.debug('Updated the network info_cache for instance',
6661                           instance=instance)
6662             except exception.InstanceNotFound:
6663                 # Instance is gone.
6664                 LOG.debug('Instance no longer exists. Unable to refresh',
6665                           instance=instance)
6666                 return
6667             except exception.InstanceInfoCacheNotFound:
6668                 # InstanceInfoCache is gone.
6669                 LOG.debug('InstanceInfoCache no longer exists. '
6670                           'Unable to refresh', instance=instance)
6671             except Exception:
6672                 LOG.error('An error occurred while refreshing the network '
6673                           'cache.', instance=instance, exc_info=True)
6674         else:
6675             LOG.debug("Didn't find any instances for network info cache "
6676                       "update.")
6677 
6678     @periodic_task.periodic_task
6679     def _poll_rebooting_instances(self, context):
6680         if CONF.reboot_timeout > 0:
6681             filters = {'task_state':
6682                        [task_states.REBOOTING,
6683                         task_states.REBOOT_STARTED,
6684                         task_states.REBOOT_PENDING],
6685                        'host': self.host}
6686             rebooting = objects.InstanceList.get_by_filters(
6687                 context, filters, expected_attrs=[], use_slave=True)
6688 
6689             to_poll = []
6690             for instance in rebooting:
6691                 if timeutils.is_older_than(instance.updated_at,
6692                                            CONF.reboot_timeout):
6693                     to_poll.append(instance)
6694 
6695             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
6696 
6697     @periodic_task.periodic_task
6698     def _poll_rescued_instances(self, context):
6699         if CONF.rescue_timeout > 0:
6700             filters = {'vm_state': vm_states.RESCUED,
6701                        'host': self.host}
6702             rescued_instances = objects.InstanceList.get_by_filters(
6703                 context, filters, expected_attrs=["system_metadata"],
6704                 use_slave=True)
6705 
6706             to_unrescue = []
6707             for instance in rescued_instances:
6708                 if timeutils.is_older_than(instance.launched_at,
6709                                            CONF.rescue_timeout):
6710                     to_unrescue.append(instance)
6711 
6712             for instance in to_unrescue:
6713                 self.compute_api.unrescue(context, instance)
6714 
6715     @periodic_task.periodic_task
6716     def _poll_unconfirmed_resizes(self, context):
6717         if CONF.resize_confirm_window == 0:
6718             return
6719 
6720         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
6721                 context, CONF.resize_confirm_window, self.host,
6722                 use_slave=True)
6723 
6724         migrations_info = dict(migration_count=len(migrations),
6725                 confirm_window=CONF.resize_confirm_window)
6726 
6727         if migrations_info["migration_count"] > 0:
6728             LOG.info("Found %(migration_count)d unconfirmed migrations "
6729                      "older than %(confirm_window)d seconds",
6730                      migrations_info)
6731 
6732         def _set_migration_to_error(migration, reason, **kwargs):
6733             LOG.warning("Setting migration %(migration_id)s to error: "
6734                         "%(reason)s",
6735                         {'migration_id': migration['id'], 'reason': reason},
6736                         **kwargs)
6737             migration.status = 'error'
6738             with migration.obj_as_admin():
6739                 migration.save()
6740 
6741         for migration in migrations:
6742             instance_uuid = migration.instance_uuid
6743             LOG.info("Automatically confirming migration "
6744                      "%(migration_id)s for instance %(instance_uuid)s",
6745                      {'migration_id': migration.id,
6746                       'instance_uuid': instance_uuid})
6747             expected_attrs = ['metadata', 'system_metadata']
6748             try:
6749                 instance = objects.Instance.get_by_uuid(context,
6750                             instance_uuid, expected_attrs=expected_attrs,
6751                             use_slave=True)
6752             except exception.InstanceNotFound:
6753                 reason = (_("Instance %s not found") %
6754                           instance_uuid)
6755                 _set_migration_to_error(migration, reason)
6756                 continue
6757             if instance.vm_state == vm_states.ERROR:
6758                 reason = _("In ERROR state")
6759                 _set_migration_to_error(migration, reason,
6760                                         instance=instance)
6761                 continue
6762             # race condition: The instance in DELETING state should not be
6763             # set the migration state to error, otherwise the instance in
6764             # to be deleted which is in RESIZED state
6765             # will not be able to confirm resize
6766             if instance.task_state in [task_states.DELETING,
6767                                        task_states.SOFT_DELETING]:
6768                 msg = ("Instance being deleted or soft deleted during resize "
6769                        "confirmation. Skipping.")
6770                 LOG.debug(msg, instance=instance)
6771                 continue
6772 
6773             # race condition: This condition is hit when this method is
6774             # called between the save of the migration record with a status of
6775             # finished and the save of the instance object with a state of
6776             # RESIZED. The migration record should not be set to error.
6777             if instance.task_state == task_states.RESIZE_FINISH:
6778                 msg = ("Instance still resizing during resize "
6779                        "confirmation. Skipping.")
6780                 LOG.debug(msg, instance=instance)
6781                 continue
6782 
6783             vm_state = instance.vm_state
6784             task_state = instance.task_state
6785             if vm_state != vm_states.RESIZED or task_state is not None:
6786                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
6787                            "RESIZED/None") %
6788                           {'vm_state': vm_state,
6789                            'task_state': task_state})
6790                 _set_migration_to_error(migration, reason,
6791                                         instance=instance)
6792                 continue
6793             try:
6794                 self.compute_api.confirm_resize(context, instance,
6795                                                 migration=migration)
6796             except Exception as e:
6797                 LOG.info("Error auto-confirming resize: %s. "
6798                          "Will retry later.", e, instance=instance)
6799 
6800     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
6801     def _poll_shelved_instances(self, context):
6802 
6803         if CONF.shelved_offload_time <= 0:
6804             return
6805 
6806         filters = {'vm_state': vm_states.SHELVED,
6807                    'task_state': None,
6808                    'host': self.host}
6809         shelved_instances = objects.InstanceList.get_by_filters(
6810             context, filters=filters, expected_attrs=['system_metadata'],
6811             use_slave=True)
6812 
6813         to_gc = []
6814         for instance in shelved_instances:
6815             sys_meta = instance.system_metadata
6816             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
6817             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
6818                 to_gc.append(instance)
6819 
6820         for instance in to_gc:
6821             try:
6822                 instance.task_state = task_states.SHELVING_OFFLOADING
6823                 instance.save(expected_task_state=(None,))
6824                 self.shelve_offload_instance(context, instance,
6825                                              clean_shutdown=False)
6826             except Exception:
6827                 LOG.exception('Periodic task failed to offload instance.',
6828                               instance=instance)
6829 
6830     @periodic_task.periodic_task
6831     def _instance_usage_audit(self, context):
6832         if not CONF.instance_usage_audit:
6833             return
6834 
6835         begin, end = utils.last_completed_audit_period()
6836         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
6837                                self.host):
6838             return
6839 
6840         instances = objects.InstanceList.get_active_by_window_joined(
6841             context, begin, end, host=self.host,
6842             expected_attrs=['system_metadata', 'info_cache', 'metadata',
6843                             'flavor'],
6844             use_slave=True)
6845         num_instances = len(instances)
6846         errors = 0
6847         successes = 0
6848         LOG.info("Running instance usage audit for host %(host)s "
6849                  "from %(begin_time)s to %(end_time)s. "
6850                  "%(number_instances)s instances.",
6851                  {'host': self.host,
6852                   'begin_time': begin,
6853                   'end_time': end,
6854                   'number_instances': num_instances})
6855         start_time = time.time()
6856         task_log = objects.TaskLog(context)
6857         task_log.task_name = 'instance_usage_audit'
6858         task_log.period_beginning = begin
6859         task_log.period_ending = end
6860         task_log.host = self.host
6861         task_log.task_items = num_instances
6862         task_log.message = 'Instance usage audit started...'
6863         task_log.begin_task()
6864         for instance in instances:
6865             try:
6866                 compute_utils.notify_usage_exists(
6867                     self.notifier, context, instance,
6868                     ignore_missing_network_data=False)
6869                 successes += 1
6870             except Exception:
6871                 LOG.exception('Failed to generate usage '
6872                               'audit for instance '
6873                               'on host %s', self.host,
6874                               instance=instance)
6875                 errors += 1
6876         task_log.errors = errors
6877         task_log.message = (
6878             'Instance usage audit ran for host %s, %s instances in %s seconds.'
6879             % (self.host, num_instances, time.time() - start_time))
6880         task_log.end_task()
6881 
6882     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
6883     def _poll_bandwidth_usage(self, context):
6884 
6885         if not self._bw_usage_supported:
6886             return
6887 
6888         prev_time, start_time = utils.last_completed_audit_period()
6889 
6890         curr_time = time.time()
6891         if (curr_time - self._last_bw_usage_poll >
6892                 CONF.bandwidth_poll_interval):
6893             self._last_bw_usage_poll = curr_time
6894             LOG.info("Updating bandwidth usage cache")
6895             cells_update_interval = CONF.cells.bandwidth_update_interval
6896             if (cells_update_interval > 0 and
6897                    curr_time - self._last_bw_usage_cell_update >
6898                            cells_update_interval):
6899                 self._last_bw_usage_cell_update = curr_time
6900                 update_cells = True
6901             else:
6902                 update_cells = False
6903 
6904             instances = objects.InstanceList.get_by_host(context,
6905                                                               self.host,
6906                                                               use_slave=True)
6907             try:
6908                 bw_counters = self.driver.get_all_bw_counters(instances)
6909             except NotImplementedError:
6910                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
6911                 # implemented yet.  If they don't it doesn't break anything,
6912                 # they just don't get the info in the usage events.
6913                 # NOTE(PhilDay): Record that its not supported so we can
6914                 # skip fast on future calls rather than waste effort getting
6915                 # the list of instances.
6916                 LOG.info("Bandwidth usage not supported by %(driver)s.",
6917                          {'driver': CONF.compute_driver})
6918                 self._bw_usage_supported = False
6919                 return
6920 
6921             refreshed = timeutils.utcnow()
6922             for bw_ctr in bw_counters:
6923                 # Allow switching of greenthreads between queries.
6924                 greenthread.sleep(0)
6925                 bw_in = 0
6926                 bw_out = 0
6927                 last_ctr_in = None
6928                 last_ctr_out = None
6929                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6930                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6931                     start_period=start_time, use_slave=True)
6932                 if usage:
6933                     bw_in = usage.bw_in
6934                     bw_out = usage.bw_out
6935                     last_ctr_in = usage.last_ctr_in
6936                     last_ctr_out = usage.last_ctr_out
6937                 else:
6938                     usage = (objects.BandwidthUsage.
6939                              get_by_instance_uuid_and_mac(
6940                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6941                         start_period=prev_time, use_slave=True))
6942                     if usage:
6943                         last_ctr_in = usage.last_ctr_in
6944                         last_ctr_out = usage.last_ctr_out
6945 
6946                 if last_ctr_in is not None:
6947                     if bw_ctr['bw_in'] < last_ctr_in:
6948                         # counter rollover
6949                         bw_in += bw_ctr['bw_in']
6950                     else:
6951                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6952 
6953                 if last_ctr_out is not None:
6954                     if bw_ctr['bw_out'] < last_ctr_out:
6955                         # counter rollover
6956                         bw_out += bw_ctr['bw_out']
6957                     else:
6958                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6959 
6960                 objects.BandwidthUsage(context=context).create(
6961                                               bw_ctr['uuid'],
6962                                               bw_ctr['mac_address'],
6963                                               bw_in,
6964                                               bw_out,
6965                                               bw_ctr['bw_in'],
6966                                               bw_ctr['bw_out'],
6967                                               start_period=start_time,
6968                                               last_refreshed=refreshed,
6969                                               update_cells=update_cells)
6970 
6971     def _get_host_volume_bdms(self, context, use_slave=False):
6972         """Return all block device mappings on a compute host."""
6973         compute_host_bdms = []
6974         instances = objects.InstanceList.get_by_host(context, self.host,
6975             use_slave=use_slave)
6976         for instance in instances:
6977             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6978                     context, instance.uuid, use_slave=use_slave)
6979             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6980             compute_host_bdms.append(dict(instance=instance,
6981                                           instance_bdms=instance_bdms))
6982 
6983         return compute_host_bdms
6984 
6985     def _update_volume_usage_cache(self, context, vol_usages):
6986         """Updates the volume usage cache table with a list of stats."""
6987         for usage in vol_usages:
6988             # Allow switching of greenthreads between queries.
6989             greenthread.sleep(0)
6990             vol_usage = objects.VolumeUsage(context)
6991             vol_usage.volume_id = usage['volume']
6992             vol_usage.instance_uuid = usage['instance'].uuid
6993             vol_usage.project_id = usage['instance'].project_id
6994             vol_usage.user_id = usage['instance'].user_id
6995             vol_usage.availability_zone = usage['instance'].availability_zone
6996             vol_usage.curr_reads = usage['rd_req']
6997             vol_usage.curr_read_bytes = usage['rd_bytes']
6998             vol_usage.curr_writes = usage['wr_req']
6999             vol_usage.curr_write_bytes = usage['wr_bytes']
7000             vol_usage.save()
7001             self.notifier.info(context, 'volume.usage',
7002                                compute_utils.usage_volume_info(vol_usage))
7003 
7004     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
7005     def _poll_volume_usage(self, context):
7006         if CONF.volume_usage_poll_interval == 0:
7007             return
7008 
7009         compute_host_bdms = self._get_host_volume_bdms(context,
7010                                                        use_slave=True)
7011         if not compute_host_bdms:
7012             return
7013 
7014         LOG.debug("Updating volume usage cache")
7015         try:
7016             vol_usages = self.driver.get_all_volume_usage(context,
7017                                                           compute_host_bdms)
7018         except NotImplementedError:
7019             return
7020 
7021         self._update_volume_usage_cache(context, vol_usages)
7022 
7023     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
7024                                  run_immediately=True)
7025     def _sync_power_states(self, context):
7026         """Align power states between the database and the hypervisor.
7027 
7028         To sync power state data we make a DB call to get the number of
7029         virtual machines known by the hypervisor and if the number matches the
7030         number of virtual machines known by the database, we proceed in a lazy
7031         loop, one database record at a time, checking if the hypervisor has the
7032         same power state as is in the database.
7033         """
7034         db_instances = objects.InstanceList.get_by_host(context, self.host,
7035                                                         expected_attrs=[],
7036                                                         use_slave=True)
7037 
7038         num_vm_instances = self.driver.get_num_instances()
7039         num_db_instances = len(db_instances)
7040 
7041         if num_vm_instances != num_db_instances:
7042             LOG.warning("While synchronizing instance power states, found "
7043                         "%(num_db_instances)s instances in the database "
7044                         "and %(num_vm_instances)s instances on the "
7045                         "hypervisor.",
7046                         {'num_db_instances': num_db_instances,
7047                          'num_vm_instances': num_vm_instances})
7048 
7049         def _sync(db_instance):
7050             # NOTE(melwitt): This must be synchronized as we query state from
7051             #                two separate sources, the driver and the database.
7052             #                They are set (in stop_instance) and read, in sync.
7053             @utils.synchronized(db_instance.uuid)
7054             def query_driver_power_state_and_sync():
7055                 self._query_driver_power_state_and_sync(context, db_instance)
7056 
7057             try:
7058                 query_driver_power_state_and_sync()
7059             except Exception:
7060                 LOG.exception("Periodic sync_power_state task had an "
7061                               "error while processing an instance.",
7062                               instance=db_instance)
7063 
7064             self._syncs_in_progress.pop(db_instance.uuid)
7065 
7066         for db_instance in db_instances:
7067             # process syncs asynchronously - don't want instance locking to
7068             # block entire periodic task thread
7069             uuid = db_instance.uuid
7070             if uuid in self._syncs_in_progress:
7071                 LOG.debug('Sync already in progress for %s', uuid)
7072             else:
7073                 LOG.debug('Triggering sync for uuid %s', uuid)
7074                 self._syncs_in_progress[uuid] = True
7075                 self._sync_power_pool.spawn_n(_sync, db_instance)
7076 
7077     def _query_driver_power_state_and_sync(self, context, db_instance):
7078         if db_instance.task_state is not None:
7079             LOG.info("During sync_power_state the instance has a "
7080                      "pending task (%(task)s). Skip.",
7081                      {'task': db_instance.task_state}, instance=db_instance)
7082             return
7083         # No pending tasks. Now try to figure out the real vm_power_state.
7084         try:
7085             vm_instance = self.driver.get_info(db_instance)
7086             vm_power_state = vm_instance.state
7087         except exception.InstanceNotFound:
7088             vm_power_state = power_state.NOSTATE
7089         # Note(maoy): the above get_info call might take a long time,
7090         # for example, because of a broken libvirt driver.
7091         try:
7092             self._sync_instance_power_state(context,
7093                                             db_instance,
7094                                             vm_power_state,
7095                                             use_slave=True)
7096         except exception.InstanceNotFound:
7097             # NOTE(hanlind): If the instance gets deleted during sync,
7098             # silently ignore.
7099             pass
7100 
7101     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
7102                                    use_slave=False):
7103         """Align instance power state between the database and hypervisor.
7104 
7105         If the instance is not found on the hypervisor, but is in the database,
7106         then a stop() API will be called on the instance.
7107         """
7108 
7109         # We re-query the DB to get the latest instance info to minimize
7110         # (not eliminate) race condition.
7111         db_instance.refresh(use_slave=use_slave)
7112         db_power_state = db_instance.power_state
7113         vm_state = db_instance.vm_state
7114 
7115         if self.host != db_instance.host:
7116             # on the sending end of nova-compute _sync_power_state
7117             # may have yielded to the greenthread performing a live
7118             # migration; this in turn has changed the resident-host
7119             # for the VM; However, the instance is still active, it
7120             # is just in the process of migrating to another host.
7121             # This implies that the compute source must relinquish
7122             # control to the compute destination.
7123             LOG.info("During the sync_power process the "
7124                      "instance has moved from "
7125                      "host %(src)s to host %(dst)s",
7126                      {'src': db_instance.host,
7127                       'dst': self.host},
7128                      instance=db_instance)
7129             return
7130         elif db_instance.task_state is not None:
7131             # on the receiving end of nova-compute, it could happen
7132             # that the DB instance already report the new resident
7133             # but the actual VM has not showed up on the hypervisor
7134             # yet. In this case, let's allow the loop to continue
7135             # and run the state sync in a later round
7136             LOG.info("During sync_power_state the instance has a "
7137                      "pending task (%(task)s). Skip.",
7138                      {'task': db_instance.task_state},
7139                      instance=db_instance)
7140             return
7141 
7142         orig_db_power_state = db_power_state
7143         if vm_power_state != db_power_state:
7144             LOG.info('During _sync_instance_power_state the DB '
7145                      'power_state (%(db_power_state)s) does not match '
7146                      'the vm_power_state from the hypervisor '
7147                      '(%(vm_power_state)s). Updating power_state in the '
7148                      'DB to match the hypervisor.',
7149                      {'db_power_state': db_power_state,
7150                       'vm_power_state': vm_power_state},
7151                      instance=db_instance)
7152             # power_state is always updated from hypervisor to db
7153             db_instance.power_state = vm_power_state
7154             db_instance.save()
7155             db_power_state = vm_power_state
7156 
7157         # Note(maoy): Now resolve the discrepancy between vm_state and
7158         # vm_power_state. We go through all possible vm_states.
7159         if vm_state in (vm_states.BUILDING,
7160                         vm_states.RESCUED,
7161                         vm_states.RESIZED,
7162                         vm_states.SUSPENDED,
7163                         vm_states.ERROR):
7164             # TODO(maoy): we ignore these vm_state for now.
7165             pass
7166         elif vm_state == vm_states.ACTIVE:
7167             # The only rational power state should be RUNNING
7168             if vm_power_state in (power_state.SHUTDOWN,
7169                                   power_state.CRASHED):
7170                 LOG.warning("Instance shutdown by itself. Calling the "
7171                             "stop API. Current vm_state: %(vm_state)s, "
7172                             "current task_state: %(task_state)s, "
7173                             "original DB power_state: %(db_power_state)s, "
7174                             "current VM power_state: %(vm_power_state)s",
7175                             {'vm_state': vm_state,
7176                              'task_state': db_instance.task_state,
7177                              'db_power_state': orig_db_power_state,
7178                              'vm_power_state': vm_power_state},
7179                             instance=db_instance)
7180                 try:
7181                     # Note(maoy): here we call the API instead of
7182                     # brutally updating the vm_state in the database
7183                     # to allow all the hooks and checks to be performed.
7184                     if db_instance.shutdown_terminate:
7185                         self.compute_api.delete(context, db_instance)
7186                     else:
7187                         self.compute_api.stop(context, db_instance)
7188                 except Exception:
7189                     # Note(maoy): there is no need to propagate the error
7190                     # because the same power_state will be retrieved next
7191                     # time and retried.
7192                     # For example, there might be another task scheduled.
7193                     LOG.exception("error during stop() in sync_power_state.",
7194                                   instance=db_instance)
7195             elif vm_power_state == power_state.SUSPENDED:
7196                 LOG.warning("Instance is suspended unexpectedly. Calling "
7197                             "the stop API.", instance=db_instance)
7198                 try:
7199                     self.compute_api.stop(context, db_instance)
7200                 except Exception:
7201                     LOG.exception("error during stop() in sync_power_state.",
7202                                   instance=db_instance)
7203             elif vm_power_state == power_state.PAUSED:
7204                 # Note(maoy): a VM may get into the paused state not only
7205                 # because the user request via API calls, but also
7206                 # due to (temporary) external instrumentations.
7207                 # Before the virt layer can reliably report the reason,
7208                 # we simply ignore the state discrepancy. In many cases,
7209                 # the VM state will go back to running after the external
7210                 # instrumentation is done. See bug 1097806 for details.
7211                 LOG.warning("Instance is paused unexpectedly. Ignore.",
7212                             instance=db_instance)
7213             elif vm_power_state == power_state.NOSTATE:
7214                 # Occasionally, depending on the status of the hypervisor,
7215                 # which could be restarting for example, an instance may
7216                 # not be found.  Therefore just log the condition.
7217                 LOG.warning("Instance is unexpectedly not found. Ignore.",
7218                             instance=db_instance)
7219         elif vm_state == vm_states.STOPPED:
7220             if vm_power_state not in (power_state.NOSTATE,
7221                                       power_state.SHUTDOWN,
7222                                       power_state.CRASHED):
7223                 LOG.warning("Instance is not stopped. Calling "
7224                             "the stop API. Current vm_state: %(vm_state)s,"
7225                             " current task_state: %(task_state)s, "
7226                             "original DB power_state: %(db_power_state)s, "
7227                             "current VM power_state: %(vm_power_state)s",
7228                             {'vm_state': vm_state,
7229                              'task_state': db_instance.task_state,
7230                              'db_power_state': orig_db_power_state,
7231                              'vm_power_state': vm_power_state},
7232                             instance=db_instance)
7233                 try:
7234                     # NOTE(russellb) Force the stop, because normally the
7235                     # compute API would not allow an attempt to stop a stopped
7236                     # instance.
7237                     self.compute_api.force_stop(context, db_instance)
7238                 except Exception:
7239                     LOG.exception("error during stop() in sync_power_state.",
7240                                   instance=db_instance)
7241         elif vm_state == vm_states.PAUSED:
7242             if vm_power_state in (power_state.SHUTDOWN,
7243                                   power_state.CRASHED):
7244                 LOG.warning("Paused instance shutdown by itself. Calling "
7245                             "the stop API.", instance=db_instance)
7246                 try:
7247                     self.compute_api.force_stop(context, db_instance)
7248                 except Exception:
7249                     LOG.exception("error during stop() in sync_power_state.",
7250                                   instance=db_instance)
7251         elif vm_state in (vm_states.SOFT_DELETED,
7252                           vm_states.DELETED):
7253             if vm_power_state not in (power_state.NOSTATE,
7254                                       power_state.SHUTDOWN):
7255                 # Note(maoy): this should be taken care of periodically in
7256                 # _cleanup_running_deleted_instances().
7257                 LOG.warning("Instance is not (soft-)deleted.",
7258                             instance=db_instance)
7259 
7260     @periodic_task.periodic_task
7261     def _reclaim_queued_deletes(self, context):
7262         """Reclaim instances that are queued for deletion."""
7263         interval = CONF.reclaim_instance_interval
7264         if interval <= 0:
7265             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
7266             return
7267 
7268         filters = {'vm_state': vm_states.SOFT_DELETED,
7269                    'task_state': None,
7270                    'host': self.host}
7271         instances = objects.InstanceList.get_by_filters(
7272             context, filters,
7273             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
7274             use_slave=True)
7275         for instance in instances:
7276             if self._deleted_old_enough(instance, interval):
7277                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7278                         context, instance.uuid)
7279                 LOG.info('Reclaiming deleted instance', instance=instance)
7280                 try:
7281                     self._delete_instance(context, instance, bdms)
7282                 except Exception as e:
7283                     LOG.warning("Periodic reclaim failed to delete "
7284                                 "instance: %s",
7285                                 e, instance=instance)
7286 
7287     def _get_nodename(self, instance, refresh=False):
7288         """Helper method to get the name of the first available node
7289         on this host. This method should not be used with any operations
7290         on ironic instances since it does not handle multiple nodes.
7291         """
7292         node = self.driver.get_available_nodes(refresh=refresh)[0]
7293         LOG.debug("No node specified, defaulting to %s", node,
7294                   instance=instance)
7295         return node
7296 
7297     def update_available_resource_for_node(self, context, nodename):
7298 
7299         rt = self._get_resource_tracker()
7300         try:
7301             rt.update_available_resource(context, nodename)
7302         except exception.ComputeHostNotFound:
7303             # NOTE(comstud): We can get to this case if a node was
7304             # marked 'deleted' in the DB and then re-added with a
7305             # different auto-increment id. The cached resource
7306             # tracker tried to update a deleted record and failed.
7307             # Don't add this resource tracker to the new dict, so
7308             # that this will resolve itself on the next run.
7309             LOG.info("Compute node '%s' not found in "
7310                      "update_available_resource.", nodename)
7311             # TODO(jaypipes): Yes, this is inefficient to throw away all of the
7312             # compute nodes to force a rebuild, but this is only temporary
7313             # until Ironic baremetal node resource providers are tracked
7314             # properly in the report client and this is a tiny edge case
7315             # anyway.
7316             self._resource_tracker = None
7317             return
7318         except Exception:
7319             LOG.exception("Error updating resources for node %(node)s.",
7320                           {'node': nodename})
7321 
7322     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
7323     def update_available_resource(self, context, startup=False):
7324         """See driver.get_available_resource()
7325 
7326         Periodic process that keeps that the compute host's understanding of
7327         resource availability and usage in sync with the underlying hypervisor.
7328 
7329         :param context: security context
7330         :param startup: True if this is being called when the nova-compute
7331             service is starting, False otherwise.
7332         """
7333 
7334         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
7335                                                             use_slave=True,
7336                                                             startup=startup)
7337         try:
7338             nodenames = set(self.driver.get_available_nodes())
7339         except exception.VirtDriverNotReady:
7340             LOG.warning("Virt driver is not ready.")
7341             return
7342 
7343         for nodename in nodenames:
7344             self.update_available_resource_for_node(context, nodename)
7345 
7346         # Delete orphan compute node not reported by driver but still in db
7347         for cn in compute_nodes_in_db:
7348             if cn.hypervisor_hostname not in nodenames:
7349                 LOG.info("Deleting orphan compute node %(id)s "
7350                          "hypervisor host is %(hh)s, "
7351                          "nodes are %(nodes)s",
7352                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
7353                           'nodes': nodenames})
7354                 cn.destroy()
7355                 # Delete the corresponding resource provider in placement,
7356                 # along with any associated allocations and inventory.
7357                 # TODO(cdent): Move use of reportclient into resource tracker.
7358                 self.scheduler_client.reportclient.delete_resource_provider(
7359                     context, cn, cascade=True)
7360 
7361     def _get_compute_nodes_in_db(self, context, use_slave=False,
7362                                  startup=False):
7363         try:
7364             return objects.ComputeNodeList.get_all_by_host(context, self.host,
7365                                                            use_slave=use_slave)
7366         except exception.NotFound:
7367             if startup:
7368                 LOG.warning(
7369                     "No compute node record found for host %s. If this is "
7370                     "the first time this service is starting on this "
7371                     "host, then you can ignore this warning.", self.host)
7372             else:
7373                 LOG.error("No compute node record for host %s", self.host)
7374             return []
7375 
7376     @periodic_task.periodic_task(
7377         spacing=CONF.running_deleted_instance_poll_interval)
7378     def _cleanup_running_deleted_instances(self, context):
7379         """Cleanup any instances which are erroneously still running after
7380         having been deleted.
7381 
7382         Valid actions to take are:
7383 
7384             1. noop - do nothing
7385             2. log - log which instances are erroneously running
7386             3. reap - shutdown and cleanup any erroneously running instances
7387             4. shutdown - power off *and disable* any erroneously running
7388                           instances
7389 
7390         The use-case for this cleanup task is: for various reasons, it may be
7391         possible for the database to show an instance as deleted but for that
7392         instance to still be running on a host machine (see bug
7393         https://bugs.launchpad.net/nova/+bug/911366).
7394 
7395         This cleanup task is a cross-hypervisor utility for finding these
7396         zombied instances and either logging the discrepancy (likely what you
7397         should do in production), or automatically reaping the instances (more
7398         appropriate for dev environments).
7399         """
7400         action = CONF.running_deleted_instance_action
7401 
7402         if action == "noop":
7403             return
7404 
7405         # NOTE(sirp): admin contexts don't ordinarily return deleted records
7406         with utils.temporary_mutation(context, read_deleted="yes"):
7407             for instance in self._running_deleted_instances(context):
7408                 if action == "log":
7409                     LOG.warning("Detected instance with name label "
7410                                 "'%s' which is marked as "
7411                                 "DELETED but still present on host.",
7412                                 instance.name, instance=instance)
7413 
7414                 elif action == 'shutdown':
7415                     LOG.info("Powering off instance with name label "
7416                              "'%s' which is marked as "
7417                              "DELETED but still present on host.",
7418                              instance.name, instance=instance)
7419                     try:
7420                         try:
7421                             # disable starting the instance
7422                             self.driver.set_bootable(instance, False)
7423                         except NotImplementedError:
7424                             LOG.debug("set_bootable is not implemented "
7425                                       "for the current driver")
7426                         # and power it off
7427                         self.driver.power_off(instance)
7428                     except Exception:
7429                         LOG.warning("Failed to power off instance",
7430                                     instance=instance, exc_info=True)
7431 
7432                 elif action == 'reap':
7433                     LOG.info("Destroying instance with name label "
7434                              "'%s' which is marked as "
7435                              "DELETED but still present on host.",
7436                              instance.name, instance=instance)
7437                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7438                         context, instance.uuid, use_slave=True)
7439                     self.instance_events.clear_events_for_instance(instance)
7440                     try:
7441                         self._shutdown_instance(context, instance, bdms,
7442                                                 notify=False)
7443                         self._cleanup_volumes(context, instance, bdms,
7444                                               detach=False)
7445                     except Exception as e:
7446                         LOG.warning("Periodic cleanup failed to delete "
7447                                     "instance: %s",
7448                                     e, instance=instance)
7449                 else:
7450                     raise Exception(_("Unrecognized value '%s'"
7451                                       " for CONF.running_deleted_"
7452                                       "instance_action") % action)
7453 
7454     def _running_deleted_instances(self, context):
7455         """Returns a list of instances nova thinks is deleted,
7456         but the hypervisor thinks is still running.
7457         """
7458         timeout = CONF.running_deleted_instance_timeout
7459         filters = {'deleted': True,
7460                    'soft_deleted': False}
7461         instances = self._get_instances_on_driver(context, filters)
7462         return [i for i in instances if self._deleted_old_enough(i, timeout)]
7463 
7464     def _deleted_old_enough(self, instance, timeout):
7465         deleted_at = instance.deleted_at
7466         if deleted_at:
7467             deleted_at = deleted_at.replace(tzinfo=None)
7468         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
7469 
7470     @contextlib.contextmanager
7471     def _error_out_instance_on_exception(self, context, instance,
7472                                          instance_state=vm_states.ACTIVE):
7473         instance_uuid = instance.uuid
7474         try:
7475             yield
7476         except NotImplementedError as error:
7477             with excutils.save_and_reraise_exception():
7478                 LOG.info("Setting instance back to %(state)s after: "
7479                          "%(error)s",
7480                          {'state': instance_state, 'error': error},
7481                          instance_uuid=instance_uuid)
7482                 self._instance_update(context, instance,
7483                                       vm_state=instance_state,
7484                                       task_state=None)
7485         except exception.InstanceFaultRollback as error:
7486             LOG.info("Setting instance back to ACTIVE after: %s",
7487                      error, instance_uuid=instance_uuid)
7488             self._instance_update(context, instance,
7489                                   vm_state=vm_states.ACTIVE,
7490                                   task_state=None)
7491             raise error.inner_exception
7492         except Exception:
7493             LOG.exception('Setting instance vm_state to ERROR',
7494                           instance_uuid=instance_uuid)
7495             with excutils.save_and_reraise_exception():
7496                 self._set_instance_obj_error_state(context, instance)
7497 
7498     @wrap_exception()
7499     def add_aggregate_host(self, context, aggregate, host, slave_info):
7500         """Notify hypervisor of change (for hypervisor pools)."""
7501         try:
7502             self.driver.add_to_aggregate(context, aggregate, host,
7503                                          slave_info=slave_info)
7504         except NotImplementedError:
7505             LOG.debug('Hypervisor driver does not support '
7506                       'add_aggregate_host')
7507         except exception.AggregateError:
7508             with excutils.save_and_reraise_exception():
7509                 self.driver.undo_aggregate_operation(
7510                                     context,
7511                                     aggregate.delete_host,
7512                                     aggregate, host)
7513 
7514     @wrap_exception()
7515     def remove_aggregate_host(self, context, host, slave_info, aggregate):
7516         """Removes a host from a physical hypervisor pool."""
7517         try:
7518             self.driver.remove_from_aggregate(context, aggregate, host,
7519                                               slave_info=slave_info)
7520         except NotImplementedError:
7521             LOG.debug('Hypervisor driver does not support '
7522                       'remove_aggregate_host')
7523         except (exception.AggregateError,
7524                 exception.InvalidAggregateAction) as e:
7525             with excutils.save_and_reraise_exception():
7526                 self.driver.undo_aggregate_operation(
7527                                     context,
7528                                     aggregate.add_host,
7529                                     aggregate, host,
7530                                     isinstance(e, exception.AggregateError))
7531 
7532     def _process_instance_event(self, instance, event):
7533         _event = self.instance_events.pop_instance_event(instance, event)
7534         if _event:
7535             LOG.debug('Processing event %(event)s',
7536                       {'event': event.key}, instance=instance)
7537             _event.send(event)
7538         else:
7539             # If it's a network-vif-unplugged event and the instance is being
7540             # deleted then we don't need to make this a warning as it's
7541             # expected. There are other things which could trigger this like
7542             # detaching an interface, but we don't have a task state for that.
7543             if (event.name == 'network-vif-unplugged' and
7544                     instance.task_state == task_states.DELETING):
7545                 LOG.debug('Received event %s for instance which is being '
7546                           'deleted.', event.key, instance=instance)
7547             else:
7548                 LOG.warning('Received unexpected event %(event)s for '
7549                             'instance with vm_state %(vm_state)s and '
7550                             'task_state %(task_state)s.',
7551                             {'event': event.key,
7552                              'vm_state': instance.vm_state,
7553                              'task_state': instance.task_state},
7554                             instance=instance)
7555 
7556     def _process_instance_vif_deleted_event(self, context, instance,
7557                                             deleted_vif_id):
7558         # If an attached port is deleted by neutron, it needs to
7559         # be detached from the instance.
7560         # And info cache needs to be updated.
7561         network_info = instance.info_cache.network_info
7562         for index, vif in enumerate(network_info):
7563             if vif['id'] == deleted_vif_id:
7564                 LOG.info('Neutron deleted interface %(intf)s; '
7565                          'detaching it from the instance and '
7566                          'deleting it from the info cache',
7567                          {'intf': vif['id']},
7568                          instance=instance)
7569                 del network_info[index]
7570                 base_net_api.update_instance_cache_with_nw_info(
7571                                  self.network_api, context,
7572                                  instance,
7573                                  nw_info=network_info)
7574                 try:
7575                     self.driver.detach_interface(context, instance, vif)
7576                 except NotImplementedError:
7577                     # Not all virt drivers support attach/detach of interfaces
7578                     # yet (like Ironic), so just ignore this.
7579                     pass
7580                 except exception.NovaException as ex:
7581                     # If the instance was deleted before the interface was
7582                     # detached, just log it at debug.
7583                     log_level = (logging.DEBUG
7584                                  if isinstance(ex, exception.InstanceNotFound)
7585                                  else logging.WARNING)
7586                     LOG.log(log_level,
7587                             "Detach interface failed, "
7588                             "port_id=%(port_id)s, reason: %(msg)s",
7589                             {'port_id': deleted_vif_id, 'msg': ex},
7590                             instance=instance)
7591                 break
7592 
7593     @wrap_instance_event(prefix='compute')
7594     @wrap_instance_fault
7595     def extend_volume(self, context, instance, extended_volume_id):
7596 
7597         # If an attached volume is extended by cinder, it needs to
7598         # be extended by virt driver so host can detect its new size.
7599         # And bdm needs to be updated.
7600         LOG.debug('Handling volume-extended event for volume %(vol)s',
7601                   {'vol': extended_volume_id}, instance=instance)
7602 
7603         try:
7604             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
7605                    context, extended_volume_id, instance.uuid)
7606         except exception.NotFound:
7607             LOG.warning('Extend volume failed, '
7608                         'volume %(vol)s is not attached to instance.',
7609                         {'vol': extended_volume_id},
7610                         instance=instance)
7611             return
7612 
7613         LOG.info('Cinder extended volume %(vol)s; '
7614                  'extending it to detect new size',
7615                  {'vol': extended_volume_id},
7616                  instance=instance)
7617         volume = self.volume_api.get(context, bdm.volume_id)
7618 
7619         if bdm.connection_info is None:
7620             LOG.warning('Extend volume failed, '
7621                         'attached volume %(vol)s has no connection_info',
7622                         {'vol': extended_volume_id},
7623                         instance=instance)
7624             return
7625 
7626         connection_info = jsonutils.loads(bdm.connection_info)
7627         bdm.volume_size = volume['size']
7628         bdm.save()
7629 
7630         if not self.driver.capabilities.get('supports_extend_volume', False):
7631             raise exception.ExtendVolumeNotSupported()
7632 
7633         try:
7634             self.driver.extend_volume(connection_info,
7635                                       instance)
7636         except Exception as ex:
7637             LOG.warning('Extend volume failed, '
7638                         'volume_id=%(volume_id)s, reason: %(msg)s',
7639                         {'volume_id': extended_volume_id, 'msg': ex},
7640                         instance=instance)
7641             raise
7642 
7643     @wrap_exception()
7644     def external_instance_event(self, context, instances, events):
7645         # NOTE(danms): Some event types are handled by the manager, such
7646         # as when we're asked to update the instance's info_cache. If it's
7647         # not one of those, look for some thread(s) waiting for the event and
7648         # unblock them if so.
7649         for event in events:
7650             instance = [inst for inst in instances
7651                         if inst.uuid == event.instance_uuid][0]
7652             LOG.debug('Received event %(event)s',
7653                       {'event': event.key},
7654                       instance=instance)
7655             if event.name == 'network-changed':
7656                 try:
7657                     self.network_api.get_instance_nw_info(context, instance)
7658                 except exception.NotFound as e:
7659                     LOG.info('Failed to process external instance event '
7660                              '%(event)s due to: %(error)s',
7661                              {'event': event.key, 'error': six.text_type(e)},
7662                              instance=instance)
7663             elif event.name == 'network-vif-deleted':
7664                 try:
7665                     self._process_instance_vif_deleted_event(context,
7666                                                              instance,
7667                                                              event.tag)
7668                 except exception.NotFound as e:
7669                     LOG.info('Failed to process external instance event '
7670                              '%(event)s due to: %(error)s',
7671                              {'event': event.key, 'error': six.text_type(e)},
7672                              instance=instance)
7673             elif event.name == 'volume-extended':
7674                 self.extend_volume(context, instance, event.tag)
7675             else:
7676                 self._process_instance_event(instance, event)
7677 
7678     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
7679                                  external_process_ok=True)
7680     def _run_image_cache_manager_pass(self, context):
7681         """Run a single pass of the image cache manager."""
7682 
7683         if not self.driver.capabilities.get("has_imagecache", False):
7684             return
7685 
7686         # Determine what other nodes use this storage
7687         storage_users.register_storage_use(CONF.instances_path, CONF.host)
7688         nodes = storage_users.get_storage_users(CONF.instances_path)
7689 
7690         # Filter all_instances to only include those nodes which share this
7691         # storage path.
7692         # TODO(mikal): this should be further refactored so that the cache
7693         # cleanup code doesn't know what those instances are, just a remote
7694         # count, and then this logic should be pushed up the stack.
7695         filters = {'deleted': False,
7696                    'soft_deleted': True,
7697                    'host': nodes}
7698         filtered_instances = objects.InstanceList.get_by_filters(context,
7699                                  filters, expected_attrs=[], use_slave=True)
7700 
7701         self.driver.manage_image_cache(context, filtered_instances)
7702 
7703     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7704     def _run_pending_deletes(self, context):
7705         """Retry any pending instance file deletes."""
7706         LOG.debug('Cleaning up deleted instances')
7707         filters = {'deleted': True,
7708                    'soft_deleted': False,
7709                    'host': CONF.host,
7710                    'cleaned': False}
7711         attrs = ['system_metadata']
7712         with utils.temporary_mutation(context, read_deleted='yes'):
7713             instances = objects.InstanceList.get_by_filters(
7714                 context, filters, expected_attrs=attrs, use_slave=True)
7715         LOG.debug('There are %d instances to clean', len(instances))
7716 
7717         # TODO(raj_singh): Remove this if condition when min value is
7718         # introduced to "maximum_instance_delete_attempts" cfg option.
7719         if CONF.maximum_instance_delete_attempts < 1:
7720             LOG.warning('Future versions of Nova will restrict the '
7721                         '"maximum_instance_delete_attempts" config option '
7722                         'to values >=1. Update your configuration file to '
7723                         'mitigate future upgrade issues.')
7724 
7725         for instance in instances:
7726             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
7727             LOG.debug('Instance has had %(attempts)s of %(max)s '
7728                       'cleanup attempts',
7729                       {'attempts': attempts,
7730                        'max': CONF.maximum_instance_delete_attempts},
7731                       instance=instance)
7732             if attempts < CONF.maximum_instance_delete_attempts:
7733                 success = self.driver.delete_instance_files(instance)
7734 
7735                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
7736                 if success:
7737                     instance.cleaned = True
7738                 with utils.temporary_mutation(context, read_deleted='yes'):
7739                     instance.save()
7740 
7741     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7742     def _cleanup_incomplete_migrations(self, context):
7743         """Delete instance files on failed resize/revert-resize operation
7744 
7745         During resize/revert-resize operation, if that instance gets deleted
7746         in-between then instance files might remain either on source or
7747         destination compute node because of race condition.
7748         """
7749         LOG.debug('Cleaning up deleted instances with incomplete migration ')
7750         migration_filters = {'host': CONF.host,
7751                              'status': 'error'}
7752         migrations = objects.MigrationList.get_by_filters(context,
7753                                                           migration_filters)
7754 
7755         if not migrations:
7756             return
7757 
7758         inst_uuid_from_migrations = set([migration.instance_uuid for migration
7759                                          in migrations])
7760 
7761         inst_filters = {'deleted': True, 'soft_deleted': False,
7762                         'uuid': inst_uuid_from_migrations}
7763         attrs = ['info_cache', 'security_groups', 'system_metadata']
7764         with utils.temporary_mutation(context, read_deleted='yes'):
7765             instances = objects.InstanceList.get_by_filters(
7766                 context, inst_filters, expected_attrs=attrs, use_slave=True)
7767 
7768         for instance in instances:
7769             if instance.host != CONF.host:
7770                 for migration in migrations:
7771                     if instance.uuid == migration.instance_uuid:
7772                         # Delete instance files if not cleanup properly either
7773                         # from the source or destination compute nodes when
7774                         # the instance is deleted during resizing.
7775                         self.driver.delete_instance_files(instance)
7776                         try:
7777                             migration.status = 'failed'
7778                             with migration.obj_as_admin():
7779                                 migration.save()
7780                         except exception.MigrationNotFound:
7781                             LOG.warning("Migration %s is not found.",
7782                                         migration.id,
7783                                         instance=instance)
7784                         break
7785 
7786     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7787                                    exception.QemuGuestAgentNotEnabled,
7788                                    exception.NovaException,
7789                                    NotImplementedError)
7790     @wrap_exception()
7791     def quiesce_instance(self, context, instance):
7792         """Quiesce an instance on this host."""
7793         context = context.elevated()
7794         image_meta = objects.ImageMeta.from_instance(instance)
7795         self.driver.quiesce(context, instance, image_meta)
7796 
7797     def _wait_for_snapshots_completion(self, context, mapping):
7798         for mapping_dict in mapping:
7799             if mapping_dict.get('source_type') == 'snapshot':
7800 
7801                 def _wait_snapshot():
7802                     snapshot = self.volume_api.get_snapshot(
7803                         context, mapping_dict['snapshot_id'])
7804                     if snapshot.get('status') != 'creating':
7805                         raise loopingcall.LoopingCallDone()
7806 
7807                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
7808                 timer.start(interval=0.5).wait()
7809 
7810     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7811                                    exception.QemuGuestAgentNotEnabled,
7812                                    exception.NovaException,
7813                                    NotImplementedError)
7814     @wrap_exception()
7815     def unquiesce_instance(self, context, instance, mapping=None):
7816         """Unquiesce an instance on this host.
7817 
7818         If snapshots' image mapping is provided, it waits until snapshots are
7819         completed before unqueiscing.
7820         """
7821         context = context.elevated()
7822         if mapping:
7823             try:
7824                 self._wait_for_snapshots_completion(context, mapping)
7825             except Exception as error:
7826                 LOG.exception("Exception while waiting completion of "
7827                               "volume snapshots: %s",
7828                               error, instance=instance)
7829         image_meta = objects.ImageMeta.from_instance(instance)
7830         self.driver.unquiesce(context, instance, image_meta)
