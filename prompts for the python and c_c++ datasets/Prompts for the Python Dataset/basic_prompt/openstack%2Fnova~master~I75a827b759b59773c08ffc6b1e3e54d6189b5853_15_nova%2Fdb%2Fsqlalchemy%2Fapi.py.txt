Please review the code below to detect security defects. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are found, please state '''No security defects are detected in the code'''.

1 # Copyright (c) 2011 X.commerce, a business unit of eBay Inc.
2 # Copyright 2010 United States Government as represented by the
3 # Administrator of the National Aeronautics and Space Administration.
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Implementation of SQLAlchemy backend."""
19 
20 import collections
21 import copy
22 import datetime
23 import functools
24 import inspect
25 import sys
26 
27 from oslo_db import api as oslo_db_api
28 from oslo_db import exception as db_exc
29 from oslo_db.sqlalchemy import enginefacade
30 from oslo_db.sqlalchemy import update_match
31 from oslo_db.sqlalchemy import utils as sqlalchemyutils
32 from oslo_log import log as logging
33 from oslo_utils import excutils
34 from oslo_utils import importutils
35 from oslo_utils import timeutils
36 from oslo_utils import uuidutils
37 import six
38 from six.moves import range
39 import sqlalchemy as sa
40 from sqlalchemy import and_
41 from sqlalchemy import Boolean
42 from sqlalchemy.exc import NoSuchTableError
43 from sqlalchemy.ext.compiler import compiles
44 from sqlalchemy import Integer
45 from sqlalchemy import MetaData
46 from sqlalchemy import or_
47 from sqlalchemy.orm import aliased
48 from sqlalchemy.orm import contains_eager
49 from sqlalchemy.orm import joinedload
50 from sqlalchemy.orm import joinedload_all
51 from sqlalchemy.orm import noload
52 from sqlalchemy.orm import undefer
53 from sqlalchemy.schema import Table
54 from sqlalchemy import sql
55 from sqlalchemy.sql.expression import asc
56 from sqlalchemy.sql.expression import cast
57 from sqlalchemy.sql.expression import desc
58 from sqlalchemy.sql.expression import UpdateBase
59 from sqlalchemy.sql import false
60 from sqlalchemy.sql import func
61 from sqlalchemy.sql import null
62 from sqlalchemy.sql import true
63 
64 from nova import block_device
65 from nova.compute import task_states
66 from nova.compute import vm_states
67 import nova.conf
68 import nova.context
69 from nova.db.sqlalchemy import models
70 from nova import exception
71 from nova.i18n import _
72 from nova import safe_utils
73 
74 profiler_sqlalchemy = importutils.try_import('osprofiler.sqlalchemy')
75 
76 CONF = nova.conf.CONF
77 
78 
79 LOG = logging.getLogger(__name__)
80 
81 main_context_manager = enginefacade.transaction_context()
82 api_context_manager = enginefacade.transaction_context()
83 
84 
85 def _get_db_conf(conf_group, connection=None):
86     kw = dict(
87         connection=connection or conf_group.connection,
88         slave_connection=conf_group.slave_connection,
89         sqlite_fk=False,
90         __autocommit=True,
91         expire_on_commit=False,
92         mysql_sql_mode=conf_group.mysql_sql_mode,
93         connection_recycle_time=conf_group.connection_recycle_time,
94         connection_debug=conf_group.connection_debug,
95         max_pool_size=conf_group.max_pool_size,
96         max_overflow=conf_group.max_overflow,
97         pool_timeout=conf_group.pool_timeout,
98         sqlite_synchronous=conf_group.sqlite_synchronous,
99         connection_trace=conf_group.connection_trace,
100         max_retries=conf_group.max_retries,
101         retry_interval=conf_group.retry_interval)
102     return kw
103 
104 
105 def _context_manager_from_context(context):
106     if context:
107         try:
108             return context.db_connection
109         except AttributeError:
110             pass
111 
112 
113 def configure(conf):
114     main_context_manager.configure(**_get_db_conf(conf.database))
115     api_context_manager.configure(**_get_db_conf(conf.api_database))
116 
117     if profiler_sqlalchemy and CONF.profiler.enabled \
118             and CONF.profiler.trace_sqlalchemy:
119 
120         main_context_manager.append_on_engine_create(
121             lambda eng: profiler_sqlalchemy.add_tracing(sa, eng, "db"))
122         api_context_manager.append_on_engine_create(
123             lambda eng: profiler_sqlalchemy.add_tracing(sa, eng, "db"))
124 
125 
126 def create_context_manager(connection=None):
127     """Create a database context manager object.
128 
129     : param connection: The database connection string
130     """
131     ctxt_mgr = enginefacade.transaction_context()
132     ctxt_mgr.configure(**_get_db_conf(CONF.database, connection=connection))
133     return ctxt_mgr
134 
135 
136 def get_context_manager(context):
137     """Get a database context manager object.
138 
139     :param context: The request context that can contain a context manager
140     """
141     return _context_manager_from_context(context) or main_context_manager
142 
143 
144 def get_engine(use_slave=False, context=None):
145     """Get a database engine object.
146 
147     :param use_slave: Whether to use the slave connection
148     :param context: The request context that can contain a context manager
149     """
150     ctxt_mgr = get_context_manager(context)
151     return ctxt_mgr.get_legacy_facade().get_engine(use_slave=use_slave)
152 
153 
154 def get_api_engine():
155     return api_context_manager.get_legacy_facade().get_engine()
156 
157 
158 _SHADOW_TABLE_PREFIX = 'shadow_'
159 _DEFAULT_QUOTA_NAME = 'default'
160 PER_PROJECT_QUOTAS = ['fixed_ips', 'floating_ips', 'networks']
161 
162 
163 def get_backend():
164     """The backend is this module itself."""
165     return sys.modules[__name__]
166 
167 
168 def require_context(f):
169     """Decorator to require *any* user or admin context.
170 
171     This does no authorization for user or project access matching, see
172     :py:func:`nova.context.authorize_project_context` and
173     :py:func:`nova.context.authorize_user_context`.
174 
175     The first argument to the wrapped function must be the context.
176 
177     """
178 
179     @functools.wraps(f)
180     def wrapper(*args, **kwargs):
181         nova.context.require_context(args[0])
182         return f(*args, **kwargs)
183     return wrapper
184 
185 
186 def require_instance_exists_using_uuid(f):
187     """Decorator to require the specified instance to exist.
188 
189     Requires the wrapped function to use context and instance_uuid as
190     their first two arguments.
191     """
192     @functools.wraps(f)
193     def wrapper(context, instance_uuid, *args, **kwargs):
194         instance_get_by_uuid(context, instance_uuid)
195         return f(context, instance_uuid, *args, **kwargs)
196 
197     return wrapper
198 
199 
200 def require_aggregate_exists(f):
201     """Decorator to require the specified aggregate to exist.
202 
203     Requires the wrapped function to use context and aggregate_id as
204     their first two arguments.
205     """
206 
207     @functools.wraps(f)
208     def wrapper(context, aggregate_id, *args, **kwargs):
209         aggregate_get(context, aggregate_id)
210         return f(context, aggregate_id, *args, **kwargs)
211     return wrapper
212 
213 
214 def select_db_reader_mode(f):
215     """Decorator to select synchronous or asynchronous reader mode.
216 
217     The kwarg argument 'use_slave' defines reader mode. Asynchronous reader
218     will be used if 'use_slave' is True and synchronous reader otherwise.
219     If 'use_slave' is not specified default value 'False' will be used.
220 
221     Wrapped function must have a context in the arguments.
222     """
223 
224     @functools.wraps(f)
225     def wrapper(*args, **kwargs):
226         wrapped_func = safe_utils.get_wrapped_function(f)
227         keyed_args = inspect.getcallargs(wrapped_func, *args, **kwargs)
228 
229         context = keyed_args['context']
230         use_slave = keyed_args.get('use_slave', False)
231 
232         if use_slave:
233             reader_mode = get_context_manager(context).async
234         else:
235             reader_mode = get_context_manager(context).reader
236 
237         with reader_mode.using(context):
238             return f(*args, **kwargs)
239     return wrapper
240 
241 
242 def pick_context_manager_writer(f):
243     """Decorator to use a writer db context manager.
244 
245     The db context manager will be picked from the RequestContext.
246 
247     Wrapped function must have a RequestContext in the arguments.
248     """
249     @functools.wraps(f)
250     def wrapped(context, *args, **kwargs):
251         ctxt_mgr = get_context_manager(context)
252         with ctxt_mgr.writer.using(context):
253             return f(context, *args, **kwargs)
254     return wrapped
255 
256 
257 def pick_context_manager_reader(f):
258     """Decorator to use a reader db context manager.
259 
260     The db context manager will be picked from the RequestContext.
261 
262     Wrapped function must have a RequestContext in the arguments.
263     """
264     @functools.wraps(f)
265     def wrapped(context, *args, **kwargs):
266         ctxt_mgr = get_context_manager(context)
267         with ctxt_mgr.reader.using(context):
268             return f(context, *args, **kwargs)
269     return wrapped
270 
271 
272 def pick_context_manager_reader_allow_async(f):
273     """Decorator to use a reader.allow_async db context manager.
274 
275     The db context manager will be picked from the RequestContext.
276 
277     Wrapped function must have a RequestContext in the arguments.
278     """
279     @functools.wraps(f)
280     def wrapped(context, *args, **kwargs):
281         ctxt_mgr = get_context_manager(context)
282         with ctxt_mgr.reader.allow_async.using(context):
283             return f(context, *args, **kwargs)
284     return wrapped
285 
286 
287 def model_query(context, model,
288                 args=None,
289                 read_deleted=None,
290                 project_only=False):
291     """Query helper that accounts for context's `read_deleted` field.
292 
293     :param context:     NovaContext of the query.
294     :param model:       Model to query. Must be a subclass of ModelBase.
295     :param args:        Arguments to query. If None - model is used.
296     :param read_deleted: If not None, overrides context's read_deleted field.
297                         Permitted values are 'no', which does not return
298                         deleted values; 'only', which only returns deleted
299                         values; and 'yes', which does not filter deleted
300                         values.
301     :param project_only: If set and context is user-type, then restrict
302                         query to match the context's project_id. If set to
303                         'allow_none', restriction includes project_id = None.
304     """
305 
306     if read_deleted is None:
307         read_deleted = context.read_deleted
308 
309     query_kwargs = {}
310     if 'no' == read_deleted:
311         query_kwargs['deleted'] = False
312     elif 'only' == read_deleted:
313         query_kwargs['deleted'] = True
314     elif 'yes' == read_deleted:
315         pass
316     else:
317         raise ValueError(_("Unrecognized read_deleted value '%s'")
318                            % read_deleted)
319 
320     query = sqlalchemyutils.model_query(
321         model, context.session, args, **query_kwargs)
322 
323     # We can't use oslo.db model_query's project_id here, as it doesn't allow
324     # us to return both our projects and unowned projects.
325     if nova.context.is_user_context(context) and project_only:
326         if project_only == 'allow_none':
327             query = query.\
328                 filter(or_(model.project_id == context.project_id,
329                            model.project_id == null()))
330         else:
331             query = query.filter_by(project_id=context.project_id)
332 
333     return query
334 
335 
336 def convert_objects_related_datetimes(values, *datetime_keys):
337     if not datetime_keys:
338         datetime_keys = ('created_at', 'deleted_at', 'updated_at')
339 
340     for key in datetime_keys:
341         if key in values and values[key]:
342             if isinstance(values[key], six.string_types):
343                 try:
344                     values[key] = timeutils.parse_strtime(values[key])
345                 except ValueError:
346                     # Try alternate parsing since parse_strtime will fail
347                     # with say converting '2015-05-28T19:59:38+00:00'
348                     values[key] = timeutils.parse_isotime(values[key])
349             # NOTE(danms): Strip UTC timezones from datetimes, since they're
350             # stored that way in the database
351             values[key] = values[key].replace(tzinfo=None)
352     return values
353 
354 
355 def _sync_instances(context, project_id, user_id):
356     return dict(zip(('instances', 'cores', 'ram'),
357                     _instance_data_get_for_user(context, project_id, user_id)))
358 
359 
360 def _sync_floating_ips(context, project_id, user_id):
361     return dict(floating_ips=_floating_ip_count_by_project(
362                 context, project_id))
363 
364 
365 def _sync_fixed_ips(context, project_id, user_id):
366     return dict(fixed_ips=_fixed_ip_count_by_project(context, project_id))
367 
368 
369 def _sync_security_groups(context, project_id, user_id):
370     return dict(security_groups=_security_group_count_by_project_and_user(
371                 context, project_id, user_id))
372 
373 
374 def _sync_server_groups(context, project_id, user_id):
375     return dict(server_groups=_instance_group_count_by_project_and_user(
376                 context, project_id, user_id))
377 
378 QUOTA_SYNC_FUNCTIONS = {
379     '_sync_instances': _sync_instances,
380     '_sync_floating_ips': _sync_floating_ips,
381     '_sync_fixed_ips': _sync_fixed_ips,
382     '_sync_security_groups': _sync_security_groups,
383     '_sync_server_groups': _sync_server_groups,
384 }
385 
386 ###################
387 
388 
389 def constraint(**conditions):
390     return Constraint(conditions)
391 
392 
393 def equal_any(*values):
394     return EqualityCondition(values)
395 
396 
397 def not_equal(*values):
398     return InequalityCondition(values)
399 
400 
401 class Constraint(object):
402 
403     def __init__(self, conditions):
404         self.conditions = conditions
405 
406     def apply(self, model, query):
407         for key, condition in self.conditions.items():
408             for clause in condition.clauses(getattr(model, key)):
409                 query = query.filter(clause)
410         return query
411 
412 
413 class EqualityCondition(object):
414 
415     def __init__(self, values):
416         self.values = values
417 
418     def clauses(self, field):
419         # method signature requires us to return an iterable even if for OR
420         # operator this will actually be a single clause
421         return [or_(*[field == value for value in self.values])]
422 
423 
424 class InequalityCondition(object):
425 
426     def __init__(self, values):
427         self.values = values
428 
429     def clauses(self, field):
430         return [field != value for value in self.values]
431 
432 
433 class DeleteFromSelect(UpdateBase):
434     def __init__(self, table, select, column):
435         self.table = table
436         self.select = select
437         self.column = column
438 
439 
440 # NOTE(guochbo): some versions of MySQL doesn't yet support subquery with
441 # 'LIMIT & IN/ALL/ANY/SOME' We need work around this with nesting select .
442 @compiles(DeleteFromSelect)
443 def visit_delete_from_select(element, compiler, **kw):
444     return "DELETE FROM %s WHERE %s in (SELECT T1.%s FROM (%s) as T1)" % (
445         compiler.process(element.table, asfrom=True),
446         compiler.process(element.column),
447         element.column.name,
448         compiler.process(element.select))
449 
450 ###################
451 
452 
453 @pick_context_manager_writer
454 def service_destroy(context, service_id):
455     service = service_get(context, service_id)
456 
457     model_query(context, models.Service).\
458                 filter_by(id=service_id).\
459                 soft_delete(synchronize_session=False)
460 
461     # TODO(sbauza): Remove the service_id filter in a later release
462     # once we are sure that all compute nodes report the host field
463     model_query(context, models.ComputeNode).\
464                 filter(or_(models.ComputeNode.service_id == service_id,
465                            models.ComputeNode.host == service['host'])).\
466                 soft_delete(synchronize_session=False)
467 
468 
469 @pick_context_manager_reader
470 def service_get(context, service_id):
471     query = model_query(context, models.Service).filter_by(id=service_id)
472 
473     result = query.first()
474     if not result:
475         raise exception.ServiceNotFound(service_id=service_id)
476 
477     return result
478 
479 
480 @pick_context_manager_reader
481 def service_get_by_uuid(context, service_uuid):
482     query = model_query(context, models.Service).filter_by(uuid=service_uuid)
483 
484     result = query.first()
485     if not result:
486         raise exception.ServiceNotFound(service_id=service_uuid)
487 
488     return result
489 
490 
491 @pick_context_manager_reader_allow_async
492 def service_get_minimum_version(context, binaries):
493     min_versions = context.session.query(
494         models.Service.binary,
495         func.min(models.Service.version)).\
496                          filter(models.Service.binary.in_(binaries)).\
497                          filter(models.Service.deleted == 0).\
498                          filter(models.Service.forced_down == false()).\
499                          group_by(models.Service.binary)
500     return dict(min_versions)
501 
502 
503 @pick_context_manager_reader
504 def service_get_all(context, disabled=None):
505     query = model_query(context, models.Service)
506 
507     if disabled is not None:
508         query = query.filter_by(disabled=disabled)
509 
510     return query.all()
511 
512 
513 @pick_context_manager_reader
514 def service_get_all_by_topic(context, topic):
515     return model_query(context, models.Service, read_deleted="no").\
516                 filter_by(disabled=False).\
517                 filter_by(topic=topic).\
518                 all()
519 
520 
521 @pick_context_manager_reader
522 def service_get_by_host_and_topic(context, host, topic):
523     return model_query(context, models.Service, read_deleted="no").\
524                 filter_by(disabled=False).\
525                 filter_by(host=host).\
526                 filter_by(topic=topic).\
527                 first()
528 
529 
530 @pick_context_manager_reader
531 def service_get_all_by_binary(context, binary, include_disabled=False):
532     query = model_query(context, models.Service, read_deleted="no").\
533                     filter_by(binary=binary)
534     if not include_disabled:
535         query = query.filter_by(disabled=False)
536     return query.all()
537 
538 
539 @pick_context_manager_reader
540 def service_get_all_computes_by_hv_type(context, hv_type,
541                                         include_disabled=False):
542     query = model_query(context, models.Service, read_deleted="no").\
543                     filter_by(binary='nova-compute')
544     if not include_disabled:
545         query = query.filter_by(disabled=False)
546     query = query.join(models.ComputeNode,
547                        models.Service.host == models.ComputeNode.host).\
548                   filter(models.ComputeNode.hypervisor_type == hv_type).\
549                   distinct('host')
550     return query.all()
551 
552 
553 @pick_context_manager_reader
554 def service_get_by_host_and_binary(context, host, binary):
555     result = model_query(context, models.Service, read_deleted="no").\
556                     filter_by(host=host).\
557                     filter_by(binary=binary).\
558                     first()
559 
560     if not result:
561         raise exception.HostBinaryNotFound(host=host, binary=binary)
562 
563     return result
564 
565 
566 @pick_context_manager_reader
567 def service_get_all_by_host(context, host):
568     return model_query(context, models.Service, read_deleted="no").\
569                 filter_by(host=host).\
570                 all()
571 
572 
573 @pick_context_manager_reader_allow_async
574 def service_get_by_compute_host(context, host):
575     result = model_query(context, models.Service, read_deleted="no").\
576                 filter_by(host=host).\
577                 filter_by(binary='nova-compute').\
578                 first()
579 
580     if not result:
581         raise exception.ComputeHostNotFound(host=host)
582 
583     return result
584 
585 
586 @pick_context_manager_writer
587 def service_create(context, values):
588     service_ref = models.Service()
589     service_ref.update(values)
590     # We only auto-disable nova-compute services since those are the only
591     # ones that can be enabled using the os-services REST API and they are
592     # the only ones where being disabled means anything. It does
593     # not make sense to be able to disable non-compute services like
594     # nova-scheduler or nova-osapi_compute since that does nothing.
595     if not CONF.enable_new_services and values.get('binary') == 'nova-compute':
596         msg = _("New compute service disabled due to config option.")
597         service_ref.disabled = True
598         service_ref.disabled_reason = msg
599     try:
600         service_ref.save(context.session)
601     except db_exc.DBDuplicateEntry as e:
602         if 'binary' in e.columns:
603             raise exception.ServiceBinaryExists(host=values.get('host'),
604                         binary=values.get('binary'))
605         raise exception.ServiceTopicExists(host=values.get('host'),
606                         topic=values.get('topic'))
607     return service_ref
608 
609 
610 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
611 @pick_context_manager_writer
612 def service_update(context, service_id, values):
613     service_ref = service_get(context, service_id)
614     # Only servicegroup.drivers.db.DbDriver._report_state() updates
615     # 'report_count', so if that value changes then store the timestamp
616     # as the last time we got a state report.
617     if 'report_count' in values:
618         if values['report_count'] > service_ref.report_count:
619             service_ref.last_seen_up = timeutils.utcnow()
620     service_ref.update(values)
621 
622     return service_ref
623 
624 
625 ###################
626 
627 
628 def _compute_node_select(context, filters=None, limit=None, marker=None):
629     if filters is None:
630         filters = {}
631 
632     cn_tbl = sa.alias(models.ComputeNode.__table__, name='cn')
633     select = sa.select([cn_tbl])
634 
635     if context.read_deleted == "no":
636         select = select.where(cn_tbl.c.deleted == 0)
637     if "compute_id" in filters:
638         select = select.where(cn_tbl.c.id == filters["compute_id"])
639     if "service_id" in filters:
640         select = select.where(cn_tbl.c.service_id == filters["service_id"])
641     if "host" in filters:
642         select = select.where(cn_tbl.c.host == filters["host"])
643     if "hypervisor_hostname" in filters:
644         hyp_hostname = filters["hypervisor_hostname"]
645         select = select.where(cn_tbl.c.hypervisor_hostname == hyp_hostname)
646     if "mapped" in filters:
647         select = select.where(cn_tbl.c.mapped < filters['mapped'])
648     if marker is not None:
649         try:
650             compute_node_get(context, marker)
651         except exception.ComputeHostNotFound:
652             raise exception.MarkerNotFound(marker=marker)
653         select = select.where(cn_tbl.c.id > marker)
654     if limit is not None:
655         select = select.limit(limit)
656     # Explicitly order by id, so we're not dependent on the native sort
657     # order of the underlying DB.
658     select = select.order_by(asc("id"))
659     return select
660 
661 
662 def _compute_node_fetchall(context, filters=None, limit=None, marker=None):
663     select = _compute_node_select(context, filters, limit=limit, marker=marker)
664     engine = get_engine(context=context)
665     conn = engine.connect()
666 
667     results = conn.execute(select).fetchall()
668 
669     # Callers expect dict-like objects, not SQLAlchemy RowProxy objects...
670     results = [dict(r) for r in results]
671     conn.close()
672     return results
673 
674 
675 @pick_context_manager_reader
676 def compute_node_get(context, compute_id):
677     results = _compute_node_fetchall(context, {"compute_id": compute_id})
678     if not results:
679         raise exception.ComputeHostNotFound(host=compute_id)
680     return results[0]
681 
682 
683 @pick_context_manager_reader
684 def compute_node_get_model(context, compute_id):
685     # TODO(edleafe): remove once the compute node resource provider migration
686     # is complete, and this distinction is no longer necessary.
687     result = model_query(context, models.ComputeNode).\
688             filter_by(id=compute_id).\
689             first()
690     if not result:
691         raise exception.ComputeHostNotFound(host=compute_id)
692     return result
693 
694 
695 @pick_context_manager_reader
696 def compute_nodes_get_by_service_id(context, service_id):
697     results = _compute_node_fetchall(context, {"service_id": service_id})
698     if not results:
699         raise exception.ServiceNotFound(service_id=service_id)
700     return results
701 
702 
703 @pick_context_manager_reader
704 def compute_node_get_by_host_and_nodename(context, host, nodename):
705     results = _compute_node_fetchall(context,
706             {"host": host, "hypervisor_hostname": nodename})
707     if not results:
708         raise exception.ComputeHostNotFound(host=host)
709     return results[0]
710 
711 
712 @pick_context_manager_reader_allow_async
713 def compute_node_get_all_by_host(context, host):
714     results = _compute_node_fetchall(context, {"host": host})
715     if not results:
716         raise exception.ComputeHostNotFound(host=host)
717     return results
718 
719 
720 @pick_context_manager_reader
721 def compute_node_get_all(context):
722     return _compute_node_fetchall(context)
723 
724 
725 @pick_context_manager_reader
726 def compute_node_get_all_mapped_less_than(context, mapped_less_than):
727     return _compute_node_fetchall(context,
728                                   {'mapped': mapped_less_than})
729 
730 
731 @pick_context_manager_reader
732 def compute_node_get_all_by_pagination(context, limit=None, marker=None):
733     return _compute_node_fetchall(context, limit=limit, marker=marker)
734 
735 
736 @pick_context_manager_reader
737 def compute_node_search_by_hypervisor(context, hypervisor_match):
738     field = models.ComputeNode.hypervisor_hostname
739     return model_query(context, models.ComputeNode).\
740             filter(field.like('%%%s%%' % hypervisor_match)).\
741             all()
742 
743 
744 @pick_context_manager_writer
745 def compute_node_create(context, values):
746     """Creates a new ComputeNode and populates the capacity fields
747     with the most recent data.
748     """
749     convert_objects_related_datetimes(values)
750 
751     compute_node_ref = models.ComputeNode()
752     compute_node_ref.update(values)
753     compute_node_ref.save(context.session)
754 
755     return compute_node_ref
756 
757 
758 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
759 @pick_context_manager_writer
760 def compute_node_update(context, compute_id, values):
761     """Updates the ComputeNode record with the most recent data."""
762 
763     compute_ref = compute_node_get_model(context, compute_id)
764     # Always update this, even if there's going to be no other
765     # changes in data.  This ensures that we invalidate the
766     # scheduler cache of compute node data in case of races.
767     values['updated_at'] = timeutils.utcnow()
768     convert_objects_related_datetimes(values)
769     compute_ref.update(values)
770 
771     return compute_ref
772 
773 
774 @pick_context_manager_writer
775 def compute_node_delete(context, compute_id):
776     """Delete a ComputeNode record."""
777     result = model_query(context, models.ComputeNode).\
778              filter_by(id=compute_id).\
779              soft_delete(synchronize_session=False)
780 
781     if not result:
782         raise exception.ComputeHostNotFound(host=compute_id)
783 
784 
785 @pick_context_manager_reader
786 def compute_node_statistics(context):
787     """Compute statistics over all compute nodes."""
788     engine = get_engine(context=context)
789     services_tbl = models.Service.__table__
790 
791     inner_sel = sa.alias(_compute_node_select(context), name='inner_sel')
792 
793     # TODO(sbauza): Remove the service_id filter in a later release
794     # once we are sure that all compute nodes report the host field
795     j = sa.join(
796         inner_sel, services_tbl,
797         sql.and_(
798             sql.or_(
799                 inner_sel.c.host == services_tbl.c.host,
800                 inner_sel.c.service_id == services_tbl.c.id
801             ),
802             services_tbl.c.disabled == false(),
803             services_tbl.c.binary == 'nova-compute',
804             services_tbl.c.deleted == 0
805         )
806     )
807 
808     # NOTE(jaypipes): This COALESCE() stuff is temporary while the data
809     # migration to the new resource providers inventories and allocations
810     # tables is completed.
811     agg_cols = [
812         func.count().label('count'),
813         sql.func.sum(
814             inner_sel.c.vcpus
815         ).label('vcpus'),
816         sql.func.sum(
817             inner_sel.c.memory_mb
818         ).label('memory_mb'),
819         sql.func.sum(
820             inner_sel.c.local_gb
821         ).label('local_gb'),
822         sql.func.sum(
823             inner_sel.c.vcpus_used
824         ).label('vcpus_used'),
825         sql.func.sum(
826             inner_sel.c.memory_mb_used
827         ).label('memory_mb_used'),
828         sql.func.sum(
829             inner_sel.c.local_gb_used
830         ).label('local_gb_used'),
831         sql.func.sum(
832             inner_sel.c.free_ram_mb
833         ).label('free_ram_mb'),
834         sql.func.sum(
835             inner_sel.c.free_disk_gb
836         ).label('free_disk_gb'),
837         sql.func.sum(
838             inner_sel.c.current_workload
839         ).label('current_workload'),
840         sql.func.sum(
841             inner_sel.c.running_vms
842         ).label('running_vms'),
843         sql.func.sum(
844             inner_sel.c.disk_available_least
845         ).label('disk_available_least'),
846     ]
847     select = sql.select(agg_cols).select_from(j)
848     conn = engine.connect()
849 
850     results = conn.execute(select).fetchone()
851 
852     # Build a dict of the info--making no assumptions about result
853     fields = ('count', 'vcpus', 'memory_mb', 'local_gb', 'vcpus_used',
854               'memory_mb_used', 'local_gb_used', 'free_ram_mb', 'free_disk_gb',
855               'current_workload', 'running_vms', 'disk_available_least')
856     results = {field: int(results[idx] or 0)
857                for idx, field in enumerate(fields)}
858     conn.close()
859     return results
860 
861 
862 ###################
863 
864 
865 @pick_context_manager_writer
866 def certificate_create(context, values):
867     certificate_ref = models.Certificate()
868     for (key, value) in values.items():
869         certificate_ref[key] = value
870     certificate_ref.save(context.session)
871     return certificate_ref
872 
873 
874 @pick_context_manager_reader
875 def certificate_get_all_by_project(context, project_id):
876     return model_query(context, models.Certificate, read_deleted="no").\
877                    filter_by(project_id=project_id).\
878                    all()
879 
880 
881 @pick_context_manager_reader
882 def certificate_get_all_by_user(context, user_id):
883     return model_query(context, models.Certificate, read_deleted="no").\
884                    filter_by(user_id=user_id).\
885                    all()
886 
887 
888 @pick_context_manager_reader
889 def certificate_get_all_by_user_and_project(context, user_id, project_id):
890     return model_query(context, models.Certificate, read_deleted="no").\
891                    filter_by(user_id=user_id).\
892                    filter_by(project_id=project_id).\
893                    all()
894 
895 
896 ###################
897 
898 
899 @require_context
900 @pick_context_manager_reader
901 def floating_ip_get(context, id):
902     try:
903         result = model_query(context, models.FloatingIp, project_only=True).\
904                      filter_by(id=id).\
905                      options(joinedload_all('fixed_ip.instance')).\
906                      first()
907 
908         if not result:
909             raise exception.FloatingIpNotFound(id=id)
910     except db_exc.DBError:
911         LOG.warning("Invalid floating IP ID %s in request", id)
912         raise exception.InvalidID(id=id)
913     return result
914 
915 
916 @require_context
917 @pick_context_manager_reader
918 def floating_ip_get_pools(context):
919     pools = []
920     for result in model_query(context, models.FloatingIp,
921                               (models.FloatingIp.pool,)).distinct():
922         pools.append({'name': result[0]})
923     return pools
924 
925 
926 @require_context
927 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
928 @pick_context_manager_writer
929 def floating_ip_allocate_address(context, project_id, pool,
930                                  auto_assigned=False):
931     nova.context.authorize_project_context(context, project_id)
932     floating_ip_ref = model_query(context, models.FloatingIp,
933                                   read_deleted="no").\
934         filter_by(fixed_ip_id=None).\
935         filter_by(project_id=None).\
936         filter_by(pool=pool).\
937         first()
938 
939     if not floating_ip_ref:
940         raise exception.NoMoreFloatingIps()
941 
942     params = {'project_id': project_id, 'auto_assigned': auto_assigned}
943 
944     rows_update = model_query(context, models.FloatingIp, read_deleted="no").\
945         filter_by(id=floating_ip_ref['id']).\
946         filter_by(fixed_ip_id=None).\
947         filter_by(project_id=None).\
948         filter_by(pool=pool).\
949         update(params, synchronize_session='evaluate')
950 
951     if not rows_update:
952         LOG.debug('The row was updated in a concurrent transaction, '
953                   'we will fetch another one')
954         raise db_exc.RetryRequest(exception.FloatingIpAllocateFailed())
955 
956     return floating_ip_ref['address']
957 
958 
959 @require_context
960 @pick_context_manager_writer
961 def floating_ip_bulk_create(context, ips, want_result=True):
962     try:
963         tab = models.FloatingIp().__table__
964         context.session.execute(tab.insert(), ips)
965     except db_exc.DBDuplicateEntry as e:
966         raise exception.FloatingIpExists(address=e.value)
967 
968     if want_result:
969         return model_query(context, models.FloatingIp).filter(
970             models.FloatingIp.address.in_(
971                 [ip['address'] for ip in ips])).all()
972 
973 
974 def _ip_range_splitter(ips, block_size=256):
975     """Yields blocks of IPs no more than block_size elements long."""
976     out = []
977     count = 0
978     for ip in ips:
979         out.append(ip['address'])
980         count += 1
981 
982         if count > block_size - 1:
983             yield out
984             out = []
985             count = 0
986 
987     if out:
988         yield out
989 
990 
991 @require_context
992 @pick_context_manager_writer
993 def floating_ip_bulk_destroy(context, ips):
994     project_id_to_quota_count = collections.defaultdict(int)
995     for ip_block in _ip_range_splitter(ips):
996         # Find any floating IPs that were not auto_assigned and
997         # thus need quota released.
998         query = model_query(context, models.FloatingIp).\
999             filter(models.FloatingIp.address.in_(ip_block)).\
1000             filter_by(auto_assigned=False)
1001         for row in query.all():
1002             # The count is negative since we release quota by
1003             # reserving negative quota.
1004             project_id_to_quota_count[row['project_id']] -= 1
1005         # Delete the floating IPs.
1006         model_query(context, models.FloatingIp).\
1007             filter(models.FloatingIp.address.in_(ip_block)).\
1008             soft_delete(synchronize_session='fetch')
1009 
1010 
1011 @require_context
1012 @pick_context_manager_writer
1013 def floating_ip_create(context, values):
1014     floating_ip_ref = models.FloatingIp()
1015     floating_ip_ref.update(values)
1016     try:
1017         floating_ip_ref.save(context.session)
1018     except db_exc.DBDuplicateEntry:
1019         raise exception.FloatingIpExists(address=values['address'])
1020     return floating_ip_ref
1021 
1022 
1023 def _floating_ip_count_by_project(context, project_id):
1024     nova.context.authorize_project_context(context, project_id)
1025     # TODO(tr3buchet): why leave auto_assigned floating IPs out?
1026     return model_query(context, models.FloatingIp, read_deleted="no").\
1027                    filter_by(project_id=project_id).\
1028                    filter_by(auto_assigned=False).\
1029                    count()
1030 
1031 
1032 @require_context
1033 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
1034 @pick_context_manager_writer
1035 def floating_ip_fixed_ip_associate(context, floating_address,
1036                                    fixed_address, host):
1037     fixed_ip_ref = model_query(context, models.FixedIp).\
1038                      filter_by(address=fixed_address).\
1039                      options(joinedload('network')).\
1040                      first()
1041     if not fixed_ip_ref:
1042         raise exception.FixedIpNotFoundForAddress(address=fixed_address)
1043     rows = model_query(context, models.FloatingIp).\
1044                 filter_by(address=floating_address).\
1045                 filter(models.FloatingIp.project_id ==
1046                        context.project_id).\
1047                 filter(or_(models.FloatingIp.fixed_ip_id ==
1048                            fixed_ip_ref['id'],
1049                            models.FloatingIp.fixed_ip_id.is_(None))).\
1050                 update({'fixed_ip_id': fixed_ip_ref['id'], 'host': host})
1051 
1052     if not rows:
1053         raise exception.FloatingIpAssociateFailed(address=floating_address)
1054 
1055     return fixed_ip_ref
1056 
1057 
1058 @require_context
1059 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
1060 @pick_context_manager_writer
1061 def floating_ip_deallocate(context, address):
1062     return model_query(context, models.FloatingIp).\
1063         filter_by(address=address).\
1064         filter(and_(models.FloatingIp.project_id != null()),
1065                     models.FloatingIp.fixed_ip_id == null()).\
1066         update({'project_id': None,
1067                 'host': None,
1068                 'auto_assigned': False},
1069                synchronize_session=False)
1070 
1071 
1072 @require_context
1073 @pick_context_manager_writer
1074 def floating_ip_destroy(context, address):
1075     model_query(context, models.FloatingIp).\
1076             filter_by(address=address).\
1077             delete()
1078 
1079 
1080 @require_context
1081 @pick_context_manager_writer
1082 def floating_ip_disassociate(context, address):
1083     floating_ip_ref = model_query(context,
1084                                   models.FloatingIp).\
1085                         filter_by(address=address).\
1086                         first()
1087     if not floating_ip_ref:
1088         raise exception.FloatingIpNotFoundForAddress(address=address)
1089 
1090     fixed_ip_ref = model_query(context, models.FixedIp).\
1091         filter_by(id=floating_ip_ref['fixed_ip_id']).\
1092         options(joinedload('network')).\
1093         first()
1094     floating_ip_ref.fixed_ip_id = None
1095     floating_ip_ref.host = None
1096 
1097     return fixed_ip_ref
1098 
1099 
1100 def _floating_ip_get_all(context):
1101     return model_query(context, models.FloatingIp, read_deleted="no")
1102 
1103 
1104 @pick_context_manager_reader
1105 def floating_ip_get_all(context):
1106     floating_ip_refs = _floating_ip_get_all(context).\
1107                        options(joinedload('fixed_ip')).\
1108                        all()
1109     if not floating_ip_refs:
1110         raise exception.NoFloatingIpsDefined()
1111     return floating_ip_refs
1112 
1113 
1114 @pick_context_manager_reader
1115 def floating_ip_get_all_by_host(context, host):
1116     floating_ip_refs = _floating_ip_get_all(context).\
1117                        filter_by(host=host).\
1118                        options(joinedload('fixed_ip')).\
1119                        all()
1120     if not floating_ip_refs:
1121         raise exception.FloatingIpNotFoundForHost(host=host)
1122     return floating_ip_refs
1123 
1124 
1125 @require_context
1126 @pick_context_manager_reader
1127 def floating_ip_get_all_by_project(context, project_id):
1128     nova.context.authorize_project_context(context, project_id)
1129     # TODO(tr3buchet): why do we not want auto_assigned floating IPs here?
1130     return _floating_ip_get_all(context).\
1131                          filter_by(project_id=project_id).\
1132                          filter_by(auto_assigned=False).\
1133                          options(joinedload_all('fixed_ip.instance')).\
1134                          all()
1135 
1136 
1137 @require_context
1138 @pick_context_manager_reader
1139 def floating_ip_get_by_address(context, address):
1140     return _floating_ip_get_by_address(context, address)
1141 
1142 
1143 def _floating_ip_get_by_address(context, address):
1144 
1145     # if address string is empty explicitly set it to None
1146     if not address:
1147         address = None
1148     try:
1149         result = model_query(context, models.FloatingIp).\
1150                     filter_by(address=address).\
1151                     options(joinedload_all('fixed_ip.instance')).\
1152                     first()
1153 
1154         if not result:
1155             raise exception.FloatingIpNotFoundForAddress(address=address)
1156     except db_exc.DBError:
1157         msg = _("Invalid floating IP %s in request") % address
1158         LOG.warning(msg)
1159         raise exception.InvalidIpAddressError(msg)
1160 
1161     # If the floating IP has a project ID set, check to make sure
1162     # the non-admin user has access.
1163     if result.project_id and nova.context.is_user_context(context):
1164         nova.context.authorize_project_context(context, result.project_id)
1165 
1166     return result
1167 
1168 
1169 @require_context
1170 @pick_context_manager_reader
1171 def floating_ip_get_by_fixed_address(context, fixed_address):
1172     return model_query(context, models.FloatingIp).\
1173                        outerjoin(models.FixedIp,
1174                                  models.FixedIp.id ==
1175                                  models.FloatingIp.fixed_ip_id).\
1176                        filter(models.FixedIp.address == fixed_address).\
1177                        all()
1178 
1179 
1180 @require_context
1181 @pick_context_manager_reader
1182 def floating_ip_get_by_fixed_ip_id(context, fixed_ip_id):
1183     return model_query(context, models.FloatingIp).\
1184                 filter_by(fixed_ip_id=fixed_ip_id).\
1185                 all()
1186 
1187 
1188 @require_context
1189 @pick_context_manager_writer
1190 def floating_ip_update(context, address, values):
1191     float_ip_ref = _floating_ip_get_by_address(context, address)
1192     float_ip_ref.update(values)
1193     try:
1194         float_ip_ref.save(context.session)
1195     except db_exc.DBDuplicateEntry:
1196         raise exception.FloatingIpExists(address=values['address'])
1197     return float_ip_ref
1198 
1199 
1200 ###################
1201 
1202 
1203 @require_context
1204 @pick_context_manager_reader
1205 def dnsdomain_get(context, fqdomain):
1206     return model_query(context, models.DNSDomain, read_deleted="no").\
1207                filter_by(domain=fqdomain).\
1208                with_lockmode('update').\
1209                first()
1210 
1211 
1212 def _dnsdomain_get_or_create(context, fqdomain):
1213     domain_ref = dnsdomain_get(context, fqdomain)
1214     if not domain_ref:
1215         dns_ref = models.DNSDomain()
1216         dns_ref.update({'domain': fqdomain,
1217                         'availability_zone': None,
1218                         'project_id': None})
1219         return dns_ref
1220 
1221     return domain_ref
1222 
1223 
1224 @pick_context_manager_writer
1225 def dnsdomain_register_for_zone(context, fqdomain, zone):
1226     domain_ref = _dnsdomain_get_or_create(context, fqdomain)
1227     domain_ref.scope = 'private'
1228     domain_ref.availability_zone = zone
1229     context.session.add(domain_ref)
1230 
1231 
1232 @pick_context_manager_writer
1233 def dnsdomain_register_for_project(context, fqdomain, project):
1234     domain_ref = _dnsdomain_get_or_create(context, fqdomain)
1235     domain_ref.scope = 'public'
1236     domain_ref.project_id = project
1237     context.session.add(domain_ref)
1238 
1239 
1240 @pick_context_manager_writer
1241 def dnsdomain_unregister(context, fqdomain):
1242     model_query(context, models.DNSDomain).\
1243                  filter_by(domain=fqdomain).\
1244                  delete()
1245 
1246 
1247 @pick_context_manager_reader
1248 def dnsdomain_get_all(context):
1249     return model_query(context, models.DNSDomain, read_deleted="no").all()
1250 
1251 
1252 ###################
1253 
1254 
1255 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
1256 @pick_context_manager_writer
1257 def fixed_ip_associate(context, address, instance_uuid, network_id=None,
1258                        reserved=False, virtual_interface_id=None):
1259     """Keyword arguments:
1260     reserved -- should be a boolean value(True or False), exact value will be
1261     used to filter on the fixed IP address
1262     """
1263     if not uuidutils.is_uuid_like(instance_uuid):
1264         raise exception.InvalidUUID(uuid=instance_uuid)
1265 
1266     network_or_none = or_(models.FixedIp.network_id == network_id,
1267                           models.FixedIp.network_id == null())
1268     fixed_ip_ref = model_query(context, models.FixedIp, read_deleted="no").\
1269                            filter(network_or_none).\
1270                            filter_by(reserved=reserved).\
1271                            filter_by(address=address).\
1272                            first()
1273 
1274     if fixed_ip_ref is None:
1275         raise exception.FixedIpNotFoundForNetwork(address=address,
1276                                         network_uuid=network_id)
1277     if fixed_ip_ref.instance_uuid:
1278         raise exception.FixedIpAlreadyInUse(address=address,
1279                                             instance_uuid=instance_uuid)
1280 
1281     params = {'instance_uuid': instance_uuid,
1282               'allocated': virtual_interface_id is not None}
1283     if not fixed_ip_ref.network_id:
1284         params['network_id'] = network_id
1285     if virtual_interface_id:
1286         params['virtual_interface_id'] = virtual_interface_id
1287 
1288     rows_updated = model_query(context, models.FixedIp, read_deleted="no").\
1289                             filter_by(id=fixed_ip_ref.id).\
1290                             filter(network_or_none).\
1291                             filter_by(reserved=reserved).\
1292                             filter_by(address=address).\
1293                             update(params, synchronize_session='evaluate')
1294 
1295     if not rows_updated:
1296         LOG.debug('The row was updated in a concurrent transaction, '
1297                   'we will fetch another row')
1298         raise db_exc.RetryRequest(
1299             exception.FixedIpAssociateFailed(net=network_id))
1300 
1301     return fixed_ip_ref
1302 
1303 
1304 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
1305 @pick_context_manager_writer
1306 def fixed_ip_associate_pool(context, network_id, instance_uuid=None,
1307                             host=None, virtual_interface_id=None):
1308     """allocate a fixed ip out of a fixed ip network pool.
1309 
1310     This allocates an unallocated fixed ip out of a specified
1311     network. We sort by updated_at to hand out the oldest address in
1312     the list.
1313 
1314     """
1315     if instance_uuid and not uuidutils.is_uuid_like(instance_uuid):
1316         raise exception.InvalidUUID(uuid=instance_uuid)
1317 
1318     network_or_none = or_(models.FixedIp.network_id == network_id,
1319                           models.FixedIp.network_id == null())
1320     fixed_ip_ref = model_query(context, models.FixedIp, read_deleted="no").\
1321                            filter(network_or_none).\
1322                            filter_by(reserved=False).\
1323                            filter_by(instance_uuid=None).\
1324                            filter_by(host=None).\
1325                            filter_by(leased=False).\
1326                            order_by(asc(models.FixedIp.updated_at)).\
1327                            first()
1328 
1329     if not fixed_ip_ref:
1330         raise exception.NoMoreFixedIps(net=network_id)
1331 
1332     params = {'allocated': virtual_interface_id is not None}
1333     if fixed_ip_ref['network_id'] is None:
1334         params['network_id'] = network_id
1335     if instance_uuid:
1336         params['instance_uuid'] = instance_uuid
1337     if host:
1338         params['host'] = host
1339     if virtual_interface_id:
1340         params['virtual_interface_id'] = virtual_interface_id
1341 
1342     rows_updated = model_query(context, models.FixedIp, read_deleted="no").\
1343         filter_by(id=fixed_ip_ref['id']).\
1344         filter_by(network_id=fixed_ip_ref['network_id']).\
1345         filter_by(reserved=False).\
1346         filter_by(instance_uuid=None).\
1347         filter_by(host=None).\
1348         filter_by(leased=False).\
1349         filter_by(address=fixed_ip_ref['address']).\
1350         update(params, synchronize_session='evaluate')
1351 
1352     if not rows_updated:
1353         LOG.debug('The row was updated in a concurrent transaction, '
1354                   'we will fetch another row')
1355         raise db_exc.RetryRequest(
1356             exception.FixedIpAssociateFailed(net=network_id))
1357 
1358     return fixed_ip_ref
1359 
1360 
1361 @require_context
1362 @pick_context_manager_writer
1363 def fixed_ip_create(context, values):
1364     fixed_ip_ref = models.FixedIp()
1365     fixed_ip_ref.update(values)
1366     try:
1367         fixed_ip_ref.save(context.session)
1368     except db_exc.DBDuplicateEntry:
1369         raise exception.FixedIpExists(address=values['address'])
1370     return fixed_ip_ref
1371 
1372 
1373 @require_context
1374 @pick_context_manager_writer
1375 def fixed_ip_bulk_create(context, ips):
1376     try:
1377         tab = models.FixedIp.__table__
1378         context.session.execute(tab.insert(), ips)
1379     except db_exc.DBDuplicateEntry as e:
1380         raise exception.FixedIpExists(address=e.value)
1381 
1382 
1383 @require_context
1384 @pick_context_manager_writer
1385 def fixed_ip_disassociate(context, address):
1386     _fixed_ip_get_by_address(context, address).update(
1387         {'instance_uuid': None,
1388          'virtual_interface_id': None})
1389 
1390 
1391 @pick_context_manager_writer
1392 def fixed_ip_disassociate_all_by_timeout(context, host, time):
1393     # NOTE(vish): only update fixed ips that "belong" to this
1394     #             host; i.e. the network host or the instance
1395     #             host matches. Two queries necessary because
1396     #             join with update doesn't work.
1397     host_filter = or_(and_(models.Instance.host == host,
1398                            models.Network.multi_host == true()),
1399                       models.Network.host == host)
1400     result = model_query(context, models.FixedIp, (models.FixedIp.id,),
1401                          read_deleted="no").\
1402             filter(models.FixedIp.allocated == false()).\
1403             filter(models.FixedIp.updated_at < time).\
1404             join((models.Network,
1405                   models.Network.id == models.FixedIp.network_id)).\
1406             join((models.Instance,
1407                   models.Instance.uuid == models.FixedIp.instance_uuid)).\
1408             filter(host_filter).\
1409             all()
1410     fixed_ip_ids = [fip[0] for fip in result]
1411     if not fixed_ip_ids:
1412         return 0
1413     result = model_query(context, models.FixedIp).\
1414                          filter(models.FixedIp.id.in_(fixed_ip_ids)).\
1415                          update({'instance_uuid': None,
1416                                  'leased': False,
1417                                  'updated_at': timeutils.utcnow()},
1418                                 synchronize_session='fetch')
1419     return result
1420 
1421 
1422 @require_context
1423 @pick_context_manager_reader
1424 def fixed_ip_get(context, id, get_network=False):
1425     query = model_query(context, models.FixedIp).filter_by(id=id)
1426     if get_network:
1427         query = query.options(joinedload('network'))
1428     result = query.first()
1429     if not result:
1430         raise exception.FixedIpNotFound(id=id)
1431 
1432     # FIXME(sirp): shouldn't we just use project_only here to restrict the
1433     # results?
1434     if (nova.context.is_user_context(context) and
1435             result['instance_uuid'] is not None):
1436         instance = instance_get_by_uuid(context.elevated(read_deleted='yes'),
1437                                         result['instance_uuid'])
1438         nova.context.authorize_project_context(context, instance.project_id)
1439 
1440     return result
1441 
1442 
1443 @pick_context_manager_reader
1444 def fixed_ip_get_all(context):
1445     result = model_query(context, models.FixedIp, read_deleted="yes").all()
1446     if not result:
1447         raise exception.NoFixedIpsDefined()
1448 
1449     return result
1450 
1451 
1452 @require_context
1453 @pick_context_manager_reader
1454 def fixed_ip_get_by_address(context, address, columns_to_join=None):
1455     return _fixed_ip_get_by_address(context, address,
1456                                     columns_to_join=columns_to_join)
1457 
1458 
1459 def _fixed_ip_get_by_address(context, address, columns_to_join=None):
1460     if columns_to_join is None:
1461         columns_to_join = []
1462 
1463     try:
1464         result = model_query(context, models.FixedIp)
1465         for column in columns_to_join:
1466             result = result.options(joinedload_all(column))
1467         result = result.filter_by(address=address).first()
1468         if not result:
1469             raise exception.FixedIpNotFoundForAddress(address=address)
1470     except db_exc.DBError:
1471         msg = _("Invalid fixed IP Address %s in request") % address
1472         LOG.warning(msg)
1473         raise exception.FixedIpInvalid(msg)
1474 
1475     # NOTE(sirp): shouldn't we just use project_only here to restrict the
1476     # results?
1477     if (nova.context.is_user_context(context) and
1478             result['instance_uuid'] is not None):
1479         instance = _instance_get_by_uuid(
1480             context.elevated(read_deleted='yes'),
1481             result['instance_uuid'])
1482         nova.context.authorize_project_context(context,
1483                                                instance.project_id)
1484     return result
1485 
1486 
1487 @require_context
1488 @pick_context_manager_reader
1489 def fixed_ip_get_by_floating_address(context, floating_address):
1490     return model_query(context, models.FixedIp).\
1491                        join(models.FloatingIp,
1492                             models.FloatingIp.fixed_ip_id ==
1493                             models.FixedIp.id).\
1494                        filter(models.FloatingIp.address == floating_address).\
1495                        first()
1496     # NOTE(tr3buchet) please don't invent an exception here, None is fine
1497 
1498 
1499 @require_context
1500 @pick_context_manager_reader
1501 def fixed_ip_get_by_instance(context, instance_uuid):
1502     if not uuidutils.is_uuid_like(instance_uuid):
1503         raise exception.InvalidUUID(uuid=instance_uuid)
1504 
1505     vif_and = and_(models.VirtualInterface.id ==
1506                    models.FixedIp.virtual_interface_id,
1507                    models.VirtualInterface.deleted == 0)
1508     result = model_query(context, models.FixedIp, read_deleted="no").\
1509                  filter_by(instance_uuid=instance_uuid).\
1510                  outerjoin(models.VirtualInterface, vif_and).\
1511                  options(contains_eager("virtual_interface")).\
1512                  options(joinedload('network')).\
1513                  options(joinedload('floating_ips')).\
1514                  order_by(asc(models.VirtualInterface.created_at),
1515                           asc(models.VirtualInterface.id)).\
1516                  all()
1517 
1518     if not result:
1519         raise exception.FixedIpNotFoundForInstance(instance_uuid=instance_uuid)
1520 
1521     return result
1522 
1523 
1524 @pick_context_manager_reader
1525 def fixed_ip_get_by_host(context, host):
1526     instance_uuids = _instance_get_all_uuids_by_host(context, host)
1527     if not instance_uuids:
1528         return []
1529 
1530     return model_query(context, models.FixedIp).\
1531              filter(models.FixedIp.instance_uuid.in_(instance_uuids)).\
1532              all()
1533 
1534 
1535 @require_context
1536 @pick_context_manager_reader
1537 def fixed_ip_get_by_network_host(context, network_id, host):
1538     result = model_query(context, models.FixedIp, read_deleted="no").\
1539                  filter_by(network_id=network_id).\
1540                  filter_by(host=host).\
1541                  first()
1542 
1543     if not result:
1544         raise exception.FixedIpNotFoundForNetworkHost(network_id=network_id,
1545                                                       host=host)
1546     return result
1547 
1548 
1549 @require_context
1550 @pick_context_manager_reader
1551 def fixed_ips_by_virtual_interface(context, vif_id):
1552     result = model_query(context, models.FixedIp, read_deleted="no").\
1553                  filter_by(virtual_interface_id=vif_id).\
1554                  options(joinedload('network')).\
1555                  options(joinedload('floating_ips')).\
1556                  all()
1557 
1558     return result
1559 
1560 
1561 @require_context
1562 @pick_context_manager_writer
1563 def fixed_ip_update(context, address, values):
1564     _fixed_ip_get_by_address(context, address).update(values)
1565 
1566 
1567 def _fixed_ip_count_by_project(context, project_id):
1568     nova.context.authorize_project_context(context, project_id)
1569     return model_query(context, models.FixedIp, (models.FixedIp.id,),
1570                        read_deleted="no").\
1571                 join((models.Instance,
1572                       models.Instance.uuid == models.FixedIp.instance_uuid)).\
1573                 filter(models.Instance.project_id == project_id).\
1574                 count()
1575 
1576 
1577 ###################
1578 
1579 
1580 @require_context
1581 @pick_context_manager_writer
1582 def virtual_interface_create(context, values):
1583     """Create a new virtual interface record in the database.
1584 
1585     :param values: = dict containing column values
1586     """
1587     try:
1588         vif_ref = models.VirtualInterface()
1589         vif_ref.update(values)
1590         vif_ref.save(context.session)
1591     except db_exc.DBError:
1592         LOG.exception("VIF creation failed with a database error.")
1593         raise exception.VirtualInterfaceCreateException()
1594 
1595     return vif_ref
1596 
1597 
1598 def _virtual_interface_query(context):
1599     return model_query(context, models.VirtualInterface, read_deleted="no")
1600 
1601 
1602 @require_context
1603 @pick_context_manager_writer
1604 def virtual_interface_update(context, address, values):
1605     vif_ref = virtual_interface_get_by_address(context, address)
1606     vif_ref.update(values)
1607     vif_ref.save(context.session)
1608     return vif_ref
1609 
1610 
1611 @require_context
1612 @pick_context_manager_reader
1613 def virtual_interface_get(context, vif_id):
1614     """Gets a virtual interface from the table.
1615 
1616     :param vif_id: = id of the virtual interface
1617     """
1618     vif_ref = _virtual_interface_query(context).\
1619                       filter_by(id=vif_id).\
1620                       first()
1621     return vif_ref
1622 
1623 
1624 @require_context
1625 @pick_context_manager_reader
1626 def virtual_interface_get_by_address(context, address):
1627     """Gets a virtual interface from the table.
1628 
1629     :param address: = the address of the interface you're looking to get
1630     """
1631     try:
1632         vif_ref = _virtual_interface_query(context).\
1633                           filter_by(address=address).\
1634                           first()
1635     except db_exc.DBError:
1636         msg = _("Invalid virtual interface address %s in request") % address
1637         LOG.warning(msg)
1638         raise exception.InvalidIpAddressError(msg)
1639     return vif_ref
1640 
1641 
1642 @require_context
1643 @pick_context_manager_reader
1644 def virtual_interface_get_by_uuid(context, vif_uuid):
1645     """Gets a virtual interface from the table.
1646 
1647     :param vif_uuid: the uuid of the interface you're looking to get
1648     """
1649     vif_ref = _virtual_interface_query(context).\
1650                       filter_by(uuid=vif_uuid).\
1651                       first()
1652     return vif_ref
1653 
1654 
1655 @require_context
1656 @require_instance_exists_using_uuid
1657 @pick_context_manager_reader_allow_async
1658 def virtual_interface_get_by_instance(context, instance_uuid):
1659     """Gets all virtual interfaces for instance.
1660 
1661     :param instance_uuid: = uuid of the instance to retrieve vifs for
1662     """
1663     vif_refs = _virtual_interface_query(context).\
1664                        filter_by(instance_uuid=instance_uuid).\
1665                        order_by(asc("created_at"), asc("id")).\
1666                        all()
1667     return vif_refs
1668 
1669 
1670 @require_context
1671 @pick_context_manager_reader
1672 def virtual_interface_get_by_instance_and_network(context, instance_uuid,
1673                                                   network_id):
1674     """Gets virtual interface for instance that's associated with network."""
1675     vif_ref = _virtual_interface_query(context).\
1676                       filter_by(instance_uuid=instance_uuid).\
1677                       filter_by(network_id=network_id).\
1678                       first()
1679     return vif_ref
1680 
1681 
1682 @require_context
1683 @pick_context_manager_writer
1684 def virtual_interface_delete_by_instance(context, instance_uuid):
1685     """Delete virtual interface records that are associated
1686     with the instance given by instance_id.
1687 
1688     :param instance_uuid: = uuid of instance
1689     """
1690     _virtual_interface_query(context).\
1691            filter_by(instance_uuid=instance_uuid).\
1692            soft_delete()
1693 
1694 
1695 @require_context
1696 @pick_context_manager_writer
1697 def virtual_interface_delete(context, id):
1698     """Delete virtual interface records.
1699 
1700     :param id: id of the interface
1701     """
1702     _virtual_interface_query(context).\
1703         filter_by(id=id).\
1704         soft_delete()
1705 
1706 
1707 @require_context
1708 @pick_context_manager_reader
1709 def virtual_interface_get_all(context):
1710     """Get all vifs."""
1711     vif_refs = _virtual_interface_query(context).all()
1712     return vif_refs
1713 
1714 
1715 ###################
1716 
1717 
1718 def _metadata_refs(metadata_dict, meta_class):
1719     metadata_refs = []
1720     if metadata_dict:
1721         for k, v in metadata_dict.items():
1722             metadata_ref = meta_class()
1723             metadata_ref['key'] = k
1724             metadata_ref['value'] = v
1725             metadata_refs.append(metadata_ref)
1726     return metadata_refs
1727 
1728 
1729 def _validate_unique_server_name(context, name):
1730     if not CONF.osapi_compute_unique_server_name_scope:
1731         return
1732 
1733     lowername = name.lower()
1734     base_query = model_query(context, models.Instance, read_deleted='no').\
1735             filter(func.lower(models.Instance.hostname) == lowername)
1736 
1737     if CONF.osapi_compute_unique_server_name_scope == 'project':
1738         instance_with_same_name = base_query.\
1739                         filter_by(project_id=context.project_id).\
1740                         count()
1741 
1742     elif CONF.osapi_compute_unique_server_name_scope == 'global':
1743         instance_with_same_name = base_query.count()
1744 
1745     else:
1746         return
1747 
1748     if instance_with_same_name > 0:
1749         raise exception.InstanceExists(name=lowername)
1750 
1751 
1752 def _handle_objects_related_type_conversions(values):
1753     """Make sure that certain things in values (which may have come from
1754     an objects.instance.Instance object) are in suitable form for the
1755     database.
1756     """
1757     # NOTE(danms): Make sure IP addresses are passed as strings to
1758     # the database engine
1759     for key in ('access_ip_v4', 'access_ip_v6'):
1760         if key in values and values[key] is not None:
1761             values[key] = str(values[key])
1762 
1763     datetime_keys = ('created_at', 'deleted_at', 'updated_at',
1764                      'launched_at', 'terminated_at')
1765     convert_objects_related_datetimes(values, *datetime_keys)
1766 
1767 
1768 def _check_instance_exists_in_project(context, instance_uuid):
1769     if not model_query(context, models.Instance, read_deleted="no",
1770                        project_only=True).filter_by(
1771                        uuid=instance_uuid).first():
1772         raise exception.InstanceNotFound(instance_id=instance_uuid)
1773 
1774 
1775 @require_context
1776 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
1777 @pick_context_manager_writer
1778 def instance_create(context, values):
1779     """Create a new Instance record in the database.
1780 
1781     context - request context object
1782     values - dict containing column values.
1783     """
1784 
1785     security_group_ensure_default(context)
1786 
1787     values = values.copy()
1788     values['metadata'] = _metadata_refs(
1789             values.get('metadata'), models.InstanceMetadata)
1790 
1791     values['system_metadata'] = _metadata_refs(
1792             values.get('system_metadata'), models.InstanceSystemMetadata)
1793     _handle_objects_related_type_conversions(values)
1794 
1795     instance_ref = models.Instance()
1796     if not values.get('uuid'):
1797         values['uuid'] = uuidutils.generate_uuid()
1798     instance_ref['info_cache'] = models.InstanceInfoCache()
1799     info_cache = values.pop('info_cache', None)
1800     if info_cache is not None:
1801         instance_ref['info_cache'].update(info_cache)
1802     security_groups = values.pop('security_groups', [])
1803     instance_ref['extra'] = models.InstanceExtra()
1804     instance_ref['extra'].update(
1805         {'numa_topology': None,
1806          'pci_requests': None,
1807          'vcpu_model': None,
1808          })
1809     instance_ref['extra'].update(values.pop('extra', {}))
1810     instance_ref.update(values)
1811 
1812     def _get_sec_group_models(security_groups):
1813         models = []
1814         default_group = _security_group_ensure_default(context)
1815         if 'default' in security_groups:
1816             models.append(default_group)
1817             # Generate a new list, so we don't modify the original
1818             security_groups = [x for x in security_groups if x != 'default']
1819         if security_groups:
1820             models.extend(_security_group_get_by_names(
1821                 context, security_groups))
1822         return models
1823 
1824     if 'hostname' in values:
1825         _validate_unique_server_name(context, values['hostname'])
1826     instance_ref.security_groups = _get_sec_group_models(security_groups)
1827     context.session.add(instance_ref)
1828 
1829     # create the instance uuid to ec2_id mapping entry for instance
1830     ec2_instance_create(context, instance_ref['uuid'])
1831 
1832     # Parity with the return value of instance_get_all_by_filters_sort()
1833     # Obviously a newly-created instance record can't already have a fault
1834     # record because of the FK constraint, so this is fine.
1835     instance_ref.fault = None
1836 
1837     return instance_ref
1838 
1839 
1840 def _instance_data_get_for_user(context, project_id, user_id):
1841     result = model_query(context, models.Instance, (
1842         func.count(models.Instance.id),
1843         func.sum(models.Instance.vcpus),
1844         func.sum(models.Instance.memory_mb))).\
1845         filter_by(project_id=project_id)
1846     if user_id:
1847         result = result.filter_by(user_id=user_id).first()
1848     else:
1849         result = result.first()
1850     # NOTE(vish): convert None to 0
1851     return (result[0] or 0, result[1] or 0, result[2] or 0)
1852 
1853 
1854 @require_context
1855 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
1856 @pick_context_manager_writer
1857 def instance_destroy(context, instance_uuid, constraint=None):
1858     if uuidutils.is_uuid_like(instance_uuid):
1859         instance_ref = _instance_get_by_uuid(context, instance_uuid)
1860     else:
1861         raise exception.InvalidUUID(instance_uuid)
1862 
1863     query = model_query(context, models.Instance).\
1864                     filter_by(uuid=instance_uuid)
1865     if constraint is not None:
1866         query = constraint.apply(models.Instance, query)
1867     count = query.soft_delete()
1868     if count == 0:
1869         raise exception.ConstraintNotMet()
1870     model_query(context, models.SecurityGroupInstanceAssociation).\
1871             filter_by(instance_uuid=instance_uuid).\
1872             soft_delete()
1873     model_query(context, models.InstanceInfoCache).\
1874             filter_by(instance_uuid=instance_uuid).\
1875             soft_delete()
1876     model_query(context, models.InstanceMetadata).\
1877             filter_by(instance_uuid=instance_uuid).\
1878             soft_delete()
1879     model_query(context, models.InstanceFault).\
1880             filter_by(instance_uuid=instance_uuid).\
1881             soft_delete()
1882     model_query(context, models.InstanceExtra).\
1883             filter_by(instance_uuid=instance_uuid).\
1884             soft_delete()
1885     model_query(context, models.InstanceSystemMetadata).\
1886             filter_by(instance_uuid=instance_uuid).\
1887             soft_delete()
1888     model_query(context, models.InstanceGroupMember).\
1889             filter_by(instance_id=instance_uuid).\
1890             soft_delete()
1891     model_query(context, models.BlockDeviceMapping).\
1892             filter_by(instance_uuid=instance_uuid).\
1893             soft_delete()
1894     model_query(context, models.Migration).\
1895             filter_by(instance_uuid=instance_uuid).\
1896             soft_delete()
1897     # NOTE(snikitin): We can't use model_query here, because there is no
1898     # column 'deleted' in 'tags' table.
1899     context.session.query(models.Tag).filter_by(
1900         resource_id=instance_uuid).delete()
1901     context.session.query(models.ConsoleAuthToken).filter_by(
1902         instance_uuid=instance_uuid).delete()
1903     # NOTE(cfriesen): We intentionally do not soft-delete entries in the
1904     # instance_actions or instance_actions_events tables because they
1905     # can be used by operators to find out what actions were performed on a
1906     # deleted instance.  Both of these tables are special-cased in
1907     # _archive_deleted_rows_for_table().
1908 
1909     return instance_ref
1910 
1911 
1912 @require_context
1913 @pick_context_manager_reader_allow_async
1914 def instance_get_by_uuid(context, uuid, columns_to_join=None):
1915     return _instance_get_by_uuid(context, uuid,
1916                                  columns_to_join=columns_to_join)
1917 
1918 
1919 def _instance_get_by_uuid(context, uuid, columns_to_join=None):
1920     result = _build_instance_get(context, columns_to_join=columns_to_join).\
1921                 filter_by(uuid=uuid).\
1922                 first()
1923 
1924     if not result:
1925         raise exception.InstanceNotFound(instance_id=uuid)
1926 
1927     return result
1928 
1929 
1930 @require_context
1931 @pick_context_manager_reader
1932 def instance_get(context, instance_id, columns_to_join=None):
1933     try:
1934         result = _build_instance_get(context, columns_to_join=columns_to_join
1935                                      ).filter_by(id=instance_id).first()
1936 
1937         if not result:
1938             raise exception.InstanceNotFound(instance_id=instance_id)
1939 
1940         return result
1941     except db_exc.DBError:
1942         # NOTE(sdague): catch all in case the db engine chokes on the
1943         # id because it's too long of an int to store.
1944         LOG.warning("Invalid instance id %s in request", instance_id)
1945         raise exception.InvalidID(id=instance_id)
1946 
1947 
1948 def _build_instance_get(context, columns_to_join=None):
1949     query = model_query(context, models.Instance, project_only=True).\
1950             options(joinedload_all('security_groups.rules')).\
1951             options(joinedload('info_cache'))
1952     if columns_to_join is None:
1953         columns_to_join = ['metadata', 'system_metadata']
1954     for column in columns_to_join:
1955         if column in ['info_cache', 'security_groups']:
1956             # Already always joined above
1957             continue
1958         if 'extra.' in column:
1959             query = query.options(undefer(column))
1960         else:
1961             query = query.options(joinedload(column))
1962     # NOTE(alaski) Stop lazy loading of columns not needed.
1963     for col in ['metadata', 'system_metadata']:
1964         if col not in columns_to_join:
1965             query = query.options(noload(col))
1966     return query
1967 
1968 
1969 def _instances_fill_metadata(context, instances, manual_joins=None):
1970     """Selectively fill instances with manually-joined metadata. Note that
1971     instance will be converted to a dict.
1972 
1973     :param context: security context
1974     :param instances: list of instances to fill
1975     :param manual_joins: list of tables to manually join (can be any
1976                          combination of 'metadata' and 'system_metadata' or
1977                          None to take the default of both)
1978     """
1979     uuids = [inst['uuid'] for inst in instances]
1980 
1981     if manual_joins is None:
1982         manual_joins = ['metadata', 'system_metadata']
1983 
1984     meta = collections.defaultdict(list)
1985     if 'metadata' in manual_joins:
1986         for row in _instance_metadata_get_multi(context, uuids):
1987             meta[row['instance_uuid']].append(row)
1988 
1989     sys_meta = collections.defaultdict(list)
1990     if 'system_metadata' in manual_joins:
1991         for row in _instance_system_metadata_get_multi(context, uuids):
1992             sys_meta[row['instance_uuid']].append(row)
1993 
1994     pcidevs = collections.defaultdict(list)
1995     if 'pci_devices' in manual_joins:
1996         for row in _instance_pcidevs_get_multi(context, uuids):
1997             pcidevs[row['instance_uuid']].append(row)
1998 
1999     if 'fault' in manual_joins:
2000         faults = instance_fault_get_by_instance_uuids(context, uuids,
2001                                                       latest=True)
2002     else:
2003         faults = {}
2004 
2005     filled_instances = []
2006     for inst in instances:
2007         inst = dict(inst)
2008         inst['system_metadata'] = sys_meta[inst['uuid']]
2009         inst['metadata'] = meta[inst['uuid']]
2010         if 'pci_devices' in manual_joins:
2011             inst['pci_devices'] = pcidevs[inst['uuid']]
2012         inst_faults = faults.get(inst['uuid'])
2013         inst['fault'] = inst_faults and inst_faults[0] or None
2014         filled_instances.append(inst)
2015 
2016     return filled_instances
2017 
2018 
2019 def _manual_join_columns(columns_to_join):
2020     """Separate manually joined columns from columns_to_join
2021 
2022     If columns_to_join contains 'metadata', 'system_metadata', 'fault', or
2023     'pci_devices' those columns are removed from columns_to_join and added
2024     to a manual_joins list to be used with the _instances_fill_metadata method.
2025 
2026     The columns_to_join formal parameter is copied and not modified, the return
2027     tuple has the modified columns_to_join list to be used with joinedload in
2028     a model query.
2029 
2030     :param:columns_to_join: List of columns to join in a model query.
2031     :return: tuple of (manual_joins, columns_to_join)
2032     """
2033     manual_joins = []
2034     columns_to_join_new = copy.copy(columns_to_join)
2035     for column in ('metadata', 'system_metadata', 'pci_devices', 'fault'):
2036         if column in columns_to_join_new:
2037             columns_to_join_new.remove(column)
2038             manual_joins.append(column)
2039     return manual_joins, columns_to_join_new
2040 
2041 
2042 @require_context
2043 @pick_context_manager_reader
2044 def instance_get_all(context, columns_to_join=None):
2045     if columns_to_join is None:
2046         columns_to_join_new = ['info_cache', 'security_groups']
2047         manual_joins = ['metadata', 'system_metadata']
2048     else:
2049         manual_joins, columns_to_join_new = (
2050             _manual_join_columns(columns_to_join))
2051     query = model_query(context, models.Instance)
2052     for column in columns_to_join_new:
2053         query = query.options(joinedload(column))
2054     if not context.is_admin:
2055         # If we're not admin context, add appropriate filter..
2056         if context.project_id:
2057             query = query.filter_by(project_id=context.project_id)
2058         else:
2059             query = query.filter_by(user_id=context.user_id)
2060     instances = query.all()
2061     return _instances_fill_metadata(context, instances, manual_joins)
2062 
2063 
2064 @require_context
2065 @pick_context_manager_reader_allow_async
2066 def instance_get_all_by_filters(context, filters, sort_key, sort_dir,
2067                                 limit=None, marker=None, columns_to_join=None):
2068     """Return instances matching all filters sorted by the primary key.
2069 
2070     See instance_get_all_by_filters_sort for more information.
2071     """
2072     # Invoke the API with the multiple sort keys and directions using the
2073     # single sort key/direction
2074     return instance_get_all_by_filters_sort(context, filters, limit=limit,
2075                                             marker=marker,
2076                                             columns_to_join=columns_to_join,
2077                                             sort_keys=[sort_key],
2078                                             sort_dirs=[sort_dir])
2079 
2080 
2081 @require_context
2082 @pick_context_manager_reader_allow_async
2083 def instance_get_all_by_filters_sort(context, filters, limit=None, marker=None,
2084                                      columns_to_join=None, sort_keys=None,
2085                                      sort_dirs=None):
2086     """Return instances that match all filters sorted by the given keys.
2087     Deleted instances will be returned by default, unless there's a filter that
2088     says otherwise.
2089 
2090     Depending on the name of a filter, matching for that filter is
2091     performed using either exact matching or as regular expression
2092     matching. Exact matching is applied for the following filters::
2093 
2094     |   ['project_id', 'user_id', 'image_ref',
2095     |    'vm_state', 'instance_type_id', 'uuid',
2096     |    'metadata', 'host', 'system_metadata']
2097 
2098 
2099     A third type of filter (also using exact matching), filters
2100     based on instance metadata tags when supplied under a special
2101     key named 'filter'::
2102 
2103     |   filters = {
2104     |       'filter': [
2105     |           {'name': 'tag-key', 'value': '<metakey>'},
2106     |           {'name': 'tag-value', 'value': '<metaval>'},
2107     |           {'name': 'tag:<metakey>', 'value': '<metaval>'}
2108     |       ]
2109     |   }
2110 
2111     Special keys are used to tweek the query further::
2112 
2113     |   'changes-since' - only return instances updated after
2114     |   'deleted' - only return (or exclude) deleted instances
2115     |   'soft_deleted' - modify behavior of 'deleted' to either
2116     |                    include or exclude instances whose
2117     |                    vm_state is SOFT_DELETED.
2118 
2119     A fourth type of filter (also using exact matching), filters
2120     based on instance tags (not metadata tags). There are two types
2121     of these tags:
2122 
2123     `tags` -- One or more strings that will be used to filter results
2124             in an AND expression: T1 AND T2
2125 
2126     `tags-any` -- One or more strings that will be used to filter results in
2127             an OR expression: T1 OR T2
2128 
2129     `not-tags` -- One or more strings that will be used to filter results in
2130             an NOT AND expression: NOT (T1 AND T2)
2131 
2132     `not-tags-any` -- One or more strings that will be used to filter results
2133             in an NOT OR expression: NOT (T1 OR T2)
2134 
2135     Tags should be represented as list::
2136 
2137     |    filters = {
2138     |        'tags': [some-tag, some-another-tag],
2139     |        'tags-any: [some-any-tag, some-another-any-tag],
2140     |        'not-tags: [some-not-tag, some-another-not-tag],
2141     |        'not-tags-any: [some-not-any-tag, some-another-not-any-tag]
2142     |    }
2143 
2144     """
2145     # NOTE(mriedem): If the limit is 0 there is no point in even going
2146     # to the database since nothing is going to be returned anyway.
2147     if limit == 0:
2148         return []
2149 
2150     sort_keys, sort_dirs = process_sort_params(sort_keys,
2151                                                sort_dirs,
2152                                                default_dir='desc')
2153 
2154     if columns_to_join is None:
2155         columns_to_join_new = ['info_cache', 'security_groups']
2156         manual_joins = ['metadata', 'system_metadata']
2157     else:
2158         manual_joins, columns_to_join_new = (
2159             _manual_join_columns(columns_to_join))
2160 
2161     query_prefix = context.session.query(models.Instance)
2162     for column in columns_to_join_new:
2163         if 'extra.' in column:
2164             query_prefix = query_prefix.options(undefer(column))
2165         else:
2166             query_prefix = query_prefix.options(joinedload(column))
2167 
2168     # Note: order_by is done in the sqlalchemy.utils.py paginate_query(),
2169     # no need to do it here as well
2170 
2171     # Make a copy of the filters dictionary to use going forward, as we'll
2172     # be modifying it and we shouldn't affect the caller's use of it.
2173     filters = copy.deepcopy(filters)
2174 
2175     if 'changes-since' in filters:
2176         changes_since = timeutils.normalize_time(filters['changes-since'])
2177         query_prefix = query_prefix.\
2178                             filter(models.Instance.updated_at >= changes_since)
2179 
2180     if 'deleted' in filters:
2181         # Instances can be soft or hard deleted and the query needs to
2182         # include or exclude both
2183         deleted = filters.pop('deleted')
2184         if deleted:
2185             if filters.pop('soft_deleted', True):
2186                 delete = or_(
2187                     models.Instance.deleted == models.Instance.id,
2188                     models.Instance.vm_state == vm_states.SOFT_DELETED
2189                     )
2190                 query_prefix = query_prefix.\
2191                     filter(delete)
2192             else:
2193                 query_prefix = query_prefix.\
2194                     filter(models.Instance.deleted == models.Instance.id)
2195         else:
2196             query_prefix = query_prefix.\
2197                     filter_by(deleted=0)
2198             if not filters.pop('soft_deleted', False):
2199                 # It would be better to have vm_state not be nullable
2200                 # but until then we test it explicitly as a workaround.
2201                 not_soft_deleted = or_(
2202                     models.Instance.vm_state != vm_states.SOFT_DELETED,
2203                     models.Instance.vm_state == null()
2204                     )
2205                 query_prefix = query_prefix.filter(not_soft_deleted)
2206 
2207     if 'cleaned' in filters:
2208         cleaned = 1 if filters.pop('cleaned') else 0
2209         query_prefix = query_prefix.filter(models.Instance.cleaned == cleaned)
2210 
2211     if 'tags' in filters:
2212         tags = filters.pop('tags')
2213         # We build a JOIN ladder expression for each tag, JOIN'ing
2214         # the first tag to the instances table, and each subsequent
2215         # tag to the last JOIN'd tags table
2216         first_tag = tags.pop(0)
2217         query_prefix = query_prefix.join(models.Instance.tags)
2218         query_prefix = query_prefix.filter(models.Tag.tag == first_tag)
2219 
2220         for tag in tags:
2221             tag_alias = aliased(models.Tag)
2222             query_prefix = query_prefix.join(tag_alias,
2223                                              models.Instance.tags)
2224             query_prefix = query_prefix.filter(tag_alias.tag == tag)
2225 
2226     if 'tags-any' in filters:
2227         tags = filters.pop('tags-any')
2228         tag_alias = aliased(models.Tag)
2229         query_prefix = query_prefix.join(tag_alias, models.Instance.tags)
2230         query_prefix = query_prefix.filter(tag_alias.tag.in_(tags))
2231 
2232     if 'not-tags' in filters:
2233         tags = filters.pop('not-tags')
2234         first_tag = tags.pop(0)
2235         subq = query_prefix.session.query(models.Tag.resource_id)
2236         subq = subq.join(models.Instance.tags)
2237         subq = subq.filter(models.Tag.tag == first_tag)
2238 
2239         for tag in tags:
2240             tag_alias = aliased(models.Tag)
2241             subq = subq.join(tag_alias, models.Instance.tags)
2242             subq = subq.filter(tag_alias.tag == tag)
2243 
2244         query_prefix = query_prefix.filter(~models.Instance.uuid.in_(subq))
2245 
2246     if 'not-tags-any' in filters:
2247         tags = filters.pop('not-tags-any')
2248         query_prefix = query_prefix.filter(~models.Instance.tags.any(
2249             models.Tag.tag.in_(tags)))
2250 
2251     if not context.is_admin:
2252         # If we're not admin context, add appropriate filter..
2253         if context.project_id:
2254             filters['project_id'] = context.project_id
2255         else:
2256             filters['user_id'] = context.user_id
2257 
2258     # Filters for exact matches that we can do along with the SQL query...
2259     # For other filters that don't match this, we will do regexp matching
2260     exact_match_filter_names = ['project_id', 'user_id', 'image_ref',
2261                                 'vm_state', 'instance_type_id', 'uuid',
2262                                 'metadata', 'host', 'task_state',
2263                                 'system_metadata']
2264 
2265     # Filter the query
2266     query_prefix = _exact_instance_filter(query_prefix,
2267                                 filters, exact_match_filter_names)
2268     if query_prefix is None:
2269         return []
2270     query_prefix = _regex_instance_filter(query_prefix, filters)
2271 
2272     # paginate query
2273     if marker is not None:
2274         try:
2275             marker = _instance_get_by_uuid(
2276                     context.elevated(read_deleted='yes'), marker)
2277         except exception.InstanceNotFound:
2278             raise exception.MarkerNotFound(marker=marker)
2279     try:
2280         query_prefix = sqlalchemyutils.paginate_query(query_prefix,
2281                                models.Instance, limit,
2282                                sort_keys,
2283                                marker=marker,
2284                                sort_dirs=sort_dirs)
2285     except db_exc.InvalidSortKey:
2286         raise exception.InvalidSortKey()
2287 
2288     return _instances_fill_metadata(context, query_prefix.all(), manual_joins)
2289 
2290 
2291 @require_context
2292 @pick_context_manager_reader_allow_async
2293 def instance_get_by_sort_filters(context, sort_keys, sort_dirs, values):
2294     """Attempt to get a single instance based on a combination of sort
2295     keys, directions and filter values. This is used to try to find a
2296     marker instance when we don't have a marker uuid.
2297 
2298     This returns just a uuid of the instance that matched.
2299     """
2300 
2301     model = models.Instance
2302     query = context.session.query(model.uuid)
2303 
2304     # NOTE(danms): Below is a re-implementation of our
2305     # oslo_db.sqlalchemy.utils.paginate_query() utility. We can't use that
2306     # directly because it does not return the marker and we need it to.
2307     # The below is basically the same algorithm, stripped down to just what
2308     # we need, and augmented with the filter criteria required for us to
2309     # get back the instance that would correspond to our query.
2310 
2311     # This is our position in sort_keys,sort_dirs,values for the loop below
2312     key_index = 0
2313 
2314     # We build a list of criteria to apply to the query, which looks
2315     # approximately like this (assuming all ascending):
2316     #
2317     #  OR(row.key1 > val1,
2318     #     AND(row.key1 == val1, row.key2 > val2),
2319     #     AND(row.key1 == val1, row.key2 == val2, row.key3 >= val3),
2320     #  )
2321     #
2322     # The final key is compared with the "or equal" variant so that
2323     # a complete match instance is still returned.
2324     criteria = []
2325 
2326     for skey, sdir, val in zip(sort_keys, sort_dirs, values):
2327         # Apply ordering to our query for the key, direction we're processing
2328         if sdir == 'desc':
2329             query = query.order_by(desc(getattr(model, skey)))
2330         else:
2331             query = query.order_by(asc(getattr(model, skey)))
2332 
2333         # Build a list of equivalence requirements on keys we've already
2334         # processed through the loop. In other words, if we're adding
2335         # key2 > val2, make sure that key1 == val1
2336         crit_attrs = []
2337         for equal_attr in range(0, key_index):
2338             crit_attrs.append(
2339                 (getattr(model, sort_keys[equal_attr]) == values[equal_attr]))
2340 
2341         model_attr = getattr(model, skey)
2342         if isinstance(model_attr.type, Boolean):
2343             model_attr = cast(model_attr, Integer)
2344             val = int(val)
2345 
2346         if skey == sort_keys[-1]:
2347             # If we are the last key, then we should use or-equal to
2348             # allow a complete match to be returned
2349             if sdir == 'asc':
2350                 crit = (model_attr >= val)
2351             else:
2352                 crit = (model_attr <= val)
2353         else:
2354             # If we're not the last key, then strict greater or less than
2355             # so we order strictly.
2356             if sdir == 'asc':
2357                 crit = (model_attr > val)
2358             else:
2359                 crit = (model_attr < val)
2360 
2361         # AND together all the above
2362         crit_attrs.append(crit)
2363         criteria.append(and_(*crit_attrs))
2364         key_index += 1
2365 
2366     # OR together all the ANDs
2367     query = query.filter(or_(*criteria))
2368 
2369     # We can't raise InstanceNotFound because we don't have a uuid to
2370     # be looking for, so just return nothing if no match.
2371     result = query.limit(1).first()
2372     if result:
2373         # We're querying for a single column, which means we get back a
2374         # tuple of one thing. Strip that out and just return the uuid
2375         # for our caller.
2376         return result[0]
2377     else:
2378         return result
2379 
2380 
2381 def _db_connection_type(db_connection):
2382     """Returns a lowercase symbol for the db type.
2383 
2384     This is useful when we need to change what we are doing per DB
2385     (like handling regexes). In a CellsV2 world it probably needs to
2386     do something better than use the database configuration string.
2387     """
2388 
2389     db_string = db_connection.split(':')[0].split('+')[0]
2390     return db_string.lower()
2391 
2392 
2393 def _safe_regex_mysql(raw_string):
2394     """Make regex safe to mysql.
2395 
2396     Certain items like '|' are interpreted raw by mysql REGEX. If you
2397     search for a single | then you trigger an error because it's
2398     expecting content on either side.
2399 
2400     For consistency sake we escape all '|'. This does mean we wouldn't
2401     support something like foo|bar to match completely different
2402     things, however, one can argue putting such complicated regex into
2403     name search probably means you are doing this wrong.
2404     """
2405     return raw_string.replace('|', '\\|')
2406 
2407 
2408 def _get_regexp_ops(connection):
2409     """Return safety filter and db opts for regex."""
2410     regexp_op_map = {
2411         'postgresql': '~',
2412         'mysql': 'REGEXP',
2413         'sqlite': 'REGEXP'
2414     }
2415     regex_safe_filters = {
2416         'mysql': _safe_regex_mysql
2417     }
2418     db_type = _db_connection_type(connection)
2419 
2420     return (regex_safe_filters.get(db_type, lambda x: x),
2421             regexp_op_map.get(db_type, 'LIKE'))
2422 
2423 
2424 def _regex_instance_filter(query, filters):
2425 
2426     """Applies regular expression filtering to an Instance query.
2427 
2428     Returns the updated query.
2429 
2430     :param query: query to apply filters to
2431     :param filters: dictionary of filters with regex values
2432     """
2433 
2434     model = models.Instance
2435     safe_regex_filter, db_regexp_op = _get_regexp_ops(CONF.database.connection)
2436     for filter_name in filters:
2437         try:
2438             column_attr = getattr(model, filter_name)
2439         except AttributeError:
2440             continue
2441         if 'property' == type(column_attr).__name__:
2442             continue
2443         filter_val = filters[filter_name]
2444         # Sometimes the REGEX filter value is not a string
2445         if not isinstance(filter_val, six.string_types):
2446             filter_val = str(filter_val)
2447         if db_regexp_op == 'LIKE':
2448             query = query.filter(column_attr.op(db_regexp_op)(
2449                                  u'%' + filter_val + u'%'))
2450         else:
2451             filter_val = safe_regex_filter(filter_val)
2452             query = query.filter(column_attr.op(db_regexp_op)(
2453                                  filter_val))
2454     return query
2455 
2456 
2457 def _exact_instance_filter(query, filters, legal_keys):
2458     """Applies exact match filtering to an Instance query.
2459 
2460     Returns the updated query.  Modifies filters argument to remove
2461     filters consumed.
2462 
2463     :param query: query to apply filters to
2464     :param filters: dictionary of filters; values that are lists,
2465                     tuples, sets, or frozensets cause an 'IN' test to
2466                     be performed, while exact matching ('==' operator)
2467                     is used for other values
2468     :param legal_keys: list of keys to apply exact filtering to
2469     """
2470 
2471     filter_dict = {}
2472     model = models.Instance
2473 
2474     # Walk through all the keys
2475     for key in legal_keys:
2476         # Skip ones we're not filtering on
2477         if key not in filters:
2478             continue
2479 
2480         # OK, filtering on this key; what value do we search for?
2481         value = filters.pop(key)
2482 
2483         if key in ('metadata', 'system_metadata'):
2484             column_attr = getattr(model, key)
2485             if isinstance(value, list):
2486                 for item in value:
2487                     for k, v in item.items():
2488                         query = query.filter(column_attr.any(key=k))
2489                         query = query.filter(column_attr.any(value=v))
2490 
2491             else:
2492                 for k, v in value.items():
2493                     query = query.filter(column_attr.any(key=k))
2494                     query = query.filter(column_attr.any(value=v))
2495         elif isinstance(value, (list, tuple, set, frozenset)):
2496             if not value:
2497                 return None  # empty IN-predicate; short circuit
2498             # Looking for values in a list; apply to query directly
2499             column_attr = getattr(model, key)
2500             query = query.filter(column_attr.in_(value))
2501         else:
2502             # OK, simple exact match; save for later
2503             filter_dict[key] = value
2504 
2505     # Apply simple exact matches
2506     if filter_dict:
2507         query = query.filter(*[getattr(models.Instance, k) == v
2508                                for k, v in filter_dict.items()])
2509     return query
2510 
2511 
2512 def process_sort_params(sort_keys, sort_dirs,
2513                         default_keys=['created_at', 'id'],
2514                         default_dir='asc'):
2515     """Process the sort parameters to include default keys.
2516 
2517     Creates a list of sort keys and a list of sort directions. Adds the default
2518     keys to the end of the list if they are not already included.
2519 
2520     When adding the default keys to the sort keys list, the associated
2521     direction is:
2522     1) The first element in the 'sort_dirs' list (if specified), else
2523     2) 'default_dir' value (Note that 'asc' is the default value since this is
2524     the default in sqlalchemy.utils.paginate_query)
2525 
2526     :param sort_keys: List of sort keys to include in the processed list
2527     :param sort_dirs: List of sort directions to include in the processed list
2528     :param default_keys: List of sort keys that need to be included in the
2529                          processed list, they are added at the end of the list
2530                          if not already specified.
2531     :param default_dir: Sort direction associated with each of the default
2532                         keys that are not supplied, used when they are added
2533                         to the processed list
2534     :returns: list of sort keys, list of sort directions
2535     :raise exception.InvalidInput: If more sort directions than sort keys
2536                                    are specified or if an invalid sort
2537                                    direction is specified
2538     """
2539     # Determine direction to use for when adding default keys
2540     if sort_dirs and len(sort_dirs) != 0:
2541         default_dir_value = sort_dirs[0]
2542     else:
2543         default_dir_value = default_dir
2544 
2545     # Create list of keys (do not modify the input list)
2546     if sort_keys:
2547         result_keys = list(sort_keys)
2548     else:
2549         result_keys = []
2550 
2551     # If a list of directions is not provided, use the default sort direction
2552     # for all provided keys
2553     if sort_dirs:
2554         result_dirs = []
2555         # Verify sort direction
2556         for sort_dir in sort_dirs:
2557             if sort_dir not in ('asc', 'desc'):
2558                 msg = _("Unknown sort direction, must be 'desc' or 'asc'")
2559                 raise exception.InvalidInput(reason=msg)
2560             result_dirs.append(sort_dir)
2561     else:
2562         result_dirs = [default_dir_value for _sort_key in result_keys]
2563 
2564     # Ensure that the key and direction length match
2565     while len(result_dirs) < len(result_keys):
2566         result_dirs.append(default_dir_value)
2567     # Unless more direction are specified, which is an error
2568     if len(result_dirs) > len(result_keys):
2569         msg = _("Sort direction size exceeds sort key size")
2570         raise exception.InvalidInput(reason=msg)
2571 
2572     # Ensure defaults are included
2573     for key in default_keys:
2574         if key not in result_keys:
2575             result_keys.append(key)
2576             result_dirs.append(default_dir_value)
2577 
2578     return result_keys, result_dirs
2579 
2580 
2581 @require_context
2582 @pick_context_manager_reader_allow_async
2583 def instance_get_active_by_window_joined(context, begin, end=None,
2584                                          project_id=None, host=None,
2585                                          columns_to_join=None, limit=None,
2586                                          marker=None):
2587     """Return instances and joins that were active during window."""
2588     query = context.session.query(models.Instance)
2589 
2590     if columns_to_join is None:
2591         columns_to_join_new = ['info_cache', 'security_groups']
2592         manual_joins = ['metadata', 'system_metadata']
2593     else:
2594         manual_joins, columns_to_join_new = (
2595             _manual_join_columns(columns_to_join))
2596 
2597     for column in columns_to_join_new:
2598         if 'extra.' in column:
2599             query = query.options(undefer(column))
2600         else:
2601             query = query.options(joinedload(column))
2602 
2603     query = query.filter(or_(models.Instance.terminated_at == null(),
2604                              models.Instance.terminated_at > begin))
2605     if end:
2606         query = query.filter(models.Instance.launched_at < end)
2607     if project_id:
2608         query = query.filter_by(project_id=project_id)
2609     if host:
2610         query = query.filter_by(host=host)
2611 
2612     if marker is not None:
2613         try:
2614             marker = _instance_get_by_uuid(
2615                 context.elevated(read_deleted='yes'), marker)
2616         except exception.InstanceNotFound:
2617             raise exception.MarkerNotFound(marker=marker)
2618 
2619     query = sqlalchemyutils.paginate_query(
2620         query, models.Instance, limit, ['project_id', 'uuid'], marker=marker)
2621 
2622     return _instances_fill_metadata(context, query.all(), manual_joins)
2623 
2624 
2625 def _instance_get_all_query(context, project_only=False, joins=None):
2626     if joins is None:
2627         joins = ['info_cache', 'security_groups']
2628 
2629     query = model_query(context,
2630                         models.Instance,
2631                         project_only=project_only)
2632     for column in joins:
2633         if 'extra.' in column:
2634             query = query.options(undefer(column))
2635         else:
2636             query = query.options(joinedload(column))
2637     return query
2638 
2639 
2640 @pick_context_manager_reader_allow_async
2641 def instance_get_all_by_host(context, host, columns_to_join=None):
2642     query = _instance_get_all_query(context, joins=columns_to_join)
2643     return _instances_fill_metadata(context,
2644                                     query.filter_by(host=host).all(),
2645                                     manual_joins=columns_to_join)
2646 
2647 
2648 def _instance_get_all_uuids_by_host(context, host):
2649     """Return a list of the instance uuids on a given host.
2650 
2651     Returns a list of UUIDs, not Instance model objects.
2652     """
2653     uuids = []
2654     for tuple in model_query(context, models.Instance, (models.Instance.uuid,),
2655                              read_deleted="no").\
2656                 filter_by(host=host).\
2657                 all():
2658         uuids.append(tuple[0])
2659     return uuids
2660 
2661 
2662 @pick_context_manager_reader
2663 def instance_get_all_by_host_and_node(context, host, node,
2664                                       columns_to_join=None):
2665     if columns_to_join is None:
2666         manual_joins = []
2667     else:
2668         candidates = ['system_metadata', 'metadata']
2669         manual_joins = [x for x in columns_to_join if x in candidates]
2670         columns_to_join = list(set(columns_to_join) - set(candidates))
2671     return _instances_fill_metadata(context,
2672             _instance_get_all_query(
2673                 context,
2674                 joins=columns_to_join).filter_by(host=host).
2675                 filter_by(node=node).all(), manual_joins=manual_joins)
2676 
2677 
2678 @pick_context_manager_reader
2679 def instance_get_all_by_host_and_not_type(context, host, type_id=None):
2680     return _instances_fill_metadata(context,
2681         _instance_get_all_query(context).filter_by(host=host).
2682                    filter(models.Instance.instance_type_id != type_id).all())
2683 
2684 
2685 @pick_context_manager_reader
2686 def instance_get_all_by_grantee_security_groups(context, group_ids):
2687     if not group_ids:
2688         return []
2689     return _instances_fill_metadata(context,
2690         _instance_get_all_query(context).
2691             join(models.Instance.security_groups).
2692             filter(models.SecurityGroup.rules.any(
2693                 models.SecurityGroupIngressRule.group_id.in_(group_ids))).
2694             all())
2695 
2696 
2697 @require_context
2698 @pick_context_manager_reader
2699 def instance_floating_address_get_all(context, instance_uuid):
2700     if not uuidutils.is_uuid_like(instance_uuid):
2701         raise exception.InvalidUUID(uuid=instance_uuid)
2702 
2703     floating_ips = model_query(context,
2704                                models.FloatingIp,
2705                                (models.FloatingIp.address,)).\
2706         join(models.FloatingIp.fixed_ip).\
2707         filter_by(instance_uuid=instance_uuid)
2708 
2709     return [floating_ip.address for floating_ip in floating_ips]
2710 
2711 
2712 # NOTE(hanlind): This method can be removed as conductor RPC API moves to v2.0.
2713 @pick_context_manager_reader
2714 def instance_get_all_hung_in_rebooting(context, reboot_window):
2715     reboot_window = (timeutils.utcnow() -
2716                      datetime.timedelta(seconds=reboot_window))
2717 
2718     # NOTE(danms): this is only used in the _poll_rebooting_instances()
2719     # call in compute/manager, so we can avoid the metadata lookups
2720     # explicitly
2721     return _instances_fill_metadata(context,
2722         model_query(context, models.Instance).
2723             filter(models.Instance.updated_at <= reboot_window).
2724             filter_by(task_state=task_states.REBOOTING).all(),
2725         manual_joins=[])
2726 
2727 
2728 def _retry_instance_update():
2729     """Wrap with oslo_db_api.wrap_db_retry, and also retry on
2730     UnknownInstanceUpdateConflict.
2731     """
2732     exception_checker = \
2733         lambda exc: isinstance(exc, (exception.UnknownInstanceUpdateConflict,))
2734     return oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True,
2735                                      exception_checker=exception_checker)
2736 
2737 
2738 @require_context
2739 @_retry_instance_update()
2740 @pick_context_manager_writer
2741 def instance_update(context, instance_uuid, values, expected=None):
2742     return _instance_update(context, instance_uuid, values, expected)
2743 
2744 
2745 @require_context
2746 @_retry_instance_update()
2747 @pick_context_manager_writer
2748 def instance_update_and_get_original(context, instance_uuid, values,
2749                                      columns_to_join=None, expected=None):
2750     """Set the given properties on an instance and update it. Return
2751     a shallow copy of the original instance reference, as well as the
2752     updated one.
2753 
2754     :param context: = request context object
2755     :param instance_uuid: = instance uuid
2756     :param values: = dict containing column values
2757 
2758     If "expected_task_state" exists in values, the update can only happen
2759     when the task state before update matches expected_task_state. Otherwise
2760     a UnexpectedTaskStateError is thrown.
2761 
2762     :returns: a tuple of the form (old_instance_ref, new_instance_ref)
2763 
2764     Raises NotFound if instance does not exist.
2765     """
2766     instance_ref = _instance_get_by_uuid(context, instance_uuid,
2767                                          columns_to_join=columns_to_join)
2768     return (copy.copy(instance_ref), _instance_update(
2769         context, instance_uuid, values, expected, original=instance_ref))
2770 
2771 
2772 # NOTE(danms): This updates the instance's metadata list in-place and in
2773 # the database to avoid stale data and refresh issues. It assumes the
2774 # delete=True behavior of instance_metadata_update(...)
2775 def _instance_metadata_update_in_place(context, instance, metadata_type, model,
2776                                        metadata):
2777     metadata = dict(metadata)
2778     to_delete = []
2779     for keyvalue in instance[metadata_type]:
2780         key = keyvalue['key']
2781         if key in metadata:
2782             keyvalue['value'] = metadata.pop(key)
2783         elif key not in metadata:
2784             to_delete.append(keyvalue)
2785 
2786     # NOTE: we have to hard_delete here otherwise we will get more than one
2787     # system_metadata record when we read deleted for an instance;
2788     # regular metadata doesn't have the same problem because we don't
2789     # allow reading deleted regular metadata anywhere.
2790     if metadata_type == 'system_metadata':
2791         for condemned in to_delete:
2792             context.session.delete(condemned)
2793             instance[metadata_type].remove(condemned)
2794     else:
2795         for condemned in to_delete:
2796             condemned.soft_delete(context.session)
2797 
2798     for key, value in metadata.items():
2799         newitem = model()
2800         newitem.update({'key': key, 'value': value,
2801                         'instance_uuid': instance['uuid']})
2802         context.session.add(newitem)
2803         instance[metadata_type].append(newitem)
2804 
2805 
2806 def _instance_update(context, instance_uuid, values, expected, original=None):
2807     if not uuidutils.is_uuid_like(instance_uuid):
2808         raise exception.InvalidUUID(instance_uuid)
2809 
2810     if expected is None:
2811         expected = {}
2812     else:
2813         # Coerce all single values to singleton lists
2814         expected = {k: [None] if v is None else sqlalchemyutils.to_list(v)
2815                        for (k, v) in expected.items()}
2816 
2817     # Extract 'expected_' values from values dict, as these aren't actually
2818     # updates
2819     for field in ('task_state', 'vm_state'):
2820         expected_field = 'expected_%s' % field
2821         if expected_field in values:
2822             value = values.pop(expected_field, None)
2823             # Coerce all single values to singleton lists
2824             if value is None:
2825                 expected[field] = [None]
2826             else:
2827                 expected[field] = sqlalchemyutils.to_list(value)
2828 
2829     # Values which need to be updated separately
2830     metadata = values.pop('metadata', None)
2831     system_metadata = values.pop('system_metadata', None)
2832 
2833     _handle_objects_related_type_conversions(values)
2834 
2835     # Hostname is potentially unique, but this is enforced in code rather
2836     # than the DB. The query below races, but the number of users of
2837     # osapi_compute_unique_server_name_scope is small, and a robust fix
2838     # will be complex. This is intentionally left as is for the moment.
2839     if 'hostname' in values:
2840         _validate_unique_server_name(context, values['hostname'])
2841 
2842     compare = models.Instance(uuid=instance_uuid, **expected)
2843     try:
2844         instance_ref = model_query(context, models.Instance,
2845                                    project_only=True).\
2846                        update_on_match(compare, 'uuid', values)
2847     except update_match.NoRowsMatched:
2848         # Update failed. Try to find why and raise a specific error.
2849 
2850         # We should get here only because our expected values were not current
2851         # when update_on_match executed. Having failed, we now have a hint that
2852         # the values are out of date and should check them.
2853 
2854         # This code is made more complex because we are using repeatable reads.
2855         # If we have previously read the original instance in the current
2856         # transaction, reading it again will return the same data, even though
2857         # the above update failed because it has changed: it is not possible to
2858         # determine what has changed in this transaction. In this case we raise
2859         # UnknownInstanceUpdateConflict, which will cause the operation to be
2860         # retried in a new transaction.
2861 
2862         # Because of the above, if we have previously read the instance in the
2863         # current transaction it will have been passed as 'original', and there
2864         # is no point refreshing it. If we have not previously read the
2865         # instance, we can fetch it here and we will get fresh data.
2866         if original is None:
2867             original = _instance_get_by_uuid(context, instance_uuid)
2868 
2869         conflicts_expected = {}
2870         conflicts_actual = {}
2871         for (field, expected_values) in expected.items():
2872             actual = original[field]
2873             if actual not in expected_values:
2874                 conflicts_expected[field] = expected_values
2875                 conflicts_actual[field] = actual
2876 
2877         # Exception properties
2878         exc_props = {
2879             'instance_uuid': instance_uuid,
2880             'expected': conflicts_expected,
2881             'actual': conflicts_actual
2882         }
2883 
2884         # There was a conflict, but something (probably the MySQL read view,
2885         # but possibly an exceptionally unlikely second race) is preventing us
2886         # from seeing what it is. When we go round again we'll get a fresh
2887         # transaction and a fresh read view.
2888         if len(conflicts_actual) == 0:
2889             raise exception.UnknownInstanceUpdateConflict(**exc_props)
2890 
2891         # Task state gets special handling for convenience. We raise the
2892         # specific error UnexpectedDeletingTaskStateError or
2893         # UnexpectedTaskStateError as appropriate
2894         if 'task_state' in conflicts_actual:
2895             conflict_task_state = conflicts_actual['task_state']
2896             if conflict_task_state == task_states.DELETING:
2897                 exc = exception.UnexpectedDeletingTaskStateError
2898             else:
2899                 exc = exception.UnexpectedTaskStateError
2900 
2901         # Everything else is an InstanceUpdateConflict
2902         else:
2903             exc = exception.InstanceUpdateConflict
2904 
2905         raise exc(**exc_props)
2906 
2907     if metadata is not None:
2908         _instance_metadata_update_in_place(context, instance_ref,
2909                                            'metadata',
2910                                            models.InstanceMetadata,
2911                                            metadata)
2912 
2913     if system_metadata is not None:
2914         _instance_metadata_update_in_place(context, instance_ref,
2915                                            'system_metadata',
2916                                            models.InstanceSystemMetadata,
2917                                            system_metadata)
2918 
2919     return instance_ref
2920 
2921 
2922 @pick_context_manager_writer
2923 def instance_add_security_group(context, instance_uuid, security_group_id):
2924     """Associate the given security group with the given instance."""
2925     sec_group_ref = models.SecurityGroupInstanceAssociation()
2926     sec_group_ref.update({'instance_uuid': instance_uuid,
2927                           'security_group_id': security_group_id})
2928     sec_group_ref.save(context.session)
2929 
2930 
2931 @require_context
2932 @pick_context_manager_writer
2933 def instance_remove_security_group(context, instance_uuid, security_group_id):
2934     """Disassociate the given security group from the given instance."""
2935     model_query(context, models.SecurityGroupInstanceAssociation).\
2936                 filter_by(instance_uuid=instance_uuid).\
2937                 filter_by(security_group_id=security_group_id).\
2938                 soft_delete()
2939 
2940 
2941 ###################
2942 
2943 
2944 @require_context
2945 @pick_context_manager_reader
2946 def instance_info_cache_get(context, instance_uuid):
2947     """Gets an instance info cache from the table.
2948 
2949     :param instance_uuid: = uuid of the info cache's instance
2950     """
2951     return model_query(context, models.InstanceInfoCache).\
2952                          filter_by(instance_uuid=instance_uuid).\
2953                          first()
2954 
2955 
2956 @require_context
2957 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
2958 @pick_context_manager_writer
2959 def instance_info_cache_update(context, instance_uuid, values):
2960     """Update an instance info cache record in the table.
2961 
2962     :param instance_uuid: = uuid of info cache's instance
2963     :param values: = dict containing column values to update
2964     """
2965     convert_objects_related_datetimes(values)
2966 
2967     info_cache = model_query(context, models.InstanceInfoCache).\
2968                      filter_by(instance_uuid=instance_uuid).\
2969                      first()
2970     needs_create = False
2971     if info_cache and info_cache['deleted']:
2972         raise exception.InstanceInfoCacheNotFound(
2973                 instance_uuid=instance_uuid)
2974     elif not info_cache:
2975         # NOTE(tr3buchet): just in case someone blows away an instance's
2976         #                  cache entry, re-create it.
2977         values['instance_uuid'] = instance_uuid
2978         info_cache = models.InstanceInfoCache(**values)
2979         needs_create = True
2980 
2981     try:
2982         with get_context_manager(context).writer.savepoint.using(context):
2983             if needs_create:
2984                 info_cache.save(context.session)
2985             else:
2986                 info_cache.update(values)
2987     except db_exc.DBDuplicateEntry:
2988         # NOTE(sirp): Possible race if two greenthreads attempt to
2989         # recreate the instance cache entry at the same time. First one
2990         # wins.
2991         pass
2992 
2993     return info_cache
2994 
2995 
2996 @require_context
2997 @pick_context_manager_writer
2998 def instance_info_cache_delete(context, instance_uuid):
2999     """Deletes an existing instance_info_cache record
3000 
3001     :param instance_uuid: = uuid of the instance tied to the cache record
3002     """
3003     model_query(context, models.InstanceInfoCache).\
3004                          filter_by(instance_uuid=instance_uuid).\
3005                          soft_delete()
3006 
3007 
3008 ###################
3009 
3010 
3011 def _instance_extra_create(context, values):
3012     inst_extra_ref = models.InstanceExtra()
3013     inst_extra_ref.update(values)
3014     inst_extra_ref.save(context.session)
3015     return inst_extra_ref
3016 
3017 
3018 @pick_context_manager_writer
3019 def instance_extra_update_by_uuid(context, instance_uuid, values):
3020     rows_updated = model_query(context, models.InstanceExtra).\
3021         filter_by(instance_uuid=instance_uuid).\
3022         update(values)
3023     if not rows_updated:
3024         LOG.debug("Created instance_extra for %s", instance_uuid)
3025         create_values = copy.copy(values)
3026         create_values["instance_uuid"] = instance_uuid
3027         _instance_extra_create(context, create_values)
3028         rows_updated = 1
3029     return rows_updated
3030 
3031 
3032 @pick_context_manager_reader
3033 def instance_extra_get_by_instance_uuid(context, instance_uuid,
3034                                         columns=None):
3035     query = model_query(context, models.InstanceExtra).\
3036         filter_by(instance_uuid=instance_uuid)
3037     if columns is None:
3038         columns = ['numa_topology', 'pci_requests', 'flavor', 'vcpu_model',
3039                    'migration_context']
3040     for column in columns:
3041         query = query.options(undefer(column))
3042     instance_extra = query.first()
3043     return instance_extra
3044 
3045 
3046 ###################
3047 
3048 
3049 @require_context
3050 @pick_context_manager_writer
3051 def key_pair_create(context, values):
3052     try:
3053         key_pair_ref = models.KeyPair()
3054         key_pair_ref.update(values)
3055         key_pair_ref.save(context.session)
3056         return key_pair_ref
3057     except db_exc.DBDuplicateEntry:
3058         raise exception.KeyPairExists(key_name=values['name'])
3059 
3060 
3061 @require_context
3062 @pick_context_manager_writer
3063 def key_pair_destroy(context, user_id, name):
3064     result = model_query(context, models.KeyPair).\
3065                          filter_by(user_id=user_id).\
3066                          filter_by(name=name).\
3067                          soft_delete()
3068     if not result:
3069         raise exception.KeypairNotFound(user_id=user_id, name=name)
3070 
3071 
3072 @require_context
3073 @pick_context_manager_reader
3074 def key_pair_get(context, user_id, name):
3075     result = model_query(context, models.KeyPair).\
3076                      filter_by(user_id=user_id).\
3077                      filter_by(name=name).\
3078                      first()
3079 
3080     if not result:
3081         raise exception.KeypairNotFound(user_id=user_id, name=name)
3082 
3083     return result
3084 
3085 
3086 @require_context
3087 @pick_context_manager_reader
3088 def key_pair_get_all_by_user(context, user_id, limit=None, marker=None):
3089     marker_row = None
3090     if marker is not None:
3091         marker_row = model_query(context, models.KeyPair, read_deleted="no").\
3092             filter_by(name=marker).filter_by(user_id=user_id).first()
3093         if not marker_row:
3094             raise exception.MarkerNotFound(marker=marker)
3095 
3096     query = model_query(context, models.KeyPair, read_deleted="no").\
3097         filter_by(user_id=user_id)
3098 
3099     query = sqlalchemyutils.paginate_query(
3100         query, models.KeyPair, limit, ['name'], marker=marker_row)
3101 
3102     return query.all()
3103 
3104 
3105 @require_context
3106 @pick_context_manager_reader
3107 def key_pair_count_by_user(context, user_id):
3108     return model_query(context, models.KeyPair, read_deleted="no").\
3109                    filter_by(user_id=user_id).\
3110                    count()
3111 
3112 
3113 ###################
3114 
3115 @pick_context_manager_writer
3116 def network_associate(context, project_id, network_id=None, force=False):
3117     """Associate a project with a network.
3118 
3119     called by project_get_networks under certain conditions
3120     and network manager add_network_to_project()
3121 
3122     only associate if the project doesn't already have a network
3123     or if force is True
3124 
3125     force solves race condition where a fresh project has multiple instance
3126     builds simultaneously picked up by multiple network hosts which attempt
3127     to associate the project with multiple networks
3128     force should only be used as a direct consequence of user request
3129     all automated requests should not use force
3130     """
3131     def network_query(project_filter, id=None):
3132         filter_kwargs = {'project_id': project_filter}
3133         if id is not None:
3134             filter_kwargs['id'] = id
3135         return model_query(context, models.Network, read_deleted="no").\
3136                        filter_by(**filter_kwargs).\
3137                        with_lockmode('update').\
3138                        first()
3139 
3140     if not force:
3141         # find out if project has a network
3142         network_ref = network_query(project_id)
3143 
3144     if force or not network_ref:
3145         # in force mode or project doesn't have a network so associate
3146         # with a new network
3147 
3148         # get new network
3149         network_ref = network_query(None, network_id)
3150         if not network_ref:
3151             raise exception.NoMoreNetworks()
3152 
3153         # associate with network
3154         # NOTE(vish): if with_lockmode isn't supported, as in sqlite,
3155         #             then this has concurrency issues
3156         network_ref['project_id'] = project_id
3157         context.session.add(network_ref)
3158     return network_ref
3159 
3160 
3161 def _network_ips_query(context, network_id):
3162     return model_query(context, models.FixedIp, read_deleted="no").\
3163                    filter_by(network_id=network_id)
3164 
3165 
3166 @pick_context_manager_reader
3167 def network_count_reserved_ips(context, network_id):
3168     return _network_ips_query(context, network_id).\
3169                     filter_by(reserved=True).\
3170                     count()
3171 
3172 
3173 @pick_context_manager_writer
3174 def network_create_safe(context, values):
3175     network_ref = models.Network()
3176     network_ref['uuid'] = uuidutils.generate_uuid()
3177     network_ref.update(values)
3178 
3179     try:
3180         network_ref.save(context.session)
3181         return network_ref
3182     except db_exc.DBDuplicateEntry:
3183         raise exception.DuplicateVlan(vlan=values['vlan'])
3184 
3185 
3186 @pick_context_manager_writer
3187 def network_delete_safe(context, network_id):
3188     result = model_query(context, models.FixedIp, read_deleted="no").\
3189                      filter_by(network_id=network_id).\
3190                      filter_by(allocated=True).\
3191                      count()
3192     if result != 0:
3193         raise exception.NetworkInUse(network_id=network_id)
3194     network_ref = _network_get(context, network_id=network_id)
3195 
3196     model_query(context, models.FixedIp, read_deleted="no").\
3197             filter_by(network_id=network_id).\
3198             soft_delete()
3199 
3200     context.session.delete(network_ref)
3201 
3202 
3203 @pick_context_manager_writer
3204 def network_disassociate(context, network_id, disassociate_host,
3205                          disassociate_project):
3206     net_update = {}
3207     if disassociate_project:
3208         net_update['project_id'] = None
3209     if disassociate_host:
3210         net_update['host'] = None
3211     network_update(context, network_id, net_update)
3212 
3213 
3214 def _network_get(context, network_id, project_only='allow_none'):
3215     result = model_query(context, models.Network, project_only=project_only).\
3216                     filter_by(id=network_id).\
3217                     first()
3218 
3219     if not result:
3220         raise exception.NetworkNotFound(network_id=network_id)
3221 
3222     return result
3223 
3224 
3225 @require_context
3226 @pick_context_manager_reader
3227 def network_get(context, network_id, project_only='allow_none'):
3228     return _network_get(context, network_id, project_only=project_only)
3229 
3230 
3231 @require_context
3232 @pick_context_manager_reader
3233 def network_get_all(context, project_only):
3234     result = model_query(context, models.Network, read_deleted="no",
3235                          project_only=project_only).all()
3236 
3237     if not result:
3238         raise exception.NoNetworksFound()
3239 
3240     return result
3241 
3242 
3243 @require_context
3244 @pick_context_manager_reader
3245 def network_get_all_by_uuids(context, network_uuids, project_only):
3246     result = model_query(context, models.Network, read_deleted="no",
3247                          project_only=project_only).\
3248                 filter(models.Network.uuid.in_(network_uuids)).\
3249                 all()
3250 
3251     if not result:
3252         raise exception.NoNetworksFound()
3253 
3254     # check if the result contains all the networks
3255     # we are looking for
3256     for network_uuid in network_uuids:
3257         for network in result:
3258             if network['uuid'] == network_uuid:
3259                 break
3260         else:
3261             if project_only:
3262                 raise exception.NetworkNotFoundForProject(
3263                       network_uuid=network_uuid, project_id=context.project_id)
3264             raise exception.NetworkNotFound(network_id=network_uuid)
3265 
3266     return result
3267 
3268 
3269 def _get_associated_fixed_ips_query(context, network_id, host=None):
3270     # NOTE(vish): The ugly joins here are to solve a performance issue and
3271     #             should be removed once we can add and remove leases
3272     #             without regenerating the whole list
3273     vif_and = and_(models.VirtualInterface.id ==
3274                    models.FixedIp.virtual_interface_id,
3275                    models.VirtualInterface.deleted == 0)
3276     inst_and = and_(models.Instance.uuid == models.FixedIp.instance_uuid,
3277                     models.Instance.deleted == 0)
3278     # NOTE(vish): This subquery left joins the minimum interface id for each
3279     #             instance. If the join succeeds (i.e. the 11th column is not
3280     #             null), then the fixed ip is on the first interface.
3281     subq = context.session.query(
3282         func.min(models.VirtualInterface.id).label("id"),
3283         models.VirtualInterface.instance_uuid).\
3284         group_by(models.VirtualInterface.instance_uuid).subquery()
3285     subq_and = and_(subq.c.id == models.FixedIp.virtual_interface_id,
3286             subq.c.instance_uuid == models.VirtualInterface.instance_uuid)
3287     query = context.session.query(
3288         models.FixedIp.address,
3289         models.FixedIp.instance_uuid,
3290         models.FixedIp.network_id,
3291         models.FixedIp.virtual_interface_id,
3292         models.VirtualInterface.address,
3293         models.Instance.hostname,
3294         models.Instance.updated_at,
3295         models.Instance.created_at,
3296         models.FixedIp.allocated,
3297         models.FixedIp.leased,
3298         subq.c.id).\
3299         filter(models.FixedIp.deleted == 0).\
3300         filter(models.FixedIp.network_id == network_id).\
3301         join((models.VirtualInterface, vif_and)).\
3302         join((models.Instance, inst_and)).\
3303         outerjoin((subq, subq_and)).\
3304         filter(models.FixedIp.instance_uuid != null()).\
3305         filter(models.FixedIp.virtual_interface_id != null())
3306     if host:
3307         query = query.filter(models.Instance.host == host)
3308     return query
3309 
3310 
3311 @pick_context_manager_reader
3312 def network_get_associated_fixed_ips(context, network_id, host=None):
3313     # FIXME(sirp): since this returns fixed_ips, this would be better named
3314     # fixed_ip_get_all_by_network.
3315     query = _get_associated_fixed_ips_query(context, network_id, host)
3316     result = query.all()
3317     data = []
3318     for datum in result:
3319         cleaned = {}
3320         cleaned['address'] = datum[0]
3321         cleaned['instance_uuid'] = datum[1]
3322         cleaned['network_id'] = datum[2]
3323         cleaned['vif_id'] = datum[3]
3324         cleaned['vif_address'] = datum[4]
3325         cleaned['instance_hostname'] = datum[5]
3326         cleaned['instance_updated'] = datum[6]
3327         cleaned['instance_created'] = datum[7]
3328         cleaned['allocated'] = datum[8]
3329         cleaned['leased'] = datum[9]
3330         # NOTE(vish): default_route is True if this fixed ip is on the first
3331         #             interface its instance.
3332         cleaned['default_route'] = datum[10] is not None
3333         data.append(cleaned)
3334     return data
3335 
3336 
3337 @pick_context_manager_reader
3338 def network_in_use_on_host(context, network_id, host):
3339     query = _get_associated_fixed_ips_query(context, network_id, host)
3340     return query.count() > 0
3341 
3342 
3343 def _network_get_query(context):
3344     return model_query(context, models.Network, read_deleted="no")
3345 
3346 
3347 @pick_context_manager_reader
3348 def network_get_by_uuid(context, uuid):
3349     result = _network_get_query(context).filter_by(uuid=uuid).first()
3350 
3351     if not result:
3352         raise exception.NetworkNotFoundForUUID(uuid=uuid)
3353 
3354     return result
3355 
3356 
3357 @pick_context_manager_reader
3358 def network_get_by_cidr(context, cidr):
3359     result = _network_get_query(context).\
3360                 filter(or_(models.Network.cidr == cidr,
3361                            models.Network.cidr_v6 == cidr)).\
3362                 first()
3363 
3364     if not result:
3365         raise exception.NetworkNotFoundForCidr(cidr=cidr)
3366 
3367     return result
3368 
3369 
3370 @pick_context_manager_reader
3371 def network_get_all_by_host(context, host):
3372     fixed_host_filter = or_(models.FixedIp.host == host,
3373             and_(models.FixedIp.instance_uuid != null(),
3374                  models.Instance.host == host))
3375     fixed_ip_query = model_query(context, models.FixedIp,
3376                                  (models.FixedIp.network_id,)).\
3377                      outerjoin((models.Instance,
3378                                 models.Instance.uuid ==
3379                                 models.FixedIp.instance_uuid)).\
3380                      filter(fixed_host_filter)
3381     # NOTE(vish): return networks that have host set
3382     #             or that have a fixed ip with host set
3383     #             or that have an instance with host set
3384     host_filter = or_(models.Network.host == host,
3385                       models.Network.id.in_(fixed_ip_query.subquery()))
3386     return _network_get_query(context).filter(host_filter).all()
3387 
3388 
3389 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
3390 @pick_context_manager_writer
3391 def network_set_host(context, network_id, host_id):
3392     network_ref = _network_get_query(context).\
3393         filter_by(id=network_id).\
3394         first()
3395 
3396     if not network_ref:
3397         raise exception.NetworkNotFound(network_id=network_id)
3398 
3399     if network_ref.host:
3400         return None
3401 
3402     rows_updated = _network_get_query(context).\
3403         filter_by(id=network_id).\
3404         filter_by(host=None).\
3405         update({'host': host_id})
3406 
3407     if not rows_updated:
3408         LOG.debug('The row was updated in a concurrent transaction, '
3409                   'we will fetch another row')
3410         raise db_exc.RetryRequest(
3411             exception.NetworkSetHostFailed(network_id=network_id))
3412 
3413 
3414 @require_context
3415 @pick_context_manager_writer
3416 def network_update(context, network_id, values):
3417     network_ref = _network_get(context, network_id)
3418     network_ref.update(values)
3419     try:
3420         network_ref.save(context.session)
3421     except db_exc.DBDuplicateEntry:
3422         raise exception.DuplicateVlan(vlan=values['vlan'])
3423     return network_ref
3424 
3425 
3426 ###################
3427 
3428 
3429 @require_context
3430 @pick_context_manager_reader
3431 def quota_get(context, project_id, resource, user_id=None):
3432     model = models.ProjectUserQuota if user_id else models.Quota
3433     query = model_query(context, model).\
3434                     filter_by(project_id=project_id).\
3435                     filter_by(resource=resource)
3436     if user_id:
3437         query = query.filter_by(user_id=user_id)
3438 
3439     result = query.first()
3440     if not result:
3441         if user_id:
3442             raise exception.ProjectUserQuotaNotFound(project_id=project_id,
3443                                                      user_id=user_id)
3444         else:
3445             raise exception.ProjectQuotaNotFound(project_id=project_id)
3446 
3447     return result
3448 
3449 
3450 @require_context
3451 @pick_context_manager_reader
3452 def quota_get_all_by_project_and_user(context, project_id, user_id):
3453     user_quotas = model_query(context, models.ProjectUserQuota,
3454                               (models.ProjectUserQuota.resource,
3455                                models.ProjectUserQuota.hard_limit)).\
3456                    filter_by(project_id=project_id).\
3457                    filter_by(user_id=user_id).\
3458                    all()
3459 
3460     result = {'project_id': project_id, 'user_id': user_id}
3461     for user_quota in user_quotas:
3462         result[user_quota.resource] = user_quota.hard_limit
3463 
3464     return result
3465 
3466 
3467 @require_context
3468 @pick_context_manager_reader
3469 def quota_get_all_by_project(context, project_id):
3470     rows = model_query(context, models.Quota, read_deleted="no").\
3471                    filter_by(project_id=project_id).\
3472                    all()
3473 
3474     result = {'project_id': project_id}
3475     for row in rows:
3476         result[row.resource] = row.hard_limit
3477 
3478     return result
3479 
3480 
3481 @require_context
3482 @pick_context_manager_reader
3483 def quota_get_all(context, project_id):
3484     result = model_query(context, models.ProjectUserQuota).\
3485                    filter_by(project_id=project_id).\
3486                    all()
3487 
3488     return result
3489 
3490 
3491 def quota_get_per_project_resources():
3492     return PER_PROJECT_QUOTAS
3493 
3494 
3495 @pick_context_manager_writer
3496 def quota_create(context, project_id, resource, limit, user_id=None):
3497     per_user = user_id and resource not in PER_PROJECT_QUOTAS
3498     quota_ref = models.ProjectUserQuota() if per_user else models.Quota()
3499     if per_user:
3500         quota_ref.user_id = user_id
3501     quota_ref.project_id = project_id
3502     quota_ref.resource = resource
3503     quota_ref.hard_limit = limit
3504     try:
3505         quota_ref.save(context.session)
3506     except db_exc.DBDuplicateEntry:
3507         raise exception.QuotaExists(project_id=project_id, resource=resource)
3508     return quota_ref
3509 
3510 
3511 @pick_context_manager_writer
3512 def quota_update(context, project_id, resource, limit, user_id=None):
3513     per_user = user_id and resource not in PER_PROJECT_QUOTAS
3514     model = models.ProjectUserQuota if per_user else models.Quota
3515     query = model_query(context, model).\
3516                 filter_by(project_id=project_id).\
3517                 filter_by(resource=resource)
3518     if per_user:
3519         query = query.filter_by(user_id=user_id)
3520 
3521     result = query.update({'hard_limit': limit})
3522     if not result:
3523         if per_user:
3524             raise exception.ProjectUserQuotaNotFound(project_id=project_id,
3525                                                      user_id=user_id)
3526         else:
3527             raise exception.ProjectQuotaNotFound(project_id=project_id)
3528 
3529 
3530 ###################
3531 
3532 
3533 @require_context
3534 @pick_context_manager_reader
3535 def quota_class_get(context, class_name, resource):
3536     result = model_query(context, models.QuotaClass, read_deleted="no").\
3537                      filter_by(class_name=class_name).\
3538                      filter_by(resource=resource).\
3539                      first()
3540 
3541     if not result:
3542         raise exception.QuotaClassNotFound(class_name=class_name)
3543 
3544     return result
3545 
3546 
3547 @pick_context_manager_reader
3548 def quota_class_get_default(context):
3549     rows = model_query(context, models.QuotaClass, read_deleted="no").\
3550                    filter_by(class_name=_DEFAULT_QUOTA_NAME).\
3551                    all()
3552 
3553     result = {'class_name': _DEFAULT_QUOTA_NAME}
3554     for row in rows:
3555         result[row.resource] = row.hard_limit
3556 
3557     return result
3558 
3559 
3560 @require_context
3561 @pick_context_manager_reader
3562 def quota_class_get_all_by_name(context, class_name):
3563     rows = model_query(context, models.QuotaClass, read_deleted="no").\
3564                    filter_by(class_name=class_name).\
3565                    all()
3566 
3567     result = {'class_name': class_name}
3568     for row in rows:
3569         result[row.resource] = row.hard_limit
3570 
3571     return result
3572 
3573 
3574 @pick_context_manager_writer
3575 def quota_class_create(context, class_name, resource, limit):
3576     quota_class_ref = models.QuotaClass()
3577     quota_class_ref.class_name = class_name
3578     quota_class_ref.resource = resource
3579     quota_class_ref.hard_limit = limit
3580     quota_class_ref.save(context.session)
3581     return quota_class_ref
3582 
3583 
3584 @pick_context_manager_writer
3585 def quota_class_update(context, class_name, resource, limit):
3586     result = model_query(context, models.QuotaClass, read_deleted="no").\
3587                      filter_by(class_name=class_name).\
3588                      filter_by(resource=resource).\
3589                      update({'hard_limit': limit})
3590 
3591     if not result:
3592         raise exception.QuotaClassNotFound(class_name=class_name)
3593 
3594 
3595 ###################
3596 
3597 
3598 @require_context
3599 @pick_context_manager_reader
3600 def quota_usage_get(context, project_id, resource, user_id=None):
3601     query = model_query(context, models.QuotaUsage, read_deleted="no").\
3602                      filter_by(project_id=project_id).\
3603                      filter_by(resource=resource)
3604     if user_id:
3605         if resource not in PER_PROJECT_QUOTAS:
3606             result = query.filter_by(user_id=user_id).first()
3607         else:
3608             result = query.filter_by(user_id=None).first()
3609     else:
3610         result = query.first()
3611 
3612     if not result:
3613         raise exception.QuotaUsageNotFound(project_id=project_id)
3614 
3615     return result
3616 
3617 
3618 def _quota_usage_get_all(context, project_id, user_id=None):
3619     query = model_query(context, models.QuotaUsage, read_deleted="no").\
3620                    filter_by(project_id=project_id)
3621     result = {'project_id': project_id}
3622     if user_id:
3623         query = query.filter(or_(models.QuotaUsage.user_id == user_id,
3624                                  models.QuotaUsage.user_id == null()))
3625         result['user_id'] = user_id
3626 
3627     rows = query.all()
3628     for row in rows:
3629         if row.resource in result:
3630             result[row.resource]['in_use'] += row.in_use
3631             result[row.resource]['reserved'] += row.reserved
3632         else:
3633             result[row.resource] = dict(in_use=row.in_use,
3634                                         reserved=row.reserved)
3635 
3636     return result
3637 
3638 
3639 @require_context
3640 @pick_context_manager_reader
3641 def quota_usage_get_all_by_project_and_user(context, project_id, user_id):
3642     return _quota_usage_get_all(context, project_id, user_id=user_id)
3643 
3644 
3645 @require_context
3646 @pick_context_manager_reader
3647 def quota_usage_get_all_by_project(context, project_id):
3648     return _quota_usage_get_all(context, project_id)
3649 
3650 
3651 def _quota_usage_create(project_id, user_id, resource, in_use,
3652                         reserved, until_refresh, session):
3653     quota_usage_ref = models.QuotaUsage()
3654     quota_usage_ref.project_id = project_id
3655     quota_usage_ref.user_id = user_id
3656     quota_usage_ref.resource = resource
3657     quota_usage_ref.in_use = in_use
3658     quota_usage_ref.reserved = reserved
3659     quota_usage_ref.until_refresh = until_refresh
3660     # updated_at is needed for judgement of max_age
3661     quota_usage_ref.updated_at = timeutils.utcnow()
3662 
3663     quota_usage_ref.save(session)
3664 
3665     return quota_usage_ref
3666 
3667 
3668 @pick_context_manager_writer
3669 def quota_usage_update(context, project_id, user_id, resource, **kwargs):
3670     updates = {}
3671 
3672     for key in ['in_use', 'reserved', 'until_refresh']:
3673         if key in kwargs:
3674             updates[key] = kwargs[key]
3675 
3676     result = model_query(context, models.QuotaUsage, read_deleted="no").\
3677                      filter_by(project_id=project_id).\
3678                      filter_by(resource=resource).\
3679                      filter(or_(models.QuotaUsage.user_id == user_id,
3680                                 models.QuotaUsage.user_id == null())).\
3681                      update(updates)
3682 
3683     if not result:
3684         raise exception.QuotaUsageNotFound(project_id=project_id)
3685 
3686 
3687 ###################
3688 
3689 
3690 def _reservation_create(uuid, usage, project_id, user_id, resource,
3691                         delta, expire, session):
3692     reservation_ref = models.Reservation()
3693     reservation_ref.uuid = uuid
3694     reservation_ref.usage_id = usage['id']
3695     reservation_ref.project_id = project_id
3696     reservation_ref.user_id = user_id
3697     reservation_ref.resource = resource
3698     reservation_ref.delta = delta
3699     reservation_ref.expire = expire
3700     reservation_ref.save(session)
3701     return reservation_ref
3702 
3703 
3704 ###################
3705 
3706 
3707 # NOTE(johannes): The quota code uses SQL locking to ensure races don't
3708 # cause under or over counting of resources. To avoid deadlocks, this
3709 # code always acquires the lock on quota_usages before acquiring the lock
3710 # on reservations.
3711 
3712 def _get_project_user_quota_usages(context, project_id, user_id):
3713     rows = model_query(context, models.QuotaUsage,
3714                        read_deleted="no").\
3715         filter_by(project_id=project_id).\
3716         order_by(models.QuotaUsage.id.asc()).\
3717         with_lockmode('update').\
3718         all()
3719     proj_result = dict()
3720     user_result = dict()
3721     # Get the total count of in_use,reserved
3722     for row in rows:
3723         proj_result.setdefault(row.resource,
3724                                dict(in_use=0, reserved=0, total=0))
3725         proj_result[row.resource]['in_use'] += row.in_use
3726         proj_result[row.resource]['reserved'] += row.reserved
3727         proj_result[row.resource]['total'] += (row.in_use + row.reserved)
3728         if row.user_id is None or row.user_id == user_id:
3729             user_result[row.resource] = row
3730     return proj_result, user_result
3731 
3732 
3733 def _create_quota_usage_if_missing(user_usages, resource, until_refresh,
3734                                    project_id, user_id, session):
3735     """Creates a QuotaUsage record and adds to user_usages if not present.
3736 
3737     :param user_usages:   dict of resource keys to QuotaUsage records. This is
3738                           updated if resource is not in user_usages yet or
3739                           until_refresh is not None.
3740     :param resource:      The resource being checked for quota usage.
3741     :param until_refresh: Count of reservations until usage is refreshed,
3742                           int or None
3743     :param project_id:    The project being checked for quota usage.
3744     :param user_id:       The user being checked for quota usage.
3745     :param session:       DB session holding a transaction lock.
3746     :return:              True if a new QuotaUsage record was created and added
3747                           to user_usages, False otherwise.
3748     """
3749     new_usage = None
3750     if resource not in user_usages:
3751         user_id_to_use = user_id
3752         if resource in PER_PROJECT_QUOTAS:
3753             user_id_to_use = None
3754         new_usage = _quota_usage_create(project_id, user_id_to_use, resource,
3755                                         0, 0, until_refresh or None, session)
3756         user_usages[resource] = new_usage
3757     return new_usage is not None
3758 
3759 
3760 def _is_quota_refresh_needed(quota_usage, max_age):
3761     """Determines if a quota usage refresh is needed.
3762 
3763     :param quota_usage:   A QuotaUsage object for a given resource.
3764     :param max_age:       Number of seconds between subsequent usage refreshes.
3765     :return:              True if a refresh is needed, False otherwise.
3766     """
3767     refresh = False
3768     if quota_usage.in_use < 0:
3769         # Negative in_use count indicates a desync, so try to
3770         # heal from that...
3771         LOG.debug('in_use has dropped below 0; forcing refresh for '
3772                   'QuotaUsage: %s', dict(quota_usage))
3773         refresh = True
3774     elif quota_usage.until_refresh is not None:
3775         quota_usage.until_refresh -= 1
3776         if quota_usage.until_refresh <= 0:
3777             refresh = True
3778     elif max_age and (timeutils.utcnow() -
3779             quota_usage.updated_at).seconds >= max_age:
3780         refresh = True
3781 
3782     return refresh
3783 
3784 
3785 def _refresh_quota_usages(quota_usage, until_refresh, in_use):
3786     """Refreshes quota usage for the given resource.
3787 
3788     :param quota_usage:   A QuotaUsage object for a given resource.
3789     :param until_refresh: Count of reservations until usage is refreshed,
3790                           int or None
3791     :param in_use:        Actual quota usage for the resource.
3792     """
3793     if quota_usage.in_use != in_use:
3794         LOG.info('quota_usages out of sync, updating. '
3795                  'project_id: %(project_id)s, '
3796                  'user_id: %(user_id)s, '
3797                  'resource: %(res)s, '
3798                  'tracked usage: %(tracked_use)s, '
3799                  'actual usage: %(in_use)s',
3800                  {'project_id': quota_usage.project_id,
3801                   'user_id': quota_usage.user_id,
3802                   'res': quota_usage.resource,
3803                   'tracked_use': quota_usage.in_use,
3804                   'in_use': in_use})
3805     else:
3806         LOG.debug('QuotaUsage has not changed, refresh is unnecessary for: %s',
3807                   dict(quota_usage))
3808 
3809     # Update the usage
3810     quota_usage.in_use = in_use
3811     quota_usage.until_refresh = until_refresh or None
3812 
3813 
3814 def _refresh_quota_usages_if_needed(user_usages, context, resources, keys,
3815                                     project_id, user_id, until_refresh,
3816                                     max_age, force_refresh=False):
3817     elevated = context.elevated()
3818 
3819     # Handle usage refresh
3820     work = set(keys)
3821     while work:
3822         resource = work.pop()
3823 
3824         # Do we need to refresh the usage?
3825         created = _create_quota_usage_if_missing(user_usages, resource,
3826                                                  until_refresh, project_id,
3827                                                  user_id, context.session)
3828 
3829         refresh = force_refresh
3830         if not refresh:
3831             refresh = created or \
3832                       _is_quota_refresh_needed(user_usages[resource], max_age)
3833 
3834         # OK, refresh the usage
3835         if refresh:
3836             # Grab the sync routine
3837             sync = QUOTA_SYNC_FUNCTIONS[resources[resource].sync]
3838 
3839             updates = sync(elevated, project_id, user_id)
3840             for res, in_use in updates.items():
3841                 # Make sure we have a destination for the usage!
3842                 _create_quota_usage_if_missing(user_usages, res,
3843                                                until_refresh, project_id,
3844                                                user_id, context.session)
3845                 _refresh_quota_usages(user_usages[res], until_refresh,
3846                                       in_use)
3847 
3848                 # Because more than one resource may be refreshed
3849                 # by the call to the sync routine, and we don't
3850                 # want to double-sync, we make sure all refreshed
3851                 # resources are dropped from the work set.
3852                 work.discard(res)
3853 
3854                 # NOTE(Vek): We make the assumption that the sync
3855                 #            routine actually refreshes the
3856                 #            resources that it is the sync routine
3857                 #            for.  We don't check, because this is
3858                 #            a best-effort mechanism.
3859 
3860 
3861 def _calculate_overquota(project_quotas, user_quotas, deltas,
3862                          project_usages, user_usages):
3863     """Checks if any resources will go over quota based on the request.
3864 
3865     :param project_quotas: dict of resource quotas (limits) for the project.
3866     :param user_quotas:    dict of resource quotas (limits) for the user.
3867     :param deltas:         dict of resource keys to positive/negative quota
3868                            changes for the resources in a given operation.
3869     :param project_usages: dict of resource keys to QuotaUsage records for the
3870                            project.
3871     :param user_usages:    dict of resource keys to QuotaUsage records for the
3872                            user.
3873     :return:               list of resources that are over-quota for the
3874                            operation.
3875     """
3876     overs = []
3877     for res, delta in deltas.items():
3878         # We can't go over-quota if we're not reserving anything.
3879         if delta >= 0:
3880             # We can't go over-quota if we have unlimited quotas.
3881             # over if the project usage + delta is more than project quota
3882             if 0 <= project_quotas[res] < delta + project_usages[res]['total']:
3883                 LOG.debug('Request is over project quota for resource '
3884                           '"%(res)s". Project limit: %(limit)s, delta: '
3885                           '%(delta)s, current total project usage: %(total)s',
3886                           {'res': res, 'limit': project_quotas[res],
3887                            'delta': delta,
3888                            'total': project_usages[res]['total']})
3889                 overs.append(res)
3890             # We can't go over-quota if we have unlimited quotas.
3891             # over if the user usage + delta is more than user quota
3892             elif 0 <= user_quotas[res] < delta + user_usages[res]['total']:
3893                 LOG.debug('Request is over user quota for resource '
3894                           '"%(res)s". User limit: %(limit)s, delta: '
3895                           '%(delta)s, current total user usage: %(total)s',
3896                           {'res': res, 'limit': user_quotas[res],
3897                            'delta': delta, 'total': user_usages[res]['total']})
3898                 overs.append(res)
3899     return overs
3900 
3901 
3902 @require_context
3903 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
3904 @pick_context_manager_writer
3905 def quota_usage_refresh(context, resources, keys, until_refresh, max_age,
3906                         project_id=None, user_id=None):
3907     if project_id is None:
3908         project_id = context.project_id
3909     if user_id is None:
3910         user_id = context.user_id
3911 
3912     # Get the current usages
3913     project_usages, user_usages = _get_project_user_quota_usages(
3914             context, project_id, user_id)
3915 
3916     # Force refresh of the usages
3917     _refresh_quota_usages_if_needed(user_usages, context, resources, keys,
3918                                     project_id, user_id, until_refresh,
3919                                     max_age, force_refresh=True)
3920 
3921 
3922 @require_context
3923 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
3924 @pick_context_manager_writer
3925 def quota_reserve(context, resources, project_quotas, user_quotas, deltas,
3926                   expire, until_refresh, max_age, project_id=None,
3927                   user_id=None):
3928     if project_id is None:
3929         project_id = context.project_id
3930     if user_id is None:
3931         user_id = context.user_id
3932 
3933     # Get the current usages
3934     project_usages, user_usages = _get_project_user_quota_usages(
3935             context, project_id, user_id)
3936 
3937     _refresh_quota_usages_if_needed(user_usages, context, resources,
3938                                     deltas.keys(), project_id, user_id,
3939                                     until_refresh, max_age)
3940 
3941     # Check for deltas that would go negative
3942     unders = [res for res, delta in deltas.items()
3943               if delta < 0 and
3944               delta + user_usages[res].in_use < 0]
3945 
3946     # Now, let's check the quotas
3947     # NOTE(Vek): We're only concerned about positive increments.
3948     #            If a project has gone over quota, we want them to
3949     #            be able to reduce their usage without any
3950     #            problems.
3951     for key, value in user_usages.items():
3952         if key not in project_usages:
3953             LOG.debug('Copying QuotaUsage for resource "%(key)s" from '
3954                       'user_usages into project_usages: %(value)s',
3955                       {'key': key, 'value': dict(value)})
3956             project_usages[key] = value
3957 
3958     overs = _calculate_overquota(project_quotas, user_quotas, deltas,
3959                                  project_usages, user_usages)
3960 
3961     # NOTE(Vek): The quota check needs to be in the transaction,
3962     #            but the transaction doesn't fail just because
3963     #            we're over quota, so the OverQuota raise is
3964     #            outside the transaction.  If we did the raise
3965     #            here, our usage updates would be discarded, but
3966     #            they're not invalidated by being over-quota.
3967 
3968     # Create the reservations
3969     if not overs:
3970         reservations = []
3971         for res, delta in deltas.items():
3972             reservation = _reservation_create(
3973                                              uuidutils.generate_uuid(),
3974                                              user_usages[res],
3975                                              project_id,
3976                                              user_id,
3977                                              res, delta, expire,
3978                                              context.session)
3979             reservations.append(reservation.uuid)
3980 
3981             # Also update the reserved quantity
3982             # NOTE(Vek): Again, we are only concerned here about
3983             #            positive increments.  Here, though, we're
3984             #            worried about the following scenario:
3985             #
3986             #            1) User initiates resize down.
3987             #            2) User allocates a new instance.
3988             #            3) Resize down fails or is reverted.
3989             #            4) User is now over quota.
3990             #
3991             #            To prevent this, we only update the
3992             #            reserved value if the delta is positive.
3993             if delta > 0:
3994                 user_usages[res].reserved += delta
3995 
3996     # Apply updates to the usages table
3997     for usage_ref in user_usages.values():
3998         context.session.add(usage_ref)
3999 
4000     if unders:
4001         LOG.warning("Change will make usage less than 0 for the following "
4002                     "resources: %s", unders)
4003 
4004     if overs:
4005         if project_quotas == user_quotas:
4006             usages = project_usages
4007         else:
4008             # NOTE(mriedem): user_usages is a dict of resource keys to
4009             # QuotaUsage sqlalchemy dict-like objects and doesn't log well
4010             # so convert the user_usages values to something useful for
4011             # logging. Remove this if we ever change how
4012             # _get_project_user_quota_usages returns the user_usages values.
4013             user_usages = {k: dict(in_use=v['in_use'], reserved=v['reserved'],
4014                                    total=v['total'])
4015                       for k, v in user_usages.items()}
4016             usages = user_usages
4017         usages = {k: dict(in_use=v['in_use'], reserved=v['reserved'])
4018                   for k, v in usages.items()}
4019         LOG.debug('Raise OverQuota exception because: '
4020                   'project_quotas: %(project_quotas)s, '
4021                   'user_quotas: %(user_quotas)s, deltas: %(deltas)s, '
4022                   'overs: %(overs)s, project_usages: %(project_usages)s, '
4023                   'user_usages: %(user_usages)s',
4024                   {'project_quotas': project_quotas,
4025                    'user_quotas': user_quotas,
4026                    'overs': overs, 'deltas': deltas,
4027                    'project_usages': project_usages,
4028                    'user_usages': user_usages})
4029         raise exception.OverQuota(overs=sorted(overs), quotas=user_quotas,
4030                                   usages=usages)
4031 
4032     return reservations
4033 
4034 
4035 def _quota_reservations_query(context, reservations):
4036     """Return the relevant reservations."""
4037 
4038     # Get the listed reservations
4039     return model_query(context, models.Reservation, read_deleted="no").\
4040         filter(models.Reservation.uuid.in_(reservations)).\
4041         with_lockmode('update')
4042 
4043 
4044 @require_context
4045 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
4046 @pick_context_manager_writer
4047 def reservation_commit(context, reservations, project_id=None, user_id=None):
4048     _project_usages, user_usages = _get_project_user_quota_usages(
4049             context, project_id, user_id)
4050     reservation_query = _quota_reservations_query(context, reservations)
4051     for reservation in reservation_query.all():
4052         usage = user_usages[reservation.resource]
4053         if reservation.delta >= 0:
4054             usage.reserved -= reservation.delta
4055         usage.in_use += reservation.delta
4056     reservation_query.soft_delete(synchronize_session=False)
4057 
4058 
4059 @require_context
4060 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
4061 @pick_context_manager_writer
4062 def reservation_rollback(context, reservations, project_id=None, user_id=None):
4063     _project_usages, user_usages = _get_project_user_quota_usages(
4064             context, project_id, user_id)
4065     reservation_query = _quota_reservations_query(context, reservations)
4066     for reservation in reservation_query.all():
4067         usage = user_usages[reservation.resource]
4068         if reservation.delta >= 0:
4069             usage.reserved -= reservation.delta
4070     reservation_query.soft_delete(synchronize_session=False)
4071 
4072 
4073 @pick_context_manager_writer
4074 def quota_destroy_all_by_project_and_user(context, project_id, user_id):
4075     model_query(context, models.ProjectUserQuota, read_deleted="no").\
4076         filter_by(project_id=project_id).\
4077         filter_by(user_id=user_id).\
4078         soft_delete(synchronize_session=False)
4079 
4080     model_query(context, models.QuotaUsage, read_deleted="no").\
4081         filter_by(project_id=project_id).\
4082         filter_by(user_id=user_id).\
4083         soft_delete(synchronize_session=False)
4084 
4085     model_query(context, models.Reservation, read_deleted="no").\
4086         filter_by(project_id=project_id).\
4087         filter_by(user_id=user_id).\
4088         soft_delete(synchronize_session=False)
4089 
4090 
4091 @pick_context_manager_writer
4092 def quota_destroy_all_by_project(context, project_id):
4093     model_query(context, models.Quota, read_deleted="no").\
4094         filter_by(project_id=project_id).\
4095         soft_delete(synchronize_session=False)
4096 
4097     model_query(context, models.ProjectUserQuota, read_deleted="no").\
4098         filter_by(project_id=project_id).\
4099         soft_delete(synchronize_session=False)
4100 
4101     model_query(context, models.QuotaUsage, read_deleted="no").\
4102         filter_by(project_id=project_id).\
4103         soft_delete(synchronize_session=False)
4104 
4105     model_query(context, models.Reservation, read_deleted="no").\
4106         filter_by(project_id=project_id).\
4107         soft_delete(synchronize_session=False)
4108 
4109 
4110 ###################
4111 
4112 
4113 def _ec2_volume_get_query(context):
4114     return model_query(context, models.VolumeIdMapping, read_deleted='yes')
4115 
4116 
4117 def _ec2_snapshot_get_query(context):
4118     return model_query(context, models.SnapshotIdMapping, read_deleted='yes')
4119 
4120 
4121 @require_context
4122 @pick_context_manager_writer
4123 def ec2_volume_create(context, volume_uuid, id=None):
4124     """Create ec2 compatible volume by provided uuid."""
4125     ec2_volume_ref = models.VolumeIdMapping()
4126     ec2_volume_ref.update({'uuid': volume_uuid})
4127     if id is not None:
4128         ec2_volume_ref.update({'id': id})
4129 
4130     ec2_volume_ref.save(context.session)
4131 
4132     return ec2_volume_ref
4133 
4134 
4135 @require_context
4136 @pick_context_manager_reader
4137 def ec2_volume_get_by_uuid(context, volume_uuid):
4138     result = _ec2_volume_get_query(context).\
4139                     filter_by(uuid=volume_uuid).\
4140                     first()
4141 
4142     if not result:
4143         raise exception.VolumeNotFound(volume_id=volume_uuid)
4144 
4145     return result
4146 
4147 
4148 @require_context
4149 @pick_context_manager_reader
4150 def ec2_volume_get_by_id(context, volume_id):
4151     result = _ec2_volume_get_query(context).\
4152                     filter_by(id=volume_id).\
4153                     first()
4154 
4155     if not result:
4156         raise exception.VolumeNotFound(volume_id=volume_id)
4157 
4158     return result
4159 
4160 
4161 @require_context
4162 @pick_context_manager_writer
4163 def ec2_snapshot_create(context, snapshot_uuid, id=None):
4164     """Create ec2 compatible snapshot by provided uuid."""
4165     ec2_snapshot_ref = models.SnapshotIdMapping()
4166     ec2_snapshot_ref.update({'uuid': snapshot_uuid})
4167     if id is not None:
4168         ec2_snapshot_ref.update({'id': id})
4169 
4170     ec2_snapshot_ref.save(context.session)
4171 
4172     return ec2_snapshot_ref
4173 
4174 
4175 @require_context
4176 @pick_context_manager_reader
4177 def ec2_snapshot_get_by_ec2_id(context, ec2_id):
4178     result = _ec2_snapshot_get_query(context).\
4179                     filter_by(id=ec2_id).\
4180                     first()
4181 
4182     if not result:
4183         raise exception.SnapshotNotFound(snapshot_id=ec2_id)
4184 
4185     return result
4186 
4187 
4188 @require_context
4189 @pick_context_manager_reader
4190 def ec2_snapshot_get_by_uuid(context, snapshot_uuid):
4191     result = _ec2_snapshot_get_query(context).\
4192                     filter_by(uuid=snapshot_uuid).\
4193                     first()
4194 
4195     if not result:
4196         raise exception.SnapshotNotFound(snapshot_id=snapshot_uuid)
4197 
4198     return result
4199 
4200 
4201 ###################
4202 
4203 
4204 def _block_device_mapping_get_query(context, columns_to_join=None):
4205     if columns_to_join is None:
4206         columns_to_join = []
4207 
4208     query = model_query(context, models.BlockDeviceMapping)
4209 
4210     for column in columns_to_join:
4211         query = query.options(joinedload(column))
4212 
4213     return query
4214 
4215 
4216 def _scrub_empty_str_values(dct, keys_to_scrub):
4217     """Remove any keys found in sequence keys_to_scrub from the dict
4218     if they have the value ''.
4219     """
4220     for key in keys_to_scrub:
4221         if key in dct and dct[key] == '':
4222             del dct[key]
4223 
4224 
4225 def _from_legacy_values(values, legacy, allow_updates=False):
4226     if legacy:
4227         if allow_updates and block_device.is_safe_for_update(values):
4228             return values
4229         else:
4230             return block_device.BlockDeviceDict.from_legacy(values)
4231     else:
4232         return values
4233 
4234 
4235 @require_context
4236 @pick_context_manager_writer
4237 def block_device_mapping_create(context, values, legacy=True):
4238     _scrub_empty_str_values(values, ['volume_size'])
4239     values = _from_legacy_values(values, legacy)
4240     convert_objects_related_datetimes(values)
4241 
4242     bdm_ref = models.BlockDeviceMapping()
4243     bdm_ref.update(values)
4244     bdm_ref.save(context.session)
4245     return bdm_ref
4246 
4247 
4248 @require_context
4249 @pick_context_manager_writer
4250 def block_device_mapping_update(context, bdm_id, values, legacy=True):
4251     _scrub_empty_str_values(values, ['volume_size'])
4252     values = _from_legacy_values(values, legacy, allow_updates=True)
4253     convert_objects_related_datetimes(values)
4254 
4255     query = _block_device_mapping_get_query(context).filter_by(id=bdm_id)
4256     query.update(values)
4257     return query.first()
4258 
4259 
4260 @pick_context_manager_writer
4261 def block_device_mapping_update_or_create(context, values, legacy=True):
4262     _scrub_empty_str_values(values, ['volume_size'])
4263     values = _from_legacy_values(values, legacy, allow_updates=True)
4264     convert_objects_related_datetimes(values)
4265 
4266     result = None
4267     # NOTE(xqueralt): Only update a BDM when device_name was provided. We
4268     # allow empty device names so they will be set later by the manager.
4269     if values['device_name']:
4270         query = _block_device_mapping_get_query(context)
4271         result = query.filter_by(instance_uuid=values['instance_uuid'],
4272                                  device_name=values['device_name']).first()
4273 
4274     if result:
4275         result.update(values)
4276     else:
4277         # Either the device_name doesn't exist in the database yet, or no
4278         # device_name was provided. Both cases mean creating a new BDM.
4279         result = models.BlockDeviceMapping(**values)
4280         result.save(context.session)
4281 
4282     # NOTE(xqueralt): Prevent from having multiple swap devices for the
4283     # same instance. This will delete all the existing ones.
4284     if block_device.new_format_is_swap(values):
4285         query = _block_device_mapping_get_query(context)
4286         query = query.filter_by(instance_uuid=values['instance_uuid'],
4287                                 source_type='blank', guest_format='swap')
4288         query = query.filter(models.BlockDeviceMapping.id != result.id)
4289         query.soft_delete()
4290 
4291     return result
4292 
4293 
4294 @require_context
4295 @pick_context_manager_reader_allow_async
4296 def block_device_mapping_get_all_by_instance_uuids(context, instance_uuids):
4297     if not instance_uuids:
4298         return []
4299     return _block_device_mapping_get_query(context).filter(
4300         models.BlockDeviceMapping.instance_uuid.in_(instance_uuids)).all()
4301 
4302 
4303 @require_context
4304 @pick_context_manager_reader_allow_async
4305 def block_device_mapping_get_all_by_instance(context, instance_uuid):
4306     return _block_device_mapping_get_query(context).\
4307                  filter_by(instance_uuid=instance_uuid).\
4308                  all()
4309 
4310 
4311 @require_context
4312 @pick_context_manager_reader
4313 def block_device_mapping_get_all_by_volume_id(context, volume_id,
4314         columns_to_join=None):
4315     return _block_device_mapping_get_query(context,
4316             columns_to_join=columns_to_join).\
4317                  filter_by(volume_id=volume_id).\
4318                  all()
4319 
4320 
4321 @require_context
4322 @pick_context_manager_reader
4323 def block_device_mapping_get_by_instance_and_volume_id(context, volume_id,
4324                                                        instance_uuid,
4325                                                        columns_to_join=None):
4326     return _block_device_mapping_get_query(context,
4327             columns_to_join=columns_to_join).\
4328                  filter_by(volume_id=volume_id).\
4329                  filter_by(instance_uuid=instance_uuid).\
4330                  first()
4331 
4332 
4333 @require_context
4334 @pick_context_manager_writer
4335 def block_device_mapping_destroy(context, bdm_id):
4336     _block_device_mapping_get_query(context).\
4337             filter_by(id=bdm_id).\
4338             soft_delete()
4339 
4340 
4341 @require_context
4342 @pick_context_manager_writer
4343 def block_device_mapping_destroy_by_instance_and_volume(context, instance_uuid,
4344                                                         volume_id):
4345     _block_device_mapping_get_query(context).\
4346             filter_by(instance_uuid=instance_uuid).\
4347             filter_by(volume_id=volume_id).\
4348             soft_delete()
4349 
4350 
4351 @require_context
4352 @pick_context_manager_writer
4353 def block_device_mapping_destroy_by_instance_and_device(context, instance_uuid,
4354                                                         device_name):
4355     _block_device_mapping_get_query(context).\
4356             filter_by(instance_uuid=instance_uuid).\
4357             filter_by(device_name=device_name).\
4358             soft_delete()
4359 
4360 
4361 ###################
4362 
4363 
4364 @require_context
4365 @pick_context_manager_writer
4366 def security_group_create(context, values):
4367     security_group_ref = models.SecurityGroup()
4368     # FIXME(devcamcar): Unless I do this, rules fails with lazy load exception
4369     # once save() is called.  This will get cleaned up in next orm pass.
4370     security_group_ref.rules
4371     security_group_ref.update(values)
4372     try:
4373         with get_context_manager(context).writer.savepoint.using(context):
4374             security_group_ref.save(context.session)
4375     except db_exc.DBDuplicateEntry:
4376         raise exception.SecurityGroupExists(
4377                 project_id=values['project_id'],
4378                 security_group_name=values['name'])
4379     return security_group_ref
4380 
4381 
4382 def _security_group_get_query(context, read_deleted=None,
4383                               project_only=False, join_rules=True):
4384     query = model_query(context, models.SecurityGroup,
4385             read_deleted=read_deleted, project_only=project_only)
4386     if join_rules:
4387         query = query.options(joinedload_all('rules.grantee_group'))
4388     return query
4389 
4390 
4391 def _security_group_get_by_names(context, group_names):
4392     """Get security group models for a project by a list of names.
4393     Raise SecurityGroupNotFoundForProject for a name not found.
4394     """
4395     query = _security_group_get_query(context, read_deleted="no",
4396                                       join_rules=False).\
4397             filter_by(project_id=context.project_id).\
4398             filter(models.SecurityGroup.name.in_(group_names))
4399     sg_models = query.all()
4400     if len(sg_models) == len(group_names):
4401         return sg_models
4402     # Find the first one missing and raise
4403     group_names_from_models = [x.name for x in sg_models]
4404     for group_name in group_names:
4405         if group_name not in group_names_from_models:
4406             raise exception.SecurityGroupNotFoundForProject(
4407                 project_id=context.project_id, security_group_id=group_name)
4408     # Not Reached
4409 
4410 
4411 @require_context
4412 @pick_context_manager_reader
4413 def security_group_get_all(context):
4414     return _security_group_get_query(context).all()
4415 
4416 
4417 @require_context
4418 @pick_context_manager_reader
4419 def security_group_get(context, security_group_id, columns_to_join=None):
4420     join_rules = columns_to_join and 'rules' in columns_to_join
4421     if join_rules:
4422         columns_to_join.remove('rules')
4423     query = _security_group_get_query(context, project_only=True,
4424                                       join_rules=join_rules).\
4425                     filter_by(id=security_group_id)
4426 
4427     if columns_to_join is None:
4428         columns_to_join = []
4429     for column in columns_to_join:
4430         if column.startswith('instances'):
4431             query = query.options(joinedload_all(column))
4432 
4433     result = query.first()
4434     if not result:
4435         raise exception.SecurityGroupNotFound(
4436                 security_group_id=security_group_id)
4437 
4438     return result
4439 
4440 
4441 @require_context
4442 @pick_context_manager_reader
4443 def security_group_get_by_name(context, project_id, group_name,
4444                                columns_to_join=None):
4445     query = _security_group_get_query(context,
4446                                       read_deleted="no", join_rules=False).\
4447             filter_by(project_id=project_id).\
4448             filter_by(name=group_name)
4449 
4450     if columns_to_join is None:
4451         columns_to_join = ['instances', 'rules.grantee_group']
4452 
4453     for column in columns_to_join:
4454         query = query.options(joinedload_all(column))
4455 
4456     result = query.first()
4457     if not result:
4458         raise exception.SecurityGroupNotFoundForProject(
4459                 project_id=project_id, security_group_id=group_name)
4460 
4461     return result
4462 
4463 
4464 @require_context
4465 @pick_context_manager_reader
4466 def security_group_get_by_project(context, project_id):
4467     return _security_group_get_query(context, read_deleted="no").\
4468                         filter_by(project_id=project_id).\
4469                         all()
4470 
4471 
4472 @require_context
4473 @pick_context_manager_reader
4474 def security_group_get_by_instance(context, instance_uuid):
4475     return _security_group_get_query(context, read_deleted="no").\
4476                    join(models.SecurityGroup.instances).\
4477                    filter_by(uuid=instance_uuid).\
4478                    all()
4479 
4480 
4481 @require_context
4482 @pick_context_manager_reader
4483 def security_group_in_use(context, group_id):
4484     # Are there any instances that haven't been deleted
4485     # that include this group?
4486     inst_assoc = model_query(context,
4487                              models.SecurityGroupInstanceAssociation,
4488                              read_deleted="no").\
4489                     filter_by(security_group_id=group_id).\
4490                     all()
4491     for ia in inst_assoc:
4492         num_instances = model_query(context, models.Instance,
4493                                     read_deleted="no").\
4494                     filter_by(uuid=ia.instance_uuid).\
4495                     count()
4496         if num_instances:
4497             return True
4498 
4499     return False
4500 
4501 
4502 @require_context
4503 @pick_context_manager_writer
4504 def security_group_update(context, security_group_id, values,
4505                           columns_to_join=None):
4506     query = model_query(context, models.SecurityGroup).filter_by(
4507         id=security_group_id)
4508     if columns_to_join:
4509         for column in columns_to_join:
4510             query = query.options(joinedload_all(column))
4511     security_group_ref = query.first()
4512 
4513     if not security_group_ref:
4514         raise exception.SecurityGroupNotFound(
4515                 security_group_id=security_group_id)
4516     security_group_ref.update(values)
4517     name = security_group_ref['name']
4518     project_id = security_group_ref['project_id']
4519     try:
4520         security_group_ref.save(context.session)
4521     except db_exc.DBDuplicateEntry:
4522         raise exception.SecurityGroupExists(
4523                 project_id=project_id,
4524                 security_group_name=name)
4525     return security_group_ref
4526 
4527 
4528 def security_group_ensure_default(context):
4529     """Ensure default security group exists for a project_id."""
4530 
4531     try:
4532         # NOTE(rpodolyaka): create the default security group, if it doesn't
4533         # exist. This must be done in a separate transaction, so that
4534         # this one is not aborted in case a concurrent one succeeds first
4535         # and the unique constraint for security group names is violated
4536         # by a concurrent INSERT
4537         with get_context_manager(context).writer.independent.using(context):
4538             return _security_group_ensure_default(context)
4539     except exception.SecurityGroupExists:
4540         # NOTE(rpodolyaka): a concurrent transaction has succeeded first,
4541         # suppress the error and proceed
4542         return security_group_get_by_name(context, context.project_id,
4543                                           'default')
4544 
4545 
4546 @pick_context_manager_writer
4547 def _security_group_ensure_default(context):
4548     try:
4549         default_group = _security_group_get_by_names(context, ['default'])[0]
4550     except exception.NotFound:
4551         values = {'name': 'default',
4552                   'description': 'default',
4553                   'user_id': context.user_id,
4554                   'project_id': context.project_id}
4555         default_group = security_group_create(context, values)
4556         usage = model_query(context, models.QuotaUsage, read_deleted="no").\
4557             filter_by(project_id=context.project_id).\
4558             filter_by(user_id=context.user_id).\
4559             filter_by(resource='security_groups')
4560         # Create quota usage for auto created default security group
4561         if not usage.first():
4562             _quota_usage_create(context.project_id,
4563                                 context.user_id,
4564                                 'security_groups',
4565                                 1, 0,
4566                                 CONF.quota.until_refresh,
4567                                 context.session)
4568         else:
4569             usage.update({'in_use': int(usage.first().in_use) + 1})
4570 
4571         default_rules = _security_group_rule_get_default_query(context).all()
4572         for default_rule in default_rules:
4573             # This is suboptimal, it should be programmatic to know
4574             # the values of the default_rule
4575             rule_values = {'protocol': default_rule.protocol,
4576                            'from_port': default_rule.from_port,
4577                            'to_port': default_rule.to_port,
4578                            'cidr': default_rule.cidr,
4579                            'parent_group_id': default_group.id,
4580             }
4581             _security_group_rule_create(context, rule_values)
4582     return default_group
4583 
4584 
4585 @require_context
4586 @pick_context_manager_writer
4587 def security_group_destroy(context, security_group_id):
4588     model_query(context, models.SecurityGroup).\
4589             filter_by(id=security_group_id).\
4590             soft_delete()
4591     model_query(context, models.SecurityGroupInstanceAssociation).\
4592             filter_by(security_group_id=security_group_id).\
4593             soft_delete()
4594     model_query(context, models.SecurityGroupIngressRule).\
4595             filter_by(group_id=security_group_id).\
4596             soft_delete()
4597     model_query(context, models.SecurityGroupIngressRule).\
4598             filter_by(parent_group_id=security_group_id).\
4599             soft_delete()
4600 
4601 
4602 def _security_group_count_by_project_and_user(context, project_id, user_id):
4603     nova.context.authorize_project_context(context, project_id)
4604     return model_query(context, models.SecurityGroup, read_deleted="no").\
4605                    filter_by(project_id=project_id).\
4606                    filter_by(user_id=user_id).\
4607                    count()
4608 
4609 
4610 ###################
4611 
4612 
4613 def _security_group_rule_create(context, values):
4614     security_group_rule_ref = models.SecurityGroupIngressRule()
4615     security_group_rule_ref.update(values)
4616     security_group_rule_ref.save(context.session)
4617     return security_group_rule_ref
4618 
4619 
4620 def _security_group_rule_get_query(context):
4621     return model_query(context, models.SecurityGroupIngressRule)
4622 
4623 
4624 @require_context
4625 @pick_context_manager_reader
4626 def security_group_rule_get(context, security_group_rule_id):
4627     result = (_security_group_rule_get_query(context).
4628                          filter_by(id=security_group_rule_id).
4629                          first())
4630 
4631     if not result:
4632         raise exception.SecurityGroupNotFoundForRule(
4633                                                rule_id=security_group_rule_id)
4634 
4635     return result
4636 
4637 
4638 @require_context
4639 @pick_context_manager_reader
4640 def security_group_rule_get_by_security_group(context, security_group_id,
4641                                               columns_to_join=None):
4642     if columns_to_join is None:
4643         columns_to_join = ['grantee_group.instances.system_metadata',
4644                            'grantee_group.instances.info_cache']
4645     query = (_security_group_rule_get_query(context).
4646              filter_by(parent_group_id=security_group_id))
4647     for column in columns_to_join:
4648         query = query.options(joinedload_all(column))
4649     return query.all()
4650 
4651 
4652 @require_context
4653 @pick_context_manager_reader
4654 def security_group_rule_get_by_instance(context, instance_uuid):
4655     return (_security_group_rule_get_query(context).
4656             join('parent_group', 'instances').
4657             filter_by(uuid=instance_uuid).
4658             options(joinedload('grantee_group')).
4659             all())
4660 
4661 
4662 @require_context
4663 @pick_context_manager_writer
4664 def security_group_rule_create(context, values):
4665     return _security_group_rule_create(context, values)
4666 
4667 
4668 @require_context
4669 @pick_context_manager_writer
4670 def security_group_rule_destroy(context, security_group_rule_id):
4671     count = (_security_group_rule_get_query(context).
4672                     filter_by(id=security_group_rule_id).
4673                     soft_delete())
4674     if count == 0:
4675         raise exception.SecurityGroupNotFoundForRule(
4676                                             rule_id=security_group_rule_id)
4677 
4678 
4679 @require_context
4680 @pick_context_manager_reader
4681 def security_group_rule_count_by_group(context, security_group_id):
4682     return (model_query(context, models.SecurityGroupIngressRule,
4683                    read_deleted="no").
4684                    filter_by(parent_group_id=security_group_id).
4685                    count())
4686 
4687 
4688 ###################
4689 
4690 
4691 def _security_group_rule_get_default_query(context):
4692     return model_query(context, models.SecurityGroupIngressDefaultRule)
4693 
4694 
4695 @require_context
4696 @pick_context_manager_reader
4697 def security_group_default_rule_get(context, security_group_rule_default_id):
4698     result = _security_group_rule_get_default_query(context).\
4699                         filter_by(id=security_group_rule_default_id).\
4700                         first()
4701 
4702     if not result:
4703         raise exception.SecurityGroupDefaultRuleNotFound(
4704                                         rule_id=security_group_rule_default_id)
4705 
4706     return result
4707 
4708 
4709 @pick_context_manager_writer
4710 def security_group_default_rule_destroy(context,
4711                                         security_group_rule_default_id):
4712     count = _security_group_rule_get_default_query(context).\
4713                         filter_by(id=security_group_rule_default_id).\
4714                         soft_delete()
4715     if count == 0:
4716         raise exception.SecurityGroupDefaultRuleNotFound(
4717                                     rule_id=security_group_rule_default_id)
4718 
4719 
4720 @pick_context_manager_writer
4721 def security_group_default_rule_create(context, values):
4722     security_group_default_rule_ref = models.SecurityGroupIngressDefaultRule()
4723     security_group_default_rule_ref.update(values)
4724     security_group_default_rule_ref.save(context.session)
4725     return security_group_default_rule_ref
4726 
4727 
4728 @require_context
4729 @pick_context_manager_reader
4730 def security_group_default_rule_list(context):
4731     return _security_group_rule_get_default_query(context).all()
4732 
4733 
4734 ###################
4735 
4736 
4737 @pick_context_manager_writer
4738 def provider_fw_rule_create(context, rule):
4739     fw_rule_ref = models.ProviderFirewallRule()
4740     fw_rule_ref.update(rule)
4741     fw_rule_ref.save(context.session)
4742     return fw_rule_ref
4743 
4744 
4745 @pick_context_manager_reader
4746 def provider_fw_rule_get_all(context):
4747     return model_query(context, models.ProviderFirewallRule).all()
4748 
4749 
4750 @pick_context_manager_writer
4751 def provider_fw_rule_destroy(context, rule_id):
4752     context.session.query(models.ProviderFirewallRule).\
4753         filter_by(id=rule_id).\
4754         soft_delete()
4755 
4756 
4757 ###################
4758 
4759 
4760 @require_context
4761 @pick_context_manager_writer
4762 def project_get_networks(context, project_id, associate=True):
4763     # NOTE(tr3buchet): as before this function will associate
4764     # a project with a network if it doesn't have one and
4765     # associate is true
4766     result = model_query(context, models.Network, read_deleted="no").\
4767                      filter_by(project_id=project_id).\
4768                      all()
4769 
4770     if not result:
4771         if not associate:
4772             return []
4773 
4774         return [network_associate(context, project_id)]
4775 
4776     return result
4777 
4778 
4779 ###################
4780 
4781 
4782 @pick_context_manager_writer
4783 def migration_create(context, values):
4784     migration = models.Migration()
4785     migration.update(values)
4786     migration.save(context.session)
4787     return migration
4788 
4789 
4790 @pick_context_manager_writer
4791 def migration_update(context, id, values):
4792     migration = migration_get(context, id)
4793     migration.update(values)
4794 
4795     return migration
4796 
4797 
4798 @pick_context_manager_reader
4799 def migration_get(context, id):
4800     result = model_query(context, models.Migration, read_deleted="yes").\
4801                      filter_by(id=id).\
4802                      first()
4803 
4804     if not result:
4805         raise exception.MigrationNotFound(migration_id=id)
4806 
4807     return result
4808 
4809 
4810 @pick_context_manager_reader
4811 def migration_get_by_uuid(context, migration_uuid):
4812     result = model_query(context, models.Migration, read_deleted="yes").\
4813                      filter_by(uuid=migration_uuid).\
4814                      first()
4815 
4816     if not result:
4817         raise exception.MigrationNotFound(migration_id=migration_uuid)
4818 
4819     return result
4820 
4821 
4822 @pick_context_manager_reader
4823 def migration_get_by_id_and_instance(context, id, instance_uuid):
4824     result = model_query(context, models.Migration).\
4825                      filter_by(id=id).\
4826                      filter_by(instance_uuid=instance_uuid).\
4827                      first()
4828 
4829     if not result:
4830         raise exception.MigrationNotFoundForInstance(migration_id=id,
4831                                                      instance_id=instance_uuid)
4832 
4833     return result
4834 
4835 
4836 @pick_context_manager_reader
4837 def migration_get_by_instance_and_status(context, instance_uuid, status):
4838     result = model_query(context, models.Migration, read_deleted="yes").\
4839                      filter_by(instance_uuid=instance_uuid).\
4840                      filter_by(status=status).\
4841                      first()
4842 
4843     if not result:
4844         raise exception.MigrationNotFoundByStatus(instance_id=instance_uuid,
4845                                                   status=status)
4846 
4847     return result
4848 
4849 
4850 @pick_context_manager_reader_allow_async
4851 def migration_get_unconfirmed_by_dest_compute(context, confirm_window,
4852                                               dest_compute):
4853     confirm_window = (timeutils.utcnow() -
4854                       datetime.timedelta(seconds=confirm_window))
4855 
4856     return model_query(context, models.Migration, read_deleted="yes").\
4857              filter(models.Migration.updated_at <= confirm_window).\
4858              filter_by(status="finished").\
4859              filter_by(dest_compute=dest_compute).\
4860              all()
4861 
4862 
4863 @pick_context_manager_reader
4864 def migration_get_in_progress_by_host_and_node(context, host, node):
4865     # TODO(mriedem): Tracking what various code flows set for
4866     # migration status is nutty, since it happens all over the place
4867     # and several of the statuses are redundant (done and completed).
4868     # We need to define these in an enum somewhere and just update
4869     # that one central place that defines what "in progress" means.
4870     # NOTE(mriedem): The 'finished' status is not in this list because
4871     # 'finished' means a resize is finished on the destination host
4872     # and the instance is in VERIFY_RESIZE state, so the end state
4873     # for a resize is actually 'confirmed' or 'reverted'.
4874     return model_query(context, models.Migration).\
4875             filter(or_(and_(models.Migration.source_compute == host,
4876                             models.Migration.source_node == node),
4877                        and_(models.Migration.dest_compute == host,
4878                             models.Migration.dest_node == node))).\
4879             filter(~models.Migration.status.in_(['accepted', 'confirmed',
4880                                                  'reverted', 'error',
4881                                                  'failed', 'completed',
4882                                                  'cancelled', 'done'])).\
4883             options(joinedload_all('instance.system_metadata')).\
4884             all()
4885 
4886 
4887 @pick_context_manager_reader
4888 def migration_get_in_progress_by_instance(context, instance_uuid,
4889                                           migration_type=None):
4890     # TODO(Shaohe Feng) we should share the in-progress list.
4891     # TODO(Shaohe Feng) will also summarize all status to a new
4892     # MigrationStatus class.
4893     query = model_query(context, models.Migration).\
4894             filter_by(instance_uuid=instance_uuid).\
4895             filter(models.Migration.status.in_(['queued', 'preparing',
4896                                                 'running',
4897                                                 'post-migrating']))
4898     if migration_type:
4899         query = query.filter(models.Migration.migration_type == migration_type)
4900 
4901     return query.all()
4902 
4903 
4904 @pick_context_manager_reader
4905 def migration_get_all_by_filters(context, filters):
4906     query = model_query(context, models.Migration)
4907     if "status" in filters:
4908         status = filters["status"]
4909         status = [status] if isinstance(status, six.string_types) else status
4910         query = query.filter(models.Migration.status.in_(status))
4911     if "host" in filters:
4912         host = filters["host"]
4913         query = query.filter(or_(models.Migration.source_compute == host,
4914                                  models.Migration.dest_compute == host))
4915     elif "source_compute" in filters:
4916         host = filters['source_compute']
4917         query = query.filter(models.Migration.source_compute == host)
4918     if "migration_type" in filters:
4919         migtype = filters["migration_type"]
4920         query = query.filter(models.Migration.migration_type == migtype)
4921     if "hidden" in filters:
4922         hidden = filters["hidden"]
4923         query = query.filter(models.Migration.hidden == hidden)
4924     if "instance_uuid" in filters:
4925         uuid = filters["instance_uuid"]
4926         query = query.filter(models.Migration.instance_uuid == uuid)
4927     return query.all()
4928 
4929 
4930 @pick_context_manager_writer
4931 def migration_migrate_to_uuid(context, count):
4932     # Avoid circular import
4933     from nova import objects
4934 
4935     db_migrations = model_query(context, models.Migration).filter_by(
4936         uuid=None).limit(count).all()
4937 
4938     done = 0
4939     for db_migration in db_migrations:
4940         mig = objects.Migration(context)
4941         mig._from_db_object(context, mig, db_migration)
4942         done += 1
4943 
4944     # We don't have any situation where we can (detectably) not
4945     # migrate a thing, so report anything that matched as "completed".
4946     return done, done
4947 
4948 
4949 ##################
4950 
4951 
4952 @pick_context_manager_writer
4953 def console_pool_create(context, values):
4954     pool = models.ConsolePool()
4955     pool.update(values)
4956     try:
4957         pool.save(context.session)
4958     except db_exc.DBDuplicateEntry:
4959         raise exception.ConsolePoolExists(
4960             host=values["host"],
4961             console_type=values["console_type"],
4962             compute_host=values["compute_host"],
4963         )
4964     return pool
4965 
4966 
4967 @pick_context_manager_reader
4968 def console_pool_get_by_host_type(context, compute_host, host,
4969                                   console_type):
4970 
4971     result = model_query(context, models.ConsolePool, read_deleted="no").\
4972                    filter_by(host=host).\
4973                    filter_by(console_type=console_type).\
4974                    filter_by(compute_host=compute_host).\
4975                    options(joinedload('consoles')).\
4976                    first()
4977 
4978     if not result:
4979         raise exception.ConsolePoolNotFoundForHostType(
4980                 host=host, console_type=console_type,
4981                 compute_host=compute_host)
4982 
4983     return result
4984 
4985 
4986 @pick_context_manager_reader
4987 def console_pool_get_all_by_host_type(context, host, console_type):
4988     return model_query(context, models.ConsolePool, read_deleted="no").\
4989                    filter_by(host=host).\
4990                    filter_by(console_type=console_type).\
4991                    options(joinedload('consoles')).\
4992                    all()
4993 
4994 
4995 ##################
4996 
4997 
4998 @pick_context_manager_writer
4999 def console_create(context, values):
5000     console = models.Console()
5001     console.update(values)
5002     console.save(context.session)
5003     return console
5004 
5005 
5006 @pick_context_manager_writer
5007 def console_delete(context, console_id):
5008     # NOTE(mdragon): consoles are meant to be transient.
5009     context.session.query(models.Console).\
5010         filter_by(id=console_id).\
5011         delete()
5012 
5013 
5014 @pick_context_manager_reader
5015 def console_get_by_pool_instance(context, pool_id, instance_uuid):
5016     result = model_query(context, models.Console, read_deleted="yes").\
5017                    filter_by(pool_id=pool_id).\
5018                    filter_by(instance_uuid=instance_uuid).\
5019                    options(joinedload('pool')).\
5020                    first()
5021 
5022     if not result:
5023         raise exception.ConsoleNotFoundInPoolForInstance(
5024                 pool_id=pool_id, instance_uuid=instance_uuid)
5025 
5026     return result
5027 
5028 
5029 @pick_context_manager_reader
5030 def console_get_all_by_instance(context, instance_uuid, columns_to_join=None):
5031     query = model_query(context, models.Console, read_deleted="yes").\
5032                 filter_by(instance_uuid=instance_uuid)
5033     if columns_to_join:
5034         for column in columns_to_join:
5035             query = query.options(joinedload(column))
5036     return query.all()
5037 
5038 
5039 @pick_context_manager_reader
5040 def console_get(context, console_id, instance_uuid=None):
5041     query = model_query(context, models.Console, read_deleted="yes").\
5042                     filter_by(id=console_id).\
5043                     options(joinedload('pool'))
5044 
5045     if instance_uuid is not None:
5046         query = query.filter_by(instance_uuid=instance_uuid)
5047 
5048     result = query.first()
5049 
5050     if not result:
5051         if instance_uuid:
5052             raise exception.ConsoleNotFoundForInstance(
5053                     instance_uuid=instance_uuid)
5054         else:
5055             raise exception.ConsoleNotFound(console_id=console_id)
5056 
5057     return result
5058 
5059 
5060 ##################
5061 
5062 
5063 @pick_context_manager_writer
5064 def flavor_create(context, values, projects=None):
5065     """Create a new instance type. In order to pass in extra specs,
5066     the values dict should contain a 'extra_specs' key/value pair:
5067 
5068     {'extra_specs' : {'k1': 'v1', 'k2': 'v2', ...}}
5069 
5070     """
5071     specs = values.get('extra_specs')
5072     specs_refs = []
5073     if specs:
5074         for k, v in specs.items():
5075             specs_ref = models.InstanceTypeExtraSpecs()
5076             specs_ref['key'] = k
5077             specs_ref['value'] = v
5078             specs_refs.append(specs_ref)
5079 
5080     values['extra_specs'] = specs_refs
5081     instance_type_ref = models.InstanceTypes()
5082     instance_type_ref.update(values)
5083 
5084     if projects is None:
5085         projects = []
5086 
5087     try:
5088         instance_type_ref.save(context.session)
5089     except db_exc.DBDuplicateEntry as e:
5090         if 'flavorid' in e.columns:
5091             raise exception.FlavorIdExists(flavor_id=values['flavorid'])
5092         raise exception.FlavorExists(name=values['name'])
5093     except Exception as e:
5094         raise db_exc.DBError(e)
5095     for project in set(projects):
5096         access_ref = models.InstanceTypeProjects()
5097         access_ref.update({"instance_type_id": instance_type_ref.id,
5098                            "project_id": project})
5099         access_ref.save(context.session)
5100 
5101     return _dict_with_extra_specs(instance_type_ref)
5102 
5103 
5104 def _dict_with_extra_specs(inst_type_query):
5105     """Takes an instance or instance type query returned
5106     by sqlalchemy and returns it as a dictionary, converting the
5107     extra_specs entry from a list of dicts:
5108 
5109     'extra_specs' : [{'key': 'k1', 'value': 'v1', ...}, ...]
5110 
5111     to a single dict:
5112 
5113     'extra_specs' : {'k1': 'v1'}
5114 
5115     """
5116     inst_type_dict = dict(inst_type_query)
5117     extra_specs = {x['key']: x['value']
5118                    for x in inst_type_query['extra_specs']}
5119     inst_type_dict['extra_specs'] = extra_specs
5120     return inst_type_dict
5121 
5122 
5123 def _flavor_get_query(context, read_deleted=None):
5124     query = model_query(context, models.InstanceTypes,
5125                        read_deleted=read_deleted).\
5126                        options(joinedload('extra_specs'))
5127     if not context.is_admin:
5128         the_filter = [models.InstanceTypes.is_public == true()]
5129         the_filter.extend([
5130             models.InstanceTypes.projects.any(project_id=context.project_id)
5131         ])
5132         query = query.filter(or_(*the_filter))
5133     return query
5134 
5135 
5136 @require_context
5137 @pick_context_manager_reader
5138 def flavor_get_all(context, inactive=False, filters=None,
5139                    sort_key='flavorid', sort_dir='asc', limit=None,
5140                    marker=None):
5141     """Returns all flavors.
5142     """
5143     filters = filters or {}
5144 
5145     # FIXME(sirp): now that we have the `disabled` field for flavors, we
5146     # should probably remove the use of `deleted` to mark inactive. `deleted`
5147     # should mean truly deleted, e.g. we can safely purge the record out of the
5148     # database.
5149     read_deleted = "yes" if inactive else "no"
5150 
5151     query = _flavor_get_query(context, read_deleted=read_deleted)
5152 
5153     if 'min_memory_mb' in filters:
5154         query = query.filter(
5155                 models.InstanceTypes.memory_mb >= filters['min_memory_mb'])
5156 
5157     if 'min_root_gb' in filters:
5158         query = query.filter(
5159                 models.InstanceTypes.root_gb >= filters['min_root_gb'])
5160 
5161     if 'disabled' in filters:
5162         query = query.filter(
5163                 models.InstanceTypes.disabled == filters['disabled'])
5164 
5165     if 'is_public' in filters and filters['is_public'] is not None:
5166         the_filter = [models.InstanceTypes.is_public == filters['is_public']]
5167         if filters['is_public'] and context.project_id is not None:
5168             the_filter.extend([
5169                 models.InstanceTypes.projects.any(
5170                     project_id=context.project_id, deleted=0)
5171             ])
5172         if len(the_filter) > 1:
5173             query = query.filter(or_(*the_filter))
5174         else:
5175             query = query.filter(the_filter[0])
5176 
5177     marker_row = None
5178     if marker is not None:
5179         marker_row = _flavor_get_query(context, read_deleted=read_deleted).\
5180                     filter_by(flavorid=marker).\
5181                     first()
5182         if not marker_row:
5183             raise exception.MarkerNotFound(marker=marker)
5184 
5185     query = sqlalchemyutils.paginate_query(query, models.InstanceTypes, limit,
5186                                            [sort_key, 'id'],
5187                                            marker=marker_row,
5188                                            sort_dir=sort_dir)
5189 
5190     inst_types = query.all()
5191 
5192     return [_dict_with_extra_specs(i) for i in inst_types]
5193 
5194 
5195 def _flavor_get_id_from_flavor_query(context, flavor_id):
5196     return model_query(context, models.InstanceTypes,
5197                        (models.InstanceTypes.id,),
5198                        read_deleted="no").\
5199                 filter_by(flavorid=flavor_id)
5200 
5201 
5202 def _flavor_get_id_from_flavor(context, flavor_id):
5203     result = _flavor_get_id_from_flavor_query(context, flavor_id).first()
5204     if not result:
5205         raise exception.FlavorNotFound(flavor_id=flavor_id)
5206     return result[0]
5207 
5208 
5209 @require_context
5210 @pick_context_manager_reader
5211 def flavor_get(context, id):
5212     """Returns a dict describing specific flavor."""
5213     result = _flavor_get_query(context).\
5214                         filter_by(id=id).\
5215                         first()
5216     if not result:
5217         raise exception.FlavorNotFound(flavor_id=id)
5218     return _dict_with_extra_specs(result)
5219 
5220 
5221 @require_context
5222 @pick_context_manager_reader
5223 def flavor_get_by_name(context, name):
5224     """Returns a dict describing specific flavor."""
5225     result = _flavor_get_query(context).\
5226                         filter_by(name=name).\
5227                         first()
5228     if not result:
5229         raise exception.FlavorNotFoundByName(flavor_name=name)
5230     return _dict_with_extra_specs(result)
5231 
5232 
5233 @require_context
5234 @pick_context_manager_reader
5235 def flavor_get_by_flavor_id(context, flavor_id, read_deleted):
5236     """Returns a dict describing specific flavor_id."""
5237     result = _flavor_get_query(context, read_deleted=read_deleted).\
5238                         filter_by(flavorid=flavor_id).\
5239                         order_by(asc(models.InstanceTypes.deleted),
5240                                  asc(models.InstanceTypes.id)).\
5241                         first()
5242     if not result:
5243         raise exception.FlavorNotFound(flavor_id=flavor_id)
5244     return _dict_with_extra_specs(result)
5245 
5246 
5247 @pick_context_manager_writer
5248 def flavor_destroy(context, flavor_id):
5249     """Marks specific flavor as deleted."""
5250     ref = model_query(context, models.InstanceTypes, read_deleted="no").\
5251                 filter_by(flavorid=flavor_id).\
5252                 first()
5253     if not ref:
5254         raise exception.FlavorNotFound(flavor_id=flavor_id)
5255 
5256     ref.soft_delete(context.session)
5257     model_query(context, models.InstanceTypeExtraSpecs, read_deleted="no").\
5258             filter_by(instance_type_id=ref['id']).\
5259             soft_delete()
5260     model_query(context, models.InstanceTypeProjects, read_deleted="no").\
5261             filter_by(instance_type_id=ref['id']).\
5262             soft_delete()
5263 
5264 
5265 def _flavor_access_query(context):
5266     return model_query(context, models.InstanceTypeProjects, read_deleted="no")
5267 
5268 
5269 @pick_context_manager_reader
5270 def flavor_access_get_by_flavor_id(context, flavor_id):
5271     """Get flavor access list by flavor id."""
5272     instance_type_id_subq = _flavor_get_id_from_flavor_query(context,
5273                                                              flavor_id)
5274     access_refs = _flavor_access_query(context).\
5275                         filter_by(instance_type_id=instance_type_id_subq).\
5276                         all()
5277     return access_refs
5278 
5279 
5280 @pick_context_manager_writer
5281 def flavor_access_add(context, flavor_id, project_id):
5282     """Add given tenant to the flavor access list."""
5283     instance_type_id = _flavor_get_id_from_flavor(context, flavor_id)
5284 
5285     access_ref = models.InstanceTypeProjects()
5286     access_ref.update({"instance_type_id": instance_type_id,
5287                        "project_id": project_id})
5288     try:
5289         access_ref.save(context.session)
5290     except db_exc.DBDuplicateEntry:
5291         raise exception.FlavorAccessExists(flavor_id=flavor_id,
5292                                             project_id=project_id)
5293     return access_ref
5294 
5295 
5296 @pick_context_manager_writer
5297 def flavor_access_remove(context, flavor_id, project_id):
5298     """Remove given tenant from the flavor access list."""
5299     instance_type_id = _flavor_get_id_from_flavor(context, flavor_id)
5300 
5301     count = _flavor_access_query(context).\
5302                     filter_by(instance_type_id=instance_type_id).\
5303                     filter_by(project_id=project_id).\
5304                     soft_delete(synchronize_session=False)
5305     if count == 0:
5306         raise exception.FlavorAccessNotFound(flavor_id=flavor_id,
5307                                              project_id=project_id)
5308 
5309 
5310 def _flavor_extra_specs_get_query(context, flavor_id):
5311     instance_type_id_subq = _flavor_get_id_from_flavor_query(context,
5312                                                              flavor_id)
5313 
5314     return model_query(context, models.InstanceTypeExtraSpecs,
5315                        read_deleted="no").\
5316                 filter_by(instance_type_id=instance_type_id_subq)
5317 
5318 
5319 @require_context
5320 @pick_context_manager_reader
5321 def flavor_extra_specs_get(context, flavor_id):
5322     rows = _flavor_extra_specs_get_query(context, flavor_id).all()
5323     return {row['key']: row['value'] for row in rows}
5324 
5325 
5326 @require_context
5327 @pick_context_manager_writer
5328 def flavor_extra_specs_delete(context, flavor_id, key):
5329     result = _flavor_extra_specs_get_query(context, flavor_id).\
5330                      filter(models.InstanceTypeExtraSpecs.key == key).\
5331                      soft_delete(synchronize_session=False)
5332     # did not find the extra spec
5333     if result == 0:
5334         raise exception.FlavorExtraSpecsNotFound(
5335                 extra_specs_key=key, flavor_id=flavor_id)
5336 
5337 
5338 @require_context
5339 @pick_context_manager_writer
5340 def flavor_extra_specs_update_or_create(context, flavor_id, specs,
5341                                                max_retries=10):
5342     for attempt in range(max_retries):
5343         try:
5344             instance_type_id = _flavor_get_id_from_flavor(context, flavor_id)
5345 
5346             spec_refs = model_query(context, models.InstanceTypeExtraSpecs,
5347                                     read_deleted="no").\
5348               filter_by(instance_type_id=instance_type_id).\
5349               filter(models.InstanceTypeExtraSpecs.key.in_(specs.keys())).\
5350               all()
5351 
5352             existing_keys = set()
5353             for spec_ref in spec_refs:
5354                 key = spec_ref["key"]
5355                 existing_keys.add(key)
5356                 with get_context_manager(context).writer.savepoint.using(
5357                         context):
5358                     spec_ref.update({"value": specs[key]})
5359 
5360             for key, value in specs.items():
5361                 if key in existing_keys:
5362                     continue
5363                 spec_ref = models.InstanceTypeExtraSpecs()
5364                 with get_context_manager(context).writer.savepoint.using(
5365                         context):
5366                     spec_ref.update({"key": key, "value": value,
5367                                      "instance_type_id": instance_type_id})
5368                     context.session.add(spec_ref)
5369 
5370             return specs
5371         except db_exc.DBDuplicateEntry:
5372             # a concurrent transaction has been committed,
5373             # try again unless this was the last attempt
5374             if attempt == max_retries - 1:
5375                 raise exception.FlavorExtraSpecUpdateCreateFailed(
5376                                     id=flavor_id, retries=max_retries)
5377 
5378 
5379 ####################
5380 
5381 
5382 @pick_context_manager_writer
5383 def cell_create(context, values):
5384     cell = models.Cell()
5385     cell.update(values)
5386     try:
5387         cell.save(context.session)
5388     except db_exc.DBDuplicateEntry:
5389         raise exception.CellExists(name=values['name'])
5390     return cell
5391 
5392 
5393 def _cell_get_by_name_query(context, cell_name):
5394     return model_query(context, models.Cell).filter_by(name=cell_name)
5395 
5396 
5397 @pick_context_manager_writer
5398 def cell_update(context, cell_name, values):
5399     cell_query = _cell_get_by_name_query(context, cell_name)
5400     if not cell_query.update(values):
5401         raise exception.CellNotFound(cell_name=cell_name)
5402     cell = cell_query.first()
5403     return cell
5404 
5405 
5406 @pick_context_manager_writer
5407 def cell_delete(context, cell_name):
5408     return _cell_get_by_name_query(context, cell_name).soft_delete()
5409 
5410 
5411 @pick_context_manager_reader
5412 def cell_get(context, cell_name):
5413     result = _cell_get_by_name_query(context, cell_name).first()
5414     if not result:
5415         raise exception.CellNotFound(cell_name=cell_name)
5416     return result
5417 
5418 
5419 @pick_context_manager_reader
5420 def cell_get_all(context):
5421     return model_query(context, models.Cell, read_deleted="no").all()
5422 
5423 
5424 ########################
5425 # User-provided metadata
5426 
5427 def _instance_metadata_get_multi(context, instance_uuids):
5428     if not instance_uuids:
5429         return []
5430     return model_query(context, models.InstanceMetadata).filter(
5431         models.InstanceMetadata.instance_uuid.in_(instance_uuids))
5432 
5433 
5434 def _instance_metadata_get_query(context, instance_uuid):
5435     return model_query(context, models.InstanceMetadata, read_deleted="no").\
5436                     filter_by(instance_uuid=instance_uuid)
5437 
5438 
5439 @require_context
5440 @pick_context_manager_reader
5441 def instance_metadata_get(context, instance_uuid):
5442     rows = _instance_metadata_get_query(context, instance_uuid).all()
5443     return {row['key']: row['value'] for row in rows}
5444 
5445 
5446 @require_context
5447 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
5448 @pick_context_manager_writer
5449 def instance_metadata_delete(context, instance_uuid, key):
5450     _instance_metadata_get_query(context, instance_uuid).\
5451         filter_by(key=key).\
5452         soft_delete()
5453 
5454 
5455 @require_context
5456 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
5457 @pick_context_manager_writer
5458 def instance_metadata_update(context, instance_uuid, metadata, delete):
5459     all_keys = metadata.keys()
5460     if delete:
5461         _instance_metadata_get_query(context, instance_uuid).\
5462             filter(~models.InstanceMetadata.key.in_(all_keys)).\
5463             soft_delete(synchronize_session=False)
5464 
5465     already_existing_keys = []
5466     meta_refs = _instance_metadata_get_query(context, instance_uuid).\
5467         filter(models.InstanceMetadata.key.in_(all_keys)).\
5468         all()
5469 
5470     for meta_ref in meta_refs:
5471         already_existing_keys.append(meta_ref.key)
5472         meta_ref.update({"value": metadata[meta_ref.key]})
5473 
5474     new_keys = set(all_keys) - set(already_existing_keys)
5475     for key in new_keys:
5476         meta_ref = models.InstanceMetadata()
5477         meta_ref.update({"key": key, "value": metadata[key],
5478                          "instance_uuid": instance_uuid})
5479         context.session.add(meta_ref)
5480 
5481     return metadata
5482 
5483 
5484 #######################
5485 # System-owned metadata
5486 
5487 
5488 def _instance_system_metadata_get_multi(context, instance_uuids):
5489     if not instance_uuids:
5490         return []
5491     return model_query(context, models.InstanceSystemMetadata,
5492                        read_deleted='yes').filter(
5493         models.InstanceSystemMetadata.instance_uuid.in_(instance_uuids))
5494 
5495 
5496 def _instance_system_metadata_get_query(context, instance_uuid):
5497     return model_query(context, models.InstanceSystemMetadata).\
5498                     filter_by(instance_uuid=instance_uuid)
5499 
5500 
5501 @require_context
5502 @pick_context_manager_reader
5503 def instance_system_metadata_get(context, instance_uuid):
5504     rows = _instance_system_metadata_get_query(context, instance_uuid).all()
5505     return {row['key']: row['value'] for row in rows}
5506 
5507 
5508 @require_context
5509 @pick_context_manager_writer
5510 def instance_system_metadata_update(context, instance_uuid, metadata, delete):
5511     all_keys = metadata.keys()
5512     if delete:
5513         _instance_system_metadata_get_query(context, instance_uuid).\
5514             filter(~models.InstanceSystemMetadata.key.in_(all_keys)).\
5515             soft_delete(synchronize_session=False)
5516 
5517     already_existing_keys = []
5518     meta_refs = _instance_system_metadata_get_query(context, instance_uuid).\
5519         filter(models.InstanceSystemMetadata.key.in_(all_keys)).\
5520         all()
5521 
5522     for meta_ref in meta_refs:
5523         already_existing_keys.append(meta_ref.key)
5524         meta_ref.update({"value": metadata[meta_ref.key]})
5525 
5526     new_keys = set(all_keys) - set(already_existing_keys)
5527     for key in new_keys:
5528         meta_ref = models.InstanceSystemMetadata()
5529         meta_ref.update({"key": key, "value": metadata[key],
5530                          "instance_uuid": instance_uuid})
5531         context.session.add(meta_ref)
5532 
5533     return metadata
5534 
5535 
5536 ####################
5537 
5538 
5539 @pick_context_manager_writer
5540 def agent_build_create(context, values):
5541     agent_build_ref = models.AgentBuild()
5542     agent_build_ref.update(values)
5543     try:
5544         agent_build_ref.save(context.session)
5545     except db_exc.DBDuplicateEntry:
5546         raise exception.AgentBuildExists(hypervisor=values['hypervisor'],
5547                         os=values['os'], architecture=values['architecture'])
5548     return agent_build_ref
5549 
5550 
5551 @pick_context_manager_reader
5552 def agent_build_get_by_triple(context, hypervisor, os, architecture):
5553     return model_query(context, models.AgentBuild, read_deleted="no").\
5554                    filter_by(hypervisor=hypervisor).\
5555                    filter_by(os=os).\
5556                    filter_by(architecture=architecture).\
5557                    first()
5558 
5559 
5560 @pick_context_manager_reader
5561 def agent_build_get_all(context, hypervisor=None):
5562     if hypervisor:
5563         return model_query(context, models.AgentBuild, read_deleted="no").\
5564                    filter_by(hypervisor=hypervisor).\
5565                    all()
5566     else:
5567         return model_query(context, models.AgentBuild, read_deleted="no").\
5568                    all()
5569 
5570 
5571 @pick_context_manager_writer
5572 def agent_build_destroy(context, agent_build_id):
5573     rows_affected = model_query(context, models.AgentBuild).filter_by(
5574                                         id=agent_build_id).soft_delete()
5575     if rows_affected == 0:
5576         raise exception.AgentBuildNotFound(id=agent_build_id)
5577 
5578 
5579 @pick_context_manager_writer
5580 def agent_build_update(context, agent_build_id, values):
5581     rows_affected = model_query(context, models.AgentBuild).\
5582                    filter_by(id=agent_build_id).\
5583                    update(values)
5584     if rows_affected == 0:
5585         raise exception.AgentBuildNotFound(id=agent_build_id)
5586 
5587 
5588 ####################
5589 
5590 @require_context
5591 @pick_context_manager_reader_allow_async
5592 def bw_usage_get(context, uuid, start_period, mac):
5593     values = {'start_period': start_period}
5594     values = convert_objects_related_datetimes(values, 'start_period')
5595     return model_query(context, models.BandwidthUsage, read_deleted="yes").\
5596                            filter_by(start_period=values['start_period']).\
5597                            filter_by(uuid=uuid).\
5598                            filter_by(mac=mac).\
5599                            first()
5600 
5601 
5602 @require_context
5603 @pick_context_manager_reader_allow_async
5604 def bw_usage_get_by_uuids(context, uuids, start_period):
5605     values = {'start_period': start_period}
5606     values = convert_objects_related_datetimes(values, 'start_period')
5607     return (
5608         model_query(context, models.BandwidthUsage, read_deleted="yes").
5609         filter(models.BandwidthUsage.uuid.in_(uuids)).
5610         filter_by(start_period=values['start_period']).
5611         all()
5612     )
5613 
5614 
5615 @require_context
5616 @oslo_db_api.wrap_db_retry(max_retries=5, retry_on_deadlock=True)
5617 @pick_context_manager_writer
5618 def bw_usage_update(context, uuid, mac, start_period, bw_in, bw_out,
5619                     last_ctr_in, last_ctr_out, last_refreshed=None):
5620 
5621     if last_refreshed is None:
5622         last_refreshed = timeutils.utcnow()
5623 
5624     # NOTE(comstud): More often than not, we'll be updating records vs
5625     # creating records.  Optimize accordingly, trying to update existing
5626     # records.  Fall back to creation when no rows are updated.
5627     ts_values = {'last_refreshed': last_refreshed,
5628                  'start_period': start_period}
5629     ts_keys = ('start_period', 'last_refreshed')
5630     ts_values = convert_objects_related_datetimes(ts_values, *ts_keys)
5631     values = {'last_refreshed': ts_values['last_refreshed'],
5632               'last_ctr_in': last_ctr_in,
5633               'last_ctr_out': last_ctr_out,
5634               'bw_in': bw_in,
5635               'bw_out': bw_out}
5636     # NOTE(pkholkin): order_by() is needed here to ensure that the
5637     # same record is updated every time. It can be removed after adding
5638     # unique constraint to this model.
5639     bw_usage = model_query(context, models.BandwidthUsage,
5640             read_deleted='yes').\
5641                     filter_by(start_period=ts_values['start_period']).\
5642                     filter_by(uuid=uuid).\
5643                     filter_by(mac=mac).\
5644                     order_by(asc(models.BandwidthUsage.id)).first()
5645 
5646     if bw_usage:
5647         bw_usage.update(values)
5648         return bw_usage
5649 
5650     bwusage = models.BandwidthUsage()
5651     bwusage.start_period = ts_values['start_period']
5652     bwusage.uuid = uuid
5653     bwusage.mac = mac
5654     bwusage.last_refreshed = ts_values['last_refreshed']
5655     bwusage.bw_in = bw_in
5656     bwusage.bw_out = bw_out
5657     bwusage.last_ctr_in = last_ctr_in
5658     bwusage.last_ctr_out = last_ctr_out
5659     bwusage.save(context.session)
5660 
5661     return bwusage
5662 
5663 
5664 ####################
5665 
5666 
5667 @require_context
5668 @pick_context_manager_reader
5669 def vol_get_usage_by_time(context, begin):
5670     """Return volumes usage that have been updated after a specified time."""
5671     return model_query(context, models.VolumeUsage, read_deleted="yes").\
5672                    filter(or_(models.VolumeUsage.tot_last_refreshed == null(),
5673                               models.VolumeUsage.tot_last_refreshed > begin,
5674                               models.VolumeUsage.curr_last_refreshed == null(),
5675                               models.VolumeUsage.curr_last_refreshed > begin,
5676                               )).all()
5677 
5678 
5679 @require_context
5680 @pick_context_manager_writer
5681 def vol_usage_update(context, id, rd_req, rd_bytes, wr_req, wr_bytes,
5682                      instance_id, project_id, user_id, availability_zone,
5683                      update_totals=False):
5684 
5685     refreshed = timeutils.utcnow()
5686 
5687     values = {}
5688     # NOTE(dricco): We will be mostly updating current usage records vs
5689     # updating total or creating records. Optimize accordingly.
5690     if not update_totals:
5691         values = {'curr_last_refreshed': refreshed,
5692                   'curr_reads': rd_req,
5693                   'curr_read_bytes': rd_bytes,
5694                   'curr_writes': wr_req,
5695                   'curr_write_bytes': wr_bytes,
5696                   'instance_uuid': instance_id,
5697                   'project_id': project_id,
5698                   'user_id': user_id,
5699                   'availability_zone': availability_zone}
5700     else:
5701         values = {'tot_last_refreshed': refreshed,
5702                   'tot_reads': models.VolumeUsage.tot_reads + rd_req,
5703                   'tot_read_bytes': models.VolumeUsage.tot_read_bytes +
5704                                     rd_bytes,
5705                   'tot_writes': models.VolumeUsage.tot_writes + wr_req,
5706                   'tot_write_bytes': models.VolumeUsage.tot_write_bytes +
5707                                      wr_bytes,
5708                   'curr_reads': 0,
5709                   'curr_read_bytes': 0,
5710                   'curr_writes': 0,
5711                   'curr_write_bytes': 0,
5712                   'instance_uuid': instance_id,
5713                   'project_id': project_id,
5714                   'user_id': user_id,
5715                   'availability_zone': availability_zone}
5716 
5717     current_usage = model_query(context, models.VolumeUsage,
5718                         read_deleted="yes").\
5719                         filter_by(volume_id=id).\
5720                         first()
5721     if current_usage:
5722         if (rd_req < current_usage['curr_reads'] or
5723             rd_bytes < current_usage['curr_read_bytes'] or
5724             wr_req < current_usage['curr_writes'] or
5725                 wr_bytes < current_usage['curr_write_bytes']):
5726             LOG.info("Volume(%s) has lower stats then what is in "
5727                      "the database. Instance must have been rebooted "
5728                      "or crashed. Updating totals.", id)
5729             if not update_totals:
5730                 values['tot_reads'] = (models.VolumeUsage.tot_reads +
5731                                        current_usage['curr_reads'])
5732                 values['tot_read_bytes'] = (
5733                     models.VolumeUsage.tot_read_bytes +
5734                     current_usage['curr_read_bytes'])
5735                 values['tot_writes'] = (models.VolumeUsage.tot_writes +
5736                                         current_usage['curr_writes'])
5737                 values['tot_write_bytes'] = (
5738                     models.VolumeUsage.tot_write_bytes +
5739                     current_usage['curr_write_bytes'])
5740             else:
5741                 values['tot_reads'] = (models.VolumeUsage.tot_reads +
5742                                        current_usage['curr_reads'] +
5743                                        rd_req)
5744                 values['tot_read_bytes'] = (
5745                     models.VolumeUsage.tot_read_bytes +
5746                     current_usage['curr_read_bytes'] + rd_bytes)
5747                 values['tot_writes'] = (models.VolumeUsage.tot_writes +
5748                                         current_usage['curr_writes'] +
5749                                         wr_req)
5750                 values['tot_write_bytes'] = (
5751                     models.VolumeUsage.tot_write_bytes +
5752                     current_usage['curr_write_bytes'] + wr_bytes)
5753 
5754         current_usage.update(values)
5755         current_usage.save(context.session)
5756         context.session.refresh(current_usage)
5757         return current_usage
5758 
5759     vol_usage = models.VolumeUsage()
5760     vol_usage.volume_id = id
5761     vol_usage.instance_uuid = instance_id
5762     vol_usage.project_id = project_id
5763     vol_usage.user_id = user_id
5764     vol_usage.availability_zone = availability_zone
5765 
5766     if not update_totals:
5767         vol_usage.curr_last_refreshed = refreshed
5768         vol_usage.curr_reads = rd_req
5769         vol_usage.curr_read_bytes = rd_bytes
5770         vol_usage.curr_writes = wr_req
5771         vol_usage.curr_write_bytes = wr_bytes
5772     else:
5773         vol_usage.tot_last_refreshed = refreshed
5774         vol_usage.tot_reads = rd_req
5775         vol_usage.tot_read_bytes = rd_bytes
5776         vol_usage.tot_writes = wr_req
5777         vol_usage.tot_write_bytes = wr_bytes
5778 
5779     vol_usage.save(context.session)
5780 
5781     return vol_usage
5782 
5783 
5784 ####################
5785 
5786 
5787 @pick_context_manager_reader
5788 def s3_image_get(context, image_id):
5789     """Find local s3 image represented by the provided id."""
5790     result = model_query(context, models.S3Image, read_deleted="yes").\
5791                  filter_by(id=image_id).\
5792                  first()
5793 
5794     if not result:
5795         raise exception.ImageNotFound(image_id=image_id)
5796 
5797     return result
5798 
5799 
5800 @pick_context_manager_reader
5801 def s3_image_get_by_uuid(context, image_uuid):
5802     """Find local s3 image represented by the provided uuid."""
5803     result = model_query(context, models.S3Image, read_deleted="yes").\
5804                  filter_by(uuid=image_uuid).\
5805                  first()
5806 
5807     if not result:
5808         raise exception.ImageNotFound(image_id=image_uuid)
5809 
5810     return result
5811 
5812 
5813 @pick_context_manager_writer
5814 def s3_image_create(context, image_uuid):
5815     """Create local s3 image represented by provided uuid."""
5816     try:
5817         s3_image_ref = models.S3Image()
5818         s3_image_ref.update({'uuid': image_uuid})
5819         s3_image_ref.save(context.session)
5820     except Exception as e:
5821         raise db_exc.DBError(e)
5822 
5823     return s3_image_ref
5824 
5825 
5826 ####################
5827 
5828 
5829 def _aggregate_get_query(context, model_class, id_field=None, id=None,
5830                          read_deleted=None):
5831     columns_to_join = {models.Aggregate: ['_hosts', '_metadata']}
5832 
5833     query = model_query(context, model_class, read_deleted=read_deleted)
5834 
5835     for c in columns_to_join.get(model_class, []):
5836         query = query.options(joinedload(c))
5837 
5838     if id and id_field:
5839         query = query.filter(id_field == id)
5840 
5841     return query
5842 
5843 
5844 @pick_context_manager_writer
5845 def aggregate_create(context, values, metadata=None):
5846     query = _aggregate_get_query(context,
5847                                  models.Aggregate,
5848                                  models.Aggregate.name,
5849                                  values['name'],
5850                                  read_deleted='no')
5851     aggregate = query.first()
5852     if not aggregate:
5853         aggregate = models.Aggregate()
5854         aggregate.update(values)
5855         aggregate.save(context.session)
5856         # We don't want these to be lazy loaded later.  We know there is
5857         # nothing here since we just created this aggregate.
5858         aggregate._hosts = []
5859         aggregate._metadata = []
5860     else:
5861         raise exception.AggregateNameExists(aggregate_name=values['name'])
5862     if metadata:
5863         aggregate_metadata_add(context, aggregate.id, metadata)
5864         # NOTE(pkholkin): '_metadata' attribute was updated during
5865         # 'aggregate_metadata_add' method, so it should be expired and
5866         # read from db
5867         context.session.expire(aggregate, ['_metadata'])
5868         aggregate._metadata
5869 
5870     return aggregate
5871 
5872 
5873 @pick_context_manager_reader
5874 def aggregate_get(context, aggregate_id):
5875     query = _aggregate_get_query(context,
5876                                  models.Aggregate,
5877                                  models.Aggregate.id,
5878                                  aggregate_id)
5879     aggregate = query.first()
5880 
5881     if not aggregate:
5882         raise exception.AggregateNotFound(aggregate_id=aggregate_id)
5883 
5884     return aggregate
5885 
5886 
5887 @pick_context_manager_reader
5888 def aggregate_get_by_uuid(context, uuid):
5889     query = _aggregate_get_query(context,
5890                                  models.Aggregate,
5891                                  models.Aggregate.uuid,
5892                                  uuid)
5893     aggregate = query.first()
5894 
5895     if not aggregate:
5896         raise exception.AggregateNotFound(aggregate_id=uuid)
5897 
5898     return aggregate
5899 
5900 
5901 @pick_context_manager_reader
5902 def aggregate_get_by_host(context, host, key=None):
5903     """Return rows that match host (mandatory) and metadata key (optional).
5904 
5905     :param host matches host, and is required.
5906     :param key Matches metadata key, if not None.
5907     """
5908     query = model_query(context, models.Aggregate)
5909     query = query.options(joinedload('_hosts'))
5910     query = query.options(joinedload('_metadata'))
5911     query = query.join('_hosts')
5912     query = query.filter(models.AggregateHost.host == host)
5913 
5914     if key:
5915         query = query.join("_metadata").filter(
5916             models.AggregateMetadata.key == key)
5917     return query.all()
5918 
5919 
5920 @pick_context_manager_reader
5921 def aggregate_metadata_get_by_host(context, host, key=None):
5922     query = model_query(context, models.Aggregate)
5923     query = query.join("_hosts")
5924     query = query.join("_metadata")
5925     query = query.filter(models.AggregateHost.host == host)
5926     query = query.options(contains_eager("_metadata"))
5927 
5928     if key:
5929         query = query.filter(models.AggregateMetadata.key == key)
5930     rows = query.all()
5931 
5932     metadata = collections.defaultdict(set)
5933     for agg in rows:
5934         for kv in agg._metadata:
5935             metadata[kv['key']].add(kv['value'])
5936     return dict(metadata)
5937 
5938 
5939 @pick_context_manager_reader
5940 def aggregate_get_by_metadata_key(context, key):
5941     """Return rows that match metadata key.
5942 
5943     :param key Matches metadata key.
5944     """
5945     query = model_query(context, models.Aggregate)
5946     query = query.join("_metadata")
5947     query = query.filter(models.AggregateMetadata.key == key)
5948     query = query.options(contains_eager("_metadata"))
5949     query = query.options(joinedload("_hosts"))
5950     return query.all()
5951 
5952 
5953 @pick_context_manager_writer
5954 def aggregate_update(context, aggregate_id, values):
5955     if "name" in values:
5956         aggregate_by_name = (_aggregate_get_query(context,
5957                                                   models.Aggregate,
5958                                                   models.Aggregate.name,
5959                                                   values['name'],
5960                                                   read_deleted='no').first())
5961         if aggregate_by_name and aggregate_by_name.id != aggregate_id:
5962             # there is another aggregate with the new name
5963             raise exception.AggregateNameExists(aggregate_name=values['name'])
5964 
5965     aggregate = (_aggregate_get_query(context,
5966                                      models.Aggregate,
5967                                      models.Aggregate.id,
5968                                      aggregate_id).first())
5969 
5970     set_delete = True
5971     if aggregate:
5972         if "availability_zone" in values:
5973             az = values.pop('availability_zone')
5974             if 'metadata' not in values:
5975                 values['metadata'] = {'availability_zone': az}
5976                 set_delete = False
5977             else:
5978                 values['metadata']['availability_zone'] = az
5979         metadata = values.get('metadata')
5980         if metadata is not None:
5981             aggregate_metadata_add(context,
5982                                    aggregate_id,
5983                                    values.pop('metadata'),
5984                                    set_delete=set_delete)
5985 
5986         aggregate.update(values)
5987         aggregate.save(context.session)
5988         return aggregate_get(context, aggregate.id)
5989     else:
5990         raise exception.AggregateNotFound(aggregate_id=aggregate_id)
5991 
5992 
5993 @pick_context_manager_writer
5994 def aggregate_delete(context, aggregate_id):
5995     count = _aggregate_get_query(context,
5996                                  models.Aggregate,
5997                                  models.Aggregate.id,
5998                                  aggregate_id).\
5999                 soft_delete()
6000     if count == 0:
6001         raise exception.AggregateNotFound(aggregate_id=aggregate_id)
6002 
6003     # Delete Metadata
6004     model_query(context, models.AggregateMetadata).\
6005                 filter_by(aggregate_id=aggregate_id).\
6006                 soft_delete()
6007 
6008 
6009 @pick_context_manager_reader
6010 def aggregate_get_all(context):
6011     return _aggregate_get_query(context, models.Aggregate).all()
6012 
6013 
6014 def _aggregate_metadata_get_query(context, aggregate_id, read_deleted="yes"):
6015     return model_query(context,
6016                        models.AggregateMetadata,
6017                        read_deleted=read_deleted).\
6018                 filter_by(aggregate_id=aggregate_id)
6019 
6020 
6021 @require_aggregate_exists
6022 @pick_context_manager_reader
6023 def aggregate_metadata_get(context, aggregate_id):
6024     rows = model_query(context,
6025                        models.AggregateMetadata).\
6026                        filter_by(aggregate_id=aggregate_id).all()
6027 
6028     return {r['key']: r['value'] for r in rows}
6029 
6030 
6031 @require_aggregate_exists
6032 @pick_context_manager_writer
6033 def aggregate_metadata_delete(context, aggregate_id, key):
6034     count = _aggregate_get_query(context,
6035                                  models.AggregateMetadata,
6036                                  models.AggregateMetadata.aggregate_id,
6037                                  aggregate_id).\
6038                                  filter_by(key=key).\
6039                                  soft_delete()
6040     if count == 0:
6041         raise exception.AggregateMetadataNotFound(aggregate_id=aggregate_id,
6042                                                   metadata_key=key)
6043 
6044 
6045 @require_aggregate_exists
6046 @pick_context_manager_writer
6047 def aggregate_metadata_add(context, aggregate_id, metadata, set_delete=False,
6048                            max_retries=10):
6049     all_keys = metadata.keys()
6050     for attempt in range(max_retries):
6051         try:
6052             query = _aggregate_metadata_get_query(context, aggregate_id,
6053                                                   read_deleted='no')
6054             if set_delete:
6055                 query.filter(~models.AggregateMetadata.key.in_(all_keys)).\
6056                     soft_delete(synchronize_session=False)
6057 
6058             already_existing_keys = set()
6059             if all_keys:
6060                 query = query.filter(
6061                     models.AggregateMetadata.key.in_(all_keys))
6062                 for meta_ref in query.all():
6063                     key = meta_ref.key
6064                     meta_ref.update({"value": metadata[key]})
6065                     already_existing_keys.add(key)
6066 
6067             new_entries = []
6068             for key, value in metadata.items():
6069                 if key in already_existing_keys:
6070                     continue
6071                 new_entries.append({"key": key,
6072                                     "value": value,
6073                                     "aggregate_id": aggregate_id})
6074             if new_entries:
6075                 context.session.execute(
6076                     models.AggregateMetadata.__table__.insert(),
6077                     new_entries)
6078 
6079             return metadata
6080         except db_exc.DBDuplicateEntry:
6081             # a concurrent transaction has been committed,
6082             # try again unless this was the last attempt
6083             with excutils.save_and_reraise_exception() as ctxt:
6084                 if attempt < max_retries - 1:
6085                     ctxt.reraise = False
6086                 else:
6087                     LOG.warning("Add metadata failed for aggregate %(id)s "
6088                                 "after %(retries)s retries",
6089                                 {"id": aggregate_id, "retries": max_retries})
6090 
6091 
6092 @require_aggregate_exists
6093 @pick_context_manager_reader
6094 def aggregate_host_get_all(context, aggregate_id):
6095     rows = model_query(context,
6096                        models.AggregateHost).\
6097                        filter_by(aggregate_id=aggregate_id).all()
6098 
6099     return [r.host for r in rows]
6100 
6101 
6102 @require_aggregate_exists
6103 @pick_context_manager_writer
6104 def aggregate_host_delete(context, aggregate_id, host):
6105     count = _aggregate_get_query(context,
6106                                  models.AggregateHost,
6107                                  models.AggregateHost.aggregate_id,
6108                                  aggregate_id).\
6109             filter_by(host=host).\
6110             soft_delete()
6111     if count == 0:
6112         raise exception.AggregateHostNotFound(aggregate_id=aggregate_id,
6113                                               host=host)
6114 
6115 
6116 @require_aggregate_exists
6117 @pick_context_manager_writer
6118 def aggregate_host_add(context, aggregate_id, host):
6119     host_ref = models.AggregateHost()
6120     host_ref.update({"host": host, "aggregate_id": aggregate_id})
6121     try:
6122         host_ref.save(context.session)
6123     except db_exc.DBDuplicateEntry:
6124         raise exception.AggregateHostExists(host=host,
6125                                             aggregate_id=aggregate_id)
6126     return host_ref
6127 
6128 
6129 ################
6130 
6131 
6132 @pick_context_manager_writer
6133 def instance_fault_create(context, values):
6134     """Create a new InstanceFault."""
6135     fault_ref = models.InstanceFault()
6136     fault_ref.update(values)
6137     fault_ref.save(context.session)
6138     return dict(fault_ref)
6139 
6140 
6141 @pick_context_manager_reader
6142 def instance_fault_get_by_instance_uuids(context, instance_uuids,
6143                                          latest=False):
6144     """Get all instance faults for the provided instance_uuids.
6145 
6146     :param instance_uuids: List of UUIDs of instances to grab faults for
6147     :param latest: Optional boolean indicating we should only return the latest
6148                    fault for the instance
6149     """
6150     if not instance_uuids:
6151         return {}
6152 
6153     faults_tbl = models.InstanceFault.__table__
6154     # NOTE(rpodolyaka): filtering by instance_uuids is performed in both
6155     # code branches below for the sake of a better query plan. On change,
6156     # make sure to update the other one as well.
6157     query = model_query(context, models.InstanceFault,
6158                         [faults_tbl],
6159                         read_deleted='no')
6160 
6161     if latest:
6162         # NOTE(jaypipes): We join instance_faults to a derived table of the
6163         # latest faults per instance UUID. The SQL produced below looks like
6164         # this:
6165         #
6166         #  SELECT instance_faults.*
6167         #  FROM instance_faults
6168         #  JOIN (
6169         #    SELECT instance_uuid, MAX(id) AS max_id
6170         #    FROM instance_faults
6171         #    WHERE instance_uuid IN ( ... )
6172         #    AND deleted = 0
6173         #    GROUP BY instance_uuid
6174         #  ) AS latest_faults
6175         #    ON instance_faults.id = latest_faults.max_id;
6176         latest_faults = model_query(
6177             context, models.InstanceFault,
6178             [faults_tbl.c.instance_uuid,
6179              sql.func.max(faults_tbl.c.id).label('max_id')],
6180             read_deleted='no'
6181         ).filter(
6182             faults_tbl.c.instance_uuid.in_(instance_uuids)
6183         ).group_by(
6184             faults_tbl.c.instance_uuid
6185         ).subquery(name="latest_faults")
6186 
6187         query = query.join(latest_faults,
6188                            faults_tbl.c.id == latest_faults.c.max_id)
6189     else:
6190         query = query.filter(models.InstanceFault.instance_uuid.in_(
6191                                         instance_uuids)).order_by(desc("id"))
6192 
6193     output = {}
6194     for instance_uuid in instance_uuids:
6195         output[instance_uuid] = []
6196 
6197     for row in query:
6198         output[row.instance_uuid].append(row._asdict())
6199 
6200     return output
6201 
6202 
6203 ##################
6204 
6205 
6206 @pick_context_manager_writer
6207 def action_start(context, values):
6208     convert_objects_related_datetimes(values, 'start_time', 'updated_at')
6209     action_ref = models.InstanceAction()
6210     action_ref.update(values)
6211     action_ref.save(context.session)
6212     return action_ref
6213 
6214 
6215 @pick_context_manager_writer
6216 def action_finish(context, values):
6217     convert_objects_related_datetimes(values, 'start_time', 'finish_time',
6218                                       'updated_at')
6219     query = model_query(context, models.InstanceAction).\
6220                         filter_by(instance_uuid=values['instance_uuid']).\
6221                         filter_by(request_id=values['request_id'])
6222     if query.update(values) != 1:
6223         raise exception.InstanceActionNotFound(
6224                                     request_id=values['request_id'],
6225                                     instance_uuid=values['instance_uuid'])
6226     return query.one()
6227 
6228 
6229 @pick_context_manager_reader
6230 def actions_get(context, instance_uuid):
6231     """Get all instance actions for the provided uuid."""
6232     actions = model_query(context, models.InstanceAction).\
6233                           filter_by(instance_uuid=instance_uuid).\
6234                           order_by(desc("created_at"), desc("id")).\
6235                           all()
6236     return actions
6237 
6238 
6239 @pick_context_manager_reader
6240 def action_get_by_request_id(context, instance_uuid, request_id):
6241     """Get the action by request_id and given instance."""
6242     action = _action_get_by_request_id(context, instance_uuid, request_id)
6243     return action
6244 
6245 
6246 def _action_get_by_request_id(context, instance_uuid, request_id):
6247     result = model_query(context, models.InstanceAction).\
6248                          filter_by(instance_uuid=instance_uuid).\
6249                          filter_by(request_id=request_id).\
6250                          first()
6251     return result
6252 
6253 
6254 def _action_get_last_created_by_instance_uuid(context, instance_uuid):
6255     result = (model_query(context, models.InstanceAction).
6256                      filter_by(instance_uuid=instance_uuid).
6257                      order_by(desc("created_at"), desc("id")).
6258                      first())
6259     return result
6260 
6261 
6262 @pick_context_manager_writer
6263 def action_event_start(context, values):
6264     """Start an event on an instance action."""
6265     convert_objects_related_datetimes(values, 'start_time')
6266     action = _action_get_by_request_id(context, values['instance_uuid'],
6267                                        values['request_id'])
6268     # When nova-compute restarts, the context is generated again in
6269     # init_host workflow, the request_id was different with the request_id
6270     # recorded in InstanceAction, so we can't get the original record
6271     # according to request_id. Try to get the last created action so that
6272     # init_instance can continue to finish the recovery action, like:
6273     # powering_off, unpausing, and so on.
6274     if not action and not context.project_id:
6275         action = _action_get_last_created_by_instance_uuid(
6276             context, values['instance_uuid'])
6277 
6278     if not action:
6279         raise exception.InstanceActionNotFound(
6280                                     request_id=values['request_id'],
6281                                     instance_uuid=values['instance_uuid'])
6282 
6283     values['action_id'] = action['id']
6284 
6285     event_ref = models.InstanceActionEvent()
6286     event_ref.update(values)
6287     context.session.add(event_ref)
6288 
6289     # Update action updated_at.
6290     action.update({'updated_at': values['start_time']})
6291     action.save(context.session)
6292 
6293     return event_ref
6294 
6295 
6296 @pick_context_manager_writer
6297 def action_event_finish(context, values):
6298     """Finish an event on an instance action."""
6299     convert_objects_related_datetimes(values, 'start_time', 'finish_time')
6300     action = _action_get_by_request_id(context, values['instance_uuid'],
6301                                        values['request_id'])
6302     # When nova-compute restarts, the context is generated again in
6303     # init_host workflow, the request_id was different with the request_id
6304     # recorded in InstanceAction, so we can't get the original record
6305     # according to request_id. Try to get the last created action so that
6306     # init_instance can continue to finish the recovery action, like:
6307     # powering_off, unpausing, and so on.
6308     if not action and not context.project_id:
6309         action = _action_get_last_created_by_instance_uuid(
6310             context, values['instance_uuid'])
6311 
6312     if not action:
6313         raise exception.InstanceActionNotFound(
6314                                     request_id=values['request_id'],
6315                                     instance_uuid=values['instance_uuid'])
6316 
6317     event_ref = model_query(context, models.InstanceActionEvent).\
6318                             filter_by(action_id=action['id']).\
6319                             filter_by(event=values['event']).\
6320                             first()
6321 
6322     if not event_ref:
6323         raise exception.InstanceActionEventNotFound(action_id=action['id'],
6324                                                     event=values['event'])
6325     event_ref.update(values)
6326 
6327     if values['result'].lower() == 'error':
6328         action.update({'message': 'Error'})
6329 
6330     # Update action updated_at.
6331     action.update({'updated_at': values['finish_time']})
6332     action.save(context.session)
6333 
6334     return event_ref
6335 
6336 
6337 @pick_context_manager_reader
6338 def action_events_get(context, action_id):
6339     events = model_query(context, models.InstanceActionEvent).\
6340                          filter_by(action_id=action_id).\
6341                          order_by(desc("created_at"), desc("id")).\
6342                          all()
6343 
6344     return events
6345 
6346 
6347 @pick_context_manager_reader
6348 def action_event_get_by_id(context, action_id, event_id):
6349     event = model_query(context, models.InstanceActionEvent).\
6350                         filter_by(action_id=action_id).\
6351                         filter_by(id=event_id).\
6352                         first()
6353 
6354     return event
6355 
6356 
6357 ##################
6358 
6359 
6360 @require_context
6361 @pick_context_manager_writer
6362 def ec2_instance_create(context, instance_uuid, id=None):
6363     """Create ec2 compatible instance by provided uuid."""
6364     ec2_instance_ref = models.InstanceIdMapping()
6365     ec2_instance_ref.update({'uuid': instance_uuid})
6366     if id is not None:
6367         ec2_instance_ref.update({'id': id})
6368 
6369     ec2_instance_ref.save(context.session)
6370 
6371     return ec2_instance_ref
6372 
6373 
6374 @require_context
6375 @pick_context_manager_reader
6376 def ec2_instance_get_by_uuid(context, instance_uuid):
6377     result = _ec2_instance_get_query(context).\
6378                     filter_by(uuid=instance_uuid).\
6379                     first()
6380 
6381     if not result:
6382         raise exception.InstanceNotFound(instance_id=instance_uuid)
6383 
6384     return result
6385 
6386 
6387 @require_context
6388 @pick_context_manager_reader
6389 def ec2_instance_get_by_id(context, instance_id):
6390     result = _ec2_instance_get_query(context).\
6391                     filter_by(id=instance_id).\
6392                     first()
6393 
6394     if not result:
6395         raise exception.InstanceNotFound(instance_id=instance_id)
6396 
6397     return result
6398 
6399 
6400 @require_context
6401 @pick_context_manager_reader
6402 def get_instance_uuid_by_ec2_id(context, ec2_id):
6403     result = ec2_instance_get_by_id(context, ec2_id)
6404     return result['uuid']
6405 
6406 
6407 def _ec2_instance_get_query(context):
6408     return model_query(context, models.InstanceIdMapping, read_deleted='yes')
6409 
6410 
6411 ##################
6412 
6413 
6414 def _task_log_get_query(context, task_name, period_beginning,
6415                         period_ending, host=None, state=None):
6416     values = {'period_beginning': period_beginning,
6417               'period_ending': period_ending}
6418     values = convert_objects_related_datetimes(values, *values.keys())
6419 
6420     query = model_query(context, models.TaskLog).\
6421                      filter_by(task_name=task_name).\
6422                      filter_by(period_beginning=values['period_beginning']).\
6423                      filter_by(period_ending=values['period_ending'])
6424     if host is not None:
6425         query = query.filter_by(host=host)
6426     if state is not None:
6427         query = query.filter_by(state=state)
6428     return query
6429 
6430 
6431 @pick_context_manager_reader
6432 def task_log_get(context, task_name, period_beginning, period_ending, host,
6433                  state=None):
6434     return _task_log_get_query(context, task_name, period_beginning,
6435                                period_ending, host, state).first()
6436 
6437 
6438 @pick_context_manager_reader
6439 def task_log_get_all(context, task_name, period_beginning, period_ending,
6440                      host=None, state=None):
6441     return _task_log_get_query(context, task_name, period_beginning,
6442                                period_ending, host, state).all()
6443 
6444 
6445 @pick_context_manager_writer
6446 def task_log_begin_task(context, task_name, period_beginning, period_ending,
6447                         host, task_items=None, message=None):
6448     values = {'period_beginning': period_beginning,
6449               'period_ending': period_ending}
6450     values = convert_objects_related_datetimes(values, *values.keys())
6451 
6452     task = models.TaskLog()
6453     task.task_name = task_name
6454     task.period_beginning = values['period_beginning']
6455     task.period_ending = values['period_ending']
6456     task.host = host
6457     task.state = "RUNNING"
6458     if message:
6459         task.message = message
6460     if task_items:
6461         task.task_items = task_items
6462     try:
6463         task.save(context.session)
6464     except db_exc.DBDuplicateEntry:
6465         raise exception.TaskAlreadyRunning(task_name=task_name, host=host)
6466 
6467 
6468 @pick_context_manager_writer
6469 def task_log_end_task(context, task_name, period_beginning, period_ending,
6470                       host, errors, message=None):
6471     values = dict(state="DONE", errors=errors)
6472     if message:
6473         values["message"] = message
6474 
6475     rows = _task_log_get_query(context, task_name, period_beginning,
6476                                period_ending, host).update(values)
6477     if rows == 0:
6478         # It's not running!
6479         raise exception.TaskNotRunning(task_name=task_name, host=host)
6480 
6481 
6482 ##################
6483 
6484 
6485 def _archive_if_instance_deleted(table, shadow_table, instances, conn,
6486                                  max_rows):
6487     """Look for records that pertain to deleted instances, but may not be
6488     deleted themselves. This catches cases where we delete an instance,
6489     but leave some residue because of a failure in a cleanup path or
6490     similar.
6491 
6492     Logic is: if I have a column called instance_uuid, and that instance
6493     is deleted, then I can be deleted.
6494     """
6495     query_insert = shadow_table.insert(inline=True).\
6496         from_select(
6497             [c.name for c in table.c],
6498             sql.select(
6499                 [table],
6500                 and_(instances.c.deleted != instances.c.deleted.default.arg,
6501                      instances.c.uuid == table.c.instance_uuid)).
6502             order_by(table.c.id).limit(max_rows))
6503 
6504     query_delete = sql.select(
6505         [table.c.id],
6506         and_(instances.c.deleted != instances.c.deleted.default.arg,
6507              instances.c.uuid == table.c.instance_uuid)).\
6508         order_by(table.c.id).limit(max_rows)
6509     delete_statement = DeleteFromSelect(table, query_delete,
6510                                         table.c.id)
6511 
6512     try:
6513         with conn.begin():
6514             conn.execute(query_insert)
6515             result_delete = conn.execute(delete_statement)
6516             return result_delete.rowcount
6517     except db_exc.DBReferenceError as ex:
6518         LOG.warning('Failed to archive %(table)s: %(error)s',
6519                     {'table': table.__tablename__,
6520                      'error': six.text_type(ex)})
6521         return 0
6522 
6523 
6524 def _archive_deleted_rows_for_table(tablename, max_rows):
6525     """Move up to max_rows rows from one tables to the corresponding
6526     shadow table.
6527 
6528     :returns: number of rows archived
6529     """
6530     engine = get_engine()
6531     conn = engine.connect()
6532     metadata = MetaData()
6533     metadata.bind = engine
6534     # NOTE(tdurakov): table metadata should be received
6535     # from models, not db tables. Default value specified by SoftDeleteMixin
6536     # is known only by models, not DB layer.
6537     # IMPORTANT: please do not change source of metadata information for table.
6538     table = models.BASE.metadata.tables[tablename]
6539 
6540     shadow_tablename = _SHADOW_TABLE_PREFIX + tablename
6541     rows_archived = 0
6542     deleted_instance_uuids = []
6543     try:
6544         shadow_table = Table(shadow_tablename, metadata, autoload=True)
6545     except NoSuchTableError:
6546         # No corresponding shadow table; skip it.
6547         return rows_archived, deleted_instance_uuids
6548 
6549     if tablename == "dns_domains":
6550         # We have one table (dns_domains) where the key is called
6551         # "domain" rather than "id"
6552         column = table.c.domain
6553     else:
6554         column = table.c.id
6555     # NOTE(guochbo): Use DeleteFromSelect to avoid
6556     # database's limit of maximum parameter in one SQL statement.
6557     deleted_column = table.c.deleted
6558     columns = [c.name for c in table.c]
6559 
6560     # NOTE(clecomte): Tables instance_actions and instances_actions_events
6561     # have to be manage differently so we soft-delete them here to let
6562     # the archive work the same for all tables
6563     # NOTE(takashin): The record in table migrations should be
6564     # soft deleted when the instance is deleted.
6565     # This is just for upgrading.
6566     if tablename in ("instance_actions", "migrations"):
6567         instances = models.BASE.metadata.tables["instances"]
6568         deleted_instances = sql.select([instances.c.uuid]).\
6569             where(instances.c.deleted != instances.c.deleted.default.arg)
6570         update_statement = table.update().values(deleted=table.c.id).\
6571             where(table.c.instance_uuid.in_(deleted_instances))
6572 
6573         conn.execute(update_statement)
6574 
6575     elif tablename == "instance_actions_events":
6576         # NOTE(clecomte): we have to grab all the relation from
6577         # instances because instance_actions_events rely on
6578         # action_id and not uuid
6579         instances = models.BASE.metadata.tables["instances"]
6580         instance_actions = models.BASE.metadata.tables["instance_actions"]
6581         deleted_instances = sql.select([instances.c.uuid]).\
6582             where(instances.c.deleted != instances.c.deleted.default.arg)
6583         deleted_actions = sql.select([instance_actions.c.id]).\
6584             where(instance_actions.c.instance_uuid.in_(deleted_instances))
6585 
6586         update_statement = table.update().values(deleted=table.c.id).\
6587             where(table.c.action_id.in_(deleted_actions))
6588 
6589         conn.execute(update_statement)
6590 
6591     insert = shadow_table.insert(inline=True).\
6592         from_select(columns,
6593                     sql.select([table],
6594                                deleted_column != deleted_column.default.arg).
6595                     order_by(column).limit(max_rows))
6596     query_delete = sql.select([column],
6597                           deleted_column != deleted_column.default.arg).\
6598                           order_by(column).limit(max_rows)
6599 
6600     delete_statement = DeleteFromSelect(table, query_delete, column)
6601 
6602     # NOTE(tssurya): In order to facilitate the deletion of records from
6603     # instance_mappings table in the nova_api DB, the rows of deleted instances
6604     # from the instances table are stored prior to their deletion from
6605     # the instances table. Basically the uuids of the archived instances
6606     # are queried and returned.
6607     if tablename == "instances":
6608         query_delete = query_delete.column(table.c.uuid)
6609         rows = conn.execute(query_delete).fetchall()
6610         deleted_instance_uuids = [r[1] for r in rows]
6611 
6612     try:
6613         # Group the insert and delete in a transaction.
6614         with conn.begin():
6615             conn.execute(insert)
6616             if tablename == "instances":
6617                 delete_statement = table.delete().where(table.c.uuid.in_(
6618                                                 deleted_instance_uuids))
6619             result_delete = conn.execute(delete_statement)
6620         rows_archived = result_delete.rowcount
6621     except db_exc.DBReferenceError as ex:
6622         # A foreign key constraint keeps us from deleting some of
6623         # these rows until we clean up a dependent table.  Just
6624         # skip this table for now; we'll come back to it later.
6625         LOG.warning("IntegrityError detected when archiving table "
6626                     "%(tablename)s: %(error)s",
6627                     {'tablename': tablename, 'error': six.text_type(ex)})
6628 
6629     if ((max_rows is None or rows_archived < max_rows)
6630             and 'instance_uuid' in columns):
6631         instances = models.BASE.metadata.tables['instances']
6632         limit = max_rows - rows_archived if max_rows is not None else None
6633         extra = _archive_if_instance_deleted(table, shadow_table, instances,
6634                                              conn, limit)
6635         rows_archived += extra
6636 
6637     return rows_archived, deleted_instance_uuids
6638 
6639 
6640 def archive_deleted_rows(max_rows=None):
6641     """Move up to max_rows rows from production tables to the corresponding
6642     shadow tables.
6643 
6644     :returns: dict that maps table name to number of rows archived from that
6645               table, for example:
6646 
6647     ::
6648 
6649         {
6650             'instances': 5,
6651             'block_device_mapping': 5,
6652             'pci_devices': 2,
6653         }
6654 
6655     """
6656     table_to_rows_archived = {}
6657     deleted_instance_uuids = []
6658     total_rows_archived = 0
6659     meta = MetaData(get_engine(use_slave=True))
6660     meta.reflect()
6661     # Reverse sort the tables so we get the leaf nodes first for processing.
6662     for table in reversed(meta.sorted_tables):
6663         tablename = table.name
6664         rows_archived = 0
6665         # skip the special sqlalchemy-migrate migrate_version table and any
6666         # shadow tables
6667         if (tablename == 'migrate_version' or
6668                 tablename.startswith(_SHADOW_TABLE_PREFIX)):
6669             continue
6670         rows_archived,\
6671         deleted_instance_uuid = _archive_deleted_rows_for_table(
6672                 tablename, max_rows=max_rows - total_rows_archived)
6673         total_rows_archived += rows_archived
6674         if tablename == 'instances':
6675             deleted_instance_uuids = deleted_instance_uuid
6676         # Only report results for tables that had updates.
6677         if rows_archived:
6678             table_to_rows_archived[tablename] = rows_archived
6679         if total_rows_archived >= max_rows:
6680             break
6681     return table_to_rows_archived, deleted_instance_uuids
6682 
6683 
6684 @pick_context_manager_writer
6685 def service_uuids_online_data_migration(context, max_count):
6686     from nova.objects import service
6687 
6688     count_all = 0
6689     count_hit = 0
6690 
6691     db_services = model_query(context, models.Service).filter_by(
6692         uuid=None).limit(max_count)
6693     for db_service in db_services:
6694         count_all += 1
6695         service_obj = service.Service._from_db_object(
6696             context, service.Service(), db_service)
6697         if 'uuid' in service_obj:
6698             count_hit += 1
6699     return count_all, count_hit
6700 
6701 
6702 ####################
6703 
6704 
6705 def _instance_group_get_query(context, model_class, id_field=None, id=None,
6706                               read_deleted=None):
6707     columns_to_join = {models.InstanceGroup: ['_policies', '_members']}
6708     query = model_query(context, model_class, read_deleted=read_deleted,
6709                         project_only=True)
6710     for c in columns_to_join.get(model_class, []):
6711         query = query.options(joinedload(c))
6712 
6713     if id and id_field:
6714         query = query.filter(id_field == id)
6715 
6716     return query
6717 
6718 
6719 @pick_context_manager_writer
6720 def instance_group_create(context, values, policies=None, members=None):
6721     """Create a new group."""
6722     uuid = values.get('uuid', None)
6723     if uuid is None:
6724         uuid = uuidutils.generate_uuid()
6725         values['uuid'] = uuid
6726 
6727     try:
6728         group = models.InstanceGroup()
6729         group.update(values)
6730         group.save(context.session)
6731     except db_exc.DBDuplicateEntry:
6732         raise exception.InstanceGroupIdExists(group_uuid=uuid)
6733 
6734     # We don't want '_policies' and '_members' attributes to be lazy loaded
6735     # later. We know there is nothing here since we just created this
6736     # instance group.
6737     if policies:
6738         _instance_group_policies_add(context, group.id, policies)
6739     else:
6740         group._policies = []
6741     if members:
6742         _instance_group_members_add(context, group.id, members)
6743     else:
6744         group._members = []
6745 
6746     return instance_group_get(context, uuid)
6747 
6748 
6749 @pick_context_manager_reader
6750 def instance_group_get(context, group_uuid):
6751     """Get a specific group by uuid."""
6752     group = _instance_group_get_query(context,
6753                                       models.InstanceGroup,
6754                                       models.InstanceGroup.uuid,
6755                                       group_uuid).\
6756                             first()
6757     if not group:
6758         raise exception.InstanceGroupNotFound(group_uuid=group_uuid)
6759     return group
6760 
6761 
6762 @pick_context_manager_reader
6763 def instance_group_get_by_instance(context, instance_uuid):
6764     group_member = model_query(context, models.InstanceGroupMember).\
6765                                filter_by(instance_id=instance_uuid).\
6766                                first()
6767     if not group_member:
6768         raise exception.InstanceGroupNotFound(group_uuid='')
6769     group = _instance_group_get_query(context, models.InstanceGroup,
6770                                       models.InstanceGroup.id,
6771                                       group_member.group_id).first()
6772     if not group:
6773         raise exception.InstanceGroupNotFound(
6774                 group_uuid=group_member.group_id)
6775     return group
6776 
6777 
6778 @pick_context_manager_writer
6779 def instance_group_update(context, group_uuid, values):
6780     """Update the attributes of a group.
6781 
6782     If values contains a metadata key, it updates the aggregate metadata
6783     too. Similarly for the policies and members.
6784     """
6785     group = model_query(context, models.InstanceGroup).\
6786             filter_by(uuid=group_uuid).\
6787             first()
6788     if not group:
6789         raise exception.InstanceGroupNotFound(group_uuid=group_uuid)
6790 
6791     policies = values.get('policies')
6792     if policies is not None:
6793         _instance_group_policies_add(context,
6794                                      group.id,
6795                                      values.pop('policies'),
6796                                      set_delete=True)
6797     members = values.get('members')
6798     if members is not None:
6799         _instance_group_members_add(context,
6800                                     group.id,
6801                                     values.pop('members'),
6802                                     set_delete=True)
6803 
6804     group.update(values)
6805 
6806     if policies:
6807         values['policies'] = policies
6808     if members:
6809         values['members'] = members
6810 
6811 
6812 @pick_context_manager_writer
6813 def instance_group_delete(context, group_uuid):
6814     """Delete a group."""
6815     group_id = _instance_group_id(context, group_uuid)
6816 
6817     count = _instance_group_get_query(context,
6818                                       models.InstanceGroup,
6819                                       models.InstanceGroup.uuid,
6820                                       group_uuid).soft_delete()
6821     if count == 0:
6822         raise exception.InstanceGroupNotFound(group_uuid=group_uuid)
6823 
6824     # Delete policies, metadata and members
6825     instance_models = [models.InstanceGroupPolicy,
6826                        models.InstanceGroupMember]
6827     for model in instance_models:
6828         model_query(context, model).filter_by(group_id=group_id).soft_delete()
6829 
6830 
6831 @pick_context_manager_reader
6832 def instance_group_get_all(context):
6833     """Get all groups."""
6834     return _instance_group_get_query(context, models.InstanceGroup).all()
6835 
6836 
6837 @pick_context_manager_reader
6838 def instance_group_get_all_by_project_id(context, project_id):
6839     """Get all groups."""
6840     return _instance_group_get_query(context, models.InstanceGroup).\
6841                             filter_by(project_id=project_id).\
6842                             all()
6843 
6844 
6845 def _instance_group_count_by_project_and_user(context, project_id, user_id):
6846     return model_query(context, models.InstanceGroup, read_deleted="no").\
6847                    filter_by(project_id=project_id).\
6848                    filter_by(user_id=user_id).\
6849                    count()
6850 
6851 
6852 def _instance_group_model_get_query(context, model_class, group_id,
6853                                     read_deleted='no'):
6854     return model_query(context,
6855                        model_class,
6856                        read_deleted=read_deleted).\
6857                 filter_by(group_id=group_id)
6858 
6859 
6860 def _instance_group_id(context, group_uuid):
6861     """Returns the group database ID for the group UUID."""
6862 
6863     result = model_query(context,
6864                          models.InstanceGroup,
6865                          (models.InstanceGroup.id,)).\
6866                 filter_by(uuid=group_uuid).\
6867                 first()
6868     if not result:
6869         raise exception.InstanceGroupNotFound(group_uuid=group_uuid)
6870     return result.id
6871 
6872 
6873 def _instance_group_members_add(context, id, members, set_delete=False):
6874     all_members = set(members)
6875     query = _instance_group_model_get_query(context,
6876                                             models.InstanceGroupMember, id)
6877     if set_delete:
6878         query.filter(~models.InstanceGroupMember.instance_id.in_(
6879                      all_members)).\
6880               soft_delete(synchronize_session=False)
6881 
6882     query = query.filter(
6883             models.InstanceGroupMember.instance_id.in_(all_members))
6884     already_existing = set()
6885     for member_ref in query.all():
6886         already_existing.add(member_ref.instance_id)
6887 
6888     for instance_id in members:
6889         if instance_id in already_existing:
6890             continue
6891         member_ref = models.InstanceGroupMember()
6892         member_ref.update({'instance_id': instance_id,
6893                            'group_id': id})
6894         context.session.add(member_ref)
6895 
6896     return members
6897 
6898 
6899 @pick_context_manager_writer
6900 def instance_group_members_add(context, group_uuid, members,
6901                                set_delete=False):
6902     id = _instance_group_id(context, group_uuid)
6903     return _instance_group_members_add(context, id, members,
6904                                        set_delete=set_delete)
6905 
6906 
6907 @pick_context_manager_writer
6908 def instance_group_member_delete(context, group_uuid, instance_id):
6909     id = _instance_group_id(context, group_uuid)
6910     count = _instance_group_model_get_query(context,
6911                                             models.InstanceGroupMember,
6912                                             id).\
6913                             filter_by(instance_id=instance_id).\
6914                             soft_delete()
6915     if count == 0:
6916         raise exception.InstanceGroupMemberNotFound(group_uuid=group_uuid,
6917                                                     instance_id=instance_id)
6918 
6919 
6920 @pick_context_manager_reader
6921 def instance_group_members_get(context, group_uuid):
6922     id = _instance_group_id(context, group_uuid)
6923     instances = model_query(context,
6924                             models.InstanceGroupMember,
6925                             (models.InstanceGroupMember.instance_id,)).\
6926                     filter_by(group_id=id).all()
6927     return [instance[0] for instance in instances]
6928 
6929 
6930 def _instance_group_policies_add(context, id, policies, set_delete=False):
6931     allpols = set(policies)
6932     query = _instance_group_model_get_query(context,
6933                                             models.InstanceGroupPolicy, id)
6934     if set_delete:
6935         query.filter(~models.InstanceGroupPolicy.policy.in_(allpols)).\
6936             soft_delete(synchronize_session=False)
6937 
6938     query = query.filter(models.InstanceGroupPolicy.policy.in_(allpols))
6939     already_existing = set()
6940     for policy_ref in query.all():
6941         already_existing.add(policy_ref.policy)
6942 
6943     for policy in policies:
6944         if policy in already_existing:
6945             continue
6946         policy_ref = models.InstanceGroupPolicy()
6947         policy_ref.update({'policy': policy,
6948                            'group_id': id})
6949         context.session.add(policy_ref)
6950 
6951     return policies
6952 
6953 
6954 ####################
6955 
6956 
6957 @pick_context_manager_reader
6958 def pci_device_get_by_addr(context, node_id, dev_addr):
6959     pci_dev_ref = model_query(context, models.PciDevice).\
6960                         filter_by(compute_node_id=node_id).\
6961                         filter_by(address=dev_addr).\
6962                         first()
6963     if not pci_dev_ref:
6964         raise exception.PciDeviceNotFound(node_id=node_id, address=dev_addr)
6965     return pci_dev_ref
6966 
6967 
6968 @pick_context_manager_reader
6969 def pci_device_get_by_id(context, id):
6970     pci_dev_ref = model_query(context, models.PciDevice).\
6971                         filter_by(id=id).\
6972                         first()
6973     if not pci_dev_ref:
6974         raise exception.PciDeviceNotFoundById(id=id)
6975     return pci_dev_ref
6976 
6977 
6978 @pick_context_manager_reader
6979 def pci_device_get_all_by_node(context, node_id):
6980     return model_query(context, models.PciDevice).\
6981                        filter_by(compute_node_id=node_id).\
6982                        all()
6983 
6984 
6985 @pick_context_manager_reader
6986 def pci_device_get_all_by_parent_addr(context, node_id, parent_addr):
6987     return model_query(context, models.PciDevice).\
6988                        filter_by(compute_node_id=node_id).\
6989                        filter_by(parent_addr=parent_addr).\
6990                        all()
6991 
6992 
6993 @require_context
6994 @pick_context_manager_reader
6995 def pci_device_get_all_by_instance_uuid(context, instance_uuid):
6996     return model_query(context, models.PciDevice).\
6997                        filter_by(status='allocated').\
6998                        filter_by(instance_uuid=instance_uuid).\
6999                        all()
7000 
7001 
7002 @pick_context_manager_reader
7003 def _instance_pcidevs_get_multi(context, instance_uuids):
7004     if not instance_uuids:
7005         return []
7006     return model_query(context, models.PciDevice).\
7007         filter_by(status='allocated').\
7008         filter(models.PciDevice.instance_uuid.in_(instance_uuids))
7009 
7010 
7011 @pick_context_manager_writer
7012 def pci_device_destroy(context, node_id, address):
7013     result = model_query(context, models.PciDevice).\
7014                          filter_by(compute_node_id=node_id).\
7015                          filter_by(address=address).\
7016                          soft_delete()
7017     if not result:
7018         raise exception.PciDeviceNotFound(node_id=node_id, address=address)
7019 
7020 
7021 @pick_context_manager_writer
7022 def pci_device_update(context, node_id, address, values):
7023     query = model_query(context, models.PciDevice, read_deleted="no").\
7024                     filter_by(compute_node_id=node_id).\
7025                     filter_by(address=address)
7026     if query.update(values) == 0:
7027         device = models.PciDevice()
7028         device.update(values)
7029         context.session.add(device)
7030     return query.one()
7031 
7032 
7033 ####################
7034 
7035 
7036 @pick_context_manager_writer
7037 def instance_tag_add(context, instance_uuid, tag):
7038     tag_ref = models.Tag()
7039     tag_ref.resource_id = instance_uuid
7040     tag_ref.tag = tag
7041 
7042     try:
7043         _check_instance_exists_in_project(context, instance_uuid)
7044         with get_context_manager(context).writer.savepoint.using(context):
7045             context.session.add(tag_ref)
7046     except db_exc.DBDuplicateEntry:
7047         # NOTE(snikitin): We should ignore tags duplicates
7048         pass
7049 
7050     return tag_ref
7051 
7052 
7053 @pick_context_manager_writer
7054 def instance_tag_set(context, instance_uuid, tags):
7055     _check_instance_exists_in_project(context, instance_uuid)
7056 
7057     existing = context.session.query(models.Tag.tag).filter_by(
7058         resource_id=instance_uuid).all()
7059 
7060     existing = set(row.tag for row in existing)
7061     tags = set(tags)
7062     to_delete = existing - tags
7063     to_add = tags - existing
7064 
7065     if to_delete:
7066         context.session.query(models.Tag).filter_by(
7067             resource_id=instance_uuid).filter(
7068             models.Tag.tag.in_(to_delete)).delete(
7069             synchronize_session=False)
7070 
7071     if to_add:
7072         data = [
7073             {'resource_id': instance_uuid, 'tag': tag} for tag in to_add]
7074         context.session.execute(models.Tag.__table__.insert(), data)
7075 
7076     return context.session.query(models.Tag).filter_by(
7077         resource_id=instance_uuid).all()
7078 
7079 
7080 @pick_context_manager_reader
7081 def instance_tag_get_by_instance_uuid(context, instance_uuid):
7082     _check_instance_exists_in_project(context, instance_uuid)
7083     return context.session.query(models.Tag).filter_by(
7084         resource_id=instance_uuid).all()
7085 
7086 
7087 @pick_context_manager_writer
7088 def instance_tag_delete(context, instance_uuid, tag):
7089     _check_instance_exists_in_project(context, instance_uuid)
7090     result = context.session.query(models.Tag).filter_by(
7091         resource_id=instance_uuid, tag=tag).delete()
7092 
7093     if not result:
7094         raise exception.InstanceTagNotFound(instance_id=instance_uuid,
7095                                             tag=tag)
7096 
7097 
7098 @pick_context_manager_writer
7099 def instance_tag_delete_all(context, instance_uuid):
7100     _check_instance_exists_in_project(context, instance_uuid)
7101     context.session.query(models.Tag).filter_by(
7102         resource_id=instance_uuid).delete()
7103 
7104 
7105 @pick_context_manager_reader
7106 def instance_tag_exists(context, instance_uuid, tag):
7107     _check_instance_exists_in_project(context, instance_uuid)
7108     q = context.session.query(models.Tag).filter_by(
7109         resource_id=instance_uuid, tag=tag)
7110     return context.session.query(q.exists()).scalar()
7111 
7112 
7113 ####################
7114 
7115 
7116 @pick_context_manager_writer
7117 def console_auth_token_create(context, values):
7118     instance_uuid = values.get('instance_uuid')
7119     _check_instance_exists_in_project(context, instance_uuid)
7120     token_ref = models.ConsoleAuthToken()
7121     token_ref.update(values)
7122     context.session.add(token_ref)
7123     return token_ref
7124 
7125 
7126 @pick_context_manager_reader
7127 def console_auth_token_get_valid(context, token_hash, instance_uuid):
7128     _check_instance_exists_in_project(context, instance_uuid)
7129     return context.session.query(models.ConsoleAuthToken).\
7130         filter_by(token_hash=token_hash).\
7131         filter_by(instance_uuid=instance_uuid).\
7132         filter(models.ConsoleAuthToken.expires > timeutils.utcnow_ts()).\
7133         first()
7134 
7135 
7136 @pick_context_manager_writer
7137 def console_auth_token_destroy_all_by_instance(context, instance_uuid):
7138     context.session.query(models.ConsoleAuthToken).\
7139         filter_by(instance_uuid=instance_uuid).delete()
7140 
7141 
7142 @pick_context_manager_writer
7143 def console_auth_token_destroy_expired_by_host(context, host):
7144     context.session.query(models.ConsoleAuthToken).\
7145         filter_by(host=host).\
7146         filter(models.ConsoleAuthToken.expires <= timeutils.utcnow_ts()).\
7147         delete()
