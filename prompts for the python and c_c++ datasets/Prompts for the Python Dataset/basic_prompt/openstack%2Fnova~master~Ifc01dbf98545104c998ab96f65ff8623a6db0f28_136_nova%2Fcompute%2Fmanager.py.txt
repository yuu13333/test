Please review the code below to detect security defects. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are found, please state '''No security defects are detected in the code'''.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 from cursive import exception as cursive_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 from keystoneauth1 import exceptions as keystone_exception
44 from oslo_log import log as logging
45 import oslo_messaging as messaging
46 from oslo_serialization import jsonutils
47 from oslo_service import loopingcall
48 from oslo_service import periodic_task
49 from oslo_utils import excutils
50 from oslo_utils import strutils
51 from oslo_utils import timeutils
52 from oslo_utils import uuidutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova.console import rpcapi as console_rpcapi
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova import image
77 from nova.image import glance
78 from nova import manager
79 from nova import network
80 from nova.network import base_api as base_net_api
81 from nova.network import model as network_model
82 from nova.network.security_group import openstack_driver
83 from nova import objects
84 from nova.objects import base as obj_base
85 from nova.objects import fields
86 from nova.objects import instance as obj_instance
87 from nova.objects import migrate_data as migrate_data_obj
88 from nova.pci import whitelist
89 from nova import rpc
90 from nova import safe_utils
91 from nova.scheduler import client as scheduler_client
92 from nova import utils
93 from nova.virt import block_device as driver_block_device
94 from nova.virt import configdrive
95 from nova.virt import driver
96 from nova.virt import event as virtevent
97 from nova.virt import storage_users
98 from nova.virt import virtapi
99 from nova.volume import cinder
100 
101 CONF = nova.conf.CONF
102 
103 LOG = logging.getLogger(__name__)
104 
105 get_notifier = functools.partial(rpc.get_notifier, service='compute')
106 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
107                                    get_notifier=get_notifier,
108                                    binary='nova-compute')
109 
110 
111 @contextlib.contextmanager
112 def errors_out_migration_ctxt(migration):
113     """Context manager to error out migration on failure."""
114 
115     try:
116         yield
117     except Exception as ex:
118         with excutils.save_and_reraise_exception():
119             # NOTE(rajesht): If InstanceNotFound error is thrown from
120             # decorated function, migration status should be set to
121             # 'error', without checking current migration status.
122             if not isinstance(ex, exception.InstanceNotFound):
123                 status = migration.status
124                 if status not in ['migrating', 'post-migrating']:
125                     return
126 
127             migration.status = 'error'
128             try:
129                 with migration.obj_as_admin():
130                     migration.save()
131             except Exception:
132                 LOG.debug('Error setting migration status for instance %s.',
133                           migration.instance_uuid, exc_info=True)
134 
135 
136 @utils.expects_func_args('migration')
137 def errors_out_migration(function):
138     """Decorator to error out migration on failure."""
139 
140     @functools.wraps(function)
141     def decorated_function(self, context, *args, **kwargs):
142         wrapped_func = safe_utils.get_wrapped_function(function)
143         keyed_args = inspect.getcallargs(wrapped_func, self, context,
144                                          *args, **kwargs)
145         migration = keyed_args['migration']
146         with errors_out_migration_ctxt(migration):
147             return function(self, context, *args, **kwargs)
148 
149     return decorated_function
150 
151 
152 @utils.expects_func_args('instance')
153 def reverts_task_state(function):
154     """Decorator to revert task_state on failure."""
155 
156     @functools.wraps(function)
157     def decorated_function(self, context, *args, **kwargs):
158         try:
159             return function(self, context, *args, **kwargs)
160         except exception.UnexpectedTaskStateError as e:
161             # Note(maoy): unexpected task state means the current
162             # task is preempted. Do not clear task state in this
163             # case.
164             with excutils.save_and_reraise_exception():
165                 LOG.info("Task possibly preempted: %s",
166                          e.format_message())
167         except Exception:
168             with excutils.save_and_reraise_exception():
169                 wrapped_func = safe_utils.get_wrapped_function(function)
170                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
171                                                  *args, **kwargs)
172                 # NOTE(mriedem): 'instance' must be in keyed_args because we
173                 # have utils.expects_func_args('instance') decorating this
174                 # method.
175                 instance = keyed_args['instance']
176                 original_task_state = instance.task_state
177                 try:
178                     self._instance_update(context, instance, task_state=None)
179                     LOG.info("Successfully reverted task state from %s on "
180                              "failure for instance.",
181                              original_task_state, instance=instance)
182                 except exception.InstanceNotFound:
183                     # We might delete an instance that failed to build shortly
184                     # after it errored out this is an expected case and we
185                     # should not trace on it.
186                     pass
187                 except Exception as e:
188                     LOG.warning("Failed to revert task state for instance. "
189                                 "Error: %s", e, instance=instance)
190 
191     return decorated_function
192 
193 
194 @utils.expects_func_args('instance')
195 def wrap_instance_fault(function):
196     """Wraps a method to catch exceptions related to instances.
197 
198     This decorator wraps a method to catch any exceptions having to do with
199     an instance that may get thrown. It then logs an instance fault in the db.
200     """
201 
202     @functools.wraps(function)
203     def decorated_function(self, context, *args, **kwargs):
204         try:
205             return function(self, context, *args, **kwargs)
206         except exception.InstanceNotFound:
207             raise
208         except Exception as e:
209             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
210             # we will get a KeyError exception which will cover up the real
211             # exception. So, we update kwargs with the values from args first.
212             # then, we can get 'instance' from kwargs easily.
213             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
214 
215             with excutils.save_and_reraise_exception():
216                 compute_utils.add_instance_fault_from_exc(context,
217                         kwargs['instance'], e, sys.exc_info())
218 
219     return decorated_function
220 
221 
222 @utils.expects_func_args('image_id', 'instance')
223 def delete_image_on_error(function):
224     """Used for snapshot related method to ensure the image created in
225     compute.api is deleted when an error occurs.
226     """
227 
228     @functools.wraps(function)
229     def decorated_function(self, context, image_id, instance,
230                            *args, **kwargs):
231         try:
232             return function(self, context, image_id, instance,
233                             *args, **kwargs)
234         except Exception:
235             with excutils.save_and_reraise_exception():
236                 LOG.debug("Cleaning up image %s", image_id,
237                           exc_info=True, instance=instance)
238                 try:
239                     self.image_api.delete(context, image_id)
240                 except exception.ImageNotFound:
241                     # Since we're trying to cleanup an image, we don't care if
242                     # if it's already gone.
243                     pass
244                 except Exception:
245                     LOG.exception("Error while trying to clean up image %s",
246                                   image_id, instance=instance)
247 
248     return decorated_function
249 
250 
251 # TODO(danms): Remove me after Icehouse
252 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
253 # NOTE(mikal): if the method being decorated has more than one decorator, then
254 # put this one first. Otherwise the various exception handling decorators do
255 # not function correctly.
256 def object_compat(function):
257     """Wraps a method that expects a new-world instance
258 
259     This provides compatibility for callers passing old-style dict
260     instances.
261     """
262 
263     @functools.wraps(function)
264     def decorated_function(self, context, *args, **kwargs):
265         def _load_instance(instance_or_dict):
266             if isinstance(instance_or_dict, dict):
267                 # try to get metadata and system_metadata for most cases but
268                 # only attempt to load those if the db instance already has
269                 # those fields joined
270                 metas = [meta for meta in ('metadata', 'system_metadata')
271                          if meta in instance_or_dict]
272                 instance = objects.Instance._from_db_object(
273                     context, objects.Instance(), instance_or_dict,
274                     expected_attrs=metas)
275                 instance._context = context
276                 return instance
277             return instance_or_dict
278 
279         try:
280             kwargs['instance'] = _load_instance(kwargs['instance'])
281         except KeyError:
282             args = (_load_instance(args[0]),) + args[1:]
283 
284         migration = kwargs.get('migration')
285         if isinstance(migration, dict):
286             migration = objects.Migration._from_db_object(
287                     context.elevated(), objects.Migration(),
288                     migration)
289             kwargs['migration'] = migration
290 
291         return function(self, context, *args, **kwargs)
292 
293     return decorated_function
294 
295 
296 class InstanceEvents(object):
297     def __init__(self):
298         self._events = {}
299 
300     @staticmethod
301     def _lock_name(instance):
302         return '%s-%s' % (instance.uuid, 'events')
303 
304     def prepare_for_instance_event(self, instance, event_name):
305         """Prepare to receive an event for an instance.
306 
307         This will register an event for the given instance that we will
308         wait on later. This should be called before initiating whatever
309         action will trigger the event. The resulting eventlet.event.Event
310         object should be wait()'d on to ensure completion.
311 
312         :param instance: the instance for which the event will be generated
313         :param event_name: the name of the event we're expecting
314         :returns: an event object that should be wait()'d on
315         """
316         if self._events is None:
317             # NOTE(danms): We really should have a more specific error
318             # here, but this is what we use for our default error case
319             raise exception.NovaException('In shutdown, no new events '
320                                           'can be scheduled')
321 
322         @utils.synchronized(self._lock_name(instance))
323         def _create_or_get_event():
324             instance_events = self._events.setdefault(instance.uuid, {})
325             return instance_events.setdefault(event_name,
326                                               eventlet.event.Event())
327         LOG.debug('Preparing to wait for external event %(event)s',
328                   {'event': event_name}, instance=instance)
329         return _create_or_get_event()
330 
331     def pop_instance_event(self, instance, event):
332         """Remove a pending event from the wait list.
333 
334         This will remove a pending event from the wait list so that it
335         can be used to signal the waiters to wake up.
336 
337         :param instance: the instance for which the event was generated
338         :param event: the nova.objects.external_event.InstanceExternalEvent
339                       that describes the event
340         :returns: the eventlet.event.Event object on which the waiters
341                   are blocked
342         """
343         no_events_sentinel = object()
344         no_matching_event_sentinel = object()
345 
346         @utils.synchronized(self._lock_name(instance))
347         def _pop_event():
348             if not self._events:
349                 LOG.debug('Unexpected attempt to pop events during shutdown',
350                           instance=instance)
351                 return no_events_sentinel
352             events = self._events.get(instance.uuid)
353             if not events:
354                 return no_events_sentinel
355             _event = events.pop(event.key, None)
356             if not events:
357                 del self._events[instance.uuid]
358             if _event is None:
359                 return no_matching_event_sentinel
360             return _event
361 
362         result = _pop_event()
363         if result is no_events_sentinel:
364             LOG.debug('No waiting events found dispatching %(event)s',
365                       {'event': event.key},
366                       instance=instance)
367             return None
368         elif result is no_matching_event_sentinel:
369             LOG.debug('No event matching %(event)s in %(events)s',
370                       {'event': event.key,
371                        'events': self._events.get(instance.uuid, {}).keys()},
372                       instance=instance)
373             return None
374         else:
375             return result
376 
377     def clear_events_for_instance(self, instance):
378         """Remove all pending events for an instance.
379 
380         This will remove all events currently pending for an instance
381         and return them (indexed by event name).
382 
383         :param instance: the instance for which events should be purged
384         :returns: a dictionary of {event_name: eventlet.event.Event}
385         """
386         @utils.synchronized(self._lock_name(instance))
387         def _clear_events():
388             if self._events is None:
389                 LOG.debug('Unexpected attempt to clear events during shutdown',
390                           instance=instance)
391                 return dict()
392             return self._events.pop(instance.uuid, {})
393         return _clear_events()
394 
395     def cancel_all_events(self):
396         if self._events is None:
397             LOG.debug('Unexpected attempt to cancel events during shutdown.')
398             return
399         our_events = self._events
400         # NOTE(danms): Block new events
401         self._events = None
402 
403         for instance_uuid, events in our_events.items():
404             for event_name, eventlet_event in events.items():
405                 LOG.debug('Canceling in-flight event %(event)s for '
406                           'instance %(instance_uuid)s',
407                           {'event': event_name,
408                            'instance_uuid': instance_uuid})
409                 name, tag = event_name.rsplit('-', 1)
410                 event = objects.InstanceExternalEvent(
411                     instance_uuid=instance_uuid,
412                     name=name, status='failed',
413                     tag=tag, data={})
414                 eventlet_event.send(event)
415 
416 
417 class ComputeVirtAPI(virtapi.VirtAPI):
418     def __init__(self, compute):
419         super(ComputeVirtAPI, self).__init__()
420         self._compute = compute
421 
422     def _default_error_callback(self, event_name, instance):
423         raise exception.NovaException(_('Instance event failed'))
424 
425     @contextlib.contextmanager
426     def wait_for_instance_event(self, instance, event_names, deadline=300,
427                                 error_callback=None):
428         """Plan to wait for some events, run some code, then wait.
429 
430         This context manager will first create plans to wait for the
431         provided event_names, yield, and then wait for all the scheduled
432         events to complete.
433 
434         Note that this uses an eventlet.timeout.Timeout to bound the
435         operation, so callers should be prepared to catch that
436         failure and handle that situation appropriately.
437 
438         If the event is not received by the specified timeout deadline,
439         eventlet.timeout.Timeout is raised.
440 
441         If the event is received but did not have a 'completed'
442         status, a NovaException is raised.  If an error_callback is
443         provided, instead of raising an exception as detailed above
444         for the failure case, the callback will be called with the
445         event_name and instance, and can return True to continue
446         waiting for the rest of the events, False to stop processing,
447         or raise an exception which will bubble up to the waiter.
448 
449         :param instance: The instance for which an event is expected
450         :param event_names: A list of event names. Each element can be a
451                             string event name or tuple of strings to
452                             indicate (name, tag).
453         :param deadline: Maximum number of seconds we should wait for all
454                          of the specified events to arrive.
455         :param error_callback: A function to be called if an event arrives
456 
457         """
458 
459         if error_callback is None:
460             error_callback = self._default_error_callback
461         events = {}
462         for event_name in event_names:
463             if isinstance(event_name, tuple):
464                 name, tag = event_name
465                 event_name = objects.InstanceExternalEvent.make_key(
466                     name, tag)
467             try:
468                 events[event_name] = (
469                     self._compute.instance_events.prepare_for_instance_event(
470                         instance, event_name))
471             except exception.NovaException:
472                 error_callback(event_name, instance)
473                 # NOTE(danms): Don't wait for any of the events. They
474                 # should all be canceled and fired immediately below,
475                 # but don't stick around if not.
476                 deadline = 0
477         yield
478         with eventlet.timeout.Timeout(deadline):
479             for event_name, event in events.items():
480                 actual_event = event.wait()
481                 if actual_event.status == 'completed':
482                     continue
483                 decision = error_callback(event_name, instance)
484                 if decision is False:
485                     break
486 
487 
488 class ComputeManager(manager.Manager):
489     """Manages the running instances from creation to destruction."""
490 
491     target = messaging.Target(version='4.17')
492 
493     # How long to wait in seconds before re-issuing a shutdown
494     # signal to an instance during power off.  The overall
495     # time to wait is set by CONF.shutdown_timeout.
496     SHUTDOWN_RETRY_INTERVAL = 10
497 
498     def __init__(self, compute_driver=None, *args, **kwargs):
499         """Load configuration options and connect to the hypervisor."""
500         self.virtapi = ComputeVirtAPI(self)
501         self.network_api = network.API()
502         self.volume_api = cinder.API()
503         self.image_api = image.API()
504         self._last_host_check = 0
505         self._last_bw_usage_poll = 0
506         self._bw_usage_supported = True
507         self._last_bw_usage_cell_update = 0
508         self.compute_api = compute.API()
509         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
510         self.conductor_api = conductor.API()
511         self.compute_task_api = conductor.ComputeTaskAPI()
512         self.is_neutron_security_groups = (
513             openstack_driver.is_neutron_security_groups())
514         self.cells_rpcapi = cells_rpcapi.CellsAPI()
515         self.scheduler_client = scheduler_client.SchedulerClient()
516         self._resource_tracker = None
517         self.instance_events = InstanceEvents()
518         self._sync_power_pool = eventlet.GreenPool(
519             size=CONF.sync_power_state_pool_size)
520         self._syncs_in_progress = {}
521         self.send_instance_updates = (
522             CONF.filter_scheduler.track_instance_changes)
523         if CONF.max_concurrent_builds != 0:
524             self._build_semaphore = eventlet.semaphore.Semaphore(
525                 CONF.max_concurrent_builds)
526         else:
527             self._build_semaphore = compute_utils.UnlimitedSemaphore()
528         if max(CONF.max_concurrent_live_migrations, 0) != 0:
529             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
530                 CONF.max_concurrent_live_migrations)
531         else:
532             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
533         self._failed_builds = 0
534 
535         super(ComputeManager, self).__init__(service_name="compute",
536                                              *args, **kwargs)
537 
538         # NOTE(russellb) Load the driver last.  It may call back into the
539         # compute manager via the virtapi, so we want it to be fully
540         # initialized before that happens.
541         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
542         self.use_legacy_block_device_info = \
543                             self.driver.need_legacy_block_device_info
544 
545     def reset(self):
546         LOG.info('Reloading compute RPC API')
547         compute_rpcapi.LAST_VERSION = None
548         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
549 
550     def _get_resource_tracker(self):
551         if not self._resource_tracker:
552             rt = resource_tracker.ResourceTracker(self.host, self.driver)
553             self._resource_tracker = rt
554         return self._resource_tracker
555 
556     def _update_resource_tracker(self, context, instance):
557         """Let the resource tracker know that an instance has changed state."""
558 
559         if instance.host == self.host:
560             rt = self._get_resource_tracker()
561             rt.update_usage(context, instance, instance.node)
562 
563     def _instance_update(self, context, instance, **kwargs):
564         """Update an instance in the database using kwargs as value."""
565 
566         for k, v in kwargs.items():
567             setattr(instance, k, v)
568         instance.save()
569         self._update_resource_tracker(context, instance)
570 
571     def _nil_out_instance_obj_host_and_node(self, instance):
572         # NOTE(jwcroppe): We don't do instance.save() here for performance
573         # reasons; a call to this is expected to be immediately followed by
574         # another call that does instance.save(), thus avoiding two writes
575         # to the database layer.
576         instance.host = None
577         instance.node = None
578 
579     def _set_instance_obj_error_state(self, context, instance,
580                                       clean_task_state=False):
581         try:
582             instance.vm_state = vm_states.ERROR
583             if clean_task_state:
584                 instance.task_state = None
585             instance.save()
586         except exception.InstanceNotFound:
587             LOG.debug('Instance has been destroyed from under us while '
588                       'trying to set it to ERROR', instance=instance)
589 
590     def _get_instances_on_driver(self, context, filters=None):
591         """Return a list of instance records for the instances found
592         on the hypervisor which satisfy the specified filters. If filters=None
593         return a list of instance records for all the instances found on the
594         hypervisor.
595         """
596         if not filters:
597             filters = {}
598         try:
599             driver_uuids = self.driver.list_instance_uuids()
600             if len(driver_uuids) == 0:
601                 # Short circuit, don't waste a DB call
602                 return objects.InstanceList()
603             filters['uuid'] = driver_uuids
604             local_instances = objects.InstanceList.get_by_filters(
605                 context, filters, use_slave=True)
606             return local_instances
607         except NotImplementedError:
608             pass
609 
610         # The driver doesn't support uuids listing, so we'll have
611         # to brute force.
612         driver_instances = self.driver.list_instances()
613         # NOTE(mjozefcz): In this case we need to apply host filter.
614         # Without this all instance data would be fetched from db.
615         filters['host'] = self.host
616         instances = objects.InstanceList.get_by_filters(context, filters,
617                                                         use_slave=True)
618         name_map = {instance.name: instance for instance in instances}
619         local_instances = []
620         for driver_instance in driver_instances:
621             instance = name_map.get(driver_instance)
622             if not instance:
623                 continue
624             local_instances.append(instance)
625         return local_instances
626 
627     def _destroy_evacuated_instances(self, context):
628         """Destroys evacuated instances.
629 
630         While nova-compute was down, the instances running on it could be
631         evacuated to another host. Check that the instances reported
632         by the driver are still associated with this host.  If they are
633         not, destroy them, with the exception of instances which are in
634         the MIGRATING, RESIZE_MIGRATING, RESIZE_MIGRATED, RESIZE_FINISH
635         task state or RESIZED vm state.
636         """
637         filters = {
638             'source_compute': self.host,
639             'status': ['accepted', 'done'],
640             'migration_type': 'evacuation',
641         }
642         with utils.temporary_mutation(context, read_deleted='yes'):
643             evacuations = objects.MigrationList.get_by_filters(context,
644                                                                filters)
645         if not evacuations:
646             return
647         evacuations = {mig.instance_uuid: mig for mig in evacuations}
648 
649         local_instances = self._get_instances_on_driver(context)
650         evacuated = [inst for inst in local_instances
651                      if inst.uuid in evacuations]
652         for instance in evacuated:
653             migration = evacuations[instance.uuid]
654             LOG.info('Deleting instance as it has been evacuated from '
655                      'this host', instance=instance)
656             try:
657                 network_info = self.network_api.get_instance_nw_info(
658                     context, instance)
659                 bdi = self._get_instance_block_device_info(context,
660                                                            instance)
661                 destroy_disks = not (self._is_instance_storage_shared(
662                     context, instance))
663             except exception.InstanceNotFound:
664                 network_info = network_model.NetworkInfo()
665                 bdi = {}
666                 LOG.info('Instance has been marked deleted already, '
667                          'removing it from the hypervisor.',
668                          instance=instance)
669                 # always destroy disks if the instance was deleted
670                 destroy_disks = True
671             self.driver.destroy(context, instance,
672                                 network_info,
673                                 bdi, destroy_disks)
674 
675             rt = self._get_resource_tracker()
676             rt.delete_allocation_for_evacuated_instance(
677                 instance, migration.source_node)
678 
679             migration.status = 'completed'
680             migration.save()
681 
682     def _is_instance_storage_shared(self, context, instance, host=None):
683         shared_storage = True
684         data = None
685         try:
686             data = self.driver.check_instance_shared_storage_local(context,
687                                                        instance)
688             if data:
689                 shared_storage = (self.compute_rpcapi.
690                                   check_instance_shared_storage(context,
691                                   instance, data, host=host))
692         except NotImplementedError:
693             LOG.debug('Hypervisor driver does not support '
694                       'instance shared storage check, '
695                       'assuming it\'s not on shared storage',
696                       instance=instance)
697             shared_storage = False
698         except Exception:
699             LOG.exception('Failed to check if instance shared',
700                           instance=instance)
701         finally:
702             if data:
703                 self.driver.check_instance_shared_storage_cleanup(context,
704                                                                   data)
705         return shared_storage
706 
707     def _complete_partial_deletion(self, context, instance):
708         """Complete deletion for instances in DELETED status but not marked as
709         deleted in the DB
710         """
711         system_meta = instance.system_metadata
712         instance.destroy()
713         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
714                 context, instance.uuid)
715         self._complete_deletion(context,
716                                 instance,
717                                 bdms,
718                                 system_meta)
719 
720     def _complete_deletion(self, context, instance, bdms,
721                            system_meta):
722         # ensure block device mappings are not leaked
723         for bdm in bdms:
724             bdm.destroy()
725 
726         self._update_resource_tracker(context, instance)
727 
728         rt = self._get_resource_tracker()
729         rt.reportclient.delete_allocation_for_instance(instance.uuid)
730 
731         self._notify_about_instance_usage(context, instance, "delete.end",
732                 system_metadata=system_meta)
733         compute_utils.notify_about_instance_action(context, instance,
734                 self.host, action=fields.NotificationAction.DELETE,
735                 phase=fields.NotificationPhase.END)
736         self._delete_scheduler_instance_info(context, instance.uuid)
737 
738     def _init_instance(self, context, instance):
739         """Initialize this instance during service init."""
740 
741         # NOTE(danms): If the instance appears to not be owned by this
742         # host, it may have been evacuated away, but skipped by the
743         # evacuation cleanup code due to configuration. Thus, if that
744         # is a possibility, don't touch the instance in any way, but
745         # log the concern. This will help avoid potential issues on
746         # startup due to misconfiguration.
747         if instance.host != self.host:
748             LOG.warning('Instance %(uuid)s appears to not be owned '
749                         'by this host, but by %(host)s. Startup '
750                         'processing is being skipped.',
751                         {'uuid': instance.uuid,
752                          'host': instance.host})
753             return
754 
755         # Instances that are shut down, or in an error state can not be
756         # initialized and are not attempted to be recovered. The exception
757         # to this are instances that are in RESIZE_MIGRATING or DELETING,
758         # which are dealt with further down.
759         if (instance.vm_state == vm_states.SOFT_DELETED or
760             (instance.vm_state == vm_states.ERROR and
761             instance.task_state not in
762             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
763             LOG.debug("Instance is in %s state.",
764                       instance.vm_state, instance=instance)
765             return
766 
767         if instance.vm_state == vm_states.DELETED:
768             try:
769                 self._complete_partial_deletion(context, instance)
770             except Exception:
771                 # we don't want that an exception blocks the init_host
772                 LOG.exception('Failed to complete a deletion',
773                               instance=instance)
774             return
775 
776         if (instance.vm_state == vm_states.BUILDING or
777             instance.task_state in [task_states.SCHEDULING,
778                                     task_states.BLOCK_DEVICE_MAPPING,
779                                     task_states.NETWORKING,
780                                     task_states.SPAWNING]):
781             # NOTE(dave-mcnally) compute stopped before instance was fully
782             # spawned so set to ERROR state. This is safe to do as the state
783             # may be set by the api but the host is not so if we get here the
784             # instance has already been scheduled to this particular host.
785             LOG.debug("Instance failed to spawn correctly, "
786                       "setting to ERROR state", instance=instance)
787             instance.task_state = None
788             instance.vm_state = vm_states.ERROR
789             instance.save()
790             return
791 
792         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
793             instance.task_state in [task_states.REBUILDING,
794                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
795                                     task_states.REBUILD_SPAWNING]):
796             # NOTE(jichenjc) compute stopped before instance was fully
797             # spawned so set to ERROR state. This is consistent to BUILD
798             LOG.debug("Instance failed to rebuild correctly, "
799                       "setting to ERROR state", instance=instance)
800             instance.task_state = None
801             instance.vm_state = vm_states.ERROR
802             instance.save()
803             return
804 
805         if (instance.vm_state != vm_states.ERROR and
806             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
807                                     task_states.IMAGE_PENDING_UPLOAD,
808                                     task_states.IMAGE_UPLOADING,
809                                     task_states.IMAGE_SNAPSHOT]):
810             LOG.debug("Instance in transitional state %s at start-up "
811                       "clearing task state",
812                       instance.task_state, instance=instance)
813             try:
814                 self._post_interrupted_snapshot_cleanup(context, instance)
815             except Exception:
816                 # we don't want that an exception blocks the init_host
817                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
818             instance.task_state = None
819             instance.save()
820 
821         if (instance.vm_state != vm_states.ERROR and
822             instance.task_state in [task_states.RESIZE_PREP]):
823             LOG.debug("Instance in transitional state %s at start-up "
824                       "clearing task state",
825                       instance['task_state'], instance=instance)
826             instance.task_state = None
827             instance.save()
828 
829         if instance.task_state == task_states.DELETING:
830             try:
831                 LOG.info('Service started deleting the instance during '
832                          'the previous run, but did not finish. Restarting'
833                          ' the deletion now.', instance=instance)
834                 instance.obj_load_attr('metadata')
835                 instance.obj_load_attr('system_metadata')
836                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
837                         context, instance.uuid)
838                 self._delete_instance(context, instance, bdms)
839             except Exception:
840                 # we don't want that an exception blocks the init_host
841                 LOG.exception('Failed to complete a deletion',
842                               instance=instance)
843                 self._set_instance_obj_error_state(context, instance)
844             return
845 
846         current_power_state = self._get_power_state(context, instance)
847         try_reboot, reboot_type = self._retry_reboot(context, instance,
848                                                      current_power_state)
849 
850         if try_reboot:
851             LOG.debug("Instance in transitional state (%(task_state)s) at "
852                       "start-up and power state is (%(power_state)s), "
853                       "triggering reboot",
854                       {'task_state': instance.task_state,
855                        'power_state': current_power_state},
856                       instance=instance)
857 
858             # NOTE(mikal): if the instance was doing a soft reboot that got as
859             # far as shutting down the instance but not as far as starting it
860             # again, then we've just become a hard reboot. That means the
861             # task state for the instance needs to change so that we're in one
862             # of the expected task states for a hard reboot.
863             soft_types = [task_states.REBOOT_STARTED,
864                           task_states.REBOOT_PENDING,
865                           task_states.REBOOTING]
866             if instance.task_state in soft_types and reboot_type == 'HARD':
867                 instance.task_state = task_states.REBOOT_PENDING_HARD
868                 instance.save()
869 
870             self.reboot_instance(context, instance, block_device_info=None,
871                                  reboot_type=reboot_type)
872             return
873 
874         elif (current_power_state == power_state.RUNNING and
875               instance.task_state in [task_states.REBOOT_STARTED,
876                                       task_states.REBOOT_STARTED_HARD,
877                                       task_states.PAUSING,
878                                       task_states.UNPAUSING]):
879             LOG.warning("Instance in transitional state "
880                         "(%(task_state)s) at start-up and power state "
881                         "is (%(power_state)s), clearing task state",
882                         {'task_state': instance.task_state,
883                          'power_state': current_power_state},
884                         instance=instance)
885             instance.task_state = None
886             instance.vm_state = vm_states.ACTIVE
887             instance.save()
888         elif (current_power_state == power_state.PAUSED and
889               instance.task_state == task_states.UNPAUSING):
890             LOG.warning("Instance in transitional state "
891                         "(%(task_state)s) at start-up and power state "
892                         "is (%(power_state)s), clearing task state "
893                         "and unpausing the instance",
894                         {'task_state': instance.task_state,
895                          'power_state': current_power_state},
896                         instance=instance)
897             try:
898                 self.unpause_instance(context, instance)
899             except NotImplementedError:
900                 # Some virt driver didn't support pause and unpause
901                 pass
902             except Exception:
903                 LOG.exception('Failed to unpause instance', instance=instance)
904             return
905 
906         if instance.task_state == task_states.POWERING_OFF:
907             try:
908                 LOG.debug("Instance in transitional state %s at start-up "
909                           "retrying stop request",
910                           instance.task_state, instance=instance)
911                 self.stop_instance(context, instance, True)
912             except Exception:
913                 # we don't want that an exception blocks the init_host
914                 LOG.exception('Failed to stop instance', instance=instance)
915             return
916 
917         if instance.task_state == task_states.POWERING_ON:
918             try:
919                 LOG.debug("Instance in transitional state %s at start-up "
920                           "retrying start request",
921                           instance.task_state, instance=instance)
922                 self.start_instance(context, instance)
923             except Exception:
924                 # we don't want that an exception blocks the init_host
925                 LOG.exception('Failed to start instance', instance=instance)
926             return
927 
928         net_info = instance.get_network_info()
929         try:
930             self.driver.plug_vifs(instance, net_info)
931         except NotImplementedError as e:
932             LOG.debug(e, instance=instance)
933         except exception.VirtualInterfacePlugException:
934             # we don't want an exception to block the init_host
935             LOG.exception("Vifs plug failed", instance=instance)
936             self._set_instance_obj_error_state(context, instance)
937             return
938 
939         if instance.task_state == task_states.RESIZE_MIGRATING:
940             # We crashed during resize/migration, so roll back for safety
941             try:
942                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
943                 # not in system_metadata we default to True for backwards
944                 # compatibility
945                 power_on = (instance.system_metadata.get('old_vm_state') !=
946                             vm_states.STOPPED)
947 
948                 block_dev_info = self._get_instance_block_device_info(context,
949                                                                       instance)
950 
951                 self.driver.finish_revert_migration(context,
952                     instance, net_info, block_dev_info, power_on)
953 
954             except Exception:
955                 LOG.exception('Failed to revert crashed migration',
956                               instance=instance)
957             finally:
958                 LOG.info('Instance found in migrating state during '
959                          'startup. Resetting task_state',
960                          instance=instance)
961                 instance.task_state = None
962                 instance.save()
963         if instance.task_state == task_states.MIGRATING:
964             # Live migration did not complete, but instance is on this
965             # host, so reset the state.
966             instance.task_state = None
967             instance.save(expected_task_state=[task_states.MIGRATING])
968 
969         db_state = instance.power_state
970         drv_state = self._get_power_state(context, instance)
971         expect_running = (db_state == power_state.RUNNING and
972                           drv_state != db_state)
973 
974         LOG.debug('Current state is %(drv_state)s, state in DB is '
975                   '%(db_state)s.',
976                   {'drv_state': drv_state, 'db_state': db_state},
977                   instance=instance)
978 
979         if expect_running and CONF.resume_guests_state_on_host_boot:
980             LOG.info('Rebooting instance after nova-compute restart.',
981                      instance=instance)
982 
983             block_device_info = \
984                 self._get_instance_block_device_info(context, instance)
985 
986             try:
987                 self.driver.resume_state_on_host_boot(
988                     context, instance, net_info, block_device_info)
989             except NotImplementedError:
990                 LOG.warning('Hypervisor driver does not support '
991                             'resume guests', instance=instance)
992             except Exception:
993                 # NOTE(vish): The instance failed to resume, so we set the
994                 #             instance to error and attempt to continue.
995                 LOG.warning('Failed to resume instance',
996                             instance=instance)
997                 self._set_instance_obj_error_state(context, instance)
998 
999         elif drv_state == power_state.RUNNING:
1000             # VMwareAPI drivers will raise an exception
1001             try:
1002                 self.driver.ensure_filtering_rules_for_instance(
1003                                        instance, net_info)
1004             except NotImplementedError:
1005                 LOG.debug('Hypervisor driver does not support '
1006                           'firewall rules', instance=instance)
1007 
1008     def _retry_reboot(self, context, instance, current_power_state):
1009         current_task_state = instance.task_state
1010         retry_reboot = False
1011         reboot_type = compute_utils.get_reboot_type(current_task_state,
1012                                                     current_power_state)
1013 
1014         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1015                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1016         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1017                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1018         started_not_running = (current_task_state in
1019                                [task_states.REBOOT_STARTED,
1020                                 task_states.REBOOT_STARTED_HARD] and
1021                                current_power_state != power_state.RUNNING)
1022 
1023         if pending_soft or pending_hard or started_not_running:
1024             retry_reboot = True
1025 
1026         return retry_reboot, reboot_type
1027 
1028     def handle_lifecycle_event(self, event):
1029         LOG.info("VM %(state)s (Lifecycle Event)",
1030                  {'state': event.get_name()},
1031                  instance_uuid=event.get_instance_uuid())
1032         context = nova.context.get_admin_context(read_deleted='yes')
1033         instance = objects.Instance.get_by_uuid(context,
1034                                                 event.get_instance_uuid(),
1035                                                 expected_attrs=[])
1036         vm_power_state = None
1037         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1038             vm_power_state = power_state.SHUTDOWN
1039         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1040             vm_power_state = power_state.RUNNING
1041         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1042             vm_power_state = power_state.PAUSED
1043         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1044             vm_power_state = power_state.RUNNING
1045         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1046             vm_power_state = power_state.SUSPENDED
1047         else:
1048             LOG.warning("Unexpected power state %d", event.get_transition())
1049 
1050         # Note(lpetrut): The event may be delayed, thus not reflecting
1051         # the current instance power state. In that case, ignore the event.
1052         current_power_state = self._get_power_state(context, instance)
1053         if current_power_state == vm_power_state:
1054             LOG.debug('Synchronizing instance power state after lifecycle '
1055                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1056                       'current task_state: %(task_state)s, current DB '
1057                       'power_state: %(db_power_state)s, VM power_state: '
1058                       '%(vm_power_state)s',
1059                       {'event': event.get_name(),
1060                        'vm_state': instance.vm_state,
1061                        'task_state': instance.task_state,
1062                        'db_power_state': instance.power_state,
1063                        'vm_power_state': vm_power_state},
1064                       instance_uuid=instance.uuid)
1065             self._sync_instance_power_state(context,
1066                                             instance,
1067                                             vm_power_state)
1068 
1069     def handle_events(self, event):
1070         if isinstance(event, virtevent.LifecycleEvent):
1071             try:
1072                 self.handle_lifecycle_event(event)
1073             except exception.InstanceNotFound:
1074                 LOG.debug("Event %s arrived for non-existent instance. The "
1075                           "instance was probably deleted.", event)
1076         else:
1077             LOG.debug("Ignoring event %s", event)
1078 
1079     def init_virt_events(self):
1080         if CONF.workarounds.handle_virt_lifecycle_events:
1081             self.driver.register_event_listener(self.handle_events)
1082         else:
1083             # NOTE(mriedem): If the _sync_power_states periodic task is
1084             # disabled we should emit a warning in the logs.
1085             if CONF.sync_power_state_interval < 0:
1086                 LOG.warning('Instance lifecycle events from the compute '
1087                             'driver have been disabled. Note that lifecycle '
1088                             'changes to an instance outside of the compute '
1089                             'service will not be synchronized '
1090                             'automatically since the _sync_power_states '
1091                             'periodic task is also disabled.')
1092             else:
1093                 LOG.info('Instance lifecycle events from the compute '
1094                          'driver have been disabled. Note that lifecycle '
1095                          'changes to an instance outside of the compute '
1096                          'service will only be synchronized by the '
1097                          '_sync_power_states periodic task.')
1098 
1099     def init_host(self):
1100         """Initialization for a standalone compute service."""
1101 
1102         if CONF.pci.passthrough_whitelist:
1103             # Simply loading the PCI passthrough whitelist will do a bunch of
1104             # validation that would otherwise wait until the PciDevTracker is
1105             # constructed when updating available resources for the compute
1106             # node(s) in the resource tracker, effectively killing that task.
1107             # So load up the whitelist when starting the compute service to
1108             # flush any invalid configuration early so we can kill the service
1109             # if the configuration is wrong.
1110             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1111 
1112         # NOTE(sbauza): We want the compute node to hard fail if it won't be
1113         # able to provide its resources to the placement API, or it will not
1114         # be able to be eligible as a destination.
1115         if CONF.placement.os_region_name is None:
1116             raise exception.PlacementNotConfigured()
1117 
1118         self.driver.init_host(host=self.host)
1119         context = nova.context.get_admin_context()
1120         instances = objects.InstanceList.get_by_host(
1121             context, self.host, expected_attrs=['info_cache', 'metadata'])
1122 
1123         if CONF.defer_iptables_apply:
1124             self.driver.filter_defer_apply_on()
1125 
1126         self.init_virt_events()
1127 
1128         try:
1129             # checking that instance was not already evacuated to other host
1130             self._destroy_evacuated_instances(context)
1131             for instance in instances:
1132                 self._init_instance(context, instance)
1133         finally:
1134             if CONF.defer_iptables_apply:
1135                 self.driver.filter_defer_apply_off()
1136             if instances:
1137                 # We only send the instance info to the scheduler on startup
1138                 # if there is anything to send, otherwise this host might
1139                 # not be mapped yet in a cell and the scheduler may have
1140                 # issues dealing with the information. Later changes to
1141                 # instances on this host will update the scheduler, or the
1142                 # _sync_scheduler_instance_info periodic task will.
1143                 self._update_scheduler_instance_info(context, instances)
1144 
1145     def cleanup_host(self):
1146         self.driver.register_event_listener(None)
1147         self.instance_events.cancel_all_events()
1148         self.driver.cleanup_host(host=self.host)
1149 
1150     def pre_start_hook(self):
1151         """After the service is initialized, but before we fully bring
1152         the service up by listening on RPC queues, make sure to update
1153         our available resources (and indirectly our available nodes).
1154         """
1155         self.update_available_resource(nova.context.get_admin_context(),
1156                                        startup=True)
1157 
1158     def _get_power_state(self, context, instance):
1159         """Retrieve the power state for the given instance."""
1160         LOG.debug('Checking state', instance=instance)
1161         try:
1162             return self.driver.get_info(instance).state
1163         except exception.InstanceNotFound:
1164             return power_state.NOSTATE
1165 
1166     def get_console_topic(self, context):
1167         """Retrieves the console host for a project on this host.
1168 
1169         Currently this is just set in the flags for each compute host.
1170 
1171         """
1172         # TODO(mdragon): perhaps make this variable by console_type?
1173         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1174 
1175     @wrap_exception()
1176     def get_console_pool_info(self, context, console_type):
1177         return self.driver.get_console_pool_info(console_type)
1178 
1179     # NOTE(hanlind): This and the virt method it calls can be removed in
1180     # version 5.0 of the RPC API
1181     @wrap_exception()
1182     def refresh_security_group_rules(self, context, security_group_id):
1183         """Tell the virtualization driver to refresh security group rules.
1184 
1185         Passes straight through to the virtualization driver.
1186 
1187         """
1188         return self.driver.refresh_security_group_rules(security_group_id)
1189 
1190     # TODO(alaski): Remove object_compat for RPC version 5.0
1191     @object_compat
1192     @wrap_exception()
1193     def refresh_instance_security_rules(self, context, instance):
1194         """Tell the virtualization driver to refresh security rules for
1195         an instance.
1196 
1197         Passes straight through to the virtualization driver.
1198 
1199         Synchronize the call because we may still be in the middle of
1200         creating the instance.
1201         """
1202         @utils.synchronized(instance.uuid)
1203         def _sync_refresh():
1204             try:
1205                 return self.driver.refresh_instance_security_rules(instance)
1206             except NotImplementedError:
1207                 LOG.debug('Hypervisor driver does not support '
1208                           'security groups.', instance=instance)
1209 
1210         return _sync_refresh()
1211 
1212     def _await_block_device_map_created(self, context, vol_id):
1213         # TODO(yamahata): creating volume simultaneously
1214         #                 reduces creation time?
1215         # TODO(yamahata): eliminate dumb polling
1216         start = time.time()
1217         retries = CONF.block_device_allocate_retries
1218         if retries < 0:
1219             LOG.warning("Treating negative config value (%(retries)s) for "
1220                         "'block_device_retries' as 0.",
1221                         {'retries': retries})
1222         # (1) treat  negative config value as 0
1223         # (2) the configured value is 0, one attempt should be made
1224         # (3) the configured value is > 0, then the total number attempts
1225         #      is (retries + 1)
1226         attempts = 1
1227         if retries >= 1:
1228             attempts = retries + 1
1229         for attempt in range(1, attempts + 1):
1230             volume = self.volume_api.get(context, vol_id)
1231             volume_status = volume['status']
1232             if volume_status not in ['creating', 'downloading']:
1233                 if volume_status == 'available':
1234                     return attempt
1235                 LOG.warning("Volume id: %(vol_id)s finished being "
1236                             "created but its status is %(vol_status)s.",
1237                             {'vol_id': vol_id,
1238                              'vol_status': volume_status})
1239                 break
1240             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1241         raise exception.VolumeNotCreated(volume_id=vol_id,
1242                                          seconds=int(time.time() - start),
1243                                          attempts=attempt,
1244                                          volume_status=volume_status)
1245 
1246     def _decode_files(self, injected_files):
1247         """Base64 decode the list of files to inject."""
1248         if not injected_files:
1249             return []
1250 
1251         def _decode(f):
1252             path, contents = f
1253             # Py3 raises binascii.Error instead of TypeError as in Py27
1254             try:
1255                 decoded = base64.b64decode(contents)
1256                 return path, decoded
1257             except (TypeError, binascii.Error):
1258                 raise exception.Base64Exception(path=path)
1259 
1260         return [_decode(f) for f in injected_files]
1261 
1262     def _validate_instance_group_policy(self, context, instance,
1263             filter_properties):
1264         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1265         # However, there is a race condition with the enforcement of
1266         # the policy.  Since more than one instance may be scheduled at the
1267         # same time, it's possible that more than one instance with an
1268         # anti-affinity policy may end up here.  It's also possible that
1269         # multiple instances with an affinity policy could end up on different
1270         # hosts.  This is a validation step to make sure that starting the
1271         # instance here doesn't violate the policy.
1272 
1273         scheduler_hints = filter_properties.get('scheduler_hints') or {}
1274         group_hint = scheduler_hints.get('group')
1275         if not group_hint:
1276             return
1277 
1278         @utils.synchronized(group_hint)
1279         def _do_validation(context, instance, group_hint):
1280             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1281             if 'anti-affinity' in group.policies:
1282                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1283                 if self.host in group_hosts:
1284                     msg = _("Anti-affinity instance group policy "
1285                             "was violated.")
1286                     raise exception.RescheduledException(
1287                             instance_uuid=instance.uuid,
1288                             reason=msg)
1289             elif 'affinity' in group.policies:
1290                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1291                 if group_hosts and self.host not in group_hosts:
1292                     msg = _("Affinity instance group policy was violated.")
1293                     raise exception.RescheduledException(
1294                             instance_uuid=instance.uuid,
1295                             reason=msg)
1296 
1297         if not CONF.workarounds.disable_group_policy_check_upcall:
1298             _do_validation(context, instance, group_hint)
1299 
1300     def _log_original_error(self, exc_info, instance_uuid):
1301         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1302                   exc_info=exc_info)
1303 
1304     def _reschedule(self, context, request_spec, filter_properties,
1305             instance, reschedule_method, method_args, task_state,
1306             exc_info=None):
1307         """Attempt to re-schedule a compute operation."""
1308 
1309         instance_uuid = instance.uuid
1310         retry = filter_properties.get('retry')
1311         if not retry:
1312             # no retry information, do not reschedule.
1313             LOG.debug("Retry info not present, will not reschedule",
1314                       instance_uuid=instance_uuid)
1315             return
1316 
1317         if not request_spec:
1318             LOG.debug("No request spec, will not reschedule",
1319                       instance_uuid=instance_uuid)
1320             return
1321 
1322         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1323                   {'method': reschedule_method.__name__,
1324                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1325 
1326         # reset the task state:
1327         self._instance_update(context, instance, task_state=task_state)
1328 
1329         if exc_info:
1330             # stringify to avoid circular ref problem in json serialization:
1331             retry['exc'] = traceback.format_exception_only(exc_info[0],
1332                                     exc_info[1])
1333 
1334         reschedule_method(context, *method_args)
1335         return True
1336 
1337     @periodic_task.periodic_task
1338     def _check_instance_build_time(self, context):
1339         """Ensure that instances are not stuck in build."""
1340         timeout = CONF.instance_build_timeout
1341         if timeout == 0:
1342             return
1343 
1344         filters = {'vm_state': vm_states.BUILDING,
1345                    'host': self.host}
1346 
1347         building_insts = objects.InstanceList.get_by_filters(context,
1348                            filters, expected_attrs=[], use_slave=True)
1349 
1350         for instance in building_insts:
1351             if timeutils.is_older_than(instance.created_at, timeout):
1352                 self._set_instance_obj_error_state(context, instance)
1353                 LOG.warning("Instance build timed out. Set to error "
1354                             "state.", instance=instance)
1355 
1356     def _check_instance_exists(self, context, instance):
1357         """Ensure an instance with the same name is not already present."""
1358         if self.driver.instance_exists(instance):
1359             raise exception.InstanceExists(name=instance.name)
1360 
1361     def _allocate_network_async(self, context, instance, requested_networks,
1362                                 macs, security_groups, is_vpn):
1363         """Method used to allocate networks in the background.
1364 
1365         Broken out for testing.
1366         """
1367         # First check to see if we're specifically not supposed to allocate
1368         # networks because if so, we can exit early.
1369         if requested_networks and requested_networks.no_allocate:
1370             LOG.debug("Not allocating networking since 'none' was specified.",
1371                       instance=instance)
1372             return network_model.NetworkInfo([])
1373 
1374         LOG.debug("Allocating IP information in the background.",
1375                   instance=instance)
1376         retries = CONF.network_allocate_retries
1377         attempts = retries + 1
1378         retry_time = 1
1379         bind_host_id = self.driver.network_binding_host_id(context, instance)
1380         for attempt in range(1, attempts + 1):
1381             try:
1382                 nwinfo = self.network_api.allocate_for_instance(
1383                         context, instance, vpn=is_vpn,
1384                         requested_networks=requested_networks,
1385                         macs=macs,
1386                         security_groups=security_groups,
1387                         bind_host_id=bind_host_id)
1388                 LOG.debug('Instance network_info: |%s|', nwinfo,
1389                           instance=instance)
1390                 instance.system_metadata['network_allocated'] = 'True'
1391                 # NOTE(JoshNang) do not save the instance here, as it can cause
1392                 # races. The caller shares a reference to instance and waits
1393                 # for this async greenthread to finish before calling
1394                 # instance.save().
1395                 return nwinfo
1396             except Exception:
1397                 exc_info = sys.exc_info()
1398                 log_info = {'attempt': attempt,
1399                             'attempts': attempts}
1400                 if attempt == attempts:
1401                     LOG.exception('Instance failed network setup '
1402                                   'after %(attempts)d attempt(s)',
1403                                   log_info)
1404                     six.reraise(*exc_info)
1405                 LOG.warning('Instance failed network setup '
1406                             '(attempt %(attempt)d of %(attempts)d)',
1407                             log_info, instance=instance)
1408                 time.sleep(retry_time)
1409                 retry_time *= 2
1410                 if retry_time > 30:
1411                     retry_time = 30
1412         # Not reached.
1413 
1414     def _build_networks_for_instance(self, context, instance,
1415             requested_networks, security_groups):
1416 
1417         # If we're here from a reschedule the network may already be allocated.
1418         if strutils.bool_from_string(
1419                 instance.system_metadata.get('network_allocated', 'False')):
1420             # NOTE(alex_xu): The network_allocated is True means the network
1421             # resource already allocated at previous scheduling, and the
1422             # network setup is cleanup at previous. After rescheduling, the
1423             # network resource need setup on the new host.
1424             self.network_api.setup_instance_network_on_host(
1425                 context, instance, instance.host)
1426             return self.network_api.get_instance_nw_info(context, instance)
1427 
1428         if not self.is_neutron_security_groups:
1429             security_groups = []
1430 
1431         macs = self.driver.macs_for_instance(instance)
1432         network_info = self._allocate_network(context, instance,
1433                 requested_networks, macs, security_groups)
1434 
1435         return network_info
1436 
1437     def _allocate_network(self, context, instance, requested_networks, macs,
1438                           security_groups):
1439         """Start network allocation asynchronously.  Return an instance
1440         of NetworkInfoAsyncWrapper that can be used to retrieve the
1441         allocated networks when the operation has finished.
1442         """
1443         # NOTE(comstud): Since we're allocating networks asynchronously,
1444         # this task state has little meaning, as we won't be in this
1445         # state for very long.
1446         instance.vm_state = vm_states.BUILDING
1447         instance.task_state = task_states.NETWORKING
1448         instance.save(expected_task_state=[None])
1449         self._update_resource_tracker(context, instance)
1450 
1451         is_vpn = False
1452         return network_model.NetworkInfoAsyncWrapper(
1453                 self._allocate_network_async, context, instance,
1454                 requested_networks, macs, security_groups, is_vpn)
1455 
1456     def _default_root_device_name(self, instance, image_meta, root_bdm):
1457         try:
1458             return self.driver.default_root_device_name(instance,
1459                                                         image_meta,
1460                                                         root_bdm)
1461         except NotImplementedError:
1462             return compute_utils.get_next_device_name(instance, [])
1463 
1464     def _default_device_names_for_instance(self, instance,
1465                                            root_device_name,
1466                                            *block_device_lists):
1467         try:
1468             self.driver.default_device_names_for_instance(instance,
1469                                                           root_device_name,
1470                                                           *block_device_lists)
1471         except NotImplementedError:
1472             compute_utils.default_device_names_for_instance(
1473                 instance, root_device_name, *block_device_lists)
1474 
1475     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1476         # NOTE(ndipanov): Copy obj to avoid changing the original
1477         block_device_obj = block_device_obj.obj_clone()
1478         try:
1479             return self.driver.get_device_name_for_instance(
1480                 instance, bdms, block_device_obj)
1481         except NotImplementedError:
1482             return compute_utils.get_device_name_for_instance(
1483                 instance, bdms, block_device_obj.get("device_name"))
1484 
1485     def _default_block_device_names(self, instance, image_meta, block_devices):
1486         """Verify that all the devices have the device_name set. If not,
1487         provide a default name.
1488 
1489         It also ensures that there is a root_device_name and is set to the
1490         first block device in the boot sequence (boot_index=0).
1491         """
1492         root_bdm = block_device.get_root_bdm(block_devices)
1493         if not root_bdm:
1494             return
1495 
1496         # Get the root_device_name from the root BDM or the instance
1497         root_device_name = None
1498         update_root_bdm = False
1499 
1500         if root_bdm.device_name:
1501             root_device_name = root_bdm.device_name
1502             instance.root_device_name = root_device_name
1503         elif instance.root_device_name:
1504             root_device_name = instance.root_device_name
1505             root_bdm.device_name = root_device_name
1506             update_root_bdm = True
1507         else:
1508             root_device_name = self._default_root_device_name(instance,
1509                                                               image_meta,
1510                                                               root_bdm)
1511 
1512             instance.root_device_name = root_device_name
1513             root_bdm.device_name = root_device_name
1514             update_root_bdm = True
1515 
1516         if update_root_bdm:
1517             root_bdm.save()
1518 
1519         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1520                             block_devices))
1521         swap = list(filter(block_device.new_format_is_swap,
1522                       block_devices))
1523         block_device_mapping = list(filter(
1524               driver_block_device.is_block_device_mapping, block_devices))
1525 
1526         self._default_device_names_for_instance(instance,
1527                                                 root_device_name,
1528                                                 ephemerals,
1529                                                 swap,
1530                                                 block_device_mapping)
1531 
1532     def _block_device_info_to_legacy(self, block_device_info):
1533         """Convert BDI to the old format for drivers that need it."""
1534 
1535         if self.use_legacy_block_device_info:
1536             ephemerals = driver_block_device.legacy_block_devices(
1537                 driver.block_device_info_get_ephemerals(block_device_info))
1538             mapping = driver_block_device.legacy_block_devices(
1539                 driver.block_device_info_get_mapping(block_device_info))
1540             swap = block_device_info['swap']
1541             if swap:
1542                 swap = swap.legacy()
1543 
1544             block_device_info.update({
1545                 'ephemerals': ephemerals,
1546                 'swap': swap,
1547                 'block_device_mapping': mapping})
1548 
1549     def _add_missing_dev_names(self, bdms, instance):
1550         for bdm in bdms:
1551             if bdm.device_name is not None:
1552                 continue
1553 
1554             device_name = self._get_device_name_for_instance(instance,
1555                                                              bdms, bdm)
1556             values = {'device_name': device_name}
1557             bdm.update(values)
1558             bdm.save()
1559 
1560     def _prep_block_device(self, context, instance, bdms):
1561         """Set up the block device for an instance with error logging."""
1562         try:
1563             self._add_missing_dev_names(bdms, instance)
1564             block_device_info = driver.get_block_device_info(instance, bdms)
1565             mapping = driver.block_device_info_get_mapping(block_device_info)
1566             driver_block_device.attach_block_devices(
1567                 mapping, context, instance, self.volume_api, self.driver,
1568                 wait_func=self._await_block_device_map_created)
1569             for bdm in bdms:
1570                 if bdm.attachment_id:
1571                     self.volume_api.attachment_complete(context,
1572                                                         bdm.attachment_id)
1573 
1574             self._block_device_info_to_legacy(block_device_info)
1575             return block_device_info
1576 
1577         except exception.OverQuota as e:
1578             LOG.warning('Failed to create block device for instance due'
1579                         ' to exceeding volume related resource quota.'
1580                         ' Error: %s', e.message, instance=instance)
1581             raise
1582 
1583         except Exception as ex:
1584             LOG.exception('Instance failed block device setup',
1585                           instance=instance)
1586             # InvalidBDM will eventually result in a BuildAbortException when
1587             # booting from volume, and will be recorded as an instance fault.
1588             # Maintain the original exception message which most likely has
1589             # useful details which the standard InvalidBDM error message lacks.
1590             raise exception.InvalidBDM(six.text_type(ex))
1591 
1592     def _update_instance_after_spawn(self, context, instance):
1593         instance.power_state = self._get_power_state(context, instance)
1594         instance.vm_state = vm_states.ACTIVE
1595         instance.task_state = None
1596         instance.launched_at = timeutils.utcnow()
1597         configdrive.update_instance(instance)
1598 
1599     def _update_scheduler_instance_info(self, context, instance):
1600         """Sends an InstanceList with created or updated Instance objects to
1601         the Scheduler client.
1602 
1603         In the case of init_host, the value passed will already be an
1604         InstanceList. Other calls will send individual Instance objects that
1605         have been created or resized. In this case, we create an InstanceList
1606         object containing that Instance.
1607         """
1608         if not self.send_instance_updates:
1609             return
1610         if isinstance(instance, obj_instance.Instance):
1611             instance = objects.InstanceList(objects=[instance])
1612         context = context.elevated()
1613         self.scheduler_client.update_instance_info(context, self.host,
1614                                                    instance)
1615 
1616     def _delete_scheduler_instance_info(self, context, instance_uuid):
1617         """Sends the uuid of the deleted Instance to the Scheduler client."""
1618         if not self.send_instance_updates:
1619             return
1620         context = context.elevated()
1621         self.scheduler_client.delete_instance_info(context, self.host,
1622                                                    instance_uuid)
1623 
1624     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1625     def _sync_scheduler_instance_info(self, context):
1626         if not self.send_instance_updates:
1627             return
1628         context = context.elevated()
1629         instances = objects.InstanceList.get_by_host(context, self.host,
1630                                                      expected_attrs=[],
1631                                                      use_slave=True)
1632         uuids = [instance.uuid for instance in instances]
1633         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1634 
1635     def _notify_about_instance_usage(self, context, instance, event_suffix,
1636                                      network_info=None, system_metadata=None,
1637                                      extra_usage_info=None, fault=None):
1638         compute_utils.notify_about_instance_usage(
1639             self.notifier, context, instance, event_suffix,
1640             network_info=network_info,
1641             system_metadata=system_metadata,
1642             extra_usage_info=extra_usage_info, fault=fault)
1643 
1644     def _deallocate_network(self, context, instance,
1645                             requested_networks=None):
1646         # If we were told not to allocate networks let's save ourselves
1647         # the trouble of calling the network API.
1648         if requested_networks and requested_networks.no_allocate:
1649             LOG.debug("Skipping network deallocation for instance since "
1650                       "networking was not requested.", instance=instance)
1651             return
1652 
1653         LOG.debug('Deallocating network for instance', instance=instance)
1654         with timeutils.StopWatch() as timer:
1655             self.network_api.deallocate_for_instance(
1656                 context, instance, requested_networks=requested_networks)
1657         # nova-network does an rpc call so we're OK tracking time spent here
1658         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1659                  timer.elapsed(), instance=instance)
1660 
1661     def _get_instance_block_device_info(self, context, instance,
1662                                         refresh_conn_info=False,
1663                                         bdms=None):
1664         """Transform block devices to the driver block_device format."""
1665 
1666         if not bdms:
1667             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1668                     context, instance.uuid)
1669         block_device_info = driver.get_block_device_info(instance, bdms)
1670 
1671         if not refresh_conn_info:
1672             # if the block_device_mapping has no value in connection_info
1673             # (returned as None), don't include in the mapping
1674             block_device_info['block_device_mapping'] = [
1675                 bdm for bdm in driver.block_device_info_get_mapping(
1676                                     block_device_info)
1677                 if bdm.get('connection_info')]
1678         else:
1679             driver_block_device.refresh_conn_infos(
1680                 driver.block_device_info_get_mapping(block_device_info),
1681                 context, instance, self.volume_api, self.driver)
1682 
1683         self._block_device_info_to_legacy(block_device_info)
1684 
1685         return block_device_info
1686 
1687     def _build_failed(self):
1688         self._failed_builds += 1
1689         limit = CONF.compute.consecutive_build_service_disable_threshold
1690         if limit and self._failed_builds >= limit:
1691             # NOTE(danms): If we're doing a bunch of parallel builds,
1692             # it is possible (although not likely) that we have already
1693             # failed N-1 builds before this and we race with a successful
1694             # build and disable ourselves here when we might've otherwise
1695             # not.
1696             LOG.error('Disabling service due to %(fails)i '
1697                       'consecutive build failures',
1698                       {'fails': self._failed_builds})
1699             ctx = nova.context.get_admin_context()
1700             service = objects.Service.get_by_compute_host(ctx, CONF.host)
1701             service.disabled = True
1702             service.disabled_reason = (
1703                 'Auto-disabled due to %i build failures' % self._failed_builds)
1704             service.save()
1705             # NOTE(danms): Reset our counter now so that when the admin
1706             # re-enables us we can start fresh
1707             self._failed_builds = 0
1708         elif self._failed_builds > 1:
1709             LOG.warning('%(fails)i consecutive build failures',
1710                         {'fails': self._failed_builds})
1711 
1712     @wrap_exception()
1713     @reverts_task_state
1714     @wrap_instance_fault
1715     def build_and_run_instance(self, context, instance, image, request_spec,
1716                      filter_properties, admin_password=None,
1717                      injected_files=None, requested_networks=None,
1718                      security_groups=None, block_device_mapping=None,
1719                      node=None, limits=None):
1720 
1721         @utils.synchronized(instance.uuid)
1722         def _locked_do_build_and_run_instance(*args, **kwargs):
1723             # NOTE(danms): We grab the semaphore with the instance uuid
1724             # locked because we could wait in line to build this instance
1725             # for a while and we want to make sure that nothing else tries
1726             # to do anything with this instance while we wait.
1727             with self._build_semaphore:
1728                 try:
1729                     result = self._do_build_and_run_instance(*args, **kwargs)
1730                 except Exception:
1731                     # NOTE(mriedem): This should really only happen if
1732                     # _decode_files in _do_build_and_run_instance fails, and
1733                     # that's before a guest is spawned so it's OK to remove
1734                     # allocations for the instance for this node from Placement
1735                     # below as there is no guest consuming resources anyway.
1736                     # The _decode_files case could be handled more specifically
1737                     # but that's left for another day.
1738                     result = build_results.FAILED
1739                     raise
1740                 finally:
1741                     fails = (build_results.FAILED,
1742                              build_results.RESCHEDULED)
1743                     if result in fails:
1744                         # Remove the allocation records from Placement for
1745                         # the instance if the build failed or is being
1746                         # rescheduled to another node. The instance.host is
1747                         # likely set to None in _do_build_and_run_instance
1748                         # which means if the user deletes the instance, it will
1749                         # be deleted in the API, not the compute service.
1750                         # Setting the instance.host to None in
1751                         # _do_build_and_run_instance means that the
1752                         # ResourceTracker will no longer consider this instance
1753                         # to be claiming resources against it, so we want to
1754                         # reflect that same thing in Placement.
1755                         rt = self._get_resource_tracker()
1756                         rt.reportclient.delete_allocation_for_instance(
1757                             instance.uuid)
1758 
1759                         self._build_failed()
1760                     else:
1761                         self._failed_builds = 0
1762 
1763         # NOTE(danms): We spawn here to return the RPC worker thread back to
1764         # the pool. Since what follows could take a really long time, we don't
1765         # want to tie up RPC workers.
1766         utils.spawn_n(_locked_do_build_and_run_instance,
1767                       context, instance, image, request_spec,
1768                       filter_properties, admin_password, injected_files,
1769                       requested_networks, security_groups,
1770                       block_device_mapping, node, limits)
1771 
1772     def _check_device_tagging(self, requested_networks, block_device_mapping):
1773         tagging_requested = False
1774         if requested_networks:
1775             for net in requested_networks:
1776                 if 'tag' in net and net.tag is not None:
1777                     tagging_requested = True
1778                     break
1779         if block_device_mapping and not tagging_requested:
1780             for bdm in block_device_mapping:
1781                 if 'tag' in bdm and bdm.tag is not None:
1782                     tagging_requested = True
1783                     break
1784         if (tagging_requested and
1785                 not self.driver.capabilities.get('supports_device_tagging')):
1786             raise exception.BuildAbortException('Attempt to boot guest with '
1787                                                 'tagged devices on host that '
1788                                                 'does not support tagging.')
1789 
1790     @hooks.add_hook('build_instance')
1791     @wrap_exception()
1792     @reverts_task_state
1793     @wrap_instance_event(prefix='compute')
1794     @wrap_instance_fault
1795     def _do_build_and_run_instance(self, context, instance, image,
1796             request_spec, filter_properties, admin_password, injected_files,
1797             requested_networks, security_groups, block_device_mapping,
1798             node=None, limits=None):
1799 
1800         try:
1801             LOG.debug('Starting instance...', instance=instance)
1802             instance.vm_state = vm_states.BUILDING
1803             instance.task_state = None
1804             instance.save(expected_task_state=
1805                     (task_states.SCHEDULING, None))
1806         except exception.InstanceNotFound:
1807             msg = 'Instance disappeared before build.'
1808             LOG.debug(msg, instance=instance)
1809             return build_results.FAILED
1810         except exception.UnexpectedTaskStateError as e:
1811             LOG.debug(e.format_message(), instance=instance)
1812             return build_results.FAILED
1813 
1814         # b64 decode the files to inject:
1815         decoded_files = self._decode_files(injected_files)
1816 
1817         if limits is None:
1818             limits = {}
1819 
1820         if node is None:
1821             node = self.driver.get_available_nodes(refresh=True)[0]
1822             LOG.debug('No node specified, defaulting to %s', node,
1823                       instance=instance)
1824 
1825         try:
1826             with timeutils.StopWatch() as timer:
1827                 self._build_and_run_instance(context, instance, image,
1828                         decoded_files, admin_password, requested_networks,
1829                         security_groups, block_device_mapping, node, limits,
1830                         filter_properties)
1831             LOG.info('Took %0.2f seconds to build instance.',
1832                      timer.elapsed(), instance=instance)
1833             return build_results.ACTIVE
1834         except exception.RescheduledException as e:
1835             retry = filter_properties.get('retry')
1836             if not retry:
1837                 # no retry information, do not reschedule.
1838                 LOG.debug("Retry info not present, will not reschedule",
1839                     instance=instance)
1840                 self._cleanup_allocated_networks(context, instance,
1841                     requested_networks)
1842                 self._cleanup_volumes(context, instance.uuid,
1843                     block_device_mapping, raise_exc=False)
1844                 compute_utils.add_instance_fault_from_exc(context,
1845                         instance, e, sys.exc_info(),
1846                         fault_message=e.kwargs['reason'])
1847                 self._nil_out_instance_obj_host_and_node(instance)
1848                 self._set_instance_obj_error_state(context, instance,
1849                                                    clean_task_state=True)
1850                 return build_results.FAILED
1851             LOG.debug(e.format_message(), instance=instance)
1852             # This will be used for logging the exception
1853             retry['exc'] = traceback.format_exception(*sys.exc_info())
1854             # This will be used for setting the instance fault message
1855             retry['exc_reason'] = e.kwargs['reason']
1856             # NOTE(comstud): Deallocate networks if the driver wants
1857             # us to do so.
1858             # NOTE(vladikr): SR-IOV ports should be deallocated to
1859             # allow new sriov pci devices to be allocated on a new host.
1860             # Otherwise, if devices with pci addresses are already allocated
1861             # on the destination host, the instance will fail to spawn.
1862             # info_cache.network_info should be present at this stage.
1863             if (self.driver.deallocate_networks_on_reschedule(instance) or
1864                 self.deallocate_sriov_ports_on_reschedule(instance)):
1865                 self._cleanup_allocated_networks(context, instance,
1866                         requested_networks)
1867             else:
1868                 # NOTE(alex_xu): Network already allocated and we don't
1869                 # want to deallocate them before rescheduling. But we need
1870                 # to cleanup those network resources setup on this host before
1871                 # rescheduling.
1872                 self.network_api.cleanup_instance_network_on_host(
1873                     context, instance, self.host)
1874 
1875             self._nil_out_instance_obj_host_and_node(instance)
1876             instance.task_state = task_states.SCHEDULING
1877             instance.save()
1878 
1879             self.compute_task_api.build_instances(context, [instance],
1880                     image, filter_properties, admin_password,
1881                     injected_files, requested_networks, security_groups,
1882                     block_device_mapping)
1883             return build_results.RESCHEDULED
1884         except (exception.InstanceNotFound,
1885                 exception.UnexpectedDeletingTaskStateError):
1886             msg = 'Instance disappeared during build.'
1887             LOG.debug(msg, instance=instance)
1888             self._cleanup_allocated_networks(context, instance,
1889                     requested_networks)
1890             return build_results.FAILED
1891         except exception.BuildAbortException as e:
1892             LOG.exception(e.format_message(), instance=instance)
1893             self._cleanup_allocated_networks(context, instance,
1894                     requested_networks)
1895             self._cleanup_volumes(context, instance.uuid,
1896                     block_device_mapping, raise_exc=False)
1897             compute_utils.add_instance_fault_from_exc(context, instance,
1898                     e, sys.exc_info())
1899             self._nil_out_instance_obj_host_and_node(instance)
1900             self._set_instance_obj_error_state(context, instance,
1901                                                clean_task_state=True)
1902             return build_results.FAILED
1903         except Exception as e:
1904             # Should not reach here.
1905             LOG.exception('Unexpected build failure, not rescheduling build.',
1906                           instance=instance)
1907             self._cleanup_allocated_networks(context, instance,
1908                     requested_networks)
1909             self._cleanup_volumes(context, instance.uuid,
1910                     block_device_mapping, raise_exc=False)
1911             compute_utils.add_instance_fault_from_exc(context, instance,
1912                     e, sys.exc_info())
1913             self._nil_out_instance_obj_host_and_node(instance)
1914             self._set_instance_obj_error_state(context, instance,
1915                                                clean_task_state=True)
1916             return build_results.FAILED
1917 
1918     def deallocate_sriov_ports_on_reschedule(self, instance):
1919         """Determine if networks are needed to be deallocated before reschedule
1920 
1921         Check the cached network info for any assigned SR-IOV ports.
1922         SR-IOV ports should be deallocated prior to rescheduling
1923         in order to allow new sriov pci devices to be allocated on a new host.
1924         """
1925         info_cache = instance.info_cache
1926 
1927         def _has_sriov_port(vif):
1928             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1929 
1930         if (info_cache and info_cache.network_info):
1931             for vif in info_cache.network_info:
1932                 if _has_sriov_port(vif):
1933                     return True
1934         return False
1935 
1936     def _build_and_run_instance(self, context, instance, image, injected_files,
1937             admin_password, requested_networks, security_groups,
1938             block_device_mapping, node, limits, filter_properties):
1939 
1940         image_name = image.get('name')
1941         self._notify_about_instance_usage(context, instance, 'create.start',
1942                 extra_usage_info={'image_name': image_name})
1943         compute_utils.notify_about_instance_create(
1944             context, instance, self.host,
1945             phase=fields.NotificationPhase.START)
1946 
1947         # NOTE(mikal): cache the keystone roles associated with the instance
1948         # at boot time for later reference
1949         instance.system_metadata.update(
1950             {'boot_roles': ','.join(context.roles)})
1951 
1952         self._check_device_tagging(requested_networks, block_device_mapping)
1953 
1954         try:
1955             rt = self._get_resource_tracker()
1956             with rt.instance_claim(context, instance, node, limits):
1957                 # NOTE(russellb) It's important that this validation be done
1958                 # *after* the resource tracker instance claim, as that is where
1959                 # the host is set on the instance.
1960                 self._validate_instance_group_policy(context, instance,
1961                         filter_properties)
1962                 image_meta = objects.ImageMeta.from_dict(image)
1963                 with self._build_resources(context, instance,
1964                         requested_networks, security_groups, image_meta,
1965                         block_device_mapping) as resources:
1966                     instance.vm_state = vm_states.BUILDING
1967                     instance.task_state = task_states.SPAWNING
1968                     # NOTE(JoshNang) This also saves the changes to the
1969                     # instance from _allocate_network_async, as they aren't
1970                     # saved in that function to prevent races.
1971                     instance.save(expected_task_state=
1972                             task_states.BLOCK_DEVICE_MAPPING)
1973                     block_device_info = resources['block_device_info']
1974                     network_info = resources['network_info']
1975                     LOG.debug('Start spawning the instance on the hypervisor.',
1976                               instance=instance)
1977                     with timeutils.StopWatch() as timer:
1978                         self.driver.spawn(context, instance, image_meta,
1979                                           injected_files, admin_password,
1980                                           network_info=network_info,
1981                                           block_device_info=block_device_info)
1982                     LOG.info('Took %0.2f seconds to spawn the instance on '
1983                              'the hypervisor.', timer.elapsed(),
1984                              instance=instance)
1985         except (exception.InstanceNotFound,
1986                 exception.UnexpectedDeletingTaskStateError) as e:
1987             with excutils.save_and_reraise_exception():
1988                 self._notify_about_instance_usage(context, instance,
1989                     'create.error', fault=e)
1990                 compute_utils.notify_about_instance_create(
1991                     context, instance, self.host,
1992                     phase=fields.NotificationPhase.ERROR, exception=e)
1993         except exception.ComputeResourcesUnavailable as e:
1994             LOG.debug(e.format_message(), instance=instance)
1995             self._notify_about_instance_usage(context, instance,
1996                     'create.error', fault=e)
1997             compute_utils.notify_about_instance_create(
1998                     context, instance, self.host,
1999                     phase=fields.NotificationPhase.ERROR, exception=e)
2000             raise exception.RescheduledException(
2001                     instance_uuid=instance.uuid, reason=e.format_message())
2002         except exception.BuildAbortException as e:
2003             with excutils.save_and_reraise_exception():
2004                 LOG.debug(e.format_message(), instance=instance)
2005                 self._notify_about_instance_usage(context, instance,
2006                     'create.error', fault=e)
2007                 compute_utils.notify_about_instance_create(
2008                     context, instance, self.host,
2009                     phase=fields.NotificationPhase.ERROR, exception=e)
2010         except (exception.FixedIpLimitExceeded,
2011                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2012             LOG.warning('No more network or fixed IP to be allocated',
2013                         instance=instance)
2014             self._notify_about_instance_usage(context, instance,
2015                     'create.error', fault=e)
2016             compute_utils.notify_about_instance_create(
2017                     context, instance, self.host,
2018                     phase=fields.NotificationPhase.ERROR, exception=e)
2019             msg = _('Failed to allocate the network(s) with error %s, '
2020                     'not rescheduling.') % e.format_message()
2021             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2022                     reason=msg)
2023         except (exception.VirtualInterfaceCreateException,
2024                 exception.VirtualInterfaceMacAddressException,
2025                 exception.FixedIpInvalidOnHost,
2026                 exception.UnableToAutoAllocateNetwork) as e:
2027             LOG.exception('Failed to allocate network(s)',
2028                           instance=instance)
2029             self._notify_about_instance_usage(context, instance,
2030                     'create.error', fault=e)
2031             compute_utils.notify_about_instance_create(
2032                     context, instance, self.host,
2033                     phase=fields.NotificationPhase.ERROR, exception=e)
2034             msg = _('Failed to allocate the network(s), not rescheduling.')
2035             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2036                     reason=msg)
2037         except (exception.FlavorDiskTooSmall,
2038                 exception.FlavorMemoryTooSmall,
2039                 exception.ImageNotActive,
2040                 exception.ImageUnacceptable,
2041                 exception.InvalidDiskInfo,
2042                 exception.InvalidDiskFormat,
2043                 cursive_exception.SignatureVerificationError,
2044                 exception.VolumeEncryptionNotSupported,
2045                 exception.InvalidInput) as e:
2046             self._notify_about_instance_usage(context, instance,
2047                     'create.error', fault=e)
2048             compute_utils.notify_about_instance_create(
2049                     context, instance, self.host,
2050                     phase=fields.NotificationPhase.ERROR, exception=e)
2051             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2052                     reason=e.format_message())
2053         except Exception as e:
2054             self._notify_about_instance_usage(context, instance,
2055                     'create.error', fault=e)
2056             compute_utils.notify_about_instance_create(
2057                     context, instance, self.host,
2058                     phase=fields.NotificationPhase.ERROR, exception=e)
2059             raise exception.RescheduledException(
2060                     instance_uuid=instance.uuid, reason=six.text_type(e))
2061 
2062         # NOTE(alaski): This is only useful during reschedules, remove it now.
2063         instance.system_metadata.pop('network_allocated', None)
2064 
2065         # If CONF.default_access_ip_network_name is set, grab the
2066         # corresponding network and set the access ip values accordingly.
2067         network_name = CONF.default_access_ip_network_name
2068         if (network_name and not instance.access_ip_v4 and
2069                 not instance.access_ip_v6):
2070             # Note that when there are multiple ips to choose from, an
2071             # arbitrary one will be chosen.
2072             for vif in network_info:
2073                 if vif['network']['label'] == network_name:
2074                     for ip in vif.fixed_ips():
2075                         if not instance.access_ip_v4 and ip['version'] == 4:
2076                             instance.access_ip_v4 = ip['address']
2077                         if not instance.access_ip_v6 and ip['version'] == 6:
2078                             instance.access_ip_v6 = ip['address']
2079                     break
2080 
2081         self._update_instance_after_spawn(context, instance)
2082 
2083         try:
2084             instance.save(expected_task_state=task_states.SPAWNING)
2085         except (exception.InstanceNotFound,
2086                 exception.UnexpectedDeletingTaskStateError) as e:
2087             with excutils.save_and_reraise_exception():
2088                 self._notify_about_instance_usage(context, instance,
2089                     'create.error', fault=e)
2090                 compute_utils.notify_about_instance_create(
2091                     context, instance, self.host,
2092                     phase=fields.NotificationPhase.ERROR, exception=e)
2093 
2094         self._update_scheduler_instance_info(context, instance)
2095         self._notify_about_instance_usage(context, instance, 'create.end',
2096                 extra_usage_info={'message': _('Success')},
2097                 network_info=network_info)
2098         compute_utils.notify_about_instance_create(context, instance,
2099                 self.host, phase=fields.NotificationPhase.END)
2100 
2101     @contextlib.contextmanager
2102     def _build_resources(self, context, instance, requested_networks,
2103                          security_groups, image_meta, block_device_mapping):
2104         resources = {}
2105         network_info = None
2106         try:
2107             LOG.debug('Start building networks asynchronously for instance.',
2108                       instance=instance)
2109             network_info = self._build_networks_for_instance(context, instance,
2110                     requested_networks, security_groups)
2111             resources['network_info'] = network_info
2112         except (exception.InstanceNotFound,
2113                 exception.UnexpectedDeletingTaskStateError):
2114             raise
2115         except exception.UnexpectedTaskStateError as e:
2116             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2117                     reason=e.format_message())
2118         except Exception:
2119             # Because this allocation is async any failures are likely to occur
2120             # when the driver accesses network_info during spawn().
2121             LOG.exception('Failed to allocate network(s)',
2122                           instance=instance)
2123             msg = _('Failed to allocate the network(s), not rescheduling.')
2124             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2125                     reason=msg)
2126 
2127         try:
2128             # Verify that all the BDMs have a device_name set and assign a
2129             # default to the ones missing it with the help of the driver.
2130             self._default_block_device_names(instance, image_meta,
2131                                              block_device_mapping)
2132 
2133             LOG.debug('Start building block device mappings for instance.',
2134                       instance=instance)
2135             instance.vm_state = vm_states.BUILDING
2136             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2137             instance.save()
2138 
2139             block_device_info = self._prep_block_device(context, instance,
2140                     block_device_mapping)
2141             resources['block_device_info'] = block_device_info
2142         except (exception.InstanceNotFound,
2143                 exception.UnexpectedDeletingTaskStateError):
2144             with excutils.save_and_reraise_exception():
2145                 # Make sure the async call finishes
2146                 if network_info is not None:
2147                     network_info.wait(do_raise=False)
2148         except (exception.UnexpectedTaskStateError,
2149                 exception.OverQuota, exception.InvalidBDM) as e:
2150             # Make sure the async call finishes
2151             if network_info is not None:
2152                 network_info.wait(do_raise=False)
2153             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2154                     reason=e.format_message())
2155         except Exception:
2156             LOG.exception('Failure prepping block device',
2157                           instance=instance)
2158             # Make sure the async call finishes
2159             if network_info is not None:
2160                 network_info.wait(do_raise=False)
2161             msg = _('Failure prepping block device.')
2162             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2163                     reason=msg)
2164 
2165         try:
2166             yield resources
2167         except Exception as exc:
2168             with excutils.save_and_reraise_exception() as ctxt:
2169                 if not isinstance(exc, (
2170                         exception.InstanceNotFound,
2171                         exception.UnexpectedDeletingTaskStateError)):
2172                     LOG.exception('Instance failed to spawn',
2173                                   instance=instance)
2174                 # Make sure the async call finishes
2175                 if network_info is not None:
2176                     network_info.wait(do_raise=False)
2177                 # if network_info is empty we're likely here because of
2178                 # network allocation failure. Since nothing can be reused on
2179                 # rescheduling it's better to deallocate network to eliminate
2180                 # the chance of orphaned ports in neutron
2181                 deallocate_networks = False if network_info else True
2182                 try:
2183                     self._shutdown_instance(context, instance,
2184                             block_device_mapping, requested_networks,
2185                             try_deallocate_networks=deallocate_networks)
2186                 except Exception as exc2:
2187                     ctxt.reraise = False
2188                     LOG.warning('Could not clean up failed build,'
2189                                 ' not rescheduling. Error: %s',
2190                                 six.text_type(exc2))
2191                     raise exception.BuildAbortException(
2192                             instance_uuid=instance.uuid,
2193                             reason=six.text_type(exc))
2194 
2195     def _cleanup_allocated_networks(self, context, instance,
2196             requested_networks):
2197         try:
2198             self._deallocate_network(context, instance, requested_networks)
2199         except Exception:
2200             LOG.exception('Failed to deallocate networks', instance=instance)
2201             return
2202 
2203         instance.system_metadata['network_allocated'] = 'False'
2204         try:
2205             instance.save()
2206         except exception.InstanceNotFound:
2207             # NOTE(alaski): It's possible that we're cleaning up the networks
2208             # because the instance was deleted.  If that's the case then this
2209             # exception will be raised by instance.save()
2210             pass
2211 
2212     def _try_deallocate_network(self, context, instance,
2213                                 requested_networks=None):
2214         try:
2215             # tear down allocated network structure
2216             self._deallocate_network(context, instance, requested_networks)
2217         except Exception as ex:
2218             with excutils.save_and_reraise_exception():
2219                 LOG.error('Failed to deallocate network for instance. '
2220                           'Error: %s', ex, instance=instance)
2221                 self._set_instance_obj_error_state(context, instance)
2222 
2223     def _get_power_off_values(self, context, instance, clean_shutdown):
2224         """Get the timing configuration for powering down this instance."""
2225         if clean_shutdown:
2226             timeout = compute_utils.get_value_from_system_metadata(instance,
2227                           key='image_os_shutdown_timeout', type=int,
2228                           default=CONF.shutdown_timeout)
2229             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2230         else:
2231             timeout = 0
2232             retry_interval = 0
2233 
2234         return timeout, retry_interval
2235 
2236     def _power_off_instance(self, context, instance, clean_shutdown=True):
2237         """Power off an instance on this host."""
2238         timeout, retry_interval = self._get_power_off_values(context,
2239                                         instance, clean_shutdown)
2240         self.driver.power_off(instance, timeout, retry_interval)
2241 
2242     def _shutdown_instance(self, context, instance,
2243                            bdms, requested_networks=None, notify=True,
2244                            try_deallocate_networks=True):
2245         """Shutdown an instance on this host.
2246 
2247         :param:context: security context
2248         :param:instance: a nova.objects.Instance object
2249         :param:bdms: the block devices for the instance to be torn
2250                      down
2251         :param:requested_networks: the networks on which the instance
2252                                    has ports
2253         :param:notify: true if a final usage notification should be
2254                        emitted
2255         :param:try_deallocate_networks: false if we should avoid
2256                                         trying to teardown networking
2257         """
2258         context = context.elevated()
2259         LOG.info('Terminating instance', instance=instance)
2260 
2261         if notify:
2262             self._notify_about_instance_usage(context, instance,
2263                                               "shutdown.start")
2264             compute_utils.notify_about_instance_action(context, instance,
2265                     self.host, action=fields.NotificationAction.SHUTDOWN,
2266                     phase=fields.NotificationPhase.START)
2267 
2268         network_info = instance.get_network_info()
2269 
2270         # NOTE(vish) get bdms before destroying the instance
2271         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2272         block_device_info = self._get_instance_block_device_info(
2273             context, instance, bdms=bdms)
2274 
2275         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2276         #                want to keep ip allocated for certain failures
2277         timer = timeutils.StopWatch()
2278         try:
2279             LOG.debug('Start destroying the instance on the hypervisor.',
2280                       instance=instance)
2281             timer.start()
2282             self.driver.destroy(context, instance, network_info,
2283                     block_device_info)
2284             LOG.info('Took %0.2f seconds to destroy the instance on the '
2285                      'hypervisor.', timer.elapsed(), instance=instance)
2286         except exception.InstancePowerOffFailure:
2287             # if the instance can't power off, don't release the ip
2288             with excutils.save_and_reraise_exception():
2289                 pass
2290         except Exception:
2291             with excutils.save_and_reraise_exception():
2292                 # deallocate ip and fail without proceeding to
2293                 # volume api calls, preserving current behavior
2294                 if try_deallocate_networks:
2295                     self._try_deallocate_network(context, instance,
2296                                                  requested_networks)
2297 
2298         if try_deallocate_networks:
2299             self._try_deallocate_network(context, instance, requested_networks)
2300 
2301         timer.restart()
2302         for bdm in vol_bdms:
2303             try:
2304                 if bdm.attachment_id:
2305                     self.volume_api.attachment_delete(context,
2306                                                       bdm.attachment_id)
2307                 else:
2308                     # NOTE(vish): actual driver detach done in driver.destroy,
2309                     #             so just tell cinder that we are done with it.
2310                     connector = self.driver.get_volume_connector(instance)
2311                     self.volume_api.terminate_connection(context,
2312                                                          bdm.volume_id,
2313                                                          connector)
2314                     self.volume_api.detach(context, bdm.volume_id,
2315                                            instance.uuid)
2316 
2317             except exception.VolumeAttachmentNotFound as exc:
2318                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2319                           instance=instance)
2320             except exception.DiskNotFound as exc:
2321                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2322                           instance=instance)
2323             except exception.VolumeNotFound as exc:
2324                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2325                           instance=instance)
2326             except (cinder_exception.EndpointNotFound,
2327                     keystone_exception.EndpointNotFound) as exc:
2328                 LOG.warning('Ignoring EndpointNotFound for '
2329                             'volume %(volume_id)s: %(exc)s',
2330                             {'exc': exc, 'volume_id': bdm.volume_id},
2331                             instance=instance)
2332             except cinder_exception.ClientException as exc:
2333                 LOG.warning('Ignoring unknown cinder exception for '
2334                             'volume %(volume_id)s: %(exc)s',
2335                             {'exc': exc, 'volume_id': bdm.volume_id},
2336                             instance=instance)
2337             except Exception as exc:
2338                 LOG.warning('Ignoring unknown exception for '
2339                             'volume %(volume_id)s: %(exc)s',
2340                             {'exc': exc, 'volume_id': bdm.volume_id},
2341                             instance=instance)
2342         if vol_bdms:
2343             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2344                      'for instance.',
2345                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2346                      instance=instance)
2347 
2348         if notify:
2349             self._notify_about_instance_usage(context, instance,
2350                                               "shutdown.end")
2351             compute_utils.notify_about_instance_action(context, instance,
2352                     self.host, action=fields.NotificationAction.SHUTDOWN,
2353                     phase=fields.NotificationPhase.END)
2354 
2355     def _cleanup_volumes(self, context, instance_uuid, bdms, raise_exc=True):
2356         exc_info = None
2357 
2358         for bdm in bdms:
2359             LOG.debug("terminating bdm %s", bdm,
2360                       instance_uuid=instance_uuid)
2361             if bdm.volume_id and bdm.delete_on_termination:
2362                 try:
2363                     self.volume_api.delete(context, bdm.volume_id)
2364                 except Exception as exc:
2365                     exc_info = sys.exc_info()
2366                     LOG.warning('Failed to delete volume: %(volume_id)s '
2367                                 'due to %(exc)s',
2368                                 {'volume_id': bdm.volume_id, 'exc': exc})
2369         if exc_info is not None and raise_exc:
2370             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2371 
2372     @hooks.add_hook("delete_instance")
2373     def _delete_instance(self, context, instance, bdms):
2374         """Delete an instance on this host.
2375 
2376         :param context: nova request context
2377         :param instance: nova.objects.instance.Instance object
2378         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2379         """
2380         events = self.instance_events.clear_events_for_instance(instance)
2381         if events:
2382             LOG.debug('Events pending at deletion: %(events)s',
2383                       {'events': ','.join(events.keys())},
2384                       instance=instance)
2385         self._notify_about_instance_usage(context, instance,
2386                                           "delete.start")
2387         compute_utils.notify_about_instance_action(context, instance,
2388                 self.host, action=fields.NotificationAction.DELETE,
2389                 phase=fields.NotificationPhase.START)
2390 
2391         self._shutdown_instance(context, instance, bdms)
2392         # NOTE(dims): instance.info_cache.delete() should be called after
2393         # _shutdown_instance in the compute manager as shutdown calls
2394         # deallocate_for_instance so the info_cache is still needed
2395         # at this point.
2396         if instance.info_cache is not None:
2397             instance.info_cache.delete()
2398         else:
2399             # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2400             # is None. When the root cause that instance.info_cache becomes
2401             # None is fixed, the log level should be reconsidered.
2402             LOG.warning("Info cache for instance could not be found. "
2403                         "Ignore.", instance=instance)
2404 
2405         # NOTE(vish): We have already deleted the instance, so we have
2406         #             to ignore problems cleaning up the volumes. It
2407         #             would be nice to let the user know somehow that
2408         #             the volume deletion failed, but it is not
2409         #             acceptable to have an instance that can not be
2410         #             deleted. Perhaps this could be reworked in the
2411         #             future to set an instance fault the first time
2412         #             and to only ignore the failure if the instance
2413         #             is already in ERROR.
2414         self._cleanup_volumes(context, instance.uuid, bdms,
2415                 raise_exc=False)
2416         # if a delete task succeeded, always update vm state and task
2417         # state without expecting task state to be DELETING
2418         instance.vm_state = vm_states.DELETED
2419         instance.task_state = None
2420         instance.power_state = power_state.NOSTATE
2421         instance.terminated_at = timeutils.utcnow()
2422         instance.save()
2423         system_meta = instance.system_metadata
2424         instance.destroy()
2425 
2426         self._complete_deletion(context,
2427                                 instance,
2428                                 bdms,
2429                                 system_meta)
2430 
2431     @wrap_exception()
2432     @reverts_task_state
2433     @wrap_instance_event(prefix='compute')
2434     @wrap_instance_fault
2435     def terminate_instance(self, context, instance, bdms, reservations):
2436         """Terminate an instance on this host."""
2437         @utils.synchronized(instance.uuid)
2438         def do_terminate_instance(instance, bdms):
2439             # NOTE(mriedem): If we are deleting the instance while it was
2440             # booting from volume, we could be racing with a database update of
2441             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2442             # to compute here, the BDMs may be stale at this point. So check
2443             # for any volume BDMs that don't have volume_id set and if we
2444             # detect that, we need to refresh the BDM list before proceeding.
2445             # TODO(mriedem): Move this into _delete_instance and make the bdms
2446             # parameter optional.
2447             for bdm in list(bdms):
2448                 if bdm.is_volume and not bdm.volume_id:
2449                     LOG.debug('There are potentially stale BDMs during '
2450                               'delete, refreshing the BlockDeviceMappingList.',
2451                               instance=instance)
2452                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2453                         context, instance.uuid)
2454                     break
2455             try:
2456                 self._delete_instance(context, instance, bdms)
2457             except exception.InstanceNotFound:
2458                 LOG.info("Instance disappeared during terminate",
2459                          instance=instance)
2460             except Exception:
2461                 # As we're trying to delete always go to Error if something
2462                 # goes wrong that _delete_instance can't handle.
2463                 with excutils.save_and_reraise_exception():
2464                     LOG.exception('Setting instance vm_state to ERROR',
2465                                   instance=instance)
2466                     self._set_instance_obj_error_state(context, instance)
2467 
2468         do_terminate_instance(instance, bdms)
2469 
2470     # NOTE(johannes): This is probably better named power_off_instance
2471     # so it matches the driver method, but because of other issues, we
2472     # can't use that name in grizzly.
2473     @wrap_exception()
2474     @reverts_task_state
2475     @wrap_instance_event(prefix='compute')
2476     @wrap_instance_fault
2477     def stop_instance(self, context, instance, clean_shutdown):
2478         """Stopping an instance on this host."""
2479 
2480         @utils.synchronized(instance.uuid)
2481         def do_stop_instance():
2482             current_power_state = self._get_power_state(context, instance)
2483             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2484                       'current task_state: %(task_state)s, current DB '
2485                       'power_state: %(db_power_state)s, current VM '
2486                       'power_state: %(current_power_state)s',
2487                       {'vm_state': instance.vm_state,
2488                        'task_state': instance.task_state,
2489                        'db_power_state': instance.power_state,
2490                        'current_power_state': current_power_state},
2491                       instance_uuid=instance.uuid)
2492 
2493             # NOTE(mriedem): If the instance is already powered off, we are
2494             # possibly tearing down and racing with other operations, so we can
2495             # expect the task_state to be None if something else updates the
2496             # instance and we're not locking it.
2497             expected_task_state = [task_states.POWERING_OFF]
2498             # The list of power states is from _sync_instance_power_state.
2499             if current_power_state in (power_state.NOSTATE,
2500                                        power_state.SHUTDOWN,
2501                                        power_state.CRASHED):
2502                 LOG.info('Instance is already powered off in the '
2503                          'hypervisor when stop is called.',
2504                          instance=instance)
2505                 expected_task_state.append(None)
2506 
2507             self._notify_about_instance_usage(context, instance,
2508                                               "power_off.start")
2509 
2510             compute_utils.notify_about_instance_action(context, instance,
2511                         self.host, action=fields.NotificationAction.POWER_OFF,
2512                         phase=fields.NotificationPhase.START)
2513 
2514             self._power_off_instance(context, instance, clean_shutdown)
2515             instance.power_state = self._get_power_state(context, instance)
2516             instance.vm_state = vm_states.STOPPED
2517             instance.task_state = None
2518             instance.save(expected_task_state=expected_task_state)
2519             self._notify_about_instance_usage(context, instance,
2520                                               "power_off.end")
2521 
2522             compute_utils.notify_about_instance_action(context, instance,
2523                         self.host, action=fields.NotificationAction.POWER_OFF,
2524                         phase=fields.NotificationPhase.END)
2525 
2526         do_stop_instance()
2527 
2528     def _power_on(self, context, instance):
2529         network_info = self.network_api.get_instance_nw_info(context, instance)
2530         block_device_info = self._get_instance_block_device_info(context,
2531                                                                  instance)
2532         self.driver.power_on(context, instance,
2533                              network_info,
2534                              block_device_info)
2535 
2536     def _delete_snapshot_of_shelved_instance(self, context, instance,
2537                                              snapshot_id):
2538         """Delete snapshot of shelved instance."""
2539         try:
2540             self.image_api.delete(context, snapshot_id)
2541         except (exception.ImageNotFound,
2542                 exception.ImageNotAuthorized) as exc:
2543             LOG.warning("Failed to delete snapshot "
2544                         "from shelved instance (%s).",
2545                         exc.format_message(), instance=instance)
2546         except Exception:
2547             LOG.exception("Something wrong happened when trying to "
2548                           "delete snapshot from shelved instance.",
2549                           instance=instance)
2550 
2551     # NOTE(johannes): This is probably better named power_on_instance
2552     # so it matches the driver method, but because of other issues, we
2553     # can't use that name in grizzly.
2554     @wrap_exception()
2555     @reverts_task_state
2556     @wrap_instance_event(prefix='compute')
2557     @wrap_instance_fault
2558     def start_instance(self, context, instance):
2559         """Starting an instance on this host."""
2560         self._notify_about_instance_usage(context, instance, "power_on.start")
2561         compute_utils.notify_about_instance_action(context, instance,
2562             self.host, action=fields.NotificationAction.POWER_ON,
2563             phase=fields.NotificationPhase.START)
2564         self._power_on(context, instance)
2565         instance.power_state = self._get_power_state(context, instance)
2566         instance.vm_state = vm_states.ACTIVE
2567         instance.task_state = None
2568 
2569         # Delete an image(VM snapshot) for a shelved instance
2570         snapshot_id = instance.system_metadata.get('shelved_image_id')
2571         if snapshot_id:
2572             self._delete_snapshot_of_shelved_instance(context, instance,
2573                                                       snapshot_id)
2574 
2575         # Delete system_metadata for a shelved instance
2576         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2577 
2578         instance.save(expected_task_state=task_states.POWERING_ON)
2579         self._notify_about_instance_usage(context, instance, "power_on.end")
2580         compute_utils.notify_about_instance_action(context, instance,
2581             self.host, action=fields.NotificationAction.POWER_ON,
2582             phase=fields.NotificationPhase.END)
2583 
2584     @messaging.expected_exceptions(NotImplementedError,
2585                                    exception.TriggerCrashDumpNotSupported,
2586                                    exception.InstanceNotRunning)
2587     @wrap_exception()
2588     @wrap_instance_event(prefix='compute')
2589     @wrap_instance_fault
2590     def trigger_crash_dump(self, context, instance):
2591         """Trigger crash dump in an instance."""
2592 
2593         self._notify_about_instance_usage(context, instance,
2594                                           "trigger_crash_dump.start")
2595 
2596         # This method does not change task_state and power_state because the
2597         # effect of a trigger depends on user's configuration.
2598         self.driver.trigger_crash_dump(instance)
2599 
2600         self._notify_about_instance_usage(context, instance,
2601                                           "trigger_crash_dump.end")
2602 
2603     @wrap_exception()
2604     @reverts_task_state
2605     @wrap_instance_event(prefix='compute')
2606     @wrap_instance_fault
2607     def soft_delete_instance(self, context, instance, reservations):
2608         """Soft delete an instance on this host."""
2609         self._notify_about_instance_usage(context, instance,
2610                                           "soft_delete.start")
2611         compute_utils.notify_about_instance_action(context, instance,
2612             self.host, action=fields.NotificationAction.SOFT_DELETE,
2613             phase=fields.NotificationPhase.START)
2614         try:
2615             self.driver.soft_delete(instance)
2616         except NotImplementedError:
2617             # Fallback to just powering off the instance if the
2618             # hypervisor doesn't implement the soft_delete method
2619             self.driver.power_off(instance)
2620         instance.power_state = self._get_power_state(context, instance)
2621         instance.vm_state = vm_states.SOFT_DELETED
2622         instance.task_state = None
2623         instance.save(expected_task_state=[task_states.SOFT_DELETING])
2624         self._notify_about_instance_usage(context, instance, "soft_delete.end")
2625         compute_utils.notify_about_instance_action(context, instance,
2626             self.host, action=fields.NotificationAction.SOFT_DELETE,
2627             phase=fields.NotificationPhase.END)
2628 
2629     @wrap_exception()
2630     @reverts_task_state
2631     @wrap_instance_event(prefix='compute')
2632     @wrap_instance_fault
2633     def restore_instance(self, context, instance):
2634         """Restore a soft-deleted instance on this host."""
2635         self._notify_about_instance_usage(context, instance, "restore.start")
2636         compute_utils.notify_about_instance_action(context, instance,
2637             self.host, action=fields.NotificationAction.RESTORE,
2638             phase=fields.NotificationPhase.START)
2639         try:
2640             self.driver.restore(instance)
2641         except NotImplementedError:
2642             # Fallback to just powering on the instance if the hypervisor
2643             # doesn't implement the restore method
2644             self._power_on(context, instance)
2645         instance.power_state = self._get_power_state(context, instance)
2646         instance.vm_state = vm_states.ACTIVE
2647         instance.task_state = None
2648         instance.save(expected_task_state=task_states.RESTORING)
2649         self._notify_about_instance_usage(context, instance, "restore.end")
2650         compute_utils.notify_about_instance_action(context, instance,
2651             self.host, action=fields.NotificationAction.RESTORE,
2652             phase=fields.NotificationPhase.END)
2653 
2654     @staticmethod
2655     def _set_migration_status(migration, status):
2656         """Set the status, and guard against a None being passed in.
2657 
2658         This is useful as some of the compute RPC calls will not pass
2659         a migration object in older versions. The check can be removed when
2660         we move past 4.x major version of the RPC API.
2661         """
2662         if migration:
2663             migration.status = status
2664             migration.save()
2665 
2666     def _rebuild_default_impl(self, context, instance, image_meta,
2667                               injected_files, admin_password, bdms,
2668                               detach_block_devices, attach_block_devices,
2669                               network_info=None,
2670                               recreate=False, block_device_info=None,
2671                               preserve_ephemeral=False):
2672         if preserve_ephemeral:
2673             # The default code path does not support preserving ephemeral
2674             # partitions.
2675             raise exception.PreserveEphemeralNotSupported()
2676 
2677         if recreate:
2678             detach_block_devices(context, bdms)
2679         else:
2680             self._power_off_instance(context, instance, clean_shutdown=True)
2681             detach_block_devices(context, bdms)
2682             self.driver.destroy(context, instance,
2683                                 network_info=network_info,
2684                                 block_device_info=block_device_info)
2685 
2686         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2687         instance.save(expected_task_state=[task_states.REBUILDING])
2688 
2689         new_block_device_info = attach_block_devices(context, instance, bdms)
2690 
2691         instance.task_state = task_states.REBUILD_SPAWNING
2692         instance.save(
2693             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2694 
2695         with instance.mutated_migration_context():
2696             self.driver.spawn(context, instance, image_meta, injected_files,
2697                               admin_password, network_info=network_info,
2698                               block_device_info=new_block_device_info)
2699 
2700     def _notify_instance_rebuild_error(self, context, instance, error):
2701         self._notify_about_instance_usage(context, instance,
2702                                           'rebuild.error', fault=error)
2703         compute_utils.notify_about_instance_action(
2704             context, instance, self.host,
2705             action=fields.NotificationAction.REBUILD,
2706             phase=fields.NotificationPhase.ERROR, exception=error)
2707 
2708     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2709     @wrap_exception()
2710     @reverts_task_state
2711     @wrap_instance_event(prefix='compute')
2712     @wrap_instance_fault
2713     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2714                          injected_files, new_pass, orig_sys_metadata,
2715                          bdms, recreate, on_shared_storage=None,
2716                          preserve_ephemeral=False, migration=None,
2717                          scheduled_node=None, limits=None):
2718         """Destroy and re-make this instance.
2719 
2720         A 'rebuild' effectively purges all existing data from the system and
2721         remakes the VM with given 'metadata' and 'personalities'.
2722 
2723         :param context: `nova.RequestContext` object
2724         :param instance: Instance object
2725         :param orig_image_ref: Original image_ref before rebuild
2726         :param image_ref: New image_ref for rebuild
2727         :param injected_files: Files to inject
2728         :param new_pass: password to set on rebuilt instance
2729         :param orig_sys_metadata: instance system metadata from pre-rebuild
2730         :param bdms: block-device-mappings to use for rebuild
2731         :param recreate: True if the instance is being recreated (e.g. the
2732             hypervisor it was on failed) - cleanup of old state will be
2733             skipped.
2734         :param on_shared_storage: True if instance files on shared storage.
2735                                   If not provided then information from the
2736                                   driver will be used to decide if the instance
2737                                   files are available or not on the target host
2738         :param preserve_ephemeral: True if the default ephemeral storage
2739                                    partition must be preserved on rebuild
2740         :param migration: a Migration object if one was created for this
2741                           rebuild operation (if it's a part of evacuate)
2742         :param scheduled_node: A node of the host chosen by the scheduler. If a
2743                                host was specified by the user, this will be
2744                                None
2745         :param limits: Overcommit limits set by the scheduler. If a host was
2746                        specified by the user, this will be None
2747         """
2748         context = context.elevated()
2749 
2750         LOG.info("Rebuilding instance", instance=instance)
2751 
2752         # NOTE(gyee): there are three possible scenarios.
2753         #
2754         #   1. instance is being rebuilt on the same node. In this case,
2755         #      recreate should be False and scheduled_node should be None.
2756         #   2. instance is being rebuilt on a node chosen by the
2757         #      scheduler (i.e. evacuate). In this case, scheduled_node should
2758         #      be specified and recreate should be True.
2759         #   3. instance is being rebuilt on a node chosen by the user. (i.e.
2760         #      force evacuate). In this case, scheduled_node is not specified
2761         #      and recreate is set to True.
2762         #
2763         # For scenarios #2 and #3, we must do rebuild claim as server is
2764         # being evacuated to a different node.
2765         if recreate or scheduled_node is not None:
2766             rt = self._get_resource_tracker()
2767             rebuild_claim = rt.rebuild_claim
2768         else:
2769             rebuild_claim = claims.NopClaim
2770 
2771         image_meta = {}
2772         if image_ref:
2773             image_meta = self.image_api.get(context, image_ref)
2774 
2775         # NOTE(mriedem): On a recreate (evacuate), we need to update
2776         # the instance's host and node properties to reflect it's
2777         # destination node for the recreate.
2778         if not scheduled_node:
2779             if recreate:
2780                 try:
2781                     compute_node = self._get_compute_info(context, self.host)
2782                     scheduled_node = compute_node.hypervisor_hostname
2783                 except exception.ComputeHostNotFound:
2784                     LOG.exception('Failed to get compute_info for %s',
2785                                   self.host)
2786             else:
2787                 scheduled_node = instance.node
2788 
2789         with self._error_out_instance_on_exception(context, instance):
2790             try:
2791                 claim_ctxt = rebuild_claim(
2792                     context, instance, scheduled_node,
2793                     limits=limits, image_meta=image_meta,
2794                     migration=migration)
2795                 self._do_rebuild_instance_with_claim(
2796                     claim_ctxt, context, instance, orig_image_ref,
2797                     image_ref, injected_files, new_pass, orig_sys_metadata,
2798                     bdms, recreate, on_shared_storage, preserve_ephemeral)
2799             except exception.ComputeResourcesUnavailable as e:
2800                 LOG.debug("Could not rebuild instance on this host, not "
2801                           "enough resources available.", instance=instance)
2802 
2803                 # NOTE(ndipanov): We just abort the build for now and leave a
2804                 # migration record for potential cleanup later
2805                 self._set_migration_status(migration, 'failed')
2806                 self._notify_instance_rebuild_error(context, instance, e)
2807 
2808                 raise exception.BuildAbortException(
2809                     instance_uuid=instance.uuid, reason=e.format_message())
2810             except (exception.InstanceNotFound,
2811                     exception.UnexpectedDeletingTaskStateError) as e:
2812                 LOG.debug('Instance was deleted while rebuilding',
2813                           instance=instance)
2814                 self._set_migration_status(migration, 'failed')
2815                 self._notify_instance_rebuild_error(context, instance, e)
2816             except Exception as e:
2817                 self._set_migration_status(migration, 'failed')
2818                 self._notify_instance_rebuild_error(context, instance, e)
2819                 raise
2820             else:
2821                 instance.apply_migration_context()
2822                 # NOTE (ndipanov): This save will now update the host and node
2823                 # attributes making sure that next RT pass is consistent since
2824                 # it will be based on the instance and not the migration DB
2825                 # entry.
2826                 instance.host = self.host
2827                 instance.node = scheduled_node
2828                 instance.save()
2829                 instance.drop_migration_context()
2830 
2831                 # NOTE (ndipanov): Mark the migration as done only after we
2832                 # mark the instance as belonging to this host.
2833                 self._set_migration_status(migration, 'done')
2834 
2835     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2836         """Helper to avoid deep nesting in the top-level method."""
2837 
2838         with claim_context:
2839             self._do_rebuild_instance(*args, **kwargs)
2840 
2841     @staticmethod
2842     def _get_image_name(image_meta):
2843         if image_meta.obj_attr_is_set("name"):
2844             return image_meta.name
2845         else:
2846             return ''
2847 
2848     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2849                              image_ref, injected_files, new_pass,
2850                              orig_sys_metadata, bdms, recreate,
2851                              on_shared_storage, preserve_ephemeral):
2852         orig_vm_state = instance.vm_state
2853 
2854         if recreate:
2855             if not self.driver.capabilities["supports_recreate"]:
2856                 raise exception.InstanceRecreateNotSupported
2857 
2858             self._check_instance_exists(context, instance)
2859 
2860             if on_shared_storage is None:
2861                 LOG.debug('on_shared_storage is not provided, using driver'
2862                             'information to decide if the instance needs to'
2863                             'be recreated')
2864                 on_shared_storage = self.driver.instance_on_disk(instance)
2865 
2866             elif (on_shared_storage !=
2867                     self.driver.instance_on_disk(instance)):
2868                 # To cover case when admin expects that instance files are
2869                 # on shared storage, but not accessible and vice versa
2870                 raise exception.InvalidSharedStorage(
2871                         _("Invalid state of instance files on shared"
2872                             " storage"))
2873 
2874             if on_shared_storage:
2875                 LOG.info('disk on shared storage, recreating using'
2876                          ' existing disk')
2877             else:
2878                 image_ref = orig_image_ref = instance.image_ref
2879                 LOG.info("disk not on shared storage, rebuilding from:"
2880                          " '%s'", str(image_ref))
2881 
2882         if image_ref:
2883             image_meta = objects.ImageMeta.from_image_ref(
2884                 context, self.image_api, image_ref)
2885         else:
2886             image_meta = instance.image_meta
2887 
2888         # This instance.exists message should contain the original
2889         # image_ref, not the new one.  Since the DB has been updated
2890         # to point to the new one... we have to override it.
2891         # TODO(jaypipes): Move generate_image_url() into the nova.image.api
2892         orig_image_ref_url = glance.generate_image_url(orig_image_ref)
2893         extra_usage_info = {'image_ref_url': orig_image_ref_url}
2894         compute_utils.notify_usage_exists(
2895                 self.notifier, context, instance,
2896                 current_period=True, system_metadata=orig_sys_metadata,
2897                 extra_usage_info=extra_usage_info)
2898 
2899         # This message should contain the new image_ref
2900         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
2901         self._notify_about_instance_usage(context, instance,
2902                 "rebuild.start", extra_usage_info=extra_usage_info)
2903         # NOTE: image_name is not included in the versioned notification
2904         # because we already provide the image_uuid in the notification
2905         # payload and the image details can be looked up via the uuid.
2906         compute_utils.notify_about_instance_action(
2907             context, instance, self.host,
2908             action=fields.NotificationAction.REBUILD,
2909             phase=fields.NotificationPhase.START)
2910 
2911         instance.power_state = self._get_power_state(context, instance)
2912         instance.task_state = task_states.REBUILDING
2913         instance.save(expected_task_state=[task_states.REBUILDING])
2914 
2915         if recreate:
2916             self.network_api.setup_networks_on_host(
2917                     context, instance, self.host)
2918             # For nova-network this is needed to move floating IPs
2919             # For neutron this updates the host in the port binding
2920             # TODO(cfriesen): this network_api call and the one above
2921             # are so similar, we should really try to unify them.
2922             self.network_api.setup_instance_network_on_host(
2923                     context, instance, self.host)
2924 
2925         network_info = instance.get_network_info()
2926         if bdms is None:
2927             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2928                     context, instance.uuid)
2929 
2930         block_device_info = \
2931             self._get_instance_block_device_info(
2932                     context, instance, bdms=bdms)
2933 
2934         def detach_block_devices(context, bdms):
2935             for bdm in bdms:
2936                 if bdm.is_volume:
2937                     self._detach_volume(context, bdm, instance,
2938                                         destroy_bdm=False)
2939                     # NOTE (ildikov): Having the attachment_id set in the BDM
2940                     # means that it's the new Cinder attach/detach flow
2941                     # (available from v3.44). In that case we explicitely
2942                     # attach and detach the volumes through attachment level
2943                     # operations. In this scenario we create a new attachment
2944                     # here as by deleting the one above the volume became
2945                     # 'available' therefore we need to reserve it again until
2946                     # it gets attached later in this flow.
2947                     if bdm.attachment_id:
2948                         attachment_id = self.volume_api.attachment_create(
2949                             context, bdm['volume_id'], instance.uuid)['id']
2950                         bdm.attachment_id = attachment_id
2951                         bdm.save()
2952         files = self._decode_files(injected_files)
2953 
2954         kwargs = dict(
2955             context=context,
2956             instance=instance,
2957             image_meta=image_meta,
2958             injected_files=files,
2959             admin_password=new_pass,
2960             bdms=bdms,
2961             detach_block_devices=detach_block_devices,
2962             attach_block_devices=self._prep_block_device,
2963             block_device_info=block_device_info,
2964             network_info=network_info,
2965             preserve_ephemeral=preserve_ephemeral,
2966             recreate=recreate)
2967         try:
2968             with instance.mutated_migration_context():
2969                 self.driver.rebuild(**kwargs)
2970         except NotImplementedError:
2971             # NOTE(rpodolyaka): driver doesn't provide specialized version
2972             # of rebuild, fall back to the default implementation
2973             self._rebuild_default_impl(**kwargs)
2974         self._update_instance_after_spawn(context, instance)
2975         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
2976 
2977         if orig_vm_state == vm_states.STOPPED:
2978             LOG.info("bringing vm to original state: '%s'",
2979                      orig_vm_state, instance=instance)
2980             instance.vm_state = vm_states.ACTIVE
2981             instance.task_state = task_states.POWERING_OFF
2982             instance.progress = 0
2983             instance.save()
2984             self.stop_instance(context, instance, False)
2985         self._update_scheduler_instance_info(context, instance)
2986         self._notify_about_instance_usage(
2987                 context, instance, "rebuild.end",
2988                 network_info=network_info,
2989                 extra_usage_info=extra_usage_info)
2990         compute_utils.notify_about_instance_action(
2991             context, instance, self.host,
2992             action=fields.NotificationAction.REBUILD,
2993             phase=fields.NotificationPhase.END)
2994 
2995     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
2996                                      block_device_info):
2997         """Handle cases where the virt-layer had to detach non-working volumes
2998         in order to complete an operation.
2999         """
3000         for bdm in block_device_info['block_device_mapping']:
3001             if bdm.get('mount_device') in bad_devices:
3002                 try:
3003                     volume_id = bdm['connection_info']['data']['volume_id']
3004                 except KeyError:
3005                     continue
3006 
3007                 # NOTE(sirp): ideally we'd just call
3008                 # `compute_api.detach_volume` here but since that hits the
3009                 # DB directly, that's off limits from within the
3010                 # compute-manager.
3011                 #
3012                 # API-detach
3013                 LOG.info("Detaching from volume api: %s", volume_id)
3014                 self.volume_api.begin_detaching(context, volume_id)
3015 
3016                 # Manager-detach
3017                 self.detach_volume(context, volume_id, instance)
3018 
3019     @wrap_exception()
3020     @reverts_task_state
3021     @wrap_instance_event(prefix='compute')
3022     @wrap_instance_fault
3023     def reboot_instance(self, context, instance, block_device_info,
3024                         reboot_type):
3025         """Reboot an instance on this host."""
3026         # acknowledge the request made it to the manager
3027         if reboot_type == "SOFT":
3028             instance.task_state = task_states.REBOOT_PENDING
3029             expected_states = (task_states.REBOOTING,
3030                                task_states.REBOOT_PENDING,
3031                                task_states.REBOOT_STARTED)
3032         else:
3033             instance.task_state = task_states.REBOOT_PENDING_HARD
3034             expected_states = (task_states.REBOOTING_HARD,
3035                                task_states.REBOOT_PENDING_HARD,
3036                                task_states.REBOOT_STARTED_HARD)
3037         context = context.elevated()
3038         LOG.info("Rebooting instance", instance=instance)
3039 
3040         block_device_info = self._get_instance_block_device_info(context,
3041                                                                  instance)
3042 
3043         network_info = self.network_api.get_instance_nw_info(context, instance)
3044 
3045         self._notify_about_instance_usage(context, instance, "reboot.start")
3046         compute_utils.notify_about_instance_action(
3047             context, instance, self.host,
3048             action=fields.NotificationAction.REBOOT,
3049             phase=fields.NotificationPhase.START
3050         )
3051 
3052         instance.power_state = self._get_power_state(context, instance)
3053         instance.save(expected_task_state=expected_states)
3054 
3055         if instance.power_state != power_state.RUNNING:
3056             state = instance.power_state
3057             running = power_state.RUNNING
3058             LOG.warning('trying to reboot a non-running instance:'
3059                         ' (state: %(state)s expected: %(running)s)',
3060                         {'state': state, 'running': running},
3061                         instance=instance)
3062 
3063         def bad_volumes_callback(bad_devices):
3064             self._handle_bad_volumes_detached(
3065                     context, instance, bad_devices, block_device_info)
3066 
3067         try:
3068             # Don't change it out of rescue mode
3069             if instance.vm_state == vm_states.RESCUED:
3070                 new_vm_state = vm_states.RESCUED
3071             else:
3072                 new_vm_state = vm_states.ACTIVE
3073             new_power_state = None
3074             if reboot_type == "SOFT":
3075                 instance.task_state = task_states.REBOOT_STARTED
3076                 expected_state = task_states.REBOOT_PENDING
3077             else:
3078                 instance.task_state = task_states.REBOOT_STARTED_HARD
3079                 expected_state = task_states.REBOOT_PENDING_HARD
3080             instance.save(expected_task_state=expected_state)
3081             self.driver.reboot(context, instance,
3082                                network_info,
3083                                reboot_type,
3084                                block_device_info=block_device_info,
3085                                bad_volumes_callback=bad_volumes_callback)
3086 
3087         except Exception as error:
3088             with excutils.save_and_reraise_exception() as ctxt:
3089                 exc_info = sys.exc_info()
3090                 # if the reboot failed but the VM is running don't
3091                 # put it into an error state
3092                 new_power_state = self._get_power_state(context, instance)
3093                 if new_power_state == power_state.RUNNING:
3094                     LOG.warning('Reboot failed but instance is running',
3095                                 instance=instance)
3096                     compute_utils.add_instance_fault_from_exc(context,
3097                             instance, error, exc_info)
3098                     self._notify_about_instance_usage(context, instance,
3099                             'reboot.error', fault=error)
3100                     compute_utils.notify_about_instance_action(
3101                         context, instance, self.host,
3102                         action=fields.NotificationAction.REBOOT,
3103                         phase=fields.NotificationPhase.ERROR,
3104                         exception=error
3105                     )
3106                     ctxt.reraise = False
3107                 else:
3108                     LOG.error('Cannot reboot instance: %s', error,
3109                               instance=instance)
3110                     self._set_instance_obj_error_state(context, instance)
3111 
3112         if not new_power_state:
3113             new_power_state = self._get_power_state(context, instance)
3114         try:
3115             instance.power_state = new_power_state
3116             instance.vm_state = new_vm_state
3117             instance.task_state = None
3118             instance.save()
3119         except exception.InstanceNotFound:
3120             LOG.warning("Instance disappeared during reboot",
3121                         instance=instance)
3122 
3123         self._notify_about_instance_usage(context, instance, "reboot.end")
3124         compute_utils.notify_about_instance_action(
3125             context, instance, self.host,
3126             action=fields.NotificationAction.REBOOT,
3127             phase=fields.NotificationPhase.END
3128         )
3129 
3130     @delete_image_on_error
3131     def _do_snapshot_instance(self, context, image_id, instance):
3132         self._snapshot_instance(context, image_id, instance,
3133                                 task_states.IMAGE_BACKUP)
3134 
3135     @wrap_exception()
3136     @reverts_task_state
3137     @wrap_instance_fault
3138     def backup_instance(self, context, image_id, instance, backup_type,
3139                         rotation):
3140         """Backup an instance on this host.
3141 
3142         :param backup_type: daily | weekly
3143         :param rotation: int representing how many backups to keep around
3144         """
3145         self._do_snapshot_instance(context, image_id, instance)
3146         self._rotate_backups(context, instance, backup_type, rotation)
3147 
3148     @wrap_exception()
3149     @reverts_task_state
3150     @wrap_instance_fault
3151     @delete_image_on_error
3152     def snapshot_instance(self, context, image_id, instance):
3153         """Snapshot an instance on this host.
3154 
3155         :param context: security context
3156         :param image_id: glance.db.sqlalchemy.models.Image.Id
3157         :param instance: a nova.objects.instance.Instance object
3158         """
3159         # NOTE(dave-mcnally) the task state will already be set by the api
3160         # but if the compute manager has crashed/been restarted prior to the
3161         # request getting here the task state may have been cleared so we set
3162         # it again and things continue normally
3163         try:
3164             instance.task_state = task_states.IMAGE_SNAPSHOT
3165             instance.save(
3166                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3167         except exception.InstanceNotFound:
3168             # possibility instance no longer exists, no point in continuing
3169             LOG.debug("Instance not found, could not set state %s "
3170                       "for instance.",
3171                       task_states.IMAGE_SNAPSHOT, instance=instance)
3172             return
3173 
3174         except exception.UnexpectedDeletingTaskStateError:
3175             LOG.debug("Instance being deleted, snapshot cannot continue",
3176                       instance=instance)
3177             return
3178 
3179         self._snapshot_instance(context, image_id, instance,
3180                                 task_states.IMAGE_SNAPSHOT)
3181 
3182     def _snapshot_instance(self, context, image_id, instance,
3183                            expected_task_state):
3184         context = context.elevated()
3185 
3186         instance.power_state = self._get_power_state(context, instance)
3187         try:
3188             instance.save()
3189 
3190             LOG.info('instance snapshotting', instance=instance)
3191 
3192             if instance.power_state != power_state.RUNNING:
3193                 state = instance.power_state
3194                 running = power_state.RUNNING
3195                 LOG.warning('trying to snapshot a non-running instance: '
3196                             '(state: %(state)s expected: %(running)s)',
3197                             {'state': state, 'running': running},
3198                             instance=instance)
3199 
3200             self._notify_about_instance_usage(
3201                 context, instance, "snapshot.start")
3202             compute_utils.notify_about_instance_action(context, instance,
3203                 self.host, action=fields.NotificationAction.SNAPSHOT,
3204                 phase=fields.NotificationPhase.START)
3205 
3206             def update_task_state(task_state,
3207                                   expected_state=expected_task_state):
3208                 instance.task_state = task_state
3209                 instance.save(expected_task_state=expected_state)
3210 
3211             self.driver.snapshot(context, instance, image_id,
3212                                  update_task_state)
3213 
3214             instance.task_state = None
3215             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3216 
3217             self._notify_about_instance_usage(context, instance,
3218                                               "snapshot.end")
3219             compute_utils.notify_about_instance_action(context, instance,
3220                 self.host, action=fields.NotificationAction.SNAPSHOT,
3221                 phase=fields.NotificationPhase.END)
3222         except (exception.InstanceNotFound,
3223                 exception.UnexpectedDeletingTaskStateError):
3224             # the instance got deleted during the snapshot
3225             # Quickly bail out of here
3226             msg = 'Instance disappeared during snapshot'
3227             LOG.debug(msg, instance=instance)
3228             try:
3229                 image_service = glance.get_default_image_service()
3230                 image = image_service.show(context, image_id)
3231                 if image['status'] != 'active':
3232                     image_service.delete(context, image_id)
3233             except Exception:
3234                 LOG.warning("Error while trying to clean up image %s",
3235                             image_id, instance=instance)
3236         except exception.ImageNotFound:
3237             instance.task_state = None
3238             instance.save()
3239             LOG.warning("Image not found during snapshot", instance=instance)
3240 
3241     def _post_interrupted_snapshot_cleanup(self, context, instance):
3242         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3243 
3244     @messaging.expected_exceptions(NotImplementedError)
3245     @wrap_exception()
3246     def volume_snapshot_create(self, context, instance, volume_id,
3247                                create_info):
3248         self.driver.volume_snapshot_create(context, instance, volume_id,
3249                                            create_info)
3250 
3251     @messaging.expected_exceptions(NotImplementedError)
3252     @wrap_exception()
3253     def volume_snapshot_delete(self, context, instance, volume_id,
3254                                snapshot_id, delete_info):
3255         self.driver.volume_snapshot_delete(context, instance, volume_id,
3256                                            snapshot_id, delete_info)
3257 
3258     @wrap_instance_fault
3259     def _rotate_backups(self, context, instance, backup_type, rotation):
3260         """Delete excess backups associated to an instance.
3261 
3262         Instances are allowed a fixed number of backups (the rotation number);
3263         this method deletes the oldest backups that exceed the rotation
3264         threshold.
3265 
3266         :param context: security context
3267         :param instance: Instance dict
3268         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3269         :param rotation: int representing how many backups to keep around;
3270             None if rotation shouldn't be used (as in the case of snapshots)
3271         """
3272         filters = {'property-image_type': 'backup',
3273                    'property-backup_type': backup_type,
3274                    'property-instance_uuid': instance.uuid}
3275 
3276         images = self.image_api.get_all(context, filters=filters,
3277                                         sort_key='created_at', sort_dir='desc')
3278         num_images = len(images)
3279         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3280                   {'num_images': num_images, 'rotation': rotation},
3281                   instance=instance)
3282 
3283         if num_images > rotation:
3284             # NOTE(sirp): this deletes all backups that exceed the rotation
3285             # limit
3286             excess = len(images) - rotation
3287             LOG.debug("Rotating out %d backups", excess,
3288                       instance=instance)
3289             for i in range(excess):
3290                 image = images.pop()
3291                 image_id = image['id']
3292                 LOG.debug("Deleting image %s", image_id,
3293                           instance=instance)
3294                 try:
3295                     self.image_api.delete(context, image_id)
3296                 except exception.ImageNotFound:
3297                     LOG.info("Failed to find image %(image_id)s to "
3298                              "delete", {'image_id': image_id},
3299                              instance=instance)
3300 
3301     @wrap_exception()
3302     @reverts_task_state
3303     @wrap_instance_event(prefix='compute')
3304     @wrap_instance_fault
3305     def set_admin_password(self, context, instance, new_pass):
3306         """Set the root/admin password for an instance on this host.
3307 
3308         This is generally only called by API password resets after an
3309         image has been built.
3310 
3311         @param context: Nova auth context.
3312         @param instance: Nova instance object.
3313         @param new_pass: The admin password for the instance.
3314         """
3315 
3316         context = context.elevated()
3317         if new_pass is None:
3318             # Generate a random password
3319             new_pass = utils.generate_password()
3320 
3321         current_power_state = self._get_power_state(context, instance)
3322         expected_state = power_state.RUNNING
3323 
3324         if current_power_state != expected_state:
3325             instance.task_state = None
3326             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3327             _msg = _('instance %s is not running') % instance.uuid
3328             raise exception.InstancePasswordSetFailed(
3329                 instance=instance.uuid, reason=_msg)
3330 
3331         try:
3332             self.driver.set_admin_password(instance, new_pass)
3333             LOG.info("Root password set", instance=instance)
3334             instance.task_state = None
3335             instance.save(
3336                 expected_task_state=task_states.UPDATING_PASSWORD)
3337         except exception.InstanceAgentNotEnabled:
3338             with excutils.save_and_reraise_exception():
3339                 LOG.debug('Guest agent is not enabled for the instance.',
3340                           instance=instance)
3341                 instance.task_state = None
3342                 instance.save(
3343                     expected_task_state=task_states.UPDATING_PASSWORD)
3344         except exception.SetAdminPasswdNotSupported:
3345             with excutils.save_and_reraise_exception():
3346                 LOG.info('set_admin_password is not supported '
3347                          'by this driver or guest instance.',
3348                          instance=instance)
3349                 instance.task_state = None
3350                 instance.save(
3351                     expected_task_state=task_states.UPDATING_PASSWORD)
3352         except NotImplementedError:
3353             LOG.warning('set_admin_password is not implemented '
3354                         'by this driver or guest instance.',
3355                         instance=instance)
3356             instance.task_state = None
3357             instance.save(
3358                 expected_task_state=task_states.UPDATING_PASSWORD)
3359             raise NotImplementedError(_('set_admin_password is not '
3360                                         'implemented by this driver or guest '
3361                                         'instance.'))
3362         except exception.UnexpectedTaskStateError:
3363             # interrupted by another (most likely delete) task
3364             # do not retry
3365             raise
3366         except Exception:
3367             # Catch all here because this could be anything.
3368             LOG.exception('set_admin_password failed', instance=instance)
3369             self._set_instance_obj_error_state(context, instance)
3370             # We create a new exception here so that we won't
3371             # potentially reveal password information to the
3372             # API caller.  The real exception is logged above
3373             _msg = _('error setting admin password')
3374             raise exception.InstancePasswordSetFailed(
3375                 instance=instance.uuid, reason=_msg)
3376 
3377     @wrap_exception()
3378     @reverts_task_state
3379     @wrap_instance_fault
3380     def inject_file(self, context, path, file_contents, instance):
3381         """Write a file to the specified path in an instance on this host."""
3382         # NOTE(russellb) Remove this method, as well as the underlying virt
3383         # driver methods, when the compute rpc interface is bumped to 4.x
3384         # as it is no longer used.
3385         context = context.elevated()
3386         current_power_state = self._get_power_state(context, instance)
3387         expected_state = power_state.RUNNING
3388         if current_power_state != expected_state:
3389             LOG.warning('trying to inject a file into a non-running '
3390                         '(state: %(current_state)s expected: '
3391                         '%(expected_state)s)',
3392                         {'current_state': current_power_state,
3393                          'expected_state': expected_state},
3394                         instance=instance)
3395         LOG.info('injecting file to %s', path, instance=instance)
3396         self.driver.inject_file(instance, path, file_contents)
3397 
3398     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3399         """Determine what image should be used to boot the rescue VM."""
3400         # 1. If rescue_image_ref is passed in, use that for rescue.
3401         # 2. Else, use the base image associated with instance's current image.
3402         #       The idea here is to provide the customer with a rescue
3403         #       environment which they are familiar with.
3404         #       So, if they built their instance off of a Debian image,
3405         #       their rescue VM will also be Debian.
3406         # 3. As a last resort, use instance's current image.
3407         if not rescue_image_ref:
3408             system_meta = utils.instance_sys_meta(instance)
3409             rescue_image_ref = system_meta.get('image_base_image_ref')
3410 
3411         if not rescue_image_ref:
3412             LOG.warning('Unable to find a different image to use for '
3413                         'rescue VM, using instance\'s current image',
3414                         instance=instance)
3415             rescue_image_ref = instance.image_ref
3416 
3417         return objects.ImageMeta.from_image_ref(
3418             context, self.image_api, rescue_image_ref)
3419 
3420     @wrap_exception()
3421     @reverts_task_state
3422     @wrap_instance_event(prefix='compute')
3423     @wrap_instance_fault
3424     def rescue_instance(self, context, instance, rescue_password,
3425                         rescue_image_ref, clean_shutdown):
3426         context = context.elevated()
3427         LOG.info('Rescuing', instance=instance)
3428 
3429         admin_password = (rescue_password if rescue_password else
3430                       utils.generate_password())
3431 
3432         network_info = self.network_api.get_instance_nw_info(context, instance)
3433 
3434         rescue_image_meta = self._get_rescue_image(context, instance,
3435                                                    rescue_image_ref)
3436 
3437         extra_usage_info = {'rescue_image_name':
3438                             self._get_image_name(rescue_image_meta)}
3439         self._notify_about_instance_usage(context, instance,
3440                 "rescue.start", extra_usage_info=extra_usage_info,
3441                 network_info=network_info)
3442 
3443         try:
3444             self._power_off_instance(context, instance, clean_shutdown)
3445 
3446             self.driver.rescue(context, instance,
3447                                network_info,
3448                                rescue_image_meta, admin_password)
3449         except Exception as e:
3450             LOG.exception("Error trying to Rescue Instance",
3451                           instance=instance)
3452             self._set_instance_obj_error_state(context, instance)
3453             raise exception.InstanceNotRescuable(
3454                 instance_id=instance.uuid,
3455                 reason=_("Driver Error: %s") % e)
3456 
3457         compute_utils.notify_usage_exists(self.notifier, context, instance,
3458                                           current_period=True)
3459 
3460         instance.vm_state = vm_states.RESCUED
3461         instance.task_state = None
3462         instance.power_state = self._get_power_state(context, instance)
3463         instance.launched_at = timeutils.utcnow()
3464         instance.save(expected_task_state=task_states.RESCUING)
3465 
3466         self._notify_about_instance_usage(context, instance,
3467                 "rescue.end", extra_usage_info=extra_usage_info,
3468                 network_info=network_info)
3469 
3470     @wrap_exception()
3471     @reverts_task_state
3472     @wrap_instance_event(prefix='compute')
3473     @wrap_instance_fault
3474     def unrescue_instance(self, context, instance):
3475         context = context.elevated()
3476         LOG.info('Unrescuing', instance=instance)
3477 
3478         network_info = self.network_api.get_instance_nw_info(context, instance)
3479         self._notify_about_instance_usage(context, instance,
3480                 "unrescue.start", network_info=network_info)
3481         with self._error_out_instance_on_exception(context, instance):
3482             self.driver.unrescue(instance,
3483                                  network_info)
3484 
3485         instance.vm_state = vm_states.ACTIVE
3486         instance.task_state = None
3487         instance.power_state = self._get_power_state(context, instance)
3488         instance.save(expected_task_state=task_states.UNRESCUING)
3489 
3490         self._notify_about_instance_usage(context,
3491                                           instance,
3492                                           "unrescue.end",
3493                                           network_info=network_info)
3494 
3495     @wrap_exception()
3496     @wrap_instance_fault
3497     def change_instance_metadata(self, context, diff, instance):
3498         """Update the metadata published to the instance."""
3499         LOG.debug("Changing instance metadata according to %r",
3500                   diff, instance=instance)
3501         self.driver.change_instance_metadata(context, instance, diff)
3502 
3503     @wrap_exception()
3504     @wrap_instance_event(prefix='compute')
3505     @wrap_instance_fault
3506     def confirm_resize(self, context, instance, reservations, migration):
3507         @utils.synchronized(instance.uuid)
3508         def do_confirm_resize(context, instance, migration_id):
3509             # NOTE(wangpan): Get the migration status from db, if it has been
3510             #                confirmed, we do nothing and return here
3511             LOG.debug("Going to confirm migration %s", migration_id,
3512                       instance=instance)
3513             try:
3514                 # TODO(russellb) Why are we sending the migration object just
3515                 # to turn around and look it up from the db again?
3516                 migration = objects.Migration.get_by_id(
3517                                     context.elevated(), migration_id)
3518             except exception.MigrationNotFound:
3519                 LOG.error("Migration %s is not found during confirmation",
3520                           migration_id, instance=instance)
3521                 return
3522 
3523             if migration.status == 'confirmed':
3524                 LOG.info("Migration %s is already confirmed",
3525                          migration_id, instance=instance)
3526                 return
3527             elif migration.status not in ('finished', 'confirming'):
3528                 LOG.warning("Unexpected confirmation status '%(status)s' "
3529                             "of migration %(id)s, exit confirmation process",
3530                             {"status": migration.status, "id": migration_id},
3531                             instance=instance)
3532                 return
3533 
3534             # NOTE(wangpan): Get the instance from db, if it has been
3535             #                deleted, we do nothing and return here
3536             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3537             try:
3538                 instance = objects.Instance.get_by_uuid(
3539                         context, instance.uuid,
3540                         expected_attrs=expected_attrs)
3541             except exception.InstanceNotFound:
3542                 LOG.info("Instance is not found during confirmation",
3543                          instance=instance)
3544                 return
3545 
3546             self._confirm_resize(context, instance, migration=migration)
3547 
3548         do_confirm_resize(context, instance, migration.id)
3549 
3550     def _confirm_resize(self, context, instance, migration=None):
3551         """Destroys the source instance."""
3552         self._notify_about_instance_usage(context, instance,
3553                                           "resize.confirm.start")
3554 
3555         with self._error_out_instance_on_exception(context, instance):
3556             # NOTE(danms): delete stashed migration information
3557             old_instance_type = instance.old_flavor
3558             instance.old_flavor = None
3559             instance.new_flavor = None
3560             instance.system_metadata.pop('old_vm_state', None)
3561             instance.save()
3562 
3563             # NOTE(tr3buchet): tear down networks on source host
3564             self.network_api.setup_networks_on_host(context, instance,
3565                                migration.source_compute, teardown=True)
3566 
3567             network_info = self.network_api.get_instance_nw_info(context,
3568                                                                  instance)
3569             self.driver.confirm_migration(context, migration, instance,
3570                                           network_info)
3571 
3572             migration.status = 'confirmed'
3573             with migration.obj_as_admin():
3574                 migration.save()
3575 
3576             rt = self._get_resource_tracker()
3577             rt.drop_move_claim(context, instance, migration.source_node,
3578                                old_instance_type, prefix='old_')
3579             instance.drop_migration_context()
3580 
3581             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3582             # might have manually powered up the instance to confirm the
3583             # resize/migrate, so we need to check the current power state
3584             # on the instance and set the vm_state appropriately. We default
3585             # to ACTIVE because if the power state is not SHUTDOWN, we
3586             # assume _sync_instance_power_state will clean it up.
3587             p_state = instance.power_state
3588             vm_state = None
3589             if p_state == power_state.SHUTDOWN:
3590                 vm_state = vm_states.STOPPED
3591                 LOG.debug("Resized/migrated instance is powered off. "
3592                           "Setting vm_state to '%s'.", vm_state,
3593                           instance=instance)
3594             else:
3595                 vm_state = vm_states.ACTIVE
3596 
3597             instance.vm_state = vm_state
3598             instance.task_state = None
3599             instance.save(expected_task_state=[None, task_states.DELETING])
3600 
3601             self._notify_about_instance_usage(
3602                 context, instance, "resize.confirm.end",
3603                 network_info=network_info)
3604 
3605     @wrap_exception()
3606     @reverts_task_state
3607     @wrap_instance_event(prefix='compute')
3608     @errors_out_migration
3609     @wrap_instance_fault
3610     def revert_resize(self, context, instance, migration, reservations):
3611         """Destroys the new instance on the destination machine.
3612 
3613         Reverts the model changes, and powers on the old instance on the
3614         source machine.
3615 
3616         """
3617         # NOTE(comstud): A revert_resize is essentially a resize back to
3618         # the old size, so we need to send a usage event here.
3619         compute_utils.notify_usage_exists(self.notifier, context, instance,
3620                                           current_period=True)
3621 
3622         with self._error_out_instance_on_exception(context, instance):
3623             # NOTE(tr3buchet): tear down networks on destination host
3624             self.network_api.setup_networks_on_host(context, instance,
3625                                                     teardown=True)
3626 
3627             migration_p = obj_base.obj_to_primitive(migration)
3628             self.network_api.migrate_instance_start(context,
3629                                                     instance,
3630                                                     migration_p)
3631 
3632             network_info = self.network_api.get_instance_nw_info(context,
3633                                                                  instance)
3634             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3635                     context, instance.uuid)
3636             block_device_info = self._get_instance_block_device_info(
3637                                 context, instance, bdms=bdms)
3638 
3639             destroy_disks = not self._is_instance_storage_shared(
3640                 context, instance, host=migration.source_compute)
3641             self.driver.destroy(context, instance, network_info,
3642                                 block_device_info, destroy_disks)
3643 
3644             self._terminate_volume_connections(context, instance, bdms)
3645 
3646             migration.status = 'reverted'
3647             with migration.obj_as_admin():
3648                 migration.save()
3649 
3650             # NOTE(ndipanov): We need to do this here because dropping the
3651             # claim means we lose the migration_context data. We really should
3652             # fix this by moving the drop_move_claim call to the
3653             # finish_revert_resize method as this is racy (revert is dropped,
3654             # but instance resources will be tracked with the new flavor until
3655             # it gets rolled back in finish_revert_resize, which is
3656             # potentially wrong for a period of time).
3657             instance.revert_migration_context()
3658             instance.save()
3659 
3660             rt = self._get_resource_tracker()
3661             rt.drop_move_claim(context, instance, instance.node)
3662 
3663             self.compute_rpcapi.finish_revert_resize(context, instance,
3664                     migration, migration.source_compute)
3665 
3666     @wrap_exception()
3667     @reverts_task_state
3668     @wrap_instance_event(prefix='compute')
3669     @errors_out_migration
3670     @wrap_instance_fault
3671     def finish_revert_resize(self, context, instance, reservations, migration):
3672         """Finishes the second half of reverting a resize.
3673 
3674         Bring the original source instance state back (active/shutoff) and
3675         revert the resized attributes in the database.
3676 
3677         """
3678         with self._error_out_instance_on_exception(context, instance):
3679             self._notify_about_instance_usage(
3680                     context, instance, "resize.revert.start")
3681 
3682             # NOTE(mriedem): delete stashed old_vm_state information; we
3683             # default to ACTIVE for backwards compatibility if old_vm_state
3684             # is not set
3685             old_vm_state = instance.system_metadata.pop('old_vm_state',
3686                                                         vm_states.ACTIVE)
3687 
3688             self._set_instance_info(instance, instance.old_flavor)
3689             instance.old_flavor = None
3690             instance.new_flavor = None
3691             instance.host = migration.source_compute
3692             instance.node = migration.source_node
3693             instance.save()
3694 
3695             self.network_api.setup_networks_on_host(context, instance,
3696                                                     migration.source_compute)
3697             migration_p = obj_base.obj_to_primitive(migration)
3698             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
3699             # source host temporarily. "network_api.migrate_instance_finish"
3700             # will setup the network for the instance on the destination host.
3701             # For revert resize, the instance will back to the source host, the
3702             # setup of the network for instance should be on the source host.
3703             # So set the migration_p['dest_compute'] to source host at here.
3704             migration_p['dest_compute'] = migration.source_compute
3705             self.network_api.migrate_instance_finish(context,
3706                                                      instance,
3707                                                      migration_p)
3708             network_info = self.network_api.get_instance_nw_info(context,
3709                                                                  instance)
3710 
3711             block_device_info = self._get_instance_block_device_info(
3712                     context, instance, refresh_conn_info=True)
3713 
3714             power_on = old_vm_state != vm_states.STOPPED
3715             self.driver.finish_revert_migration(context, instance,
3716                                        network_info,
3717                                        block_device_info, power_on)
3718 
3719             instance.drop_migration_context()
3720             instance.launched_at = timeutils.utcnow()
3721             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
3722 
3723             # if the original vm state was STOPPED, set it back to STOPPED
3724             LOG.info("Updating instance to original state: '%s'",
3725                      old_vm_state, instance=instance)
3726             if power_on:
3727                 instance.vm_state = vm_states.ACTIVE
3728                 instance.task_state = None
3729                 instance.save()
3730             else:
3731                 instance.task_state = task_states.POWERING_OFF
3732                 instance.save()
3733                 self.stop_instance(context, instance=instance,
3734                                    clean_shutdown=True)
3735 
3736             self._notify_about_instance_usage(
3737                     context, instance, "resize.revert.end")
3738 
3739     def _prep_resize(self, context, image, instance, instance_type,
3740                      filter_properties, node, clean_shutdown=True):
3741 
3742         if not filter_properties:
3743             filter_properties = {}
3744 
3745         if not instance.host:
3746             self._set_instance_obj_error_state(context, instance)
3747             msg = _('Instance has no source host')
3748             raise exception.MigrationError(reason=msg)
3749 
3750         same_host = instance.host == self.host
3751         # if the flavor IDs match, it's migrate; otherwise resize
3752         if same_host and instance_type.id == instance['instance_type_id']:
3753             # check driver whether support migrate to same host
3754             if not self.driver.capabilities['supports_migrate_to_same_host']:
3755                 raise exception.UnableToMigrateToSelf(
3756                     instance_id=instance.uuid, host=self.host)
3757 
3758         # NOTE(danms): Stash the new instance_type to avoid having to
3759         # look it up in the database later
3760         instance.new_flavor = instance_type
3761         # NOTE(mriedem): Stash the old vm_state so we can set the
3762         # resized/reverted instance back to the same state later.
3763         vm_state = instance.vm_state
3764         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
3765         instance.system_metadata['old_vm_state'] = vm_state
3766         instance.save()
3767 
3768         limits = filter_properties.get('limits', {})
3769         rt = self._get_resource_tracker()
3770         with rt.resize_claim(context, instance, instance_type, node,
3771                              image_meta=image, limits=limits) as claim:
3772             LOG.info('Migrating', instance=instance)
3773             self.compute_rpcapi.resize_instance(
3774                     context, instance, claim.migration, image,
3775                     instance_type, clean_shutdown)
3776 
3777     @wrap_exception()
3778     @reverts_task_state
3779     @wrap_instance_event(prefix='compute')
3780     @wrap_instance_fault
3781     def prep_resize(self, context, image, instance, instance_type,
3782                     reservations, request_spec, filter_properties, node,
3783                     clean_shutdown):
3784         """Initiates the process of moving a running instance to another host.
3785 
3786         Possibly changes the RAM and disk size in the process.
3787 
3788         """
3789         if node is None:
3790             node = self.driver.get_available_nodes(refresh=True)[0]
3791             LOG.debug("No node specified, defaulting to %s", node,
3792                       instance=instance)
3793 
3794         # NOTE(melwitt): Remove this in version 5.0 of the RPC API
3795         # Code downstream may expect extra_specs to be populated since it
3796         # is receiving an object, so lookup the flavor to ensure this.
3797         if not isinstance(instance_type, objects.Flavor):
3798             instance_type = objects.Flavor.get_by_id(context,
3799                                                      instance_type['id'])
3800         with self._error_out_instance_on_exception(context, instance):
3801             compute_utils.notify_usage_exists(self.notifier, context, instance,
3802                                               current_period=True)
3803             self._notify_about_instance_usage(
3804                     context, instance, "resize.prep.start")
3805             failed = False
3806             try:
3807                 self._prep_resize(context, image, instance,
3808                                   instance_type, filter_properties,
3809                                   node, clean_shutdown)
3810             except Exception:
3811                 failed = True
3812                 # try to re-schedule the resize elsewhere:
3813                 exc_info = sys.exc_info()
3814                 self._reschedule_resize_or_reraise(context, image, instance,
3815                         exc_info, instance_type, request_spec,
3816                         filter_properties)
3817             finally:
3818                 if failed:
3819                     # Since we hit a failure, we're either rescheduling or dead
3820                     # and either way we need to cleanup any allocations created
3821                     # by the scheduler for the destination node. Note that for
3822                     # a resize to the same host, the scheduler will merge the
3823                     # flavors, so here we'd be subtracting the new flavor from
3824                     # the allocated resources on this node.
3825                     rt = self._get_resource_tracker()
3826                     rt.delete_allocation_for_failed_resize(
3827                         instance, node, instance_type)
3828 
3829                 extra_usage_info = dict(
3830                         new_instance_type=instance_type.name,
3831                         new_instance_type_id=instance_type.id)
3832 
3833                 self._notify_about_instance_usage(
3834                     context, instance, "resize.prep.end",
3835                     extra_usage_info=extra_usage_info)
3836 
3837     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
3838             instance_type, request_spec, filter_properties):
3839         """Try to re-schedule the resize or re-raise the original error to
3840         error out the instance.
3841         """
3842         if not request_spec:
3843             request_spec = {}
3844         if not filter_properties:
3845             filter_properties = {}
3846 
3847         rescheduled = False
3848         instance_uuid = instance.uuid
3849 
3850         try:
3851             reschedule_method = self.compute_task_api.resize_instance
3852             scheduler_hint = dict(filter_properties=filter_properties)
3853             method_args = (instance, None, scheduler_hint, instance_type)
3854             task_state = task_states.RESIZE_PREP
3855 
3856             rescheduled = self._reschedule(context, request_spec,
3857                     filter_properties, instance, reschedule_method,
3858                     method_args, task_state, exc_info)
3859         except Exception as error:
3860             rescheduled = False
3861             LOG.exception("Error trying to reschedule",
3862                           instance_uuid=instance_uuid)
3863             compute_utils.add_instance_fault_from_exc(context,
3864                     instance, error,
3865                     exc_info=sys.exc_info())
3866             self._notify_about_instance_usage(context, instance,
3867                     'resize.error', fault=error)
3868 
3869         if rescheduled:
3870             self._log_original_error(exc_info, instance_uuid)
3871             compute_utils.add_instance_fault_from_exc(context,
3872                     instance, exc_info[1], exc_info=exc_info)
3873             self._notify_about_instance_usage(context, instance,
3874                     'resize.error', fault=exc_info[1])
3875         else:
3876             # not re-scheduling
3877             six.reraise(*exc_info)
3878 
3879     @wrap_exception()
3880     @reverts_task_state
3881     @wrap_instance_event(prefix='compute')
3882     @wrap_instance_fault
3883     def resize_instance(self, context, instance, image,
3884                         reservations, migration, instance_type,
3885                         clean_shutdown):
3886         """Starts the migration of a running instance to another host."""
3887         with self._error_out_instance_on_exception(context, instance), \
3888              errors_out_migration_ctxt(migration):
3889             # TODO(chaochin) Remove this until v5 RPC API
3890             # Code downstream may expect extra_specs to be populated since it
3891             # is receiving an object, so lookup the flavor to ensure this.
3892             if (not instance_type or
3893                 not isinstance(instance_type, objects.Flavor)):
3894                 instance_type = objects.Flavor.get_by_id(
3895                     context, migration['new_instance_type_id'])
3896 
3897             network_info = self.network_api.get_instance_nw_info(context,
3898                                                                  instance)
3899 
3900             migration.status = 'migrating'
3901             with migration.obj_as_admin():
3902                 migration.save()
3903 
3904             instance.task_state = task_states.RESIZE_MIGRATING
3905             instance.save(expected_task_state=task_states.RESIZE_PREP)
3906 
3907             self._notify_about_instance_usage(
3908                 context, instance, "resize.start", network_info=network_info)
3909 
3910             compute_utils.notify_about_instance_action(context, instance,
3911                    self.host, action=fields.NotificationAction.RESIZE,
3912                    phase=fields.NotificationPhase.START)
3913 
3914             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3915                     context, instance.uuid)
3916             block_device_info = self._get_instance_block_device_info(
3917                                 context, instance, bdms=bdms)
3918 
3919             timeout, retry_interval = self._get_power_off_values(context,
3920                                             instance, clean_shutdown)
3921             disk_info = self.driver.migrate_disk_and_power_off(
3922                     context, instance, migration.dest_host,
3923                     instance_type, network_info,
3924                     block_device_info,
3925                     timeout, retry_interval)
3926 
3927             self._terminate_volume_connections(context, instance, bdms)
3928 
3929             migration_p = obj_base.obj_to_primitive(migration)
3930             self.network_api.migrate_instance_start(context,
3931                                                     instance,
3932                                                     migration_p)
3933 
3934             migration.status = 'post-migrating'
3935             with migration.obj_as_admin():
3936                 migration.save()
3937 
3938             instance.host = migration.dest_compute
3939             instance.node = migration.dest_node
3940             instance.task_state = task_states.RESIZE_MIGRATED
3941             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
3942 
3943             self.compute_rpcapi.finish_resize(context, instance,
3944                     migration, image, disk_info, migration.dest_compute)
3945 
3946         self._notify_about_instance_usage(context, instance, "resize.end",
3947                                           network_info=network_info)
3948 
3949         compute_utils.notify_about_instance_action(context, instance,
3950                self.host, action=fields.NotificationAction.RESIZE,
3951                phase=fields.NotificationPhase.END)
3952         self.instance_events.clear_events_for_instance(instance)
3953 
3954     def _terminate_volume_connections(self, context, instance, bdms):
3955         connector = None
3956         for bdm in bdms:
3957             if bdm.is_volume:
3958                 if bdm.attachment_id:
3959                     self.volume_api.attachment_delete(context,
3960                                                       bdm.attachment_id)
3961                     # NOTE(jdg): So here's the thing, the idea behind the new
3962                     # attach API's was to have a new code fork/path that we
3963                     # followed, we're not going to do that so we have to do
3964                     # some extra work in here to make it *behave* just like the
3965                     # old code. Cinder doesn't allow disconnect/reconnect (you
3966                     # just delete the attachment and get a new one)
3967                     # attachments in the new attach code so we have to do
3968                     # a delete and create without a connector (reserve),
3969                     # in other words, beware
3970                     attachment_id = self.volume_api.attachment_create(
3971                         context, bdm.volume_id, instance.uuid)['id']
3972                     bdm.attachment_id = attachment_id
3973                     bdm.save()
3974 
3975                 else:
3976                     if connector is None:
3977                         connector = self.driver.get_volume_connector(instance)
3978                     self.volume_api.terminate_connection(context,
3979                                                          bdm.volume_id,
3980                                                          connector)
3981 
3982     @staticmethod
3983     def _set_instance_info(instance, instance_type):
3984         instance.instance_type_id = instance_type.id
3985         instance.memory_mb = instance_type.memory_mb
3986         instance.vcpus = instance_type.vcpus
3987         instance.root_gb = instance_type.root_gb
3988         instance.ephemeral_gb = instance_type.ephemeral_gb
3989         instance.flavor = instance_type
3990 
3991     def _finish_resize(self, context, instance, migration, disk_info,
3992                        image_meta):
3993         resize_instance = False
3994         old_instance_type_id = migration['old_instance_type_id']
3995         new_instance_type_id = migration['new_instance_type_id']
3996         old_instance_type = instance.get_flavor()
3997         # NOTE(mriedem): Get the old_vm_state so we know if we should
3998         # power on the instance. If old_vm_state is not set we need to default
3999         # to ACTIVE for backwards compatibility
4000         old_vm_state = instance.system_metadata.get('old_vm_state',
4001                                                     vm_states.ACTIVE)
4002         instance.old_flavor = old_instance_type
4003 
4004         if old_instance_type_id != new_instance_type_id:
4005             instance_type = instance.get_flavor('new')
4006             self._set_instance_info(instance, instance_type)
4007             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4008                 if old_instance_type[key] != instance_type[key]:
4009                     resize_instance = True
4010                     break
4011         instance.apply_migration_context()
4012 
4013         # NOTE(tr3buchet): setup networks on destination host
4014         self.network_api.setup_networks_on_host(context, instance,
4015                                                 migration['dest_compute'])
4016 
4017         migration_p = obj_base.obj_to_primitive(migration)
4018         self.network_api.migrate_instance_finish(context,
4019                                                  instance,
4020                                                  migration_p)
4021 
4022         network_info = self.network_api.get_instance_nw_info(context, instance)
4023 
4024         instance.task_state = task_states.RESIZE_FINISH
4025         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4026 
4027         self._notify_about_instance_usage(
4028             context, instance, "finish_resize.start",
4029             network_info=network_info)
4030         compute_utils.notify_about_instance_action(context, instance,
4031                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4032                phase=fields.NotificationPhase.START)
4033 
4034         block_device_info = self._get_instance_block_device_info(
4035                             context, instance, refresh_conn_info=True)
4036 
4037         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4038         # automatically power on the instance after it's migrated
4039         power_on = old_vm_state != vm_states.STOPPED
4040 
4041         try:
4042             self.driver.finish_migration(context, migration, instance,
4043                                          disk_info,
4044                                          network_info,
4045                                          image_meta, resize_instance,
4046                                          block_device_info, power_on)
4047         except Exception:
4048             with excutils.save_and_reraise_exception():
4049                 if old_instance_type_id != new_instance_type_id:
4050                     self._set_instance_info(instance,
4051                                             old_instance_type)
4052 
4053         migration.status = 'finished'
4054         with migration.obj_as_admin():
4055             migration.save()
4056 
4057         instance.vm_state = vm_states.RESIZED
4058         instance.task_state = None
4059         instance.launched_at = timeutils.utcnow()
4060         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4061 
4062         return network_info
4063 
4064     @wrap_exception()
4065     @reverts_task_state
4066     @wrap_instance_event(prefix='compute')
4067     @wrap_instance_fault
4068     def finish_resize(self, context, disk_info, image, instance,
4069                       reservations, migration):
4070         """Completes the migration process.
4071 
4072         Sets up the newly transferred disk and turns on the instance at its
4073         new host machine.
4074 
4075         """
4076         with self._error_out_instance_on_exception(context, instance), \
4077              errors_out_migration_ctxt(migration):
4078             image_meta = objects.ImageMeta.from_dict(image)
4079             network_info = self._finish_resize(context, instance, migration,
4080                                                disk_info, image_meta)
4081 
4082         self._update_scheduler_instance_info(context, instance)
4083         self._notify_about_instance_usage(
4084             context, instance, "finish_resize.end",
4085             network_info=network_info)
4086         compute_utils.notify_about_instance_action(context, instance,
4087                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4088                phase=fields.NotificationPhase.END)
4089 
4090     @wrap_exception()
4091     @wrap_instance_fault
4092     def add_fixed_ip_to_instance(self, context, network_id, instance):
4093         """Calls network_api to add new fixed_ip to instance
4094         then injects the new network info and resets instance networking.
4095 
4096         """
4097         self._notify_about_instance_usage(
4098                 context, instance, "create_ip.start")
4099 
4100         network_info = self.network_api.add_fixed_ip_to_instance(context,
4101                                                                  instance,
4102                                                                  network_id)
4103         self._inject_network_info(context, instance, network_info)
4104         self.reset_network(context, instance)
4105 
4106         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4107         instance.updated_at = timeutils.utcnow()
4108         instance.save()
4109 
4110         self._notify_about_instance_usage(
4111             context, instance, "create_ip.end", network_info=network_info)
4112 
4113     @wrap_exception()
4114     @wrap_instance_fault
4115     def remove_fixed_ip_from_instance(self, context, address, instance):
4116         """Calls network_api to remove existing fixed_ip from instance
4117         by injecting the altered network info and resetting
4118         instance networking.
4119         """
4120         self._notify_about_instance_usage(
4121                 context, instance, "delete_ip.start")
4122 
4123         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4124                                                                       instance,
4125                                                                       address)
4126         self._inject_network_info(context, instance, network_info)
4127         self.reset_network(context, instance)
4128 
4129         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4130         instance.updated_at = timeutils.utcnow()
4131         instance.save()
4132 
4133         self._notify_about_instance_usage(
4134             context, instance, "delete_ip.end", network_info=network_info)
4135 
4136     @wrap_exception()
4137     @reverts_task_state
4138     @wrap_instance_event(prefix='compute')
4139     @wrap_instance_fault
4140     def pause_instance(self, context, instance):
4141         """Pause an instance on this host."""
4142         context = context.elevated()
4143         LOG.info('Pausing', instance=instance)
4144         self._notify_about_instance_usage(context, instance, 'pause.start')
4145         compute_utils.notify_about_instance_action(context, instance,
4146                self.host, action=fields.NotificationAction.PAUSE,
4147                phase=fields.NotificationPhase.START)
4148         self.driver.pause(instance)
4149         instance.power_state = self._get_power_state(context, instance)
4150         instance.vm_state = vm_states.PAUSED
4151         instance.task_state = None
4152         instance.save(expected_task_state=task_states.PAUSING)
4153         self._notify_about_instance_usage(context, instance, 'pause.end')
4154         compute_utils.notify_about_instance_action(context, instance,
4155                self.host, action=fields.NotificationAction.PAUSE,
4156                phase=fields.NotificationPhase.END)
4157 
4158     @wrap_exception()
4159     @reverts_task_state
4160     @wrap_instance_event(prefix='compute')
4161     @wrap_instance_fault
4162     def unpause_instance(self, context, instance):
4163         """Unpause a paused instance on this host."""
4164         context = context.elevated()
4165         LOG.info('Unpausing', instance=instance)
4166         self._notify_about_instance_usage(context, instance, 'unpause.start')
4167         compute_utils.notify_about_instance_action(context, instance,
4168             self.host, action=fields.NotificationAction.UNPAUSE,
4169             phase=fields.NotificationPhase.START)
4170         self.driver.unpause(instance)
4171         instance.power_state = self._get_power_state(context, instance)
4172         instance.vm_state = vm_states.ACTIVE
4173         instance.task_state = None
4174         instance.save(expected_task_state=task_states.UNPAUSING)
4175         self._notify_about_instance_usage(context, instance, 'unpause.end')
4176         compute_utils.notify_about_instance_action(context, instance,
4177             self.host, action=fields.NotificationAction.UNPAUSE,
4178             phase=fields.NotificationPhase.END)
4179 
4180     @wrap_exception()
4181     def host_power_action(self, context, action):
4182         """Reboots, shuts down or powers up the host."""
4183         return self.driver.host_power_action(action)
4184 
4185     @wrap_exception()
4186     def host_maintenance_mode(self, context, host, mode):
4187         """Start/Stop host maintenance window. On start, it triggers
4188         guest VMs evacuation.
4189         """
4190         return self.driver.host_maintenance_mode(host, mode)
4191 
4192     @wrap_exception()
4193     def set_host_enabled(self, context, enabled):
4194         """Sets the specified host's ability to accept new instances."""
4195         return self.driver.set_host_enabled(enabled)
4196 
4197     @wrap_exception()
4198     def get_host_uptime(self, context):
4199         """Returns the result of calling "uptime" on the target host."""
4200         return self.driver.get_host_uptime()
4201 
4202     @wrap_exception()
4203     @wrap_instance_fault
4204     def get_diagnostics(self, context, instance):
4205         """Retrieve diagnostics for an instance on this host."""
4206         current_power_state = self._get_power_state(context, instance)
4207         if current_power_state == power_state.RUNNING:
4208             LOG.info("Retrieving diagnostics", instance=instance)
4209             return self.driver.get_diagnostics(instance)
4210         else:
4211             raise exception.InstanceInvalidState(
4212                 attr='power state',
4213                 instance_uuid=instance.uuid,
4214                 state=power_state.STATE_MAP[instance.power_state],
4215                 method='get_diagnostics')
4216 
4217     # TODO(alaski): Remove object_compat for RPC version 5.0
4218     @object_compat
4219     @wrap_exception()
4220     @wrap_instance_fault
4221     def get_instance_diagnostics(self, context, instance):
4222         """Retrieve diagnostics for an instance on this host."""
4223         current_power_state = self._get_power_state(context, instance)
4224         if current_power_state == power_state.RUNNING:
4225             LOG.info("Retrieving diagnostics", instance=instance)
4226             return self.driver.get_instance_diagnostics(instance)
4227         else:
4228             raise exception.InstanceInvalidState(
4229                 attr='power state',
4230                 instance_uuid=instance.uuid,
4231                 state=power_state.STATE_MAP[instance.power_state],
4232                 method='get_diagnostics')
4233 
4234     @wrap_exception()
4235     @reverts_task_state
4236     @wrap_instance_event(prefix='compute')
4237     @wrap_instance_fault
4238     def suspend_instance(self, context, instance):
4239         """Suspend the given instance."""
4240         context = context.elevated()
4241 
4242         # Store the old state
4243         instance.system_metadata['old_vm_state'] = instance.vm_state
4244         self._notify_about_instance_usage(context, instance, 'suspend.start')
4245         compute_utils.notify_about_instance_action(context, instance,
4246                 self.host, action=fields.NotificationAction.SUSPEND,
4247                 phase=fields.NotificationPhase.START)
4248         with self._error_out_instance_on_exception(context, instance,
4249              instance_state=instance.vm_state):
4250             self.driver.suspend(context, instance)
4251         instance.power_state = self._get_power_state(context, instance)
4252         instance.vm_state = vm_states.SUSPENDED
4253         instance.task_state = None
4254         instance.save(expected_task_state=task_states.SUSPENDING)
4255         self._notify_about_instance_usage(context, instance, 'suspend.end')
4256         compute_utils.notify_about_instance_action(context, instance,
4257                 self.host, action=fields.NotificationAction.SUSPEND,
4258                 phase=fields.NotificationPhase.END)
4259 
4260     @wrap_exception()
4261     @reverts_task_state
4262     @wrap_instance_event(prefix='compute')
4263     @wrap_instance_fault
4264     def resume_instance(self, context, instance):
4265         """Resume the given suspended instance."""
4266         context = context.elevated()
4267         LOG.info('Resuming', instance=instance)
4268 
4269         self._notify_about_instance_usage(context, instance, 'resume.start')
4270         compute_utils.notify_about_instance_action(context, instance,
4271             self.host, action=fields.NotificationAction.RESUME,
4272             phase=fields.NotificationPhase.START)
4273 
4274         network_info = self.network_api.get_instance_nw_info(context, instance)
4275         block_device_info = self._get_instance_block_device_info(
4276                             context, instance)
4277 
4278         with self._error_out_instance_on_exception(context, instance,
4279              instance_state=instance.vm_state):
4280             self.driver.resume(context, instance, network_info,
4281                                block_device_info)
4282 
4283         instance.power_state = self._get_power_state(context, instance)
4284 
4285         # We default to the ACTIVE state for backwards compatibility
4286         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4287                                                          vm_states.ACTIVE)
4288 
4289         instance.task_state = None
4290         instance.save(expected_task_state=task_states.RESUMING)
4291         self._notify_about_instance_usage(context, instance, 'resume.end')
4292         compute_utils.notify_about_instance_action(context, instance,
4293             self.host, action=fields.NotificationAction.RESUME,
4294             phase=fields.NotificationPhase.END)
4295 
4296     @wrap_exception()
4297     @reverts_task_state
4298     @wrap_instance_event(prefix='compute')
4299     @wrap_instance_fault
4300     def shelve_instance(self, context, instance, image_id,
4301                         clean_shutdown):
4302         """Shelve an instance.
4303 
4304         This should be used when you want to take a snapshot of the instance.
4305         It also adds system_metadata that can be used by a periodic task to
4306         offload the shelved instance after a period of time.
4307 
4308         :param context: request context
4309         :param instance: an Instance object
4310         :param image_id: an image id to snapshot to.
4311         :param clean_shutdown: give the GuestOS a chance to stop
4312         """
4313 
4314         @utils.synchronized(instance.uuid)
4315         def do_shelve_instance():
4316             self._shelve_instance(context, instance, image_id, clean_shutdown)
4317         do_shelve_instance()
4318 
4319     def _shelve_instance(self, context, instance, image_id,
4320                          clean_shutdown):
4321         LOG.info('Shelving', instance=instance)
4322         compute_utils.notify_usage_exists(self.notifier, context, instance,
4323                                           current_period=True)
4324         self._notify_about_instance_usage(context, instance, 'shelve.start')
4325         compute_utils.notify_about_instance_action(context, instance,
4326                 self.host, action=fields.NotificationAction.SHELVE,
4327                 phase=fields.NotificationPhase.START)
4328 
4329         def update_task_state(task_state, expected_state=task_states.SHELVING):
4330             shelving_state_map = {
4331                     task_states.IMAGE_PENDING_UPLOAD:
4332                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4333                     task_states.IMAGE_UPLOADING:
4334                         task_states.SHELVING_IMAGE_UPLOADING,
4335                     task_states.SHELVING: task_states.SHELVING}
4336             task_state = shelving_state_map[task_state]
4337             expected_state = shelving_state_map[expected_state]
4338             instance.task_state = task_state
4339             instance.save(expected_task_state=expected_state)
4340 
4341         self._power_off_instance(context, instance, clean_shutdown)
4342         self.driver.snapshot(context, instance, image_id, update_task_state)
4343 
4344         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4345         instance.system_metadata['shelved_image_id'] = image_id
4346         instance.system_metadata['shelved_host'] = self.host
4347         instance.vm_state = vm_states.SHELVED
4348         instance.task_state = None
4349         if CONF.shelved_offload_time == 0:
4350             instance.task_state = task_states.SHELVING_OFFLOADING
4351         instance.power_state = self._get_power_state(context, instance)
4352         instance.save(expected_task_state=[
4353                 task_states.SHELVING,
4354                 task_states.SHELVING_IMAGE_UPLOADING])
4355 
4356         self._notify_about_instance_usage(context, instance, 'shelve.end')
4357         compute_utils.notify_about_instance_action(context, instance,
4358                 self.host, action=fields.NotificationAction.SHELVE,
4359                 phase=fields.NotificationPhase.END)
4360 
4361         if CONF.shelved_offload_time == 0:
4362             self._shelve_offload_instance(context, instance,
4363                                           clean_shutdown=False)
4364 
4365     @wrap_exception()
4366     @reverts_task_state
4367     @wrap_instance_fault
4368     def shelve_offload_instance(self, context, instance, clean_shutdown):
4369         """Remove a shelved instance from the hypervisor.
4370 
4371         This frees up those resources for use by other instances, but may lead
4372         to slower unshelve times for this instance.  This method is used by
4373         volume backed instances since restoring them doesn't involve the
4374         potentially large download of an image.
4375 
4376         :param context: request context
4377         :param instance: nova.objects.instance.Instance
4378         :param clean_shutdown: give the GuestOS a chance to stop
4379         """
4380 
4381         @utils.synchronized(instance.uuid)
4382         def do_shelve_offload_instance():
4383             self._shelve_offload_instance(context, instance, clean_shutdown)
4384         do_shelve_offload_instance()
4385 
4386     def _shelve_offload_instance(self, context, instance, clean_shutdown):
4387         LOG.info('Shelve offloading', instance=instance)
4388         self._notify_about_instance_usage(context, instance,
4389                 'shelve_offload.start')
4390         compute_utils.notify_about_instance_action(context, instance,
4391                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4392                 phase=fields.NotificationPhase.START)
4393 
4394         self._power_off_instance(context, instance, clean_shutdown)
4395         current_power_state = self._get_power_state(context, instance)
4396 
4397         self.network_api.cleanup_instance_network_on_host(context, instance,
4398                                                           instance.host)
4399         network_info = self.network_api.get_instance_nw_info(context, instance)
4400         block_device_info = self._get_instance_block_device_info(context,
4401                                                                  instance)
4402         self.driver.destroy(context, instance, network_info,
4403                 block_device_info)
4404 
4405         instance.power_state = current_power_state
4406         # NOTE(mriedem): The vm_state has to be set before updating the
4407         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4408         # values cannot be nulled out until after updating the resource tracker
4409         # though.
4410         instance.vm_state = vm_states.SHELVED_OFFLOADED
4411         instance.task_state = None
4412         instance.save(expected_task_state=[task_states.SHELVING,
4413                                            task_states.SHELVING_OFFLOADING])
4414 
4415         # NOTE(ndipanov): Free resources from the resource tracker
4416         self._update_resource_tracker(context, instance)
4417 
4418         rt = self._get_resource_tracker()
4419         rt.delete_allocation_for_shelve_offloaded_instance(instance)
4420 
4421         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4422         # instance, so ensure any calls result in errors
4423         self._nil_out_instance_obj_host_and_node(instance)
4424         instance.save(expected_task_state=None)
4425 
4426         self._delete_scheduler_instance_info(context, instance.uuid)
4427         self._notify_about_instance_usage(context, instance,
4428                 'shelve_offload.end')
4429         compute_utils.notify_about_instance_action(context, instance,
4430                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4431                 phase=fields.NotificationPhase.END)
4432 
4433     @wrap_exception()
4434     @reverts_task_state
4435     @wrap_instance_event(prefix='compute')
4436     @wrap_instance_fault
4437     def unshelve_instance(self, context, instance, image,
4438                           filter_properties, node):
4439         """Unshelve the instance.
4440 
4441         :param context: request context
4442         :param instance: a nova.objects.instance.Instance object
4443         :param image: an image to build from.  If None we assume a
4444             volume backed instance.
4445         :param filter_properties: dict containing limits, retry info etc.
4446         :param node: target compute node
4447         """
4448         if filter_properties is None:
4449             filter_properties = {}
4450 
4451         @utils.synchronized(instance.uuid)
4452         def do_unshelve_instance():
4453             self._unshelve_instance(context, instance, image,
4454                                     filter_properties, node)
4455         do_unshelve_instance()
4456 
4457     def _unshelve_instance_key_scrub(self, instance):
4458         """Remove data from the instance that may cause side effects."""
4459         cleaned_keys = dict(
4460                 key_data=instance.key_data,
4461                 auto_disk_config=instance.auto_disk_config)
4462         instance.key_data = None
4463         instance.auto_disk_config = False
4464         return cleaned_keys
4465 
4466     def _unshelve_instance_key_restore(self, instance, keys):
4467         """Restore previously scrubbed keys before saving the instance."""
4468         instance.update(keys)
4469 
4470     def _unshelve_instance(self, context, instance, image, filter_properties,
4471                            node):
4472         LOG.info('Unshelving', instance=instance)
4473         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4474         compute_utils.notify_about_instance_action(context, instance,
4475                 self.host, action=fields.NotificationAction.UNSHELVE,
4476                 phase=fields.NotificationPhase.START)
4477 
4478         instance.task_state = task_states.SPAWNING
4479         instance.save()
4480 
4481         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4482                 context, instance.uuid)
4483         block_device_info = self._prep_block_device(context, instance, bdms)
4484         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4485 
4486         if node is None:
4487             node = self.driver.get_available_nodes()[0]
4488             LOG.debug('No node specified, defaulting to %s', node,
4489                       instance=instance)
4490 
4491         rt = self._get_resource_tracker()
4492         limits = filter_properties.get('limits', {})
4493 
4494         shelved_image_ref = instance.image_ref
4495         if image:
4496             instance.image_ref = image['id']
4497             image_meta = objects.ImageMeta.from_dict(image)
4498         else:
4499             image_meta = objects.ImageMeta.from_dict(
4500                 utils.get_image_from_system_metadata(
4501                     instance.system_metadata))
4502 
4503         self.network_api.setup_instance_network_on_host(context, instance,
4504                                                         self.host)
4505         network_info = self.network_api.get_instance_nw_info(context, instance)
4506         try:
4507             with rt.instance_claim(context, instance, node, limits):
4508                 self.driver.spawn(context, instance, image_meta,
4509                                   injected_files=[],
4510                                   admin_password=None,
4511                                   network_info=network_info,
4512                                   block_device_info=block_device_info)
4513         except Exception:
4514             with excutils.save_and_reraise_exception():
4515                 LOG.exception('Instance failed to spawn',
4516                               instance=instance)
4517 
4518         if image:
4519             instance.image_ref = shelved_image_ref
4520             self._delete_snapshot_of_shelved_instance(context, instance,
4521                                                       image['id'])
4522 
4523         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4524         self._update_instance_after_spawn(context, instance)
4525         # Delete system_metadata for a shelved instance
4526         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4527 
4528         instance.save(expected_task_state=task_states.SPAWNING)
4529         self._update_scheduler_instance_info(context, instance)
4530         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4531         compute_utils.notify_about_instance_action(context, instance,
4532                 self.host, action=fields.NotificationAction.UNSHELVE,
4533                 phase=fields.NotificationPhase.END)
4534 
4535     @messaging.expected_exceptions(NotImplementedError)
4536     @wrap_instance_fault
4537     def reset_network(self, context, instance):
4538         """Reset networking on the given instance."""
4539         LOG.debug('Reset network', instance=instance)
4540         self.driver.reset_network(instance)
4541 
4542     def _inject_network_info(self, context, instance, network_info):
4543         """Inject network info for the given instance."""
4544         LOG.debug('Inject network info', instance=instance)
4545         LOG.debug('network_info to inject: |%s|', network_info,
4546                   instance=instance)
4547 
4548         self.driver.inject_network_info(instance,
4549                                         network_info)
4550 
4551     @wrap_instance_fault
4552     def inject_network_info(self, context, instance):
4553         """Inject network info, but don't return the info."""
4554         network_info = self.network_api.get_instance_nw_info(context, instance)
4555         self._inject_network_info(context, instance, network_info)
4556 
4557     @messaging.expected_exceptions(NotImplementedError,
4558                                    exception.ConsoleNotAvailable,
4559                                    exception.InstanceNotFound)
4560     @wrap_exception()
4561     @wrap_instance_fault
4562     def get_console_output(self, context, instance, tail_length):
4563         """Send the console output for the given instance."""
4564         context = context.elevated()
4565         LOG.info("Get console output", instance=instance)
4566         output = self.driver.get_console_output(context, instance)
4567 
4568         if type(output) is six.text_type:
4569             output = six.b(output)
4570 
4571         if tail_length is not None:
4572             output = self._tail_log(output, tail_length)
4573 
4574         return output.decode('ascii', 'replace')
4575 
4576     def _tail_log(self, log, length):
4577         try:
4578             length = int(length)
4579         except ValueError:
4580             length = 0
4581 
4582         if length == 0:
4583             return b''
4584         else:
4585             return b'\n'.join(log.split(b'\n')[-int(length):])
4586 
4587     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4588                                    exception.InstanceNotReady,
4589                                    exception.InstanceNotFound,
4590                                    exception.ConsoleTypeUnavailable,
4591                                    NotImplementedError)
4592     @wrap_exception()
4593     @wrap_instance_fault
4594     def get_vnc_console(self, context, console_type, instance):
4595         """Return connection information for a vnc console."""
4596         context = context.elevated()
4597         LOG.debug("Getting vnc console", instance=instance)
4598         token = uuidutils.generate_uuid()
4599 
4600         if not CONF.vnc.enabled:
4601             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4602 
4603         if console_type == 'novnc':
4604             # For essex, novncproxy_base_url must include the full path
4605             # including the html file (like http://myhost/vnc_auto.html)
4606             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
4607         elif console_type == 'xvpvnc':
4608             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
4609         else:
4610             raise exception.ConsoleTypeInvalid(console_type=console_type)
4611 
4612         try:
4613             # Retrieve connect info from driver, and then decorate with our
4614             # access info token
4615             console = self.driver.get_vnc_console(context, instance)
4616             connect_info = console.get_connection_info(token, access_url)
4617         except exception.InstanceNotFound:
4618             if instance.vm_state != vm_states.BUILDING:
4619                 raise
4620             raise exception.InstanceNotReady(instance_id=instance.uuid)
4621 
4622         return connect_info
4623 
4624     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4625                                    exception.InstanceNotReady,
4626                                    exception.InstanceNotFound,
4627                                    exception.ConsoleTypeUnavailable,
4628                                    NotImplementedError)
4629     @wrap_exception()
4630     @wrap_instance_fault
4631     def get_spice_console(self, context, console_type, instance):
4632         """Return connection information for a spice console."""
4633         context = context.elevated()
4634         LOG.debug("Getting spice console", instance=instance)
4635         token = uuidutils.generate_uuid()
4636 
4637         if not CONF.spice.enabled:
4638             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4639 
4640         if console_type == 'spice-html5':
4641             # For essex, spicehtml5proxy_base_url must include the full path
4642             # including the html file (like http://myhost/spice_auto.html)
4643             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
4644                                           token)
4645         else:
4646             raise exception.ConsoleTypeInvalid(console_type=console_type)
4647 
4648         try:
4649             # Retrieve connect info from driver, and then decorate with our
4650             # access info token
4651             console = self.driver.get_spice_console(context, instance)
4652             connect_info = console.get_connection_info(token, access_url)
4653         except exception.InstanceNotFound:
4654             if instance.vm_state != vm_states.BUILDING:
4655                 raise
4656             raise exception.InstanceNotReady(instance_id=instance.uuid)
4657 
4658         return connect_info
4659 
4660     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4661                                    exception.InstanceNotReady,
4662                                    exception.InstanceNotFound,
4663                                    exception.ConsoleTypeUnavailable,
4664                                    NotImplementedError)
4665     @wrap_exception()
4666     @wrap_instance_fault
4667     def get_rdp_console(self, context, console_type, instance):
4668         """Return connection information for a RDP console."""
4669         context = context.elevated()
4670         LOG.debug("Getting RDP console", instance=instance)
4671         token = uuidutils.generate_uuid()
4672 
4673         if not CONF.rdp.enabled:
4674             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4675 
4676         if console_type == 'rdp-html5':
4677             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
4678                                           token)
4679         else:
4680             raise exception.ConsoleTypeInvalid(console_type=console_type)
4681 
4682         try:
4683             # Retrieve connect info from driver, and then decorate with our
4684             # access info token
4685             console = self.driver.get_rdp_console(context, instance)
4686             connect_info = console.get_connection_info(token, access_url)
4687         except exception.InstanceNotFound:
4688             if instance.vm_state != vm_states.BUILDING:
4689                 raise
4690             raise exception.InstanceNotReady(instance_id=instance.uuid)
4691 
4692         return connect_info
4693 
4694     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4695                                    exception.InstanceNotReady,
4696                                    exception.InstanceNotFound,
4697                                    exception.ConsoleTypeUnavailable,
4698                                    NotImplementedError)
4699     @wrap_exception()
4700     @wrap_instance_fault
4701     def get_mks_console(self, context, console_type, instance):
4702         """Return connection information for a MKS console."""
4703         context = context.elevated()
4704         LOG.debug("Getting MKS console", instance=instance)
4705         token = uuidutils.generate_uuid()
4706 
4707         if not CONF.mks.enabled:
4708             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4709 
4710         if console_type == 'webmks':
4711             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
4712                                           token)
4713         else:
4714             raise exception.ConsoleTypeInvalid(console_type=console_type)
4715 
4716         try:
4717             # Retrieve connect info from driver, and then decorate with our
4718             # access info token
4719             console = self.driver.get_mks_console(context, instance)
4720             connect_info = console.get_connection_info(token, access_url)
4721         except exception.InstanceNotFound:
4722             if instance.vm_state != vm_states.BUILDING:
4723                 raise
4724             raise exception.InstanceNotReady(instance_id=instance.uuid)
4725 
4726         return connect_info
4727 
4728     @messaging.expected_exceptions(
4729         exception.ConsoleTypeInvalid,
4730         exception.InstanceNotReady,
4731         exception.InstanceNotFound,
4732         exception.ConsoleTypeUnavailable,
4733         exception.SocketPortRangeExhaustedException,
4734         exception.ImageSerialPortNumberInvalid,
4735         exception.ImageSerialPortNumberExceedFlavorValue,
4736         NotImplementedError)
4737     @wrap_exception()
4738     @wrap_instance_fault
4739     def get_serial_console(self, context, console_type, instance):
4740         """Returns connection information for a serial console."""
4741 
4742         LOG.debug("Getting serial console", instance=instance)
4743 
4744         if not CONF.serial_console.enabled:
4745             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4746 
4747         context = context.elevated()
4748 
4749         token = uuidutils.generate_uuid()
4750         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
4751 
4752         try:
4753             # Retrieve connect info from driver, and then decorate with our
4754             # access info token
4755             console = self.driver.get_serial_console(context, instance)
4756             connect_info = console.get_connection_info(token, access_url)
4757         except exception.InstanceNotFound:
4758             if instance.vm_state != vm_states.BUILDING:
4759                 raise
4760             raise exception.InstanceNotReady(instance_id=instance.uuid)
4761 
4762         return connect_info
4763 
4764     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4765                                    exception.InstanceNotReady,
4766                                    exception.InstanceNotFound)
4767     @wrap_exception()
4768     @wrap_instance_fault
4769     def validate_console_port(self, ctxt, instance, port, console_type):
4770         if console_type == "spice-html5":
4771             console_info = self.driver.get_spice_console(ctxt, instance)
4772         elif console_type == "rdp-html5":
4773             console_info = self.driver.get_rdp_console(ctxt, instance)
4774         elif console_type == "serial":
4775             console_info = self.driver.get_serial_console(ctxt, instance)
4776         elif console_type == "webmks":
4777             console_info = self.driver.get_mks_console(ctxt, instance)
4778         else:
4779             console_info = self.driver.get_vnc_console(ctxt, instance)
4780 
4781         return console_info.port == port
4782 
4783     @wrap_exception()
4784     @reverts_task_state
4785     @wrap_instance_fault
4786     def reserve_block_device_name(self, context, instance, device,
4787                                   volume_id, disk_bus, device_type, tag=None):
4788         if (tag and not
4789                 self.driver.capabilities.get('supports_tagged_attach_volume',
4790                                              False)):
4791             raise exception.VolumeTaggedAttachNotSupported()
4792 
4793         @utils.synchronized(instance.uuid)
4794         def do_reserve():
4795             bdms = (
4796                 objects.BlockDeviceMappingList.get_by_instance_uuid(
4797                     context, instance.uuid))
4798 
4799             # NOTE(ndipanov): We need to explicitly set all the fields on the
4800             #                 object so that obj_load_attr does not fail
4801             new_bdm = objects.BlockDeviceMapping(
4802                     context=context,
4803                     source_type='volume', destination_type='volume',
4804                     instance_uuid=instance.uuid, boot_index=None,
4805                     volume_id=volume_id,
4806                     device_name=device, guest_format=None,
4807                     disk_bus=disk_bus, device_type=device_type, tag=tag)
4808 
4809             new_bdm.device_name = self._get_device_name_for_instance(
4810                     instance, bdms, new_bdm)
4811 
4812             # NOTE(vish): create bdm here to avoid race condition
4813             new_bdm.create()
4814             return new_bdm
4815 
4816         return do_reserve()
4817 
4818     @wrap_exception()
4819     @wrap_instance_fault
4820     def attach_volume(self, context, instance, bdm):
4821         """Attach a volume to an instance."""
4822         driver_bdm = driver_block_device.convert_volume(bdm)
4823 
4824         @utils.synchronized(instance.uuid)
4825         def do_attach_volume(context, instance, driver_bdm):
4826             try:
4827                 return self._attach_volume(context, instance, driver_bdm)
4828             except Exception:
4829                 with excutils.save_and_reraise_exception():
4830                     bdm.destroy()
4831 
4832         do_attach_volume(context, instance, driver_bdm)
4833 
4834     def _attach_volume(self, context, instance, bdm):
4835         context = context.elevated()
4836         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
4837                  {'volume_id': bdm.volume_id,
4838                   'mountpoint': bdm['mount_device']},
4839                  instance=instance)
4840         compute_utils.notify_about_volume_attach_detach(
4841             context, instance, self.host,
4842             action=fields.NotificationAction.VOLUME_ATTACH,
4843             phase=fields.NotificationPhase.START,
4844             volume_id=bdm.volume_id)
4845         try:
4846             bdm.attach(context, instance, self.volume_api, self.driver,
4847                        do_driver_attach=True)
4848         except Exception as e:
4849             with excutils.save_and_reraise_exception():
4850                 LOG.exception("Failed to attach %(volume_id)s "
4851                               "at %(mountpoint)s",
4852                               {'volume_id': bdm.volume_id,
4853                                'mountpoint': bdm['mount_device']},
4854                               instance=instance)
4855                 if bdm['attachment_id']:
4856                     self.volume_api.attachment_delete(context,
4857                                                       bdm['attachment_id'])
4858                 else:
4859                     self.volume_api.unreserve_volume(context, bdm.volume_id)
4860                 compute_utils.notify_about_volume_attach_detach(
4861                     context, instance, self.host,
4862                     action=fields.NotificationAction.VOLUME_ATTACH,
4863                     phase=fields.NotificationPhase.ERROR,
4864                     exception=e,
4865                     volume_id=bdm.volume_id)
4866 
4867         info = {'volume_id': bdm.volume_id}
4868         self._notify_about_instance_usage(
4869             context, instance, "volume.attach", extra_usage_info=info)
4870         compute_utils.notify_about_volume_attach_detach(
4871             context, instance, self.host,
4872             action=fields.NotificationAction.VOLUME_ATTACH,
4873             phase=fields.NotificationPhase.END,
4874             volume_id=bdm.volume_id)
4875 
4876     def _notify_volume_usage_detach(self, context, instance, bdm):
4877         if CONF.volume_usage_poll_interval <= 0:
4878             return
4879 
4880         vol_stats = []
4881         mp = bdm.device_name
4882         # Handle bootable volumes which will not contain /dev/
4883         if '/dev/' in mp:
4884             mp = mp[5:]
4885         try:
4886             vol_stats = self.driver.block_stats(instance, mp)
4887         except NotImplementedError:
4888             return
4889 
4890         LOG.debug("Updating volume usage cache with totals", instance=instance)
4891         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
4892         vol_usage = objects.VolumeUsage(context)
4893         vol_usage.volume_id = bdm.volume_id
4894         vol_usage.instance_uuid = instance.uuid
4895         vol_usage.project_id = instance.project_id
4896         vol_usage.user_id = instance.user_id
4897         vol_usage.availability_zone = instance.availability_zone
4898         vol_usage.curr_reads = rd_req
4899         vol_usage.curr_read_bytes = rd_bytes
4900         vol_usage.curr_writes = wr_req
4901         vol_usage.curr_write_bytes = wr_bytes
4902         vol_usage.save(update_totals=True)
4903         self.notifier.info(context, 'volume.usage',
4904                            compute_utils.usage_volume_info(vol_usage))
4905 
4906     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
4907                        attachment_id=None):
4908         """Detach a volume from an instance.
4909 
4910         :param context: security context
4911         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
4912         :param instance: the Instance object to detach the volume from
4913         :param destroy_bdm: if True, the corresponding BDM entry will be marked
4914                             as deleted. Disabling this is useful for operations
4915                             like rebuild, when we don't want to destroy BDM
4916         :param attachment_id: The volume attachment_id for the given instance
4917                               and volume.
4918         """
4919         volume_id = bdm.volume_id
4920         compute_utils.notify_about_volume_attach_detach(
4921             context, instance, self.host,
4922             action=fields.NotificationAction.VOLUME_DETACH,
4923             phase=fields.NotificationPhase.START,
4924             volume_id=volume_id)
4925 
4926         self._notify_volume_usage_detach(context, instance, bdm)
4927 
4928         LOG.info('Detaching volume %(volume_id)s',
4929                  {'volume_id': volume_id}, instance=instance)
4930 
4931         driver_bdm = driver_block_device.convert_volume(bdm)
4932         driver_bdm.detach(context, instance, self.volume_api, self.driver,
4933                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
4934 
4935         info = dict(volume_id=volume_id)
4936         self._notify_about_instance_usage(
4937             context, instance, "volume.detach", extra_usage_info=info)
4938         compute_utils.notify_about_volume_attach_detach(
4939             context, instance, self.host,
4940             action=fields.NotificationAction.VOLUME_DETACH,
4941             phase=fields.NotificationPhase.END,
4942             volume_id=volume_id)
4943 
4944         if 'tag' in bdm and bdm.tag:
4945             self._delete_disk_metadata(instance, bdm)
4946         if destroy_bdm:
4947             bdm.destroy()
4948 
4949     def _delete_disk_metadata(self, instance, bdm):
4950         for device in instance.device_metadata.devices:
4951             if isinstance(device, objects.DiskMetadata):
4952                 if 'serial' in device:
4953                     if device.serial == bdm.volume_id:
4954                         instance.device_metadata.devices.remove(device)
4955                         instance.save()
4956                         break
4957                 else:
4958                     # NOTE(artom) We log the entire device object because all
4959                     # fields are nullable and may not be set
4960                     LOG.warning('Unable to determine whether to clean up '
4961                                 'device metadata for disk %s', device,
4962                                 instance=instance)
4963 
4964     @wrap_exception()
4965     @wrap_instance_fault
4966     def detach_volume(self, context, volume_id, instance, attachment_id=None):
4967         """Detach a volume from an instance.
4968 
4969         :param context: security context
4970         :param volume_id: the volume id
4971         :param instance: the Instance object to detach the volume from
4972         :param attachment_id: The volume attachment_id for the given instance
4973                               and volume.
4974 
4975         """
4976         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4977                 context, volume_id, instance.uuid)
4978         self._detach_volume(context, bdm, instance,
4979                             attachment_id=attachment_id)
4980 
4981     def _init_volume_connection(self, context, new_volume_id,
4982                                 old_volume_id, connector, bdm,
4983                                 new_attachment_id):
4984 
4985         if new_attachment_id is None:
4986             # We're dealing with an old-style attachment so initialize the
4987             # connection so we can get the connection_info.
4988             new_cinfo = self.volume_api.initialize_connection(context,
4989                                                               new_volume_id,
4990                                                               connector)
4991         else:
4992             # This is a new style attachment and the API created the new
4993             # volume attachment and passed the id to the compute over RPC.
4994             # At this point we need to update the new volume attachment with
4995             # the host connector, which will give us back the new attachment
4996             # connection_info.
4997             new_cinfo = self.volume_api.attachment_update(
4998                 context, new_attachment_id, connector)['connection_info']
4999 
5000         old_cinfo = jsonutils.loads(bdm['connection_info'])
5001         if old_cinfo and 'serial' not in old_cinfo:
5002             old_cinfo['serial'] = old_volume_id
5003         # NOTE(lyarwood): serial is not always present in the returned
5004         # connection_info so set it if it is missing as we do in
5005         # DriverVolumeBlockDevice.attach().
5006         if 'serial' not in new_cinfo:
5007             new_cinfo['serial'] = new_volume_id
5008         return (old_cinfo, new_cinfo)
5009 
5010     def _swap_volume(self, context, instance, bdm, connector,
5011                      old_volume_id, new_volume_id, resize_to,
5012                      new_attachment_id, is_cinder_migration):
5013         mountpoint = bdm['device_name']
5014         failed = False
5015         new_cinfo = None
5016         try:
5017             old_cinfo, new_cinfo = self._init_volume_connection(
5018                 context, new_volume_id, old_volume_id, connector,
5019                 bdm, new_attachment_id)
5020             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5021             # currently implementing swap_volume, will modify the contents of
5022             # new_cinfo when connect_volume is called. This is then saved to
5023             # the BDM in swap_volume for future use outside of this flow.
5024             LOG.debug("swap_volume: Calling driver volume swap with "
5025                       "connection infos: new: %(new_cinfo)s; "
5026                       "old: %(old_cinfo)s",
5027                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo},
5028                       instance=instance)
5029             self.driver.swap_volume(old_cinfo, new_cinfo, instance, mountpoint,
5030                                     resize_to)
5031             if new_attachment_id:
5032                 self.volume_api.attachment_complete(context, new_attachment_id)
5033             LOG.debug("swap_volume: Driver volume swap returned, new "
5034                       "connection_info is now : %(new_cinfo)s",
5035                       {'new_cinfo': new_cinfo})
5036         except Exception as ex:
5037             failed = True
5038             with excutils.save_and_reraise_exception():
5039                 compute_utils.notify_about_volume_swap(
5040                     context, instance, self.host,
5041                     fields.NotificationAction.VOLUME_SWAP,
5042                     fields.NotificationPhase.ERROR,
5043                     old_volume_id, new_volume_id, ex)
5044                 if new_cinfo:
5045                     msg = ("Failed to swap volume %(old_volume_id)s "
5046                            "for %(new_volume_id)s")
5047                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5048                                         'new_volume_id': new_volume_id},
5049                                   instance=instance)
5050                 else:
5051                     msg = ("Failed to connect to volume %(volume_id)s "
5052                            "with volume at %(mountpoint)s")
5053                     LOG.exception(msg, {'volume_id': new_volume_id,
5054                                         'mountpoint': bdm['device_name']},
5055                                   instance=instance)
5056 
5057                 # The API marked the volume as 'detaching' for the old volume
5058                 # so we need to roll that back so the volume goes back to
5059                 # 'in-use' state.
5060                 self.volume_api.roll_detaching(context, old_volume_id)
5061 
5062                 if new_attachment_id is None:
5063                     # The API reserved the new volume so it would be in
5064                     # 'attaching' status, so we need to unreserve it so it
5065                     # goes back to 'available' status.
5066                     self.volume_api.unreserve_volume(context, new_volume_id)
5067                 else:
5068                     # This is a new style attachment for the new volume, which
5069                     # was created in the API. We just need to delete it here
5070                     # to put the new volume back into 'available' status.
5071                     self.volume_api.attachment_delete(
5072                         context, new_attachment_id)
5073         finally:
5074             # TODO(mriedem): This finally block is terribly confusing and is
5075             # trying to do too much. We should consider removing the finally
5076             # block and move whatever needs to happen on success and failure
5077             # into the blocks above for clarity, even if it means a bit of
5078             # redundant code.
5079             conn_volume = new_volume_id if failed else old_volume_id
5080             if new_cinfo:
5081                 LOG.debug("swap_volume: removing Cinder connection "
5082                           "for volume %(volume)s", {'volume': conn_volume},
5083                           instance=instance)
5084                 if bdm.attachment_id is None:
5085                     # This is the pre-3.44 flow for new-style volume
5086                     # attachments so just terminate the connection.
5087                     self.volume_api.terminate_connection(context,
5088                                                          conn_volume,
5089                                                          connector)
5090                 else:
5091                     # This is a new style volume attachment. If we failed, then
5092                     # the new attachment was already deleted above in the
5093                     # exception block and we have nothing more to do here. If
5094                     # swap_volume was successful in the driver, then we need to
5095                     # "detach" the original attachment by deleting it.
5096                     if not failed:
5097                         self.volume_api.attachment_delete(
5098                             context, bdm.attachment_id)
5099 
5100             # Need to make some decisions based on whether this was
5101             # a Cinder initiated migration or not. The callback to
5102             # migration completion isn't needed in the case of a
5103             # nova initiated simple swap of two volume
5104             # "volume-update" call so skip that. The new attachment
5105             # scenarios will give us a new attachment record and
5106             # that's what we want.
5107             if bdm.attachment_id and not is_cinder_migration:
5108                 # we don't callback to cinder
5109                 comp_ret = {'save_volume_id': new_volume_id}
5110             else:
5111                 # NOTE(lyarwood): The following call to
5112                 # os-migrate-volume-completion returns a dict containing
5113                 # save_volume_id, this volume id has two possible values :
5114                 # 1. old_volume_id if we are migrating (retyping) volumes
5115                 # 2. new_volume_id if we are swapping between two existing
5116                 #    volumes
5117                 # This volume id is later used to update the volume_id and
5118                 # connection_info['serial'] of the BDM.
5119                 comp_ret = self.volume_api.migrate_volume_completion(
5120                                                           context,
5121                                                           old_volume_id,
5122                                                           new_volume_id,
5123                                                           error=failed)
5124                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5125                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5126                           instance=instance)
5127 
5128         return (comp_ret, new_cinfo)
5129 
5130     @wrap_exception()
5131     @wrap_instance_fault
5132     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
5133                     new_attachment_id=None):
5134         """Swap volume for an instance."""
5135         context = context.elevated()
5136 
5137         compute_utils.notify_about_volume_swap(
5138             context, instance, self.host,
5139             fields.NotificationAction.VOLUME_SWAP,
5140             fields.NotificationPhase.START,
5141             old_volume_id, new_volume_id)
5142 
5143         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5144                 context, old_volume_id, instance.uuid)
5145         connector = self.driver.get_volume_connector(instance)
5146 
5147         resize_to = 0
5148         old_volume = self.volume_api.get(context, old_volume_id)
5149         # Yes this is a tightly-coupled state check of what's going on inside
5150         # cinder, but we need this while we still support old (v1/v2) and
5151         # new style attachments (v3.44). Once we drop support for old style
5152         # attachments we could think about cleaning up the cinder-initiated
5153         # swap volume API flows.
5154         is_cinder_migration = (
5155             True if old_volume['status'] in ('retyping',
5156                                              'migrating') else False)
5157         old_vol_size = old_volume['size']
5158         new_vol_size = self.volume_api.get(context, new_volume_id)['size']
5159         if new_vol_size > old_vol_size:
5160             resize_to = new_vol_size
5161 
5162         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5163                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5164                  instance=instance)
5165         comp_ret, new_cinfo = self._swap_volume(context,
5166                                                 instance,
5167                                                 bdm,
5168                                                 connector,
5169                                                 old_volume_id,
5170                                                 new_volume_id,
5171                                                 resize_to,
5172                                                 new_attachment_id,
5173                                                 is_cinder_migration)
5174 
5175         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5176         # correct volume_id returned by Cinder.
5177         save_volume_id = comp_ret['save_volume_id']
5178         new_cinfo['serial'] = save_volume_id
5179         values = {
5180             'connection_info': jsonutils.dumps(new_cinfo),
5181             'source_type': 'volume',
5182             'destination_type': 'volume',
5183             'snapshot_id': None,
5184             'volume_id': save_volume_id,
5185             'no_device': None}
5186 
5187         if resize_to:
5188             values['volume_size'] = resize_to
5189 
5190         if new_attachment_id is not None:
5191             # This was a volume swap for a new-style attachment so we
5192             # need to update the BDM attachment_id for the new attachment.
5193             values['attachment_id'] = new_attachment_id
5194 
5195         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5196                   "%(updates)s", {'volume_id': bdm.volume_id,
5197                                   'updates': values},
5198                   instance=instance)
5199         bdm.update(values)
5200         bdm.save()
5201 
5202         compute_utils.notify_about_volume_swap(
5203             context, instance, self.host,
5204             fields.NotificationAction.VOLUME_SWAP,
5205             fields.NotificationPhase.END,
5206             old_volume_id, new_volume_id)
5207 
5208     @wrap_exception()
5209     def remove_volume_connection(self, context, volume_id, instance):
5210         """Remove a volume connection using the volume api."""
5211         # NOTE(vish): We don't want to actually mark the volume
5212         #             detached, or delete the bdm, just remove the
5213         #             connection from this host.
5214 
5215         try:
5216             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5217                     context, volume_id, instance.uuid)
5218             driver_bdm = driver_block_device.convert_volume(bdm)
5219             driver_bdm.driver_detach(context, instance,
5220                                      self.volume_api, self.driver)
5221             connector = self.driver.get_volume_connector(instance)
5222             self.volume_api.terminate_connection(context, volume_id, connector)
5223         except exception.NotFound:
5224             pass
5225 
5226     @wrap_exception()
5227     @wrap_instance_fault
5228     def attach_interface(self, context, instance, network_id, port_id,
5229                          requested_ip, tag=None):
5230         """Use hotplug to add an network adapter to an instance."""
5231         if not self.driver.capabilities['supports_attach_interface']:
5232             raise exception.AttachInterfaceNotSupported(
5233                 instance_uuid=instance.uuid)
5234         if (tag and not
5235             self.driver.capabilities.get('supports_tagged_attach_interface',
5236                                          False)):
5237             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5238         bind_host_id = self.driver.network_binding_host_id(context, instance)
5239         network_info = self.network_api.allocate_port_for_instance(
5240             context, instance, port_id, network_id, requested_ip,
5241             bind_host_id=bind_host_id, tag=tag)
5242         if len(network_info) != 1:
5243             LOG.error('allocate_port_for_instance returned %(ports)s '
5244                       'ports', {'ports': len(network_info)})
5245             raise exception.InterfaceAttachFailed(
5246                     instance_uuid=instance.uuid)
5247         image_meta = objects.ImageMeta.from_instance(instance)
5248 
5249         try:
5250             self.driver.attach_interface(context, instance, image_meta,
5251                                          network_info[0])
5252         except exception.NovaException as ex:
5253             port_id = network_info[0].get('id')
5254             LOG.warning("attach interface failed , try to deallocate "
5255                         "port %(port_id)s, reason: %(msg)s",
5256                         {'port_id': port_id, 'msg': ex},
5257                         instance=instance)
5258             try:
5259                 self.network_api.deallocate_port_for_instance(
5260                     context, instance, port_id)
5261             except Exception:
5262                 LOG.warning("deallocate port %(port_id)s failed",
5263                             {'port_id': port_id}, instance=instance)
5264             raise exception.InterfaceAttachFailed(
5265                 instance_uuid=instance.uuid)
5266 
5267         return network_info[0]
5268 
5269     @wrap_exception()
5270     @wrap_instance_fault
5271     def detach_interface(self, context, instance, port_id):
5272         """Detach a network adapter from an instance."""
5273         network_info = instance.info_cache.network_info
5274         condemned = None
5275         for vif in network_info:
5276             if vif['id'] == port_id:
5277                 condemned = vif
5278                 break
5279         if condemned is None:
5280             raise exception.PortNotFound(_("Port %s is not "
5281                                            "attached") % port_id)
5282         try:
5283             self.driver.detach_interface(context, instance, condemned)
5284         except exception.NovaException as ex:
5285             LOG.warning("Detach interface failed, port_id=%(port_id)s,"
5286                         " reason: %(msg)s",
5287                         {'port_id': port_id, 'msg': ex}, instance=instance)
5288             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5289         else:
5290             try:
5291                 self.network_api.deallocate_port_for_instance(
5292                     context, instance, port_id)
5293             except Exception as ex:
5294                 with excutils.save_and_reraise_exception():
5295                     # Since this is a cast operation, log the failure for
5296                     # triage.
5297                     LOG.warning('Failed to deallocate port %(port_id)s '
5298                                 'for instance. Error: %(error)s',
5299                                 {'port_id': port_id, 'error': ex},
5300                                 instance=instance)
5301 
5302     def _get_compute_info(self, context, host):
5303         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5304             context, host)
5305 
5306     @wrap_exception()
5307     def check_instance_shared_storage(self, ctxt, instance, data):
5308         """Check if the instance files are shared
5309 
5310         :param ctxt: security context
5311         :param instance: dict of instance data
5312         :param data: result of driver.check_instance_shared_storage_local
5313 
5314         Returns True if instance disks located on shared storage and
5315         False otherwise.
5316         """
5317         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5318 
5319     @wrap_exception()
5320     @wrap_instance_event(prefix='compute')
5321     @wrap_instance_fault
5322     def check_can_live_migrate_destination(self, ctxt, instance,
5323                                            block_migration, disk_over_commit):
5324         """Check if it is possible to execute live migration.
5325 
5326         This runs checks on the destination host, and then calls
5327         back to the source host to check the results.
5328 
5329         :param context: security context
5330         :param instance: dict of instance data
5331         :param block_migration: if true, prepare for block migration
5332                                 if None, calculate it in driver
5333         :param disk_over_commit: if true, allow disk over commit
5334                                  if None, ignore disk usage checking
5335         :returns: a dict containing migration info
5336         """
5337         return self._do_check_can_live_migrate_destination(ctxt, instance,
5338                                                             block_migration,
5339                                                             disk_over_commit)
5340 
5341     def _do_check_can_live_migrate_destination(self, ctxt, instance,
5342                                                block_migration,
5343                                                disk_over_commit):
5344         src_compute_info = obj_base.obj_to_primitive(
5345             self._get_compute_info(ctxt, instance.host))
5346         dst_compute_info = obj_base.obj_to_primitive(
5347             self._get_compute_info(ctxt, CONF.host))
5348         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5349             instance, src_compute_info, dst_compute_info,
5350             block_migration, disk_over_commit)
5351         LOG.debug('destination check data is %s', dest_check_data)
5352         try:
5353             migrate_data = self.compute_rpcapi.\
5354                                 check_can_live_migrate_source(ctxt, instance,
5355                                                               dest_check_data)
5356         finally:
5357             self.driver.cleanup_live_migration_destination_check(ctxt,
5358                     dest_check_data)
5359         return migrate_data
5360 
5361     @wrap_exception()
5362     @wrap_instance_event(prefix='compute')
5363     @wrap_instance_fault
5364     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5365         """Check if it is possible to execute live migration.
5366 
5367         This checks if the live migration can succeed, based on the
5368         results from check_can_live_migrate_destination.
5369 
5370         :param ctxt: security context
5371         :param instance: dict of instance data
5372         :param dest_check_data: result of check_can_live_migrate_destination
5373         :returns: a dict containing migration info
5374         """
5375         is_volume_backed = compute_utils.is_volume_backed_instance(ctxt,
5376                                                                       instance)
5377         # TODO(tdurakov): remove dict to object conversion once RPC API version
5378         # is bumped to 5.x
5379         got_migrate_data_object = isinstance(dest_check_data,
5380                                              migrate_data_obj.LiveMigrateData)
5381         if not got_migrate_data_object:
5382             dest_check_data = \
5383                 migrate_data_obj.LiveMigrateData.detect_implementation(
5384                     dest_check_data)
5385         dest_check_data.is_volume_backed = is_volume_backed
5386         block_device_info = self._get_instance_block_device_info(
5387                             ctxt, instance, refresh_conn_info=False)
5388         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5389                                                            dest_check_data,
5390                                                            block_device_info)
5391         if not got_migrate_data_object:
5392             result = result.to_legacy_dict()
5393         LOG.debug('source check data is %s', result)
5394         return result
5395 
5396     @wrap_exception()
5397     @wrap_instance_event(prefix='compute')
5398     @wrap_instance_fault
5399     def pre_live_migration(self, context, instance, block_migration, disk,
5400                            migrate_data):
5401         """Preparations for live migration at dest host.
5402 
5403         :param context: security context
5404         :param instance: dict of instance data
5405         :param block_migration: if true, prepare for block migration
5406         :param migrate_data: A dict or LiveMigrateData object holding data
5407                              required for live migration without shared
5408                              storage.
5409 
5410         """
5411         LOG.debug('pre_live_migration data is %s', migrate_data)
5412         # TODO(tdurakov): remove dict to object conversion once RPC API version
5413         # is bumped to 5.x
5414         got_migrate_data_object = isinstance(migrate_data,
5415                                              migrate_data_obj.LiveMigrateData)
5416         if not got_migrate_data_object:
5417             migrate_data = \
5418                 migrate_data_obj.LiveMigrateData.detect_implementation(
5419                     migrate_data)
5420         block_device_info = self._get_instance_block_device_info(
5421                             context, instance, refresh_conn_info=True)
5422 
5423         network_info = self.network_api.get_instance_nw_info(context, instance)
5424         self._notify_about_instance_usage(
5425                      context, instance, "live_migration.pre.start",
5426                      network_info=network_info)
5427 
5428         migrate_data = self.driver.pre_live_migration(context,
5429                                        instance,
5430                                        block_device_info,
5431                                        network_info,
5432                                        disk,
5433                                        migrate_data)
5434         LOG.debug('driver pre_live_migration data is %s', migrate_data)
5435 
5436         # NOTE(tr3buchet): setup networks on destination host
5437         self.network_api.setup_networks_on_host(context, instance,
5438                                                          self.host)
5439 
5440         # Creating filters to hypervisors and firewalls.
5441         # An example is that nova-instance-instance-xxx,
5442         # which is written to libvirt.xml(Check "virsh nwfilter-list")
5443         # This nwfilter is necessary on the destination host.
5444         # In addition, this method is creating filtering rule
5445         # onto destination host.
5446         self.driver.ensure_filtering_rules_for_instance(instance,
5447                                             network_info)
5448 
5449         self._notify_about_instance_usage(
5450                      context, instance, "live_migration.pre.end",
5451                      network_info=network_info)
5452         # TODO(tdurakov): remove dict to object conversion once RPC API version
5453         # is bumped to 5.x
5454         if not got_migrate_data_object and migrate_data:
5455             migrate_data = migrate_data.to_legacy_dict(
5456                 pre_migration_result=True)
5457             migrate_data = migrate_data['pre_live_migration_result']
5458         LOG.debug('pre_live_migration result data is %s', migrate_data)
5459         return migrate_data
5460 
5461     def _do_live_migration(self, context, dest, instance, block_migration,
5462                            migration, migrate_data):
5463         # NOTE(danms): We should enhance the RT to account for migrations
5464         # and use the status field to denote when the accounting has been
5465         # done on source/destination. For now, this is just here for status
5466         # reporting
5467         self._set_migration_status(migration, 'preparing')
5468 
5469         got_migrate_data_object = isinstance(migrate_data,
5470                                              migrate_data_obj.LiveMigrateData)
5471         if not got_migrate_data_object:
5472             migrate_data = \
5473                 migrate_data_obj.LiveMigrateData.detect_implementation(
5474                     migrate_data)
5475 
5476         try:
5477             if ('block_migration' in migrate_data and
5478                     migrate_data.block_migration):
5479                 block_device_info = self._get_instance_block_device_info(
5480                     context, instance)
5481                 disk = self.driver.get_instance_disk_info(
5482                     instance, block_device_info=block_device_info)
5483             else:
5484                 disk = None
5485 
5486             migrate_data = self.compute_rpcapi.pre_live_migration(
5487                 context, instance,
5488                 block_migration, disk, dest, migrate_data)
5489         except Exception:
5490             with excutils.save_and_reraise_exception():
5491                 LOG.exception('Pre live migration failed at %s',
5492                               dest, instance=instance)
5493                 self._set_migration_status(migration, 'error')
5494                 self._rollback_live_migration(context, instance, dest,
5495                                               migrate_data)
5496 
5497         self._set_migration_status(migration, 'running')
5498 
5499         if migrate_data:
5500             migrate_data.migration = migration
5501         LOG.debug('live_migration data is %s', migrate_data)
5502         try:
5503             self.driver.live_migration(context, instance, dest,
5504                                        self._post_live_migration,
5505                                        self._rollback_live_migration,
5506                                        block_migration, migrate_data)
5507         except Exception:
5508             LOG.exception('Live migration failed.', instance=instance)
5509             with excutils.save_and_reraise_exception():
5510                 # Put instance and migration into error state,
5511                 # as its almost certainly too late to rollback
5512                 self._set_migration_status(migration, 'error')
5513                 # first refresh instance as it may have got updated by
5514                 # post_live_migration_at_destination
5515                 instance.refresh()
5516                 self._set_instance_obj_error_state(context, instance,
5517                                                    clean_task_state=True)
5518 
5519     @wrap_exception()
5520     @wrap_instance_event(prefix='compute')
5521     @wrap_instance_fault
5522     def live_migration(self, context, dest, instance, block_migration,
5523                        migration, migrate_data):
5524         """Executing live migration.
5525 
5526         :param context: security context
5527         :param dest: destination host
5528         :param instance: a nova.objects.instance.Instance object
5529         :param block_migration: if true, prepare for block migration
5530         :param migration: an nova.objects.Migration object
5531         :param migrate_data: implementation specific params
5532 
5533         """
5534         self._set_migration_status(migration, 'queued')
5535 
5536         def dispatch_live_migration(*args, **kwargs):
5537             with self._live_migration_semaphore:
5538                 self._do_live_migration(*args, **kwargs)
5539 
5540         # NOTE(danms): We spawn here to return the RPC worker thread back to
5541         # the pool. Since what follows could take a really long time, we don't
5542         # want to tie up RPC workers.
5543         utils.spawn_n(dispatch_live_migration,
5544                       context, dest, instance,
5545                       block_migration, migration,
5546                       migrate_data)
5547 
5548     # TODO(tdurakov): migration_id is used since 4.12 rpc api version
5549     # remove migration_id parameter when the compute RPC version
5550     # is bumped to 5.x.
5551     @wrap_exception()
5552     @wrap_instance_event(prefix='compute')
5553     @wrap_instance_fault
5554     def live_migration_force_complete(self, context, instance,
5555                                       migration_id=None):
5556         """Force live migration to complete.
5557 
5558         :param context: Security context
5559         :param instance: The instance that is being migrated
5560         :param migration_id: ID of ongoing migration; is currently not used,
5561         and isn't removed for backward compatibility
5562         """
5563 
5564         self._notify_about_instance_usage(
5565             context, instance, 'live.migration.force.complete.start')
5566         self.driver.live_migration_force_complete(instance)
5567         self._notify_about_instance_usage(
5568             context, instance, 'live.migration.force.complete.end')
5569 
5570     @wrap_exception()
5571     @wrap_instance_event(prefix='compute')
5572     @wrap_instance_fault
5573     def live_migration_abort(self, context, instance, migration_id):
5574         """Abort an in-progress live migration.
5575 
5576         :param context: Security context
5577         :param instance: The instance that is being migrated
5578         :param migration_id: ID of in-progress live migration
5579 
5580         """
5581         migration = objects.Migration.get_by_id(context, migration_id)
5582         if migration.status != 'running':
5583             raise exception.InvalidMigrationState(migration_id=migration_id,
5584                     instance_uuid=instance.uuid,
5585                     state=migration.status,
5586                     method='abort live migration')
5587 
5588         self._notify_about_instance_usage(
5589             context, instance, 'live.migration.abort.start')
5590         self.driver.live_migration_abort(instance)
5591         self._notify_about_instance_usage(
5592             context, instance, 'live.migration.abort.end')
5593 
5594     def _live_migration_cleanup_flags(self, migrate_data):
5595         """Determine whether disks or instance path need to be cleaned up after
5596         live migration (at source on success, at destination on rollback)
5597 
5598         Block migration needs empty image at destination host before migration
5599         starts, so if any failure occurs, any empty images has to be deleted.
5600 
5601         Also Volume backed live migration w/o shared storage needs to delete
5602         newly created instance-xxx dir on the destination as a part of its
5603         rollback process
5604 
5605         :param migrate_data: implementation specific data
5606         :returns: (bool, bool) -- do_cleanup, destroy_disks
5607         """
5608         # NOTE(pkoniszewski): block migration specific params are set inside
5609         # migrate_data objects for drivers that expose block live migration
5610         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
5611         # cleanup is not needed.
5612         is_shared_block_storage = True
5613         is_shared_instance_path = True
5614         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
5615             is_shared_block_storage = migrate_data.is_shared_block_storage
5616             is_shared_instance_path = migrate_data.is_shared_instance_path
5617         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
5618             is_shared_block_storage = not migrate_data.block_migration
5619             is_shared_instance_path = not migrate_data.block_migration
5620         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
5621             is_shared_instance_path = migrate_data.is_shared_instance_path
5622             is_shared_block_storage = migrate_data.is_shared_instance_path
5623 
5624         # No instance booting at source host, but instance dir
5625         # must be deleted for preparing next block migration
5626         # must be deleted for preparing next live migration w/o shared storage
5627         do_cleanup = not is_shared_instance_path
5628         destroy_disks = not is_shared_block_storage
5629 
5630         return (do_cleanup, destroy_disks)
5631 
5632     @wrap_exception()
5633     @wrap_instance_fault
5634     def _post_live_migration(self, ctxt, instance,
5635                             dest, block_migration=False, migrate_data=None):
5636         """Post operations for live migration.
5637 
5638         This method is called from live_migration
5639         and mainly updating database record.
5640 
5641         :param ctxt: security context
5642         :param instance: instance dict
5643         :param dest: destination host
5644         :param block_migration: if true, prepare for block migration
5645         :param migrate_data: if not None, it is a dict which has data
5646         required for live migration without shared storage
5647 
5648         """
5649         LOG.info('_post_live_migration() is started..',
5650                  instance=instance)
5651 
5652         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5653                 ctxt, instance.uuid)
5654 
5655         # Cleanup source host post live-migration
5656         block_device_info = self._get_instance_block_device_info(
5657                             ctxt, instance, bdms=bdms)
5658         self.driver.post_live_migration(ctxt, instance, block_device_info,
5659                                         migrate_data)
5660 
5661         # Detaching volumes.
5662         connector = self.driver.get_volume_connector(instance)
5663         for bdm in bdms:
5664             # NOTE(vish): We don't want to actually mark the volume
5665             #             detached, or delete the bdm, just remove the
5666             #             connection from this host.
5667 
5668             # remove the volume connection without detaching from hypervisor
5669             # because the instance is not running anymore on the current host
5670             if bdm.is_volume:
5671                 self.volume_api.terminate_connection(ctxt, bdm.volume_id,
5672                                                      connector)
5673 
5674         # Releasing vlan.
5675         # (not necessary in current implementation?)
5676 
5677         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
5678 
5679         self._notify_about_instance_usage(ctxt, instance,
5680                                           "live_migration._post.start",
5681                                           network_info=network_info)
5682         # Releasing security group ingress rule.
5683         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
5684                   instance=instance)
5685         self.driver.unfilter_instance(instance,
5686                                       network_info)
5687 
5688         migration = {'source_compute': self.host,
5689                      'dest_compute': dest, }
5690         self.network_api.migrate_instance_start(ctxt,
5691                                                 instance,
5692                                                 migration)
5693 
5694         destroy_vifs = False
5695         try:
5696             self.driver.post_live_migration_at_source(ctxt, instance,
5697                                                       network_info)
5698         except NotImplementedError as ex:
5699             LOG.debug(ex, instance=instance)
5700             # For all hypervisors other than libvirt, there is a possibility
5701             # they are unplugging networks from source node in the cleanup
5702             # method
5703             destroy_vifs = True
5704 
5705         # NOTE(danms): Save source node before calling post method on
5706         # destination, which will update it
5707         source_node = instance.node
5708 
5709         # Define domain at destination host, without doing it,
5710         # pause/suspend/terminate do not work.
5711         post_at_dest_success = True
5712         try:
5713             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
5714                     instance, block_migration, dest)
5715         except Exception as error:
5716             post_at_dest_success = False
5717             # We don't want to break _post_live_migration() if
5718             # post_live_migration_at_destination() fails as it should never
5719             # affect cleaning up source node.
5720             LOG.exception("Post live migration at destination %s failed",
5721                           dest, instance=instance, error=error)
5722 
5723         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5724                 migrate_data)
5725 
5726         if do_cleanup:
5727             LOG.debug('Calling driver.cleanup from _post_live_migration',
5728                       instance=instance)
5729             self.driver.cleanup(ctxt, instance, network_info,
5730                                 destroy_disks=destroy_disks,
5731                                 migrate_data=migrate_data,
5732                                 destroy_vifs=destroy_vifs)
5733 
5734         self.instance_events.clear_events_for_instance(instance)
5735 
5736         # NOTE(timello): make sure we update available resources on source
5737         # host even before next periodic task.
5738         self.update_available_resource(ctxt)
5739 
5740         rt = self._get_resource_tracker()
5741         rt.delete_allocation_for_migrated_instance(
5742             instance, source_node)
5743 
5744         self._update_scheduler_instance_info(ctxt, instance)
5745         self._notify_about_instance_usage(ctxt, instance,
5746                                           "live_migration._post.end",
5747                                           network_info=network_info)
5748         if post_at_dest_success:
5749             LOG.info('Migrating instance to %s finished successfully.',
5750                      dest, instance=instance)
5751 
5752         if migrate_data and migrate_data.obj_attr_is_set('migration'):
5753             migrate_data.migration.status = 'completed'
5754             migrate_data.migration.save()
5755 
5756     def _consoles_enabled(self):
5757         """Returns whether a console is enable."""
5758         return (CONF.vnc.enabled or CONF.spice.enabled or
5759                 CONF.rdp.enabled or CONF.serial_console.enabled or
5760                 CONF.mks.enabled)
5761 
5762     @wrap_exception()
5763     @wrap_instance_event(prefix='compute')
5764     @wrap_instance_fault
5765     def post_live_migration_at_destination(self, context, instance,
5766                                            block_migration):
5767         """Post operations for live migration .
5768 
5769         :param context: security context
5770         :param instance: Instance dict
5771         :param block_migration: if true, prepare for block migration
5772 
5773         """
5774         LOG.info('Post operation of migration started',
5775                  instance=instance)
5776 
5777         # NOTE(tr3buchet): setup networks on destination host
5778         #                  this is called a second time because
5779         #                  multi_host does not create the bridge in
5780         #                  plug_vifs
5781         self.network_api.setup_networks_on_host(context, instance,
5782                                                          self.host)
5783         migration = {'source_compute': instance.host,
5784                      'dest_compute': self.host, }
5785         self.network_api.migrate_instance_finish(context,
5786                                                  instance,
5787                                                  migration)
5788 
5789         network_info = self.network_api.get_instance_nw_info(context, instance)
5790         self._notify_about_instance_usage(
5791                      context, instance, "live_migration.post.dest.start",
5792                      network_info=network_info)
5793         block_device_info = self._get_instance_block_device_info(context,
5794                                                                  instance)
5795 
5796         try:
5797             self.driver.post_live_migration_at_destination(
5798                 context, instance, network_info, block_migration,
5799                 block_device_info)
5800         except Exception:
5801             with excutils.save_and_reraise_exception():
5802                 instance.vm_state = vm_states.ERROR
5803                 LOG.error('Unexpected error during post live migration at '
5804                           'destination host.', instance=instance)
5805         finally:
5806             # Restore instance state and update host
5807             current_power_state = self._get_power_state(context, instance)
5808             node_name = None
5809             prev_host = instance.host
5810             try:
5811                 compute_node = self._get_compute_info(context, self.host)
5812                 node_name = compute_node.hypervisor_hostname
5813             except exception.ComputeHostNotFound:
5814                 LOG.exception('Failed to get compute_info for %s', self.host)
5815             finally:
5816                 instance.host = self.host
5817                 instance.power_state = current_power_state
5818                 instance.task_state = None
5819                 instance.node = node_name
5820                 instance.progress = 0
5821                 instance.save(expected_task_state=task_states.MIGRATING)
5822 
5823         # NOTE(tr3buchet): tear down networks on source host
5824         self.network_api.setup_networks_on_host(context, instance,
5825                                                 prev_host, teardown=True)
5826         # NOTE(vish): this is necessary to update dhcp
5827         self.network_api.setup_networks_on_host(context, instance, self.host)
5828         self._notify_about_instance_usage(
5829                      context, instance, "live_migration.post.dest.end",
5830                      network_info=network_info)
5831 
5832     @wrap_exception()
5833     @wrap_instance_fault
5834     def _rollback_live_migration(self, context, instance,
5835                                  dest, migrate_data=None,
5836                                  migration_status='error'):
5837         """Recovers Instance/volume state from migrating -> running.
5838 
5839         :param context: security context
5840         :param instance: nova.objects.instance.Instance object
5841         :param dest:
5842             This method is called from live migration src host.
5843             This param specifies destination host.
5844         :param migrate_data:
5845             if not none, contains implementation specific data.
5846         :param migration_status:
5847             Contains the status we want to set for the migration object
5848 
5849         """
5850         instance.task_state = None
5851         instance.progress = 0
5852         instance.save(expected_task_state=[task_states.MIGRATING])
5853 
5854         # TODO(tdurakov): remove dict to object conversion once RPC API version
5855         # is bumped to 5.x
5856         if isinstance(migrate_data, dict):
5857             migration = migrate_data.pop('migration', None)
5858             migrate_data = \
5859                 migrate_data_obj.LiveMigrateData.detect_implementation(
5860                     migrate_data)
5861         elif (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
5862               migrate_data.obj_attr_is_set('migration')):
5863             migration = migrate_data.migration
5864         else:
5865             migration = None
5866 
5867         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
5868         self.network_api.setup_networks_on_host(context, instance, self.host)
5869 
5870         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5871                 context, instance.uuid)
5872         for bdm in bdms:
5873             if bdm.is_volume:
5874                 self.compute_rpcapi.remove_volume_connection(
5875                         context, instance, bdm.volume_id, dest)
5876 
5877         self._notify_about_instance_usage(context, instance,
5878                                           "live_migration._rollback.start")
5879         compute_utils.notify_about_instance_action(context, instance,
5880                 self.host,
5881                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
5882                 phase=fields.NotificationPhase.START)
5883 
5884         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5885                 migrate_data)
5886 
5887         if do_cleanup:
5888             self.compute_rpcapi.rollback_live_migration_at_destination(
5889                     context, instance, dest, destroy_disks=destroy_disks,
5890                     migrate_data=migrate_data)
5891 
5892         self._notify_about_instance_usage(context, instance,
5893                                           "live_migration._rollback.end")
5894         compute_utils.notify_about_instance_action(context, instance,
5895                 self.host,
5896                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
5897                 phase=fields.NotificationPhase.END)
5898 
5899         self._set_migration_status(migration, migration_status)
5900 
5901     @wrap_exception()
5902     @wrap_instance_event(prefix='compute')
5903     @wrap_instance_fault
5904     def rollback_live_migration_at_destination(self, context, instance,
5905                                                destroy_disks,
5906                                                migrate_data):
5907         """Cleaning up image directory that is created pre_live_migration.
5908 
5909         :param context: security context
5910         :param instance: a nova.objects.instance.Instance object sent over rpc
5911         """
5912         network_info = self.network_api.get_instance_nw_info(context, instance)
5913         self._notify_about_instance_usage(
5914                       context, instance, "live_migration.rollback.dest.start",
5915                       network_info=network_info)
5916         try:
5917             # NOTE(tr3buchet): tear down networks on destination host
5918             self.network_api.setup_networks_on_host(context, instance,
5919                                                     self.host, teardown=True)
5920         except Exception:
5921             with excutils.save_and_reraise_exception():
5922                 # NOTE(tdurakov): even if teardown networks fails driver
5923                 # should try to rollback live migration on destination.
5924                 LOG.exception('An error occurred while deallocating network.',
5925                               instance=instance)
5926         finally:
5927             # always run this even if setup_networks_on_host fails
5928             # NOTE(vish): The mapping is passed in so the driver can disconnect
5929             #             from remote volumes if necessary
5930             block_device_info = self._get_instance_block_device_info(context,
5931                                                                      instance)
5932             # TODO(tdurakov): remove dict to object conversion once RPC API
5933             # version is bumped to 5.x
5934             if isinstance(migrate_data, dict):
5935                 migrate_data = \
5936                     migrate_data_obj.LiveMigrateData.detect_implementation(
5937                         migrate_data)
5938             self.driver.rollback_live_migration_at_destination(
5939                 context, instance, network_info, block_device_info,
5940                 destroy_disks=destroy_disks, migrate_data=migrate_data)
5941 
5942         self._notify_about_instance_usage(
5943                         context, instance, "live_migration.rollback.dest.end",
5944                         network_info=network_info)
5945 
5946     @periodic_task.periodic_task(
5947         spacing=CONF.heal_instance_info_cache_interval)
5948     def _heal_instance_info_cache(self, context):
5949         """Called periodically.  On every call, try to update the
5950         info_cache's network information for another instance by
5951         calling to the network manager.
5952 
5953         This is implemented by keeping a cache of uuids of instances
5954         that live on this host.  On each call, we pop one off of a
5955         list, pull the DB record, and try the call to the network API.
5956         If anything errors don't fail, as it's possible the instance
5957         has been deleted, etc.
5958         """
5959         heal_interval = CONF.heal_instance_info_cache_interval
5960         if not heal_interval:
5961             return
5962 
5963         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
5964         instance = None
5965 
5966         LOG.debug('Starting heal instance info cache')
5967 
5968         if not instance_uuids:
5969             # The list of instances to heal is empty so rebuild it
5970             LOG.debug('Rebuilding the list of instances to heal')
5971             db_instances = objects.InstanceList.get_by_host(
5972                 context, self.host, expected_attrs=[], use_slave=True)
5973             for inst in db_instances:
5974                 # We don't want to refresh the cache for instances
5975                 # which are building or deleting so don't put them
5976                 # in the list. If they are building they will get
5977                 # added to the list next time we build it.
5978                 if (inst.vm_state == vm_states.BUILDING):
5979                     LOG.debug('Skipping network cache update for instance '
5980                               'because it is Building.', instance=inst)
5981                     continue
5982                 if (inst.task_state == task_states.DELETING):
5983                     LOG.debug('Skipping network cache update for instance '
5984                               'because it is being deleted.', instance=inst)
5985                     continue
5986 
5987                 if not instance:
5988                     # Save the first one we find so we don't
5989                     # have to get it again
5990                     instance = inst
5991                 else:
5992                     instance_uuids.append(inst['uuid'])
5993 
5994             self._instance_uuids_to_heal = instance_uuids
5995         else:
5996             # Find the next valid instance on the list
5997             while instance_uuids:
5998                 try:
5999                     inst = objects.Instance.get_by_uuid(
6000                             context, instance_uuids.pop(0),
6001                             expected_attrs=['system_metadata', 'info_cache',
6002                                             'flavor'],
6003                             use_slave=True)
6004                 except exception.InstanceNotFound:
6005                     # Instance is gone.  Try to grab another.
6006                     continue
6007 
6008                 # Check the instance hasn't been migrated
6009                 if inst.host != self.host:
6010                     LOG.debug('Skipping network cache update for instance '
6011                               'because it has been migrated to another '
6012                               'host.', instance=inst)
6013                 # Check the instance isn't being deleting
6014                 elif inst.task_state == task_states.DELETING:
6015                     LOG.debug('Skipping network cache update for instance '
6016                               'because it is being deleted.', instance=inst)
6017                 else:
6018                     instance = inst
6019                     break
6020 
6021         if instance:
6022             # We have an instance now to refresh
6023             try:
6024                 # Call to network API to get instance info.. this will
6025                 # force an update to the instance's info_cache
6026                 self.network_api.get_instance_nw_info(context, instance)
6027                 LOG.debug('Updated the network info_cache for instance',
6028                           instance=instance)
6029             except exception.InstanceNotFound:
6030                 # Instance is gone.
6031                 LOG.debug('Instance no longer exists. Unable to refresh',
6032                           instance=instance)
6033                 return
6034             except exception.InstanceInfoCacheNotFound:
6035                 # InstanceInfoCache is gone.
6036                 LOG.debug('InstanceInfoCache no longer exists. '
6037                           'Unable to refresh', instance=instance)
6038             except Exception:
6039                 LOG.error('An error occurred while refreshing the network '
6040                           'cache.', instance=instance, exc_info=True)
6041         else:
6042             LOG.debug("Didn't find any instances for network info cache "
6043                       "update.")
6044 
6045     @periodic_task.periodic_task
6046     def _poll_rebooting_instances(self, context):
6047         if CONF.reboot_timeout > 0:
6048             filters = {'task_state':
6049                        [task_states.REBOOTING,
6050                         task_states.REBOOT_STARTED,
6051                         task_states.REBOOT_PENDING],
6052                        'host': self.host}
6053             rebooting = objects.InstanceList.get_by_filters(
6054                 context, filters, expected_attrs=[], use_slave=True)
6055 
6056             to_poll = []
6057             for instance in rebooting:
6058                 if timeutils.is_older_than(instance.updated_at,
6059                                            CONF.reboot_timeout):
6060                     to_poll.append(instance)
6061 
6062             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
6063 
6064     @periodic_task.periodic_task
6065     def _poll_rescued_instances(self, context):
6066         if CONF.rescue_timeout > 0:
6067             filters = {'vm_state': vm_states.RESCUED,
6068                        'host': self.host}
6069             rescued_instances = objects.InstanceList.get_by_filters(
6070                 context, filters, expected_attrs=["system_metadata"],
6071                 use_slave=True)
6072 
6073             to_unrescue = []
6074             for instance in rescued_instances:
6075                 if timeutils.is_older_than(instance.launched_at,
6076                                            CONF.rescue_timeout):
6077                     to_unrescue.append(instance)
6078 
6079             for instance in to_unrescue:
6080                 self.compute_api.unrescue(context, instance)
6081 
6082     @periodic_task.periodic_task
6083     def _poll_unconfirmed_resizes(self, context):
6084         if CONF.resize_confirm_window == 0:
6085             return
6086 
6087         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
6088                 context, CONF.resize_confirm_window, self.host,
6089                 use_slave=True)
6090 
6091         migrations_info = dict(migration_count=len(migrations),
6092                 confirm_window=CONF.resize_confirm_window)
6093 
6094         if migrations_info["migration_count"] > 0:
6095             LOG.info("Found %(migration_count)d unconfirmed migrations "
6096                      "older than %(confirm_window)d seconds",
6097                      migrations_info)
6098 
6099         def _set_migration_to_error(migration, reason, **kwargs):
6100             LOG.warning("Setting migration %(migration_id)s to error: "
6101                         "%(reason)s",
6102                         {'migration_id': migration['id'], 'reason': reason},
6103                         **kwargs)
6104             migration.status = 'error'
6105             with migration.obj_as_admin():
6106                 migration.save()
6107 
6108         for migration in migrations:
6109             instance_uuid = migration.instance_uuid
6110             LOG.info("Automatically confirming migration "
6111                      "%(migration_id)s for instance %(instance_uuid)s",
6112                      {'migration_id': migration.id,
6113                       'instance_uuid': instance_uuid})
6114             expected_attrs = ['metadata', 'system_metadata']
6115             try:
6116                 instance = objects.Instance.get_by_uuid(context,
6117                             instance_uuid, expected_attrs=expected_attrs,
6118                             use_slave=True)
6119             except exception.InstanceNotFound:
6120                 reason = (_("Instance %s not found") %
6121                           instance_uuid)
6122                 _set_migration_to_error(migration, reason)
6123                 continue
6124             if instance.vm_state == vm_states.ERROR:
6125                 reason = _("In ERROR state")
6126                 _set_migration_to_error(migration, reason,
6127                                         instance=instance)
6128                 continue
6129             # race condition: The instance in DELETING state should not be
6130             # set the migration state to error, otherwise the instance in
6131             # to be deleted which is in RESIZED state
6132             # will not be able to confirm resize
6133             if instance.task_state in [task_states.DELETING,
6134                                        task_states.SOFT_DELETING]:
6135                 msg = ("Instance being deleted or soft deleted during resize "
6136                        "confirmation. Skipping.")
6137                 LOG.debug(msg, instance=instance)
6138                 continue
6139 
6140             # race condition: This condition is hit when this method is
6141             # called between the save of the migration record with a status of
6142             # finished and the save of the instance object with a state of
6143             # RESIZED. The migration record should not be set to error.
6144             if instance.task_state == task_states.RESIZE_FINISH:
6145                 msg = ("Instance still resizing during resize "
6146                        "confirmation. Skipping.")
6147                 LOG.debug(msg, instance=instance)
6148                 continue
6149 
6150             vm_state = instance.vm_state
6151             task_state = instance.task_state
6152             if vm_state != vm_states.RESIZED or task_state is not None:
6153                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
6154                            "RESIZED/None") %
6155                           {'vm_state': vm_state,
6156                            'task_state': task_state})
6157                 _set_migration_to_error(migration, reason,
6158                                         instance=instance)
6159                 continue
6160             try:
6161                 self.compute_api.confirm_resize(context, instance,
6162                                                 migration=migration)
6163             except Exception as e:
6164                 LOG.info("Error auto-confirming resize: %s. "
6165                          "Will retry later.", e, instance=instance)
6166 
6167     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
6168     def _poll_shelved_instances(self, context):
6169 
6170         if CONF.shelved_offload_time <= 0:
6171             return
6172 
6173         filters = {'vm_state': vm_states.SHELVED,
6174                    'task_state': None,
6175                    'host': self.host}
6176         shelved_instances = objects.InstanceList.get_by_filters(
6177             context, filters=filters, expected_attrs=['system_metadata'],
6178             use_slave=True)
6179 
6180         to_gc = []
6181         for instance in shelved_instances:
6182             sys_meta = instance.system_metadata
6183             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
6184             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
6185                 to_gc.append(instance)
6186 
6187         for instance in to_gc:
6188             try:
6189                 instance.task_state = task_states.SHELVING_OFFLOADING
6190                 instance.save(expected_task_state=(None,))
6191                 self.shelve_offload_instance(context, instance,
6192                                              clean_shutdown=False)
6193             except Exception:
6194                 LOG.exception('Periodic task failed to offload instance.',
6195                               instance=instance)
6196 
6197     @periodic_task.periodic_task
6198     def _instance_usage_audit(self, context):
6199         if not CONF.instance_usage_audit:
6200             return
6201 
6202         begin, end = utils.last_completed_audit_period()
6203         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
6204                                self.host):
6205             return
6206 
6207         instances = objects.InstanceList.get_active_by_window_joined(
6208             context, begin, end, host=self.host,
6209             expected_attrs=['system_metadata', 'info_cache', 'metadata',
6210                             'flavor'],
6211             use_slave=True)
6212         num_instances = len(instances)
6213         errors = 0
6214         successes = 0
6215         LOG.info("Running instance usage audit for host %(host)s "
6216                  "from %(begin_time)s to %(end_time)s. "
6217                  "%(number_instances)s instances.",
6218                  {'host': self.host,
6219                   'begin_time': begin,
6220                   'end_time': end,
6221                   'number_instances': num_instances})
6222         start_time = time.time()
6223         task_log = objects.TaskLog(context)
6224         task_log.task_name = 'instance_usage_audit'
6225         task_log.period_beginning = begin
6226         task_log.period_ending = end
6227         task_log.host = self.host
6228         task_log.task_items = num_instances
6229         task_log.message = 'Instance usage audit started...'
6230         task_log.begin_task()
6231         for instance in instances:
6232             try:
6233                 compute_utils.notify_usage_exists(
6234                     self.notifier, context, instance,
6235                     ignore_missing_network_data=False)
6236                 successes += 1
6237             except Exception:
6238                 LOG.exception('Failed to generate usage '
6239                               'audit for instance '
6240                               'on host %s', self.host,
6241                               instance=instance)
6242                 errors += 1
6243         task_log.errors = errors
6244         task_log.message = (
6245             'Instance usage audit ran for host %s, %s instances in %s seconds.'
6246             % (self.host, num_instances, time.time() - start_time))
6247         task_log.end_task()
6248 
6249     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
6250     def _poll_bandwidth_usage(self, context):
6251 
6252         if not self._bw_usage_supported:
6253             return
6254 
6255         prev_time, start_time = utils.last_completed_audit_period()
6256 
6257         curr_time = time.time()
6258         if (curr_time - self._last_bw_usage_poll >
6259                 CONF.bandwidth_poll_interval):
6260             self._last_bw_usage_poll = curr_time
6261             LOG.info("Updating bandwidth usage cache")
6262             cells_update_interval = CONF.cells.bandwidth_update_interval
6263             if (cells_update_interval > 0 and
6264                    curr_time - self._last_bw_usage_cell_update >
6265                            cells_update_interval):
6266                 self._last_bw_usage_cell_update = curr_time
6267                 update_cells = True
6268             else:
6269                 update_cells = False
6270 
6271             instances = objects.InstanceList.get_by_host(context,
6272                                                               self.host,
6273                                                               use_slave=True)
6274             try:
6275                 bw_counters = self.driver.get_all_bw_counters(instances)
6276             except NotImplementedError:
6277                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
6278                 # implemented yet.  If they don't it doesn't break anything,
6279                 # they just don't get the info in the usage events.
6280                 # NOTE(PhilDay): Record that its not supported so we can
6281                 # skip fast on future calls rather than waste effort getting
6282                 # the list of instances.
6283                 LOG.info("Bandwidth usage not supported by hypervisor.")
6284                 self._bw_usage_supported = False
6285                 return
6286 
6287             refreshed = timeutils.utcnow()
6288             for bw_ctr in bw_counters:
6289                 # Allow switching of greenthreads between queries.
6290                 greenthread.sleep(0)
6291                 bw_in = 0
6292                 bw_out = 0
6293                 last_ctr_in = None
6294                 last_ctr_out = None
6295                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6296                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6297                     start_period=start_time, use_slave=True)
6298                 if usage:
6299                     bw_in = usage.bw_in
6300                     bw_out = usage.bw_out
6301                     last_ctr_in = usage.last_ctr_in
6302                     last_ctr_out = usage.last_ctr_out
6303                 else:
6304                     usage = (objects.BandwidthUsage.
6305                              get_by_instance_uuid_and_mac(
6306                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6307                         start_period=prev_time, use_slave=True))
6308                     if usage:
6309                         last_ctr_in = usage.last_ctr_in
6310                         last_ctr_out = usage.last_ctr_out
6311 
6312                 if last_ctr_in is not None:
6313                     if bw_ctr['bw_in'] < last_ctr_in:
6314                         # counter rollover
6315                         bw_in += bw_ctr['bw_in']
6316                     else:
6317                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6318 
6319                 if last_ctr_out is not None:
6320                     if bw_ctr['bw_out'] < last_ctr_out:
6321                         # counter rollover
6322                         bw_out += bw_ctr['bw_out']
6323                     else:
6324                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6325 
6326                 objects.BandwidthUsage(context=context).create(
6327                                               bw_ctr['uuid'],
6328                                               bw_ctr['mac_address'],
6329                                               bw_in,
6330                                               bw_out,
6331                                               bw_ctr['bw_in'],
6332                                               bw_ctr['bw_out'],
6333                                               start_period=start_time,
6334                                               last_refreshed=refreshed,
6335                                               update_cells=update_cells)
6336 
6337     def _get_host_volume_bdms(self, context, use_slave=False):
6338         """Return all block device mappings on a compute host."""
6339         compute_host_bdms = []
6340         instances = objects.InstanceList.get_by_host(context, self.host,
6341             use_slave=use_slave)
6342         for instance in instances:
6343             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6344                     context, instance.uuid, use_slave=use_slave)
6345             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6346             compute_host_bdms.append(dict(instance=instance,
6347                                           instance_bdms=instance_bdms))
6348 
6349         return compute_host_bdms
6350 
6351     def _update_volume_usage_cache(self, context, vol_usages):
6352         """Updates the volume usage cache table with a list of stats."""
6353         for usage in vol_usages:
6354             # Allow switching of greenthreads between queries.
6355             greenthread.sleep(0)
6356             vol_usage = objects.VolumeUsage(context)
6357             vol_usage.volume_id = usage['volume']
6358             vol_usage.instance_uuid = usage['instance'].uuid
6359             vol_usage.project_id = usage['instance'].project_id
6360             vol_usage.user_id = usage['instance'].user_id
6361             vol_usage.availability_zone = usage['instance'].availability_zone
6362             vol_usage.curr_reads = usage['rd_req']
6363             vol_usage.curr_read_bytes = usage['rd_bytes']
6364             vol_usage.curr_writes = usage['wr_req']
6365             vol_usage.curr_write_bytes = usage['wr_bytes']
6366             vol_usage.save()
6367             self.notifier.info(context, 'volume.usage',
6368                                compute_utils.usage_volume_info(vol_usage))
6369 
6370     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
6371     def _poll_volume_usage(self, context):
6372         if CONF.volume_usage_poll_interval == 0:
6373             return
6374 
6375         compute_host_bdms = self._get_host_volume_bdms(context,
6376                                                        use_slave=True)
6377         if not compute_host_bdms:
6378             return
6379 
6380         LOG.debug("Updating volume usage cache")
6381         try:
6382             vol_usages = self.driver.get_all_volume_usage(context,
6383                                                           compute_host_bdms)
6384         except NotImplementedError:
6385             return
6386 
6387         self._update_volume_usage_cache(context, vol_usages)
6388 
6389     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
6390                                  run_immediately=True)
6391     def _sync_power_states(self, context):
6392         """Align power states between the database and the hypervisor.
6393 
6394         To sync power state data we make a DB call to get the number of
6395         virtual machines known by the hypervisor and if the number matches the
6396         number of virtual machines known by the database, we proceed in a lazy
6397         loop, one database record at a time, checking if the hypervisor has the
6398         same power state as is in the database.
6399         """
6400         db_instances = objects.InstanceList.get_by_host(context, self.host,
6401                                                         expected_attrs=[],
6402                                                         use_slave=True)
6403 
6404         num_vm_instances = self.driver.get_num_instances()
6405         num_db_instances = len(db_instances)
6406 
6407         if num_vm_instances != num_db_instances:
6408             LOG.warning("While synchronizing instance power states, found "
6409                         "%(num_db_instances)s instances in the database "
6410                         "and %(num_vm_instances)s instances on the "
6411                         "hypervisor.",
6412                         {'num_db_instances': num_db_instances,
6413                          'num_vm_instances': num_vm_instances})
6414 
6415         def _sync(db_instance):
6416             # NOTE(melwitt): This must be synchronized as we query state from
6417             #                two separate sources, the driver and the database.
6418             #                They are set (in stop_instance) and read, in sync.
6419             @utils.synchronized(db_instance.uuid)
6420             def query_driver_power_state_and_sync():
6421                 self._query_driver_power_state_and_sync(context, db_instance)
6422 
6423             try:
6424                 query_driver_power_state_and_sync()
6425             except Exception:
6426                 LOG.exception("Periodic sync_power_state task had an "
6427                               "error while processing an instance.",
6428                               instance=db_instance)
6429 
6430             self._syncs_in_progress.pop(db_instance.uuid)
6431 
6432         for db_instance in db_instances:
6433             # process syncs asynchronously - don't want instance locking to
6434             # block entire periodic task thread
6435             uuid = db_instance.uuid
6436             if uuid in self._syncs_in_progress:
6437                 LOG.debug('Sync already in progress for %s', uuid)
6438             else:
6439                 LOG.debug('Triggering sync for uuid %s', uuid)
6440                 self._syncs_in_progress[uuid] = True
6441                 self._sync_power_pool.spawn_n(_sync, db_instance)
6442 
6443     def _query_driver_power_state_and_sync(self, context, db_instance):
6444         if db_instance.task_state is not None:
6445             LOG.info("During sync_power_state the instance has a "
6446                      "pending task (%(task)s). Skip.",
6447                      {'task': db_instance.task_state}, instance=db_instance)
6448             return
6449         # No pending tasks. Now try to figure out the real vm_power_state.
6450         try:
6451             vm_instance = self.driver.get_info(db_instance)
6452             vm_power_state = vm_instance.state
6453         except exception.InstanceNotFound:
6454             vm_power_state = power_state.NOSTATE
6455         # Note(maoy): the above get_info call might take a long time,
6456         # for example, because of a broken libvirt driver.
6457         try:
6458             self._sync_instance_power_state(context,
6459                                             db_instance,
6460                                             vm_power_state,
6461                                             use_slave=True)
6462         except exception.InstanceNotFound:
6463             # NOTE(hanlind): If the instance gets deleted during sync,
6464             # silently ignore.
6465             pass
6466 
6467     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
6468                                    use_slave=False):
6469         """Align instance power state between the database and hypervisor.
6470 
6471         If the instance is not found on the hypervisor, but is in the database,
6472         then a stop() API will be called on the instance.
6473         """
6474 
6475         # We re-query the DB to get the latest instance info to minimize
6476         # (not eliminate) race condition.
6477         db_instance.refresh(use_slave=use_slave)
6478         db_power_state = db_instance.power_state
6479         vm_state = db_instance.vm_state
6480 
6481         if self.host != db_instance.host:
6482             # on the sending end of nova-compute _sync_power_state
6483             # may have yielded to the greenthread performing a live
6484             # migration; this in turn has changed the resident-host
6485             # for the VM; However, the instance is still active, it
6486             # is just in the process of migrating to another host.
6487             # This implies that the compute source must relinquish
6488             # control to the compute destination.
6489             LOG.info("During the sync_power process the "
6490                      "instance has moved from "
6491                      "host %(src)s to host %(dst)s",
6492                      {'src': db_instance.host,
6493                       'dst': self.host},
6494                      instance=db_instance)
6495             return
6496         elif db_instance.task_state is not None:
6497             # on the receiving end of nova-compute, it could happen
6498             # that the DB instance already report the new resident
6499             # but the actual VM has not showed up on the hypervisor
6500             # yet. In this case, let's allow the loop to continue
6501             # and run the state sync in a later round
6502             LOG.info("During sync_power_state the instance has a "
6503                      "pending task (%(task)s). Skip.",
6504                      {'task': db_instance.task_state},
6505                      instance=db_instance)
6506             return
6507 
6508         orig_db_power_state = db_power_state
6509         if vm_power_state != db_power_state:
6510             LOG.info('During _sync_instance_power_state the DB '
6511                      'power_state (%(db_power_state)s) does not match '
6512                      'the vm_power_state from the hypervisor '
6513                      '(%(vm_power_state)s). Updating power_state in the '
6514                      'DB to match the hypervisor.',
6515                      {'db_power_state': db_power_state,
6516                       'vm_power_state': vm_power_state},
6517                      instance=db_instance)
6518             # power_state is always updated from hypervisor to db
6519             db_instance.power_state = vm_power_state
6520             db_instance.save()
6521             db_power_state = vm_power_state
6522 
6523         # Note(maoy): Now resolve the discrepancy between vm_state and
6524         # vm_power_state. We go through all possible vm_states.
6525         if vm_state in (vm_states.BUILDING,
6526                         vm_states.RESCUED,
6527                         vm_states.RESIZED,
6528                         vm_states.SUSPENDED,
6529                         vm_states.ERROR):
6530             # TODO(maoy): we ignore these vm_state for now.
6531             pass
6532         elif vm_state == vm_states.ACTIVE:
6533             # The only rational power state should be RUNNING
6534             if vm_power_state in (power_state.SHUTDOWN,
6535                                   power_state.CRASHED):
6536                 LOG.warning("Instance shutdown by itself. Calling the "
6537                             "stop API. Current vm_state: %(vm_state)s, "
6538                             "current task_state: %(task_state)s, "
6539                             "original DB power_state: %(db_power_state)s, "
6540                             "current VM power_state: %(vm_power_state)s",
6541                             {'vm_state': vm_state,
6542                              'task_state': db_instance.task_state,
6543                              'db_power_state': orig_db_power_state,
6544                              'vm_power_state': vm_power_state},
6545                             instance=db_instance)
6546                 try:
6547                     # Note(maoy): here we call the API instead of
6548                     # brutally updating the vm_state in the database
6549                     # to allow all the hooks and checks to be performed.
6550                     if db_instance.shutdown_terminate:
6551                         self.compute_api.delete(context, db_instance)
6552                     else:
6553                         self.compute_api.stop(context, db_instance)
6554                 except Exception:
6555                     # Note(maoy): there is no need to propagate the error
6556                     # because the same power_state will be retrieved next
6557                     # time and retried.
6558                     # For example, there might be another task scheduled.
6559                     LOG.exception("error during stop() in sync_power_state.",
6560                                   instance=db_instance)
6561             elif vm_power_state == power_state.SUSPENDED:
6562                 LOG.warning("Instance is suspended unexpectedly. Calling "
6563                             "the stop API.", instance=db_instance)
6564                 try:
6565                     self.compute_api.stop(context, db_instance)
6566                 except Exception:
6567                     LOG.exception("error during stop() in sync_power_state.",
6568                                   instance=db_instance)
6569             elif vm_power_state == power_state.PAUSED:
6570                 # Note(maoy): a VM may get into the paused state not only
6571                 # because the user request via API calls, but also
6572                 # due to (temporary) external instrumentations.
6573                 # Before the virt layer can reliably report the reason,
6574                 # we simply ignore the state discrepancy. In many cases,
6575                 # the VM state will go back to running after the external
6576                 # instrumentation is done. See bug 1097806 for details.
6577                 LOG.warning("Instance is paused unexpectedly. Ignore.",
6578                             instance=db_instance)
6579             elif vm_power_state == power_state.NOSTATE:
6580                 # Occasionally, depending on the status of the hypervisor,
6581                 # which could be restarting for example, an instance may
6582                 # not be found.  Therefore just log the condition.
6583                 LOG.warning("Instance is unexpectedly not found. Ignore.",
6584                             instance=db_instance)
6585         elif vm_state == vm_states.STOPPED:
6586             if vm_power_state not in (power_state.NOSTATE,
6587                                       power_state.SHUTDOWN,
6588                                       power_state.CRASHED):
6589                 LOG.warning("Instance is not stopped. Calling "
6590                             "the stop API. Current vm_state: %(vm_state)s,"
6591                             " current task_state: %(task_state)s, "
6592                             "original DB power_state: %(db_power_state)s, "
6593                             "current VM power_state: %(vm_power_state)s",
6594                             {'vm_state': vm_state,
6595                              'task_state': db_instance.task_state,
6596                              'db_power_state': orig_db_power_state,
6597                              'vm_power_state': vm_power_state},
6598                             instance=db_instance)
6599                 try:
6600                     # NOTE(russellb) Force the stop, because normally the
6601                     # compute API would not allow an attempt to stop a stopped
6602                     # instance.
6603                     self.compute_api.force_stop(context, db_instance)
6604                 except Exception:
6605                     LOG.exception("error during stop() in sync_power_state.",
6606                                   instance=db_instance)
6607         elif vm_state == vm_states.PAUSED:
6608             if vm_power_state in (power_state.SHUTDOWN,
6609                                   power_state.CRASHED):
6610                 LOG.warning("Paused instance shutdown by itself. Calling "
6611                             "the stop API.", instance=db_instance)
6612                 try:
6613                     self.compute_api.force_stop(context, db_instance)
6614                 except Exception:
6615                     LOG.exception("error during stop() in sync_power_state.",
6616                                   instance=db_instance)
6617         elif vm_state in (vm_states.SOFT_DELETED,
6618                           vm_states.DELETED):
6619             if vm_power_state not in (power_state.NOSTATE,
6620                                       power_state.SHUTDOWN):
6621                 # Note(maoy): this should be taken care of periodically in
6622                 # _cleanup_running_deleted_instances().
6623                 LOG.warning("Instance is not (soft-)deleted.",
6624                             instance=db_instance)
6625 
6626     @periodic_task.periodic_task
6627     def _reclaim_queued_deletes(self, context):
6628         """Reclaim instances that are queued for deletion."""
6629         interval = CONF.reclaim_instance_interval
6630         if interval <= 0:
6631             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
6632             return
6633 
6634         filters = {'vm_state': vm_states.SOFT_DELETED,
6635                    'task_state': None,
6636                    'host': self.host}
6637         instances = objects.InstanceList.get_by_filters(
6638             context, filters,
6639             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
6640             use_slave=True)
6641         for instance in instances:
6642             if self._deleted_old_enough(instance, interval):
6643                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6644                         context, instance.uuid)
6645                 LOG.info('Reclaiming deleted instance', instance=instance)
6646                 try:
6647                     self._delete_instance(context, instance, bdms)
6648                 except Exception as e:
6649                     LOG.warning("Periodic reclaim failed to delete "
6650                                 "instance: %s",
6651                                 e, instance=instance)
6652 
6653     def update_available_resource_for_node(self, context, nodename):
6654 
6655         rt = self._get_resource_tracker()
6656         try:
6657             rt.update_available_resource(context, nodename)
6658         except exception.ComputeHostNotFound:
6659             # NOTE(comstud): We can get to this case if a node was
6660             # marked 'deleted' in the DB and then re-added with a
6661             # different auto-increment id. The cached resource
6662             # tracker tried to update a deleted record and failed.
6663             # Don't add this resource tracker to the new dict, so
6664             # that this will resolve itself on the next run.
6665             LOG.info("Compute node '%s' not found in "
6666                      "update_available_resource.", nodename)
6667             # TODO(jaypipes): Yes, this is inefficient to throw away all of the
6668             # compute nodes to force a rebuild, but this is only temporary
6669             # until Ironic baremetal node resource providers are tracked
6670             # properly in the report client and this is a tiny edge case
6671             # anyway.
6672             self._resource_tracker = None
6673             return
6674         except Exception:
6675             LOG.exception("Error updating resources for node %(node)s.",
6676                           {'node': nodename})
6677 
6678     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
6679     def update_available_resource(self, context, startup=False):
6680         """See driver.get_available_resource()
6681 
6682         Periodic process that keeps that the compute host's understanding of
6683         resource availability and usage in sync with the underlying hypervisor.
6684 
6685         :param context: security context
6686         :param startup: True if this is being called when the nova-compute
6687             service is starting, False otherwise.
6688         """
6689 
6690         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
6691                                                             use_slave=True,
6692                                                             startup=startup)
6693         nodenames = set(self.driver.get_available_nodes())
6694         for nodename in nodenames:
6695             self.update_available_resource_for_node(context, nodename)
6696 
6697         # Delete orphan compute node not reported by driver but still in db
6698         for cn in compute_nodes_in_db:
6699             if cn.hypervisor_hostname not in nodenames:
6700                 LOG.info("Deleting orphan compute node %(id)s "
6701                          "hypervisor host is %(hh)s, "
6702                          "nodes are %(nodes)s",
6703                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
6704                           'nodes': nodenames})
6705                 cn.destroy()
6706                 # Delete the corresponding resource provider in placement,
6707                 # along with any associated allocations and inventory.
6708                 # TODO(cdent): Move use of reportclient into resource tracker.
6709                 self.scheduler_client.reportclient.delete_resource_provider(
6710                     context, cn, cascade=True)
6711 
6712     def _get_compute_nodes_in_db(self, context, use_slave=False,
6713                                  startup=False):
6714         try:
6715             return objects.ComputeNodeList.get_all_by_host(context, self.host,
6716                                                            use_slave=use_slave)
6717         except exception.NotFound:
6718             if startup:
6719                 LOG.warning(
6720                     "No compute node record found for host %s. If this is "
6721                     "the first time this service is starting on this "
6722                     "host, then you can ignore this warning.", self.host)
6723             else:
6724                 LOG.error("No compute node record for host %s", self.host)
6725             return []
6726 
6727     @periodic_task.periodic_task(
6728         spacing=CONF.running_deleted_instance_poll_interval)
6729     def _cleanup_running_deleted_instances(self, context):
6730         """Cleanup any instances which are erroneously still running after
6731         having been deleted.
6732 
6733         Valid actions to take are:
6734 
6735             1. noop - do nothing
6736             2. log - log which instances are erroneously running
6737             3. reap - shutdown and cleanup any erroneously running instances
6738             4. shutdown - power off *and disable* any erroneously running
6739                           instances
6740 
6741         The use-case for this cleanup task is: for various reasons, it may be
6742         possible for the database to show an instance as deleted but for that
6743         instance to still be running on a host machine (see bug
6744         https://bugs.launchpad.net/nova/+bug/911366).
6745 
6746         This cleanup task is a cross-hypervisor utility for finding these
6747         zombied instances and either logging the discrepancy (likely what you
6748         should do in production), or automatically reaping the instances (more
6749         appropriate for dev environments).
6750         """
6751         action = CONF.running_deleted_instance_action
6752 
6753         if action == "noop":
6754             return
6755 
6756         # NOTE(sirp): admin contexts don't ordinarily return deleted records
6757         with utils.temporary_mutation(context, read_deleted="yes"):
6758             for instance in self._running_deleted_instances(context):
6759                 if action == "log":
6760                     LOG.warning("Detected instance with name label "
6761                                 "'%s' which is marked as "
6762                                 "DELETED but still present on host.",
6763                                 instance.name, instance=instance)
6764 
6765                 elif action == 'shutdown':
6766                     LOG.info("Powering off instance with name label "
6767                              "'%s' which is marked as "
6768                              "DELETED but still present on host.",
6769                              instance.name, instance=instance)
6770                     try:
6771                         try:
6772                             # disable starting the instance
6773                             self.driver.set_bootable(instance, False)
6774                         except NotImplementedError:
6775                             LOG.debug("set_bootable is not implemented "
6776                                       "for the current driver")
6777                         # and power it off
6778                         self.driver.power_off(instance)
6779                     except Exception:
6780                         LOG.warning("Failed to power off instance",
6781                                     instance=instance, exc_info=True)
6782 
6783                 elif action == 'reap':
6784                     LOG.info("Destroying instance with name label "
6785                              "'%s' which is marked as "
6786                              "DELETED but still present on host.",
6787                              instance.name, instance=instance)
6788                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6789                         context, instance.uuid, use_slave=True)
6790                     self.instance_events.clear_events_for_instance(instance)
6791                     try:
6792                         self._shutdown_instance(context, instance, bdms,
6793                                                 notify=False)
6794                         self._cleanup_volumes(context, instance.uuid, bdms)
6795                     except Exception as e:
6796                         LOG.warning("Periodic cleanup failed to delete "
6797                                     "instance: %s",
6798                                     e, instance=instance)
6799                 else:
6800                     raise Exception(_("Unrecognized value '%s'"
6801                                       " for CONF.running_deleted_"
6802                                       "instance_action") % action)
6803 
6804     def _running_deleted_instances(self, context):
6805         """Returns a list of instances nova thinks is deleted,
6806         but the hypervisor thinks is still running.
6807         """
6808         timeout = CONF.running_deleted_instance_timeout
6809         filters = {'deleted': True,
6810                    'soft_deleted': False}
6811         instances = self._get_instances_on_driver(context, filters)
6812         return [i for i in instances if self._deleted_old_enough(i, timeout)]
6813 
6814     def _deleted_old_enough(self, instance, timeout):
6815         deleted_at = instance.deleted_at
6816         if deleted_at:
6817             deleted_at = deleted_at.replace(tzinfo=None)
6818         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
6819 
6820     @contextlib.contextmanager
6821     def _error_out_instance_on_exception(self, context, instance,
6822                                          instance_state=vm_states.ACTIVE):
6823         instance_uuid = instance.uuid
6824         try:
6825             yield
6826         except NotImplementedError as error:
6827             with excutils.save_and_reraise_exception():
6828                 LOG.info("Setting instance back to %(state)s after: "
6829                          "%(error)s",
6830                          {'state': instance_state, 'error': error},
6831                          instance_uuid=instance_uuid)
6832                 self._instance_update(context, instance,
6833                                       vm_state=instance_state,
6834                                       task_state=None)
6835         except exception.InstanceFaultRollback as error:
6836             LOG.info("Setting instance back to ACTIVE after: %s",
6837                      error, instance_uuid=instance_uuid)
6838             self._instance_update(context, instance,
6839                                   vm_state=vm_states.ACTIVE,
6840                                   task_state=None)
6841             raise error.inner_exception
6842         except Exception:
6843             LOG.exception('Setting instance vm_state to ERROR',
6844                           instance_uuid=instance_uuid)
6845             with excutils.save_and_reraise_exception():
6846                 self._set_instance_obj_error_state(context, instance)
6847 
6848     @wrap_exception()
6849     def add_aggregate_host(self, context, aggregate, host, slave_info):
6850         """Notify hypervisor of change (for hypervisor pools)."""
6851         try:
6852             self.driver.add_to_aggregate(context, aggregate, host,
6853                                          slave_info=slave_info)
6854         except NotImplementedError:
6855             LOG.debug('Hypervisor driver does not support '
6856                       'add_aggregate_host')
6857         except exception.AggregateError:
6858             with excutils.save_and_reraise_exception():
6859                 self.driver.undo_aggregate_operation(
6860                                     context,
6861                                     aggregate.delete_host,
6862                                     aggregate, host)
6863 
6864     @wrap_exception()
6865     def remove_aggregate_host(self, context, host, slave_info, aggregate):
6866         """Removes a host from a physical hypervisor pool."""
6867         try:
6868             self.driver.remove_from_aggregate(context, aggregate, host,
6869                                               slave_info=slave_info)
6870         except NotImplementedError:
6871             LOG.debug('Hypervisor driver does not support '
6872                       'remove_aggregate_host')
6873         except (exception.AggregateError,
6874                 exception.InvalidAggregateAction) as e:
6875             with excutils.save_and_reraise_exception():
6876                 self.driver.undo_aggregate_operation(
6877                                     context,
6878                                     aggregate.add_host,
6879                                     aggregate, host,
6880                                     isinstance(e, exception.AggregateError))
6881 
6882     def _process_instance_event(self, instance, event):
6883         _event = self.instance_events.pop_instance_event(instance, event)
6884         if _event:
6885             LOG.debug('Processing event %(event)s',
6886                       {'event': event.key}, instance=instance)
6887             _event.send(event)
6888         else:
6889             # If it's a network-vif-unplugged event and the instance is being
6890             # deleted then we don't need to make this a warning as it's
6891             # expected. There are other things which could trigger this like
6892             # detaching an interface, but we don't have a task state for that.
6893             if (event.name == 'network-vif-unplugged' and
6894                     instance.task_state == task_states.DELETING):
6895                 LOG.debug('Received event %s for instance which is being '
6896                           'deleted.', event.key, instance=instance)
6897             else:
6898                 LOG.warning('Received unexpected event %(event)s for '
6899                             'instance with vm_state %(vm_state)s and '
6900                             'task_state %(task_state)s.',
6901                             {'event': event.key,
6902                              'vm_state': instance.vm_state,
6903                              'task_state': instance.task_state},
6904                             instance=instance)
6905 
6906     def _process_instance_vif_deleted_event(self, context, instance,
6907                                             deleted_vif_id):
6908         # If an attached port is deleted by neutron, it needs to
6909         # be detached from the instance.
6910         # And info cache needs to be updated.
6911         network_info = instance.info_cache.network_info
6912         for index, vif in enumerate(network_info):
6913             if vif['id'] == deleted_vif_id:
6914                 LOG.info('Neutron deleted interface %(intf)s; '
6915                          'detaching it from the instance and '
6916                          'deleting it from the info cache',
6917                          {'intf': vif['id']},
6918                          instance=instance)
6919                 del network_info[index]
6920                 base_net_api.update_instance_cache_with_nw_info(
6921                                  self.network_api, context,
6922                                  instance,
6923                                  nw_info=network_info)
6924                 try:
6925                     self.driver.detach_interface(context, instance, vif)
6926                 except NotImplementedError:
6927                     # Not all virt drivers support attach/detach of interfaces
6928                     # yet (like Ironic), so just ignore this.
6929                     pass
6930                 except exception.NovaException as ex:
6931                     LOG.warning("Detach interface failed, "
6932                                 "port_id=%(port_id)s, reason: %(msg)s",
6933                                 {'port_id': deleted_vif_id, 'msg': ex},
6934                                 instance=instance)
6935                 break
6936 
6937     @wrap_instance_event(prefix='compute')
6938     @wrap_instance_fault
6939     def extend_volume(self, context, instance, extended_volume_id):
6940 
6941         # If an attached volume is extended by cinder, it needs to
6942         # be extended by virt driver so host can detect its new size.
6943         # And bdm needs to be updated.
6944         LOG.debug('Handling volume-extended event for volume %(vol)s',
6945                   {'vol': extended_volume_id}, instance=instance)
6946 
6947         try:
6948             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
6949                    context, extended_volume_id, instance.uuid)
6950         except exception.NotFound:
6951             LOG.warning('Extend volume failed, '
6952                         'volume %(vol)s is not attached to instance.',
6953                         {'vol': extended_volume_id},
6954                         instance=instance)
6955             return
6956 
6957         LOG.info('Cinder extended volume %(vol)s; '
6958                  'extending it to detect new size',
6959                  {'vol': extended_volume_id},
6960                  instance=instance)
6961         volume = self.volume_api.get(context, bdm.volume_id)
6962 
6963         if bdm.connection_info is None:
6964             LOG.warning('Extend volume failed, '
6965                         'attached volume %(vol)s has no connection_info',
6966                         {'vol': extended_volume_id},
6967                         instance=instance)
6968             return
6969 
6970         connection_info = jsonutils.loads(bdm.connection_info)
6971         bdm.volume_size = volume['size']
6972         bdm.save()
6973 
6974         if not self.driver.capabilities.get('supports_extend_volume', False):
6975             raise exception.ExtendVolumeNotSupported()
6976 
6977         try:
6978             self.driver.extend_volume(connection_info,
6979                                       instance)
6980         except Exception as ex:
6981             LOG.warning('Extend volume failed, '
6982                         'volume_id=%(volume_id)s, reason: %(msg)s',
6983                         {'volume_id': extended_volume_id, 'msg': ex},
6984                         instance=instance)
6985             raise
6986 
6987     @wrap_exception()
6988     def external_instance_event(self, context, instances, events):
6989         # NOTE(danms): Some event types are handled by the manager, such
6990         # as when we're asked to update the instance's info_cache. If it's
6991         # not one of those, look for some thread(s) waiting for the event and
6992         # unblock them if so.
6993         for event in events:
6994             instance = [inst for inst in instances
6995                         if inst.uuid == event.instance_uuid][0]
6996             LOG.debug('Received event %(event)s',
6997                       {'event': event.key},
6998                       instance=instance)
6999             if event.name == 'network-changed':
7000                 try:
7001                     self.network_api.get_instance_nw_info(context, instance)
7002                 except exception.NotFound as e:
7003                     LOG.info('Failed to process external instance event '
7004                              '%(event)s due to: %(error)s',
7005                              {'event': event.key, 'error': six.text_type(e)},
7006                              instance=instance)
7007             elif event.name == 'network-vif-deleted':
7008                 try:
7009                     self._process_instance_vif_deleted_event(context,
7010                                                              instance,
7011                                                              event.tag)
7012                 except exception.NotFound as e:
7013                     LOG.info('Failed to process external instance event '
7014                              '%(event)s due to: %(error)s',
7015                              {'event': event.key, 'error': six.text_type(e)},
7016                              instance=instance)
7017             elif event.name == 'volume-extended':
7018                 self.extend_volume(context, instance, event.tag)
7019             else:
7020                 self._process_instance_event(instance, event)
7021 
7022     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
7023                                  external_process_ok=True)
7024     def _run_image_cache_manager_pass(self, context):
7025         """Run a single pass of the image cache manager."""
7026 
7027         if not self.driver.capabilities["has_imagecache"]:
7028             return
7029 
7030         # Determine what other nodes use this storage
7031         storage_users.register_storage_use(CONF.instances_path, CONF.host)
7032         nodes = storage_users.get_storage_users(CONF.instances_path)
7033 
7034         # Filter all_instances to only include those nodes which share this
7035         # storage path.
7036         # TODO(mikal): this should be further refactored so that the cache
7037         # cleanup code doesn't know what those instances are, just a remote
7038         # count, and then this logic should be pushed up the stack.
7039         filters = {'deleted': False,
7040                    'soft_deleted': True,
7041                    'host': nodes}
7042         filtered_instances = objects.InstanceList.get_by_filters(context,
7043                                  filters, expected_attrs=[], use_slave=True)
7044 
7045         self.driver.manage_image_cache(context, filtered_instances)
7046 
7047     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7048     def _run_pending_deletes(self, context):
7049         """Retry any pending instance file deletes."""
7050         LOG.debug('Cleaning up deleted instances')
7051         filters = {'deleted': True,
7052                    'soft_deleted': False,
7053                    'host': CONF.host,
7054                    'cleaned': False}
7055         attrs = ['system_metadata']
7056         with utils.temporary_mutation(context, read_deleted='yes'):
7057             instances = objects.InstanceList.get_by_filters(
7058                 context, filters, expected_attrs=attrs, use_slave=True)
7059         LOG.debug('There are %d instances to clean', len(instances))
7060 
7061         # TODO(raj_singh): Remove this if condition when min value is
7062         # introduced to "maximum_instance_delete_attempts" cfg option.
7063         if CONF.maximum_instance_delete_attempts < 1:
7064             LOG.warning('Future versions of Nova will restrict the '
7065                         '"maximum_instance_delete_attempts" config option '
7066                         'to values >=1. Update your configuration file to '
7067                         'mitigate future upgrade issues.')
7068 
7069         for instance in instances:
7070             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
7071             LOG.debug('Instance has had %(attempts)s of %(max)s '
7072                       'cleanup attempts',
7073                       {'attempts': attempts,
7074                        'max': CONF.maximum_instance_delete_attempts},
7075                       instance=instance)
7076             if attempts < CONF.maximum_instance_delete_attempts:
7077                 success = self.driver.delete_instance_files(instance)
7078 
7079                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
7080                 if success:
7081                     instance.cleaned = True
7082                 with utils.temporary_mutation(context, read_deleted='yes'):
7083                     instance.save()
7084 
7085     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7086     def _cleanup_incomplete_migrations(self, context):
7087         """Delete instance files on failed resize/revert-resize operation
7088 
7089         During resize/revert-resize operation, if that instance gets deleted
7090         in-between then instance files might remain either on source or
7091         destination compute node because of race condition.
7092         """
7093         LOG.debug('Cleaning up deleted instances with incomplete migration ')
7094         migration_filters = {'host': CONF.host,
7095                              'status': 'error'}
7096         migrations = objects.MigrationList.get_by_filters(context,
7097                                                           migration_filters)
7098 
7099         if not migrations:
7100             return
7101 
7102         inst_uuid_from_migrations = set([migration.instance_uuid for migration
7103                                          in migrations])
7104 
7105         inst_filters = {'deleted': True, 'soft_deleted': False,
7106                         'uuid': inst_uuid_from_migrations}
7107         attrs = ['info_cache', 'security_groups', 'system_metadata']
7108         with utils.temporary_mutation(context, read_deleted='yes'):
7109             instances = objects.InstanceList.get_by_filters(
7110                 context, inst_filters, expected_attrs=attrs, use_slave=True)
7111 
7112         for instance in instances:
7113             if instance.host != CONF.host:
7114                 for migration in migrations:
7115                     if instance.uuid == migration.instance_uuid:
7116                         # Delete instance files if not cleanup properly either
7117                         # from the source or destination compute nodes when
7118                         # the instance is deleted during resizing.
7119                         self.driver.delete_instance_files(instance)
7120                         try:
7121                             migration.status = 'failed'
7122                             with migration.obj_as_admin():
7123                                 migration.save()
7124                         except exception.MigrationNotFound:
7125                             LOG.warning("Migration %s is not found.",
7126                                         migration.id,
7127                                         instance=instance)
7128                         break
7129 
7130     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7131                                    exception.QemuGuestAgentNotEnabled,
7132                                    exception.NovaException,
7133                                    NotImplementedError)
7134     @wrap_exception()
7135     def quiesce_instance(self, context, instance):
7136         """Quiesce an instance on this host."""
7137         context = context.elevated()
7138         image_meta = objects.ImageMeta.from_instance(instance)
7139         self.driver.quiesce(context, instance, image_meta)
7140 
7141     def _wait_for_snapshots_completion(self, context, mapping):
7142         for mapping_dict in mapping:
7143             if mapping_dict.get('source_type') == 'snapshot':
7144 
7145                 def _wait_snapshot():
7146                     snapshot = self.volume_api.get_snapshot(
7147                         context, mapping_dict['snapshot_id'])
7148                     if snapshot.get('status') != 'creating':
7149                         raise loopingcall.LoopingCallDone()
7150 
7151                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
7152                 timer.start(interval=0.5).wait()
7153 
7154     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7155                                    exception.QemuGuestAgentNotEnabled,
7156                                    exception.NovaException,
7157                                    NotImplementedError)
7158     @wrap_exception()
7159     def unquiesce_instance(self, context, instance, mapping=None):
7160         """Unquiesce an instance on this host.
7161 
7162         If snapshots' image mapping is provided, it waits until snapshots are
7163         completed before unqueiscing.
7164         """
7165         context = context.elevated()
7166         if mapping:
7167             try:
7168                 self._wait_for_snapshots_completion(context, mapping)
7169             except Exception as error:
7170                 LOG.exception("Exception while waiting completion of "
7171                               "volume snapshots: %s",
7172                               error, instance=instance)
7173         image_meta = objects.ImageMeta.from_instance(instance)
7174         self.driver.unquiesce(context, instance, image_meta)
