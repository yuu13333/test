Please review the code below to detect security defects. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are found, please state '''No security defects are detected in the code'''.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import contextlib
30 import functools
31 import inspect
32 import sys
33 import time
34 import traceback
35 import uuid
36 
37 from cinderclient import exceptions as cinder_exception
38 import eventlet.event
39 from eventlet import greenthread
40 import eventlet.semaphore
41 import eventlet.timeout
42 from keystoneauth1 import exceptions as keystone_exception
43 from oslo_log import log as logging
44 import oslo_messaging as messaging
45 from oslo_serialization import jsonutils
46 from oslo_service import loopingcall
47 from oslo_service import periodic_task
48 from oslo_utils import excutils
49 from oslo_utils import strutils
50 from oslo_utils import timeutils
51 import six
52 from six.moves import range
53 
54 from nova import block_device
55 from nova.cells import rpcapi as cells_rpcapi
56 from nova.cloudpipe import pipelib
57 from nova import compute
58 from nova.compute import build_results
59 from nova.compute import claims
60 from nova.compute import power_state
61 from nova.compute import resource_tracker
62 from nova.compute import rpcapi as compute_rpcapi
63 from nova.compute import task_states
64 from nova.compute import utils as compute_utils
65 from nova.compute import vm_states
66 from nova import conductor
67 import nova.conf
68 from nova import consoleauth
69 import nova.context
70 from nova import exception
71 from nova import hooks
72 from nova.i18n import _
73 from nova.i18n import _LE
74 from nova.i18n import _LI
75 from nova.i18n import _LW
76 from nova import image
77 from nova.image import glance
78 from nova import manager
79 from nova import network
80 from nova.network import base_api as base_net_api
81 from nova.network import model as network_model
82 from nova.network.security_group import openstack_driver
83 from nova import objects
84 from nova.objects import base as obj_base
85 from nova.objects import instance as obj_instance
86 from nova.objects import migrate_data as migrate_data_obj
87 from nova import rpc
88 from nova import safe_utils
89 from nova.scheduler import client as scheduler_client
90 from nova import utils
91 from nova.virt import block_device as driver_block_device
92 from nova.virt import configdrive
93 from nova.virt import driver
94 from nova.virt import event as virtevent
95 from nova.virt import storage_users
96 from nova.virt import virtapi
97 from nova import volume
98 from nova.volume import encryptors
99 
100 CONF = nova.conf.CONF
101 CONF.import_opt('host', 'nova.netconf')
102 
103 LOG = logging.getLogger(__name__)
104 
105 get_notifier = functools.partial(rpc.get_notifier, service='compute')
106 wrap_exception = functools.partial(exception.wrap_exception,
107                                    get_notifier=get_notifier)
108 
109 
110 @utils.expects_func_args('migration')
111 def errors_out_migration(function):
112     """Decorator to error out migration on failure."""
113 
114     @functools.wraps(function)
115     def decorated_function(self, context, *args, **kwargs):
116         try:
117             return function(self, context, *args, **kwargs)
118         except Exception as ex:
119             with excutils.save_and_reraise_exception():
120                 wrapped_func = safe_utils.get_wrapped_function(function)
121                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
122                                                  *args, **kwargs)
123                 migration = keyed_args['migration']
124 
125                 # NOTE(rajesht): If InstanceNotFound error is thrown from
126                 # decorated function, migration status should be set to
127                 # 'error', without checking current migration status.
128                 if not isinstance(ex, exception.InstanceNotFound):
129                     status = migration.status
130                     if status not in ['migrating', 'post-migrating']:
131                         return
132 
133                 migration.status = 'error'
134                 try:
135                     with migration.obj_as_admin():
136                         migration.save()
137                 except Exception:
138                     LOG.debug('Error setting migration status '
139                               'for instance %s.',
140                               migration.instance_uuid, exc_info=True)
141 
142     return decorated_function
143 
144 
145 @utils.expects_func_args('instance')
146 def reverts_task_state(function):
147     """Decorator to revert task_state on failure."""
148 
149     @functools.wraps(function)
150     def decorated_function(self, context, *args, **kwargs):
151         try:
152             return function(self, context, *args, **kwargs)
153         except exception.UnexpectedTaskStateError as e:
154             # Note(maoy): unexpected task state means the current
155             # task is preempted. Do not clear task state in this
156             # case.
157             with excutils.save_and_reraise_exception():
158                 LOG.info(_LI("Task possibly preempted: %s"),
159                          e.format_message())
160         except Exception:
161             with excutils.save_and_reraise_exception():
162                 wrapped_func = safe_utils.get_wrapped_function(function)
163                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
164                                                  *args, **kwargs)
165                 # NOTE(mriedem): 'instance' must be in keyed_args because we
166                 # have utils.expects_func_args('instance') decorating this
167                 # method.
168                 instance = keyed_args['instance']
169                 original_task_state = instance.task_state
170                 try:
171                     self._instance_update(context, instance, task_state=None)
172                     LOG.info(_LI("Successfully reverted task state from %s on "
173                                  "failure for instance."), original_task_state,
174                                                            instance=instance)
175                 except exception.InstanceNotFound:
176                     # We might delete an instance that failed to build shortly
177                     # after it errored out this is an expected case and we
178                     # should not trace on it.
179                     pass
180                 except Exception as e:
181                     msg = _LW("Failed to revert task state for instance. "
182                               "Error: %s")
183                     LOG.warning(msg, e, instance=instance)
184 
185     return decorated_function
186 
187 
188 @utils.expects_func_args('instance')
189 def wrap_instance_fault(function):
190     """Wraps a method to catch exceptions related to instances.
191 
192     This decorator wraps a method to catch any exceptions having to do with
193     an instance that may get thrown. It then logs an instance fault in the db.
194     """
195 
196     @functools.wraps(function)
197     def decorated_function(self, context, *args, **kwargs):
198         try:
199             return function(self, context, *args, **kwargs)
200         except exception.InstanceNotFound:
201             raise
202         except Exception as e:
203             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
204             # we will get a KeyError exception which will cover up the real
205             # exception. So, we update kwargs with the values from args first.
206             # then, we can get 'instance' from kwargs easily.
207             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
208 
209             with excutils.save_and_reraise_exception():
210                 compute_utils.add_instance_fault_from_exc(context,
211                         kwargs['instance'], e, sys.exc_info())
212 
213     return decorated_function
214 
215 
216 @utils.expects_func_args('instance')
217 def wrap_instance_event(function):
218     """Wraps a method to log the event taken on the instance, and result.
219 
220     This decorator wraps a method to log the start and result of an event, as
221     part of an action taken on an instance.
222     """
223 
224     @functools.wraps(function)
225     def decorated_function(self, context, *args, **kwargs):
226         wrapped_func = safe_utils.get_wrapped_function(function)
227         keyed_args = inspect.getcallargs(wrapped_func, self, context, *args,
228                                          **kwargs)
229         instance_uuid = keyed_args['instance']['uuid']
230 
231         event_name = 'compute_{0}'.format(function.__name__)
232         with compute_utils.EventReporter(context, event_name, instance_uuid):
233             return function(self, context, *args, **kwargs)
234 
235     return decorated_function
236 
237 
238 @utils.expects_func_args('image_id', 'instance')
239 def delete_image_on_error(function):
240     """Used for snapshot related method to ensure the image created in
241     compute.api is deleted when an error occurs.
242     """
243 
244     @functools.wraps(function)
245     def decorated_function(self, context, image_id, instance,
246                            *args, **kwargs):
247         try:
248             return function(self, context, image_id, instance,
249                             *args, **kwargs)
250         except Exception:
251             with excutils.save_and_reraise_exception():
252                 LOG.debug("Cleaning up image %s", image_id,
253                           exc_info=True, instance=instance)
254                 try:
255                     self.image_api.delete(context, image_id)
256                 except Exception:
257                     LOG.exception(_LE("Error while trying to clean up "
258                                       "image %s"), image_id,
259                                   instance=instance)
260 
261     return decorated_function
262 
263 
264 # TODO(danms): Remove me after Icehouse
265 # NOTE(mikal): if the method being decorated has more than one decorator, then
266 # put this one first. Otherwise the various exception handling decorators do
267 # not function correctly.
268 def object_compat(function):
269     """Wraps a method that expects a new-world instance
270 
271     This provides compatibility for callers passing old-style dict
272     instances.
273     """
274 
275     @functools.wraps(function)
276     def decorated_function(self, context, *args, **kwargs):
277         def _load_instance(instance_or_dict):
278             if isinstance(instance_or_dict, dict):
279                 # try to get metadata and system_metadata for most cases but
280                 # only attempt to load those if the db instance already has
281                 # those fields joined
282                 metas = [meta for meta in ('metadata', 'system_metadata')
283                          if meta in instance_or_dict]
284                 instance = objects.Instance._from_db_object(
285                     context, objects.Instance(), instance_or_dict,
286                     expected_attrs=metas)
287                 instance._context = context
288                 return instance
289             return instance_or_dict
290 
291         try:
292             kwargs['instance'] = _load_instance(kwargs['instance'])
293         except KeyError:
294             args = (_load_instance(args[0]),) + args[1:]
295 
296         migration = kwargs.get('migration')
297         if isinstance(migration, dict):
298             migration = objects.Migration._from_db_object(
299                     context.elevated(), objects.Migration(),
300                     migration)
301             kwargs['migration'] = migration
302 
303         return function(self, context, *args, **kwargs)
304 
305     return decorated_function
306 
307 
308 class InstanceEvents(object):
309     def __init__(self):
310         self._events = {}
311 
312     @staticmethod
313     def _lock_name(instance):
314         return '%s-%s' % (instance.uuid, 'events')
315 
316     def prepare_for_instance_event(self, instance, event_name):
317         """Prepare to receive an event for an instance.
318 
319         This will register an event for the given instance that we will
320         wait on later. This should be called before initiating whatever
321         action will trigger the event. The resulting eventlet.event.Event
322         object should be wait()'d on to ensure completion.
323 
324         :param instance: the instance for which the event will be generated
325         :param event_name: the name of the event we're expecting
326         :returns: an event object that should be wait()'d on
327         """
328         if self._events is None:
329             # NOTE(danms): We really should have a more specific error
330             # here, but this is what we use for our default error case
331             raise exception.NovaException('In shutdown, no new events '
332                                           'can be scheduled')
333 
334         @utils.synchronized(self._lock_name(instance))
335         def _create_or_get_event():
336             instance_events = self._events.setdefault(instance.uuid, {})
337             return instance_events.setdefault(event_name,
338                                               eventlet.event.Event())
339         LOG.debug('Preparing to wait for external event %(event)s',
340                   {'event': event_name}, instance=instance)
341         return _create_or_get_event()
342 
343     def pop_instance_event(self, instance, event):
344         """Remove a pending event from the wait list.
345 
346         This will remove a pending event from the wait list so that it
347         can be used to signal the waiters to wake up.
348 
349         :param instance: the instance for which the event was generated
350         :param event: the nova.objects.external_event.InstanceExternalEvent
351                       that describes the event
352         :returns: the eventlet.event.Event object on which the waiters
353                   are blocked
354         """
355         no_events_sentinel = object()
356         no_matching_event_sentinel = object()
357 
358         @utils.synchronized(self._lock_name(instance))
359         def _pop_event():
360             if not self._events:
361                 LOG.debug('Unexpected attempt to pop events during shutdown',
362                           instance=instance)
363                 return no_events_sentinel
364             events = self._events.get(instance.uuid)
365             if not events:
366                 return no_events_sentinel
367             _event = events.pop(event.key, None)
368             if not events:
369                 del self._events[instance.uuid]
370             if _event is None:
371                 return no_matching_event_sentinel
372             return _event
373 
374         result = _pop_event()
375         if result is no_events_sentinel:
376             LOG.debug('No waiting events found dispatching %(event)s',
377                       {'event': event.key},
378                       instance=instance)
379             return None
380         elif result is no_matching_event_sentinel:
381             LOG.debug('No event matching %(event)s in %(events)s',
382                       {'event': event.key,
383                        'events': self._events.get(instance.uuid, {}).keys()},
384                       instance=instance)
385             return None
386         else:
387             return result
388 
389     def clear_events_for_instance(self, instance):
390         """Remove all pending events for an instance.
391 
392         This will remove all events currently pending for an instance
393         and return them (indexed by event name).
394 
395         :param instance: the instance for which events should be purged
396         :returns: a dictionary of {event_name: eventlet.event.Event}
397         """
398         @utils.synchronized(self._lock_name(instance))
399         def _clear_events():
400             if self._events is None:
401                 LOG.debug('Unexpected attempt to clear events during shutdown',
402                           instance=instance)
403                 return dict()
404             return self._events.pop(instance.uuid, {})
405         return _clear_events()
406 
407     def cancel_all_events(self):
408         if self._events is None:
409             LOG.debug('Unexpected attempt to cancel events during shutdown.')
410             return
411         our_events = self._events
412         # NOTE(danms): Block new events
413         self._events = None
414 
415         for instance_uuid, events in our_events.items():
416             for event_name, eventlet_event in events.items():
417                 LOG.debug('Canceling in-flight event %(event)s for '
418                           'instance %(instance_uuid)s',
419                           {'event': event_name,
420                            'instance_uuid': instance_uuid})
421                 name, tag = event_name.rsplit('-', 1)
422                 event = objects.InstanceExternalEvent(
423                     instance_uuid=instance_uuid,
424                     name=name, status='failed',
425                     tag=tag, data={})
426                 eventlet_event.send(event)
427 
428 
429 class ComputeVirtAPI(virtapi.VirtAPI):
430     def __init__(self, compute):
431         super(ComputeVirtAPI, self).__init__()
432         self._compute = compute
433 
434     def _default_error_callback(self, event_name, instance):
435         raise exception.NovaException(_('Instance event failed'))
436 
437     @contextlib.contextmanager
438     def wait_for_instance_event(self, instance, event_names, deadline=300,
439                                 error_callback=None):
440         """Plan to wait for some events, run some code, then wait.
441 
442         This context manager will first create plans to wait for the
443         provided event_names, yield, and then wait for all the scheduled
444         events to complete.
445 
446         Note that this uses an eventlet.timeout.Timeout to bound the
447         operation, so callers should be prepared to catch that
448         failure and handle that situation appropriately.
449 
450         If the event is not received by the specified timeout deadline,
451         eventlet.timeout.Timeout is raised.
452 
453         If the event is received but did not have a 'completed'
454         status, a NovaException is raised.  If an error_callback is
455         provided, instead of raising an exception as detailed above
456         for the failure case, the callback will be called with the
457         event_name and instance, and can return True to continue
458         waiting for the rest of the events, False to stop processing,
459         or raise an exception which will bubble up to the waiter.
460 
461         :param instance: The instance for which an event is expected
462         :param event_names: A list of event names. Each element can be a
463                             string event name or tuple of strings to
464                             indicate (name, tag).
465         :param deadline: Maximum number of seconds we should wait for all
466                          of the specified events to arrive.
467         :param error_callback: A function to be called if an event arrives
468 
469         """
470 
471         if error_callback is None:
472             error_callback = self._default_error_callback
473         events = {}
474         for event_name in event_names:
475             if isinstance(event_name, tuple):
476                 name, tag = event_name
477                 event_name = objects.InstanceExternalEvent.make_key(
478                     name, tag)
479             try:
480                 events[event_name] = (
481                     self._compute.instance_events.prepare_for_instance_event(
482                         instance, event_name))
483             except exception.NovaException:
484                 error_callback(event_name, instance)
485                 # NOTE(danms): Don't wait for any of the events. They
486                 # should all be canceled and fired immediately below,
487                 # but don't stick around if not.
488                 deadline = 0
489         yield
490         with eventlet.timeout.Timeout(deadline):
491             for event_name, event in events.items():
492                 actual_event = event.wait()
493                 if actual_event.status == 'completed':
494                     continue
495                 decision = error_callback(event_name, instance)
496                 if decision is False:
497                     break
498 
499 
500 class ComputeManager(manager.Manager):
501     """Manages the running instances from creation to destruction."""
502 
503     target = messaging.Target(version='4.11')
504 
505     # How long to wait in seconds before re-issuing a shutdown
506     # signal to an instance during power off.  The overall
507     # time to wait is set by CONF.shutdown_timeout.
508     SHUTDOWN_RETRY_INTERVAL = 10
509 
510     def __init__(self, compute_driver=None, *args, **kwargs):
511         """Load configuration options and connect to the hypervisor."""
512         self.virtapi = ComputeVirtAPI(self)
513         self.network_api = network.API()
514         self.volume_api = volume.API()
515         self.image_api = image.API()
516         self._last_host_check = 0
517         self._last_bw_usage_poll = 0
518         self._bw_usage_supported = True
519         self._last_bw_usage_cell_update = 0
520         self.compute_api = compute.API()
521         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
522         self.conductor_api = conductor.API()
523         self.compute_task_api = conductor.ComputeTaskAPI()
524         self.is_neutron_security_groups = (
525             openstack_driver.is_neutron_security_groups())
526         self.consoleauth_rpcapi = consoleauth.rpcapi.ConsoleAuthAPI()
527         self.cells_rpcapi = cells_rpcapi.CellsAPI()
528         self.scheduler_client = scheduler_client.SchedulerClient()
529         self._resource_tracker_dict = {}
530         self.instance_events = InstanceEvents()
531         self._sync_power_pool = eventlet.GreenPool()
532         self._syncs_in_progress = {}
533         self.send_instance_updates = CONF.scheduler_tracks_instance_changes
534         if CONF.max_concurrent_builds != 0:
535             self._build_semaphore = eventlet.semaphore.Semaphore(
536                 CONF.max_concurrent_builds)
537         else:
538             self._build_semaphore = compute_utils.UnlimitedSemaphore()
539         if max(CONF.max_concurrent_live_migrations, 0) != 0:
540             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
541                 CONF.max_concurrent_live_migrations)
542         else:
543             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
544 
545         super(ComputeManager, self).__init__(service_name="compute",
546                                              *args, **kwargs)
547 
548         # NOTE(russellb) Load the driver last.  It may call back into the
549         # compute manager via the virtapi, so we want it to be fully
550         # initialized before that happens.
551         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
552         self.use_legacy_block_device_info = \
553                             self.driver.need_legacy_block_device_info
554 
555     def reset(self):
556         LOG.info(_LI('Reloading compute RPC API'))
557         compute_rpcapi.LAST_VERSION = None
558         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
559 
560     def _get_resource_tracker(self, nodename):
561         rt = self._resource_tracker_dict.get(nodename)
562         if not rt:
563             if not self.driver.node_is_available(nodename):
564                 raise exception.NovaException(
565                         _("%s is not a valid node managed by this "
566                           "compute host.") % nodename)
567 
568             rt = resource_tracker.ResourceTracker(self.host,
569                                                   self.driver,
570                                                   nodename)
571             self._resource_tracker_dict[nodename] = rt
572         return rt
573 
574     def _update_resource_tracker(self, context, instance):
575         """Let the resource tracker know that an instance has changed state."""
576 
577         if (instance.host == self.host and
578                 self.driver.node_is_available(instance.node)):
579             rt = self._get_resource_tracker(instance.node)
580             rt.update_usage(context, instance)
581 
582     def _instance_update(self, context, instance, **kwargs):
583         """Update an instance in the database using kwargs as value."""
584 
585         for k, v in kwargs.items():
586             setattr(instance, k, v)
587         instance.save()
588         self._update_resource_tracker(context, instance)
589 
590     def _nil_out_instance_obj_host_and_node(self, instance):
591         # NOTE(jwcroppe): We don't do instance.save() here for performance
592         # reasons; a call to this is expected to be immediately followed by
593         # another call that does instance.save(), thus avoiding two writes
594         # to the database layer.
595         instance.host = None
596         instance.node = None
597 
598     def _set_instance_obj_error_state(self, context, instance,
599                                       clean_task_state=False):
600         try:
601             instance.vm_state = vm_states.ERROR
602             if clean_task_state:
603                 instance.task_state = None
604             instance.save()
605         except exception.InstanceNotFound:
606             LOG.debug('Instance has been destroyed from under us while '
607                       'trying to set it to ERROR', instance=instance)
608 
609     def _get_instances_on_driver(self, context, filters=None):
610         """Return a list of instance records for the instances found
611         on the hypervisor which satisfy the specified filters. If filters=None
612         return a list of instance records for all the instances found on the
613         hypervisor.
614         """
615         if not filters:
616             filters = {}
617         try:
618             driver_uuids = self.driver.list_instance_uuids()
619             if len(driver_uuids) == 0:
620                 # Short circuit, don't waste a DB call
621                 return objects.InstanceList()
622             filters['uuid'] = driver_uuids
623             local_instances = objects.InstanceList.get_by_filters(
624                 context, filters, use_slave=True)
625             return local_instances
626         except NotImplementedError:
627             pass
628 
629         # The driver doesn't support uuids listing, so we'll have
630         # to brute force.
631         driver_instances = self.driver.list_instances()
632         instances = objects.InstanceList.get_by_filters(context, filters,
633                                                         use_slave=True)
634         name_map = {instance.name: instance for instance in instances}
635         local_instances = []
636         for driver_instance in driver_instances:
637             instance = name_map.get(driver_instance)
638             if not instance:
639                 continue
640             local_instances.append(instance)
641         return local_instances
642 
643     def _destroy_evacuated_instances(self, context):
644         """Destroys evacuated instances.
645 
646         While nova-compute was down, the instances running on it could be
647         evacuated to another host. Check that the instances reported
648         by the driver are still associated with this host.  If they are
649         not, destroy them, with the exception of instances which are in
650         the MIGRATING, RESIZE_MIGRATING, RESIZE_MIGRATED, RESIZE_FINISH
651         task state or RESIZED vm state.
652         """
653         filters = {
654             'source_compute': self.host,
655             'status': ['accepted', 'done'],
656             'migration_type': 'evacuation',
657         }
658         evacuations = objects.MigrationList.get_by_filters(context, filters)
659         if not evacuations:
660             return
661         evacuations = {mig.instance_uuid: mig for mig in evacuations}
662 
663         filters = {'deleted': False}
664         local_instances = self._get_instances_on_driver(context, filters)
665         evacuated = [inst for inst in local_instances
666                      if inst.uuid in evacuations]
667         for instance in evacuated:
668             migration = evacuations[instance.uuid]
669             LOG.info(_LI('Deleting instance as it has been evacuated from '
670                          'this host'), instance=instance)
671             try:
672                 network_info = self.network_api.get_instance_nw_info(
673                     context, instance)
674                 bdi = self._get_instance_block_device_info(context,
675                                                            instance)
676                 destroy_disks = not (self._is_instance_storage_shared(
677                     context, instance))
678             except exception.InstanceNotFound:
679                 network_info = network_model.NetworkInfo()
680                 bdi = {}
681                 LOG.info(_LI('Instance has been marked deleted already, '
682                              'removing it from the hypervisor.'),
683                          instance=instance)
684                 # always destroy disks if the instance was deleted
685                 destroy_disks = True
686             self.driver.destroy(context, instance,
687                                 network_info,
688                                 bdi, destroy_disks)
689             migration.status = 'completed'
690             migration.save()
691 
692     def _is_instance_storage_shared(self, context, instance, host=None):
693         shared_storage = True
694         data = None
695         try:
696             data = self.driver.check_instance_shared_storage_local(context,
697                                                        instance)
698             if data:
699                 shared_storage = (self.compute_rpcapi.
700                                   check_instance_shared_storage(context,
701                                   instance, data, host=host))
702         except NotImplementedError:
703             LOG.debug('Hypervisor driver does not support '
704                       'instance shared storage check, '
705                       'assuming it\'s not on shared storage',
706                       instance=instance)
707             shared_storage = False
708         except Exception:
709             LOG.exception(_LE('Failed to check if instance shared'),
710                       instance=instance)
711         finally:
712             if data:
713                 self.driver.check_instance_shared_storage_cleanup(context,
714                                                                   data)
715         return shared_storage
716 
717     def _complete_partial_deletion(self, context, instance):
718         """Complete deletion for instances in DELETED status but not marked as
719         deleted in the DB
720         """
721         system_meta = instance.system_metadata
722         instance.destroy()
723         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
724                 context, instance.uuid)
725         quotas = objects.Quotas(context=context)
726         project_id, user_id = objects.quotas.ids_from_instance(context,
727                                                                instance)
728         quotas.reserve(project_id=project_id, user_id=user_id, instances=-1,
729                        cores=-instance.vcpus, ram=-instance.memory_mb)
730         self._complete_deletion(context,
731                                 instance,
732                                 bdms,
733                                 quotas,
734                                 system_meta)
735 
736     def _complete_deletion(self, context, instance, bdms,
737                            quotas, system_meta):
738         if quotas:
739             quotas.commit()
740 
741         # ensure block device mappings are not leaked
742         for bdm in bdms:
743             bdm.destroy()
744 
745         self._update_resource_tracker(context, instance)
746         self._notify_about_instance_usage(context, instance, "delete.end",
747                 system_metadata=system_meta)
748 
749         self._clean_instance_console_tokens(context, instance)
750         self._delete_scheduler_instance_info(context, instance.uuid)
751 
752     def _create_reservations(self, context, instance, project_id, user_id):
753         vcpus = instance.vcpus
754         mem_mb = instance.memory_mb
755 
756         quotas = objects.Quotas(context=context)
757         quotas.reserve(project_id=project_id,
758                        user_id=user_id,
759                        instances=-1,
760                        cores=-vcpus,
761                        ram=-mem_mb)
762         return quotas
763 
764     def _init_instance(self, context, instance):
765         '''Initialize this instance during service init.'''
766 
767         # NOTE(danms): If the instance appears to not be owned by this
768         # host, it may have been evacuated away, but skipped by the
769         # evacuation cleanup code due to configuration. Thus, if that
770         # is a possibility, don't touch the instance in any way, but
771         # log the concern. This will help avoid potential issues on
772         # startup due to misconfiguration.
773         if instance.host != self.host:
774             LOG.warning(_LW('Instance %(uuid)s appears to not be owned '
775                             'by this host, but by %(host)s. Startup '
776                             'processing is being skipped.'),
777                         {'uuid': instance.uuid,
778                          'host': instance.host})
779             return
780 
781         # Instances that are shut down, or in an error state can not be
782         # initialized and are not attempted to be recovered. The exception
783         # to this are instances that are in RESIZE_MIGRATING or DELETING,
784         # which are dealt with further down.
785         if (instance.vm_state == vm_states.SOFT_DELETED or
786             (instance.vm_state == vm_states.ERROR and
787             instance.task_state not in
788             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
789             LOG.debug("Instance is in %s state.",
790                       instance.vm_state, instance=instance)
791             return
792 
793         if instance.vm_state == vm_states.DELETED:
794             try:
795                 self._complete_partial_deletion(context, instance)
796             except Exception:
797                 # we don't want that an exception blocks the init_host
798                 msg = _LE('Failed to complete a deletion')
799                 LOG.exception(msg, instance=instance)
800             return
801 
802         if (instance.vm_state == vm_states.BUILDING or
803             instance.task_state in [task_states.SCHEDULING,
804                                     task_states.BLOCK_DEVICE_MAPPING,
805                                     task_states.NETWORKING,
806                                     task_states.SPAWNING]):
807             # NOTE(dave-mcnally) compute stopped before instance was fully
808             # spawned so set to ERROR state. This is safe to do as the state
809             # may be set by the api but the host is not so if we get here the
810             # instance has already been scheduled to this particular host.
811             LOG.debug("Instance failed to spawn correctly, "
812                       "setting to ERROR state", instance=instance)
813             instance.task_state = None
814             instance.vm_state = vm_states.ERROR
815             instance.save()
816             return
817 
818         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
819             instance.task_state in [task_states.REBUILDING,
820                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
821                                     task_states.REBUILD_SPAWNING]):
822             # NOTE(jichenjc) compute stopped before instance was fully
823             # spawned so set to ERROR state. This is consistent to BUILD
824             LOG.debug("Instance failed to rebuild correctly, "
825                       "setting to ERROR state", instance=instance)
826             instance.task_state = None
827             instance.vm_state = vm_states.ERROR
828             instance.save()
829             return
830 
831         if (instance.vm_state != vm_states.ERROR and
832             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
833                                     task_states.IMAGE_PENDING_UPLOAD,
834                                     task_states.IMAGE_UPLOADING,
835                                     task_states.IMAGE_SNAPSHOT]):
836             LOG.debug("Instance in transitional state %s at start-up "
837                       "clearing task state",
838                       instance.task_state, instance=instance)
839             try:
840                 self._post_interrupted_snapshot_cleanup(context, instance)
841             except Exception:
842                 # we don't want that an exception blocks the init_host
843                 msg = _LE('Failed to cleanup snapshot.')
844                 LOG.exception(msg, instance=instance)
845             instance.task_state = None
846             instance.save()
847 
848         if (instance.vm_state != vm_states.ERROR and
849             instance.task_state in [task_states.RESIZE_PREP]):
850             LOG.debug("Instance in transitional state %s at start-up "
851                       "clearing task state",
852                       instance['task_state'], instance=instance)
853             instance.task_state = None
854             instance.save()
855 
856         if instance.task_state == task_states.DELETING:
857             try:
858                 LOG.info(_LI('Service started deleting the instance during '
859                              'the previous run, but did not finish. Restarting'
860                              ' the deletion now.'), instance=instance)
861                 instance.obj_load_attr('metadata')
862                 instance.obj_load_attr('system_metadata')
863                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
864                         context, instance.uuid)
865                 project_id, user_id = objects.quotas.ids_from_instance(
866                     context, instance)
867                 quotas = self._create_reservations(context, instance,
868                                                    project_id, user_id)
869 
870                 self._delete_instance(context, instance, bdms, quotas)
871             except Exception:
872                 # we don't want that an exception blocks the init_host
873                 msg = _LE('Failed to complete a deletion')
874                 LOG.exception(msg, instance=instance)
875                 self._set_instance_obj_error_state(context, instance)
876             return
877 
878         try_reboot, reboot_type = self._retry_reboot(context, instance)
879         current_power_state = self._get_power_state(context, instance)
880 
881         if try_reboot:
882             LOG.debug("Instance in transitional state (%(task_state)s) at "
883                       "start-up and power state is (%(power_state)s), "
884                       "triggering reboot",
885                       {'task_state': instance.task_state,
886                        'power_state': current_power_state},
887                       instance=instance)
888 
889             # NOTE(mikal): if the instance was doing a soft reboot that got as
890             # far as shutting down the instance but not as far as starting it
891             # again, then we've just become a hard reboot. That means the
892             # task state for the instance needs to change so that we're in one
893             # of the expected task states for a hard reboot.
894             soft_types = [task_states.REBOOT_STARTED,
895                           task_states.REBOOT_PENDING,
896                           task_states.REBOOTING]
897             if instance.task_state in soft_types and reboot_type == 'HARD':
898                 instance.task_state = task_states.REBOOT_PENDING_HARD
899                 instance.save()
900 
901             self.reboot_instance(context, instance, block_device_info=None,
902                                  reboot_type=reboot_type)
903             return
904 
905         elif (current_power_state == power_state.RUNNING and
906               instance.task_state in [task_states.REBOOT_STARTED,
907                                       task_states.REBOOT_STARTED_HARD,
908                                       task_states.PAUSING,
909                                       task_states.UNPAUSING]):
910             LOG.warning(_LW("Instance in transitional state "
911                             "(%(task_state)s) at start-up and power state "
912                             "is (%(power_state)s), clearing task state"),
913                         {'task_state': instance.task_state,
914                          'power_state': current_power_state},
915                         instance=instance)
916             instance.task_state = None
917             instance.vm_state = vm_states.ACTIVE
918             instance.save()
919         elif (current_power_state == power_state.PAUSED and
920               instance.task_state == task_states.UNPAUSING):
921             LOG.warning(_LW("Instance in transitional state "
922                             "(%(task_state)s) at start-up and power state "
923                             "is (%(power_state)s), clearing task state "
924                             "and unpausing the instance"),
925                         {'task_state': instance.task_state,
926                          'power_state': current_power_state},
927                         instance=instance)
928             try:
929                 self.unpause_instance(context, instance)
930             except NotImplementedError:
931                 # Some virt driver didn't support pause and unpause
932                 pass
933             except Exception:
934                 LOG.exception(_LE('Failed to unpause instance'),
935                               instance=instance)
936             return
937 
938         if instance.task_state == task_states.POWERING_OFF:
939             try:
940                 LOG.debug("Instance in transitional state %s at start-up "
941                           "retrying stop request",
942                           instance.task_state, instance=instance)
943                 self.stop_instance(context, instance, True)
944             except Exception:
945                 # we don't want that an exception blocks the init_host
946                 msg = _LE('Failed to stop instance')
947                 LOG.exception(msg, instance=instance)
948             return
949 
950         if instance.task_state == task_states.POWERING_ON:
951             try:
952                 LOG.debug("Instance in transitional state %s at start-up "
953                           "retrying start request",
954                           instance.task_state, instance=instance)
955                 self.start_instance(context, instance)
956             except Exception:
957                 # we don't want that an exception blocks the init_host
958                 msg = _LE('Failed to start instance')
959                 LOG.exception(msg, instance=instance)
960             return
961 
962         net_info = compute_utils.get_nw_info_for_instance(instance)
963         try:
964             self.driver.plug_vifs(instance, net_info)
965         except NotImplementedError as e:
966             LOG.debug(e, instance=instance)
967         except exception.VirtualInterfacePlugException:
968             # we don't want an exception to block the init_host
969             LOG.exception(_LE("Vifs plug failed"), instance=instance)
970             self._set_instance_obj_error_state(context, instance)
971             return
972 
973         if instance.task_state == task_states.RESIZE_MIGRATING:
974             # We crashed during resize/migration, so roll back for safety
975             try:
976                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
977                 # not in system_metadata we default to True for backwards
978                 # compatibility
979                 power_on = (instance.system_metadata.get('old_vm_state') !=
980                             vm_states.STOPPED)
981 
982                 block_dev_info = self._get_instance_block_device_info(context,
983                                                                       instance)
984 
985                 self.driver.finish_revert_migration(context,
986                     instance, net_info, block_dev_info, power_on)
987 
988             except Exception:
989                 LOG.exception(_LE('Failed to revert crashed migration'),
990                               instance=instance)
991             finally:
992                 LOG.info(_LI('Instance found in migrating state during '
993                              'startup. Resetting task_state'),
994                          instance=instance)
995                 instance.task_state = None
996                 instance.save()
997         if instance.task_state == task_states.MIGRATING:
998             # Live migration did not complete, but instance is on this
999             # host, so reset the state.
1000             instance.task_state = None
1001             instance.save(expected_task_state=[task_states.MIGRATING])
1002 
1003         db_state = instance.power_state
1004         drv_state = self._get_power_state(context, instance)
1005         expect_running = (db_state == power_state.RUNNING and
1006                           drv_state != db_state)
1007 
1008         LOG.debug('Current state is %(drv_state)s, state in DB is '
1009                   '%(db_state)s.',
1010                   {'drv_state': drv_state, 'db_state': db_state},
1011                   instance=instance)
1012 
1013         if expect_running and CONF.resume_guests_state_on_host_boot:
1014             LOG.info(_LI('Rebooting instance after nova-compute restart.'),
1015                      instance=instance)
1016 
1017             block_device_info = \
1018                 self._get_instance_block_device_info(context, instance)
1019 
1020             try:
1021                 self.driver.resume_state_on_host_boot(
1022                     context, instance, net_info, block_device_info)
1023             except NotImplementedError:
1024                 LOG.warning(_LW('Hypervisor driver does not support '
1025                                 'resume guests'), instance=instance)
1026             except Exception:
1027                 # NOTE(vish): The instance failed to resume, so we set the
1028                 #             instance to error and attempt to continue.
1029                 LOG.warning(_LW('Failed to resume instance'),
1030                             instance=instance)
1031                 self._set_instance_obj_error_state(context, instance)
1032 
1033         elif drv_state == power_state.RUNNING:
1034             # VMwareAPI drivers will raise an exception
1035             try:
1036                 self.driver.ensure_filtering_rules_for_instance(
1037                                        instance, net_info)
1038             except NotImplementedError:
1039                 LOG.debug('Hypervisor driver does not support '
1040                           'firewall rules', instance=instance)
1041 
1042     def _retry_reboot(self, context, instance):
1043         current_power_state = self._get_power_state(context, instance)
1044         current_task_state = instance.task_state
1045         retry_reboot = False
1046         reboot_type = compute_utils.get_reboot_type(current_task_state,
1047                                                     current_power_state)
1048 
1049         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1050                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1051         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1052                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1053         started_not_running = (current_task_state in
1054                                [task_states.REBOOT_STARTED,
1055                                 task_states.REBOOT_STARTED_HARD] and
1056                                current_power_state != power_state.RUNNING)
1057 
1058         if pending_soft or pending_hard or started_not_running:
1059             retry_reboot = True
1060 
1061         return retry_reboot, reboot_type
1062 
1063     def handle_lifecycle_event(self, event):
1064         LOG.info(_LI("VM %(state)s (Lifecycle Event)"),
1065                  {'state': event.get_name()},
1066                  instance_uuid=event.get_instance_uuid())
1067         context = nova.context.get_admin_context(read_deleted='yes')
1068         instance = objects.Instance.get_by_uuid(context,
1069                                                 event.get_instance_uuid(),
1070                                                 expected_attrs=[])
1071         vm_power_state = None
1072         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1073             vm_power_state = power_state.SHUTDOWN
1074         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1075             vm_power_state = power_state.RUNNING
1076         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1077             vm_power_state = power_state.PAUSED
1078         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1079             vm_power_state = power_state.RUNNING
1080         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1081             vm_power_state = power_state.SUSPENDED
1082         else:
1083             LOG.warning(_LW("Unexpected power state %d"),
1084                         event.get_transition())
1085 
1086         # Note(lpetrut): The event may be delayed, thus not reflecting
1087         # the current instance power state. In that case, ignore the event.
1088         current_power_state = self._get_power_state(context, instance)
1089         if current_power_state == vm_power_state:
1090             LOG.debug('Synchronizing instance power state after lifecycle '
1091                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1092                       'current task_state: %(task_state)s, current DB '
1093                       'power_state: %(db_power_state)s, VM power_state: '
1094                       '%(vm_power_state)s',
1095                       {'event': event.get_name(),
1096                        'vm_state': instance.vm_state,
1097                        'task_state': instance.task_state,
1098                        'db_power_state': instance.power_state,
1099                        'vm_power_state': vm_power_state},
1100                       instance_uuid=instance.uuid)
1101             self._sync_instance_power_state(context,
1102                                             instance,
1103                                             vm_power_state)
1104 
1105     def handle_events(self, event):
1106         if isinstance(event, virtevent.LifecycleEvent):
1107             try:
1108                 self.handle_lifecycle_event(event)
1109             except exception.InstanceNotFound:
1110                 LOG.debug("Event %s arrived for non-existent instance. The "
1111                           "instance was probably deleted.", event)
1112         else:
1113             LOG.debug("Ignoring event %s", event)
1114 
1115     def init_virt_events(self):
1116         if CONF.workarounds.handle_virt_lifecycle_events:
1117             self.driver.register_event_listener(self.handle_events)
1118         else:
1119             # NOTE(mriedem): If the _sync_power_states periodic task is
1120             # disabled we should emit a warning in the logs.
1121             if CONF.sync_power_state_interval < 0:
1122                 LOG.warning(_LW('Instance lifecycle events from the compute '
1123                              'driver have been disabled. Note that lifecycle '
1124                              'changes to an instance outside of the compute '
1125                              'service will not be synchronized '
1126                              'automatically since the _sync_power_states '
1127                              'periodic task is also disabled.'))
1128             else:
1129                 LOG.info(_LI('Instance lifecycle events from the compute '
1130                              'driver have been disabled. Note that lifecycle '
1131                              'changes to an instance outside of the compute '
1132                              'service will only be synchronized by the '
1133                              '_sync_power_states periodic task.'))
1134 
1135     def init_host(self):
1136         """Initialization for a standalone compute service."""
1137         self.driver.init_host(host=self.host)
1138         context = nova.context.get_admin_context()
1139         instances = objects.InstanceList.get_by_host(
1140             context, self.host, expected_attrs=['info_cache', 'metadata'])
1141 
1142         if CONF.defer_iptables_apply:
1143             self.driver.filter_defer_apply_on()
1144 
1145         self.init_virt_events()
1146 
1147         try:
1148             # checking that instance was not already evacuated to other host
1149             self._destroy_evacuated_instances(context)
1150             for instance in instances:
1151                 self._init_instance(context, instance)
1152         finally:
1153             if CONF.defer_iptables_apply:
1154                 self.driver.filter_defer_apply_off()
1155             self._update_scheduler_instance_info(context, instances)
1156 
1157     def cleanup_host(self):
1158         self.driver.register_event_listener(None)
1159         self.instance_events.cancel_all_events()
1160         self.driver.cleanup_host(host=self.host)
1161 
1162     def pre_start_hook(self):
1163         """After the service is initialized, but before we fully bring
1164         the service up by listening on RPC queues, make sure to update
1165         our available resources (and indirectly our available nodes).
1166         """
1167         self.update_available_resource(nova.context.get_admin_context())
1168 
1169     def _get_power_state(self, context, instance):
1170         """Retrieve the power state for the given instance."""
1171         LOG.debug('Checking state', instance=instance)
1172         try:
1173             return self.driver.get_info(instance).state
1174         except exception.InstanceNotFound:
1175             return power_state.NOSTATE
1176 
1177     def get_console_topic(self, context):
1178         """Retrieves the console host for a project on this host.
1179 
1180         Currently this is just set in the flags for each compute host.
1181 
1182         """
1183         # TODO(mdragon): perhaps make this variable by console_type?
1184         return '%s.%s' % (CONF.console_topic, CONF.console_host)
1185 
1186     @wrap_exception()
1187     def get_console_pool_info(self, context, console_type):
1188         return self.driver.get_console_pool_info(console_type)
1189 
1190     # NOTE(hanlind): This and the virt method it calls can be removed in
1191     # version 5.0 of the RPC API
1192     @wrap_exception()
1193     def refresh_security_group_rules(self, context, security_group_id):
1194         """Tell the virtualization driver to refresh security group rules.
1195 
1196         Passes straight through to the virtualization driver.
1197 
1198         """
1199         return self.driver.refresh_security_group_rules(security_group_id)
1200 
1201     @object_compat
1202     @wrap_exception()
1203     def refresh_instance_security_rules(self, context, instance):
1204         """Tell the virtualization driver to refresh security rules for
1205         an instance.
1206 
1207         Passes straight through to the virtualization driver.
1208 
1209         Synchronise the call because we may still be in the middle of
1210         creating the instance.
1211         """
1212         @utils.synchronized(instance.uuid)
1213         def _sync_refresh():
1214             try:
1215                 return self.driver.refresh_instance_security_rules(instance)
1216             except NotImplementedError:
1217                 LOG.debug('Hypervisor driver does not support '
1218                           'security groups.', instance=instance)
1219 
1220         return _sync_refresh()
1221 
1222     def _await_block_device_map_created(self, context, vol_id):
1223         # TODO(yamahata): creating volume simultaneously
1224         #                 reduces creation time?
1225         # TODO(yamahata): eliminate dumb polling
1226         start = time.time()
1227         retries = CONF.block_device_allocate_retries
1228         if retries < 0:
1229             LOG.warning(_LW("Treating negative config value (%(retries)s) for "
1230                             "'block_device_retries' as 0."),
1231                         {'retries': retries})
1232         # (1) treat  negative config value as 0
1233         # (2) the configured value is 0, one attempt should be made
1234         # (3) the configured value is > 0, then the total number attempts
1235         #      is (retries + 1)
1236         attempts = 1
1237         if retries >= 1:
1238             attempts = retries + 1
1239         for attempt in range(1, attempts + 1):
1240             volume = self.volume_api.get(context, vol_id)
1241             volume_status = volume['status']
1242             if volume_status not in ['creating', 'downloading']:
1243                 if volume_status == 'available':
1244                     return attempt
1245                 LOG.warning(_LW("Volume id: %(vol_id)s finished being "
1246                                 "created but its status is %(vol_status)s."),
1247                             {'vol_id': vol_id,
1248                              'vol_status': volume_status})
1249                 break
1250             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1251         raise exception.VolumeNotCreated(volume_id=vol_id,
1252                                          seconds=int(time.time() - start),
1253                                          attempts=attempt,
1254                                          volume_status=volume_status)
1255 
1256     def _decode_files(self, injected_files):
1257         """Base64 decode the list of files to inject."""
1258         if not injected_files:
1259             return []
1260 
1261         def _decode(f):
1262             path, contents = f
1263             try:
1264                 decoded = base64.b64decode(contents)
1265                 return path, decoded
1266             except TypeError:
1267                 raise exception.Base64Exception(path=path)
1268 
1269         return [_decode(f) for f in injected_files]
1270 
1271     def _validate_instance_group_policy(self, context, instance,
1272             filter_properties):
1273         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1274         # However, there is a race condition with the enforcement of
1275         # the policy.  Since more than one instance may be scheduled at the
1276         # same time, it's possible that more than one instance with an
1277         # anti-affinity policy may end up here.  It's also possible that
1278         # multiple instances with an affinity policy could end up on different
1279         # hosts.  This is a validation step to make sure that starting the
1280         # instance here doesn't violate the policy.
1281 
1282         scheduler_hints = filter_properties.get('scheduler_hints') or {}
1283         group_hint = scheduler_hints.get('group')
1284         if not group_hint:
1285             return
1286 
1287         @utils.synchronized(group_hint)
1288         def _do_validation(context, instance, group_hint):
1289             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1290             if 'anti-affinity' in group.policies:
1291                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1292                 if self.host in group_hosts:
1293                     msg = _("Anti-affinity instance group policy "
1294                             "was violated.")
1295                     raise exception.RescheduledException(
1296                             instance_uuid=instance.uuid,
1297                             reason=msg)
1298             elif 'affinity' in group.policies:
1299                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1300                 if group_hosts and self.host not in group_hosts:
1301                     msg = _("Affinity instance group policy was violated.")
1302                     raise exception.RescheduledException(
1303                             instance_uuid=instance.uuid,
1304                             reason=msg)
1305 
1306         _do_validation(context, instance, group_hint)
1307 
1308     def _log_original_error(self, exc_info, instance_uuid):
1309         LOG.error(_LE('Error: %s'), exc_info[1], instance_uuid=instance_uuid,
1310                   exc_info=exc_info)
1311 
1312     def _reschedule(self, context, request_spec, filter_properties,
1313             instance, reschedule_method, method_args, task_state,
1314             exc_info=None):
1315         """Attempt to re-schedule a compute operation."""
1316 
1317         instance_uuid = instance.uuid
1318         retry = filter_properties.get('retry')
1319         if not retry:
1320             # no retry information, do not reschedule.
1321             LOG.debug("Retry info not present, will not reschedule",
1322                       instance_uuid=instance_uuid)
1323             return
1324 
1325         if not request_spec:
1326             LOG.debug("No request spec, will not reschedule",
1327                       instance_uuid=instance_uuid)
1328             return
1329 
1330         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1331                   {'method': reschedule_method.__name__,
1332                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1333 
1334         # reset the task state:
1335         self._instance_update(context, instance, task_state=task_state)
1336 
1337         if exc_info:
1338             # stringify to avoid circular ref problem in json serialization:
1339             retry['exc'] = traceback.format_exception_only(exc_info[0],
1340                                     exc_info[1])
1341 
1342         reschedule_method(context, *method_args)
1343         return True
1344 
1345     @periodic_task.periodic_task
1346     def _check_instance_build_time(self, context):
1347         """Ensure that instances are not stuck in build."""
1348         timeout = CONF.instance_build_timeout
1349         if timeout == 0:
1350             return
1351 
1352         filters = {'vm_state': vm_states.BUILDING,
1353                    'host': self.host}
1354 
1355         building_insts = objects.InstanceList.get_by_filters(context,
1356                            filters, expected_attrs=[], use_slave=True)
1357 
1358         for instance in building_insts:
1359             if timeutils.is_older_than(instance.created_at, timeout):
1360                 self._set_instance_obj_error_state(context, instance)
1361                 LOG.warning(_LW("Instance build timed out. Set to error "
1362                                 "state."), instance=instance)
1363 
1364     def _check_instance_exists(self, context, instance):
1365         """Ensure an instance with the same name is not already present."""
1366         if self.driver.instance_exists(instance):
1367             raise exception.InstanceExists(name=instance.name)
1368 
1369     def _allocate_network_async(self, context, instance, requested_networks,
1370                                 macs, security_groups, is_vpn, dhcp_options):
1371         """Method used to allocate networks in the background.
1372 
1373         Broken out for testing.
1374         """
1375         LOG.debug("Allocating IP information in the background.",
1376                   instance=instance)
1377         retries = CONF.network_allocate_retries
1378         if retries < 0:
1379             LOG.warning(_LW("Treating negative config value (%(retries)s) for "
1380                             "'network_allocate_retries' as 0."),
1381                         {'retries': retries})
1382             retries = 0
1383         attempts = retries + 1
1384         retry_time = 1
1385         bind_host_id = self.driver.network_binding_host_id(context, instance)
1386         for attempt in range(1, attempts + 1):
1387             try:
1388                 nwinfo = self.network_api.allocate_for_instance(
1389                         context, instance, vpn=is_vpn,
1390                         requested_networks=requested_networks,
1391                         macs=macs,
1392                         security_groups=security_groups,
1393                         dhcp_options=dhcp_options,
1394                         bind_host_id=bind_host_id)
1395                 LOG.debug('Instance network_info: |%s|', nwinfo,
1396                           instance=instance)
1397                 instance.system_metadata['network_allocated'] = 'True'
1398                 # NOTE(JoshNang) do not save the instance here, as it can cause
1399                 # races. The caller shares a reference to instance and waits
1400                 # for this async greenthread to finish before calling
1401                 # instance.save().
1402                 return nwinfo
1403             except Exception:
1404                 exc_info = sys.exc_info()
1405                 log_info = {'attempt': attempt,
1406                             'attempts': attempts}
1407                 if attempt == attempts:
1408                     LOG.exception(_LE('Instance failed network setup '
1409                                       'after %(attempts)d attempt(s)'),
1410                                   log_info)
1411                     six.reraise(*exc_info)
1412                 LOG.warning(_LW('Instance failed network setup '
1413                                 '(attempt %(attempt)d of %(attempts)d)'),
1414                             log_info, instance=instance)
1415                 time.sleep(retry_time)
1416                 retry_time *= 2
1417                 if retry_time > 30:
1418                     retry_time = 30
1419         # Not reached.
1420 
1421     def _build_networks_for_instance(self, context, instance,
1422             requested_networks, security_groups):
1423 
1424         # If we're here from a reschedule the network may already be allocated.
1425         if strutils.bool_from_string(
1426                 instance.system_metadata.get('network_allocated', 'False')):
1427             # NOTE(alex_xu): The network_allocated is True means the network
1428             # resource already allocated at previous scheduling, and the
1429             # network setup is cleanup at previous. After rescheduling, the
1430             # network resource need setup on the new host.
1431             self.network_api.setup_instance_network_on_host(
1432                 context, instance, instance.host)
1433             return self.network_api.get_instance_nw_info(context, instance)
1434 
1435         if not self.is_neutron_security_groups:
1436             security_groups = []
1437 
1438         macs = self.driver.macs_for_instance(instance)
1439         dhcp_options = self.driver.dhcp_options_for_instance(instance)
1440         network_info = self._allocate_network(context, instance,
1441                 requested_networks, macs, security_groups, dhcp_options)
1442 
1443         return network_info
1444 
1445     def _allocate_network(self, context, instance, requested_networks, macs,
1446                           security_groups, dhcp_options):
1447         """Start network allocation asynchronously.  Return an instance
1448         of NetworkInfoAsyncWrapper that can be used to retrieve the
1449         allocated networks when the operation has finished.
1450         """
1451         # NOTE(comstud): Since we're allocating networks asynchronously,
1452         # this task state has little meaning, as we won't be in this
1453         # state for very long.
1454         instance.vm_state = vm_states.BUILDING
1455         instance.task_state = task_states.NETWORKING
1456         instance.save(expected_task_state=[None])
1457         self._update_resource_tracker(context, instance)
1458 
1459         is_vpn = pipelib.is_vpn_image(instance.image_ref)
1460         return network_model.NetworkInfoAsyncWrapper(
1461                 self._allocate_network_async, context, instance,
1462                 requested_networks, macs, security_groups, is_vpn,
1463                 dhcp_options)
1464 
1465     def _default_root_device_name(self, instance, image_meta, root_bdm):
1466         try:
1467             return self.driver.default_root_device_name(instance,
1468                                                         image_meta,
1469                                                         root_bdm)
1470         except NotImplementedError:
1471             return compute_utils.get_next_device_name(instance, [])
1472 
1473     def _default_device_names_for_instance(self, instance,
1474                                            root_device_name,
1475                                            *block_device_lists):
1476         try:
1477             self.driver.default_device_names_for_instance(instance,
1478                                                           root_device_name,
1479                                                           *block_device_lists)
1480         except NotImplementedError:
1481             compute_utils.default_device_names_for_instance(
1482                 instance, root_device_name, *block_device_lists)
1483 
1484     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1485         # NOTE(ndipanov): Copy obj to avoid changing the original
1486         block_device_obj = block_device_obj.obj_clone()
1487         try:
1488             return self.driver.get_device_name_for_instance(
1489                 instance, bdms, block_device_obj)
1490         except NotImplementedError:
1491             return compute_utils.get_device_name_for_instance(
1492                 instance, bdms, block_device_obj.get("device_name"))
1493 
1494     def _default_block_device_names(self, context, instance,
1495                                     image_meta, block_devices):
1496         """Verify that all the devices have the device_name set. If not,
1497         provide a default name.
1498 
1499         It also ensures that there is a root_device_name and is set to the
1500         first block device in the boot sequence (boot_index=0).
1501         """
1502         root_bdm = block_device.get_root_bdm(block_devices)
1503         if not root_bdm:
1504             return
1505 
1506         # Get the root_device_name from the root BDM or the instance
1507         root_device_name = None
1508         update_root_bdm = False
1509 
1510         if root_bdm.device_name:
1511             root_device_name = root_bdm.device_name
1512             instance.root_device_name = root_device_name
1513         elif instance.root_device_name:
1514             root_device_name = instance.root_device_name
1515             root_bdm.device_name = root_device_name
1516             update_root_bdm = True
1517         else:
1518             root_device_name = self._default_root_device_name(instance,
1519                                                               image_meta,
1520                                                               root_bdm)
1521 
1522             instance.root_device_name = root_device_name
1523             root_bdm.device_name = root_device_name
1524             update_root_bdm = True
1525 
1526         if update_root_bdm:
1527             root_bdm.save()
1528 
1529         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1530                             block_devices))
1531         swap = list(filter(block_device.new_format_is_swap,
1532                       block_devices))
1533         block_device_mapping = list(filter(
1534               driver_block_device.is_block_device_mapping, block_devices))
1535 
1536         self._default_device_names_for_instance(instance,
1537                                                 root_device_name,
1538                                                 ephemerals,
1539                                                 swap,
1540                                                 block_device_mapping)
1541 
1542     def _block_device_info_to_legacy(self, block_device_info):
1543         """Convert BDI to the old format for drivers that need it."""
1544 
1545         if self.use_legacy_block_device_info:
1546             ephemerals = driver_block_device.legacy_block_devices(
1547                 driver.block_device_info_get_ephemerals(block_device_info))
1548             mapping = driver_block_device.legacy_block_devices(
1549                 driver.block_device_info_get_mapping(block_device_info))
1550             swap = block_device_info['swap']
1551             if swap:
1552                 swap = swap.legacy()
1553 
1554             block_device_info.update({
1555                 'ephemerals': ephemerals,
1556                 'swap': swap,
1557                 'block_device_mapping': mapping})
1558 
1559     def _check_dev_name(self, bdms, instance):
1560         bdms_no_device_name = [x for x in bdms if x.device_name is None]
1561         for bdm in bdms_no_device_name:
1562             device_name = self._get_device_name_for_instance(instance,
1563                                                              bdms,
1564                                                              bdm)
1565             values = {'device_name': device_name}
1566             bdm.update(values)
1567 
1568     def _prep_block_device(self, context, instance, bdms,
1569                            do_check_attach=True):
1570         """Set up the block device for an instance with error logging."""
1571         try:
1572             self._check_dev_name(bdms, instance)
1573             block_device_info = driver.get_block_device_info(instance, bdms)
1574             mapping = driver.block_device_info_get_mapping(block_device_info)
1575             driver_block_device.attach_block_devices(
1576                 mapping, context, instance, self.volume_api, self.driver,
1577                 do_check_attach=do_check_attach,
1578                 wait_func=self._await_block_device_map_created)
1579 
1580             self._block_device_info_to_legacy(block_device_info)
1581             return block_device_info
1582 
1583         except exception.OverQuota:
1584             msg = _LW('Failed to create block device for instance due to '
1585                       'being over volume resource quota')
1586             LOG.warning(msg, instance=instance)
1587             raise exception.VolumeLimitExceeded()
1588 
1589         except Exception:
1590             LOG.exception(_LE('Instance failed block device setup'),
1591                           instance=instance)
1592             raise exception.InvalidBDM()
1593 
1594     def _update_instance_after_spawn(self, context, instance):
1595         instance.power_state = self._get_power_state(context, instance)
1596         instance.vm_state = vm_states.ACTIVE
1597         instance.task_state = None
1598         instance.launched_at = timeutils.utcnow()
1599         configdrive.update_instance(instance)
1600 
1601     def _update_scheduler_instance_info(self, context, instance):
1602         """Sends an InstanceList with created or updated Instance objects to
1603         the Scheduler client.
1604 
1605         In the case of init_host, the value passed will already be an
1606         InstanceList. Other calls will send individual Instance objects that
1607         have been created or resized. In this case, we create an InstanceList
1608         object containing that Instance.
1609         """
1610         if not self.send_instance_updates:
1611             return
1612         if isinstance(instance, obj_instance.Instance):
1613             instance = objects.InstanceList(objects=[instance])
1614         context = context.elevated()
1615         self.scheduler_client.update_instance_info(context, self.host,
1616                                                    instance)
1617 
1618     def _delete_scheduler_instance_info(self, context, instance_uuid):
1619         """Sends the uuid of the deleted Instance to the Scheduler client."""
1620         if not self.send_instance_updates:
1621             return
1622         context = context.elevated()
1623         self.scheduler_client.delete_instance_info(context, self.host,
1624                                                    instance_uuid)
1625 
1626     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1627     def _sync_scheduler_instance_info(self, context):
1628         if not self.send_instance_updates:
1629             return
1630         context = context.elevated()
1631         instances = objects.InstanceList.get_by_host(context, self.host,
1632                                                      expected_attrs=[],
1633                                                      use_slave=True)
1634         uuids = [instance.uuid for instance in instances]
1635         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1636 
1637     def _notify_about_instance_usage(self, context, instance, event_suffix,
1638                                      network_info=None, system_metadata=None,
1639                                      extra_usage_info=None, fault=None):
1640         compute_utils.notify_about_instance_usage(
1641             self.notifier, context, instance, event_suffix,
1642             network_info=network_info,
1643             system_metadata=system_metadata,
1644             extra_usage_info=extra_usage_info, fault=fault)
1645 
1646     def _deallocate_network(self, context, instance,
1647                             requested_networks=None):
1648         LOG.debug('Deallocating network for instance', instance=instance)
1649         with timeutils.StopWatch() as timer:
1650             self.network_api.deallocate_for_instance(
1651                 context, instance, requested_networks=requested_networks)
1652         # nova-network does an rpc call so we're OK tracking time spent here
1653         LOG.info(_LI('Took %0.2f seconds to deallocate network for instance.'),
1654                  timer.elapsed(), instance=instance)
1655 
1656     def _get_instance_block_device_info(self, context, instance,
1657                                         refresh_conn_info=False,
1658                                         bdms=None):
1659         """Transform block devices to the driver block_device format."""
1660 
1661         if not bdms:
1662             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1663                     context, instance.uuid)
1664         block_device_info = driver.get_block_device_info(instance, bdms)
1665 
1666         if not refresh_conn_info:
1667             # if the block_device_mapping has no value in connection_info
1668             # (returned as None), don't include in the mapping
1669             block_device_info['block_device_mapping'] = [
1670                 bdm for bdm in driver.block_device_info_get_mapping(
1671                                     block_device_info)
1672                 if bdm.get('connection_info')]
1673         else:
1674             driver_block_device.refresh_conn_infos(
1675                 driver.block_device_info_get_mapping(block_device_info),
1676                 context, instance, self.volume_api, self.driver)
1677 
1678         self._block_device_info_to_legacy(block_device_info)
1679 
1680         return block_device_info
1681 
1682     @wrap_exception()
1683     @reverts_task_state
1684     @wrap_instance_fault
1685     def build_and_run_instance(self, context, instance, image, request_spec,
1686                      filter_properties, admin_password=None,
1687                      injected_files=None, requested_networks=None,
1688                      security_groups=None, block_device_mapping=None,
1689                      node=None, limits=None):
1690 
1691         @utils.synchronized(instance.uuid)
1692         def _locked_do_build_and_run_instance(*args, **kwargs):
1693             # NOTE(danms): We grab the semaphore with the instance uuid
1694             # locked because we could wait in line to build this instance
1695             # for a while and we want to make sure that nothing else tries
1696             # to do anything with this instance while we wait.
1697             with self._build_semaphore:
1698                 self._do_build_and_run_instance(*args, **kwargs)
1699 
1700         # NOTE(danms): We spawn here to return the RPC worker thread back to
1701         # the pool. Since what follows could take a really long time, we don't
1702         # want to tie up RPC workers.
1703         utils.spawn_n(_locked_do_build_and_run_instance,
1704                       context, instance, image, request_spec,
1705                       filter_properties, admin_password, injected_files,
1706                       requested_networks, security_groups,
1707                       block_device_mapping, node, limits)
1708 
1709     @hooks.add_hook('build_instance')
1710     @wrap_exception()
1711     @reverts_task_state
1712     @wrap_instance_event
1713     @wrap_instance_fault
1714     def _do_build_and_run_instance(self, context, instance, image,
1715             request_spec, filter_properties, admin_password, injected_files,
1716             requested_networks, security_groups, block_device_mapping,
1717             node=None, limits=None):
1718 
1719         try:
1720             LOG.debug('Starting instance...', context=context,
1721                       instance=instance)
1722             instance.vm_state = vm_states.BUILDING
1723             instance.task_state = None
1724             instance.save(expected_task_state=
1725                     (task_states.SCHEDULING, None))
1726         except exception.InstanceNotFound:
1727             msg = 'Instance disappeared before build.'
1728             LOG.debug(msg, instance=instance)
1729             return build_results.FAILED
1730         except exception.UnexpectedTaskStateError as e:
1731             LOG.debug(e.format_message(), instance=instance)
1732             return build_results.FAILED
1733 
1734         # b64 decode the files to inject:
1735         decoded_files = self._decode_files(injected_files)
1736 
1737         if limits is None:
1738             limits = {}
1739 
1740         if node is None:
1741             node = self.driver.get_available_nodes(refresh=True)[0]
1742             LOG.debug('No node specified, defaulting to %s', node,
1743                       instance=instance)
1744 
1745         try:
1746             with timeutils.StopWatch() as timer:
1747                 self._build_and_run_instance(context, instance, image,
1748                         decoded_files, admin_password, requested_networks,
1749                         security_groups, block_device_mapping, node, limits,
1750                         filter_properties)
1751             LOG.info(_LI('Took %0.2f seconds to build instance.'),
1752                      timer.elapsed(), instance=instance)
1753             return build_results.ACTIVE
1754         except exception.RescheduledException as e:
1755             retry = filter_properties.get('retry')
1756             if not retry:
1757                 # no retry information, do not reschedule.
1758                 LOG.debug("Retry info not present, will not reschedule",
1759                     instance=instance)
1760                 self._cleanup_allocated_networks(context, instance,
1761                     requested_networks)
1762                 compute_utils.add_instance_fault_from_exc(context,
1763                         instance, e, sys.exc_info(),
1764                         fault_message=e.kwargs['reason'])
1765                 self._nil_out_instance_obj_host_and_node(instance)
1766                 self._set_instance_obj_error_state(context, instance,
1767                                                    clean_task_state=True)
1768                 return build_results.FAILED
1769             LOG.debug(e.format_message(), instance=instance)
1770             # This will be used for logging the exception
1771             retry['exc'] = traceback.format_exception(*sys.exc_info())
1772             # This will be used for setting the instance fault message
1773             retry['exc_reason'] = e.kwargs['reason']
1774             # NOTE(comstud): Deallocate networks if the driver wants
1775             # us to do so.
1776             # NOTE(vladikr): SR-IOV ports should be deallocated to
1777             # allow new sriov pci devices to be allocated on a new host.
1778             # Otherwise, if devices with pci addresses are already allocated
1779             # on the destination host, the instance will fail to spawn.
1780             # info_cache.network_info should be present at this stage.
1781             if (self.driver.deallocate_networks_on_reschedule(instance) or
1782                 self.deallocate_sriov_ports_on_reschedule(instance)):
1783                 self._cleanup_allocated_networks(context, instance,
1784                         requested_networks)
1785             else:
1786                 # NOTE(alex_xu): Network already allocated and we don't
1787                 # want to deallocate them before rescheduling. But we need
1788                 # to cleanup those network resources setup on this host before
1789                 # rescheduling.
1790                 self.network_api.cleanup_instance_network_on_host(
1791                     context, instance, self.host)
1792 
1793             self._nil_out_instance_obj_host_and_node(instance)
1794             instance.task_state = task_states.SCHEDULING
1795             instance.save()
1796 
1797             self.compute_task_api.build_instances(context, [instance],
1798                     image, filter_properties, admin_password,
1799                     injected_files, requested_networks, security_groups,
1800                     block_device_mapping)
1801             return build_results.RESCHEDULED
1802         except (exception.InstanceNotFound,
1803                 exception.UnexpectedDeletingTaskStateError):
1804             msg = 'Instance disappeared during build.'
1805             LOG.debug(msg, instance=instance)
1806             self._cleanup_allocated_networks(context, instance,
1807                     requested_networks)
1808             return build_results.FAILED
1809         except exception.BuildAbortException as e:
1810             LOG.exception(e.format_message(), instance=instance)
1811             self._cleanup_allocated_networks(context, instance,
1812                     requested_networks)
1813             self._cleanup_volumes(context, instance.uuid,
1814                     block_device_mapping, raise_exc=False)
1815             compute_utils.add_instance_fault_from_exc(context, instance,
1816                     e, sys.exc_info())
1817             self._nil_out_instance_obj_host_and_node(instance)
1818             self._set_instance_obj_error_state(context, instance,
1819                                                clean_task_state=True)
1820             return build_results.FAILED
1821         except Exception as e:
1822             # Should not reach here.
1823             msg = _LE('Unexpected build failure, not rescheduling build.')
1824             LOG.exception(msg, instance=instance)
1825             self._cleanup_allocated_networks(context, instance,
1826                     requested_networks)
1827             self._cleanup_volumes(context, instance.uuid,
1828                     block_device_mapping, raise_exc=False)
1829             compute_utils.add_instance_fault_from_exc(context, instance,
1830                     e, sys.exc_info())
1831             self._nil_out_instance_obj_host_and_node(instance)
1832             self._set_instance_obj_error_state(context, instance,
1833                                                clean_task_state=True)
1834             return build_results.FAILED
1835 
1836     def deallocate_sriov_ports_on_reschedule(self, instance):
1837         """Determine if networks are needed to be deallocated before reschedule
1838 
1839         Check the cached network info for any assigned SR-IOV ports.
1840         SR-IOV ports should be deallocated prior to rescheduling
1841         in order to allow new sriov pci devices to be allocated on a new host.
1842         """
1843         info_cache = instance.info_cache
1844 
1845         def _has_sriov_port(vif):
1846             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1847 
1848         if (info_cache and info_cache.network_info):
1849             for vif in info_cache.network_info:
1850                 if _has_sriov_port(vif):
1851                     return True
1852         return False
1853 
1854     def _build_and_run_instance(self, context, instance, image, injected_files,
1855             admin_password, requested_networks, security_groups,
1856             block_device_mapping, node, limits, filter_properties):
1857 
1858         image_name = image.get('name')
1859         self._notify_about_instance_usage(context, instance, 'create.start',
1860                 extra_usage_info={'image_name': image_name})
1861         try:
1862             rt = self._get_resource_tracker(node)
1863             with rt.instance_claim(context, instance, limits):
1864                 # NOTE(russellb) It's important that this validation be done
1865                 # *after* the resource tracker instance claim, as that is where
1866                 # the host is set on the instance.
1867                 self._validate_instance_group_policy(context, instance,
1868                         filter_properties)
1869                 image_meta = objects.ImageMeta.from_dict(image)
1870                 with self._build_resources(context, instance,
1871                         requested_networks, security_groups, image_meta,
1872                         block_device_mapping) as resources:
1873                     instance.vm_state = vm_states.BUILDING
1874                     instance.task_state = task_states.SPAWNING
1875                     # NOTE(JoshNang) This also saves the changes to the
1876                     # instance from _allocate_network_async, as they aren't
1877                     # saved in that function to prevent races.
1878                     instance.save(expected_task_state=
1879                             task_states.BLOCK_DEVICE_MAPPING)
1880                     block_device_info = resources['block_device_info']
1881                     network_info = resources['network_info']
1882                     LOG.debug('Start spawning the instance on the hypervisor.',
1883                               instance=instance)
1884                     with timeutils.StopWatch() as timer:
1885                         self.driver.spawn(context, instance, image_meta,
1886                                           injected_files, admin_password,
1887                                           network_info=network_info,
1888                                           block_device_info=block_device_info)
1889                     LOG.info(_LI('Took %0.2f seconds to spawn the instance on '
1890                                  'the hypervisor.'), timer.elapsed(),
1891                              instance=instance)
1892         except (exception.InstanceNotFound,
1893                 exception.UnexpectedDeletingTaskStateError) as e:
1894             with excutils.save_and_reraise_exception():
1895                 self._notify_about_instance_usage(context, instance,
1896                     'create.end', fault=e)
1897         except exception.ComputeResourcesUnavailable as e:
1898             LOG.debug(e.format_message(), instance=instance)
1899             self._notify_about_instance_usage(context, instance,
1900                     'create.error', fault=e)
1901             raise exception.RescheduledException(
1902                     instance_uuid=instance.uuid, reason=e.format_message())
1903         except exception.BuildAbortException as e:
1904             with excutils.save_and_reraise_exception():
1905                 LOG.debug(e.format_message(), instance=instance)
1906                 self._notify_about_instance_usage(context, instance,
1907                     'create.error', fault=e)
1908         except (exception.FixedIpLimitExceeded,
1909                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
1910             LOG.warning(_LW('No more network or fixed IP to be allocated'),
1911                         instance=instance)
1912             self._notify_about_instance_usage(context, instance,
1913                     'create.error', fault=e)
1914             msg = _('Failed to allocate the network(s) with error %s, '
1915                     'not rescheduling.') % e.format_message()
1916             raise exception.BuildAbortException(instance_uuid=instance.uuid,
1917                     reason=msg)
1918         except (exception.VirtualInterfaceCreateException,
1919                 exception.VirtualInterfaceMacAddressException) as e:
1920             LOG.exception(_LE('Failed to allocate network(s)'),
1921                           instance=instance)
1922             self._notify_about_instance_usage(context, instance,
1923                     'create.error', fault=e)
1924             msg = _('Failed to allocate the network(s), not rescheduling.')
1925             raise exception.BuildAbortException(instance_uuid=instance.uuid,
1926                     reason=msg)
1927         except (exception.FlavorDiskTooSmall,
1928                 exception.FlavorMemoryTooSmall,
1929                 exception.ImageNotActive,
1930                 exception.ImageUnacceptable,
1931                 exception.InvalidDiskInfo) as e:
1932             self._notify_about_instance_usage(context, instance,
1933                     'create.error', fault=e)
1934             raise exception.BuildAbortException(instance_uuid=instance.uuid,
1935                     reason=e.format_message())
1936         except Exception as e:
1937             self._notify_about_instance_usage(context, instance,
1938                     'create.error', fault=e)
1939             raise exception.RescheduledException(
1940                     instance_uuid=instance.uuid, reason=six.text_type(e))
1941 
1942         # NOTE(alaski): This is only useful during reschedules, remove it now.
1943         instance.system_metadata.pop('network_allocated', None)
1944 
1945         # If CONF.default_access_ip_network_name is set, grab the
1946         # corresponding network and set the access ip values accordingly.
1947         network_name = CONF.default_access_ip_network_name
1948         if (network_name and not instance.access_ip_v4 and
1949                 not instance.access_ip_v6):
1950             # Note that when there are multiple ips to choose from, an
1951             # arbitrary one will be chosen.
1952             for vif in network_info:
1953                 if vif['network']['label'] == network_name:
1954                     for ip in vif.fixed_ips():
1955                         if not instance.access_ip_v4 and ip['version'] == 4:
1956                             instance.access_ip_v4 = ip['address']
1957                         if not instance.access_ip_v6 and ip['version'] == 6:
1958                             instance.access_ip_v6 = ip['address']
1959                     break
1960 
1961         self._update_instance_after_spawn(context, instance)
1962 
1963         try:
1964             instance.save(expected_task_state=task_states.SPAWNING)
1965         except (exception.InstanceNotFound,
1966                 exception.UnexpectedDeletingTaskStateError) as e:
1967             with excutils.save_and_reraise_exception():
1968                 self._notify_about_instance_usage(context, instance,
1969                     'create.end', fault=e)
1970 
1971         self._update_scheduler_instance_info(context, instance)
1972         self._notify_about_instance_usage(context, instance, 'create.end',
1973                 extra_usage_info={'message': _('Success')},
1974                 network_info=network_info)
1975 
1976     @contextlib.contextmanager
1977     def _build_resources(self, context, instance, requested_networks,
1978                          security_groups, image_meta, block_device_mapping):
1979         resources = {}
1980         network_info = None
1981         try:
1982             LOG.debug('Start building networks asynchronously for instance.',
1983                       instance=instance)
1984             network_info = self._build_networks_for_instance(context, instance,
1985                     requested_networks, security_groups)
1986             resources['network_info'] = network_info
1987         except (exception.InstanceNotFound,
1988                 exception.UnexpectedDeletingTaskStateError):
1989             raise
1990         except exception.UnexpectedTaskStateError as e:
1991             raise exception.BuildAbortException(instance_uuid=instance.uuid,
1992                     reason=e.format_message())
1993         except Exception:
1994             # Because this allocation is async any failures are likely to occur
1995             # when the driver accesses network_info during spawn().
1996             LOG.exception(_LE('Failed to allocate network(s)'),
1997                           instance=instance)
1998             msg = _('Failed to allocate the network(s), not rescheduling.')
1999             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2000                     reason=msg)
2001 
2002         try:
2003             # Verify that all the BDMs have a device_name set and assign a
2004             # default to the ones missing it with the help of the driver.
2005             self._default_block_device_names(context, instance, image_meta,
2006                     block_device_mapping)
2007 
2008             LOG.debug('Start building block device mappings for instance.',
2009                       instance=instance)
2010             instance.vm_state = vm_states.BUILDING
2011             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2012             instance.save()
2013 
2014             block_device_info = self._prep_block_device(context, instance,
2015                     block_device_mapping)
2016             resources['block_device_info'] = block_device_info
2017         except (exception.InstanceNotFound,
2018                 exception.UnexpectedDeletingTaskStateError):
2019             with excutils.save_and_reraise_exception():
2020                 # Make sure the async call finishes
2021                 if network_info is not None:
2022                     network_info.wait(do_raise=False)
2023         except (exception.UnexpectedTaskStateError,
2024                 exception.VolumeLimitExceeded,
2025                 exception.InvalidBDM) as e:
2026             # Make sure the async call finishes
2027             if network_info is not None:
2028                 network_info.wait(do_raise=False)
2029             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2030                     reason=e.format_message())
2031         except Exception:
2032             LOG.exception(_LE('Failure prepping block device'),
2033                     instance=instance)
2034             # Make sure the async call finishes
2035             if network_info is not None:
2036                 network_info.wait(do_raise=False)
2037             msg = _('Failure prepping block device.')
2038             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2039                     reason=msg)
2040 
2041         try:
2042             yield resources
2043         except Exception as exc:
2044             with excutils.save_and_reraise_exception() as ctxt:
2045                 if not isinstance(exc, (exception.InstanceNotFound,
2046                     exception.UnexpectedDeletingTaskStateError)):
2047                         LOG.exception(_LE('Instance failed to spawn'),
2048                                 instance=instance)
2049                 # Make sure the async call finishes
2050                 if network_info is not None:
2051                     network_info.wait(do_raise=False)
2052                 # if network_info is empty we're likely here because of
2053                 # network allocation failure. Since nothing can be reused on
2054                 # rescheduling it's better to deallocate network to eliminate
2055                 # the chance of orphaned ports in neutron
2056                 deallocate_networks = False if network_info else True
2057                 try:
2058                     self._shutdown_instance(context, instance,
2059                             block_device_mapping, requested_networks,
2060                             try_deallocate_networks=deallocate_networks)
2061                 except Exception as exc2:
2062                     ctxt.reraise = False
2063                     LOG.warning(_LW('Could not clean up failed build,'
2064                                     ' not rescheduling. Error: %s'),
2065                                 six.text_type(exc2))
2066                     raise exception.BuildAbortException(
2067                             instance_uuid=instance.uuid,
2068                             reason=six.text_type(exc))
2069 
2070     def _cleanup_allocated_networks(self, context, instance,
2071             requested_networks):
2072         try:
2073             self._deallocate_network(context, instance, requested_networks)
2074         except Exception:
2075             msg = _LE('Failed to deallocate networks')
2076             LOG.exception(msg, instance=instance)
2077             return
2078 
2079         instance.system_metadata['network_allocated'] = 'False'
2080         try:
2081             instance.save()
2082         except exception.InstanceNotFound:
2083             # NOTE(alaski): It's possible that we're cleaning up the networks
2084             # because the instance was deleted.  If that's the case then this
2085             # exception will be raised by instance.save()
2086             pass
2087 
2088     def _try_deallocate_network(self, context, instance,
2089                                 requested_networks=None):
2090         try:
2091             # tear down allocated network structure
2092             self._deallocate_network(context, instance, requested_networks)
2093         except Exception:
2094             with excutils.save_and_reraise_exception():
2095                 LOG.error(_LE('Failed to deallocate network for instance.'),
2096                           instance=instance)
2097                 self._set_instance_obj_error_state(context, instance)
2098 
2099     def _get_power_off_values(self, context, instance, clean_shutdown):
2100         """Get the timing configuration for powering down this instance."""
2101         if clean_shutdown:
2102             timeout = compute_utils.get_value_from_system_metadata(instance,
2103                           key='image_os_shutdown_timeout', type=int,
2104                           default=CONF.shutdown_timeout)
2105             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2106         else:
2107             timeout = 0
2108             retry_interval = 0
2109 
2110         return timeout, retry_interval
2111 
2112     def _power_off_instance(self, context, instance, clean_shutdown=True):
2113         """Power off an instance on this host."""
2114         timeout, retry_interval = self._get_power_off_values(context,
2115                                         instance, clean_shutdown)
2116         self.driver.power_off(instance, timeout, retry_interval)
2117 
2118     def _shutdown_instance(self, context, instance,
2119                            bdms, requested_networks=None, notify=True,
2120                            try_deallocate_networks=True):
2121         """Shutdown an instance on this host.
2122 
2123         :param:context: security context
2124         :param:instance: a nova.objects.Instance object
2125         :param:bdms: the block devices for the instance to be torn
2126                      down
2127         :param:requested_networks: the networks on which the instance
2128                                    has ports
2129         :param:notify: true if a final usage notification should be
2130                        emitted
2131         :param:try_deallocate_networks: false if we should avoid
2132                                         trying to teardown networking
2133         """
2134         context = context.elevated()
2135         LOG.info(_LI('Terminating instance'),
2136                  context=context, instance=instance)
2137 
2138         if notify:
2139             self._notify_about_instance_usage(context, instance,
2140                                               "shutdown.start")
2141 
2142         network_info = compute_utils.get_nw_info_for_instance(instance)
2143 
2144         # NOTE(vish) get bdms before destroying the instance
2145         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2146         block_device_info = self._get_instance_block_device_info(
2147             context, instance, bdms=bdms)
2148 
2149         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2150         #                want to keep ip allocated for certain failures
2151         timer = timeutils.StopWatch()
2152         try:
2153             LOG.debug('Start destroying the instance on the hypervisor.',
2154                       instance=instance)
2155             timer.start()
2156             self.driver.destroy(context, instance, network_info,
2157                     block_device_info)
2158             LOG.info(_LI('Took %0.2f seconds to destroy the instance on the '
2159                          'hypervisor.'), timer.elapsed(), instance=instance)
2160         except exception.InstancePowerOffFailure:
2161             # if the instance can't power off, don't release the ip
2162             with excutils.save_and_reraise_exception():
2163                 pass
2164         except Exception:
2165             with excutils.save_and_reraise_exception():
2166                 # deallocate ip and fail without proceeding to
2167                 # volume api calls, preserving current behavior
2168                 if try_deallocate_networks:
2169                     self._try_deallocate_network(context, instance,
2170                                                  requested_networks)
2171 
2172         if try_deallocate_networks:
2173             self._try_deallocate_network(context, instance, requested_networks)
2174 
2175         timer.restart()
2176         for bdm in vol_bdms:
2177             try:
2178                 # NOTE(vish): actual driver detach done in driver.destroy, so
2179                 #             just tell cinder that we are done with it.
2180                 connector = self.driver.get_volume_connector(instance)
2181                 self.volume_api.terminate_connection(context,
2182                                                      bdm.volume_id,
2183                                                      connector)
2184                 self.volume_api.detach(context, bdm.volume_id, instance.uuid)
2185             except exception.DiskNotFound as exc:
2186                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2187                           instance=instance)
2188             except exception.VolumeNotFound as exc:
2189                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2190                           instance=instance)
2191             except (cinder_exception.EndpointNotFound,
2192                     keystone_exception.EndpointNotFound) as exc:
2193                 LOG.warning(_LW('Ignoring EndpointNotFound for '
2194                                 'volume %(volume_id)s: %(exc)s'),
2195                             {'exc': exc, 'volume_id': bdm.volume_id},
2196                             instance=instance)
2197             except cinder_exception.ClientException as exc:
2198                 LOG.warning(_LW('Ignoring unknown cinder exception for '
2199                                 'volume %(volume_id)s: %(exc)s'),
2200                             {'exc': exc, 'volume_id': bdm.volume_id},
2201                             instance=instance)
2202             except Exception as exc:
2203                 LOG.warning(_LW('Ignoring unknown exception for '
2204                                 'volume %(volume_id)s: %(exc)s'),
2205                             {'exc': exc, 'volume_id': bdm.volume_id},
2206                             instance=instance)
2207         if vol_bdms:
2208             LOG.info(_LI('Took %(time).2f seconds to detach %(num)s volumes '
2209                          'for instance.'),
2210                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2211                      instance=instance)
2212 
2213         if notify:
2214             self._notify_about_instance_usage(context, instance,
2215                                               "shutdown.end")
2216 
2217     def _cleanup_volumes(self, context, instance_uuid, bdms, raise_exc=True):
2218         exc_info = None
2219 
2220         for bdm in bdms:
2221             LOG.debug("terminating bdm %s", bdm,
2222                       instance_uuid=instance_uuid)
2223             if bdm.volume_id and bdm.delete_on_termination:
2224                 try:
2225                     self.volume_api.delete(context, bdm.volume_id)
2226                 except Exception as exc:
2227                     exc_info = sys.exc_info()
2228                     LOG.warning(_LW('Failed to delete volume: %(volume_id)s '
2229                                     'due to %(exc)s'),
2230                                 {'volume_id': bdm.volume_id, 'exc': exc})
2231         if exc_info is not None and raise_exc:
2232             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2233 
2234     @hooks.add_hook("delete_instance")
2235     def _delete_instance(self, context, instance, bdms, quotas):
2236         """Delete an instance on this host.  Commit or rollback quotas
2237         as necessary.
2238 
2239         :param context: nova request context
2240         :param instance: nova.objects.instance.Instance object
2241         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2242         :param quotas: nova.objects.quotas.Quotas object
2243         """
2244         was_soft_deleted = instance.vm_state == vm_states.SOFT_DELETED
2245         if was_soft_deleted:
2246             # Instances in SOFT_DELETED vm_state have already had quotas
2247             # decremented.
2248             try:
2249                 quotas.rollback()
2250             except Exception:
2251                 pass
2252 
2253         try:
2254             events = self.instance_events.clear_events_for_instance(instance)
2255             if events:
2256                 LOG.debug('Events pending at deletion: %(events)s',
2257                           {'events': ','.join(events.keys())},
2258                           instance=instance)
2259             self._notify_about_instance_usage(context, instance,
2260                                               "delete.start")
2261             self._shutdown_instance(context, instance, bdms)
2262             # NOTE(dims): instance.info_cache.delete() should be called after
2263             # _shutdown_instance in the compute manager as shutdown calls
2264             # deallocate_for_instance so the info_cache is still needed
2265             # at this point.
2266             if instance.info_cache is not None:
2267                 instance.info_cache.delete()
2268             else:
2269                 # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2270                 # is None. When the root cause that instance.info_cache becomes
2271                 # None is fixed, the log level should be reconsidered.
2272                 LOG.warning(_LW("Info cache for instance could not be found. "
2273                                 "Ignore."), instance=instance)
2274 
2275             # NOTE(vish): We have already deleted the instance, so we have
2276             #             to ignore problems cleaning up the volumes. It
2277             #             would be nice to let the user know somehow that
2278             #             the volume deletion failed, but it is not
2279             #             acceptable to have an instance that can not be
2280             #             deleted. Perhaps this could be reworked in the
2281             #             future to set an instance fault the first time
2282             #             and to only ignore the failure if the instance
2283             #             is already in ERROR.
2284             self._cleanup_volumes(context, instance.uuid, bdms,
2285                     raise_exc=False)
2286             # if a delete task succeeded, always update vm state and task
2287             # state without expecting task state to be DELETING
2288             instance.vm_state = vm_states.DELETED
2289             instance.task_state = None
2290             instance.power_state = power_state.NOSTATE
2291             instance.terminated_at = timeutils.utcnow()
2292             instance.save()
2293             system_meta = instance.system_metadata
2294             instance.destroy()
2295         except Exception:
2296             with excutils.save_and_reraise_exception():
2297                 quotas.rollback()
2298 
2299         self._complete_deletion(context,
2300                                 instance,
2301                                 bdms,
2302                                 quotas,
2303                                 system_meta)
2304 
2305     @wrap_exception()
2306     @reverts_task_state
2307     @wrap_instance_event
2308     @wrap_instance_fault
2309     def terminate_instance(self, context, instance, bdms, reservations):
2310         """Terminate an instance on this host."""
2311         quotas = objects.Quotas.from_reservations(context,
2312                                                   reservations,
2313                                                   instance=instance)
2314 
2315         @utils.synchronized(instance.uuid)
2316         def do_terminate_instance(instance, bdms):
2317             # NOTE(mriedem): If we are deleting the instance while it was
2318             # booting from volume, we could be racing with a database update of
2319             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2320             # to compute here, the BDMs may be stale at this point. So check
2321             # for any volume BDMs that don't have volume_id set and if we
2322             # detect that, we need to refresh the BDM list before proceeding.
2323             # TODO(mriedem): Move this into _delete_instance and make the bdms
2324             # parameter optional.
2325             for bdm in list(bdms):
2326                 if bdm.is_volume and not bdm.volume_id:
2327                     LOG.debug('There are potentially stale BDMs during '
2328                               'delete, refreshing the BlockDeviceMappingList.',
2329                               instance=instance)
2330                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2331                         context, instance.uuid)
2332                     break
2333             try:
2334                 self._delete_instance(context, instance, bdms, quotas)
2335             except exception.InstanceNotFound:
2336                 LOG.info(_LI("Instance disappeared during terminate"),
2337                          instance=instance)
2338             except Exception:
2339                 # As we're trying to delete always go to Error if something
2340                 # goes wrong that _delete_instance can't handle.
2341                 with excutils.save_and_reraise_exception():
2342                     LOG.exception(_LE('Setting instance vm_state to ERROR'),
2343                                   instance=instance)
2344                     self._set_instance_obj_error_state(context, instance)
2345 
2346         do_terminate_instance(instance, bdms)
2347 
2348     # NOTE(johannes): This is probably better named power_off_instance
2349     # so it matches the driver method, but because of other issues, we
2350     # can't use that name in grizzly.
2351     @wrap_exception()
2352     @reverts_task_state
2353     @wrap_instance_event
2354     @wrap_instance_fault
2355     def stop_instance(self, context, instance, clean_shutdown):
2356         """Stopping an instance on this host."""
2357 
2358         @utils.synchronized(instance.uuid)
2359         def do_stop_instance():
2360             current_power_state = self._get_power_state(context, instance)
2361             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2362                       'current task_state: %(task_state)s, current DB '
2363                       'power_state: %(db_power_state)s, current VM '
2364                       'power_state: %(current_power_state)s',
2365                       {'vm_state': instance.vm_state,
2366                        'task_state': instance.task_state,
2367                        'db_power_state': instance.power_state,
2368                        'current_power_state': current_power_state},
2369                       instance_uuid=instance.uuid)
2370 
2371             # NOTE(mriedem): If the instance is already powered off, we are
2372             # possibly tearing down and racing with other operations, so we can
2373             # expect the task_state to be None if something else updates the
2374             # instance and we're not locking it.
2375             expected_task_state = [task_states.POWERING_OFF]
2376             # The list of power states is from _sync_instance_power_state.
2377             if current_power_state in (power_state.NOSTATE,
2378                                        power_state.SHUTDOWN,
2379                                        power_state.CRASHED):
2380                 LOG.info(_LI('Instance is already powered off in the '
2381                              'hypervisor when stop is called.'),
2382                          instance=instance)
2383                 expected_task_state.append(None)
2384 
2385             self._notify_about_instance_usage(context, instance,
2386                                               "power_off.start")
2387             self._power_off_instance(context, instance, clean_shutdown)
2388             instance.power_state = self._get_power_state(context, instance)
2389             instance.vm_state = vm_states.STOPPED
2390             instance.task_state = None
2391             instance.save(expected_task_state=expected_task_state)
2392             self._notify_about_instance_usage(context, instance,
2393                                               "power_off.end")
2394 
2395         do_stop_instance()
2396 
2397     def _power_on(self, context, instance):
2398         network_info = self.network_api.get_instance_nw_info(context, instance)
2399         block_device_info = self._get_instance_block_device_info(context,
2400                                                                  instance)
2401         self.driver.power_on(context, instance,
2402                              network_info,
2403                              block_device_info)
2404 
2405     def _delete_snapshot_of_shelved_instance(self, context, instance,
2406                                              snapshot_id):
2407         """Delete snapshot of shelved instance."""
2408         try:
2409             self.image_api.delete(context, snapshot_id)
2410         except (exception.ImageNotFound,
2411                 exception.ImageNotAuthorized) as exc:
2412             LOG.warning(_LW("Failed to delete snapshot "
2413                             "from shelved instance (%s)."),
2414                         exc.format_message(), instance=instance)
2415         except Exception:
2416             LOG.exception(_LE("Something wrong happened when trying to "
2417                               "delete snapshot from shelved instance."),
2418                           instance=instance)
2419 
2420     # NOTE(johannes): This is probably better named power_on_instance
2421     # so it matches the driver method, but because of other issues, we
2422     # can't use that name in grizzly.
2423     @wrap_exception()
2424     @reverts_task_state
2425     @wrap_instance_event
2426     @wrap_instance_fault
2427     def start_instance(self, context, instance):
2428         """Starting an instance on this host."""
2429         self._notify_about_instance_usage(context, instance, "power_on.start")
2430         self._power_on(context, instance)
2431         instance.power_state = self._get_power_state(context, instance)
2432         instance.vm_state = vm_states.ACTIVE
2433         instance.task_state = None
2434 
2435         # Delete an image(VM snapshot) for a shelved instance
2436         snapshot_id = instance.system_metadata.get('shelved_image_id')
2437         if snapshot_id:
2438             self._delete_snapshot_of_shelved_instance(context, instance,
2439                                                       snapshot_id)
2440 
2441         # Delete system_metadata for a shelved instance
2442         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2443 
2444         instance.save(expected_task_state=task_states.POWERING_ON)
2445         self._notify_about_instance_usage(context, instance, "power_on.end")
2446 
2447     @messaging.expected_exceptions(NotImplementedError,
2448                                    exception.TriggerCrashDumpNotSupported,
2449                                    exception.InstanceNotRunning)
2450     @wrap_exception()
2451     @wrap_instance_event
2452     @wrap_instance_fault
2453     def trigger_crash_dump(self, context, instance):
2454         """Trigger crash dump in an instance."""
2455 
2456         self._notify_about_instance_usage(context, instance,
2457                                           "trigger_crash_dump.start")
2458 
2459         # This method does not change task_state and power_state because the
2460         # effect of a trigger depends on user's configuration.
2461         self.driver.trigger_crash_dump(instance)
2462 
2463         self._notify_about_instance_usage(context, instance,
2464                                           "trigger_crash_dump.end")
2465 
2466     @wrap_exception()
2467     @reverts_task_state
2468     @wrap_instance_event
2469     @wrap_instance_fault
2470     def soft_delete_instance(self, context, instance, reservations):
2471         """Soft delete an instance on this host."""
2472 
2473         quotas = objects.Quotas.from_reservations(context,
2474                                                   reservations,
2475                                                   instance=instance)
2476         try:
2477             self._notify_about_instance_usage(context, instance,
2478                                               "soft_delete.start")
2479             try:
2480                 self.driver.soft_delete(instance)
2481             except NotImplementedError:
2482                 # Fallback to just powering off the instance if the
2483                 # hypervisor doesn't implement the soft_delete method
2484                 self.driver.power_off(instance)
2485             instance.power_state = self._get_power_state(context, instance)
2486             instance.vm_state = vm_states.SOFT_DELETED
2487             instance.task_state = None
2488             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2489         except Exception:
2490             with excutils.save_and_reraise_exception():
2491                 quotas.rollback()
2492         quotas.commit()
2493         self._notify_about_instance_usage(context, instance, "soft_delete.end")
2494 
2495     @wrap_exception()
2496     @reverts_task_state
2497     @wrap_instance_event
2498     @wrap_instance_fault
2499     def restore_instance(self, context, instance):
2500         """Restore a soft-deleted instance on this host."""
2501         self._notify_about_instance_usage(context, instance, "restore.start")
2502         try:
2503             self.driver.restore(instance)
2504         except NotImplementedError:
2505             # Fallback to just powering on the instance if the hypervisor
2506             # doesn't implement the restore method
2507             self._power_on(context, instance)
2508         instance.power_state = self._get_power_state(context, instance)
2509         instance.vm_state = vm_states.ACTIVE
2510         instance.task_state = None
2511         instance.save(expected_task_state=task_states.RESTORING)
2512         self._notify_about_instance_usage(context, instance, "restore.end")
2513 
2514     @staticmethod
2515     def _set_migration_status(migration, status):
2516         """Set the status, and guard against a None being passed in.
2517 
2518         This is useful as some of the compute RPC calls will not pass
2519         a migration object in older versions. The check can be removed when
2520         we move past 4.x major version of the RPC API.
2521         """
2522         if migration:
2523             migration.status = status
2524             migration.save()
2525 
2526     def _rebuild_default_impl(self, context, instance, image_meta,
2527                               injected_files, admin_password, bdms,
2528                               detach_block_devices, attach_block_devices,
2529                               network_info=None,
2530                               recreate=False, block_device_info=None,
2531                               preserve_ephemeral=False):
2532         if preserve_ephemeral:
2533             # The default code path does not support preserving ephemeral
2534             # partitions.
2535             raise exception.PreserveEphemeralNotSupported()
2536 
2537         if recreate:
2538             detach_block_devices(context, bdms)
2539         else:
2540             self._power_off_instance(context, instance, clean_shutdown=True)
2541             detach_block_devices(context, bdms)
2542             self.driver.destroy(context, instance,
2543                                 network_info=network_info,
2544                                 block_device_info=block_device_info)
2545 
2546         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2547         instance.save(expected_task_state=[task_states.REBUILDING])
2548 
2549         new_block_device_info = attach_block_devices(context, instance, bdms)
2550 
2551         instance.task_state = task_states.REBUILD_SPAWNING
2552         instance.save(
2553             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2554 
2555         with instance.mutated_migration_context():
2556             self.driver.spawn(context, instance, image_meta, injected_files,
2557                               admin_password, network_info=network_info,
2558                               block_device_info=new_block_device_info)
2559 
2560     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2561     @wrap_exception()
2562     @reverts_task_state
2563     @wrap_instance_event
2564     @wrap_instance_fault
2565     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2566                          injected_files, new_pass, orig_sys_metadata,
2567                          bdms, recreate, on_shared_storage=None,
2568                          preserve_ephemeral=False, migration=None,
2569                          scheduled_node=None, limits=None):
2570         """Destroy and re-make this instance.
2571 
2572         A 'rebuild' effectively purges all existing data from the system and
2573         remakes the VM with given 'metadata' and 'personalities'.
2574 
2575         :param context: `nova.RequestContext` object
2576         :param instance: Instance object
2577         :param orig_image_ref: Original image_ref before rebuild
2578         :param image_ref: New image_ref for rebuild
2579         :param injected_files: Files to inject
2580         :param new_pass: password to set on rebuilt instance
2581         :param orig_sys_metadata: instance system metadata from pre-rebuild
2582         :param bdms: block-device-mappings to use for rebuild
2583         :param recreate: True if the instance is being recreated (e.g. the
2584             hypervisor it was on failed) - cleanup of old state will be
2585             skipped.
2586         :param on_shared_storage: True if instance files on shared storage.
2587                                   If not provided then information from the
2588                                   driver will be used to decide if the instance
2589                                   files are available or not on the target host
2590         :param preserve_ephemeral: True if the default ephemeral storage
2591                                    partition must be preserved on rebuild
2592         :param migration: a Migration object if one was created for this
2593                           rebuild operation (if it's a part of evacaute)
2594         :param scheduled_node: A node of the host chosen by the scheduler. If a
2595                                host was specified by the user, this will be
2596                                None
2597         :param limits: Overcommit limits set by the scheduler. If a host was
2598                        specified by the user, this will be None
2599         """
2600         context = context.elevated()
2601 
2602         LOG.info(_LI("Rebuilding instance"), context=context,
2603                     instance=instance)
2604         if scheduled_node is not None:
2605             rt = self._get_resource_tracker(scheduled_node)
2606             rebuild_claim = rt.rebuild_claim
2607         else:
2608             rebuild_claim = claims.NopClaim
2609 
2610         image_meta = {}
2611         if image_ref:
2612             image_meta = self.image_api.get(context, image_ref)
2613 
2614         # NOTE(mriedem): On a recreate (evacuate), we need to update
2615         # the instance's host and node properties to reflect it's
2616         # destination node for the recreate.
2617         if not scheduled_node:
2618             try:
2619                 compute_node = self._get_compute_info(context, self.host)
2620                 scheduled_node = compute_node.hypervisor_hostname
2621             except exception.ComputeHostNotFound:
2622                 LOG.exception(_LE('Failed to get compute_info for %s'),
2623                                 self.host)
2624 
2625         with self._error_out_instance_on_exception(context, instance):
2626             try:
2627                 claim_ctxt = rebuild_claim(
2628                     context, instance, limits=limits, image_meta=image_meta,
2629                     migration=migration)
2630                 self._do_rebuild_instance_with_claim(
2631                     claim_ctxt, context, instance, orig_image_ref,
2632                     image_ref, injected_files, new_pass, orig_sys_metadata,
2633                     bdms, recreate, on_shared_storage, preserve_ephemeral)
2634             except exception.ComputeResourcesUnavailable as e:
2635                 LOG.debug("Could not rebuild instance on this host, not "
2636                           "enough resources available.", instance=instance)
2637 
2638                 # NOTE(ndipanov): We just abort the build for now and leave a
2639                 # migration record for potential cleanup later
2640                 self._set_migration_status(migration, 'failed')
2641 
2642                 self._notify_about_instance_usage(context, instance,
2643                         'rebuild.error', fault=e)
2644                 raise exception.BuildAbortException(
2645                     instance_uuid=instance.uuid, reason=e.format_message())
2646             except (exception.InstanceNotFound,
2647                     exception.UnexpectedDeletingTaskStateError) as e:
2648                 LOG.debug('Instance was deleted while rebuilding',
2649                           instance=instance)
2650                 self._set_migration_status(migration, 'failed')
2651                 self._notify_about_instance_usage(context, instance,
2652                         'rebuild.error', fault=e)
2653             except Exception as e:
2654                 self._set_migration_status(migration, 'failed')
2655                 self._notify_about_instance_usage(context, instance,
2656                         'rebuild.error', fault=e)
2657                 raise
2658             else:
2659                 instance.apply_migration_context()
2660                 # NOTE (ndipanov): This save will now update the host and node
2661                 # attributes making sure that next RT pass is consistent since
2662                 # it will be based on the instance and not the migration DB
2663                 # entry.
2664                 instance.host = self.host
2665                 instance.node = scheduled_node
2666                 instance.save()
2667                 instance.drop_migration_context()
2668 
2669                 # NOTE (ndipanov): Mark the migration as done only after we
2670                 # mark the instance as belonging to this host.
2671                 self._set_migration_status(migration, 'done')
2672 
2673     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2674         """Helper to avoid deep nesting in the top-level method."""
2675 
2676         with claim_context:
2677             self._do_rebuild_instance(*args, **kwargs)
2678 
2679     @staticmethod
2680     def _get_image_name(image_meta):
2681         if image_meta.obj_attr_is_set("name"):
2682             return image_meta.name
2683         else:
2684             return ''
2685 
2686     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2687                              image_ref, injected_files, new_pass,
2688                              orig_sys_metadata, bdms, recreate,
2689                              on_shared_storage, preserve_ephemeral):
2690         orig_vm_state = instance.vm_state
2691 
2692         if recreate:
2693             if not self.driver.capabilities["supports_recreate"]:
2694                 raise exception.InstanceRecreateNotSupported
2695 
2696             self._check_instance_exists(context, instance)
2697 
2698             if on_shared_storage is None:
2699                 LOG.debug('on_shared_storage is not provided, using driver'
2700                             'information to decide if the instance needs to'
2701                             'be recreated')
2702                 on_shared_storage = self.driver.instance_on_disk(instance)
2703 
2704             elif (on_shared_storage !=
2705                     self.driver.instance_on_disk(instance)):
2706                 # To cover case when admin expects that instance files are
2707                 # on shared storage, but not accessible and vice versa
2708                 raise exception.InvalidSharedStorage(
2709                         _("Invalid state of instance files on shared"
2710                             " storage"))
2711 
2712             if on_shared_storage:
2713                 LOG.info(_LI('disk on shared storage, recreating using'
2714                                 ' existing disk'))
2715             else:
2716                 image_ref = orig_image_ref = instance.image_ref
2717                 LOG.info(_LI("disk not on shared storage, rebuilding from:"
2718                                 " '%s'"), str(image_ref))
2719 
2720         if image_ref:
2721             image_meta = objects.ImageMeta.from_image_ref(
2722                 context, self.image_api, image_ref)
2723         else:
2724             image_meta = instance.image_meta
2725 
2726         # This instance.exists message should contain the original
2727         # image_ref, not the new one.  Since the DB has been updated
2728         # to point to the new one... we have to override it.
2729         # TODO(jaypipes): Move generate_image_url() into the nova.image.api
2730         orig_image_ref_url = glance.generate_image_url(orig_image_ref)
2731         extra_usage_info = {'image_ref_url': orig_image_ref_url}
2732         compute_utils.notify_usage_exists(
2733                 self.notifier, context, instance,
2734                 current_period=True, system_metadata=orig_sys_metadata,
2735                 extra_usage_info=extra_usage_info)
2736 
2737         # This message should contain the new image_ref
2738         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
2739         self._notify_about_instance_usage(context, instance,
2740                 "rebuild.start", extra_usage_info=extra_usage_info)
2741 
2742         instance.power_state = self._get_power_state(context, instance)
2743         instance.task_state = task_states.REBUILDING
2744         instance.save(expected_task_state=[task_states.REBUILDING])
2745 
2746         if recreate:
2747             # Needed for nova-network, does nothing for neutron
2748             self.network_api.setup_networks_on_host(
2749                     context, instance, self.host)
2750             # For nova-network this is needed to move floating IPs
2751             # For neutron this updates the host in the port binding
2752             # TODO(cfriesen): this network_api call and the one above
2753             # are so similar, we should really try to unify them.
2754             self.network_api.setup_instance_network_on_host(
2755                     context, instance, self.host)
2756 
2757         network_info = compute_utils.get_nw_info_for_instance(instance)
2758         if bdms is None:
2759             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2760                     context, instance.uuid)
2761 
2762         block_device_info = \
2763             self._get_instance_block_device_info(
2764                     context, instance, bdms=bdms)
2765 
2766         def detach_block_devices(context, bdms):
2767             for bdm in bdms:
2768                 if bdm.is_volume:
2769                     self._detach_volume(context, bdm.volume_id, instance,
2770                                         destroy_bdm=False)
2771 
2772         files = self._decode_files(injected_files)
2773 
2774         kwargs = dict(
2775             context=context,
2776             instance=instance,
2777             image_meta=image_meta,
2778             injected_files=files,
2779             admin_password=new_pass,
2780             bdms=bdms,
2781             detach_block_devices=detach_block_devices,
2782             attach_block_devices=self._prep_block_device,
2783             block_device_info=block_device_info,
2784             network_info=network_info,
2785             preserve_ephemeral=preserve_ephemeral,
2786             recreate=recreate)
2787         try:
2788             with instance.mutated_migration_context():
2789                 self.driver.rebuild(**kwargs)
2790         except NotImplementedError:
2791             # NOTE(rpodolyaka): driver doesn't provide specialized version
2792             # of rebuild, fall back to the default implementation
2793             self._rebuild_default_impl(**kwargs)
2794         self._update_instance_after_spawn(context, instance)
2795         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
2796 
2797         if orig_vm_state == vm_states.STOPPED:
2798             LOG.info(_LI("bringing vm to original state: '%s'"),
2799                         orig_vm_state, instance=instance)
2800             instance.vm_state = vm_states.ACTIVE
2801             instance.task_state = task_states.POWERING_OFF
2802             instance.progress = 0
2803             instance.save()
2804             self.stop_instance(context, instance, False)
2805         self._update_scheduler_instance_info(context, instance)
2806         self._notify_about_instance_usage(
2807                 context, instance, "rebuild.end",
2808                 network_info=network_info,
2809                 extra_usage_info=extra_usage_info)
2810 
2811     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
2812                                      block_device_info):
2813         """Handle cases where the virt-layer had to detach non-working volumes
2814         in order to complete an operation.
2815         """
2816         for bdm in block_device_info['block_device_mapping']:
2817             if bdm.get('mount_device') in bad_devices:
2818                 try:
2819                     volume_id = bdm['connection_info']['data']['volume_id']
2820                 except KeyError:
2821                     continue
2822 
2823                 # NOTE(sirp): ideally we'd just call
2824                 # `compute_api.detach_volume` here but since that hits the
2825                 # DB directly, that's off limits from within the
2826                 # compute-manager.
2827                 #
2828                 # API-detach
2829                 LOG.info(_LI("Detaching from volume api: %s"), volume_id)
2830                 volume = self.volume_api.get(context, volume_id)
2831                 self.volume_api.check_detach(context, volume)
2832                 self.volume_api.begin_detaching(context, volume_id)
2833 
2834                 # Manager-detach
2835                 self.detach_volume(context, volume_id, instance)
2836 
2837     @wrap_exception()
2838     @reverts_task_state
2839     @wrap_instance_event
2840     @wrap_instance_fault
2841     def reboot_instance(self, context, instance, block_device_info,
2842                         reboot_type):
2843         """Reboot an instance on this host."""
2844         # acknowledge the request made it to the manager
2845         if reboot_type == "SOFT":
2846             instance.task_state = task_states.REBOOT_PENDING
2847             expected_states = (task_states.REBOOTING,
2848                                task_states.REBOOT_PENDING,
2849                                task_states.REBOOT_STARTED)
2850         else:
2851             instance.task_state = task_states.REBOOT_PENDING_HARD
2852             expected_states = (task_states.REBOOTING_HARD,
2853                                task_states.REBOOT_PENDING_HARD,
2854                                task_states.REBOOT_STARTED_HARD)
2855         context = context.elevated()
2856         LOG.info(_LI("Rebooting instance"), context=context, instance=instance)
2857 
2858         block_device_info = self._get_instance_block_device_info(context,
2859                                                                  instance)
2860 
2861         network_info = self.network_api.get_instance_nw_info(context, instance)
2862 
2863         self._notify_about_instance_usage(context, instance, "reboot.start")
2864 
2865         instance.power_state = self._get_power_state(context, instance)
2866         instance.save(expected_task_state=expected_states)
2867 
2868         if instance.power_state != power_state.RUNNING:
2869             state = instance.power_state
2870             running = power_state.RUNNING
2871             LOG.warning(_LW('trying to reboot a non-running instance:'
2872                             ' (state: %(state)s expected: %(running)s)'),
2873                         {'state': state, 'running': running},
2874                         context=context, instance=instance)
2875 
2876         def bad_volumes_callback(bad_devices):
2877             self._handle_bad_volumes_detached(
2878                     context, instance, bad_devices, block_device_info)
2879 
2880         try:
2881             # Don't change it out of rescue mode
2882             if instance.vm_state == vm_states.RESCUED:
2883                 new_vm_state = vm_states.RESCUED
2884             else:
2885                 new_vm_state = vm_states.ACTIVE
2886             new_power_state = None
2887             if reboot_type == "SOFT":
2888                 instance.task_state = task_states.REBOOT_STARTED
2889                 expected_state = task_states.REBOOT_PENDING
2890             else:
2891                 instance.task_state = task_states.REBOOT_STARTED_HARD
2892                 expected_state = task_states.REBOOT_PENDING_HARD
2893             instance.save(expected_task_state=expected_state)
2894             self.driver.reboot(context, instance,
2895                                network_info,
2896                                reboot_type,
2897                                block_device_info=block_device_info,
2898                                bad_volumes_callback=bad_volumes_callback)
2899 
2900         except Exception as error:
2901             with excutils.save_and_reraise_exception() as ctxt:
2902                 exc_info = sys.exc_info()
2903                 # if the reboot failed but the VM is running don't
2904                 # put it into an error state
2905                 new_power_state = self._get_power_state(context, instance)
2906                 if new_power_state == power_state.RUNNING:
2907                     LOG.warning(_LW('Reboot failed but instance is running'),
2908                                 context=context, instance=instance)
2909                     compute_utils.add_instance_fault_from_exc(context,
2910                             instance, error, exc_info)
2911                     self._notify_about_instance_usage(context, instance,
2912                             'reboot.error', fault=error)
2913                     ctxt.reraise = False
2914                 else:
2915                     LOG.error(_LE('Cannot reboot instance: %s'), error,
2916                               context=context, instance=instance)
2917                     self._set_instance_obj_error_state(context, instance)
2918 
2919         if not new_power_state:
2920             new_power_state = self._get_power_state(context, instance)
2921         try:
2922             instance.power_state = new_power_state
2923             instance.vm_state = new_vm_state
2924             instance.task_state = None
2925             instance.save()
2926         except exception.InstanceNotFound:
2927             LOG.warning(_LW("Instance disappeared during reboot"),
2928                         context=context, instance=instance)
2929 
2930         self._notify_about_instance_usage(context, instance, "reboot.end")
2931 
2932     @delete_image_on_error
2933     def _do_snapshot_instance(self, context, image_id, instance):
2934         self._snapshot_instance(context, image_id, instance,
2935                                 task_states.IMAGE_BACKUP)
2936 
2937     @wrap_exception()
2938     @reverts_task_state
2939     @wrap_instance_fault
2940     def backup_instance(self, context, image_id, instance, backup_type,
2941                         rotation):
2942         """Backup an instance on this host.
2943 
2944         :param backup_type: daily | weekly
2945         :param rotation: int representing how many backups to keep around
2946         """
2947         self._do_snapshot_instance(context, image_id, instance)
2948         self._rotate_backups(context, instance, backup_type, rotation)
2949 
2950     @wrap_exception()
2951     @reverts_task_state
2952     @wrap_instance_fault
2953     @delete_image_on_error
2954     def snapshot_instance(self, context, image_id, instance):
2955         """Snapshot an instance on this host.
2956 
2957         :param context: security context
2958         :param instance: a nova.objects.instance.Instance object
2959         :param image_id: glance.db.sqlalchemy.models.Image.Id
2960         """
2961         # NOTE(dave-mcnally) the task state will already be set by the api
2962         # but if the compute manager has crashed/been restarted prior to the
2963         # request getting here the task state may have been cleared so we set
2964         # it again and things continue normally
2965         try:
2966             instance.task_state = task_states.IMAGE_SNAPSHOT
2967             instance.save(
2968                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
2969         except exception.InstanceNotFound:
2970             # possibility instance no longer exists, no point in continuing
2971             LOG.debug("Instance not found, could not set state %s "
2972                       "for instance.",
2973                       task_states.IMAGE_SNAPSHOT, instance=instance)
2974             return
2975 
2976         except exception.UnexpectedDeletingTaskStateError:
2977             LOG.debug("Instance being deleted, snapshot cannot continue",
2978                       instance=instance)
2979             return
2980 
2981         self._snapshot_instance(context, image_id, instance,
2982                                 task_states.IMAGE_SNAPSHOT)
2983 
2984     def _snapshot_instance(self, context, image_id, instance,
2985                            expected_task_state):
2986         context = context.elevated()
2987 
2988         instance.power_state = self._get_power_state(context, instance)
2989         try:
2990             instance.save()
2991 
2992             LOG.info(_LI('instance snapshotting'), context=context,
2993                   instance=instance)
2994 
2995             if instance.power_state != power_state.RUNNING:
2996                 state = instance.power_state
2997                 running = power_state.RUNNING
2998                 LOG.warning(_LW('trying to snapshot a non-running instance: '
2999                                 '(state: %(state)s expected: %(running)s)'),
3000                             {'state': state, 'running': running},
3001                             instance=instance)
3002 
3003             self._notify_about_instance_usage(
3004                 context, instance, "snapshot.start")
3005 
3006             def update_task_state(task_state,
3007                                   expected_state=expected_task_state):
3008                 instance.task_state = task_state
3009                 instance.save(expected_task_state=expected_state)
3010 
3011             self.driver.snapshot(context, instance, image_id,
3012                                  update_task_state)
3013 
3014             instance.task_state = None
3015             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3016 
3017             self._notify_about_instance_usage(context, instance,
3018                                               "snapshot.end")
3019         except (exception.InstanceNotFound,
3020                 exception.UnexpectedDeletingTaskStateError):
3021             # the instance got deleted during the snapshot
3022             # Quickly bail out of here
3023             msg = 'Instance disappeared during snapshot'
3024             LOG.debug(msg, instance=instance)
3025             try:
3026                 image_service = glance.get_default_image_service()
3027                 image = image_service.show(context, image_id)
3028                 if image['status'] != 'active':
3029                     image_service.delete(context, image_id)
3030             except Exception:
3031                 LOG.warning(_LW("Error while trying to clean up image %s"),
3032                             image_id, instance=instance)
3033         except exception.ImageNotFound:
3034             instance.task_state = None
3035             instance.save()
3036             msg = _LW("Image not found during snapshot")
3037             LOG.warning(msg, instance=instance)
3038 
3039     def _post_interrupted_snapshot_cleanup(self, context, instance):
3040         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3041 
3042     @messaging.expected_exceptions(NotImplementedError)
3043     @wrap_exception()
3044     def volume_snapshot_create(self, context, instance, volume_id,
3045                                create_info):
3046         self.driver.volume_snapshot_create(context, instance, volume_id,
3047                                            create_info)
3048 
3049     @messaging.expected_exceptions(NotImplementedError)
3050     @wrap_exception()
3051     def volume_snapshot_delete(self, context, instance, volume_id,
3052                                snapshot_id, delete_info):
3053         self.driver.volume_snapshot_delete(context, instance, volume_id,
3054                                            snapshot_id, delete_info)
3055 
3056     @wrap_instance_fault
3057     def _rotate_backups(self, context, instance, backup_type, rotation):
3058         """Delete excess backups associated to an instance.
3059 
3060         Instances are allowed a fixed number of backups (the rotation number);
3061         this method deletes the oldest backups that exceed the rotation
3062         threshold.
3063 
3064         :param context: security context
3065         :param instance: Instance dict
3066         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3067         :param rotation: int representing how many backups to keep around;
3068             None if rotation shouldn't be used (as in the case of snapshots)
3069         """
3070         filters = {'property-image_type': 'backup',
3071                    'property-backup_type': backup_type,
3072                    'property-instance_uuid': instance.uuid}
3073 
3074         images = self.image_api.get_all(context, filters=filters,
3075                                         sort_key='created_at', sort_dir='desc')
3076         num_images = len(images)
3077         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3078                   {'num_images': num_images, 'rotation': rotation},
3079                   instance=instance)
3080 
3081         if num_images > rotation:
3082             # NOTE(sirp): this deletes all backups that exceed the rotation
3083             # limit
3084             excess = len(images) - rotation
3085             LOG.debug("Rotating out %d backups", excess,
3086                       instance=instance)
3087             for i in range(excess):
3088                 image = images.pop()
3089                 image_id = image['id']
3090                 LOG.debug("Deleting image %s", image_id,
3091                           instance=instance)
3092                 self.image_api.delete(context, image_id)
3093 
3094     @wrap_exception()
3095     @reverts_task_state
3096     @wrap_instance_event
3097     @wrap_instance_fault
3098     def set_admin_password(self, context, instance, new_pass):
3099         """Set the root/admin password for an instance on this host.
3100 
3101         This is generally only called by API password resets after an
3102         image has been built.
3103 
3104         @param context: Nova auth context.
3105         @param instance: Nova instance object.
3106         @param new_pass: The admin password for the instance.
3107         """
3108 
3109         context = context.elevated()
3110         if new_pass is None:
3111             # Generate a random password
3112             new_pass = utils.generate_password()
3113 
3114         current_power_state = self._get_power_state(context, instance)
3115         expected_state = power_state.RUNNING
3116 
3117         if current_power_state != expected_state:
3118             instance.task_state = None
3119             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3120             _msg = _('instance %s is not running') % instance.uuid
3121             raise exception.InstancePasswordSetFailed(
3122                 instance=instance.uuid, reason=_msg)
3123 
3124         try:
3125             self.driver.set_admin_password(instance, new_pass)
3126             LOG.info(_LI("Root password set"), instance=instance)
3127             instance.task_state = None
3128             instance.save(
3129                 expected_task_state=task_states.UPDATING_PASSWORD)
3130         except NotImplementedError:
3131             LOG.warning(_LW('set_admin_password is not implemented '
3132                             'by this driver or guest instance.'),
3133                         instance=instance)
3134             instance.task_state = None
3135             instance.save(
3136                 expected_task_state=task_states.UPDATING_PASSWORD)
3137             raise NotImplementedError(_('set_admin_password is not '
3138                                         'implemented by this driver or guest '
3139                                         'instance.'))
3140         except exception.UnexpectedTaskStateError:
3141             # interrupted by another (most likely delete) task
3142             # do not retry
3143             raise
3144         except Exception:
3145             # Catch all here because this could be anything.
3146             LOG.exception(_LE('set_admin_password failed'),
3147                           instance=instance)
3148             self._set_instance_obj_error_state(context, instance)
3149             # We create a new exception here so that we won't
3150             # potentially reveal password information to the
3151             # API caller.  The real exception is logged above
3152             _msg = _('error setting admin password')
3153             raise exception.InstancePasswordSetFailed(
3154                 instance=instance.uuid, reason=_msg)
3155 
3156     @wrap_exception()
3157     @reverts_task_state
3158     @wrap_instance_fault
3159     def inject_file(self, context, path, file_contents, instance):
3160         """Write a file to the specified path in an instance on this host."""
3161         # NOTE(russellb) Remove this method, as well as the underlying virt
3162         # driver methods, when the compute rpc interface is bumped to 4.x
3163         # as it is no longer used.
3164         context = context.elevated()
3165         current_power_state = self._get_power_state(context, instance)
3166         expected_state = power_state.RUNNING
3167         if current_power_state != expected_state:
3168             LOG.warning(_LW('trying to inject a file into a non-running '
3169                             '(state: %(current_state)s expected: '
3170                             '%(expected_state)s)'),
3171                         {'current_state': current_power_state,
3172                          'expected_state': expected_state},
3173                         instance=instance)
3174         LOG.info(_LI('injecting file to %s'), path,
3175                     instance=instance)
3176         self.driver.inject_file(instance, path, file_contents)
3177 
3178     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3179         """Determine what image should be used to boot the rescue VM."""
3180         # 1. If rescue_image_ref is passed in, use that for rescue.
3181         # 2. Else, use the base image associated with instance's current image.
3182         #       The idea here is to provide the customer with a rescue
3183         #       environment which they are familiar with.
3184         #       So, if they built their instance off of a Debian image,
3185         #       their rescue VM will also be Debian.
3186         # 3. As a last resort, use instance's current image.
3187         if not rescue_image_ref:
3188             system_meta = utils.instance_sys_meta(instance)
3189             rescue_image_ref = system_meta.get('image_base_image_ref')
3190 
3191         if not rescue_image_ref:
3192             LOG.warning(_LW('Unable to find a different image to use for '
3193                             'rescue VM, using instance\'s current image'),
3194                         instance=instance)
3195             rescue_image_ref = instance.image_ref
3196 
3197         return objects.ImageMeta.from_image_ref(
3198             context, self.image_api, rescue_image_ref)
3199 
3200     @wrap_exception()
3201     @reverts_task_state
3202     @wrap_instance_event
3203     @wrap_instance_fault
3204     def rescue_instance(self, context, instance, rescue_password,
3205                         rescue_image_ref, clean_shutdown):
3206         context = context.elevated()
3207         LOG.info(_LI('Rescuing'), context=context, instance=instance)
3208 
3209         admin_password = (rescue_password if rescue_password else
3210                       utils.generate_password())
3211 
3212         network_info = self.network_api.get_instance_nw_info(context, instance)
3213 
3214         rescue_image_meta = self._get_rescue_image(context, instance,
3215                                                    rescue_image_ref)
3216 
3217         extra_usage_info = {'rescue_image_name':
3218                             self._get_image_name(rescue_image_meta)}
3219         self._notify_about_instance_usage(context, instance,
3220                 "rescue.start", extra_usage_info=extra_usage_info,
3221                 network_info=network_info)
3222 
3223         try:
3224             self._power_off_instance(context, instance, clean_shutdown)
3225 
3226             self.driver.rescue(context, instance,
3227                                network_info,
3228                                rescue_image_meta, admin_password)
3229         except Exception as e:
3230             LOG.exception(_LE("Error trying to Rescue Instance"),
3231                           instance=instance)
3232             self._set_instance_obj_error_state(context, instance)
3233             raise exception.InstanceNotRescuable(
3234                 instance_id=instance.uuid,
3235                 reason=_("Driver Error: %s") % e)
3236 
3237         compute_utils.notify_usage_exists(self.notifier, context, instance,
3238                                           current_period=True)
3239 
3240         instance.vm_state = vm_states.RESCUED
3241         instance.task_state = None
3242         instance.power_state = self._get_power_state(context, instance)
3243         instance.launched_at = timeutils.utcnow()
3244         instance.save(expected_task_state=task_states.RESCUING)
3245 
3246         self._notify_about_instance_usage(context, instance,
3247                 "rescue.end", extra_usage_info=extra_usage_info,
3248                 network_info=network_info)
3249 
3250     @wrap_exception()
3251     @reverts_task_state
3252     @wrap_instance_event
3253     @wrap_instance_fault
3254     def unrescue_instance(self, context, instance):
3255         context = context.elevated()
3256         LOG.info(_LI('Unrescuing'), context=context, instance=instance)
3257 
3258         network_info = self.network_api.get_instance_nw_info(context, instance)
3259         self._notify_about_instance_usage(context, instance,
3260                 "unrescue.start", network_info=network_info)
3261         with self._error_out_instance_on_exception(context, instance):
3262             self.driver.unrescue(instance,
3263                                  network_info)
3264 
3265         instance.vm_state = vm_states.ACTIVE
3266         instance.task_state = None
3267         instance.power_state = self._get_power_state(context, instance)
3268         instance.save(expected_task_state=task_states.UNRESCUING)
3269 
3270         self._notify_about_instance_usage(context,
3271                                           instance,
3272                                           "unrescue.end",
3273                                           network_info=network_info)
3274 
3275     @wrap_exception()
3276     @wrap_instance_fault
3277     def change_instance_metadata(self, context, diff, instance):
3278         """Update the metadata published to the instance."""
3279         LOG.debug("Changing instance metadata according to %r",
3280                   diff, instance=instance)
3281         self.driver.change_instance_metadata(context, instance, diff)
3282 
3283     @wrap_exception()
3284     @wrap_instance_event
3285     @wrap_instance_fault
3286     def confirm_resize(self, context, instance, reservations, migration):
3287 
3288         quotas = objects.Quotas.from_reservations(context,
3289                                                   reservations,
3290                                                   instance=instance)
3291 
3292         @utils.synchronized(instance.uuid)
3293         def do_confirm_resize(context, instance, migration_id):
3294             # NOTE(wangpan): Get the migration status from db, if it has been
3295             #                confirmed, we do nothing and return here
3296             LOG.debug("Going to confirm migration %s", migration_id,
3297                       context=context, instance=instance)
3298             try:
3299                 # TODO(russellb) Why are we sending the migration object just
3300                 # to turn around and look it up from the db again?
3301                 migration = objects.Migration.get_by_id(
3302                                     context.elevated(), migration_id)
3303             except exception.MigrationNotFound:
3304                 LOG.error(_LE("Migration %s is not found during confirmation"),
3305                           migration_id, context=context, instance=instance)
3306                 quotas.rollback()
3307                 return
3308 
3309             if migration.status == 'confirmed':
3310                 LOG.info(_LI("Migration %s is already confirmed"),
3311                          migration_id, context=context, instance=instance)
3312                 quotas.rollback()
3313                 return
3314             elif migration.status not in ('finished', 'confirming'):
3315                 LOG.warning(_LW("Unexpected confirmation status '%(status)s' "
3316                                 "of migration %(id)s, exit confirmation "
3317                                 "process"),
3318                             {"status": migration.status, "id": migration_id},
3319                             context=context, instance=instance)
3320                 quotas.rollback()
3321                 return
3322 
3323             # NOTE(wangpan): Get the instance from db, if it has been
3324             #                deleted, we do nothing and return here
3325             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3326             try:
3327                 instance = objects.Instance.get_by_uuid(
3328                         context, instance.uuid,
3329                         expected_attrs=expected_attrs)
3330             except exception.InstanceNotFound:
3331                 LOG.info(_LI("Instance is not found during confirmation"),
3332                          context=context, instance=instance)
3333                 quotas.rollback()
3334                 return
3335 
3336             self._confirm_resize(context, instance, quotas,
3337                                  migration=migration)
3338 
3339         do_confirm_resize(context, instance, migration.id)
3340 
3341     def _confirm_resize(self, context, instance, quotas,
3342                         migration=None):
3343         """Destroys the source instance."""
3344         self._notify_about_instance_usage(context, instance,
3345                                           "resize.confirm.start")
3346 
3347         with self._error_out_instance_on_exception(context, instance,
3348                                                    quotas=quotas):
3349             # NOTE(danms): delete stashed migration information
3350             old_instance_type = instance.old_flavor
3351             instance.old_flavor = None
3352             instance.new_flavor = None
3353             instance.system_metadata.pop('old_vm_state', None)
3354             instance.save()
3355 
3356             # NOTE(tr3buchet): tear down networks on source host
3357             self.network_api.setup_networks_on_host(context, instance,
3358                                migration.source_compute, teardown=True)
3359 
3360             network_info = self.network_api.get_instance_nw_info(context,
3361                                                                  instance)
3362             self.driver.confirm_migration(migration, instance,
3363                                           network_info)
3364 
3365             migration.status = 'confirmed'
3366             with migration.obj_as_admin():
3367                 migration.save()
3368 
3369             rt = self._get_resource_tracker(migration.source_node)
3370             rt.drop_move_claim(context, instance, old_instance_type)
3371 
3372             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3373             # might have manually powered up the instance to confirm the
3374             # resize/migrate, so we need to check the current power state
3375             # on the instance and set the vm_state appropriately. We default
3376             # to ACTIVE because if the power state is not SHUTDOWN, we
3377             # assume _sync_instance_power_state will clean it up.
3378             p_state = instance.power_state
3379             vm_state = None
3380             if p_state == power_state.SHUTDOWN:
3381                 vm_state = vm_states.STOPPED
3382                 LOG.debug("Resized/migrated instance is powered off. "
3383                           "Setting vm_state to '%s'.", vm_state,
3384                           instance=instance)
3385             else:
3386                 vm_state = vm_states.ACTIVE
3387 
3388             instance.vm_state = vm_state
3389             instance.task_state = None
3390             instance.save(expected_task_state=[None, task_states.DELETING])
3391 
3392             self._notify_about_instance_usage(
3393                 context, instance, "resize.confirm.end",
3394                 network_info=network_info)
3395 
3396             quotas.commit()
3397 
3398     @wrap_exception()
3399     @reverts_task_state
3400     @wrap_instance_event
3401     @errors_out_migration
3402     @wrap_instance_fault
3403     def revert_resize(self, context, instance, migration, reservations):
3404         """Destroys the new instance on the destination machine.
3405 
3406         Reverts the model changes, and powers on the old instance on the
3407         source machine.
3408 
3409         """
3410 
3411         quotas = objects.Quotas.from_reservations(context,
3412                                                   reservations,
3413                                                   instance=instance)
3414 
3415         # NOTE(comstud): A revert_resize is essentially a resize back to
3416         # the old size, so we need to send a usage event here.
3417         compute_utils.notify_usage_exists(self.notifier, context, instance,
3418                                           current_period=True)
3419 
3420         with self._error_out_instance_on_exception(context, instance,
3421                                                    quotas=quotas):
3422             # NOTE(tr3buchet): tear down networks on destination host
3423             self.network_api.setup_networks_on_host(context, instance,
3424                                                     teardown=True)
3425 
3426             migration_p = obj_base.obj_to_primitive(migration)
3427             self.network_api.migrate_instance_start(context,
3428                                                     instance,
3429                                                     migration_p)
3430 
3431             network_info = self.network_api.get_instance_nw_info(context,
3432                                                                  instance)
3433             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3434                     context, instance.uuid)
3435             block_device_info = self._get_instance_block_device_info(
3436                                 context, instance, bdms=bdms)
3437 
3438             destroy_disks = not self._is_instance_storage_shared(
3439                 context, instance, host=migration.source_compute)
3440             self.driver.destroy(context, instance, network_info,
3441                                 block_device_info, destroy_disks)
3442 
3443             self._terminate_volume_connections(context, instance, bdms)
3444 
3445             migration.status = 'reverted'
3446             with migration.obj_as_admin():
3447                 migration.save()
3448 
3449             # NOTE(ndipanov): We need to do this here because dropping the
3450             # claim means we lose the migration_context data. We really should
3451             # fix this by moving the drop_move_claim call to the
3452             # finish_revert_resize method as this is racy (revert is dropped,
3453             # but instance resources will be tracked with the new flavor until
3454             # it gets rolled back in finish_revert_resize, which is
3455             # potentially wrong for a period of time).
3456             instance.revert_migration_context()
3457             instance.save()
3458 
3459             rt = self._get_resource_tracker(instance.node)
3460             rt.drop_move_claim(context, instance)
3461 
3462             self.compute_rpcapi.finish_revert_resize(context, instance,
3463                     migration, migration.source_compute,
3464                     quotas.reservations)
3465 
3466     @wrap_exception()
3467     @reverts_task_state
3468     @wrap_instance_event
3469     @errors_out_migration
3470     @wrap_instance_fault
3471     def finish_revert_resize(self, context, instance, reservations, migration):
3472         """Finishes the second half of reverting a resize.
3473 
3474         Bring the original source instance state back (active/shutoff) and
3475         revert the resized attributes in the database.
3476 
3477         """
3478 
3479         quotas = objects.Quotas.from_reservations(context,
3480                                                   reservations,
3481                                                   instance=instance)
3482 
3483         with self._error_out_instance_on_exception(context, instance,
3484                                                    quotas=quotas):
3485             network_info = self.network_api.get_instance_nw_info(context,
3486                                                                  instance)
3487 
3488             self._notify_about_instance_usage(
3489                     context, instance, "resize.revert.start")
3490 
3491             # NOTE(mriedem): delete stashed old_vm_state information; we
3492             # default to ACTIVE for backwards compatibility if old_vm_state
3493             # is not set
3494             old_vm_state = instance.system_metadata.pop('old_vm_state',
3495                                                         vm_states.ACTIVE)
3496 
3497             self._set_instance_info(instance, instance.old_flavor)
3498             instance.old_flavor = None
3499             instance.new_flavor = None
3500             instance.host = migration.source_compute
3501             instance.node = migration.source_node
3502             instance.save()
3503 
3504             migration.dest_compute = migration.source_compute
3505             with migration.obj_as_admin():
3506                 migration.save()
3507 
3508             self.network_api.setup_networks_on_host(context, instance,
3509                                                     migration.source_compute)
3510 
3511             block_device_info = self._get_instance_block_device_info(
3512                     context, instance, refresh_conn_info=True)
3513 
3514             power_on = old_vm_state != vm_states.STOPPED
3515             self.driver.finish_revert_migration(context, instance,
3516                                        network_info,
3517                                        block_device_info, power_on)
3518 
3519             instance.launched_at = timeutils.utcnow()
3520             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
3521 
3522             migration_p = obj_base.obj_to_primitive(migration)
3523             self.network_api.migrate_instance_finish(context,
3524                                                      instance,
3525                                                      migration_p)
3526 
3527             # if the original vm state was STOPPED, set it back to STOPPED
3528             LOG.info(_LI("Updating instance to original state: '%s'"),
3529                      old_vm_state, instance=instance)
3530             if power_on:
3531                 instance.vm_state = vm_states.ACTIVE
3532                 instance.task_state = None
3533                 instance.save()
3534             else:
3535                 instance.task_state = task_states.POWERING_OFF
3536                 instance.save()
3537                 self.stop_instance(context, instance=instance,
3538                                    clean_shutdown=True)
3539 
3540             self._notify_about_instance_usage(
3541                     context, instance, "resize.revert.end")
3542             quotas.commit()
3543 
3544     def _prep_resize(self, context, image, instance, instance_type,
3545             quotas, request_spec, filter_properties, node,
3546             clean_shutdown=True):
3547 
3548         if not filter_properties:
3549             filter_properties = {}
3550 
3551         if not instance.host:
3552             self._set_instance_obj_error_state(context, instance)
3553             msg = _('Instance has no source host')
3554             raise exception.MigrationError(reason=msg)
3555 
3556         same_host = instance.host == self.host
3557         # if the flavor IDs match, it's migrate; otherwise resize
3558         if same_host and instance_type.id == instance['instance_type_id']:
3559             # check driver whether support migrate to same host
3560             if not self.driver.capabilities['supports_migrate_to_same_host']:
3561                 raise exception.UnableToMigrateToSelf(
3562                     instance_id=instance.uuid, host=self.host)
3563 
3564         # NOTE(danms): Stash the new instance_type to avoid having to
3565         # look it up in the database later
3566         instance.new_flavor = instance_type
3567         # NOTE(mriedem): Stash the old vm_state so we can set the
3568         # resized/reverted instance back to the same state later.
3569         vm_state = instance.vm_state
3570         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
3571         instance.system_metadata['old_vm_state'] = vm_state
3572         instance.save()
3573 
3574         limits = filter_properties.get('limits', {})
3575         rt = self._get_resource_tracker(node)
3576         with rt.resize_claim(context, instance, instance_type,
3577                              image_meta=image, limits=limits) as claim:
3578             LOG.info(_LI('Migrating'), context=context, instance=instance)
3579             self.compute_rpcapi.resize_instance(
3580                     context, instance, claim.migration, image,
3581                     instance_type, quotas.reservations,
3582                     clean_shutdown)
3583 
3584     @wrap_exception()
3585     @reverts_task_state
3586     @wrap_instance_event
3587     @wrap_instance_fault
3588     def prep_resize(self, context, image, instance, instance_type,
3589                     reservations, request_spec, filter_properties, node,
3590                     clean_shutdown):
3591         """Initiates the process of moving a running instance to another host.
3592 
3593         Possibly changes the RAM and disk size in the process.
3594 
3595         """
3596         if node is None:
3597             node = self.driver.get_available_nodes(refresh=True)[0]
3598             LOG.debug("No node specified, defaulting to %s", node,
3599                       instance=instance)
3600 
3601         # NOTE(melwitt): Remove this in version 5.0 of the RPC API
3602         # Code downstream may expect extra_specs to be populated since it
3603         # is receiving an object, so lookup the flavor to ensure this.
3604         if not isinstance(instance_type, objects.Flavor):
3605             instance_type = objects.Flavor.get_by_id(context,
3606                                                      instance_type['id'])
3607 
3608         quotas = objects.Quotas.from_reservations(context,
3609                                                   reservations,
3610                                                   instance=instance)
3611         with self._error_out_instance_on_exception(context, instance,
3612                                                    quotas=quotas):
3613             compute_utils.notify_usage_exists(self.notifier, context, instance,
3614                                               current_period=True)
3615             self._notify_about_instance_usage(
3616                     context, instance, "resize.prep.start")
3617             try:
3618                 self._prep_resize(context, image, instance,
3619                                   instance_type, quotas,
3620                                   request_spec, filter_properties,
3621                                   node, clean_shutdown)
3622             # NOTE(dgenin): This is thrown in LibvirtDriver when the
3623             #               instance to be migrated is backed by LVM.
3624             #               Remove when LVM migration is implemented.
3625             except exception.MigrationPreCheckError:
3626                 raise
3627             except Exception:
3628                 # try to re-schedule the resize elsewhere:
3629                 exc_info = sys.exc_info()
3630                 self._reschedule_resize_or_reraise(context, image, instance,
3631                         exc_info, instance_type, quotas, request_spec,
3632                         filter_properties)
3633             finally:
3634                 extra_usage_info = dict(
3635                         new_instance_type=instance_type.name,
3636                         new_instance_type_id=instance_type.id)
3637 
3638                 self._notify_about_instance_usage(
3639                     context, instance, "resize.prep.end",
3640                     extra_usage_info=extra_usage_info)
3641 
3642     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
3643             instance_type, quotas, request_spec, filter_properties):
3644         """Try to re-schedule the resize or re-raise the original error to
3645         error out the instance.
3646         """
3647         if not request_spec:
3648             request_spec = {}
3649         if not filter_properties:
3650             filter_properties = {}
3651 
3652         rescheduled = False
3653         instance_uuid = instance.uuid
3654 
3655         try:
3656             reschedule_method = self.compute_task_api.resize_instance
3657             scheduler_hint = dict(filter_properties=filter_properties)
3658             method_args = (instance, None, scheduler_hint, instance_type,
3659                            quotas.reservations)
3660             task_state = task_states.RESIZE_PREP
3661 
3662             rescheduled = self._reschedule(context, request_spec,
3663                     filter_properties, instance, reschedule_method,
3664                     method_args, task_state, exc_info)
3665         except Exception as error:
3666             rescheduled = False
3667             LOG.exception(_LE("Error trying to reschedule"),
3668                           instance_uuid=instance_uuid)
3669             compute_utils.add_instance_fault_from_exc(context,
3670                     instance, error,
3671                     exc_info=sys.exc_info())
3672             self._notify_about_instance_usage(context, instance,
3673                     'resize.error', fault=error)
3674 
3675         if rescheduled:
3676             self._log_original_error(exc_info, instance_uuid)
3677             compute_utils.add_instance_fault_from_exc(context,
3678                     instance, exc_info[1], exc_info=exc_info)
3679             self._notify_about_instance_usage(context, instance,
3680                     'resize.error', fault=exc_info[1])
3681         else:
3682             # not re-scheduling
3683             six.reraise(*exc_info)
3684 
3685     @wrap_exception()
3686     @reverts_task_state
3687     @wrap_instance_event
3688     @errors_out_migration
3689     @wrap_instance_fault
3690     def resize_instance(self, context, instance, image,
3691                         reservations, migration, instance_type,
3692                         clean_shutdown):
3693         """Starts the migration of a running instance to another host."""
3694 
3695         quotas = objects.Quotas.from_reservations(context,
3696                                                   reservations,
3697                                                   instance=instance)
3698         with self._error_out_instance_on_exception(context, instance,
3699                                                    quotas=quotas):
3700             # TODO(chaochin) Remove this until v5 RPC API
3701             # Code downstream may expect extra_specs to be populated since it
3702             # is receiving an object, so lookup the flavor to ensure this.
3703             if (not instance_type or
3704                 not isinstance(instance_type, objects.Flavor)):
3705                 instance_type = objects.Flavor.get_by_id(
3706                     context, migration['new_instance_type_id'])
3707 
3708             network_info = self.network_api.get_instance_nw_info(context,
3709                                                                  instance)
3710 
3711             migration.status = 'migrating'
3712             with migration.obj_as_admin():
3713                 migration.save()
3714 
3715             instance.task_state = task_states.RESIZE_MIGRATING
3716             instance.save(expected_task_state=task_states.RESIZE_PREP)
3717 
3718             self._notify_about_instance_usage(
3719                 context, instance, "resize.start", network_info=network_info)
3720 
3721             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3722                     context, instance.uuid)
3723             block_device_info = self._get_instance_block_device_info(
3724                                 context, instance, bdms=bdms)
3725 
3726             timeout, retry_interval = self._get_power_off_values(context,
3727                                             instance, clean_shutdown)
3728             disk_info = self.driver.migrate_disk_and_power_off(
3729                     context, instance, migration.dest_host,
3730                     instance_type, network_info,
3731                     block_device_info,
3732                     timeout, retry_interval)
3733 
3734             self._terminate_volume_connections(context, instance, bdms)
3735 
3736             migration_p = obj_base.obj_to_primitive(migration)
3737             self.network_api.migrate_instance_start(context,
3738                                                     instance,
3739                                                     migration_p)
3740 
3741             migration.status = 'post-migrating'
3742             with migration.obj_as_admin():
3743                 migration.save()
3744 
3745             instance.host = migration.dest_compute
3746             instance.node = migration.dest_node
3747             instance.task_state = task_states.RESIZE_MIGRATED
3748             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
3749 
3750             self.compute_rpcapi.finish_resize(context, instance,
3751                     migration, image, disk_info,
3752                     migration.dest_compute, reservations=quotas.reservations)
3753 
3754             self._notify_about_instance_usage(context, instance, "resize.end",
3755                                               network_info=network_info)
3756             self.instance_events.clear_events_for_instance(instance)
3757 
3758     def _terminate_volume_connections(self, context, instance, bdms):
3759         connector = self.driver.get_volume_connector(instance)
3760         for bdm in bdms:
3761             if bdm.is_volume:
3762                 self.volume_api.terminate_connection(context, bdm.volume_id,
3763                                                      connector)
3764 
3765     @staticmethod
3766     def _set_instance_info(instance, instance_type):
3767         instance.instance_type_id = instance_type.id
3768         instance.memory_mb = instance_type.memory_mb
3769         instance.vcpus = instance_type.vcpus
3770         instance.root_gb = instance_type.root_gb
3771         instance.ephemeral_gb = instance_type.ephemeral_gb
3772         instance.flavor = instance_type
3773 
3774     def _finish_resize(self, context, instance, migration, disk_info,
3775                        image_meta):
3776         resize_instance = False
3777         old_instance_type_id = migration['old_instance_type_id']
3778         new_instance_type_id = migration['new_instance_type_id']
3779         old_instance_type = instance.get_flavor()
3780         # NOTE(mriedem): Get the old_vm_state so we know if we should
3781         # power on the instance. If old_vm_state is not set we need to default
3782         # to ACTIVE for backwards compatibility
3783         old_vm_state = instance.system_metadata.get('old_vm_state',
3784                                                     vm_states.ACTIVE)
3785         instance.old_flavor = old_instance_type
3786 
3787         if old_instance_type_id != new_instance_type_id:
3788             instance_type = instance.get_flavor('new')
3789             self._set_instance_info(instance, instance_type)
3790             for key in ('root_gb', 'swap', 'ephemeral_gb'):
3791                 if old_instance_type[key] != instance_type[key]:
3792                     resize_instance = True
3793                     break
3794         instance.apply_migration_context()
3795 
3796         # NOTE(tr3buchet): setup networks on destination host
3797         self.network_api.setup_networks_on_host(context, instance,
3798                                                 migration['dest_compute'])
3799 
3800         migration_p = obj_base.obj_to_primitive(migration)
3801         self.network_api.migrate_instance_finish(context,
3802                                                  instance,
3803                                                  migration_p)
3804 
3805         network_info = self.network_api.get_instance_nw_info(context, instance)
3806 
3807         instance.task_state = task_states.RESIZE_FINISH
3808         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
3809 
3810         self._notify_about_instance_usage(
3811             context, instance, "finish_resize.start",
3812             network_info=network_info)
3813 
3814         block_device_info = self._get_instance_block_device_info(
3815                             context, instance, refresh_conn_info=True)
3816 
3817         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
3818         # automatically power on the instance after it's migrated
3819         power_on = old_vm_state != vm_states.STOPPED
3820 
3821         try:
3822             self.driver.finish_migration(context, migration, instance,
3823                                          disk_info,
3824                                          network_info,
3825                                          image_meta, resize_instance,
3826                                          block_device_info, power_on)
3827         except Exception:
3828             with excutils.save_and_reraise_exception():
3829                 if old_instance_type_id != new_instance_type_id:
3830                     self._set_instance_info(instance,
3831                                             old_instance_type)
3832 
3833         migration.status = 'finished'
3834         with migration.obj_as_admin():
3835             migration.save()
3836 
3837         instance.vm_state = vm_states.RESIZED
3838         instance.task_state = None
3839         instance.launched_at = timeutils.utcnow()
3840         instance.save(expected_task_state=task_states.RESIZE_FINISH)
3841 
3842         self._update_scheduler_instance_info(context, instance)
3843         self._notify_about_instance_usage(
3844             context, instance, "finish_resize.end",
3845             network_info=network_info)
3846 
3847     @wrap_exception()
3848     @reverts_task_state
3849     @wrap_instance_event
3850     @errors_out_migration
3851     @wrap_instance_fault
3852     def finish_resize(self, context, disk_info, image, instance,
3853                       reservations, migration):
3854         """Completes the migration process.
3855 
3856         Sets up the newly transferred disk and turns on the instance at its
3857         new host machine.
3858 
3859         """
3860         quotas = objects.Quotas.from_reservations(context,
3861                                                   reservations,
3862                                                   instance=instance)
3863         try:
3864             image_meta = objects.ImageMeta.from_dict(image)
3865             self._finish_resize(context, instance, migration,
3866                                 disk_info, image_meta)
3867             quotas.commit()
3868         except Exception:
3869             LOG.exception(_LE('Setting instance vm_state to ERROR'),
3870                           instance=instance)
3871             with excutils.save_and_reraise_exception():
3872                 try:
3873                     quotas.rollback()
3874                 except Exception:
3875                     LOG.exception(_LE("Failed to rollback quota for failed "
3876                                       "finish_resize"),
3877                                   instance=instance)
3878                 self._set_instance_obj_error_state(context, instance)
3879 
3880     @wrap_exception()
3881     @wrap_instance_fault
3882     def add_fixed_ip_to_instance(self, context, network_id, instance):
3883         """Calls network_api to add new fixed_ip to instance
3884         then injects the new network info and resets instance networking.
3885 
3886         """
3887         self._notify_about_instance_usage(
3888                 context, instance, "create_ip.start")
3889 
3890         network_info = self.network_api.add_fixed_ip_to_instance(context,
3891                                                                  instance,
3892                                                                  network_id)
3893         self._inject_network_info(context, instance, network_info)
3894         self.reset_network(context, instance)
3895 
3896         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
3897         instance.updated_at = timeutils.utcnow()
3898         instance.save()
3899 
3900         self._notify_about_instance_usage(
3901             context, instance, "create_ip.end", network_info=network_info)
3902 
3903     @wrap_exception()
3904     @wrap_instance_fault
3905     def remove_fixed_ip_from_instance(self, context, address, instance):
3906         """Calls network_api to remove existing fixed_ip from instance
3907         by injecting the altered network info and resetting
3908         instance networking.
3909         """
3910         self._notify_about_instance_usage(
3911                 context, instance, "delete_ip.start")
3912 
3913         network_info = self.network_api.remove_fixed_ip_from_instance(context,
3914                                                                       instance,
3915                                                                       address)
3916         self._inject_network_info(context, instance, network_info)
3917         self.reset_network(context, instance)
3918 
3919         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
3920         instance.updated_at = timeutils.utcnow()
3921         instance.save()
3922 
3923         self._notify_about_instance_usage(
3924             context, instance, "delete_ip.end", network_info=network_info)
3925 
3926     @wrap_exception()
3927     @reverts_task_state
3928     @wrap_instance_event
3929     @wrap_instance_fault
3930     def pause_instance(self, context, instance):
3931         """Pause an instance on this host."""
3932         context = context.elevated()
3933         LOG.info(_LI('Pausing'), context=context, instance=instance)
3934         self._notify_about_instance_usage(context, instance, 'pause.start')
3935         self.driver.pause(instance)
3936         instance.power_state = self._get_power_state(context, instance)
3937         instance.vm_state = vm_states.PAUSED
3938         instance.task_state = None
3939         instance.save(expected_task_state=task_states.PAUSING)
3940         self._notify_about_instance_usage(context, instance, 'pause.end')
3941 
3942     @wrap_exception()
3943     @reverts_task_state
3944     @wrap_instance_event
3945     @wrap_instance_fault
3946     def unpause_instance(self, context, instance):
3947         """Unpause a paused instance on this host."""
3948         context = context.elevated()
3949         LOG.info(_LI('Unpausing'), context=context, instance=instance)
3950         self._notify_about_instance_usage(context, instance, 'unpause.start')
3951         self.driver.unpause(instance)
3952         instance.power_state = self._get_power_state(context, instance)
3953         instance.vm_state = vm_states.ACTIVE
3954         instance.task_state = None
3955         instance.save(expected_task_state=task_states.UNPAUSING)
3956         self._notify_about_instance_usage(context, instance, 'unpause.end')
3957 
3958     @wrap_exception()
3959     def host_power_action(self, context, action):
3960         """Reboots, shuts down or powers up the host."""
3961         return self.driver.host_power_action(action)
3962 
3963     @wrap_exception()
3964     def host_maintenance_mode(self, context, host, mode):
3965         """Start/Stop host maintenance window. On start, it triggers
3966         guest VMs evacuation.
3967         """
3968         return self.driver.host_maintenance_mode(host, mode)
3969 
3970     @wrap_exception()
3971     def set_host_enabled(self, context, enabled):
3972         """Sets the specified host's ability to accept new instances."""
3973         return self.driver.set_host_enabled(enabled)
3974 
3975     @wrap_exception()
3976     def get_host_uptime(self, context):
3977         """Returns the result of calling "uptime" on the target host."""
3978         return self.driver.get_host_uptime()
3979 
3980     @wrap_exception()
3981     @wrap_instance_fault
3982     def get_diagnostics(self, context, instance):
3983         """Retrieve diagnostics for an instance on this host."""
3984         current_power_state = self._get_power_state(context, instance)
3985         if current_power_state == power_state.RUNNING:
3986             LOG.info(_LI("Retrieving diagnostics"), context=context,
3987                       instance=instance)
3988             return self.driver.get_diagnostics(instance)
3989         else:
3990             raise exception.InstanceInvalidState(
3991                 attr='power_state',
3992                 instance_uuid=instance.uuid,
3993                 state=instance.power_state,
3994                 method='get_diagnostics')
3995 
3996     @object_compat
3997     @wrap_exception()
3998     @wrap_instance_fault
3999     def get_instance_diagnostics(self, context, instance):
4000         """Retrieve diagnostics for an instance on this host."""
4001         current_power_state = self._get_power_state(context, instance)
4002         if current_power_state == power_state.RUNNING:
4003             LOG.info(_LI("Retrieving diagnostics"), context=context,
4004                       instance=instance)
4005             diags = self.driver.get_instance_diagnostics(instance)
4006             return diags.serialize()
4007         else:
4008             raise exception.InstanceInvalidState(
4009                 attr='power_state',
4010                 instance_uuid=instance.uuid,
4011                 state=instance.power_state,
4012                 method='get_diagnostics')
4013 
4014     @wrap_exception()
4015     @reverts_task_state
4016     @wrap_instance_event
4017     @wrap_instance_fault
4018     def suspend_instance(self, context, instance):
4019         """Suspend the given instance."""
4020         context = context.elevated()
4021 
4022         # Store the old state
4023         instance.system_metadata['old_vm_state'] = instance.vm_state
4024         self._notify_about_instance_usage(context, instance, 'suspend.start')
4025 
4026         with self._error_out_instance_on_exception(context, instance,
4027              instance_state=instance.vm_state):
4028             self.driver.suspend(context, instance)
4029         instance.power_state = self._get_power_state(context, instance)
4030         instance.vm_state = vm_states.SUSPENDED
4031         instance.task_state = None
4032         instance.save(expected_task_state=task_states.SUSPENDING)
4033         self._notify_about_instance_usage(context, instance, 'suspend.end')
4034 
4035     @wrap_exception()
4036     @reverts_task_state
4037     @wrap_instance_event
4038     @wrap_instance_fault
4039     def resume_instance(self, context, instance):
4040         """Resume the given suspended instance."""
4041         context = context.elevated()
4042         LOG.info(_LI('Resuming'), context=context, instance=instance)
4043 
4044         self._notify_about_instance_usage(context, instance, 'resume.start')
4045         network_info = self.network_api.get_instance_nw_info(context, instance)
4046         block_device_info = self._get_instance_block_device_info(
4047                             context, instance)
4048 
4049         with self._error_out_instance_on_exception(context, instance,
4050              instance_state=instance.vm_state):
4051             self.driver.resume(context, instance, network_info,
4052                                block_device_info)
4053 
4054         instance.power_state = self._get_power_state(context, instance)
4055 
4056         # We default to the ACTIVE state for backwards compatibility
4057         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4058                                                          vm_states.ACTIVE)
4059 
4060         instance.task_state = None
4061         instance.save(expected_task_state=task_states.RESUMING)
4062         self._notify_about_instance_usage(context, instance, 'resume.end')
4063 
4064     @wrap_exception()
4065     @reverts_task_state
4066     @wrap_instance_event
4067     @wrap_instance_fault
4068     def shelve_instance(self, context, instance, image_id,
4069                         clean_shutdown):
4070         """Shelve an instance.
4071 
4072         This should be used when you want to take a snapshot of the instance.
4073         It also adds system_metadata that can be used by a periodic task to
4074         offload the shelved instance after a period of time.
4075 
4076         :param context: request context
4077         :param instance: an Instance object
4078         :param image_id: an image id to snapshot to.
4079         :param clean_shutdown: give the GuestOS a chance to stop
4080         """
4081         compute_utils.notify_usage_exists(self.notifier, context, instance,
4082                                           current_period=True)
4083         self._notify_about_instance_usage(context, instance, 'shelve.start')
4084 
4085         def update_task_state(task_state, expected_state=task_states.SHELVING):
4086             shelving_state_map = {
4087                     task_states.IMAGE_PENDING_UPLOAD:
4088                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4089                     task_states.IMAGE_UPLOADING:
4090                         task_states.SHELVING_IMAGE_UPLOADING,
4091                     task_states.SHELVING: task_states.SHELVING}
4092             task_state = shelving_state_map[task_state]
4093             expected_state = shelving_state_map[expected_state]
4094             instance.task_state = task_state
4095             instance.save(expected_task_state=expected_state)
4096 
4097         self._power_off_instance(context, instance, clean_shutdown)
4098         self.driver.snapshot(context, instance, image_id, update_task_state)
4099 
4100         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4101         instance.system_metadata['shelved_image_id'] = image_id
4102         instance.system_metadata['shelved_host'] = self.host
4103         instance.vm_state = vm_states.SHELVED
4104         instance.task_state = None
4105         if CONF.shelved_offload_time == 0:
4106             instance.task_state = task_states.SHELVING_OFFLOADING
4107         instance.power_state = self._get_power_state(context, instance)
4108         instance.save(expected_task_state=[
4109                 task_states.SHELVING,
4110                 task_states.SHELVING_IMAGE_UPLOADING])
4111 
4112         self._notify_about_instance_usage(context, instance, 'shelve.end')
4113 
4114         if CONF.shelved_offload_time == 0:
4115             self.shelve_offload_instance(context, instance,
4116                                          clean_shutdown=False)
4117 
4118     @wrap_exception()
4119     @reverts_task_state
4120     @wrap_instance_fault
4121     def shelve_offload_instance(self, context, instance, clean_shutdown):
4122         """Remove a shelved instance from the hypervisor.
4123 
4124         This frees up those resources for use by other instances, but may lead
4125         to slower unshelve times for this instance.  This method is used by
4126         volume backed instances since restoring them doesn't involve the
4127         potentially large download of an image.
4128 
4129         :param context: request context
4130         :param instance: nova.objects.instance.Instance
4131         :param clean_shutdown: give the GuestOS a chance to stop
4132         """
4133         self._notify_about_instance_usage(context, instance,
4134                 'shelve_offload.start')
4135 
4136         self._power_off_instance(context, instance, clean_shutdown)
4137         current_power_state = self._get_power_state(context, instance)
4138 
4139         self.network_api.cleanup_instance_network_on_host(context, instance,
4140                                                           instance.host)
4141         network_info = self.network_api.get_instance_nw_info(context, instance)
4142         block_device_info = self._get_instance_block_device_info(context,
4143                                                                  instance)
4144         self.driver.destroy(context, instance, network_info,
4145                 block_device_info)
4146 
4147         instance.power_state = current_power_state
4148         instance.host = None
4149         instance.node = None
4150         instance.vm_state = vm_states.SHELVED_OFFLOADED
4151         instance.task_state = None
4152         instance.save(expected_task_state=[task_states.SHELVING,
4153                                            task_states.SHELVING_OFFLOADING])
4154         # NOTE(ndipanov): This frees the resources with the resource_tracker
4155         self._update_resource_tracker(context, instance)
4156 
4157         self._delete_scheduler_instance_info(context, instance.uuid)
4158         self._notify_about_instance_usage(context, instance,
4159                 'shelve_offload.end')
4160 
4161     @wrap_exception()
4162     @reverts_task_state
4163     @wrap_instance_event
4164     @wrap_instance_fault
4165     def unshelve_instance(self, context, instance, image,
4166                           filter_properties, node):
4167         """Unshelve the instance.
4168 
4169         :param context: request context
4170         :param instance: a nova.objects.instance.Instance object
4171         :param image: an image to build from.  If None we assume a
4172             volume backed instance.
4173         :param filter_properties: dict containing limits, retry info etc.
4174         :param node: target compute node
4175         """
4176         if filter_properties is None:
4177             filter_properties = {}
4178 
4179         @utils.synchronized(instance.uuid)
4180         def do_unshelve_instance():
4181             self._unshelve_instance(context, instance, image,
4182                                     filter_properties, node)
4183         do_unshelve_instance()
4184 
4185     def _unshelve_instance_key_scrub(self, instance):
4186         """Remove data from the instance that may cause side effects."""
4187         cleaned_keys = dict(
4188                 key_data=instance.key_data,
4189                 auto_disk_config=instance.auto_disk_config)
4190         instance.key_data = None
4191         instance.auto_disk_config = False
4192         return cleaned_keys
4193 
4194     def _unshelve_instance_key_restore(self, instance, keys):
4195         """Restore previously scrubbed keys before saving the instance."""
4196         instance.update(keys)
4197 
4198     def _unshelve_instance(self, context, instance, image, filter_properties,
4199                            node):
4200         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4201         instance.task_state = task_states.SPAWNING
4202         instance.save()
4203 
4204         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4205                 context, instance.uuid)
4206         block_device_info = self._prep_block_device(context, instance, bdms,
4207                                                     do_check_attach=False)
4208         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4209 
4210         if node is None:
4211             node = self.driver.get_available_nodes()[0]
4212             LOG.debug('No node specified, defaulting to %s', node,
4213                       instance=instance)
4214 
4215         rt = self._get_resource_tracker(node)
4216         limits = filter_properties.get('limits', {})
4217 
4218         shelved_image_ref = instance.image_ref
4219         if image:
4220             instance.image_ref = image['id']
4221             image_meta = objects.ImageMeta.from_dict(image)
4222         else:
4223             image_meta = objects.ImageMeta.from_dict(
4224                 utils.get_image_from_system_metadata(
4225                     instance.system_metadata))
4226 
4227         self.network_api.setup_instance_network_on_host(context, instance,
4228                                                         self.host)
4229         network_info = self.network_api.get_instance_nw_info(context, instance)
4230         try:
4231             with rt.instance_claim(context, instance, limits):
4232                 self.driver.spawn(context, instance, image_meta,
4233                                   injected_files=[],
4234                                   admin_password=None,
4235                                   network_info=network_info,
4236                                   block_device_info=block_device_info)
4237         except Exception:
4238             with excutils.save_and_reraise_exception():
4239                 LOG.exception(_LE('Instance failed to spawn'),
4240                               instance=instance)
4241 
4242         if image:
4243             instance.image_ref = shelved_image_ref
4244             self._delete_snapshot_of_shelved_instance(context, instance,
4245                                                       image['id'])
4246 
4247         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4248         self._update_instance_after_spawn(context, instance)
4249         # Delete system_metadata for a shelved instance
4250         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4251 
4252         instance.save(expected_task_state=task_states.SPAWNING)
4253         self._update_scheduler_instance_info(context, instance)
4254         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4255 
4256     @messaging.expected_exceptions(NotImplementedError)
4257     @wrap_instance_fault
4258     def reset_network(self, context, instance):
4259         """Reset networking on the given instance."""
4260         LOG.debug('Reset network', context=context, instance=instance)
4261         self.driver.reset_network(instance)
4262 
4263     def _inject_network_info(self, context, instance, network_info):
4264         """Inject network info for the given instance."""
4265         LOG.debug('Inject network info', context=context, instance=instance)
4266         LOG.debug('network_info to inject: |%s|', network_info,
4267                   instance=instance)
4268 
4269         self.driver.inject_network_info(instance,
4270                                         network_info)
4271 
4272     @wrap_instance_fault
4273     def inject_network_info(self, context, instance):
4274         """Inject network info, but don't return the info."""
4275         network_info = self.network_api.get_instance_nw_info(context, instance)
4276         self._inject_network_info(context, instance, network_info)
4277 
4278     @messaging.expected_exceptions(NotImplementedError,
4279                                    exception.ConsoleNotAvailable,
4280                                    exception.InstanceNotFound)
4281     @wrap_exception()
4282     @wrap_instance_fault
4283     def get_console_output(self, context, instance, tail_length):
4284         """Send the console output for the given instance."""
4285         context = context.elevated()
4286         LOG.info(_LI("Get console output"), context=context,
4287                   instance=instance)
4288         output = self.driver.get_console_output(context, instance)
4289 
4290         if type(output) is six.text_type:
4291             # the console output will be bytes.
4292             output = six.b(output)
4293 
4294         if tail_length is not None:
4295             output = self._tail_log(output, tail_length)
4296 
4297         return output.decode('utf-8', 'replace').encode('ascii', 'replace')
4298 
4299     def _tail_log(self, log, length):
4300         try:
4301             length = int(length)
4302         except ValueError:
4303             length = 0
4304 
4305         if length == 0:
4306             return b''
4307         else:
4308             return b'\n'.join(log.split(b'\n')[-int(length):])
4309 
4310     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4311                                    exception.InstanceNotReady,
4312                                    exception.InstanceNotFound,
4313                                    exception.ConsoleTypeUnavailable,
4314                                    NotImplementedError)
4315     @wrap_exception()
4316     @wrap_instance_fault
4317     def get_vnc_console(self, context, console_type, instance):
4318         """Return connection information for a vnc console."""
4319         context = context.elevated()
4320         LOG.debug("Getting vnc console", instance=instance)
4321         token = str(uuid.uuid4())
4322 
4323         if not CONF.vnc.enabled:
4324             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4325 
4326         if console_type == 'novnc':
4327             # For essex, novncproxy_base_url must include the full path
4328             # including the html file (like http://myhost/vnc_auto.html)
4329             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
4330         elif console_type == 'xvpvnc':
4331             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
4332         else:
4333             raise exception.ConsoleTypeInvalid(console_type=console_type)
4334 
4335         try:
4336             # Retrieve connect info from driver, and then decorate with our
4337             # access info token
4338             console = self.driver.get_vnc_console(context, instance)
4339             connect_info = console.get_connection_info(token, access_url)
4340         except exception.InstanceNotFound:
4341             if instance.vm_state != vm_states.BUILDING:
4342                 raise
4343             raise exception.InstanceNotReady(instance_id=instance.uuid)
4344 
4345         return connect_info
4346 
4347     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4348                                    exception.InstanceNotReady,
4349                                    exception.InstanceNotFound,
4350                                    exception.ConsoleTypeUnavailable,
4351                                    NotImplementedError)
4352     @wrap_exception()
4353     @wrap_instance_fault
4354     def get_spice_console(self, context, console_type, instance):
4355         """Return connection information for a spice console."""
4356         context = context.elevated()
4357         LOG.debug("Getting spice console", instance=instance)
4358         token = str(uuid.uuid4())
4359 
4360         if not CONF.spice.enabled:
4361             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4362 
4363         if console_type == 'spice-html5':
4364             # For essex, spicehtml5proxy_base_url must include the full path
4365             # including the html file (like http://myhost/spice_auto.html)
4366             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
4367                                           token)
4368         else:
4369             raise exception.ConsoleTypeInvalid(console_type=console_type)
4370 
4371         try:
4372             # Retrieve connect info from driver, and then decorate with our
4373             # access info token
4374             console = self.driver.get_spice_console(context, instance)
4375             connect_info = console.get_connection_info(token, access_url)
4376         except exception.InstanceNotFound:
4377             if instance.vm_state != vm_states.BUILDING:
4378                 raise
4379             raise exception.InstanceNotReady(instance_id=instance.uuid)
4380 
4381         return connect_info
4382 
4383     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4384                                    exception.InstanceNotReady,
4385                                    exception.InstanceNotFound,
4386                                    exception.ConsoleTypeUnavailable,
4387                                    NotImplementedError)
4388     @wrap_exception()
4389     @wrap_instance_fault
4390     def get_rdp_console(self, context, console_type, instance):
4391         """Return connection information for a RDP console."""
4392         context = context.elevated()
4393         LOG.debug("Getting RDP console", instance=instance)
4394         token = str(uuid.uuid4())
4395 
4396         if not CONF.rdp.enabled:
4397             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4398 
4399         if console_type == 'rdp-html5':
4400             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
4401                                           token)
4402         else:
4403             raise exception.ConsoleTypeInvalid(console_type=console_type)
4404 
4405         try:
4406             # Retrieve connect info from driver, and then decorate with our
4407             # access info token
4408             console = self.driver.get_rdp_console(context, instance)
4409             connect_info = console.get_connection_info(token, access_url)
4410         except exception.InstanceNotFound:
4411             if instance.vm_state != vm_states.BUILDING:
4412                 raise
4413             raise exception.InstanceNotReady(instance_id=instance.uuid)
4414 
4415         return connect_info
4416 
4417     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4418                                    exception.InstanceNotReady,
4419                                    exception.InstanceNotFound,
4420                                    exception.ConsoleTypeUnavailable,
4421                                    NotImplementedError)
4422     @wrap_exception()
4423     @wrap_instance_fault
4424     def get_mks_console(self, context, console_type, instance):
4425         """Return connection information for a MKS console."""
4426         context = context.elevated()
4427         LOG.debug("Getting MKS console", instance=instance)
4428         token = str(uuid.uuid4())
4429 
4430         if not CONF.mks.enabled:
4431             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4432 
4433         if console_type == 'webmks':
4434             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
4435                                           token)
4436         else:
4437             raise exception.ConsoleTypeInvalid(console_type=console_type)
4438 
4439         try:
4440             # Retrieve connect info from driver, and then decorate with our
4441             # access info token
4442             console = self.driver.get_mks_console(context, instance)
4443             connect_info = console.get_connection_info(token, access_url)
4444         except exception.InstanceNotFound:
4445             if instance.vm_state != vm_states.BUILDING:
4446                 raise
4447             raise exception.InstanceNotReady(instance_id=instance.uuid)
4448 
4449         return connect_info
4450 
4451     @messaging.expected_exceptions(
4452         exception.ConsoleTypeInvalid,
4453         exception.InstanceNotReady,
4454         exception.InstanceNotFound,
4455         exception.ConsoleTypeUnavailable,
4456         exception.SocketPortRangeExhaustedException,
4457         exception.ImageSerialPortNumberInvalid,
4458         exception.ImageSerialPortNumberExceedFlavorValue,
4459         NotImplementedError)
4460     @wrap_exception()
4461     @wrap_instance_fault
4462     def get_serial_console(self, context, console_type, instance):
4463         """Returns connection information for a serial console."""
4464 
4465         LOG.debug("Getting serial console", instance=instance)
4466 
4467         if not CONF.serial_console.enabled:
4468             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4469 
4470         context = context.elevated()
4471 
4472         token = str(uuid.uuid4())
4473         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
4474 
4475         try:
4476             # Retrieve connect info from driver, and then decorate with our
4477             # access info token
4478             console = self.driver.get_serial_console(context, instance)
4479             connect_info = console.get_connection_info(token, access_url)
4480         except exception.InstanceNotFound:
4481             if instance.vm_state != vm_states.BUILDING:
4482                 raise
4483             raise exception.InstanceNotReady(instance_id=instance.uuid)
4484 
4485         return connect_info
4486 
4487     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4488                                    exception.InstanceNotReady,
4489                                    exception.InstanceNotFound)
4490     @wrap_exception()
4491     @wrap_instance_fault
4492     def validate_console_port(self, ctxt, instance, port, console_type):
4493         if console_type == "spice-html5":
4494             console_info = self.driver.get_spice_console(ctxt, instance)
4495         elif console_type == "rdp-html5":
4496             console_info = self.driver.get_rdp_console(ctxt, instance)
4497         elif console_type == "serial":
4498             console_info = self.driver.get_serial_console(ctxt, instance)
4499         elif console_type == "webmks":
4500             console_info = self.driver.get_mks_console(ctxt, instance)
4501         else:
4502             console_info = self.driver.get_vnc_console(ctxt, instance)
4503 
4504         return console_info.port == port
4505 
4506     @wrap_exception()
4507     @reverts_task_state
4508     @wrap_instance_fault
4509     def reserve_block_device_name(self, context, instance, device,
4510                                   volume_id, disk_bus, device_type):
4511         @utils.synchronized(instance.uuid)
4512         def do_reserve():
4513             bdms = (
4514                 objects.BlockDeviceMappingList.get_by_instance_uuid(
4515                     context, instance.uuid))
4516 
4517             # NOTE(ndipanov): We need to explicitly set all the fields on the
4518             #                 object so that obj_load_attr does not fail
4519             new_bdm = objects.BlockDeviceMapping(
4520                     context=context,
4521                     source_type='volume', destination_type='volume',
4522                     instance_uuid=instance.uuid, boot_index=None,
4523                     volume_id=volume_id,
4524                     device_name=device, guest_format=None,
4525                     disk_bus=disk_bus, device_type=device_type)
4526 
4527             new_bdm.device_name = self._get_device_name_for_instance(
4528                     instance, bdms, new_bdm)
4529 
4530             # NOTE(vish): create bdm here to avoid race condition
4531             new_bdm.create()
4532             return new_bdm
4533 
4534         return do_reserve()
4535 
4536     @wrap_exception()
4537     @wrap_instance_fault
4538     def attach_volume(self, context, instance, bdm):
4539         """Attach a volume to an instance."""
4540         driver_bdm = driver_block_device.convert_volume(bdm)
4541 
4542         @utils.synchronized(instance.uuid)
4543         def do_attach_volume(context, instance, driver_bdm):
4544             try:
4545                 return self._attach_volume(context, instance, driver_bdm)
4546             except Exception:
4547                 with excutils.save_and_reraise_exception():
4548                     bdm.destroy()
4549 
4550         do_attach_volume(context, instance, driver_bdm)
4551 
4552     def _attach_volume(self, context, instance, bdm):
4553         context = context.elevated()
4554         LOG.info(_LI('Attaching volume %(volume_id)s to %(mountpoint)s'),
4555                   {'volume_id': bdm.volume_id,
4556                   'mountpoint': bdm['mount_device']},
4557                  context=context, instance=instance)
4558         try:
4559             bdm.attach(context, instance, self.volume_api, self.driver,
4560                        do_check_attach=False, do_driver_attach=True)
4561         except Exception:
4562             with excutils.save_and_reraise_exception():
4563                 LOG.exception(_LE("Failed to attach %(volume_id)s "
4564                                   "at %(mountpoint)s"),
4565                               {'volume_id': bdm.volume_id,
4566                                'mountpoint': bdm['mount_device']},
4567                               context=context, instance=instance)
4568                 self.volume_api.unreserve_volume(context, bdm.volume_id)
4569 
4570         info = {'volume_id': bdm.volume_id}
4571         self._notify_about_instance_usage(
4572             context, instance, "volume.attach", extra_usage_info=info)
4573 
4574     def _driver_detach_volume(self, context, instance, bdm):
4575         """Do the actual driver detach using block device mapping."""
4576         mp = bdm.device_name
4577         volume_id = bdm.volume_id
4578 
4579         LOG.info(_LI('Detach volume %(volume_id)s from mountpoint %(mp)s'),
4580                   {'volume_id': volume_id, 'mp': mp},
4581                   context=context, instance=instance)
4582 
4583         connection_info = jsonutils.loads(bdm.connection_info)
4584         # NOTE(vish): We currently don't use the serial when disconnecting,
4585         #             but added for completeness in case we ever do.
4586         if connection_info and 'serial' not in connection_info:
4587             connection_info['serial'] = volume_id
4588         try:
4589             if not self.driver.instance_exists(instance):
4590                 LOG.warning(_LW('Detaching volume from unknown instance'),
4591                             context=context, instance=instance)
4592 
4593             encryption = encryptors.get_encryption_metadata(
4594                 context, self.volume_api, volume_id, connection_info)
4595 
4596             self.driver.detach_volume(connection_info,
4597                                       instance,
4598                                       mp,
4599                                       encryption=encryption)
4600         except exception.DiskNotFound as err:
4601             LOG.warning(_LW('Ignoring DiskNotFound exception while detaching '
4602                             'volume %(volume_id)s from %(mp)s: %(err)s'),
4603                         {'volume_id': volume_id, 'mp': mp, 'err': err},
4604                         instance=instance)
4605         except Exception:
4606             with excutils.save_and_reraise_exception():
4607                 LOG.exception(_LE('Failed to detach volume %(volume_id)s '
4608                                   'from %(mp)s'),
4609                               {'volume_id': volume_id, 'mp': mp},
4610                               context=context, instance=instance)
4611                 self.volume_api.roll_detaching(context, volume_id)
4612 
4613         return connection_info
4614 
4615     def _detach_volume(self, context, volume_id, instance, destroy_bdm=True,
4616                        attachment_id=None):
4617         """Detach a volume from an instance.
4618 
4619         :param context: security context
4620         :param volume_id: the volume id
4621         :param instance: the Instance object to detach the volume from
4622         :param destroy_bdm: if True, the corresponding BDM entry will be marked
4623                             as deleted. Disabling this is useful for operations
4624                             like rebuild, when we don't want to destroy BDM
4625 
4626         """
4627 
4628         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4629                 context, volume_id, instance.uuid)
4630         if CONF.volume_usage_poll_interval > 0:
4631             vol_stats = []
4632             mp = bdm.device_name
4633             # Handle bootable volumes which will not contain /dev/
4634             if '/dev/' in mp:
4635                 mp = mp[5:]
4636             try:
4637                 vol_stats = self.driver.block_stats(instance, mp)
4638             except NotImplementedError:
4639                 pass
4640 
4641             if vol_stats:
4642                 LOG.debug("Updating volume usage cache with totals",
4643                           instance=instance)
4644                 rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
4645                 vol_usage = objects.VolumeUsage(context)
4646                 vol_usage.volume_id = volume_id
4647                 vol_usage.instance_uuid = instance.uuid
4648                 vol_usage.project_id = instance.project_id
4649                 vol_usage.user_id = instance.user_id
4650                 vol_usage.availability_zone = instance.availability_zone
4651                 vol_usage.curr_reads = rd_req
4652                 vol_usage.curr_read_bytes = rd_bytes
4653                 vol_usage.curr_writes = wr_req
4654                 vol_usage.curr_write_bytes = wr_bytes
4655                 vol_usage.save(update_totals=True)
4656                 self.notifier.info(context, 'volume.usage',
4657                                    compute_utils.usage_volume_info(vol_usage))
4658 
4659         connection_info = self._driver_detach_volume(context, instance, bdm)
4660         connector = self.driver.get_volume_connector(instance)
4661 
4662         if connection_info and not destroy_bdm and (
4663            connector.get('host') != instance.host):
4664             # If the volume is attached to another host (evacuate) then
4665             # this connector is for the wrong host. Use the connector that
4666             # was stored in connection_info instead (if we have one, and it
4667             # is for the expected host).
4668             stashed_connector = connection_info.get('connector')
4669             if not stashed_connector:
4670                 # Volume was attached before we began stashing connectors
4671                 LOG.warning(_LW("Host mismatch detected, but stashed "
4672                                 "volume connector not found. Instance host is "
4673                                 "%(ihost)s, but volume connector host is "
4674                                 "%(chost)s."),
4675                             {'ihost': instance.host,
4676                              'chost': connector.get('host')})
4677             elif stashed_connector.get('host') != instance.host:
4678                 # Unexpected error. The stashed connector is also not matching
4679                 # the needed instance host.
4680                 LOG.error(_LE("Host mismatch detected in stashed volume "
4681                               "connector. Will use local volume connector. "
4682                               "Instance host is %(ihost)s. Local volume "
4683                               "connector host is %(chost)s. Stashed volume "
4684                               "connector host is %(schost)s."),
4685                           {'ihost': instance.host,
4686                            'chost': connector.get('host'),
4687                            'schost': stashed_connector.get('host')})
4688             else:
4689                 # Fix found. Use stashed connector.
4690                 LOG.debug("Host mismatch detected. Found usable stashed "
4691                           "volume connector. Instance host is %(ihost)s. "
4692                           "Local volume connector host was %(chost)s. "
4693                           "Stashed volume connector host is %(schost)s.",
4694                           {'ihost': instance.host,
4695                            'chost': connector.get('host'),
4696                            'schost': stashed_connector.get('host')})
4697                 connector = stashed_connector
4698 
4699         self.volume_api.terminate_connection(context, volume_id, connector)
4700 
4701         if destroy_bdm:
4702             bdm.destroy()
4703 
4704         info = dict(volume_id=volume_id)
4705         self._notify_about_instance_usage(
4706             context, instance, "volume.detach", extra_usage_info=info)
4707         self.volume_api.detach(context.elevated(), volume_id, instance.uuid,
4708                                attachment_id)
4709 
4710     @wrap_exception()
4711     @wrap_instance_fault
4712     def detach_volume(self, context, volume_id, instance, attachment_id=None):
4713         """Detach a volume from an instance."""
4714 
4715         self._detach_volume(context, volume_id, instance,
4716                             attachment_id=attachment_id)
4717 
4718     def _init_volume_connection(self, context, new_volume_id,
4719                                 old_volume_id, connector, instance, bdm):
4720 
4721         new_cinfo = self.volume_api.initialize_connection(context,
4722                                                           new_volume_id,
4723                                                           connector)
4724         old_cinfo = jsonutils.loads(bdm['connection_info'])
4725         if old_cinfo and 'serial' not in old_cinfo:
4726             old_cinfo['serial'] = old_volume_id
4727         new_cinfo['serial'] = old_cinfo['serial']
4728         return (old_cinfo, new_cinfo)
4729 
4730     def _swap_volume(self, context, instance, bdm, connector,
4731                      old_volume_id, new_volume_id, resize_to):
4732         mountpoint = bdm['device_name']
4733         failed = False
4734         new_cinfo = None
4735         try:
4736             old_cinfo, new_cinfo = self._init_volume_connection(context,
4737                                                                 new_volume_id,
4738                                                                 old_volume_id,
4739                                                                 connector,
4740                                                                 instance,
4741                                                                 bdm)
4742             # Get encryption
4743             old_encryption = encryptors.get_encryption_metadata(
4744                                  context, self.volume_api,
4745                                  old_volume_id, old_cinfo)
4746             new_encryption = encryptors.get_encryption_metadata(
4747                                  context, self.volume_api,
4748                                  new_volume_id, new_cinfo)
4749 
4750             LOG.debug("swap_volume: Calling driver volume swap with "
4751                       "connection infos: new: %(new_cinfo)s; "
4752                       "old: %(old_cinfo)s and encryption infos: "
4753                       "new: %(new_enc)s; old: %(old_enc)s.",
4754                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo,
4755                        'new_enc': new_encryption, 'old_enc': old_encryption},
4756                       contex=context, instance=instance)
4757             self.driver.swap_volume(context, old_cinfo, new_cinfo,
4758                                     old_encryption, new_encryption,
4759                                     instance, mountpoint, resize_to)
4760         except Exception:
4761             failed = True
4762             with excutils.save_and_reraise_exception():
4763                 if new_cinfo:
4764                     msg = _LE("Failed to swap volume %(old_volume_id)s "
4765                               "for %(new_volume_id)s")
4766                     LOG.exception(msg, {'old_volume_id': old_volume_id,
4767                                         'new_volume_id': new_volume_id},
4768                                   context=context,
4769                                   instance=instance)
4770                 else:
4771                     msg = _LE("Failed to connect to volume %(volume_id)s "
4772                               "with volume at %(mountpoint)s")
4773                     LOG.exception(msg, {'volume_id': new_volume_id,
4774                                         'mountpoint': bdm['device_name']},
4775                                   context=context,
4776                                   instance=instance)
4777                 self.volume_api.roll_detaching(context, old_volume_id)
4778                 self.volume_api.unreserve_volume(context, new_volume_id)
4779         finally:
4780             conn_volume = new_volume_id if failed else old_volume_id
4781             if new_cinfo:
4782                 LOG.debug("swap_volume: calling Cinder terminate_connection "
4783                           "for %(volume)s", {'volume': conn_volume},
4784                           context=context, instance=instance)
4785                 self.volume_api.terminate_connection(context,
4786                                                      conn_volume,
4787                                                      connector)
4788             # If Cinder initiated the swap, it will keep
4789             # the original ID
4790             comp_ret = self.volume_api.migrate_volume_completion(
4791                                                       context,
4792                                                       old_volume_id,
4793                                                       new_volume_id,
4794                                                       error=failed)
4795             LOG.debug("swap_volume: Cinder migrate_volume_completion "
4796                       "returned: %(comp_ret)s", {'comp_ret': comp_ret},
4797                       context=context, instance=instance)
4798 
4799         return (comp_ret, new_cinfo)
4800 
4801     @wrap_exception()
4802     @reverts_task_state
4803     @wrap_instance_fault
4804     def swap_volume(self, context, old_volume_id, new_volume_id, instance):
4805         """Swap volume for an instance."""
4806         context = context.elevated()
4807 
4808         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4809                 context, old_volume_id, instance.uuid)
4810         connector = self.driver.get_volume_connector(instance)
4811 
4812         resize_to = 0
4813         old_vol_size = self.volume_api.get(context, old_volume_id)['size']
4814         new_vol_size = self.volume_api.get(context, new_volume_id)['size']
4815         if new_vol_size > old_vol_size:
4816             resize_to = new_vol_size
4817 
4818         LOG.info(_LI('Swapping volume %(old_volume)s for %(new_volume)s'),
4819                   {'old_volume': old_volume_id, 'new_volume': new_volume_id},
4820                   context=context, instance=instance)
4821         comp_ret, new_cinfo = self._swap_volume(context, instance,
4822                                                          bdm,
4823                                                          connector,
4824                                                          old_volume_id,
4825                                                          new_volume_id,
4826                                                          resize_to)
4827 
4828         save_volume_id = comp_ret['save_volume_id']
4829 
4830         # Update bdm
4831         values = {
4832             'connection_info': jsonutils.dumps(new_cinfo),
4833             'source_type': 'volume',
4834             'destination_type': 'volume',
4835             'snapshot_id': None,
4836             'volume_id': save_volume_id,
4837             'no_device': None}
4838 
4839         if resize_to:
4840             values['volume_size'] = resize_to
4841 
4842         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
4843                   "%(updates)s", {'volume_id': bdm.volume_id,
4844                                   'updates': values},
4845                   context=context, instance=instance)
4846         bdm.update(values)
4847         bdm.save()
4848 
4849     @wrap_exception()
4850     def remove_volume_connection(self, context, volume_id, instance):
4851         """Remove a volume connection using the volume api."""
4852         # NOTE(vish): We don't want to actually mark the volume
4853         #             detached, or delete the bdm, just remove the
4854         #             connection from this host.
4855 
4856         try:
4857             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4858                     context, volume_id, instance.uuid)
4859             self._driver_detach_volume(context, instance, bdm)
4860             connector = self.driver.get_volume_connector(instance)
4861             self.volume_api.terminate_connection(context, volume_id, connector)
4862         except exception.NotFound:
4863             pass
4864 
4865     @wrap_exception()
4866     @wrap_instance_fault
4867     def attach_interface(self, context, instance, network_id, port_id,
4868                          requested_ip):
4869         """Use hotplug to add an network adapter to an instance."""
4870         if not self.driver.capabilities['supports_attach_interface']:
4871             raise exception.AttachInterfaceNotSupported(
4872                 instance_id=instance.uuid)
4873         bind_host_id = self.driver.network_binding_host_id(context, instance)
4874         network_info = self.network_api.allocate_port_for_instance(
4875             context, instance, port_id, network_id, requested_ip,
4876             bind_host_id=bind_host_id)
4877         if len(network_info) != 1:
4878             LOG.error(_LE('allocate_port_for_instance returned %(ports)s '
4879                           'ports'), {'ports': len(network_info)})
4880             raise exception.InterfaceAttachFailed(
4881                     instance_uuid=instance.uuid)
4882         image_meta = objects.ImageMeta.from_instance(instance)
4883 
4884         try:
4885             self.driver.attach_interface(instance, image_meta, network_info[0])
4886         except exception.NovaException as ex:
4887             port_id = network_info[0].get('id')
4888             LOG.warning(_LW("attach interface failed , try to deallocate "
4889                          "port %(port_id)s, reason: %(msg)s"),
4890                      {'port_id': port_id, 'msg': ex},
4891                      instance=instance)
4892             try:
4893                 self.network_api.deallocate_port_for_instance(
4894                     context, instance, port_id)
4895             except Exception:
4896                 LOG.warning(_LW("deallocate port %(port_id)s failed"),
4897                              {'port_id': port_id}, instance=instance)
4898             raise exception.InterfaceAttachFailed(
4899                 instance_uuid=instance.uuid)
4900 
4901         return network_info[0]
4902 
4903     @wrap_exception()
4904     @wrap_instance_fault
4905     def detach_interface(self, context, instance, port_id):
4906         """Detach an network adapter from an instance."""
4907         network_info = instance.info_cache.network_info
4908         condemned = None
4909         for vif in network_info:
4910             if vif['id'] == port_id:
4911                 condemned = vif
4912                 break
4913         if condemned is None:
4914             raise exception.PortNotFound(_("Port %s is not "
4915                                            "attached") % port_id)
4916         try:
4917             self.driver.detach_interface(instance, condemned)
4918         except exception.NovaException as ex:
4919             LOG.warning(_LW("Detach interface failed, port_id=%(port_id)s,"
4920                             " reason: %(msg)s"),
4921                         {'port_id': port_id, 'msg': ex}, instance=instance)
4922             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
4923         else:
4924             try:
4925                 self.network_api.deallocate_port_for_instance(
4926                     context, instance, port_id)
4927             except Exception as ex:
4928                 with excutils.save_and_reraise_exception():
4929                     # Since this is a cast operation, log the failure for
4930                     # triage.
4931                     LOG.warning(_LW('Failed to deallocate port %(port_id)s '
4932                                     'for instance. Error: %(error)s'),
4933                                 {'port_id': port_id, 'error': ex},
4934                                 instance=instance)
4935 
4936     def _get_compute_info(self, context, host):
4937         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
4938             context, host)
4939 
4940     @wrap_exception()
4941     def check_instance_shared_storage(self, ctxt, instance, data):
4942         """Check if the instance files are shared
4943 
4944         :param ctxt: security context
4945         :param instance: dict of instance data
4946         :param data: result of driver.check_instance_shared_storage_local
4947 
4948         Returns True if instance disks located on shared storage and
4949         False otherwise.
4950         """
4951         return self.driver.check_instance_shared_storage_remote(ctxt, data)
4952 
4953     @wrap_exception()
4954     @wrap_instance_event
4955     @wrap_instance_fault
4956     def check_can_live_migrate_destination(self, ctxt, instance,
4957                                            block_migration, disk_over_commit):
4958         """Check if it is possible to execute live migration.
4959 
4960         This runs checks on the destination host, and then calls
4961         back to the source host to check the results.
4962 
4963         :param context: security context
4964         :param instance: dict of instance data
4965         :param block_migration: if true, prepare for block migration
4966                                 if None, calculate it in driver
4967         :param disk_over_commit: if true, allow disk over commit
4968                                  if None, ignore disk usage checking
4969         :returns: a dict containing migration info
4970         """
4971         return self._do_check_can_live_migrate_destination(ctxt, instance,
4972                                                             block_migration,
4973                                                             disk_over_commit)
4974 
4975     def _do_check_can_live_migrate_destination(self, ctxt, instance,
4976                                                block_migration,
4977                                                disk_over_commit):
4978         src_compute_info = obj_base.obj_to_primitive(
4979             self._get_compute_info(ctxt, instance.host))
4980         dst_compute_info = obj_base.obj_to_primitive(
4981             self._get_compute_info(ctxt, CONF.host))
4982         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
4983             instance, src_compute_info, dst_compute_info,
4984             block_migration, disk_over_commit)
4985         LOG.debug('destination check data is %s', dest_check_data)
4986         try:
4987             migrate_data = self.compute_rpcapi.\
4988                                 check_can_live_migrate_source(ctxt, instance,
4989                                                               dest_check_data)
4990         finally:
4991             self.driver.check_can_live_migrate_destination_cleanup(ctxt,
4992                     dest_check_data)
4993         return migrate_data
4994 
4995     @wrap_exception()
4996     @wrap_instance_event
4997     @wrap_instance_fault
4998     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
4999         """Check if it is possible to execute live migration.
5000 
5001         This checks if the live migration can succeed, based on the
5002         results from check_can_live_migrate_destination.
5003 
5004         :param ctxt: security context
5005         :param instance: dict of instance data
5006         :param dest_check_data: result of check_can_live_migrate_destination
5007         :returns: a dict containing migration info
5008         """
5009         is_volume_backed = self.compute_api.is_volume_backed_instance(ctxt,
5010                                                                       instance)
5011         got_migrate_data_object = isinstance(dest_check_data,
5012                                              migrate_data_obj.LiveMigrateData)
5013         if not got_migrate_data_object:
5014             dest_check_data = \
5015                 migrate_data_obj.LiveMigrateData.detect_implementation(
5016                     dest_check_data)
5017         dest_check_data.is_volume_backed = is_volume_backed
5018         block_device_info = self._get_instance_block_device_info(
5019                             ctxt, instance, refresh_conn_info=True)
5020         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5021                                                            dest_check_data,
5022                                                            block_device_info)
5023         if not got_migrate_data_object:
5024             result = result.to_legacy_dict()
5025         LOG.debug('source check data is %s', result)
5026         return result
5027 
5028     @wrap_exception()
5029     @wrap_instance_event
5030     @wrap_instance_fault
5031     def pre_live_migration(self, context, instance, block_migration, disk,
5032                            migrate_data):
5033         """Preparations for live migration at dest host.
5034 
5035         :param context: security context
5036         :param instance: dict of instance data
5037         :param block_migration: if true, prepare for block migration
5038         :param migrate_data: if not None, it is a dict which holds data
5039                              required for live migration without shared
5040                              storage.
5041 
5042         """
5043         LOG.debug('pre_live_migration data is %s', migrate_data)
5044         got_migrate_data_object = isinstance(migrate_data,
5045                                              migrate_data_obj.LiveMigrateData)
5046         if not got_migrate_data_object:
5047             migrate_data = \
5048                 migrate_data_obj.LiveMigrateData.detect_implementation(
5049                     migrate_data)
5050         block_device_info = self._get_instance_block_device_info(
5051                             context, instance, refresh_conn_info=True)
5052 
5053         network_info = self.network_api.get_instance_nw_info(context, instance)
5054         self._notify_about_instance_usage(
5055                      context, instance, "live_migration.pre.start",
5056                      network_info=network_info)
5057 
5058         migrate_data = self.driver.pre_live_migration(context,
5059                                        instance,
5060                                        block_device_info,
5061                                        network_info,
5062                                        disk,
5063                                        migrate_data)
5064         LOG.debug('driver pre_live_migration data is %s' % migrate_data)
5065 
5066         # NOTE(tr3buchet): setup networks on destination host
5067         self.network_api.setup_networks_on_host(context, instance,
5068                                                          self.host)
5069 
5070         # Creating filters to hypervisors and firewalls.
5071         # An example is that nova-instance-instance-xxx,
5072         # which is written to libvirt.xml(Check "virsh nwfilter-list")
5073         # This nwfilter is necessary on the destination host.
5074         # In addition, this method is creating filtering rule
5075         # onto destination host.
5076         self.driver.ensure_filtering_rules_for_instance(instance,
5077                                             network_info)
5078 
5079         self._notify_about_instance_usage(
5080                      context, instance, "live_migration.pre.end",
5081                      network_info=network_info)
5082 
5083         if not got_migrate_data_object and migrate_data:
5084             migrate_data = migrate_data.to_legacy_dict(
5085                 pre_migration_result=True)
5086             migrate_data = migrate_data['pre_live_migration_result']
5087         LOG.debug('pre_live_migration result data is %s', migrate_data)
5088         return migrate_data
5089 
5090     def _do_live_migration(self, context, dest, instance, block_migration,
5091                            migration, migrate_data):
5092         # NOTE(danms): We should enhance the RT to account for migrations
5093         # and use the status field to denote when the accounting has been
5094         # done on source/destination. For now, this is just here for status
5095         # reporting
5096         self._set_migration_status(migration, 'preparing')
5097 
5098         got_migrate_data_object = isinstance(migrate_data,
5099                                              migrate_data_obj.LiveMigrateData)
5100         if not got_migrate_data_object:
5101             migrate_data = \
5102                 migrate_data_obj.LiveMigrateData.detect_implementation(
5103                     migrate_data)
5104 
5105         try:
5106             if ('block_migration' in migrate_data and
5107                     migrate_data.block_migration):
5108                 block_device_info = self._get_instance_block_device_info(
5109                     context, instance)
5110                 disk = self.driver.get_instance_disk_info(
5111                     instance, block_device_info=block_device_info)
5112             else:
5113                 disk = None
5114 
5115             migrate_data = self.compute_rpcapi.pre_live_migration(
5116                 context, instance,
5117                 block_migration, disk, dest, migrate_data)
5118         except Exception:
5119             with excutils.save_and_reraise_exception():
5120                 LOG.exception(_LE('Pre live migration failed at %s'),
5121                               dest, instance=instance)
5122                 self._set_migration_status(migration, 'failed')
5123                 self._rollback_live_migration(context, instance, dest,
5124                                               block_migration, migrate_data)
5125 
5126         self._set_migration_status(migration, 'running')
5127 
5128         if migrate_data:
5129             migrate_data.migration = migration
5130         LOG.debug('live_migration data is %s', migrate_data)
5131         try:
5132             self.driver.live_migration(context, instance, dest,
5133                                        self._post_live_migration,
5134                                        self._rollback_live_migration,
5135                                        block_migration, migrate_data)
5136         except Exception:
5137             # Executing live migration
5138             # live_migration might raises exceptions, but
5139             # nothing must be recovered in this version.
5140             LOG.exception(_LE('Live migration failed.'), instance=instance)
5141             with excutils.save_and_reraise_exception():
5142                 self._set_migration_status(migration, 'failed')
5143 
5144     @wrap_exception()
5145     @wrap_instance_event
5146     @wrap_instance_fault
5147     def live_migration(self, context, dest, instance, block_migration,
5148                        migration, migrate_data):
5149         """Executing live migration.
5150 
5151         :param context: security context
5152         :param dest: destination host
5153         :param instance: a nova.objects.instance.Instance object
5154         :param block_migration: if true, prepare for block migration
5155         :param migration: an nova.objects.Migration object
5156         :param migrate_data: implementation specific params
5157 
5158         """
5159         self._set_migration_status(migration, 'queued')
5160 
5161         def dispatch_live_migration(*args, **kwargs):
5162             with self._live_migration_semaphore:
5163                 self._do_live_migration(*args, **kwargs)
5164 
5165         # NOTE(danms): We spawn here to return the RPC worker thread back to
5166         # the pool. Since what follows could take a really long time, we don't
5167         # want to tie up RPC workers.
5168         utils.spawn_n(dispatch_live_migration,
5169                       context, dest, instance,
5170                       block_migration, migration,
5171                       migrate_data)
5172 
5173     @wrap_exception()
5174     @wrap_instance_event
5175     @wrap_instance_fault
5176     def live_migration_force_complete(self, context, instance, migration_id):
5177         """Force live migration to complete.
5178 
5179         :param context: Security context
5180         :param instance: The instance that is being migrated
5181         :param migration_id: ID of ongoing migration
5182 
5183         """
5184         migration = objects.Migration.get_by_id(context, migration_id)
5185         if migration.status != 'running':
5186             raise exception.InvalidMigrationState(migration_id=migration_id,
5187                                                   instance_uuid=instance.uuid,
5188                                                   state=migration.status,
5189                                                   method='force complete')
5190 
5191         self._notify_about_instance_usage(
5192             context, instance, 'live.migration.force.complete.start')
5193         self.driver.live_migration_force_complete(instance)
5194         self._notify_about_instance_usage(
5195             context, instance, 'live.migration.force.complete.end')
5196 
5197     @wrap_exception()
5198     @wrap_instance_event
5199     @wrap_instance_fault
5200     def live_migration_abort(self, context, instance, migration_id):
5201         """Abort an in-progress live migration.
5202 
5203         :param context: Security context
5204         :param instance: The instance that is being migrated
5205         :param migration_id: ID of in-progress live migration
5206 
5207         """
5208         migration = objects.Migration.get_by_id(context, migration_id)
5209         if migration.status != 'running':
5210             raise exception.InvalidMigrationState(migration_id=migration_id,
5211                     instance_uuid=instance.uuid,
5212                     state=migration.status,
5213                     method='abort live migration')
5214 
5215         self._notify_about_instance_usage(
5216             context, instance, 'live.migration.abort.start')
5217         self.driver.live_migration_abort(instance)
5218         self._notify_about_instance_usage(
5219             context, instance, 'live.migration.abort.end')
5220 
5221     def _live_migration_cleanup_flags(self, migrate_data):
5222         """Determine whether disks or instance path need to be cleaned up after
5223         live migration (at source on success, at destination on rollback)
5224 
5225         Block migration needs empty image at destination host before migration
5226         starts, so if any failure occurs, any empty images has to be deleted.
5227 
5228         Also Volume backed live migration w/o shared storage needs to delete
5229         newly created instance-xxx dir on the destination as a part of its
5230         rollback process
5231 
5232         :param migrate_data: implementation specific data
5233         :returns: (bool, bool) -- do_cleanup, destroy_disks
5234         """
5235         # NOTE(pkoniszewski): block migration specific params are set inside
5236         # migrate_data objects for drivers that expose block live migration
5237         # information (i.e. Libvirt and Xenapi). For other drivers cleanup is
5238         # not needed.
5239         is_shared_block_storage = True
5240         is_shared_instance_path = True
5241         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
5242             is_shared_block_storage = migrate_data.is_shared_block_storage
5243             is_shared_instance_path = migrate_data.is_shared_instance_path
5244         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
5245             is_shared_block_storage = not migrate_data.block_migration
5246             is_shared_instance_path = not migrate_data.block_migration
5247 
5248         # No instance booting at source host, but instance dir
5249         # must be deleted for preparing next block migration
5250         # must be deleted for preparing next live migration w/o shared storage
5251         do_cleanup = not is_shared_instance_path
5252         destroy_disks = not is_shared_block_storage
5253 
5254         return (do_cleanup, destroy_disks)
5255 
5256     @wrap_exception()
5257     @wrap_instance_fault
5258     def _post_live_migration(self, ctxt, instance,
5259                             dest, block_migration=False, migrate_data=None):
5260         """Post operations for live migration.
5261 
5262         This method is called from live_migration
5263         and mainly updating database record.
5264 
5265         :param ctxt: security context
5266         :param instance: instance dict
5267         :param dest: destination host
5268         :param block_migration: if true, prepare for block migration
5269         :param migrate_data: if not None, it is a dict which has data
5270         required for live migration without shared storage
5271 
5272         """
5273         LOG.info(_LI('_post_live_migration() is started..'),
5274                  instance=instance)
5275 
5276         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5277                 ctxt, instance.uuid)
5278 
5279         # Cleanup source host post live-migration
5280         block_device_info = self._get_instance_block_device_info(
5281                             ctxt, instance, bdms=bdms)
5282         self.driver.post_live_migration(ctxt, instance, block_device_info,
5283                                         migrate_data)
5284 
5285         # Detaching volumes.
5286         connector = self.driver.get_volume_connector(instance)
5287         for bdm in bdms:
5288             # NOTE(vish): We don't want to actually mark the volume
5289             #             detached, or delete the bdm, just remove the
5290             #             connection from this host.
5291 
5292             # remove the volume connection without detaching from hypervisor
5293             # because the instance is not running anymore on the current host
5294             if bdm.is_volume:
5295                 self.volume_api.terminate_connection(ctxt, bdm.volume_id,
5296                                                      connector)
5297 
5298         # Releasing vlan.
5299         # (not necessary in current implementation?)
5300 
5301         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
5302 
5303         self._notify_about_instance_usage(ctxt, instance,
5304                                           "live_migration._post.start",
5305                                           network_info=network_info)
5306         # Releasing security group ingress rule.
5307         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
5308                   instance=instance)
5309         self.driver.unfilter_instance(instance,
5310                                       network_info)
5311 
5312         migration = {'source_compute': self.host,
5313                      'dest_compute': dest, }
5314         self.network_api.migrate_instance_start(ctxt,
5315                                                 instance,
5316                                                 migration)
5317 
5318         destroy_vifs = False
5319         try:
5320             self.driver.post_live_migration_at_source(ctxt, instance,
5321                                                       network_info)
5322         except NotImplementedError as ex:
5323             LOG.debug(ex, instance=instance)
5324             # For all hypervisors other than libvirt, there is a possibility
5325             # they are unplugging networks from source node in the cleanup
5326             # method
5327             destroy_vifs = True
5328 
5329         # Define domain at destination host, without doing it,
5330         # pause/suspend/terminate do not work.
5331         self.compute_rpcapi.post_live_migration_at_destination(ctxt,
5332                 instance, block_migration, dest)
5333 
5334         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5335                 migrate_data)
5336 
5337         if do_cleanup:
5338             LOG.debug('Calling driver.cleanup from _post_live_migration',
5339                       instance=instance)
5340             self.driver.cleanup(ctxt, instance, network_info,
5341                                 destroy_disks=destroy_disks,
5342                                 migrate_data=migrate_data,
5343                                 destroy_vifs=destroy_vifs)
5344 
5345         self.instance_events.clear_events_for_instance(instance)
5346 
5347         # NOTE(timello): make sure we update available resources on source
5348         # host even before next periodic task.
5349         self.update_available_resource(ctxt)
5350 
5351         self._update_scheduler_instance_info(ctxt, instance)
5352         self._notify_about_instance_usage(ctxt, instance,
5353                                           "live_migration._post.end",
5354                                           network_info=network_info)
5355         LOG.info(_LI('Migrating instance to %s finished successfully.'),
5356                  dest, instance=instance)
5357         LOG.info(_LI("You may see the error \"libvirt: QEMU error: "
5358                      "Domain not found: no domain with matching name.\" "
5359                      "This error can be safely ignored."),
5360                  instance=instance)
5361 
5362         self._clean_instance_console_tokens(ctxt, instance)
5363         if migrate_data and migrate_data.obj_attr_is_set('migration'):
5364             migrate_data.migration.status = 'completed'
5365             migrate_data.migration.save()
5366 
5367     def _consoles_enabled(self):
5368         """Returns whether a console is enable."""
5369         return (CONF.vnc.enabled or CONF.spice.enabled or
5370                 CONF.rdp.enabled or CONF.serial_console.enabled or
5371                 CONF.mks.enabled)
5372 
5373     def _clean_instance_console_tokens(self, ctxt, instance):
5374         """Clean console tokens stored for an instance."""
5375         if self._consoles_enabled():
5376             if CONF.cells.enable:
5377                 self.cells_rpcapi.consoleauth_delete_tokens(
5378                     ctxt, instance.uuid)
5379             else:
5380                 self.consoleauth_rpcapi.delete_tokens_for_instance(
5381                     ctxt, instance.uuid)
5382 
5383     @wrap_exception()
5384     @wrap_instance_event
5385     @wrap_instance_fault
5386     def post_live_migration_at_destination(self, context, instance,
5387                                            block_migration):
5388         """Post operations for live migration .
5389 
5390         :param context: security context
5391         :param instance: Instance dict
5392         :param block_migration: if true, prepare for block migration
5393 
5394         """
5395         LOG.info(_LI('Post operation of migration started'),
5396                  instance=instance)
5397 
5398         # NOTE(tr3buchet): setup networks on destination host
5399         #                  this is called a second time because
5400         #                  multi_host does not create the bridge in
5401         #                  plug_vifs
5402         self.network_api.setup_networks_on_host(context, instance,
5403                                                          self.host)
5404         migration = {'source_compute': instance.host,
5405                      'dest_compute': self.host, }
5406         self.network_api.migrate_instance_finish(context,
5407                                                  instance,
5408                                                  migration)
5409 
5410         network_info = self.network_api.get_instance_nw_info(context, instance)
5411         self._notify_about_instance_usage(
5412                      context, instance, "live_migration.post.dest.start",
5413                      network_info=network_info)
5414         block_device_info = self._get_instance_block_device_info(context,
5415                                                                  instance)
5416 
5417         try:
5418             self.driver.post_live_migration_at_destination(
5419                 context, instance, network_info, block_migration,
5420                 block_device_info)
5421         except Exception:
5422             with excutils.save_and_reraise_exception():
5423                 instance.vm_state = vm_states.ERROR
5424                 LOG.error(_LE('Unexpected error during post live migration at '
5425                               'destination host.'), instance=instance)
5426         finally:
5427             # Restore instance state and update host
5428             current_power_state = self._get_power_state(context, instance)
5429             node_name = None
5430             prev_host = instance.host
5431             try:
5432                 compute_node = self._get_compute_info(context, self.host)
5433                 node_name = compute_node.hypervisor_hostname
5434             except exception.ComputeHostNotFound:
5435                 LOG.exception(_LE('Failed to get compute_info for %s'),
5436                               self.host)
5437             finally:
5438                 instance.host = self.host
5439                 instance.power_state = current_power_state
5440                 instance.task_state = None
5441                 instance.node = node_name
5442                 instance.progress = 0
5443                 instance.save(expected_task_state=task_states.MIGRATING)
5444 
5445         # NOTE(tr3buchet): tear down networks on source host
5446         self.network_api.setup_networks_on_host(context, instance,
5447                                                 prev_host, teardown=True)
5448         # NOTE(vish): this is necessary to update dhcp
5449         self.network_api.setup_networks_on_host(context, instance, self.host)
5450         self._notify_about_instance_usage(
5451                      context, instance, "live_migration.post.dest.end",
5452                      network_info=network_info)
5453 
5454     @wrap_exception()
5455     @wrap_instance_fault
5456     def _rollback_live_migration(self, context, instance,
5457                                  dest, block_migration, migrate_data=None,
5458                                  migration_status='error'):
5459         """Recovers Instance/volume state from migrating -> running.
5460 
5461         :param context: security context
5462         :param instance: nova.objects.instance.Instance object
5463         :param dest:
5464             This method is called from live migration src host.
5465             This param specifies destination host.
5466         :param block_migration: if true, prepare for block migration
5467         :param migrate_data:
5468             if not none, contains implementation specific data.
5469         :param migration_status:
5470             Contains the status we want to set for the migration object
5471 
5472         """
5473         instance.task_state = None
5474         instance.progress = 0
5475         instance.save(expected_task_state=[task_states.MIGRATING])
5476 
5477         if isinstance(migrate_data, dict):
5478             migration = migrate_data.pop('migration', None)
5479             migrate_data = \
5480                 migrate_data_obj.LiveMigrateData.detect_implementation(
5481                     migrate_data)
5482         elif (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
5483               migrate_data.obj_attr_is_set('migration')):
5484             migration = migrate_data.migration
5485         else:
5486             migration = None
5487 
5488         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
5489         self.network_api.setup_networks_on_host(context, instance, self.host)
5490 
5491         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5492                 context, instance.uuid)
5493         for bdm in bdms:
5494             if bdm.is_volume:
5495                 self.compute_rpcapi.remove_volume_connection(
5496                         context, bdm.volume_id, instance, dest)
5497 
5498         self._notify_about_instance_usage(context, instance,
5499                                           "live_migration._rollback.start")
5500 
5501         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5502                 migrate_data)
5503 
5504         if do_cleanup:
5505             self.compute_rpcapi.rollback_live_migration_at_destination(
5506                     context, instance, dest, destroy_disks=destroy_disks,
5507                     migrate_data=migrate_data)
5508 
5509         self._notify_about_instance_usage(context, instance,
5510                                           "live_migration._rollback.end")
5511 
5512         self._set_migration_status(migration, migration_status)
5513 
5514     @wrap_exception()
5515     @wrap_instance_event
5516     @wrap_instance_fault
5517     def rollback_live_migration_at_destination(self, context, instance,
5518                                                destroy_disks,
5519                                                migrate_data):
5520         """Cleaning up image directory that is created pre_live_migration.
5521 
5522         :param context: security context
5523         :param instance: a nova.objects.instance.Instance object sent over rpc
5524         """
5525         network_info = self.network_api.get_instance_nw_info(context, instance)
5526         self._notify_about_instance_usage(
5527                       context, instance, "live_migration.rollback.dest.start",
5528                       network_info=network_info)
5529         try:
5530             # NOTE(tr3buchet): tear down networks on destination host
5531             self.network_api.setup_networks_on_host(context, instance,
5532                                                     self.host, teardown=True)
5533         except Exception:
5534             with excutils.save_and_reraise_exception():
5535                 # NOTE(tdurakov): even if teardown networks fails driver
5536                 # should try to rollback live migration on destination.
5537                 LOG.exception(
5538                     _LE('An error occurred while deallocating network.'),
5539                     instance=instance)
5540         finally:
5541             # always run this even if setup_networks_on_host fails
5542             # NOTE(vish): The mapping is passed in so the driver can disconnect
5543             #             from remote volumes if necessary
5544             block_device_info = self._get_instance_block_device_info(context,
5545                                                                      instance)
5546             if isinstance(migrate_data, dict):
5547                 migrate_data = \
5548                     migrate_data_obj.LiveMigrateData.detect_implementation(
5549                         migrate_data)
5550             self.driver.rollback_live_migration_at_destination(
5551                 context, instance, network_info, block_device_info,
5552                 destroy_disks=destroy_disks, migrate_data=migrate_data)
5553 
5554         self._notify_about_instance_usage(
5555                         context, instance, "live_migration.rollback.dest.end",
5556                         network_info=network_info)
5557 
5558     @periodic_task.periodic_task(
5559         spacing=CONF.heal_instance_info_cache_interval)
5560     def _heal_instance_info_cache(self, context):
5561         """Called periodically.  On every call, try to update the
5562         info_cache's network information for another instance by
5563         calling to the network manager.
5564 
5565         This is implemented by keeping a cache of uuids of instances
5566         that live on this host.  On each call, we pop one off of a
5567         list, pull the DB record, and try the call to the network API.
5568         If anything errors don't fail, as it's possible the instance
5569         has been deleted, etc.
5570         """
5571         heal_interval = CONF.heal_instance_info_cache_interval
5572         if not heal_interval:
5573             return
5574 
5575         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
5576         instance = None
5577 
5578         LOG.debug('Starting heal instance info cache')
5579 
5580         if not instance_uuids:
5581             # The list of instances to heal is empty so rebuild it
5582             LOG.debug('Rebuilding the list of instances to heal')
5583             db_instances = objects.InstanceList.get_by_host(
5584                 context, self.host, expected_attrs=[], use_slave=True)
5585             for inst in db_instances:
5586                 # We don't want to refresh the cache for instances
5587                 # which are building or deleting so don't put them
5588                 # in the list. If they are building they will get
5589                 # added to the list next time we build it.
5590                 if (inst.vm_state == vm_states.BUILDING):
5591                     LOG.debug('Skipping network cache update for instance '
5592                               'because it is Building.', instance=inst)
5593                     continue
5594                 if (inst.task_state == task_states.DELETING):
5595                     LOG.debug('Skipping network cache update for instance '
5596                               'because it is being deleted.', instance=inst)
5597                     continue
5598 
5599                 if not instance:
5600                     # Save the first one we find so we don't
5601                     # have to get it again
5602                     instance = inst
5603                 else:
5604                     instance_uuids.append(inst['uuid'])
5605 
5606             self._instance_uuids_to_heal = instance_uuids
5607         else:
5608             # Find the next valid instance on the list
5609             while instance_uuids:
5610                 try:
5611                     inst = objects.Instance.get_by_uuid(
5612                             context, instance_uuids.pop(0),
5613                             expected_attrs=['system_metadata', 'info_cache',
5614                                             'flavor'],
5615                             use_slave=True)
5616                 except exception.InstanceNotFound:
5617                     # Instance is gone.  Try to grab another.
5618                     continue
5619 
5620                 # Check the instance hasn't been migrated
5621                 if inst.host != self.host:
5622                     LOG.debug('Skipping network cache update for instance '
5623                               'because it has been migrated to another '
5624                               'host.', instance=inst)
5625                 # Check the instance isn't being deleting
5626                 elif inst.task_state == task_states.DELETING:
5627                     LOG.debug('Skipping network cache update for instance '
5628                               'because it is being deleted.', instance=inst)
5629                 else:
5630                     instance = inst
5631                     break
5632 
5633         if instance:
5634             # We have an instance now to refresh
5635             try:
5636                 # Call to network API to get instance info.. this will
5637                 # force an update to the instance's info_cache
5638                 self.network_api.get_instance_nw_info(context, instance)
5639                 LOG.debug('Updated the network info_cache for instance',
5640                           instance=instance)
5641             except exception.InstanceNotFound:
5642                 # Instance is gone.
5643                 LOG.debug('Instance no longer exists. Unable to refresh',
5644                           instance=instance)
5645                 return
5646             except exception.InstanceInfoCacheNotFound:
5647                 # InstanceInfoCache is gone.
5648                 LOG.debug('InstanceInfoCache no longer exists. '
5649                           'Unable to refresh', instance=instance)
5650             except Exception:
5651                 LOG.error(_LE('An error occurred while refreshing the network '
5652                               'cache.'), instance=instance, exc_info=True)
5653         else:
5654             LOG.debug("Didn't find any instances for network info cache "
5655                       "update.")
5656 
5657     @periodic_task.periodic_task
5658     def _poll_rebooting_instances(self, context):
5659         if CONF.reboot_timeout > 0:
5660             filters = {'task_state':
5661                        [task_states.REBOOTING,
5662                         task_states.REBOOT_STARTED,
5663                         task_states.REBOOT_PENDING],
5664                        'host': self.host}
5665             rebooting = objects.InstanceList.get_by_filters(
5666                 context, filters, expected_attrs=[], use_slave=True)
5667 
5668             to_poll = []
5669             for instance in rebooting:
5670                 if timeutils.is_older_than(instance.updated_at,
5671                                            CONF.reboot_timeout):
5672                     to_poll.append(instance)
5673 
5674             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
5675 
5676     @periodic_task.periodic_task
5677     def _poll_rescued_instances(self, context):
5678         if CONF.rescue_timeout > 0:
5679             filters = {'vm_state': vm_states.RESCUED,
5680                        'host': self.host}
5681             rescued_instances = objects.InstanceList.get_by_filters(
5682                 context, filters, expected_attrs=["system_metadata"],
5683                 use_slave=True)
5684 
5685             to_unrescue = []
5686             for instance in rescued_instances:
5687                 if timeutils.is_older_than(instance.launched_at,
5688                                            CONF.rescue_timeout):
5689                     to_unrescue.append(instance)
5690 
5691             for instance in to_unrescue:
5692                 self.compute_api.unrescue(context, instance)
5693 
5694     @periodic_task.periodic_task
5695     def _poll_unconfirmed_resizes(self, context):
5696         if CONF.resize_confirm_window == 0:
5697             return
5698 
5699         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
5700                 context, CONF.resize_confirm_window, self.host,
5701                 use_slave=True)
5702 
5703         migrations_info = dict(migration_count=len(migrations),
5704                 confirm_window=CONF.resize_confirm_window)
5705 
5706         if migrations_info["migration_count"] > 0:
5707             LOG.info(_LI("Found %(migration_count)d unconfirmed migrations "
5708                          "older than %(confirm_window)d seconds"),
5709                      migrations_info)
5710 
5711         def _set_migration_to_error(migration, reason, **kwargs):
5712             LOG.warning(_LW("Setting migration %(migration_id)s to error: "
5713                          "%(reason)s"),
5714                      {'migration_id': migration['id'], 'reason': reason},
5715                      **kwargs)
5716             migration.status = 'error'
5717             with migration.obj_as_admin():
5718                 migration.save()
5719 
5720         for migration in migrations:
5721             instance_uuid = migration.instance_uuid
5722             LOG.info(_LI("Automatically confirming migration "
5723                          "%(migration_id)s for instance %(instance_uuid)s"),
5724                      {'migration_id': migration.id,
5725                       'instance_uuid': instance_uuid})
5726             expected_attrs = ['metadata', 'system_metadata']
5727             try:
5728                 instance = objects.Instance.get_by_uuid(context,
5729                             instance_uuid, expected_attrs=expected_attrs,
5730                             use_slave=True)
5731             except exception.InstanceNotFound:
5732                 reason = (_("Instance %s not found") %
5733                           instance_uuid)
5734                 _set_migration_to_error(migration, reason)
5735                 continue
5736             if instance.vm_state == vm_states.ERROR:
5737                 reason = _("In ERROR state")
5738                 _set_migration_to_error(migration, reason,
5739                                         instance=instance)
5740                 continue
5741             # race condition: The instance in DELETING state should not be
5742             # set the migration state to error, otherwise the instance in
5743             # to be deleted which is in RESIZED state
5744             # will not be able to confirm resize
5745             if instance.task_state in [task_states.DELETING,
5746                                        task_states.SOFT_DELETING]:
5747                 msg = ("Instance being deleted or soft deleted during resize "
5748                        "confirmation. Skipping.")
5749                 LOG.debug(msg, instance=instance)
5750                 continue
5751 
5752             # race condition: This condition is hit when this method is
5753             # called between the save of the migration record with a status of
5754             # finished and the save of the instance object with a state of
5755             # RESIZED. The migration record should not be set to error.
5756             if instance.task_state == task_states.RESIZE_FINISH:
5757                 msg = ("Instance still resizing during resize "
5758                        "confirmation. Skipping.")
5759                 LOG.debug(msg, instance=instance)
5760                 continue
5761 
5762             vm_state = instance.vm_state
5763             task_state = instance.task_state
5764             if vm_state != vm_states.RESIZED or task_state is not None:
5765                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
5766                            "RESIZED/None") %
5767                           {'vm_state': vm_state,
5768                            'task_state': task_state})
5769                 _set_migration_to_error(migration, reason,
5770                                         instance=instance)
5771                 continue
5772             try:
5773                 self.compute_api.confirm_resize(context, instance,
5774                                                 migration=migration)
5775             except Exception as e:
5776                 LOG.info(_LI("Error auto-confirming resize: %s. "
5777                              "Will retry later."),
5778                          e, instance=instance)
5779 
5780     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
5781     def _poll_shelved_instances(self, context):
5782 
5783         if CONF.shelved_offload_time <= 0:
5784             return
5785 
5786         filters = {'vm_state': vm_states.SHELVED,
5787                    'task_state': None,
5788                    'host': self.host}
5789         shelved_instances = objects.InstanceList.get_by_filters(
5790             context, filters=filters, expected_attrs=['system_metadata'],
5791             use_slave=True)
5792 
5793         to_gc = []
5794         for instance in shelved_instances:
5795             sys_meta = instance.system_metadata
5796             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
5797             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
5798                 to_gc.append(instance)
5799 
5800         for instance in to_gc:
5801             try:
5802                 instance.task_state = task_states.SHELVING_OFFLOADING
5803                 instance.save(expected_task_state=(None,))
5804                 self.shelve_offload_instance(context, instance,
5805                                              clean_shutdown=False)
5806             except Exception:
5807                 LOG.exception(_LE('Periodic task failed to offload instance.'),
5808                         instance=instance)
5809 
5810     @periodic_task.periodic_task
5811     def _instance_usage_audit(self, context):
5812         if not CONF.instance_usage_audit:
5813             return
5814 
5815         begin, end = utils.last_completed_audit_period()
5816         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
5817                                self.host):
5818             return
5819 
5820         instances = objects.InstanceList.get_active_by_window_joined(
5821             context, begin, end, host=self.host,
5822             expected_attrs=['system_metadata', 'info_cache', 'metadata',
5823                             'flavor'],
5824             use_slave=True)
5825         num_instances = len(instances)
5826         errors = 0
5827         successes = 0
5828         LOG.info(_LI("Running instance usage audit for"
5829                      " host %(host)s from %(begin_time)s to "
5830                      "%(end_time)s. %(number_instances)s"
5831                      " instances."),
5832                  {'host': self.host,
5833                   'begin_time': begin,
5834                   'end_time': end,
5835                   'number_instances': num_instances})
5836         start_time = time.time()
5837         task_log = objects.TaskLog(context)
5838         task_log.task_name = 'instance_usage_audit'
5839         task_log.period_beginning = begin
5840         task_log.period_ending = end
5841         task_log.host = self.host
5842         task_log.task_items = num_instances
5843         task_log.message = 'Instance usage audit started...'
5844         task_log.begin_task()
5845         for instance in instances:
5846             try:
5847                 compute_utils.notify_usage_exists(
5848                     self.notifier, context, instance,
5849                     ignore_missing_network_data=False)
5850                 successes += 1
5851             except Exception:
5852                 LOG.exception(_LE('Failed to generate usage '
5853                                   'audit for instance '
5854                                   'on host %s'), self.host,
5855                               instance=instance)
5856                 errors += 1
5857         task_log.errors = errors
5858         task_log.message = (
5859             'Instance usage audit ran for host %s, %s instances in %s seconds.'
5860             % (self.host, num_instances, time.time() - start_time))
5861         task_log.end_task()
5862 
5863     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
5864     def _poll_bandwidth_usage(self, context):
5865 
5866         if not self._bw_usage_supported:
5867             return
5868 
5869         prev_time, start_time = utils.last_completed_audit_period()
5870 
5871         curr_time = time.time()
5872         if (curr_time - self._last_bw_usage_poll >
5873                 CONF.bandwidth_poll_interval):
5874             self._last_bw_usage_poll = curr_time
5875             LOG.info(_LI("Updating bandwidth usage cache"))
5876             cells_update_interval = CONF.cells.bandwidth_update_interval
5877             if (cells_update_interval > 0 and
5878                    curr_time - self._last_bw_usage_cell_update >
5879                            cells_update_interval):
5880                 self._last_bw_usage_cell_update = curr_time
5881                 update_cells = True
5882             else:
5883                 update_cells = False
5884 
5885             instances = objects.InstanceList.get_by_host(context,
5886                                                               self.host,
5887                                                               use_slave=True)
5888             try:
5889                 bw_counters = self.driver.get_all_bw_counters(instances)
5890             except NotImplementedError:
5891                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
5892                 # implemented yet.  If they don't it doesn't break anything,
5893                 # they just don't get the info in the usage events.
5894                 # NOTE(PhilDay): Record that its not supported so we can
5895                 # skip fast on future calls rather than waste effort getting
5896                 # the list of instances.
5897                 LOG.info(_LI("Bandwidth usage not supported by "
5898                              "hypervisor."))
5899                 self._bw_usage_supported = False
5900                 return
5901 
5902             refreshed = timeutils.utcnow()
5903             for bw_ctr in bw_counters:
5904                 # Allow switching of greenthreads between queries.
5905                 greenthread.sleep(0)
5906                 bw_in = 0
5907                 bw_out = 0
5908                 last_ctr_in = None
5909                 last_ctr_out = None
5910                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
5911                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
5912                     start_period=start_time, use_slave=True)
5913                 if usage:
5914                     bw_in = usage.bw_in
5915                     bw_out = usage.bw_out
5916                     last_ctr_in = usage.last_ctr_in
5917                     last_ctr_out = usage.last_ctr_out
5918                 else:
5919                     usage = (objects.BandwidthUsage.
5920                              get_by_instance_uuid_and_mac(
5921                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
5922                         start_period=prev_time, use_slave=True))
5923                     if usage:
5924                         last_ctr_in = usage.last_ctr_in
5925                         last_ctr_out = usage.last_ctr_out
5926 
5927                 if last_ctr_in is not None:
5928                     if bw_ctr['bw_in'] < last_ctr_in:
5929                         # counter rollover
5930                         bw_in += bw_ctr['bw_in']
5931                     else:
5932                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
5933 
5934                 if last_ctr_out is not None:
5935                     if bw_ctr['bw_out'] < last_ctr_out:
5936                         # counter rollover
5937                         bw_out += bw_ctr['bw_out']
5938                     else:
5939                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
5940 
5941                 objects.BandwidthUsage(context=context).create(
5942                                               bw_ctr['uuid'],
5943                                               bw_ctr['mac_address'],
5944                                               bw_in,
5945                                               bw_out,
5946                                               bw_ctr['bw_in'],
5947                                               bw_ctr['bw_out'],
5948                                               start_period=start_time,
5949                                               last_refreshed=refreshed,
5950                                               update_cells=update_cells)
5951 
5952     def _get_host_volume_bdms(self, context, use_slave=False):
5953         """Return all block device mappings on a compute host."""
5954         compute_host_bdms = []
5955         instances = objects.InstanceList.get_by_host(context, self.host,
5956             use_slave=use_slave)
5957         for instance in instances:
5958             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5959                     context, instance.uuid, use_slave=use_slave)
5960             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
5961             compute_host_bdms.append(dict(instance=instance,
5962                                           instance_bdms=instance_bdms))
5963 
5964         return compute_host_bdms
5965 
5966     def _update_volume_usage_cache(self, context, vol_usages):
5967         """Updates the volume usage cache table with a list of stats."""
5968         for usage in vol_usages:
5969             # Allow switching of greenthreads between queries.
5970             greenthread.sleep(0)
5971             vol_usage = objects.VolumeUsage(context)
5972             vol_usage.volume_id = usage['volume']
5973             vol_usage.instance_uuid = usage['instance'].uuid
5974             vol_usage.project_id = usage['instance'].project_id
5975             vol_usage.user_id = usage['instance'].user_id
5976             vol_usage.availability_zone = usage['instance'].availability_zone
5977             vol_usage.curr_reads = usage['rd_req']
5978             vol_usage.curr_read_bytes = usage['rd_bytes']
5979             vol_usage.curr_writes = usage['wr_req']
5980             vol_usage.curr_write_bytes = usage['wr_bytes']
5981             vol_usage.save()
5982             self.notifier.info(context, 'volume.usage',
5983                                compute_utils.usage_volume_info(vol_usage))
5984 
5985     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
5986     def _poll_volume_usage(self, context):
5987         if CONF.volume_usage_poll_interval == 0:
5988             return
5989 
5990         compute_host_bdms = self._get_host_volume_bdms(context,
5991                                                        use_slave=True)
5992         if not compute_host_bdms:
5993             return
5994 
5995         LOG.debug("Updating volume usage cache")
5996         try:
5997             vol_usages = self.driver.get_all_volume_usage(context,
5998                                                           compute_host_bdms)
5999         except NotImplementedError:
6000             return
6001 
6002         self._update_volume_usage_cache(context, vol_usages)
6003 
6004     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
6005                                  run_immediately=True)
6006     def _sync_power_states(self, context):
6007         """Align power states between the database and the hypervisor.
6008 
6009         To sync power state data we make a DB call to get the number of
6010         virtual machines known by the hypervisor and if the number matches the
6011         number of virtual machines known by the database, we proceed in a lazy
6012         loop, one database record at a time, checking if the hypervisor has the
6013         same power state as is in the database.
6014         """
6015         db_instances = objects.InstanceList.get_by_host(context, self.host,
6016                                                         expected_attrs=[],
6017                                                         use_slave=True)
6018 
6019         num_vm_instances = self.driver.get_num_instances()
6020         num_db_instances = len(db_instances)
6021 
6022         if num_vm_instances != num_db_instances:
6023             LOG.warning(_LW("While synchronizing instance power states, found "
6024                             "%(num_db_instances)s instances in the database "
6025                             "and %(num_vm_instances)s instances on the "
6026                             "hypervisor."),
6027                         {'num_db_instances': num_db_instances,
6028                          'num_vm_instances': num_vm_instances})
6029 
6030         def _sync(db_instance):
6031             # NOTE(melwitt): This must be synchronized as we query state from
6032             #                two separate sources, the driver and the database.
6033             #                They are set (in stop_instance) and read, in sync.
6034             @utils.synchronized(db_instance.uuid)
6035             def query_driver_power_state_and_sync():
6036                 self._query_driver_power_state_and_sync(context, db_instance)
6037 
6038             try:
6039                 query_driver_power_state_and_sync()
6040             except Exception:
6041                 LOG.exception(_LE("Periodic sync_power_state task had an "
6042                                   "error while processing an instance."),
6043                               instance=db_instance)
6044 
6045             self._syncs_in_progress.pop(db_instance.uuid)
6046 
6047         for db_instance in db_instances:
6048             # process syncs asynchronously - don't want instance locking to
6049             # block entire periodic task thread
6050             uuid = db_instance.uuid
6051             if uuid in self._syncs_in_progress:
6052                 LOG.debug('Sync already in progress for %s' % uuid)
6053             else:
6054                 LOG.debug('Triggering sync for uuid %s' % uuid)
6055                 self._syncs_in_progress[uuid] = True
6056                 self._sync_power_pool.spawn_n(_sync, db_instance)
6057 
6058     def _query_driver_power_state_and_sync(self, context, db_instance):
6059         if db_instance.task_state is not None:
6060             LOG.info(_LI("During sync_power_state the instance has a "
6061                          "pending task (%(task)s). Skip."),
6062                      {'task': db_instance.task_state}, instance=db_instance)
6063             return
6064         # No pending tasks. Now try to figure out the real vm_power_state.
6065         try:
6066             vm_instance = self.driver.get_info(db_instance)
6067             vm_power_state = vm_instance.state
6068         except exception.InstanceNotFound:
6069             vm_power_state = power_state.NOSTATE
6070         # Note(maoy): the above get_info call might take a long time,
6071         # for example, because of a broken libvirt driver.
6072         try:
6073             self._sync_instance_power_state(context,
6074                                             db_instance,
6075                                             vm_power_state,
6076                                             use_slave=True)
6077         except exception.InstanceNotFound:
6078             # NOTE(hanlind): If the instance gets deleted during sync,
6079             # silently ignore.
6080             pass
6081 
6082     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
6083                                    use_slave=False):
6084         """Align instance power state between the database and hypervisor.
6085 
6086         If the instance is not found on the hypervisor, but is in the database,
6087         then a stop() API will be called on the instance.
6088         """
6089 
6090         # We re-query the DB to get the latest instance info to minimize
6091         # (not eliminate) race condition.
6092         db_instance.refresh(use_slave=use_slave)
6093         db_power_state = db_instance.power_state
6094         vm_state = db_instance.vm_state
6095 
6096         if self.host != db_instance.host:
6097             # on the sending end of nova-compute _sync_power_state
6098             # may have yielded to the greenthread performing a live
6099             # migration; this in turn has changed the resident-host
6100             # for the VM; However, the instance is still active, it
6101             # is just in the process of migrating to another host.
6102             # This implies that the compute source must relinquish
6103             # control to the compute destination.
6104             LOG.info(_LI("During the sync_power process the "
6105                          "instance has moved from "
6106                          "host %(src)s to host %(dst)s"),
6107                      {'src': db_instance.host,
6108                       'dst': self.host},
6109                      instance=db_instance)
6110             return
6111         elif db_instance.task_state is not None:
6112             # on the receiving end of nova-compute, it could happen
6113             # that the DB instance already report the new resident
6114             # but the actual VM has not showed up on the hypervisor
6115             # yet. In this case, let's allow the loop to continue
6116             # and run the state sync in a later round
6117             LOG.info(_LI("During sync_power_state the instance has a "
6118                          "pending task (%(task)s). Skip."),
6119                      {'task': db_instance.task_state},
6120                      instance=db_instance)
6121             return
6122 
6123         orig_db_power_state = db_power_state
6124         if vm_power_state != db_power_state:
6125             LOG.info(_LI('During _sync_instance_power_state the DB '
6126                          'power_state (%(db_power_state)s) does not match '
6127                          'the vm_power_state from the hypervisor '
6128                          '(%(vm_power_state)s). Updating power_state in the '
6129                          'DB to match the hypervisor.'),
6130                      {'db_power_state': db_power_state,
6131                       'vm_power_state': vm_power_state},
6132                      instance=db_instance)
6133             # power_state is always updated from hypervisor to db
6134             db_instance.power_state = vm_power_state
6135             db_instance.save()
6136             db_power_state = vm_power_state
6137 
6138         # Note(maoy): Now resolve the discrepancy between vm_state and
6139         # vm_power_state. We go through all possible vm_states.
6140         if vm_state in (vm_states.BUILDING,
6141                         vm_states.RESCUED,
6142                         vm_states.RESIZED,
6143                         vm_states.SUSPENDED,
6144                         vm_states.ERROR):
6145             # TODO(maoy): we ignore these vm_state for now.
6146             pass
6147         elif vm_state == vm_states.ACTIVE:
6148             # The only rational power state should be RUNNING
6149             if vm_power_state in (power_state.SHUTDOWN,
6150                                   power_state.CRASHED):
6151                 LOG.warning(_LW("Instance shutdown by itself. Calling the "
6152                                 "stop API. Current vm_state: %(vm_state)s, "
6153                                 "current task_state: %(task_state)s, "
6154                                 "original DB power_state: %(db_power_state)s, "
6155                                 "current VM power_state: %(vm_power_state)s"),
6156                             {'vm_state': vm_state,
6157                              'task_state': db_instance.task_state,
6158                              'db_power_state': orig_db_power_state,
6159                              'vm_power_state': vm_power_state},
6160                             instance=db_instance)
6161                 try:
6162                     # Note(maoy): here we call the API instead of
6163                     # brutally updating the vm_state in the database
6164                     # to allow all the hooks and checks to be performed.
6165                     if db_instance.shutdown_terminate:
6166                         self.compute_api.delete(context, db_instance)
6167                     else:
6168                         self.compute_api.stop(context, db_instance)
6169                 except Exception:
6170                     # Note(maoy): there is no need to propagate the error
6171                     # because the same power_state will be retrieved next
6172                     # time and retried.
6173                     # For example, there might be another task scheduled.
6174                     LOG.exception(_LE("error during stop() in "
6175                                       "sync_power_state."),
6176                                   instance=db_instance)
6177             elif vm_power_state == power_state.SUSPENDED:
6178                 LOG.warning(_LW("Instance is suspended unexpectedly. Calling "
6179                                 "the stop API."), instance=db_instance)
6180                 try:
6181                     self.compute_api.stop(context, db_instance)
6182                 except Exception:
6183                     LOG.exception(_LE("error during stop() in "
6184                                       "sync_power_state."),
6185                                   instance=db_instance)
6186             elif vm_power_state == power_state.PAUSED:
6187                 # Note(maoy): a VM may get into the paused state not only
6188                 # because the user request via API calls, but also
6189                 # due to (temporary) external instrumentations.
6190                 # Before the virt layer can reliably report the reason,
6191                 # we simply ignore the state discrepancy. In many cases,
6192                 # the VM state will go back to running after the external
6193                 # instrumentation is done. See bug 1097806 for details.
6194                 LOG.warning(_LW("Instance is paused unexpectedly. Ignore."),
6195                             instance=db_instance)
6196             elif vm_power_state == power_state.NOSTATE:
6197                 # Occasionally, depending on the status of the hypervisor,
6198                 # which could be restarting for example, an instance may
6199                 # not be found.  Therefore just log the condition.
6200                 LOG.warning(_LW("Instance is unexpectedly not found. Ignore."),
6201                             instance=db_instance)
6202         elif vm_state == vm_states.STOPPED:
6203             if vm_power_state not in (power_state.NOSTATE,
6204                                       power_state.SHUTDOWN,
6205                                       power_state.CRASHED):
6206                 LOG.warning(_LW("Instance is not stopped. Calling "
6207                                 "the stop API. Current vm_state: %(vm_state)s,"
6208                                 " current task_state: %(task_state)s, "
6209                                 "original DB power_state: %(db_power_state)s, "
6210                                 "current VM power_state: %(vm_power_state)s"),
6211                             {'vm_state': vm_state,
6212                              'task_state': db_instance.task_state,
6213                              'db_power_state': orig_db_power_state,
6214                              'vm_power_state': vm_power_state},
6215                             instance=db_instance)
6216                 try:
6217                     # NOTE(russellb) Force the stop, because normally the
6218                     # compute API would not allow an attempt to stop a stopped
6219                     # instance.
6220                     self.compute_api.force_stop(context, db_instance)
6221                 except Exception:
6222                     LOG.exception(_LE("error during stop() in "
6223                                       "sync_power_state."),
6224                                   instance=db_instance)
6225         elif vm_state == vm_states.PAUSED:
6226             if vm_power_state in (power_state.SHUTDOWN,
6227                                   power_state.CRASHED):
6228                 LOG.warning(_LW("Paused instance shutdown by itself. Calling "
6229                                 "the stop API."), instance=db_instance)
6230                 try:
6231                     self.compute_api.force_stop(context, db_instance)
6232                 except Exception:
6233                     LOG.exception(_LE("error during stop() in "
6234                                       "sync_power_state."),
6235                                   instance=db_instance)
6236         elif vm_state in (vm_states.SOFT_DELETED,
6237                           vm_states.DELETED):
6238             if vm_power_state not in (power_state.NOSTATE,
6239                                       power_state.SHUTDOWN):
6240                 # Note(maoy): this should be taken care of periodically in
6241                 # _cleanup_running_deleted_instances().
6242                 LOG.warning(_LW("Instance is not (soft-)deleted."),
6243                             instance=db_instance)
6244 
6245     @periodic_task.periodic_task
6246     def _reclaim_queued_deletes(self, context):
6247         """Reclaim instances that are queued for deletion."""
6248         interval = CONF.reclaim_instance_interval
6249         if interval <= 0:
6250             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
6251             return
6252 
6253         # TODO(comstud, jichenjc): Dummy quota object for now See bug 1296414.
6254         # The only case that the quota might be inconsistent is
6255         # the compute node died between set instance state to SOFT_DELETED
6256         # and quota commit to DB. When compute node starts again
6257         # it will have no idea the reservation is committed or not or even
6258         # expired, since it's a rare case, so marked as todo.
6259         quotas = objects.Quotas.from_reservations(context, None)
6260 
6261         filters = {'vm_state': vm_states.SOFT_DELETED,
6262                    'task_state': None,
6263                    'host': self.host}
6264         instances = objects.InstanceList.get_by_filters(
6265             context, filters,
6266             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
6267             use_slave=True)
6268         for instance in instances:
6269             if self._deleted_old_enough(instance, interval):
6270                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6271                         context, instance.uuid)
6272                 LOG.info(_LI('Reclaiming deleted instance'), instance=instance)
6273                 try:
6274                     self._delete_instance(context, instance, bdms, quotas)
6275                 except Exception as e:
6276                     LOG.warning(_LW("Periodic reclaim failed to delete "
6277                                     "instance: %s"),
6278                                 e, instance=instance)
6279 
6280     def update_available_resource_for_node(self, context, nodename):
6281 
6282         rt = self._get_resource_tracker(nodename)
6283         try:
6284             rt.update_available_resource(context)
6285         except exception.ComputeHostNotFound:
6286             # NOTE(comstud): We can get to this case if a node was
6287             # marked 'deleted' in the DB and then re-added with a
6288             # different auto-increment id. The cached resource
6289             # tracker tried to update a deleted record and failed.
6290             # Don't add this resource tracker to the new dict, so
6291             # that this will resolve itself on the next run.
6292             LOG.info(_LI("Compute node '%s' not found in "
6293                          "update_available_resource."), nodename)
6294             self._resource_tracker_dict.pop(nodename, None)
6295             return
6296         except Exception:
6297             LOG.exception(_LE("Error updating resources for node "
6298                           "%(node)s."), {'node': nodename})
6299 
6300         # NOTE(comstud): Replace the RT cache before looping through
6301         # compute nodes to delete below, as we can end up doing greenthread
6302         # switches there. Best to have everyone using the newest cache
6303         # ASAP.
6304         self._resource_tracker_dict[nodename] = rt
6305 
6306     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
6307     def update_available_resource(self, context):
6308         """See driver.get_available_resource()
6309 
6310         Periodic process that keeps that the compute host's understanding of
6311         resource availability and usage in sync with the underlying hypervisor.
6312 
6313         :param context: security context
6314         """
6315 
6316         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
6317                                                             use_slave=True)
6318         nodenames = set(self.driver.get_available_nodes())
6319         for nodename in nodenames:
6320             self.update_available_resource_for_node(context, nodename)
6321 
6322         self._resource_tracker_dict = {
6323             k: v for k, v in self._resource_tracker_dict.items()
6324             if k in nodenames}
6325 
6326         # Delete orphan compute node not reported by driver but still in db
6327         for cn in compute_nodes_in_db:
6328             if cn.hypervisor_hostname not in nodenames:
6329                 LOG.info(_LI("Deleting orphan compute node %s"), cn.id)
6330                 cn.destroy()
6331 
6332     def _get_compute_nodes_in_db(self, context, use_slave=False):
6333         try:
6334             return objects.ComputeNodeList.get_all_by_host(context, self.host,
6335                                                            use_slave=use_slave)
6336         except exception.NotFound:
6337             LOG.error(_LE("No compute node record for host %s"), self.host)
6338             return []
6339 
6340     @periodic_task.periodic_task(
6341         spacing=CONF.running_deleted_instance_poll_interval)
6342     def _cleanup_running_deleted_instances(self, context):
6343         """Cleanup any instances which are erroneously still running after
6344         having been deleted.
6345 
6346         Valid actions to take are:
6347 
6348             1. noop - do nothing
6349             2. log - log which instances are erroneously running
6350             3. reap - shutdown and cleanup any erroneously running instances
6351             4. shutdown - power off *and disable* any erroneously running
6352                           instances
6353 
6354         The use-case for this cleanup task is: for various reasons, it may be
6355         possible for the database to show an instance as deleted but for that
6356         instance to still be running on a host machine (see bug
6357         https://bugs.launchpad.net/nova/+bug/911366).
6358 
6359         This cleanup task is a cross-hypervisor utility for finding these
6360         zombied instances and either logging the discrepancy (likely what you
6361         should do in production), or automatically reaping the instances (more
6362         appropriate for dev environments).
6363         """
6364         action = CONF.running_deleted_instance_action
6365 
6366         if action == "noop":
6367             return
6368 
6369         # NOTE(sirp): admin contexts don't ordinarily return deleted records
6370         with utils.temporary_mutation(context, read_deleted="yes"):
6371             for instance in self._running_deleted_instances(context):
6372                 if action == "log":
6373                     LOG.warning(_LW("Detected instance with name label "
6374                                     "'%s' which is marked as "
6375                                     "DELETED but still present on host."),
6376                                 instance.name, instance=instance)
6377 
6378                 elif action == 'shutdown':
6379                     LOG.info(_LI("Powering off instance with name label "
6380                                  "'%s' which is marked as "
6381                                  "DELETED but still present on host."),
6382                              instance.name, instance=instance)
6383                     try:
6384                         try:
6385                             # disable starting the instance
6386                             self.driver.set_bootable(instance, False)
6387                         except NotImplementedError:
6388                             LOG.debug("set_bootable is not implemented "
6389                                       "for the current driver")
6390                         # and power it off
6391                         self.driver.power_off(instance)
6392                     except Exception:
6393                         msg = _LW("Failed to power off instance")
6394                         LOG.warning(msg, instance=instance, exc_info=True)
6395 
6396                 elif action == 'reap':
6397                     LOG.info(_LI("Destroying instance with name label "
6398                                  "'%s' which is marked as "
6399                                  "DELETED but still present on host."),
6400                              instance.name, instance=instance)
6401                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6402                         context, instance.uuid, use_slave=True)
6403                     self.instance_events.clear_events_for_instance(instance)
6404                     try:
6405                         self._shutdown_instance(context, instance, bdms,
6406                                                 notify=False)
6407                         self._cleanup_volumes(context, instance.uuid, bdms)
6408                     except Exception as e:
6409                         LOG.warning(_LW("Periodic cleanup failed to delete "
6410                                         "instance: %s"),
6411                                     e, instance=instance)
6412                 else:
6413                     raise Exception(_("Unrecognized value '%s'"
6414                                       " for CONF.running_deleted_"
6415                                       "instance_action") % action)
6416 
6417     def _running_deleted_instances(self, context):
6418         """Returns a list of instances nova thinks is deleted,
6419         but the hypervisor thinks is still running.
6420         """
6421         timeout = CONF.running_deleted_instance_timeout
6422         filters = {'deleted': True,
6423                    'soft_deleted': False,
6424                    'host': self.host}
6425         instances = self._get_instances_on_driver(context, filters)
6426         return [i for i in instances if self._deleted_old_enough(i, timeout)]
6427 
6428     def _deleted_old_enough(self, instance, timeout):
6429         deleted_at = instance.deleted_at
6430         if deleted_at:
6431             deleted_at = deleted_at.replace(tzinfo=None)
6432         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
6433 
6434     @contextlib.contextmanager
6435     def _error_out_instance_on_exception(self, context, instance,
6436                                          quotas=None,
6437                                          instance_state=vm_states.ACTIVE):
6438         instance_uuid = instance.uuid
6439         try:
6440             yield
6441         except NotImplementedError as error:
6442             with excutils.save_and_reraise_exception():
6443                 if quotas:
6444                     quotas.rollback()
6445                 LOG.info(_LI("Setting instance back to %(state)s after: "
6446                              "%(error)s"),
6447                          {'state': instance_state, 'error': error},
6448                          instance_uuid=instance_uuid)
6449                 self._instance_update(context, instance,
6450                                       vm_state=instance_state,
6451                                       task_state=None)
6452         except exception.InstanceFaultRollback as error:
6453             if quotas:
6454                 quotas.rollback()
6455             LOG.info(_LI("Setting instance back to ACTIVE after: %s"),
6456                      error, instance_uuid=instance_uuid)
6457             self._instance_update(context, instance,
6458                                   vm_state=vm_states.ACTIVE,
6459                                   task_state=None)
6460             raise error.inner_exception
6461         except Exception:
6462             LOG.exception(_LE('Setting instance vm_state to ERROR'),
6463                           instance_uuid=instance_uuid)
6464             with excutils.save_and_reraise_exception():
6465                 if quotas:
6466                     quotas.rollback()
6467                 self._set_instance_obj_error_state(context, instance)
6468 
6469     @wrap_exception()
6470     def add_aggregate_host(self, context, aggregate, host, slave_info):
6471         """Notify hypervisor of change (for hypervisor pools)."""
6472         try:
6473             self.driver.add_to_aggregate(context, aggregate, host,
6474                                          slave_info=slave_info)
6475         except NotImplementedError:
6476             LOG.debug('Hypervisor driver does not support '
6477                       'add_aggregate_host')
6478         except exception.AggregateError:
6479             with excutils.save_and_reraise_exception():
6480                 self.driver.undo_aggregate_operation(
6481                                     context,
6482                                     aggregate.delete_host,
6483                                     aggregate, host)
6484 
6485     @wrap_exception()
6486     def remove_aggregate_host(self, context, host, slave_info, aggregate):
6487         """Removes a host from a physical hypervisor pool."""
6488         try:
6489             self.driver.remove_from_aggregate(context, aggregate, host,
6490                                               slave_info=slave_info)
6491         except NotImplementedError:
6492             LOG.debug('Hypervisor driver does not support '
6493                       'remove_aggregate_host')
6494         except (exception.AggregateError,
6495                 exception.InvalidAggregateAction) as e:
6496             with excutils.save_and_reraise_exception():
6497                 self.driver.undo_aggregate_operation(
6498                                     context,
6499                                     aggregate.add_host,
6500                                     aggregate, host,
6501                                     isinstance(e, exception.AggregateError))
6502 
6503     def _process_instance_event(self, instance, event):
6504         _event = self.instance_events.pop_instance_event(instance, event)
6505         if _event:
6506             LOG.debug('Processing event %(event)s',
6507                       {'event': event.key}, instance=instance)
6508             _event.send(event)
6509 
6510     def _process_instance_vif_deleted_event(self, context, instance,
6511                                             deleted_vif_id):
6512         # If an attached port is deleted by neutron, it needs to
6513         # be detached from the instance.
6514         # And info cache needs to be updated.
6515         network_info = instance.info_cache.network_info
6516         for index, vif in enumerate(network_info):
6517             if vif['id'] == deleted_vif_id:
6518                 LOG.info(_LI('Neutron deleted interface %(intf)s; '
6519                              'detaching it from the instance and '
6520                              'deleting it from the info cache'),
6521                          {'intf': vif['id']},
6522                          instance=instance)
6523                 del network_info[index]
6524                 base_net_api.update_instance_cache_with_nw_info(
6525                                  self.network_api, context,
6526                                  instance,
6527                                  nw_info=network_info)
6528                 try:
6529                     self.driver.detach_interface(instance, vif)
6530                 except exception.NovaException as ex:
6531                     LOG.warning(_LW("Detach interface failed, "
6532                                     "port_id=%(port_id)s, reason: %(msg)s"),
6533                                 {'port_id': deleted_vif_id, 'msg': ex},
6534                                 instance=instance)
6535                 break
6536 
6537     @wrap_exception()
6538     def external_instance_event(self, context, instances, events):
6539         # NOTE(danms): Some event types are handled by the manager, such
6540         # as when we're asked to update the instance's info_cache. If it's
6541         # not one of those, look for some thread(s) waiting for the event and
6542         # unblock them if so.
6543         for event in events:
6544             instance = [inst for inst in instances
6545                         if inst.uuid == event.instance_uuid][0]
6546             LOG.debug('Received event %(event)s',
6547                       {'event': event.key},
6548                       instance=instance)
6549             if event.name == 'network-changed':
6550                 try:
6551                     self.network_api.get_instance_nw_info(context, instance)
6552                 except exception.NotFound as e:
6553                     LOG.info(_LI('Failed to process external instance event '
6554                                  '%(event)s due to: %(error)s'),
6555                              {'event': event.key, 'error': six.text_type(e)},
6556                              instance=instance)
6557             elif event.name == 'network-vif-deleted':
6558                 self._process_instance_vif_deleted_event(context,
6559                                                          instance,
6560                                                          event.tag)
6561             else:
6562                 self._process_instance_event(instance, event)
6563 
6564     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
6565                                  external_process_ok=True)
6566     def _run_image_cache_manager_pass(self, context):
6567         """Run a single pass of the image cache manager."""
6568 
6569         if not self.driver.capabilities["has_imagecache"]:
6570             return
6571 
6572         # Determine what other nodes use this storage
6573         storage_users.register_storage_use(CONF.instances_path, CONF.host)
6574         nodes = storage_users.get_storage_users(CONF.instances_path)
6575 
6576         # Filter all_instances to only include those nodes which share this
6577         # storage path.
6578         # TODO(mikal): this should be further refactored so that the cache
6579         # cleanup code doesn't know what those instances are, just a remote
6580         # count, and then this logic should be pushed up the stack.
6581         filters = {'deleted': False,
6582                    'soft_deleted': True,
6583                    'host': nodes}
6584         filtered_instances = objects.InstanceList.get_by_filters(context,
6585                                  filters, expected_attrs=[], use_slave=True)
6586 
6587         self.driver.manage_image_cache(context, filtered_instances)
6588 
6589     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6590     def _run_pending_deletes(self, context):
6591         """Retry any pending instance file deletes."""
6592         LOG.debug('Cleaning up deleted instances')
6593         filters = {'deleted': True,
6594                    'soft_deleted': False,
6595                    'host': CONF.host,
6596                    'cleaned': False}
6597         attrs = ['info_cache', 'security_groups', 'system_metadata']
6598         with utils.temporary_mutation(context, read_deleted='yes'):
6599             instances = objects.InstanceList.get_by_filters(
6600                 context, filters, expected_attrs=attrs, use_slave=True)
6601         LOG.debug('There are %d instances to clean', len(instances))
6602 
6603         for instance in instances:
6604             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
6605             LOG.debug('Instance has had %(attempts)s of %(max)s '
6606                       'cleanup attempts',
6607                       {'attempts': attempts,
6608                        'max': CONF.maximum_instance_delete_attempts},
6609                       instance=instance)
6610             if attempts < CONF.maximum_instance_delete_attempts:
6611                 success = self.driver.delete_instance_files(instance)
6612 
6613                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
6614                 if success:
6615                     instance.cleaned = True
6616                 with utils.temporary_mutation(context, read_deleted='yes'):
6617                     instance.save()
6618 
6619     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6620     def _cleanup_incomplete_migrations(self, context):
6621         """Delete instance files on failed resize/revert-resize operation
6622 
6623         During resize/revert-resize operation, if that instance gets deleted
6624         in-between then instance files might remain either on source or
6625         destination compute node because of race condition.
6626         """
6627         LOG.debug('Cleaning up deleted instances with incomplete migration ')
6628         migration_filters = {'host': CONF.host,
6629                              'status': 'error'}
6630         migrations = objects.MigrationList.get_by_filters(context,
6631                                                           migration_filters)
6632 
6633         if not migrations:
6634             return
6635 
6636         inst_uuid_from_migrations = set([migration.instance_uuid for migration
6637                                          in migrations])
6638 
6639         inst_filters = {'deleted': True, 'soft_deleted': False,
6640                         'uuid': inst_uuid_from_migrations, 'host': CONF.host}
6641         attrs = ['info_cache', 'security_groups', 'system_metadata']
6642         with utils.temporary_mutation(context, read_deleted='yes'):
6643             instances = objects.InstanceList.get_by_filters(
6644                 context, inst_filters, expected_attrs=attrs, use_slave=True)
6645 
6646         for instance in instances:
6647             for migration in migrations:
6648                 if instance.uuid == migration.instance_uuid:
6649                     # Delete instance files if not cleanup properly either
6650                     # from the source or destination compute nodes when
6651                     # the instance is deleted during resizing.
6652                     self.driver.delete_instance_files(instance)
6653                     try:
6654                         migration.status = 'failed'
6655                         with migration.obj_as_admin():
6656                             migration.save()
6657                     except exception.MigrationNotFound:
6658                         LOG.warning(_LW("Migration %s is not found."),
6659                                     migration.id, context=context,
6660                                     instance=instance)
6661                     break
6662 
6663     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
6664                                    exception.QemuGuestAgentNotEnabled,
6665                                    exception.NovaException,
6666                                    NotImplementedError)
6667     @wrap_exception()
6668     def quiesce_instance(self, context, instance):
6669         """Quiesce an instance on this host."""
6670         context = context.elevated()
6671         image_meta = objects.ImageMeta.from_instance(instance)
6672         self.driver.quiesce(context, instance, image_meta)
6673 
6674     def _wait_for_snapshots_completion(self, context, mapping):
6675         for mapping_dict in mapping:
6676             if mapping_dict.get('source_type') == 'snapshot':
6677 
6678                 def _wait_snapshot():
6679                     snapshot = self.volume_api.get_snapshot(
6680                         context, mapping_dict['snapshot_id'])
6681                     if snapshot.get('status') != 'creating':
6682                         raise loopingcall.LoopingCallDone()
6683 
6684                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
6685                 timer.start(interval=0.5).wait()
6686 
6687     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
6688                                    exception.QemuGuestAgentNotEnabled,
6689                                    exception.NovaException,
6690                                    NotImplementedError)
6691     @wrap_exception()
6692     def unquiesce_instance(self, context, instance, mapping=None):
6693         """Unquiesce an instance on this host.
6694 
6695         If snapshots' image mapping is provided, it waits until snapshots are
6696         completed before unqueiscing.
6697         """
6698         context = context.elevated()
6699         if mapping:
6700             try:
6701                 self._wait_for_snapshots_completion(context, mapping)
6702             except Exception as error:
6703                 LOG.exception(_LE("Exception while waiting completion of "
6704                                   "volume snapshots: %s"),
6705                               error, instance=instance)
6706         image_meta = objects.ImageMeta.from_instance(instance)
6707         self.driver.unquiesce(context, instance, image_meta)
