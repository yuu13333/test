I want you to act as a code reviewer of Nova in OpenStack. Please review the code below to detect security defects. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are found, please state '''No security defects are detected in the code'''.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 from cursive import exception as cursive_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 from keystoneauth1 import exceptions as keystone_exception
44 from oslo_log import log as logging
45 import oslo_messaging as messaging
46 from oslo_serialization import jsonutils
47 from oslo_service import loopingcall
48 from oslo_service import periodic_task
49 from oslo_utils import excutils
50 from oslo_utils import strutils
51 from oslo_utils import timeutils
52 from oslo_utils import uuidutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova.console import rpcapi as console_rpcapi
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova import image
77 from nova import manager
78 from nova import network
79 from nova.network import base_api as base_net_api
80 from nova.network import model as network_model
81 from nova.network.security_group import openstack_driver
82 from nova import objects
83 from nova.objects import base as obj_base
84 from nova.objects import fields
85 from nova.objects import instance as obj_instance
86 from nova.objects import migrate_data as migrate_data_obj
87 from nova.pci import whitelist
88 from nova import rpc
89 from nova import safe_utils
90 from nova.scheduler import client as scheduler_client
91 from nova.scheduler import utils as scheduler_utils
92 from nova import utils
93 from nova.virt import block_device as driver_block_device
94 from nova.virt import configdrive
95 from nova.virt import driver
96 from nova.virt import event as virtevent
97 from nova.virt import storage_users
98 from nova.virt import virtapi
99 from nova.volume import cinder
100 
101 CONF = nova.conf.CONF
102 
103 LOG = logging.getLogger(__name__)
104 
105 get_notifier = functools.partial(rpc.get_notifier, service='compute')
106 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
107                                    get_notifier=get_notifier,
108                                    binary='nova-compute')
109 
110 
111 @contextlib.contextmanager
112 def errors_out_migration_ctxt(migration):
113     """Context manager to error out migration on failure."""
114 
115     try:
116         yield
117     except Exception:
118         with excutils.save_and_reraise_exception():
119             if migration:
120                 # We may have been passed None for our migration if we're
121                 # receiving from an older client. The migration will be
122                 # errored via the legacy path.
123                 migration.status = 'error'
124                 try:
125                     with migration.obj_as_admin():
126                         migration.save()
127                 except Exception:
128                     LOG.debug(
129                         'Error setting migration status for instance %s.',
130                         migration.instance_uuid, exc_info=True)
131 
132 
133 @utils.expects_func_args('migration')
134 def errors_out_migration(function):
135     """Decorator to error out migration on failure."""
136 
137     @functools.wraps(function)
138     def decorated_function(self, context, *args, **kwargs):
139         wrapped_func = safe_utils.get_wrapped_function(function)
140         keyed_args = inspect.getcallargs(wrapped_func, self, context,
141                                          *args, **kwargs)
142         migration = keyed_args['migration']
143         with errors_out_migration_ctxt(migration):
144             return function(self, context, *args, **kwargs)
145 
146     return decorated_function
147 
148 
149 @utils.expects_func_args('instance')
150 def reverts_task_state(function):
151     """Decorator to revert task_state on failure."""
152 
153     @functools.wraps(function)
154     def decorated_function(self, context, *args, **kwargs):
155         try:
156             return function(self, context, *args, **kwargs)
157         except exception.UnexpectedTaskStateError as e:
158             # Note(maoy): unexpected task state means the current
159             # task is preempted. Do not clear task state in this
160             # case.
161             with excutils.save_and_reraise_exception():
162                 LOG.info("Task possibly preempted: %s",
163                          e.format_message())
164         except Exception:
165             with excutils.save_and_reraise_exception():
166                 wrapped_func = safe_utils.get_wrapped_function(function)
167                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
168                                                  *args, **kwargs)
169                 # NOTE(mriedem): 'instance' must be in keyed_args because we
170                 # have utils.expects_func_args('instance') decorating this
171                 # method.
172                 instance = keyed_args['instance']
173                 original_task_state = instance.task_state
174                 try:
175                     self._instance_update(context, instance, task_state=None)
176                     LOG.info("Successfully reverted task state from %s on "
177                              "failure for instance.",
178                              original_task_state, instance=instance)
179                 except exception.InstanceNotFound:
180                     # We might delete an instance that failed to build shortly
181                     # after it errored out this is an expected case and we
182                     # should not trace on it.
183                     pass
184                 except Exception as e:
185                     LOG.warning("Failed to revert task state for instance. "
186                                 "Error: %s", e, instance=instance)
187 
188     return decorated_function
189 
190 
191 @utils.expects_func_args('instance')
192 def wrap_instance_fault(function):
193     """Wraps a method to catch exceptions related to instances.
194 
195     This decorator wraps a method to catch any exceptions having to do with
196     an instance that may get thrown. It then logs an instance fault in the db.
197     """
198 
199     @functools.wraps(function)
200     def decorated_function(self, context, *args, **kwargs):
201         try:
202             return function(self, context, *args, **kwargs)
203         except exception.InstanceNotFound:
204             raise
205         except Exception as e:
206             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
207             # we will get a KeyError exception which will cover up the real
208             # exception. So, we update kwargs with the values from args first.
209             # then, we can get 'instance' from kwargs easily.
210             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
211 
212             with excutils.save_and_reraise_exception():
213                 compute_utils.add_instance_fault_from_exc(context,
214                         kwargs['instance'], e, sys.exc_info())
215 
216     return decorated_function
217 
218 
219 @utils.expects_func_args('image_id', 'instance')
220 def delete_image_on_error(function):
221     """Used for snapshot related method to ensure the image created in
222     compute.api is deleted when an error occurs.
223     """
224 
225     @functools.wraps(function)
226     def decorated_function(self, context, image_id, instance,
227                            *args, **kwargs):
228         try:
229             return function(self, context, image_id, instance,
230                             *args, **kwargs)
231         except Exception:
232             with excutils.save_and_reraise_exception():
233                 LOG.debug("Cleaning up image %s", image_id,
234                           exc_info=True, instance=instance)
235                 try:
236                     self.image_api.delete(context, image_id)
237                 except exception.ImageNotFound:
238                     # Since we're trying to cleanup an image, we don't care if
239                     # if it's already gone.
240                     pass
241                 except Exception:
242                     LOG.exception("Error while trying to clean up image %s",
243                                   image_id, instance=instance)
244 
245     return decorated_function
246 
247 
248 # TODO(danms): Remove me after Icehouse
249 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
250 # NOTE(mikal): if the method being decorated has more than one decorator, then
251 # put this one first. Otherwise the various exception handling decorators do
252 # not function correctly.
253 def object_compat(function):
254     """Wraps a method that expects a new-world instance
255 
256     This provides compatibility for callers passing old-style dict
257     instances.
258     """
259 
260     @functools.wraps(function)
261     def decorated_function(self, context, *args, **kwargs):
262         def _load_instance(instance_or_dict):
263             if isinstance(instance_or_dict, dict):
264                 # try to get metadata and system_metadata for most cases but
265                 # only attempt to load those if the db instance already has
266                 # those fields joined
267                 metas = [meta for meta in ('metadata', 'system_metadata')
268                          if meta in instance_or_dict]
269                 instance = objects.Instance._from_db_object(
270                     context, objects.Instance(), instance_or_dict,
271                     expected_attrs=metas)
272                 instance._context = context
273                 return instance
274             return instance_or_dict
275 
276         try:
277             kwargs['instance'] = _load_instance(kwargs['instance'])
278         except KeyError:
279             args = (_load_instance(args[0]),) + args[1:]
280 
281         migration = kwargs.get('migration')
282         if isinstance(migration, dict):
283             migration = objects.Migration._from_db_object(
284                     context.elevated(), objects.Migration(),
285                     migration)
286             kwargs['migration'] = migration
287 
288         return function(self, context, *args, **kwargs)
289 
290     return decorated_function
291 
292 
293 class InstanceEvents(object):
294     def __init__(self):
295         self._events = {}
296 
297     @staticmethod
298     def _lock_name(instance):
299         return '%s-%s' % (instance.uuid, 'events')
300 
301     def prepare_for_instance_event(self, instance, event_name):
302         """Prepare to receive an event for an instance.
303 
304         This will register an event for the given instance that we will
305         wait on later. This should be called before initiating whatever
306         action will trigger the event. The resulting eventlet.event.Event
307         object should be wait()'d on to ensure completion.
308 
309         :param instance: the instance for which the event will be generated
310         :param event_name: the name of the event we're expecting
311         :returns: an event object that should be wait()'d on
312         """
313         if self._events is None:
314             # NOTE(danms): We really should have a more specific error
315             # here, but this is what we use for our default error case
316             raise exception.NovaException('In shutdown, no new events '
317                                           'can be scheduled')
318 
319         @utils.synchronized(self._lock_name(instance))
320         def _create_or_get_event():
321             instance_events = self._events.setdefault(instance.uuid, {})
322             return instance_events.setdefault(event_name,
323                                               eventlet.event.Event())
324         LOG.debug('Preparing to wait for external event %(event)s',
325                   {'event': event_name}, instance=instance)
326         return _create_or_get_event()
327 
328     def pop_instance_event(self, instance, event):
329         """Remove a pending event from the wait list.
330 
331         This will remove a pending event from the wait list so that it
332         can be used to signal the waiters to wake up.
333 
334         :param instance: the instance for which the event was generated
335         :param event: the nova.objects.external_event.InstanceExternalEvent
336                       that describes the event
337         :returns: the eventlet.event.Event object on which the waiters
338                   are blocked
339         """
340         no_events_sentinel = object()
341         no_matching_event_sentinel = object()
342 
343         @utils.synchronized(self._lock_name(instance))
344         def _pop_event():
345             if not self._events:
346                 LOG.debug('Unexpected attempt to pop events during shutdown',
347                           instance=instance)
348                 return no_events_sentinel
349             events = self._events.get(instance.uuid)
350             if not events:
351                 return no_events_sentinel
352             _event = events.pop(event.key, None)
353             if not events:
354                 del self._events[instance.uuid]
355             if _event is None:
356                 return no_matching_event_sentinel
357             return _event
358 
359         result = _pop_event()
360         if result is no_events_sentinel:
361             LOG.debug('No waiting events found dispatching %(event)s',
362                       {'event': event.key},
363                       instance=instance)
364             return None
365         elif result is no_matching_event_sentinel:
366             LOG.debug('No event matching %(event)s in %(events)s',
367                       {'event': event.key,
368                        'events': self._events.get(instance.uuid, {}).keys()},
369                       instance=instance)
370             return None
371         else:
372             return result
373 
374     def clear_events_for_instance(self, instance):
375         """Remove all pending events for an instance.
376 
377         This will remove all events currently pending for an instance
378         and return them (indexed by event name).
379 
380         :param instance: the instance for which events should be purged
381         :returns: a dictionary of {event_name: eventlet.event.Event}
382         """
383         @utils.synchronized(self._lock_name(instance))
384         def _clear_events():
385             if self._events is None:
386                 LOG.debug('Unexpected attempt to clear events during shutdown',
387                           instance=instance)
388                 return dict()
389             return self._events.pop(instance.uuid, {})
390         return _clear_events()
391 
392     def cancel_all_events(self):
393         if self._events is None:
394             LOG.debug('Unexpected attempt to cancel events during shutdown.')
395             return
396         our_events = self._events
397         # NOTE(danms): Block new events
398         self._events = None
399 
400         for instance_uuid, events in our_events.items():
401             for event_name, eventlet_event in events.items():
402                 LOG.debug('Canceling in-flight event %(event)s for '
403                           'instance %(instance_uuid)s',
404                           {'event': event_name,
405                            'instance_uuid': instance_uuid})
406                 name, tag = event_name.rsplit('-', 1)
407                 event = objects.InstanceExternalEvent(
408                     instance_uuid=instance_uuid,
409                     name=name, status='failed',
410                     tag=tag, data={})
411                 eventlet_event.send(event)
412 
413 
414 class ComputeVirtAPI(virtapi.VirtAPI):
415     def __init__(self, compute):
416         super(ComputeVirtAPI, self).__init__()
417         self._compute = compute
418 
419     def _default_error_callback(self, event_name, instance):
420         raise exception.NovaException(_('Instance event failed'))
421 
422     @contextlib.contextmanager
423     def wait_for_instance_event(self, instance, event_names, deadline=300,
424                                 error_callback=None):
425         """Plan to wait for some events, run some code, then wait.
426 
427         This context manager will first create plans to wait for the
428         provided event_names, yield, and then wait for all the scheduled
429         events to complete.
430 
431         Note that this uses an eventlet.timeout.Timeout to bound the
432         operation, so callers should be prepared to catch that
433         failure and handle that situation appropriately.
434 
435         If the event is not received by the specified timeout deadline,
436         eventlet.timeout.Timeout is raised.
437 
438         If the event is received but did not have a 'completed'
439         status, a NovaException is raised.  If an error_callback is
440         provided, instead of raising an exception as detailed above
441         for the failure case, the callback will be called with the
442         event_name and instance, and can return True to continue
443         waiting for the rest of the events, False to stop processing,
444         or raise an exception which will bubble up to the waiter.
445 
446         :param instance: The instance for which an event is expected
447         :param event_names: A list of event names. Each element can be a
448                             string event name or tuple of strings to
449                             indicate (name, tag).
450         :param deadline: Maximum number of seconds we should wait for all
451                          of the specified events to arrive.
452         :param error_callback: A function to be called if an event arrives
453 
454         """
455 
456         if error_callback is None:
457             error_callback = self._default_error_callback
458         events = {}
459         for event_name in event_names:
460             if isinstance(event_name, tuple):
461                 name, tag = event_name
462                 event_name = objects.InstanceExternalEvent.make_key(
463                     name, tag)
464             try:
465                 events[event_name] = (
466                     self._compute.instance_events.prepare_for_instance_event(
467                         instance, event_name))
468             except exception.NovaException:
469                 error_callback(event_name, instance)
470                 # NOTE(danms): Don't wait for any of the events. They
471                 # should all be canceled and fired immediately below,
472                 # but don't stick around if not.
473                 deadline = 0
474         yield
475         with eventlet.timeout.Timeout(deadline):
476             for event_name, event in events.items():
477                 actual_event = event.wait()
478                 if actual_event.status == 'completed':
479                     continue
480                 decision = error_callback(event_name, instance)
481                 if decision is False:
482                     break
483 
484 
485 class ComputeManager(manager.Manager):
486     """Manages the running instances from creation to destruction."""
487 
488     target = messaging.Target(version='5.0')
489 
490     # How long to wait in seconds before re-issuing a shutdown
491     # signal to an instance during power off.  The overall
492     # time to wait is set by CONF.shutdown_timeout.
493     SHUTDOWN_RETRY_INTERVAL = 10
494 
495     def __init__(self, compute_driver=None, *args, **kwargs):
496         """Load configuration options and connect to the hypervisor."""
497         self.virtapi = ComputeVirtAPI(self)
498         self.network_api = network.API()
499         self.volume_api = cinder.API()
500         self.image_api = image.API()
501         self._last_host_check = 0
502         self._last_bw_usage_poll = 0
503         self._bw_usage_supported = True
504         self._last_bw_usage_cell_update = 0
505         self.compute_api = compute.API()
506         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
507         self.conductor_api = conductor.API()
508         self.compute_task_api = conductor.ComputeTaskAPI()
509         self.is_neutron_security_groups = (
510             openstack_driver.is_neutron_security_groups())
511         self.cells_rpcapi = cells_rpcapi.CellsAPI()
512         self.scheduler_client = scheduler_client.SchedulerClient()
513         self.reportclient = self.scheduler_client.reportclient
514         self._resource_tracker = None
515         self.instance_events = InstanceEvents()
516         self._sync_power_pool = eventlet.GreenPool(
517             size=CONF.sync_power_state_pool_size)
518         self._syncs_in_progress = {}
519         self.send_instance_updates = (
520             CONF.filter_scheduler.track_instance_changes)
521         if CONF.max_concurrent_builds != 0:
522             self._build_semaphore = eventlet.semaphore.Semaphore(
523                 CONF.max_concurrent_builds)
524         else:
525             self._build_semaphore = compute_utils.UnlimitedSemaphore()
526         if max(CONF.max_concurrent_live_migrations, 0) != 0:
527             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
528                 CONF.max_concurrent_live_migrations)
529         else:
530             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
531         self._failed_builds = 0
532 
533         super(ComputeManager, self).__init__(service_name="compute",
534                                              *args, **kwargs)
535 
536         # NOTE(russellb) Load the driver last.  It may call back into the
537         # compute manager via the virtapi, so we want it to be fully
538         # initialized before that happens.
539         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
540         self.use_legacy_block_device_info = \
541                             self.driver.need_legacy_block_device_info
542 
543     def reset(self):
544         LOG.info('Reloading compute RPC API')
545         compute_rpcapi.LAST_VERSION = None
546         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
547 
548     def _get_resource_tracker(self):
549         if not self._resource_tracker:
550             rt = resource_tracker.ResourceTracker(self.host, self.driver)
551             self._resource_tracker = rt
552         return self._resource_tracker
553 
554     def _update_resource_tracker(self, context, instance):
555         """Let the resource tracker know that an instance has changed state."""
556 
557         if instance.host == self.host:
558             rt = self._get_resource_tracker()
559             rt.update_usage(context, instance, instance.node)
560 
561     def _instance_update(self, context, instance, **kwargs):
562         """Update an instance in the database using kwargs as value."""
563 
564         for k, v in kwargs.items():
565             setattr(instance, k, v)
566         instance.save()
567         self._update_resource_tracker(context, instance)
568 
569     def _nil_out_instance_obj_host_and_node(self, instance):
570         # NOTE(jwcroppe): We don't do instance.save() here for performance
571         # reasons; a call to this is expected to be immediately followed by
572         # another call that does instance.save(), thus avoiding two writes
573         # to the database layer.
574         instance.host = None
575         instance.node = None
576 
577     def _set_instance_obj_error_state(self, context, instance,
578                                       clean_task_state=False):
579         try:
580             instance.vm_state = vm_states.ERROR
581             if clean_task_state:
582                 instance.task_state = None
583             instance.save()
584         except exception.InstanceNotFound:
585             LOG.debug('Instance has been destroyed from under us while '
586                       'trying to set it to ERROR', instance=instance)
587 
588     def _get_instances_on_driver(self, context, filters=None):
589         """Return a list of instance records for the instances found
590         on the hypervisor which satisfy the specified filters. If filters=None
591         return a list of instance records for all the instances found on the
592         hypervisor.
593         """
594         if not filters:
595             filters = {}
596         try:
597             driver_uuids = self.driver.list_instance_uuids()
598             if len(driver_uuids) == 0:
599                 # Short circuit, don't waste a DB call
600                 return objects.InstanceList()
601             filters['uuid'] = driver_uuids
602             local_instances = objects.InstanceList.get_by_filters(
603                 context, filters, use_slave=True)
604             return local_instances
605         except NotImplementedError:
606             pass
607 
608         # The driver doesn't support uuids listing, so we'll have
609         # to brute force.
610         driver_instances = self.driver.list_instances()
611         # NOTE(mjozefcz): In this case we need to apply host filter.
612         # Without this all instance data would be fetched from db.
613         filters['host'] = self.host
614         instances = objects.InstanceList.get_by_filters(context, filters,
615                                                         use_slave=True)
616         name_map = {instance.name: instance for instance in instances}
617         local_instances = []
618         for driver_instance in driver_instances:
619             instance = name_map.get(driver_instance)
620             if not instance:
621                 continue
622             local_instances.append(instance)
623         return local_instances
624 
625     def _destroy_evacuated_instances(self, context):
626         """Destroys evacuated instances.
627 
628         While nova-compute was down, the instances running on it could be
629         evacuated to another host. This method looks for evacuation migration
630         records where this is the source host and which were either started
631         (accepted) or complete (done). From those migration records, local
632         instances reported by the hypervisor are compared to the instances
633         for the migration records and those local guests are destroyed, along
634         with instance allocation records in Placement for this node.
635         """
636         filters = {
637             'source_compute': self.host,
638             # NOTE(mriedem): Migration records that have been accepted are
639             # included in case the source node comes back up while instances
640             # are being evacuated to another host. We don't want the same
641             # instance being reported from multiple hosts.
642             'status': ['accepted', 'done'],
643             'migration_type': 'evacuation',
644         }
645         with utils.temporary_mutation(context, read_deleted='yes'):
646             evacuations = objects.MigrationList.get_by_filters(context,
647                                                                filters)
648         if not evacuations:
649             return
650         evacuations = {mig.instance_uuid: mig for mig in evacuations}
651 
652         local_instances = self._get_instances_on_driver(context)
653         evacuated = [inst for inst in local_instances
654                      if inst.uuid in evacuations]
655 
656         # NOTE(gibi): We are called from init_host and at this point the
657         # compute_nodes of the resource tracker has not been populated yet so
658         # we cannot rely on the resource tracker here.
659         compute_nodes = {}
660 
661         for instance in evacuated:
662             migration = evacuations[instance.uuid]
663             LOG.info('Deleting instance as it has been evacuated from '
664                      'this host', instance=instance)
665             try:
666                 network_info = self.network_api.get_instance_nw_info(
667                     context, instance)
668                 bdi = self._get_instance_block_device_info(context,
669                                                            instance)
670                 destroy_disks = not (self._is_instance_storage_shared(
671                     context, instance))
672             except exception.InstanceNotFound:
673                 network_info = network_model.NetworkInfo()
674                 bdi = {}
675                 LOG.info('Instance has been marked deleted already, '
676                          'removing it from the hypervisor.',
677                          instance=instance)
678                 # always destroy disks if the instance was deleted
679                 destroy_disks = True
680             self.driver.destroy(context, instance,
681                                 network_info,
682                                 bdi, destroy_disks)
683 
684             # delete the allocation of the evacuated instance from this host
685             if migration.source_node not in compute_nodes:
686                 try:
687                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
688                         context, self.host, migration.source_node).uuid
689                     compute_nodes[migration.source_node] = cn_uuid
690                 except exception.ComputeHostNotFound:
691                     LOG.error("Failed to clean allocation of evacuated "
692                               "instance as the source node %s is not found",
693                               migration.source_node, instance=instance)
694                     continue
695             cn_uuid = compute_nodes[migration.source_node]
696 
697             if not scheduler_utils.remove_allocation_from_compute(
698                     context, instance, cn_uuid, self.reportclient):
699                 LOG.error("Failed to clean allocation of evacuated instance "
700                           "on the source node %s",
701                           cn_uuid, instance=instance)
702 
703             migration.status = 'completed'
704             migration.save()
705 
706     def _is_instance_storage_shared(self, context, instance, host=None):
707         shared_storage = True
708         data = None
709         try:
710             data = self.driver.check_instance_shared_storage_local(context,
711                                                        instance)
712             if data:
713                 shared_storage = (self.compute_rpcapi.
714                                   check_instance_shared_storage(context,
715                                   instance, data, host=host))
716         except NotImplementedError:
717             LOG.debug('Hypervisor driver does not support '
718                       'instance shared storage check, '
719                       'assuming it\'s not on shared storage',
720                       instance=instance)
721             shared_storage = False
722         except Exception:
723             LOG.exception('Failed to check if instance shared',
724                           instance=instance)
725         finally:
726             if data:
727                 self.driver.check_instance_shared_storage_cleanup(context,
728                                                                   data)
729         return shared_storage
730 
731     def _complete_partial_deletion(self, context, instance):
732         """Complete deletion for instances in DELETED status but not marked as
733         deleted in the DB
734         """
735         system_meta = instance.system_metadata
736         instance.destroy()
737         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
738                 context, instance.uuid)
739         self._complete_deletion(context,
740                                 instance,
741                                 bdms,
742                                 system_meta)
743 
744     def _complete_deletion(self, context, instance, bdms,
745                            system_meta):
746         self._update_resource_tracker(context, instance)
747 
748         rt = self._get_resource_tracker()
749         rt.reportclient.delete_allocation_for_instance(context, instance.uuid)
750 
751         self._notify_about_instance_usage(context, instance, "delete.end",
752                 system_metadata=system_meta)
753         compute_utils.notify_about_instance_action(context, instance,
754                 self.host, action=fields.NotificationAction.DELETE,
755                 phase=fields.NotificationPhase.END, bdms=bdms)
756         self._delete_scheduler_instance_info(context, instance.uuid)
757 
758     def _init_instance(self, context, instance):
759         """Initialize this instance during service init."""
760 
761         # NOTE(danms): If the instance appears to not be owned by this
762         # host, it may have been evacuated away, but skipped by the
763         # evacuation cleanup code due to configuration. Thus, if that
764         # is a possibility, don't touch the instance in any way, but
765         # log the concern. This will help avoid potential issues on
766         # startup due to misconfiguration.
767         if instance.host != self.host:
768             LOG.warning('Instance %(uuid)s appears to not be owned '
769                         'by this host, but by %(host)s. Startup '
770                         'processing is being skipped.',
771                         {'uuid': instance.uuid,
772                          'host': instance.host})
773             return
774 
775         # Instances that are shut down, or in an error state can not be
776         # initialized and are not attempted to be recovered. The exception
777         # to this are instances that are in RESIZE_MIGRATING or DELETING,
778         # which are dealt with further down.
779         if (instance.vm_state == vm_states.SOFT_DELETED or
780             (instance.vm_state == vm_states.ERROR and
781             instance.task_state not in
782             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
783             LOG.debug("Instance is in %s state.",
784                       instance.vm_state, instance=instance)
785             return
786 
787         if instance.vm_state == vm_states.DELETED:
788             try:
789                 self._complete_partial_deletion(context, instance)
790             except Exception:
791                 # we don't want that an exception blocks the init_host
792                 LOG.exception('Failed to complete a deletion',
793                               instance=instance)
794             return
795 
796         if (instance.vm_state == vm_states.BUILDING or
797             instance.task_state in [task_states.SCHEDULING,
798                                     task_states.BLOCK_DEVICE_MAPPING,
799                                     task_states.NETWORKING,
800                                     task_states.SPAWNING]):
801             # NOTE(dave-mcnally) compute stopped before instance was fully
802             # spawned so set to ERROR state. This is safe to do as the state
803             # may be set by the api but the host is not so if we get here the
804             # instance has already been scheduled to this particular host.
805             LOG.debug("Instance failed to spawn correctly, "
806                       "setting to ERROR state", instance=instance)
807             instance.task_state = None
808             instance.vm_state = vm_states.ERROR
809             instance.save()
810             return
811 
812         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
813             instance.task_state in [task_states.REBUILDING,
814                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
815                                     task_states.REBUILD_SPAWNING]):
816             # NOTE(jichenjc) compute stopped before instance was fully
817             # spawned so set to ERROR state. This is consistent to BUILD
818             LOG.debug("Instance failed to rebuild correctly, "
819                       "setting to ERROR state", instance=instance)
820             instance.task_state = None
821             instance.vm_state = vm_states.ERROR
822             instance.save()
823             return
824 
825         if (instance.vm_state != vm_states.ERROR and
826             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
827                                     task_states.IMAGE_PENDING_UPLOAD,
828                                     task_states.IMAGE_UPLOADING,
829                                     task_states.IMAGE_SNAPSHOT]):
830             LOG.debug("Instance in transitional state %s at start-up "
831                       "clearing task state",
832                       instance.task_state, instance=instance)
833             try:
834                 self._post_interrupted_snapshot_cleanup(context, instance)
835             except Exception:
836                 # we don't want that an exception blocks the init_host
837                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
838             instance.task_state = None
839             instance.save()
840 
841         if (instance.vm_state != vm_states.ERROR and
842             instance.task_state in [task_states.RESIZE_PREP]):
843             LOG.debug("Instance in transitional state %s at start-up "
844                       "clearing task state",
845                       instance['task_state'], instance=instance)
846             instance.task_state = None
847             instance.save()
848 
849         if instance.task_state == task_states.DELETING:
850             try:
851                 LOG.info('Service started deleting the instance during '
852                          'the previous run, but did not finish. Restarting'
853                          ' the deletion now.', instance=instance)
854                 instance.obj_load_attr('metadata')
855                 instance.obj_load_attr('system_metadata')
856                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
857                         context, instance.uuid)
858                 self._delete_instance(context, instance, bdms)
859             except Exception:
860                 # we don't want that an exception blocks the init_host
861                 LOG.exception('Failed to complete a deletion',
862                               instance=instance)
863                 self._set_instance_obj_error_state(context, instance)
864             return
865 
866         current_power_state = self._get_power_state(context, instance)
867         try_reboot, reboot_type = self._retry_reboot(context, instance,
868                                                      current_power_state)
869 
870         if try_reboot:
871             LOG.debug("Instance in transitional state (%(task_state)s) at "
872                       "start-up and power state is (%(power_state)s), "
873                       "triggering reboot",
874                       {'task_state': instance.task_state,
875                        'power_state': current_power_state},
876                       instance=instance)
877 
878             # NOTE(mikal): if the instance was doing a soft reboot that got as
879             # far as shutting down the instance but not as far as starting it
880             # again, then we've just become a hard reboot. That means the
881             # task state for the instance needs to change so that we're in one
882             # of the expected task states for a hard reboot.
883             if (instance.task_state in task_states.soft_reboot_states and
884                 reboot_type == 'HARD'):
885                 instance.task_state = task_states.REBOOT_PENDING_HARD
886                 instance.save()
887 
888             self.reboot_instance(context, instance, block_device_info=None,
889                                  reboot_type=reboot_type)
890             return
891 
892         elif (current_power_state == power_state.RUNNING and
893               instance.task_state in [task_states.REBOOT_STARTED,
894                                       task_states.REBOOT_STARTED_HARD,
895                                       task_states.PAUSING,
896                                       task_states.UNPAUSING]):
897             LOG.warning("Instance in transitional state "
898                         "(%(task_state)s) at start-up and power state "
899                         "is (%(power_state)s), clearing task state",
900                         {'task_state': instance.task_state,
901                          'power_state': current_power_state},
902                         instance=instance)
903             instance.task_state = None
904             instance.vm_state = vm_states.ACTIVE
905             instance.save()
906         elif (current_power_state == power_state.PAUSED and
907               instance.task_state == task_states.UNPAUSING):
908             LOG.warning("Instance in transitional state "
909                         "(%(task_state)s) at start-up and power state "
910                         "is (%(power_state)s), clearing task state "
911                         "and unpausing the instance",
912                         {'task_state': instance.task_state,
913                          'power_state': current_power_state},
914                         instance=instance)
915             try:
916                 self.unpause_instance(context, instance)
917             except NotImplementedError:
918                 # Some virt driver didn't support pause and unpause
919                 pass
920             except Exception:
921                 LOG.exception('Failed to unpause instance', instance=instance)
922             return
923 
924         if instance.task_state == task_states.POWERING_OFF:
925             try:
926                 LOG.debug("Instance in transitional state %s at start-up "
927                           "retrying stop request",
928                           instance.task_state, instance=instance)
929                 self.stop_instance(context, instance, True)
930             except Exception:
931                 # we don't want that an exception blocks the init_host
932                 LOG.exception('Failed to stop instance', instance=instance)
933             return
934 
935         if instance.task_state == task_states.POWERING_ON:
936             try:
937                 LOG.debug("Instance in transitional state %s at start-up "
938                           "retrying start request",
939                           instance.task_state, instance=instance)
940                 self.start_instance(context, instance)
941             except Exception:
942                 # we don't want that an exception blocks the init_host
943                 LOG.exception('Failed to start instance', instance=instance)
944             return
945 
946         net_info = instance.get_network_info()
947         try:
948             self.driver.plug_vifs(instance, net_info)
949         except NotImplementedError as e:
950             LOG.debug(e, instance=instance)
951         except exception.VirtualInterfacePlugException:
952             # we don't want an exception to block the init_host
953             LOG.exception("Vifs plug failed", instance=instance)
954             self._set_instance_obj_error_state(context, instance)
955             return
956 
957         if instance.task_state == task_states.RESIZE_MIGRATING:
958             # We crashed during resize/migration, so roll back for safety
959             try:
960                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
961                 # not in system_metadata we default to True for backwards
962                 # compatibility
963                 power_on = (instance.system_metadata.get('old_vm_state') !=
964                             vm_states.STOPPED)
965 
966                 block_dev_info = self._get_instance_block_device_info(context,
967                                                                       instance)
968 
969                 self.driver.finish_revert_migration(context,
970                     instance, net_info, block_dev_info, power_on)
971 
972             except Exception:
973                 LOG.exception('Failed to revert crashed migration',
974                               instance=instance)
975             finally:
976                 LOG.info('Instance found in migrating state during '
977                          'startup. Resetting task_state',
978                          instance=instance)
979                 instance.task_state = None
980                 instance.save()
981         if instance.task_state == task_states.MIGRATING:
982             # Live migration did not complete, but instance is on this
983             # host, so reset the state.
984             instance.task_state = None
985             instance.save(expected_task_state=[task_states.MIGRATING])
986 
987         db_state = instance.power_state
988         drv_state = self._get_power_state(context, instance)
989         expect_running = (db_state == power_state.RUNNING and
990                           drv_state != db_state)
991 
992         LOG.debug('Current state is %(drv_state)s, state in DB is '
993                   '%(db_state)s.',
994                   {'drv_state': drv_state, 'db_state': db_state},
995                   instance=instance)
996 
997         if expect_running and CONF.resume_guests_state_on_host_boot:
998             self._resume_guests_state(context, instance, net_info)
999         elif drv_state == power_state.RUNNING:
1000             # VMwareAPI drivers will raise an exception
1001             try:
1002                 self.driver.ensure_filtering_rules_for_instance(
1003                                        instance, net_info)
1004             except NotImplementedError:
1005                 LOG.debug('Hypervisor driver does not support '
1006                           'firewall rules', instance=instance)
1007 
1008     def _resume_guests_state(self, context, instance, net_info):
1009         LOG.info('Rebooting instance after nova-compute restart.',
1010                  instance=instance)
1011         block_device_info = \
1012             self._get_instance_block_device_info(context, instance)
1013 
1014         try:
1015             self.driver.resume_state_on_host_boot(
1016                 context, instance, net_info, block_device_info)
1017         except NotImplementedError:
1018             LOG.warning('Hypervisor driver does not support '
1019                         'resume guests', instance=instance)
1020         except Exception:
1021             # NOTE(vish): The instance failed to resume, so we set the
1022             #             instance to error and attempt to continue.
1023             LOG.warning('Failed to resume instance',
1024                         instance=instance)
1025             self._set_instance_obj_error_state(context, instance)
1026 
1027     def _retry_reboot(self, context, instance, current_power_state):
1028         current_task_state = instance.task_state
1029         retry_reboot = False
1030         reboot_type = compute_utils.get_reboot_type(current_task_state,
1031                                                     current_power_state)
1032 
1033         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1034                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1035         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1036                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1037         started_not_running = (current_task_state in
1038                                [task_states.REBOOT_STARTED,
1039                                 task_states.REBOOT_STARTED_HARD] and
1040                                current_power_state != power_state.RUNNING)
1041 
1042         if pending_soft or pending_hard or started_not_running:
1043             retry_reboot = True
1044 
1045         return retry_reboot, reboot_type
1046 
1047     def handle_lifecycle_event(self, event):
1048         LOG.info("VM %(state)s (Lifecycle Event)",
1049                  {'state': event.get_name()},
1050                  instance_uuid=event.get_instance_uuid())
1051         context = nova.context.get_admin_context(read_deleted='yes')
1052         instance = objects.Instance.get_by_uuid(context,
1053                                                 event.get_instance_uuid(),
1054                                                 expected_attrs=[])
1055         vm_power_state = None
1056         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1057             vm_power_state = power_state.SHUTDOWN
1058         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1059             vm_power_state = power_state.RUNNING
1060         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1061             vm_power_state = power_state.PAUSED
1062         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1063             vm_power_state = power_state.RUNNING
1064         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1065             vm_power_state = power_state.SUSPENDED
1066         else:
1067             LOG.warning("Unexpected power state %d", event.get_transition())
1068 
1069         # Note(lpetrut): The event may be delayed, thus not reflecting
1070         # the current instance power state. In that case, ignore the event.
1071         current_power_state = self._get_power_state(context, instance)
1072         if current_power_state == vm_power_state:
1073             LOG.debug('Synchronizing instance power state after lifecycle '
1074                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1075                       'current task_state: %(task_state)s, current DB '
1076                       'power_state: %(db_power_state)s, VM power_state: '
1077                       '%(vm_power_state)s',
1078                       {'event': event.get_name(),
1079                        'vm_state': instance.vm_state,
1080                        'task_state': instance.task_state,
1081                        'db_power_state': instance.power_state,
1082                        'vm_power_state': vm_power_state},
1083                       instance_uuid=instance.uuid)
1084             self._sync_instance_power_state(context,
1085                                             instance,
1086                                             vm_power_state)
1087 
1088     def handle_events(self, event):
1089         if isinstance(event, virtevent.LifecycleEvent):
1090             try:
1091                 self.handle_lifecycle_event(event)
1092             except exception.InstanceNotFound:
1093                 LOG.debug("Event %s arrived for non-existent instance. The "
1094                           "instance was probably deleted.", event)
1095         else:
1096             LOG.debug("Ignoring event %s", event)
1097 
1098     def init_virt_events(self):
1099         if CONF.workarounds.handle_virt_lifecycle_events:
1100             self.driver.register_event_listener(self.handle_events)
1101         else:
1102             # NOTE(mriedem): If the _sync_power_states periodic task is
1103             # disabled we should emit a warning in the logs.
1104             if CONF.sync_power_state_interval < 0:
1105                 LOG.warning('Instance lifecycle events from the compute '
1106                             'driver have been disabled. Note that lifecycle '
1107                             'changes to an instance outside of the compute '
1108                             'service will not be synchronized '
1109                             'automatically since the _sync_power_states '
1110                             'periodic task is also disabled.')
1111             else:
1112                 LOG.info('Instance lifecycle events from the compute '
1113                          'driver have been disabled. Note that lifecycle '
1114                          'changes to an instance outside of the compute '
1115                          'service will only be synchronized by the '
1116                          '_sync_power_states periodic task.')
1117 
1118     def init_host(self):
1119         """Initialization for a standalone compute service."""
1120 
1121         if CONF.pci.passthrough_whitelist:
1122             # Simply loading the PCI passthrough whitelist will do a bunch of
1123             # validation that would otherwise wait until the PciDevTracker is
1124             # constructed when updating available resources for the compute
1125             # node(s) in the resource tracker, effectively killing that task.
1126             # So load up the whitelist when starting the compute service to
1127             # flush any invalid configuration early so we can kill the service
1128             # if the configuration is wrong.
1129             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1130 
1131         # NOTE(sbauza): We want the compute node to hard fail if it won't be
1132         # able to provide its resources to the placement API, or it will not
1133         # be able to be eligible as a destination.
1134         if CONF.placement.os_region_name is None:
1135             raise exception.PlacementNotConfigured()
1136 
1137         self.driver.init_host(host=self.host)
1138         context = nova.context.get_admin_context()
1139         instances = objects.InstanceList.get_by_host(
1140             context, self.host, expected_attrs=['info_cache', 'metadata'])
1141 
1142         if CONF.defer_iptables_apply:
1143             self.driver.filter_defer_apply_on()
1144 
1145         self.init_virt_events()
1146 
1147         try:
1148             # checking that instance was not already evacuated to other host
1149             self._destroy_evacuated_instances(context)
1150             for instance in instances:
1151                 self._init_instance(context, instance)
1152         finally:
1153             if CONF.defer_iptables_apply:
1154                 self.driver.filter_defer_apply_off()
1155             if instances:
1156                 # We only send the instance info to the scheduler on startup
1157                 # if there is anything to send, otherwise this host might
1158                 # not be mapped yet in a cell and the scheduler may have
1159                 # issues dealing with the information. Later changes to
1160                 # instances on this host will update the scheduler, or the
1161                 # _sync_scheduler_instance_info periodic task will.
1162                 self._update_scheduler_instance_info(context, instances)
1163 
1164     def cleanup_host(self):
1165         self.driver.register_event_listener(None)
1166         self.instance_events.cancel_all_events()
1167         self.driver.cleanup_host(host=self.host)
1168 
1169     def pre_start_hook(self):
1170         """After the service is initialized, but before we fully bring
1171         the service up by listening on RPC queues, make sure to update
1172         our available resources (and indirectly our available nodes).
1173         """
1174         self.update_available_resource(nova.context.get_admin_context(),
1175                                        startup=True)
1176 
1177     def _get_power_state(self, context, instance):
1178         """Retrieve the power state for the given instance."""
1179         LOG.debug('Checking state', instance=instance)
1180         try:
1181             return self.driver.get_info(instance).state
1182         except exception.InstanceNotFound:
1183             return power_state.NOSTATE
1184 
1185     def get_console_topic(self, context):
1186         """Retrieves the console host for a project on this host.
1187 
1188         Currently this is just set in the flags for each compute host.
1189 
1190         """
1191         # TODO(mdragon): perhaps make this variable by console_type?
1192         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1193 
1194     @wrap_exception()
1195     def get_console_pool_info(self, context, console_type):
1196         return self.driver.get_console_pool_info(console_type)
1197 
1198     @wrap_exception()
1199     def refresh_instance_security_rules(self, context, instance):
1200         """Tell the virtualization driver to refresh security rules for
1201         an instance.
1202 
1203         Passes straight through to the virtualization driver.
1204 
1205         Synchronize the call because we may still be in the middle of
1206         creating the instance.
1207         """
1208         @utils.synchronized(instance.uuid)
1209         def _sync_refresh():
1210             try:
1211                 return self.driver.refresh_instance_security_rules(instance)
1212             except NotImplementedError:
1213                 LOG.debug('Hypervisor driver does not support '
1214                           'security groups.', instance=instance)
1215 
1216         return _sync_refresh()
1217 
1218     def _await_block_device_map_created(self, context, vol_id):
1219         # TODO(yamahata): creating volume simultaneously
1220         #                 reduces creation time?
1221         # TODO(yamahata): eliminate dumb polling
1222         start = time.time()
1223         retries = CONF.block_device_allocate_retries
1224         if retries < 0:
1225             LOG.warning("Treating negative config value (%(retries)s) for "
1226                         "'block_device_retries' as 0.",
1227                         {'retries': retries})
1228         # (1) treat  negative config value as 0
1229         # (2) the configured value is 0, one attempt should be made
1230         # (3) the configured value is > 0, then the total number attempts
1231         #      is (retries + 1)
1232         attempts = 1
1233         if retries >= 1:
1234             attempts = retries + 1
1235         for attempt in range(1, attempts + 1):
1236             volume = self.volume_api.get(context, vol_id)
1237             volume_status = volume['status']
1238             if volume_status not in ['creating', 'downloading']:
1239                 if volume_status == 'available':
1240                     return attempt
1241                 LOG.warning("Volume id: %(vol_id)s finished being "
1242                             "created but its status is %(vol_status)s.",
1243                             {'vol_id': vol_id,
1244                              'vol_status': volume_status})
1245                 break
1246             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1247         raise exception.VolumeNotCreated(volume_id=vol_id,
1248                                          seconds=int(time.time() - start),
1249                                          attempts=attempt,
1250                                          volume_status=volume_status)
1251 
1252     def _decode_files(self, injected_files):
1253         """Base64 decode the list of files to inject."""
1254         if not injected_files:
1255             return []
1256 
1257         def _decode(f):
1258             path, contents = f
1259             # Py3 raises binascii.Error instead of TypeError as in Py27
1260             try:
1261                 decoded = base64.b64decode(contents)
1262                 return path, decoded
1263             except (TypeError, binascii.Error):
1264                 raise exception.Base64Exception(path=path)
1265 
1266         return [_decode(f) for f in injected_files]
1267 
1268     def _validate_instance_group_policy(self, context, instance,
1269                                         scheduler_hints):
1270         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1271         # However, there is a race condition with the enforcement of
1272         # the policy.  Since more than one instance may be scheduled at the
1273         # same time, it's possible that more than one instance with an
1274         # anti-affinity policy may end up here.  It's also possible that
1275         # multiple instances with an affinity policy could end up on different
1276         # hosts.  This is a validation step to make sure that starting the
1277         # instance here doesn't violate the policy.
1278         group_hint = scheduler_hints.get('group')
1279         if not group_hint:
1280             return
1281 
1282         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1283         # to check the type on the value and pull the single entry out. The
1284         # API request schema validates that the 'group' hint is a single value.
1285         if isinstance(group_hint, list):
1286             group_hint = group_hint[0]
1287 
1288         @utils.synchronized(group_hint)
1289         def _do_validation(context, instance, group_hint):
1290             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1291             if 'anti-affinity' in group.policies:
1292                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1293                 if self.host in group_hosts:
1294                     msg = _("Anti-affinity instance group policy "
1295                             "was violated.")
1296                     raise exception.RescheduledException(
1297                             instance_uuid=instance.uuid,
1298                             reason=msg)
1299             elif 'affinity' in group.policies:
1300                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1301                 if group_hosts and self.host not in group_hosts:
1302                     msg = _("Affinity instance group policy was violated.")
1303                     raise exception.RescheduledException(
1304                             instance_uuid=instance.uuid,
1305                             reason=msg)
1306 
1307         if not CONF.workarounds.disable_group_policy_check_upcall:
1308             _do_validation(context, instance, group_hint)
1309 
1310     def _log_original_error(self, exc_info, instance_uuid):
1311         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1312                   exc_info=exc_info)
1313 
1314     def _reschedule(self, context, request_spec, filter_properties,
1315             instance, reschedule_method, method_args, task_state,
1316             exc_info=None, host_list=None):
1317         """Attempt to re-schedule a compute operation."""
1318 
1319         instance_uuid = instance.uuid
1320         retry = filter_properties.get('retry')
1321         if not retry:
1322             # no retry information, do not reschedule.
1323             LOG.debug("Retry info not present, will not reschedule",
1324                       instance_uuid=instance_uuid)
1325             return
1326 
1327         if not request_spec:
1328             LOG.debug("No request spec, will not reschedule",
1329                       instance_uuid=instance_uuid)
1330             return
1331 
1332         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1333                   {'method': reschedule_method.__name__,
1334                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1335 
1336         # reset the task state:
1337         self._instance_update(context, instance, task_state=task_state)
1338 
1339         if exc_info:
1340             # stringify to avoid circular ref problem in json serialization:
1341             retry['exc'] = traceback.format_exception_only(exc_info[0],
1342                                     exc_info[1])
1343 
1344         reschedule_method(context, *method_args, host_list=host_list)
1345         return True
1346 
1347     @periodic_task.periodic_task
1348     def _check_instance_build_time(self, context):
1349         """Ensure that instances are not stuck in build."""
1350         timeout = CONF.instance_build_timeout
1351         if timeout == 0:
1352             return
1353 
1354         filters = {'vm_state': vm_states.BUILDING,
1355                    'host': self.host}
1356 
1357         building_insts = objects.InstanceList.get_by_filters(context,
1358                            filters, expected_attrs=[], use_slave=True)
1359 
1360         for instance in building_insts:
1361             if timeutils.is_older_than(instance.created_at, timeout):
1362                 self._set_instance_obj_error_state(context, instance)
1363                 LOG.warning("Instance build timed out. Set to error "
1364                             "state.", instance=instance)
1365 
1366     def _check_instance_exists(self, context, instance):
1367         """Ensure an instance with the same name is not already present."""
1368         if self.driver.instance_exists(instance):
1369             raise exception.InstanceExists(name=instance.name)
1370 
1371     def _allocate_network_async(self, context, instance, requested_networks,
1372                                 macs, security_groups, is_vpn):
1373         """Method used to allocate networks in the background.
1374 
1375         Broken out for testing.
1376         """
1377         # First check to see if we're specifically not supposed to allocate
1378         # networks because if so, we can exit early.
1379         if requested_networks and requested_networks.no_allocate:
1380             LOG.debug("Not allocating networking since 'none' was specified.",
1381                       instance=instance)
1382             return network_model.NetworkInfo([])
1383 
1384         LOG.debug("Allocating IP information in the background.",
1385                   instance=instance)
1386         retries = CONF.network_allocate_retries
1387         attempts = retries + 1
1388         retry_time = 1
1389         bind_host_id = self.driver.network_binding_host_id(context, instance)
1390         for attempt in range(1, attempts + 1):
1391             try:
1392                 nwinfo = self.network_api.allocate_for_instance(
1393                         context, instance, vpn=is_vpn,
1394                         requested_networks=requested_networks,
1395                         macs=macs,
1396                         security_groups=security_groups,
1397                         bind_host_id=bind_host_id)
1398                 LOG.debug('Instance network_info: |%s|', nwinfo,
1399                           instance=instance)
1400                 instance.system_metadata['network_allocated'] = 'True'
1401                 # NOTE(JoshNang) do not save the instance here, as it can cause
1402                 # races. The caller shares a reference to instance and waits
1403                 # for this async greenthread to finish before calling
1404                 # instance.save().
1405                 return nwinfo
1406             except Exception:
1407                 exc_info = sys.exc_info()
1408                 log_info = {'attempt': attempt,
1409                             'attempts': attempts}
1410                 if attempt == attempts:
1411                     LOG.exception('Instance failed network setup '
1412                                   'after %(attempts)d attempt(s)',
1413                                   log_info)
1414                     six.reraise(*exc_info)
1415                 LOG.warning('Instance failed network setup '
1416                             '(attempt %(attempt)d of %(attempts)d)',
1417                             log_info, instance=instance)
1418                 time.sleep(retry_time)
1419                 retry_time *= 2
1420                 if retry_time > 30:
1421                     retry_time = 30
1422         # Not reached.
1423 
1424     def _build_networks_for_instance(self, context, instance,
1425             requested_networks, security_groups):
1426 
1427         # If we're here from a reschedule the network may already be allocated.
1428         if strutils.bool_from_string(
1429                 instance.system_metadata.get('network_allocated', 'False')):
1430             # NOTE(alex_xu): The network_allocated is True means the network
1431             # resource already allocated at previous scheduling, and the
1432             # network setup is cleanup at previous. After rescheduling, the
1433             # network resource need setup on the new host.
1434             self.network_api.setup_instance_network_on_host(
1435                 context, instance, instance.host)
1436             return self.network_api.get_instance_nw_info(context, instance)
1437 
1438         if not self.is_neutron_security_groups:
1439             security_groups = []
1440 
1441         macs = self.driver.macs_for_instance(instance)
1442         network_info = self._allocate_network(context, instance,
1443                 requested_networks, macs, security_groups)
1444 
1445         return network_info
1446 
1447     def _allocate_network(self, context, instance, requested_networks, macs,
1448                           security_groups):
1449         """Start network allocation asynchronously.  Return an instance
1450         of NetworkInfoAsyncWrapper that can be used to retrieve the
1451         allocated networks when the operation has finished.
1452         """
1453         # NOTE(comstud): Since we're allocating networks asynchronously,
1454         # this task state has little meaning, as we won't be in this
1455         # state for very long.
1456         instance.vm_state = vm_states.BUILDING
1457         instance.task_state = task_states.NETWORKING
1458         instance.save(expected_task_state=[None])
1459 
1460         is_vpn = False
1461         return network_model.NetworkInfoAsyncWrapper(
1462                 self._allocate_network_async, context, instance,
1463                 requested_networks, macs, security_groups, is_vpn)
1464 
1465     def _default_root_device_name(self, instance, image_meta, root_bdm):
1466         try:
1467             return self.driver.default_root_device_name(instance,
1468                                                         image_meta,
1469                                                         root_bdm)
1470         except NotImplementedError:
1471             return compute_utils.get_next_device_name(instance, [])
1472 
1473     def _default_device_names_for_instance(self, instance,
1474                                            root_device_name,
1475                                            *block_device_lists):
1476         try:
1477             self.driver.default_device_names_for_instance(instance,
1478                                                           root_device_name,
1479                                                           *block_device_lists)
1480         except NotImplementedError:
1481             compute_utils.default_device_names_for_instance(
1482                 instance, root_device_name, *block_device_lists)
1483 
1484     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1485         # NOTE(ndipanov): Copy obj to avoid changing the original
1486         block_device_obj = block_device_obj.obj_clone()
1487         try:
1488             return self.driver.get_device_name_for_instance(
1489                 instance, bdms, block_device_obj)
1490         except NotImplementedError:
1491             return compute_utils.get_device_name_for_instance(
1492                 instance, bdms, block_device_obj.get("device_name"))
1493 
1494     def _default_block_device_names(self, instance, image_meta, block_devices):
1495         """Verify that all the devices have the device_name set. If not,
1496         provide a default name.
1497 
1498         It also ensures that there is a root_device_name and is set to the
1499         first block device in the boot sequence (boot_index=0).
1500         """
1501         root_bdm = block_device.get_root_bdm(block_devices)
1502         if not root_bdm:
1503             return
1504 
1505         # Get the root_device_name from the root BDM or the instance
1506         root_device_name = None
1507         update_root_bdm = False
1508 
1509         if root_bdm.device_name:
1510             root_device_name = root_bdm.device_name
1511             instance.root_device_name = root_device_name
1512         elif instance.root_device_name:
1513             root_device_name = instance.root_device_name
1514             root_bdm.device_name = root_device_name
1515             update_root_bdm = True
1516         else:
1517             root_device_name = self._default_root_device_name(instance,
1518                                                               image_meta,
1519                                                               root_bdm)
1520 
1521             instance.root_device_name = root_device_name
1522             root_bdm.device_name = root_device_name
1523             update_root_bdm = True
1524 
1525         if update_root_bdm:
1526             root_bdm.save()
1527 
1528         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1529                             block_devices))
1530         swap = list(filter(block_device.new_format_is_swap,
1531                       block_devices))
1532         block_device_mapping = list(filter(
1533               driver_block_device.is_block_device_mapping, block_devices))
1534 
1535         self._default_device_names_for_instance(instance,
1536                                                 root_device_name,
1537                                                 ephemerals,
1538                                                 swap,
1539                                                 block_device_mapping)
1540 
1541     def _block_device_info_to_legacy(self, block_device_info):
1542         """Convert BDI to the old format for drivers that need it."""
1543 
1544         if self.use_legacy_block_device_info:
1545             ephemerals = driver_block_device.legacy_block_devices(
1546                 driver.block_device_info_get_ephemerals(block_device_info))
1547             mapping = driver_block_device.legacy_block_devices(
1548                 driver.block_device_info_get_mapping(block_device_info))
1549             swap = block_device_info['swap']
1550             if swap:
1551                 swap = swap.legacy()
1552 
1553             block_device_info.update({
1554                 'ephemerals': ephemerals,
1555                 'swap': swap,
1556                 'block_device_mapping': mapping})
1557 
1558     def _add_missing_dev_names(self, bdms, instance):
1559         for bdm in bdms:
1560             if bdm.device_name is not None:
1561                 continue
1562 
1563             device_name = self._get_device_name_for_instance(instance,
1564                                                              bdms, bdm)
1565             values = {'device_name': device_name}
1566             bdm.update(values)
1567             bdm.save()
1568 
1569     def _prep_block_device(self, context, instance, bdms):
1570         """Set up the block device for an instance with error logging."""
1571         try:
1572             self._add_missing_dev_names(bdms, instance)
1573             block_device_info = driver.get_block_device_info(instance, bdms)
1574             mapping = driver.block_device_info_get_mapping(block_device_info)
1575             driver_block_device.attach_block_devices(
1576                 mapping, context, instance, self.volume_api, self.driver,
1577                 wait_func=self._await_block_device_map_created)
1578 
1579             self._block_device_info_to_legacy(block_device_info)
1580             return block_device_info
1581 
1582         except exception.OverQuota as e:
1583             LOG.warning('Failed to create block device for instance due'
1584                         ' to exceeding volume related resource quota.'
1585                         ' Error: %s', e.message, instance=instance)
1586             raise
1587 
1588         except Exception as ex:
1589             LOG.exception('Instance failed block device setup',
1590                           instance=instance)
1591             # InvalidBDM will eventually result in a BuildAbortException when
1592             # booting from volume, and will be recorded as an instance fault.
1593             # Maintain the original exception message which most likely has
1594             # useful details which the standard InvalidBDM error message lacks.
1595             raise exception.InvalidBDM(six.text_type(ex))
1596 
1597     def _update_instance_after_spawn(self, context, instance):
1598         instance.power_state = self._get_power_state(context, instance)
1599         instance.vm_state = vm_states.ACTIVE
1600         instance.task_state = None
1601         instance.launched_at = timeutils.utcnow()
1602         configdrive.update_instance(instance)
1603 
1604     def _update_scheduler_instance_info(self, context, instance):
1605         """Sends an InstanceList with created or updated Instance objects to
1606         the Scheduler client.
1607 
1608         In the case of init_host, the value passed will already be an
1609         InstanceList. Other calls will send individual Instance objects that
1610         have been created or resized. In this case, we create an InstanceList
1611         object containing that Instance.
1612         """
1613         if not self.send_instance_updates:
1614             return
1615         if isinstance(instance, obj_instance.Instance):
1616             instance = objects.InstanceList(objects=[instance])
1617         context = context.elevated()
1618         self.scheduler_client.update_instance_info(context, self.host,
1619                                                    instance)
1620 
1621     def _delete_scheduler_instance_info(self, context, instance_uuid):
1622         """Sends the uuid of the deleted Instance to the Scheduler client."""
1623         if not self.send_instance_updates:
1624             return
1625         context = context.elevated()
1626         self.scheduler_client.delete_instance_info(context, self.host,
1627                                                    instance_uuid)
1628 
1629     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1630     def _sync_scheduler_instance_info(self, context):
1631         if not self.send_instance_updates:
1632             return
1633         context = context.elevated()
1634         instances = objects.InstanceList.get_by_host(context, self.host,
1635                                                      expected_attrs=[],
1636                                                      use_slave=True)
1637         uuids = [instance.uuid for instance in instances]
1638         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1639 
1640     def _notify_about_instance_usage(self, context, instance, event_suffix,
1641                                      network_info=None, system_metadata=None,
1642                                      extra_usage_info=None, fault=None):
1643         compute_utils.notify_about_instance_usage(
1644             self.notifier, context, instance, event_suffix,
1645             network_info=network_info,
1646             system_metadata=system_metadata,
1647             extra_usage_info=extra_usage_info, fault=fault)
1648 
1649     def _deallocate_network(self, context, instance,
1650                             requested_networks=None):
1651         # If we were told not to allocate networks let's save ourselves
1652         # the trouble of calling the network API.
1653         if requested_networks and requested_networks.no_allocate:
1654             LOG.debug("Skipping network deallocation for instance since "
1655                       "networking was not requested.", instance=instance)
1656             return
1657 
1658         LOG.debug('Deallocating network for instance', instance=instance)
1659         with timeutils.StopWatch() as timer:
1660             self.network_api.deallocate_for_instance(
1661                 context, instance, requested_networks=requested_networks)
1662         # nova-network does an rpc call so we're OK tracking time spent here
1663         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1664                  timer.elapsed(), instance=instance)
1665 
1666     def _get_instance_block_device_info(self, context, instance,
1667                                         refresh_conn_info=False,
1668                                         bdms=None):
1669         """Transform block devices to the driver block_device format."""
1670 
1671         if not bdms:
1672             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1673                     context, instance.uuid)
1674         block_device_info = driver.get_block_device_info(instance, bdms)
1675 
1676         if not refresh_conn_info:
1677             # if the block_device_mapping has no value in connection_info
1678             # (returned as None), don't include in the mapping
1679             block_device_info['block_device_mapping'] = [
1680                 bdm for bdm in driver.block_device_info_get_mapping(
1681                                     block_device_info)
1682                 if bdm.get('connection_info')]
1683         else:
1684             driver_block_device.refresh_conn_infos(
1685                 driver.block_device_info_get_mapping(block_device_info),
1686                 context, instance, self.volume_api, self.driver)
1687 
1688         self._block_device_info_to_legacy(block_device_info)
1689 
1690         return block_device_info
1691 
1692     def _build_failed(self):
1693         self._failed_builds += 1
1694         limit = CONF.compute.consecutive_build_service_disable_threshold
1695         if limit and self._failed_builds >= limit:
1696             # NOTE(danms): If we're doing a bunch of parallel builds,
1697             # it is possible (although not likely) that we have already
1698             # failed N-1 builds before this and we race with a successful
1699             # build and disable ourselves here when we might've otherwise
1700             # not.
1701             LOG.error('Disabling service due to %(fails)i '
1702                       'consecutive build failures',
1703                       {'fails': self._failed_builds})
1704             ctx = nova.context.get_admin_context()
1705             service = objects.Service.get_by_compute_host(ctx, CONF.host)
1706             service.disabled = True
1707             service.disabled_reason = (
1708                 'Auto-disabled due to %i build failures' % self._failed_builds)
1709             service.save()
1710             # NOTE(danms): Reset our counter now so that when the admin
1711             # re-enables us we can start fresh
1712             self._failed_builds = 0
1713         elif self._failed_builds > 1:
1714             LOG.warning('%(fails)i consecutive build failures',
1715                         {'fails': self._failed_builds})
1716 
1717     @wrap_exception()
1718     @reverts_task_state
1719     @wrap_instance_fault
1720     def build_and_run_instance(self, context, instance, image, request_spec,
1721                      filter_properties, admin_password=None,
1722                      injected_files=None, requested_networks=None,
1723                      security_groups=None, block_device_mapping=None,
1724                      node=None, limits=None, host_list=None):
1725 
1726         @utils.synchronized(instance.uuid)
1727         def _locked_do_build_and_run_instance(*args, **kwargs):
1728             # NOTE(danms): We grab the semaphore with the instance uuid
1729             # locked because we could wait in line to build this instance
1730             # for a while and we want to make sure that nothing else tries
1731             # to do anything with this instance while we wait.
1732             with self._build_semaphore:
1733                 try:
1734                     result = self._do_build_and_run_instance(*args, **kwargs)
1735                 except Exception:
1736                     # NOTE(mriedem): This should really only happen if
1737                     # _decode_files in _do_build_and_run_instance fails, and
1738                     # that's before a guest is spawned so it's OK to remove
1739                     # allocations for the instance for this node from Placement
1740                     # below as there is no guest consuming resources anyway.
1741                     # The _decode_files case could be handled more specifically
1742                     # but that's left for another day.
1743                     result = build_results.FAILED
1744                     raise
1745                 finally:
1746                     if result == build_results.FAILED:
1747                         # Remove the allocation records from Placement for the
1748                         # instance if the build failed. The instance.host is
1749                         # likely set to None in _do_build_and_run_instance
1750                         # which means if the user deletes the instance, it
1751                         # will be deleted in the API, not the compute service.
1752                         # Setting the instance.host to None in
1753                         # _do_build_and_run_instance means that the
1754                         # ResourceTracker will no longer consider this instance
1755                         # to be claiming resources against it, so we want to
1756                         # reflect that same thing in Placement.  No need to
1757                         # call this for a reschedule, as the allocations will
1758                         # have already been removed in
1759                         # self._do_build_and_run_instance().
1760                         self._delete_allocation_for_instance(context,
1761                                                              instance.uuid)
1762 
1763                     if result in (build_results.FAILED,
1764                                   build_results.RESCHEDULED):
1765                         self._build_failed()
1766                     else:
1767                         self._failed_builds = 0
1768 
1769         # NOTE(danms): We spawn here to return the RPC worker thread back to
1770         # the pool. Since what follows could take a really long time, we don't
1771         # want to tie up RPC workers.
1772         utils.spawn_n(_locked_do_build_and_run_instance,
1773                       context, instance, image, request_spec,
1774                       filter_properties, admin_password, injected_files,
1775                       requested_networks, security_groups,
1776                       block_device_mapping, node, limits, host_list)
1777 
1778     def _delete_allocation_for_instance(self, context, instance_uuid):
1779         rt = self._get_resource_tracker()
1780         rt.reportclient.delete_allocation_for_instance(context, instance_uuid)
1781 
1782     def _check_device_tagging(self, requested_networks, block_device_mapping):
1783         tagging_requested = False
1784         if requested_networks:
1785             for net in requested_networks:
1786                 if 'tag' in net and net.tag is not None:
1787                     tagging_requested = True
1788                     break
1789         if block_device_mapping and not tagging_requested:
1790             for bdm in block_device_mapping:
1791                 if 'tag' in bdm and bdm.tag is not None:
1792                     tagging_requested = True
1793                     break
1794         if (tagging_requested and
1795                 not self.driver.capabilities.get('supports_device_tagging',
1796                                                  False)):
1797             raise exception.BuildAbortException('Attempt to boot guest with '
1798                                                 'tagged devices on host that '
1799                                                 'does not support tagging.')
1800 
1801     @hooks.add_hook('build_instance')
1802     @wrap_exception()
1803     @reverts_task_state
1804     @wrap_instance_event(prefix='compute')
1805     @wrap_instance_fault
1806     def _do_build_and_run_instance(self, context, instance, image,
1807             request_spec, filter_properties, admin_password, injected_files,
1808             requested_networks, security_groups, block_device_mapping,
1809             node=None, limits=None, host_list=None):
1810 
1811         try:
1812             LOG.debug('Starting instance...', instance=instance)
1813             instance.vm_state = vm_states.BUILDING
1814             instance.task_state = None
1815             instance.save(expected_task_state=
1816                     (task_states.SCHEDULING, None))
1817         except exception.InstanceNotFound:
1818             msg = 'Instance disappeared before build.'
1819             LOG.debug(msg, instance=instance)
1820             return build_results.FAILED
1821         except exception.UnexpectedTaskStateError as e:
1822             LOG.debug(e.format_message(), instance=instance)
1823             return build_results.FAILED
1824 
1825         # b64 decode the files to inject:
1826         decoded_files = self._decode_files(injected_files)
1827 
1828         if limits is None:
1829             limits = {}
1830 
1831         if node is None:
1832             node = self._get_nodename(instance, refresh=True)
1833 
1834         try:
1835             with timeutils.StopWatch() as timer:
1836                 self._build_and_run_instance(context, instance, image,
1837                         decoded_files, admin_password, requested_networks,
1838                         security_groups, block_device_mapping, node, limits,
1839                         filter_properties, request_spec)
1840             LOG.info('Took %0.2f seconds to build instance.',
1841                      timer.elapsed(), instance=instance)
1842             return build_results.ACTIVE
1843         except exception.RescheduledException as e:
1844             retry = filter_properties.get('retry')
1845             if not retry:
1846                 # no retry information, do not reschedule.
1847                 LOG.debug("Retry info not present, will not reschedule",
1848                     instance=instance)
1849                 self._cleanup_allocated_networks(context, instance,
1850                     requested_networks)
1851                 self._cleanup_volumes(context, instance,
1852                     block_device_mapping, raise_exc=False)
1853                 compute_utils.add_instance_fault_from_exc(context,
1854                         instance, e, sys.exc_info(),
1855                         fault_message=e.kwargs['reason'])
1856                 self._nil_out_instance_obj_host_and_node(instance)
1857                 self._set_instance_obj_error_state(context, instance,
1858                                                    clean_task_state=True)
1859                 return build_results.FAILED
1860             LOG.debug(e.format_message(), instance=instance)
1861             # This will be used for logging the exception
1862             retry['exc'] = traceback.format_exception(*sys.exc_info())
1863             # This will be used for setting the instance fault message
1864             retry['exc_reason'] = e.kwargs['reason']
1865             # NOTE(comstud): Deallocate networks if the driver wants
1866             # us to do so.
1867             # NOTE(vladikr): SR-IOV ports should be deallocated to
1868             # allow new sriov pci devices to be allocated on a new host.
1869             # Otherwise, if devices with pci addresses are already allocated
1870             # on the destination host, the instance will fail to spawn.
1871             # info_cache.network_info should be present at this stage.
1872             if (self.driver.deallocate_networks_on_reschedule(instance) or
1873                 self.deallocate_sriov_ports_on_reschedule(instance)):
1874                 self._cleanup_allocated_networks(context, instance,
1875                         requested_networks)
1876             else:
1877                 # NOTE(alex_xu): Network already allocated and we don't
1878                 # want to deallocate them before rescheduling. But we need
1879                 # to cleanup those network resources setup on this host before
1880                 # rescheduling.
1881                 self.network_api.cleanup_instance_network_on_host(
1882                     context, instance, self.host)
1883 
1884             self._nil_out_instance_obj_host_and_node(instance)
1885             instance.task_state = task_states.SCHEDULING
1886             instance.save()
1887             # The instance will have already claimed resources from this host
1888             # before this build was attempted. Now that it has failed, we need
1889             # to unclaim those resources before casting to the conductor, so
1890             # that if there are alternate hosts available for a retry, it can
1891             # claim resources on that new host for the instance.
1892             self._delete_allocation_for_instance(context, instance.uuid)
1893 
1894             self.compute_task_api.build_instances(context, [instance],
1895                     image, filter_properties, admin_password,
1896                     injected_files, requested_networks, security_groups,
1897                     block_device_mapping, request_spec=request_spec,
1898                     host_lists=[host_list])
1899             return build_results.RESCHEDULED
1900         except (exception.InstanceNotFound,
1901                 exception.UnexpectedDeletingTaskStateError):
1902             msg = 'Instance disappeared during build.'
1903             LOG.debug(msg, instance=instance)
1904             self._cleanup_allocated_networks(context, instance,
1905                     requested_networks)
1906             return build_results.FAILED
1907         except exception.BuildAbortException as e:
1908             LOG.exception(e.format_message(), instance=instance)
1909             self._cleanup_allocated_networks(context, instance,
1910                     requested_networks)
1911             self._cleanup_volumes(context, instance,
1912                     block_device_mapping, raise_exc=False)
1913             compute_utils.add_instance_fault_from_exc(context, instance,
1914                     e, sys.exc_info())
1915             self._nil_out_instance_obj_host_and_node(instance)
1916             self._set_instance_obj_error_state(context, instance,
1917                                                clean_task_state=True)
1918             return build_results.FAILED
1919         except Exception as e:
1920             # Should not reach here.
1921             LOG.exception('Unexpected build failure, not rescheduling build.',
1922                           instance=instance)
1923             self._cleanup_allocated_networks(context, instance,
1924                     requested_networks)
1925             self._cleanup_volumes(context, instance,
1926                     block_device_mapping, raise_exc=False)
1927             compute_utils.add_instance_fault_from_exc(context, instance,
1928                     e, sys.exc_info())
1929             self._nil_out_instance_obj_host_and_node(instance)
1930             self._set_instance_obj_error_state(context, instance,
1931                                                clean_task_state=True)
1932             return build_results.FAILED
1933 
1934     def deallocate_sriov_ports_on_reschedule(self, instance):
1935         """Determine if networks are needed to be deallocated before reschedule
1936 
1937         Check the cached network info for any assigned SR-IOV ports.
1938         SR-IOV ports should be deallocated prior to rescheduling
1939         in order to allow new sriov pci devices to be allocated on a new host.
1940         """
1941         info_cache = instance.info_cache
1942 
1943         def _has_sriov_port(vif):
1944             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
1945 
1946         if (info_cache and info_cache.network_info):
1947             for vif in info_cache.network_info:
1948                 if _has_sriov_port(vif):
1949                     return True
1950         return False
1951 
1952     @staticmethod
1953     def _get_scheduler_hints(filter_properties, request_spec=None):
1954         """Helper method to get scheduler hints.
1955 
1956         This method prefers to get the hints out of the request spec, but that
1957         might not be provided. Conductor will pass request_spec down to the
1958         first compute chosen for a build but older computes will not pass
1959         the request_spec to conductor's build_instances method for a
1960         a reschedule, so if we're on a host via a retry, request_spec may not
1961         be provided so we need to fallback to use the filter_properties
1962         to get scheduler hints.
1963         """
1964         hints = {}
1965         if request_spec is not None and 'scheduler_hints' in request_spec:
1966             hints = request_spec.scheduler_hints
1967         if not hints:
1968             hints = filter_properties.get('scheduler_hints') or {}
1969         return hints
1970 
1971     def _build_and_run_instance(self, context, instance, image, injected_files,
1972             admin_password, requested_networks, security_groups,
1973             block_device_mapping, node, limits, filter_properties,
1974             request_spec=None):
1975 
1976         image_name = image.get('name')
1977         self._notify_about_instance_usage(context, instance, 'create.start',
1978                 extra_usage_info={'image_name': image_name})
1979         compute_utils.notify_about_instance_create(
1980             context, instance, self.host,
1981             phase=fields.NotificationPhase.START,
1982             bdms=block_device_mapping)
1983 
1984         # NOTE(mikal): cache the keystone roles associated with the instance
1985         # at boot time for later reference
1986         instance.system_metadata.update(
1987             {'boot_roles': ','.join(context.roles)})
1988 
1989         self._check_device_tagging(requested_networks, block_device_mapping)
1990 
1991         try:
1992             scheduler_hints = self._get_scheduler_hints(filter_properties,
1993                                                         request_spec)
1994             rt = self._get_resource_tracker()
1995             with rt.instance_claim(context, instance, node, limits):
1996                 # NOTE(russellb) It's important that this validation be done
1997                 # *after* the resource tracker instance claim, as that is where
1998                 # the host is set on the instance.
1999                 self._validate_instance_group_policy(context, instance,
2000                                                      scheduler_hints)
2001                 image_meta = objects.ImageMeta.from_dict(image)
2002                 with self._build_resources(context, instance,
2003                         requested_networks, security_groups, image_meta,
2004                         block_device_mapping) as resources:
2005                     instance.vm_state = vm_states.BUILDING
2006                     instance.task_state = task_states.SPAWNING
2007                     # NOTE(JoshNang) This also saves the changes to the
2008                     # instance from _allocate_network_async, as they aren't
2009                     # saved in that function to prevent races.
2010                     instance.save(expected_task_state=
2011                             task_states.BLOCK_DEVICE_MAPPING)
2012                     block_device_info = resources['block_device_info']
2013                     network_info = resources['network_info']
2014                     allocs = resources['allocations']
2015                     LOG.debug('Start spawning the instance on the hypervisor.',
2016                               instance=instance)
2017                     with timeutils.StopWatch() as timer:
2018                         self.driver.spawn(context, instance, image_meta,
2019                                           injected_files, admin_password,
2020                                           allocs, network_info=network_info,
2021                                           block_device_info=block_device_info)
2022                     LOG.info('Took %0.2f seconds to spawn the instance on '
2023                              'the hypervisor.', timer.elapsed(),
2024                              instance=instance)
2025         except (exception.InstanceNotFound,
2026                 exception.UnexpectedDeletingTaskStateError) as e:
2027             with excutils.save_and_reraise_exception():
2028                 self._notify_about_instance_usage(context, instance,
2029                     'create.error', fault=e)
2030                 compute_utils.notify_about_instance_create(
2031                     context, instance, self.host,
2032                     phase=fields.NotificationPhase.ERROR, exception=e,
2033                     bdms=block_device_mapping)
2034         except exception.ComputeResourcesUnavailable as e:
2035             LOG.debug(e.format_message(), instance=instance)
2036             self._notify_about_instance_usage(context, instance,
2037                     'create.error', fault=e)
2038             compute_utils.notify_about_instance_create(
2039                     context, instance, self.host,
2040                     phase=fields.NotificationPhase.ERROR, exception=e,
2041                     bdms=block_device_mapping)
2042             raise exception.RescheduledException(
2043                     instance_uuid=instance.uuid, reason=e.format_message())
2044         except exception.BuildAbortException as e:
2045             with excutils.save_and_reraise_exception():
2046                 LOG.debug(e.format_message(), instance=instance)
2047                 self._notify_about_instance_usage(context, instance,
2048                     'create.error', fault=e)
2049                 compute_utils.notify_about_instance_create(
2050                     context, instance, self.host,
2051                     phase=fields.NotificationPhase.ERROR, exception=e,
2052                     bdms=block_device_mapping)
2053         except (exception.FixedIpLimitExceeded,
2054                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2055             LOG.warning('No more network or fixed IP to be allocated',
2056                         instance=instance)
2057             self._notify_about_instance_usage(context, instance,
2058                     'create.error', fault=e)
2059             compute_utils.notify_about_instance_create(
2060                     context, instance, self.host,
2061                     phase=fields.NotificationPhase.ERROR, exception=e,
2062                     bdms=block_device_mapping)
2063             msg = _('Failed to allocate the network(s) with error %s, '
2064                     'not rescheduling.') % e.format_message()
2065             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2066                     reason=msg)
2067         except (exception.VirtualInterfaceCreateException,
2068                 exception.VirtualInterfaceMacAddressException,
2069                 exception.FixedIpInvalidOnHost,
2070                 exception.UnableToAutoAllocateNetwork) as e:
2071             LOG.exception('Failed to allocate network(s)',
2072                           instance=instance)
2073             self._notify_about_instance_usage(context, instance,
2074                     'create.error', fault=e)
2075             compute_utils.notify_about_instance_create(
2076                     context, instance, self.host,
2077                     phase=fields.NotificationPhase.ERROR, exception=e,
2078                     bdms=block_device_mapping)
2079             msg = _('Failed to allocate the network(s), not rescheduling.')
2080             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2081                     reason=msg)
2082         except (exception.FlavorDiskTooSmall,
2083                 exception.FlavorMemoryTooSmall,
2084                 exception.ImageNotActive,
2085                 exception.ImageUnacceptable,
2086                 exception.InvalidDiskInfo,
2087                 exception.InvalidDiskFormat,
2088                 cursive_exception.SignatureVerificationError,
2089                 exception.VolumeEncryptionNotSupported,
2090                 exception.InvalidInput) as e:
2091             self._notify_about_instance_usage(context, instance,
2092                     'create.error', fault=e)
2093             compute_utils.notify_about_instance_create(
2094                     context, instance, self.host,
2095                     phase=fields.NotificationPhase.ERROR, exception=e,
2096                     bdms=block_device_mapping)
2097             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2098                     reason=e.format_message())
2099         except Exception as e:
2100             self._notify_about_instance_usage(context, instance,
2101                     'create.error', fault=e)
2102             compute_utils.notify_about_instance_create(
2103                     context, instance, self.host,
2104                     phase=fields.NotificationPhase.ERROR, exception=e,
2105                     bdms=block_device_mapping)
2106             raise exception.RescheduledException(
2107                     instance_uuid=instance.uuid, reason=six.text_type(e))
2108 
2109         # NOTE(alaski): This is only useful during reschedules, remove it now.
2110         instance.system_metadata.pop('network_allocated', None)
2111 
2112         # If CONF.default_access_ip_network_name is set, grab the
2113         # corresponding network and set the access ip values accordingly.
2114         network_name = CONF.default_access_ip_network_name
2115         if (network_name and not instance.access_ip_v4 and
2116                 not instance.access_ip_v6):
2117             # Note that when there are multiple ips to choose from, an
2118             # arbitrary one will be chosen.
2119             for vif in network_info:
2120                 if vif['network']['label'] == network_name:
2121                     for ip in vif.fixed_ips():
2122                         if not instance.access_ip_v4 and ip['version'] == 4:
2123                             instance.access_ip_v4 = ip['address']
2124                         if not instance.access_ip_v6 and ip['version'] == 6:
2125                             instance.access_ip_v6 = ip['address']
2126                     break
2127 
2128         self._update_instance_after_spawn(context, instance)
2129 
2130         try:
2131             instance.save(expected_task_state=task_states.SPAWNING)
2132         except (exception.InstanceNotFound,
2133                 exception.UnexpectedDeletingTaskStateError) as e:
2134             with excutils.save_and_reraise_exception():
2135                 self._notify_about_instance_usage(context, instance,
2136                     'create.error', fault=e)
2137                 compute_utils.notify_about_instance_create(
2138                     context, instance, self.host,
2139                     phase=fields.NotificationPhase.ERROR, exception=e,
2140                     bdms=block_device_mapping)
2141 
2142         self._update_scheduler_instance_info(context, instance)
2143         self._notify_about_instance_usage(context, instance, 'create.end',
2144                 extra_usage_info={'message': _('Success')},
2145                 network_info=network_info)
2146         compute_utils.notify_about_instance_create(context, instance,
2147                 self.host, phase=fields.NotificationPhase.END,
2148                 bdms=block_device_mapping)
2149 
2150     @contextlib.contextmanager
2151     def _build_resources(self, context, instance, requested_networks,
2152                          security_groups, image_meta, block_device_mapping):
2153         resources = {}
2154         network_info = None
2155         try:
2156             LOG.debug('Start building networks asynchronously for instance.',
2157                       instance=instance)
2158             network_info = self._build_networks_for_instance(context, instance,
2159                     requested_networks, security_groups)
2160             resources['network_info'] = network_info
2161         except (exception.InstanceNotFound,
2162                 exception.UnexpectedDeletingTaskStateError):
2163             raise
2164         except exception.UnexpectedTaskStateError as e:
2165             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2166                     reason=e.format_message())
2167         except Exception:
2168             # Because this allocation is async any failures are likely to occur
2169             # when the driver accesses network_info during spawn().
2170             LOG.exception('Failed to allocate network(s)',
2171                           instance=instance)
2172             msg = _('Failed to allocate the network(s), not rescheduling.')
2173             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2174                     reason=msg)
2175 
2176         try:
2177             # Depending on a virt driver, some network configuration is
2178             # necessary before preparing block devices.
2179             self.driver.prepare_networks_before_block_device_mapping(
2180                 instance, network_info)
2181 
2182             # Verify that all the BDMs have a device_name set and assign a
2183             # default to the ones missing it with the help of the driver.
2184             self._default_block_device_names(instance, image_meta,
2185                                              block_device_mapping)
2186 
2187             LOG.debug('Start building block device mappings for instance.',
2188                       instance=instance)
2189             instance.vm_state = vm_states.BUILDING
2190             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2191             instance.save()
2192 
2193             block_device_info = self._prep_block_device(context, instance,
2194                     block_device_mapping)
2195             resources['block_device_info'] = block_device_info
2196         except (exception.InstanceNotFound,
2197                 exception.UnexpectedDeletingTaskStateError):
2198             with excutils.save_and_reraise_exception():
2199                 # Make sure the async call finishes
2200                 if network_info is not None:
2201                     network_info.wait(do_raise=False)
2202                     self.driver.clean_networks_preparation(instance,
2203                                                            network_info)
2204         except (exception.UnexpectedTaskStateError,
2205                 exception.OverQuota, exception.InvalidBDM) as e:
2206             # Make sure the async call finishes
2207             if network_info is not None:
2208                 network_info.wait(do_raise=False)
2209                 self.driver.clean_networks_preparation(instance, network_info)
2210             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2211                     reason=e.format_message())
2212         except Exception:
2213             LOG.exception('Failure prepping block device',
2214                           instance=instance)
2215             # Make sure the async call finishes
2216             if network_info is not None:
2217                 network_info.wait(do_raise=False)
2218                 self.driver.clean_networks_preparation(instance, network_info)
2219             msg = _('Failure prepping block device.')
2220             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2221                     reason=msg)
2222 
2223         try:
2224             resources['allocations'] = (
2225                 self.reportclient.get_allocations_for_consumer(context,
2226                                                                instance.uuid))
2227         except Exception:
2228             LOG.exception('Failure retrieving placement allocations',
2229                           instance=instance)
2230             # Make sure the async call finishes
2231             if network_info is not None:
2232                 network_info.wait(do_raise=False)
2233             msg = _('Failure retrieving placement allocations')
2234             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2235                                                 reason=msg)
2236 
2237         try:
2238             yield resources
2239         except Exception as exc:
2240             with excutils.save_and_reraise_exception() as ctxt:
2241                 if not isinstance(exc, (
2242                         exception.InstanceNotFound,
2243                         exception.UnexpectedDeletingTaskStateError)):
2244                     LOG.exception('Instance failed to spawn',
2245                                   instance=instance)
2246                 # Make sure the async call finishes
2247                 if network_info is not None:
2248                     network_info.wait(do_raise=False)
2249                 # if network_info is empty we're likely here because of
2250                 # network allocation failure. Since nothing can be reused on
2251                 # rescheduling it's better to deallocate network to eliminate
2252                 # the chance of orphaned ports in neutron
2253                 deallocate_networks = False if network_info else True
2254                 try:
2255                     self._shutdown_instance(context, instance,
2256                             block_device_mapping, requested_networks,
2257                             try_deallocate_networks=deallocate_networks)
2258                 except Exception as exc2:
2259                     ctxt.reraise = False
2260                     LOG.warning('Could not clean up failed build,'
2261                                 ' not rescheduling. Error: %s',
2262                                 six.text_type(exc2))
2263                     raise exception.BuildAbortException(
2264                             instance_uuid=instance.uuid,
2265                             reason=six.text_type(exc))
2266 
2267     def _cleanup_allocated_networks(self, context, instance,
2268             requested_networks):
2269         try:
2270             self._deallocate_network(context, instance, requested_networks)
2271         except Exception:
2272             LOG.exception('Failed to deallocate networks', instance=instance)
2273             return
2274 
2275         instance.system_metadata['network_allocated'] = 'False'
2276         try:
2277             instance.save()
2278         except exception.InstanceNotFound:
2279             # NOTE(alaski): It's possible that we're cleaning up the networks
2280             # because the instance was deleted.  If that's the case then this
2281             # exception will be raised by instance.save()
2282             pass
2283 
2284     def _try_deallocate_network(self, context, instance,
2285                                 requested_networks=None):
2286         try:
2287             # tear down allocated network structure
2288             self._deallocate_network(context, instance, requested_networks)
2289         except Exception as ex:
2290             with excutils.save_and_reraise_exception():
2291                 LOG.error('Failed to deallocate network for instance. '
2292                           'Error: %s', ex, instance=instance)
2293                 self._set_instance_obj_error_state(context, instance)
2294 
2295     def _get_power_off_values(self, context, instance, clean_shutdown):
2296         """Get the timing configuration for powering down this instance."""
2297         if clean_shutdown:
2298             timeout = compute_utils.get_value_from_system_metadata(instance,
2299                           key='image_os_shutdown_timeout', type=int,
2300                           default=CONF.shutdown_timeout)
2301             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2302         else:
2303             timeout = 0
2304             retry_interval = 0
2305 
2306         return timeout, retry_interval
2307 
2308     def _power_off_instance(self, context, instance, clean_shutdown=True):
2309         """Power off an instance on this host."""
2310         timeout, retry_interval = self._get_power_off_values(context,
2311                                         instance, clean_shutdown)
2312         self.driver.power_off(instance, timeout, retry_interval)
2313 
2314     def _shutdown_instance(self, context, instance,
2315                            bdms, requested_networks=None, notify=True,
2316                            try_deallocate_networks=True):
2317         """Shutdown an instance on this host.
2318 
2319         :param:context: security context
2320         :param:instance: a nova.objects.Instance object
2321         :param:bdms: the block devices for the instance to be torn
2322                      down
2323         :param:requested_networks: the networks on which the instance
2324                                    has ports
2325         :param:notify: true if a final usage notification should be
2326                        emitted
2327         :param:try_deallocate_networks: false if we should avoid
2328                                         trying to teardown networking
2329         """
2330         context = context.elevated()
2331         LOG.info('Terminating instance', instance=instance)
2332 
2333         if notify:
2334             self._notify_about_instance_usage(context, instance,
2335                                               "shutdown.start")
2336             compute_utils.notify_about_instance_action(context, instance,
2337                     self.host, action=fields.NotificationAction.SHUTDOWN,
2338                     phase=fields.NotificationPhase.START, bdms=bdms)
2339 
2340         network_info = instance.get_network_info()
2341 
2342         # NOTE(vish) get bdms before destroying the instance
2343         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2344         block_device_info = self._get_instance_block_device_info(
2345             context, instance, bdms=bdms)
2346 
2347         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2348         #                want to keep ip allocated for certain failures
2349         try:
2350             LOG.debug('Start destroying the instance on the hypervisor.',
2351                       instance=instance)
2352             with timeutils.StopWatch() as timer:
2353                 self.driver.destroy(context, instance, network_info,
2354                                     block_device_info)
2355             LOG.info('Took %0.2f seconds to destroy the instance on the '
2356                      'hypervisor.', timer.elapsed(), instance=instance)
2357         except exception.InstancePowerOffFailure:
2358             # if the instance can't power off, don't release the ip
2359             with excutils.save_and_reraise_exception():
2360                 pass
2361         except Exception:
2362             with excutils.save_and_reraise_exception():
2363                 # deallocate ip and fail without proceeding to
2364                 # volume api calls, preserving current behavior
2365                 if try_deallocate_networks:
2366                     self._try_deallocate_network(context, instance,
2367                                                  requested_networks)
2368 
2369         if try_deallocate_networks:
2370             self._try_deallocate_network(context, instance, requested_networks)
2371 
2372         timer.restart()
2373         for bdm in vol_bdms:
2374             try:
2375                 if bdm.attachment_id:
2376                     self.volume_api.attachment_delete(context,
2377                                                       bdm.attachment_id)
2378                 else:
2379                     # NOTE(vish): actual driver detach done in driver.destroy,
2380                     #             so just tell cinder that we are done with it.
2381                     connector = self.driver.get_volume_connector(instance)
2382                     self.volume_api.terminate_connection(context,
2383                                                          bdm.volume_id,
2384                                                          connector)
2385                     self.volume_api.detach(context, bdm.volume_id,
2386                                            instance.uuid)
2387 
2388             except exception.VolumeAttachmentNotFound as exc:
2389                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2390                           instance=instance)
2391             except exception.DiskNotFound as exc:
2392                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2393                           instance=instance)
2394             except exception.VolumeNotFound as exc:
2395                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2396                           instance=instance)
2397             except (cinder_exception.EndpointNotFound,
2398                     keystone_exception.EndpointNotFound) as exc:
2399                 LOG.warning('Ignoring EndpointNotFound for '
2400                             'volume %(volume_id)s: %(exc)s',
2401                             {'exc': exc, 'volume_id': bdm.volume_id},
2402                             instance=instance)
2403             except cinder_exception.ClientException as exc:
2404                 LOG.warning('Ignoring unknown cinder exception for '
2405                             'volume %(volume_id)s: %(exc)s',
2406                             {'exc': exc, 'volume_id': bdm.volume_id},
2407                             instance=instance)
2408             except Exception as exc:
2409                 LOG.warning('Ignoring unknown exception for '
2410                             'volume %(volume_id)s: %(exc)s',
2411                             {'exc': exc, 'volume_id': bdm.volume_id},
2412                             instance=instance)
2413         if vol_bdms:
2414             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2415                      'for instance.',
2416                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2417                      instance=instance)
2418 
2419         if notify:
2420             self._notify_about_instance_usage(context, instance,
2421                                               "shutdown.end")
2422             compute_utils.notify_about_instance_action(context, instance,
2423                     self.host, action=fields.NotificationAction.SHUTDOWN,
2424                     phase=fields.NotificationPhase.END, bdms=bdms)
2425 
2426     def _cleanup_volumes(self, context, instance, bdms, raise_exc=True,
2427                          detach=True):
2428         exc_info = None
2429         for bdm in bdms:
2430             if detach and bdm.volume_id:
2431                 try:
2432                     LOG.debug("Detaching volume: %s", bdm.volume_id,
2433                               instance_uuid=instance.uuid)
2434                     destroy = bdm.delete_on_termination
2435                     self._detach_volume(context, bdm, instance,
2436                                         destroy_bdm=destroy)
2437                 except Exception as exc:
2438                     exc_info = sys.exc_info()
2439                     LOG.warning('Failed to detach volume: %(volume_id)s '
2440                                 'due to %(exc)s',
2441                                 {'volume_id': bdm.volume_id, 'exc': exc})
2442 
2443             if bdm.volume_id and bdm.delete_on_termination:
2444                 try:
2445                     LOG.debug("Deleting volume: %s", bdm.volume_id,
2446                               instance_uuid=instance.uuid)
2447                     self.volume_api.delete(context, bdm.volume_id)
2448                 except Exception as exc:
2449                     exc_info = sys.exc_info()
2450                     LOG.warning('Failed to delete volume: %(volume_id)s '
2451                                 'due to %(exc)s',
2452                                 {'volume_id': bdm.volume_id, 'exc': exc})
2453         if exc_info is not None and raise_exc:
2454             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2455 
2456     @hooks.add_hook("delete_instance")
2457     def _delete_instance(self, context, instance, bdms):
2458         """Delete an instance on this host.
2459 
2460         :param context: nova request context
2461         :param instance: nova.objects.instance.Instance object
2462         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2463         """
2464         events = self.instance_events.clear_events_for_instance(instance)
2465         if events:
2466             LOG.debug('Events pending at deletion: %(events)s',
2467                       {'events': ','.join(events.keys())},
2468                       instance=instance)
2469         self._notify_about_instance_usage(context, instance,
2470                                           "delete.start")
2471         compute_utils.notify_about_instance_action(context, instance,
2472                 self.host, action=fields.NotificationAction.DELETE,
2473                 phase=fields.NotificationPhase.START, bdms=bdms)
2474 
2475         self._shutdown_instance(context, instance, bdms)
2476         # NOTE(dims): instance.info_cache.delete() should be called after
2477         # _shutdown_instance in the compute manager as shutdown calls
2478         # deallocate_for_instance so the info_cache is still needed
2479         # at this point.
2480         if instance.info_cache is not None:
2481             instance.info_cache.delete()
2482         else:
2483             # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2484             # is None. When the root cause that instance.info_cache becomes
2485             # None is fixed, the log level should be reconsidered.
2486             LOG.warning("Info cache for instance could not be found. "
2487                         "Ignore.", instance=instance)
2488 
2489         # NOTE(vish): We have already deleted the instance, so we have
2490         #             to ignore problems cleaning up the volumes. It
2491         #             would be nice to let the user know somehow that
2492         #             the volume deletion failed, but it is not
2493         #             acceptable to have an instance that can not be
2494         #             deleted. Perhaps this could be reworked in the
2495         #             future to set an instance fault the first time
2496         #             and to only ignore the failure if the instance
2497         #             is already in ERROR.
2498 
2499         # NOTE(ameeda): The volumes already detached during the above
2500         #               _shutdown_instance() call and this is why
2501         #               detach is not requested from _cleanup_volumes()
2502         #               in this case
2503 
2504         self._cleanup_volumes(context, instance, bdms,
2505                 raise_exc=False, detach=False)
2506         # if a delete task succeeded, always update vm state and task
2507         # state without expecting task state to be DELETING
2508         instance.vm_state = vm_states.DELETED
2509         instance.task_state = None
2510         instance.power_state = power_state.NOSTATE
2511         instance.terminated_at = timeutils.utcnow()
2512         instance.save()
2513         system_meta = instance.system_metadata
2514         instance.destroy()
2515 
2516         self._complete_deletion(context,
2517                                 instance,
2518                                 bdms,
2519                                 system_meta)
2520 
2521     @wrap_exception()
2522     @reverts_task_state
2523     @wrap_instance_event(prefix='compute')
2524     @wrap_instance_fault
2525     def terminate_instance(self, context, instance, bdms):
2526         """Terminate an instance on this host."""
2527         @utils.synchronized(instance.uuid)
2528         def do_terminate_instance(instance, bdms):
2529             # NOTE(mriedem): If we are deleting the instance while it was
2530             # booting from volume, we could be racing with a database update of
2531             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2532             # to compute here, the BDMs may be stale at this point. So check
2533             # for any volume BDMs that don't have volume_id set and if we
2534             # detect that, we need to refresh the BDM list before proceeding.
2535             # TODO(mriedem): Move this into _delete_instance and make the bdms
2536             # parameter optional.
2537             for bdm in list(bdms):
2538                 if bdm.is_volume and not bdm.volume_id:
2539                     LOG.debug('There are potentially stale BDMs during '
2540                               'delete, refreshing the BlockDeviceMappingList.',
2541                               instance=instance)
2542                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2543                         context, instance.uuid)
2544                     break
2545             try:
2546                 self._delete_instance(context, instance, bdms)
2547             except exception.InstanceNotFound:
2548                 LOG.info("Instance disappeared during terminate",
2549                          instance=instance)
2550             except Exception:
2551                 # As we're trying to delete always go to Error if something
2552                 # goes wrong that _delete_instance can't handle.
2553                 with excutils.save_and_reraise_exception():
2554                     LOG.exception('Setting instance vm_state to ERROR',
2555                                   instance=instance)
2556                     self._set_instance_obj_error_state(context, instance)
2557 
2558         do_terminate_instance(instance, bdms)
2559 
2560     # NOTE(johannes): This is probably better named power_off_instance
2561     # so it matches the driver method, but because of other issues, we
2562     # can't use that name in grizzly.
2563     @wrap_exception()
2564     @reverts_task_state
2565     @wrap_instance_event(prefix='compute')
2566     @wrap_instance_fault
2567     def stop_instance(self, context, instance, clean_shutdown):
2568         """Stopping an instance on this host."""
2569 
2570         @utils.synchronized(instance.uuid)
2571         def do_stop_instance():
2572             current_power_state = self._get_power_state(context, instance)
2573             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2574                       'current task_state: %(task_state)s, current DB '
2575                       'power_state: %(db_power_state)s, current VM '
2576                       'power_state: %(current_power_state)s',
2577                       {'vm_state': instance.vm_state,
2578                        'task_state': instance.task_state,
2579                        'db_power_state': instance.power_state,
2580                        'current_power_state': current_power_state},
2581                       instance_uuid=instance.uuid)
2582 
2583             # NOTE(mriedem): If the instance is already powered off, we are
2584             # possibly tearing down and racing with other operations, so we can
2585             # expect the task_state to be None if something else updates the
2586             # instance and we're not locking it.
2587             expected_task_state = [task_states.POWERING_OFF]
2588             # The list of power states is from _sync_instance_power_state.
2589             if current_power_state in (power_state.NOSTATE,
2590                                        power_state.SHUTDOWN,
2591                                        power_state.CRASHED):
2592                 LOG.info('Instance is already powered off in the '
2593                          'hypervisor when stop is called.',
2594                          instance=instance)
2595                 expected_task_state.append(None)
2596 
2597             self._notify_about_instance_usage(context, instance,
2598                                               "power_off.start")
2599 
2600             compute_utils.notify_about_instance_action(context, instance,
2601                         self.host, action=fields.NotificationAction.POWER_OFF,
2602                         phase=fields.NotificationPhase.START)
2603 
2604             self._power_off_instance(context, instance, clean_shutdown)
2605             instance.power_state = self._get_power_state(context, instance)
2606             instance.vm_state = vm_states.STOPPED
2607             instance.task_state = None
2608             instance.save(expected_task_state=expected_task_state)
2609             self._notify_about_instance_usage(context, instance,
2610                                               "power_off.end")
2611 
2612             compute_utils.notify_about_instance_action(context, instance,
2613                         self.host, action=fields.NotificationAction.POWER_OFF,
2614                         phase=fields.NotificationPhase.END)
2615 
2616         do_stop_instance()
2617 
2618     def _power_on(self, context, instance):
2619         network_info = self.network_api.get_instance_nw_info(context, instance)
2620         block_device_info = self._get_instance_block_device_info(context,
2621                                                                  instance)
2622         self.driver.power_on(context, instance,
2623                              network_info,
2624                              block_device_info)
2625 
2626     def _delete_snapshot_of_shelved_instance(self, context, instance,
2627                                              snapshot_id):
2628         """Delete snapshot of shelved instance."""
2629         try:
2630             self.image_api.delete(context, snapshot_id)
2631         except (exception.ImageNotFound,
2632                 exception.ImageNotAuthorized) as exc:
2633             LOG.warning("Failed to delete snapshot "
2634                         "from shelved instance (%s).",
2635                         exc.format_message(), instance=instance)
2636         except Exception:
2637             LOG.exception("Something wrong happened when trying to "
2638                           "delete snapshot from shelved instance.",
2639                           instance=instance)
2640 
2641     # NOTE(johannes): This is probably better named power_on_instance
2642     # so it matches the driver method, but because of other issues, we
2643     # can't use that name in grizzly.
2644     @wrap_exception()
2645     @reverts_task_state
2646     @wrap_instance_event(prefix='compute')
2647     @wrap_instance_fault
2648     def start_instance(self, context, instance):
2649         """Starting an instance on this host."""
2650         self._notify_about_instance_usage(context, instance, "power_on.start")
2651         compute_utils.notify_about_instance_action(context, instance,
2652             self.host, action=fields.NotificationAction.POWER_ON,
2653             phase=fields.NotificationPhase.START)
2654         self._power_on(context, instance)
2655         instance.power_state = self._get_power_state(context, instance)
2656         instance.vm_state = vm_states.ACTIVE
2657         instance.task_state = None
2658 
2659         # Delete an image(VM snapshot) for a shelved instance
2660         snapshot_id = instance.system_metadata.get('shelved_image_id')
2661         if snapshot_id:
2662             self._delete_snapshot_of_shelved_instance(context, instance,
2663                                                       snapshot_id)
2664 
2665         # Delete system_metadata for a shelved instance
2666         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2667 
2668         instance.save(expected_task_state=task_states.POWERING_ON)
2669         self._notify_about_instance_usage(context, instance, "power_on.end")
2670         compute_utils.notify_about_instance_action(context, instance,
2671             self.host, action=fields.NotificationAction.POWER_ON,
2672             phase=fields.NotificationPhase.END)
2673 
2674     @messaging.expected_exceptions(NotImplementedError,
2675                                    exception.TriggerCrashDumpNotSupported,
2676                                    exception.InstanceNotRunning)
2677     @wrap_exception()
2678     @wrap_instance_event(prefix='compute')
2679     @wrap_instance_fault
2680     def trigger_crash_dump(self, context, instance):
2681         """Trigger crash dump in an instance."""
2682 
2683         self._notify_about_instance_usage(context, instance,
2684                                           "trigger_crash_dump.start")
2685         compute_utils.notify_about_instance_action(context, instance,
2686                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2687                 phase=fields.NotificationPhase.START)
2688 
2689         # This method does not change task_state and power_state because the
2690         # effect of a trigger depends on user's configuration.
2691         self.driver.trigger_crash_dump(instance)
2692 
2693         self._notify_about_instance_usage(context, instance,
2694                                           "trigger_crash_dump.end")
2695         compute_utils.notify_about_instance_action(context, instance,
2696                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2697                 phase=fields.NotificationPhase.END)
2698 
2699     @wrap_exception()
2700     @reverts_task_state
2701     @wrap_instance_event(prefix='compute')
2702     @wrap_instance_fault
2703     def soft_delete_instance(self, context, instance):
2704         """Soft delete an instance on this host."""
2705         with compute_utils.notify_about_instance_delete(
2706                 self.notifier, context, instance, 'soft_delete'):
2707             compute_utils.notify_about_instance_action(context, instance,
2708                 self.host, action=fields.NotificationAction.SOFT_DELETE,
2709                 phase=fields.NotificationPhase.START)
2710             try:
2711                 self.driver.soft_delete(instance)
2712             except NotImplementedError:
2713                 # Fallback to just powering off the instance if the
2714                 # hypervisor doesn't implement the soft_delete method
2715                 self.driver.power_off(instance)
2716             instance.power_state = self._get_power_state(context, instance)
2717             instance.vm_state = vm_states.SOFT_DELETED
2718             instance.task_state = None
2719             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2720             compute_utils.notify_about_instance_action(
2721                 context, instance, self.host,
2722                 action=fields.NotificationAction.SOFT_DELETE,
2723                 phase=fields.NotificationPhase.END)
2724 
2725     @wrap_exception()
2726     @reverts_task_state
2727     @wrap_instance_event(prefix='compute')
2728     @wrap_instance_fault
2729     def restore_instance(self, context, instance):
2730         """Restore a soft-deleted instance on this host."""
2731         self._notify_about_instance_usage(context, instance, "restore.start")
2732         compute_utils.notify_about_instance_action(context, instance,
2733             self.host, action=fields.NotificationAction.RESTORE,
2734             phase=fields.NotificationPhase.START)
2735         try:
2736             self.driver.restore(instance)
2737         except NotImplementedError:
2738             # Fallback to just powering on the instance if the hypervisor
2739             # doesn't implement the restore method
2740             self._power_on(context, instance)
2741         instance.power_state = self._get_power_state(context, instance)
2742         instance.vm_state = vm_states.ACTIVE
2743         instance.task_state = None
2744         instance.save(expected_task_state=task_states.RESTORING)
2745         self._notify_about_instance_usage(context, instance, "restore.end")
2746         compute_utils.notify_about_instance_action(context, instance,
2747             self.host, action=fields.NotificationAction.RESTORE,
2748             phase=fields.NotificationPhase.END)
2749 
2750     @staticmethod
2751     def _set_migration_status(migration, status):
2752         """Set the status, and guard against a None being passed in.
2753 
2754         This is useful as some of the compute RPC calls will not pass
2755         a migration object in older versions. The check can be removed when
2756         we move past 4.x major version of the RPC API.
2757         """
2758         if migration:
2759             migration.status = status
2760             migration.save()
2761 
2762     def _rebuild_default_impl(self, context, instance, image_meta,
2763                               injected_files, admin_password, allocations,
2764                               bdms, detach_block_devices, attach_block_devices,
2765                               network_info=None,
2766                               recreate=False, block_device_info=None,
2767                               preserve_ephemeral=False):
2768         if preserve_ephemeral:
2769             # The default code path does not support preserving ephemeral
2770             # partitions.
2771             raise exception.PreserveEphemeralNotSupported()
2772 
2773         if recreate:
2774             detach_block_devices(context, bdms)
2775         else:
2776             self._power_off_instance(context, instance, clean_shutdown=True)
2777             detach_block_devices(context, bdms)
2778             self.driver.destroy(context, instance,
2779                                 network_info=network_info,
2780                                 block_device_info=block_device_info)
2781 
2782         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2783         instance.save(expected_task_state=[task_states.REBUILDING])
2784 
2785         new_block_device_info = attach_block_devices(context, instance, bdms)
2786 
2787         instance.task_state = task_states.REBUILD_SPAWNING
2788         instance.save(
2789             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2790 
2791         with instance.mutated_migration_context():
2792             self.driver.spawn(context, instance, image_meta, injected_files,
2793                               admin_password, allocations,
2794                               network_info=network_info,
2795                               block_device_info=new_block_device_info)
2796 
2797     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
2798         self._notify_about_instance_usage(context, instance,
2799                                           'rebuild.error', fault=error)
2800         compute_utils.notify_about_instance_action(
2801             context, instance, self.host,
2802             action=fields.NotificationAction.REBUILD,
2803             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms)
2804 
2805     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2806     @wrap_exception()
2807     @reverts_task_state
2808     @wrap_instance_event(prefix='compute')
2809     @wrap_instance_fault
2810     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2811                          injected_files, new_pass, orig_sys_metadata,
2812                          bdms, recreate, on_shared_storage,
2813                          preserve_ephemeral, migration,
2814                          scheduled_node, limits, request_spec):
2815         """Destroy and re-make this instance.
2816 
2817         A 'rebuild' effectively purges all existing data from the system and
2818         remakes the VM with given 'metadata' and 'personalities'.
2819 
2820         :param context: `nova.RequestContext` object
2821         :param instance: Instance object
2822         :param orig_image_ref: Original image_ref before rebuild
2823         :param image_ref: New image_ref for rebuild
2824         :param injected_files: Files to inject
2825         :param new_pass: password to set on rebuilt instance
2826         :param orig_sys_metadata: instance system metadata from pre-rebuild
2827         :param bdms: block-device-mappings to use for rebuild
2828         :param recreate: True if the instance is being recreated (e.g. the
2829             hypervisor it was on failed) - cleanup of old state will be
2830             skipped.
2831         :param on_shared_storage: True if instance files on shared storage.
2832                                   If not provided then information from the
2833                                   driver will be used to decide if the instance
2834                                   files are available or not on the target host
2835         :param preserve_ephemeral: True if the default ephemeral storage
2836                                    partition must be preserved on rebuild
2837         :param migration: a Migration object if one was created for this
2838                           rebuild operation (if it's a part of evacuate)
2839         :param scheduled_node: A node of the host chosen by the scheduler. If a
2840                                host was specified by the user, this will be
2841                                None
2842         :param limits: Overcommit limits set by the scheduler. If a host was
2843                        specified by the user, this will be None
2844         :param request_spec: a RequestSpec object used to schedule the instance
2845 
2846         """
2847         # recreate=True means the instance is being evacuated from a failed
2848         # host to a new destination host (this host). The 'recreate' variable
2849         # name is confusing, so rename it to evacuate here at the top, which
2850         # is simpler than renaming a parameter in an RPC versioned method.
2851         evacuate = recreate
2852         context = context.elevated()
2853 
2854         if evacuate:
2855             LOG.info("Evacuating instance", instance=instance)
2856         else:
2857             LOG.info("Rebuilding instance", instance=instance)
2858 
2859         rt = self._get_resource_tracker()
2860         if evacuate:
2861             # This is an evacuation to a new host, so we need to perform a
2862             # resource claim.
2863             rebuild_claim = rt.rebuild_claim
2864         else:
2865             # This is a rebuild to the same host, so we don't need to make
2866             # a claim since the instance is already on this host.
2867             rebuild_claim = claims.NopClaim
2868 
2869         image_meta = {}
2870         if image_ref:
2871             image_meta = self.image_api.get(context, image_ref)
2872 
2873         # NOTE(mriedem): On an evacuate, we need to update
2874         # the instance's host and node properties to reflect it's
2875         # destination node for the evacuate.
2876         if not scheduled_node:
2877             if evacuate:
2878                 try:
2879                     compute_node = self._get_compute_info(context, self.host)
2880                     scheduled_node = compute_node.hypervisor_hostname
2881                 except exception.ComputeHostNotFound:
2882                     LOG.exception('Failed to get compute_info for %s',
2883                                   self.host)
2884             else:
2885                 scheduled_node = instance.node
2886 
2887         with self._error_out_instance_on_exception(context, instance):
2888             try:
2889                 claim_ctxt = rebuild_claim(
2890                     context, instance, scheduled_node,
2891                     limits=limits, image_meta=image_meta,
2892                     migration=migration)
2893                 self._do_rebuild_instance_with_claim(
2894                     claim_ctxt, context, instance, orig_image_ref,
2895                     image_ref, injected_files, new_pass, orig_sys_metadata,
2896                     bdms, evacuate, on_shared_storage, preserve_ephemeral,
2897                     migration, request_spec)
2898             except (exception.ComputeResourcesUnavailable,
2899                     exception.RescheduledException) as e:
2900                 if isinstance(e, exception.ComputeResourcesUnavailable):
2901                     LOG.debug("Could not rebuild instance on this host, not "
2902                               "enough resources available.", instance=instance)
2903                 else:
2904                     # RescheduledException is raised by the late server group
2905                     # policy check during evacuation if a parallel scheduling
2906                     # violated the policy.
2907                     # We catch the RescheduledException here but we don't have
2908                     # the plumbing to do an actual reschedule so we abort the
2909                     # operation.
2910                     LOG.debug("Could not rebuild instance on this host, "
2911                               "late server group check failed.",
2912                               instance=instance)
2913                 # NOTE(ndipanov): We just abort the build for now and leave a
2914                 # migration record for potential cleanup later
2915                 self._set_migration_status(migration, 'failed')
2916                 # Since the claim failed, we need to remove the allocation
2917                 # created against the destination node. Note that we can only
2918                 # get here when evacuating to a destination node. Rebuilding
2919                 # on the same host (not evacuate) uses the NopClaim which will
2920                 # not raise ComputeResourcesUnavailable.
2921                 rt.delete_allocation_for_evacuated_instance(
2922                     context, instance, scheduled_node, node_type='destination')
2923                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2924                 raise exception.BuildAbortException(
2925                     instance_uuid=instance.uuid, reason=e.format_message())
2926             except (exception.InstanceNotFound,
2927                     exception.UnexpectedDeletingTaskStateError) as e:
2928                 LOG.debug('Instance was deleted while rebuilding',
2929                           instance=instance)
2930                 self._set_migration_status(migration, 'failed')
2931                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2932             except Exception as e:
2933                 self._set_migration_status(migration, 'failed')
2934                 if evacuate or scheduled_node is not None:
2935                     rt.delete_allocation_for_evacuated_instance(
2936                         context, instance, scheduled_node,
2937                         node_type='destination')
2938                 self._notify_instance_rebuild_error(context, instance, e, bdms)
2939                 raise
2940             else:
2941                 instance.apply_migration_context()
2942                 # NOTE (ndipanov): This save will now update the host and node
2943                 # attributes making sure that next RT pass is consistent since
2944                 # it will be based on the instance and not the migration DB
2945                 # entry.
2946                 instance.host = self.host
2947                 instance.node = scheduled_node
2948                 instance.save()
2949                 instance.drop_migration_context()
2950 
2951                 # NOTE (ndipanov): Mark the migration as done only after we
2952                 # mark the instance as belonging to this host.
2953                 self._set_migration_status(migration, 'done')
2954 
2955     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2956         """Helper to avoid deep nesting in the top-level method."""
2957 
2958         with claim_context:
2959             self._do_rebuild_instance(*args, **kwargs)
2960 
2961     @staticmethod
2962     def _get_image_name(image_meta):
2963         if image_meta.obj_attr_is_set("name"):
2964             return image_meta.name
2965         else:
2966             return ''
2967 
2968     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2969                              image_ref, injected_files, new_pass,
2970                              orig_sys_metadata, bdms, evacuate,
2971                              on_shared_storage, preserve_ephemeral,
2972                              migration, request_spec):
2973         orig_vm_state = instance.vm_state
2974 
2975         if evacuate:
2976             if request_spec:
2977                 # NOTE(gibi): Do a late check of server group policy as
2978                 # parallel scheduling could violate such policy. This will
2979                 # cause the evacuate to fail as rebuild does not implement
2980                 # reschedule.
2981                 hints = self._get_scheduler_hints({}, request_spec)
2982                 self._validate_instance_group_policy(context, instance, hints)
2983 
2984             # TODO(mriedem): Rename the supports_recreate driver capability
2985             # to supports_evacuate.
2986             if not self.driver.capabilities.get("supports_recreate", False):
2987                 raise exception.InstanceRecreateNotSupported
2988 
2989             self._check_instance_exists(context, instance)
2990 
2991             if on_shared_storage is None:
2992                 LOG.debug('on_shared_storage is not provided, using driver '
2993                           'information to decide if the instance needs to '
2994                           'be evacuated')
2995                 on_shared_storage = self.driver.instance_on_disk(instance)
2996 
2997             elif (on_shared_storage !=
2998                     self.driver.instance_on_disk(instance)):
2999                 # To cover case when admin expects that instance files are
3000                 # on shared storage, but not accessible and vice versa
3001                 raise exception.InvalidSharedStorage(
3002                         _("Invalid state of instance files on shared"
3003                             " storage"))
3004 
3005             if on_shared_storage:
3006                 LOG.info('disk on shared storage, evacuating using'
3007                          ' existing disk')
3008             else:
3009                 image_ref = orig_image_ref = instance.image_ref
3010                 LOG.info("disk not on shared storage, evacuating from:"
3011                          " '%s'", str(image_ref))
3012 
3013         if image_ref:
3014             image_meta = objects.ImageMeta.from_image_ref(
3015                 context, self.image_api, image_ref)
3016         else:
3017             image_meta = instance.image_meta
3018 
3019         # This instance.exists message should contain the original
3020         # image_ref, not the new one.  Since the DB has been updated
3021         # to point to the new one... we have to override it.
3022         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
3023                                                                context)
3024         extra_usage_info = {'image_ref_url': orig_image_ref_url}
3025         compute_utils.notify_usage_exists(
3026                 self.notifier, context, instance,
3027                 current_period=True, system_metadata=orig_sys_metadata,
3028                 extra_usage_info=extra_usage_info)
3029 
3030         # This message should contain the new image_ref
3031         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
3032         self._notify_about_instance_usage(context, instance,
3033                 "rebuild.start", extra_usage_info=extra_usage_info)
3034         # NOTE: image_name is not included in the versioned notification
3035         # because we already provide the image_uuid in the notification
3036         # payload and the image details can be looked up via the uuid.
3037         compute_utils.notify_about_instance_action(
3038             context, instance, self.host,
3039             action=fields.NotificationAction.REBUILD,
3040             phase=fields.NotificationPhase.START,
3041             bdms=bdms)
3042 
3043         instance.power_state = self._get_power_state(context, instance)
3044         instance.task_state = task_states.REBUILDING
3045         instance.save(expected_task_state=[task_states.REBUILDING])
3046 
3047         if evacuate:
3048             self.network_api.setup_networks_on_host(
3049                     context, instance, self.host)
3050             # For nova-network this is needed to move floating IPs
3051             # For neutron this updates the host in the port binding
3052             # TODO(cfriesen): this network_api call and the one above
3053             # are so similar, we should really try to unify them.
3054             self.network_api.setup_instance_network_on_host(
3055                     context, instance, self.host, migration)
3056 
3057         allocations = self.reportclient.get_allocations_for_consumer(
3058             context, instance.uuid)
3059 
3060         network_info = instance.get_network_info()
3061         if bdms is None:
3062             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3063                     context, instance.uuid)
3064 
3065         block_device_info = \
3066             self._get_instance_block_device_info(
3067                     context, instance, bdms=bdms)
3068 
3069         def detach_block_devices(context, bdms):
3070             for bdm in bdms:
3071                 if bdm.is_volume:
3072                     # NOTE (ildikov): Having the attachment_id set in the BDM
3073                     # means that it's the new Cinder attach/detach flow
3074                     # (available from v3.44). In that case we explicitly
3075                     # attach and detach the volumes through attachment level
3076                     # operations. In this scenario _detach_volume will delete
3077                     # the existing attachment which would make the volume
3078                     # status change to 'available' if we don't pre-create
3079                     # another empty attachment before deleting the old one.
3080                     attachment_id = None
3081                     if bdm.attachment_id:
3082                         attachment_id = self.volume_api.attachment_create(
3083                             context, bdm['volume_id'], instance.uuid)['id']
3084                     self._detach_volume(context, bdm, instance,
3085                                         destroy_bdm=False)
3086                     if attachment_id:
3087                         bdm.attachment_id = attachment_id
3088                         bdm.save()
3089 
3090         files = self._decode_files(injected_files)
3091 
3092         # TODO(mriedem): Rename recreate->evacuate in the driver rebuild
3093         # method signature.
3094         kwargs = dict(
3095             context=context,
3096             instance=instance,
3097             image_meta=image_meta,
3098             injected_files=files,
3099             admin_password=new_pass,
3100             allocations=allocations,
3101             bdms=bdms,
3102             detach_block_devices=detach_block_devices,
3103             attach_block_devices=self._prep_block_device,
3104             block_device_info=block_device_info,
3105             network_info=network_info,
3106             preserve_ephemeral=preserve_ephemeral,
3107             recreate=evacuate)
3108         try:
3109             with instance.mutated_migration_context():
3110                 self.driver.rebuild(**kwargs)
3111         except NotImplementedError:
3112             # NOTE(rpodolyaka): driver doesn't provide specialized version
3113             # of rebuild, fall back to the default implementation
3114             self._rebuild_default_impl(**kwargs)
3115         self._update_instance_after_spawn(context, instance)
3116         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3117 
3118         if orig_vm_state == vm_states.STOPPED:
3119             LOG.info("bringing vm to original state: '%s'",
3120                      orig_vm_state, instance=instance)
3121             instance.vm_state = vm_states.ACTIVE
3122             instance.task_state = task_states.POWERING_OFF
3123             instance.progress = 0
3124             instance.save()
3125             self.stop_instance(context, instance, False)
3126         self._update_scheduler_instance_info(context, instance)
3127         self._notify_about_instance_usage(
3128                 context, instance, "rebuild.end",
3129                 network_info=network_info,
3130                 extra_usage_info=extra_usage_info)
3131         compute_utils.notify_about_instance_action(
3132             context, instance, self.host,
3133             action=fields.NotificationAction.REBUILD,
3134             phase=fields.NotificationPhase.END,
3135             bdms=bdms)
3136 
3137     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3138                                      block_device_info):
3139         """Handle cases where the virt-layer had to detach non-working volumes
3140         in order to complete an operation.
3141         """
3142         for bdm in block_device_info['block_device_mapping']:
3143             if bdm.get('mount_device') in bad_devices:
3144                 try:
3145                     volume_id = bdm['connection_info']['data']['volume_id']
3146                 except KeyError:
3147                     continue
3148 
3149                 # NOTE(sirp): ideally we'd just call
3150                 # `compute_api.detach_volume` here but since that hits the
3151                 # DB directly, that's off limits from within the
3152                 # compute-manager.
3153                 #
3154                 # API-detach
3155                 LOG.info("Detaching from volume api: %s", volume_id)
3156                 self.volume_api.begin_detaching(context, volume_id)
3157 
3158                 # Manager-detach
3159                 self.detach_volume(context, volume_id, instance)
3160 
3161     @wrap_exception()
3162     @reverts_task_state
3163     @wrap_instance_event(prefix='compute')
3164     @wrap_instance_fault
3165     def reboot_instance(self, context, instance, block_device_info,
3166                         reboot_type):
3167         """Reboot an instance on this host."""
3168         # acknowledge the request made it to the manager
3169         if reboot_type == "SOFT":
3170             instance.task_state = task_states.REBOOT_PENDING
3171             expected_states = task_states.soft_reboot_states
3172         else:
3173             instance.task_state = task_states.REBOOT_PENDING_HARD
3174             expected_states = task_states.hard_reboot_states
3175 
3176         context = context.elevated()
3177         LOG.info("Rebooting instance", instance=instance)
3178 
3179         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3180             context, instance.uuid)
3181         block_device_info = self._get_instance_block_device_info(
3182             context, instance, bdms=bdms)
3183 
3184         network_info = self.network_api.get_instance_nw_info(context, instance)
3185 
3186         self._notify_about_instance_usage(context, instance, "reboot.start")
3187         compute_utils.notify_about_instance_action(
3188             context, instance, self.host,
3189             action=fields.NotificationAction.REBOOT,
3190             phase=fields.NotificationPhase.START,
3191             bdms=bdms
3192         )
3193 
3194         instance.power_state = self._get_power_state(context, instance)
3195         instance.save(expected_task_state=expected_states)
3196 
3197         if instance.power_state != power_state.RUNNING:
3198             state = instance.power_state
3199             running = power_state.RUNNING
3200             LOG.warning('trying to reboot a non-running instance:'
3201                         ' (state: %(state)s expected: %(running)s)',
3202                         {'state': state, 'running': running},
3203                         instance=instance)
3204 
3205         def bad_volumes_callback(bad_devices):
3206             self._handle_bad_volumes_detached(
3207                     context, instance, bad_devices, block_device_info)
3208 
3209         try:
3210             # Don't change it out of rescue mode
3211             if instance.vm_state == vm_states.RESCUED:
3212                 new_vm_state = vm_states.RESCUED
3213             else:
3214                 new_vm_state = vm_states.ACTIVE
3215             new_power_state = None
3216             if reboot_type == "SOFT":
3217                 instance.task_state = task_states.REBOOT_STARTED
3218                 expected_state = task_states.REBOOT_PENDING
3219             else:
3220                 instance.task_state = task_states.REBOOT_STARTED_HARD
3221                 expected_state = task_states.REBOOT_PENDING_HARD
3222             instance.save(expected_task_state=expected_state)
3223             self.driver.reboot(context, instance,
3224                                network_info,
3225                                reboot_type,
3226                                block_device_info=block_device_info,
3227                                bad_volumes_callback=bad_volumes_callback)
3228 
3229         except Exception as error:
3230             with excutils.save_and_reraise_exception() as ctxt:
3231                 exc_info = sys.exc_info()
3232                 # if the reboot failed but the VM is running don't
3233                 # put it into an error state
3234                 new_power_state = self._get_power_state(context, instance)
3235                 if new_power_state == power_state.RUNNING:
3236                     LOG.warning('Reboot failed but instance is running',
3237                                 instance=instance)
3238                     compute_utils.add_instance_fault_from_exc(context,
3239                             instance, error, exc_info)
3240                     self._notify_about_instance_usage(context, instance,
3241                             'reboot.error', fault=error)
3242                     compute_utils.notify_about_instance_action(
3243                         context, instance, self.host,
3244                         action=fields.NotificationAction.REBOOT,
3245                         phase=fields.NotificationPhase.ERROR,
3246                         exception=error, bdms=bdms
3247                     )
3248                     ctxt.reraise = False
3249                 else:
3250                     LOG.error('Cannot reboot instance: %s', error,
3251                               instance=instance)
3252                     self._set_instance_obj_error_state(context, instance)
3253 
3254         if not new_power_state:
3255             new_power_state = self._get_power_state(context, instance)
3256         try:
3257             instance.power_state = new_power_state
3258             instance.vm_state = new_vm_state
3259             instance.task_state = None
3260             instance.save()
3261         except exception.InstanceNotFound:
3262             LOG.warning("Instance disappeared during reboot",
3263                         instance=instance)
3264 
3265         self._notify_about_instance_usage(context, instance, "reboot.end")
3266         compute_utils.notify_about_instance_action(
3267             context, instance, self.host,
3268             action=fields.NotificationAction.REBOOT,
3269             phase=fields.NotificationPhase.END,
3270             bdms=bdms
3271         )
3272 
3273     @delete_image_on_error
3274     def _do_snapshot_instance(self, context, image_id, instance):
3275         self._snapshot_instance(context, image_id, instance,
3276                                 task_states.IMAGE_BACKUP)
3277 
3278     @wrap_exception()
3279     @reverts_task_state
3280     @wrap_instance_event(prefix='compute')
3281     @wrap_instance_fault
3282     def backup_instance(self, context, image_id, instance, backup_type,
3283                         rotation):
3284         """Backup an instance on this host.
3285 
3286         :param backup_type: daily | weekly
3287         :param rotation: int representing how many backups to keep around
3288         """
3289         self._do_snapshot_instance(context, image_id, instance)
3290         self._rotate_backups(context, instance, backup_type, rotation)
3291 
3292     @wrap_exception()
3293     @reverts_task_state
3294     @wrap_instance_event(prefix='compute')
3295     @wrap_instance_fault
3296     @delete_image_on_error
3297     def snapshot_instance(self, context, image_id, instance):
3298         """Snapshot an instance on this host.
3299 
3300         :param context: security context
3301         :param image_id: glance.db.sqlalchemy.models.Image.Id
3302         :param instance: a nova.objects.instance.Instance object
3303         """
3304         # NOTE(dave-mcnally) the task state will already be set by the api
3305         # but if the compute manager has crashed/been restarted prior to the
3306         # request getting here the task state may have been cleared so we set
3307         # it again and things continue normally
3308         try:
3309             instance.task_state = task_states.IMAGE_SNAPSHOT
3310             instance.save(
3311                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3312         except exception.InstanceNotFound:
3313             # possibility instance no longer exists, no point in continuing
3314             LOG.debug("Instance not found, could not set state %s "
3315                       "for instance.",
3316                       task_states.IMAGE_SNAPSHOT, instance=instance)
3317             return
3318 
3319         except exception.UnexpectedDeletingTaskStateError:
3320             LOG.debug("Instance being deleted, snapshot cannot continue",
3321                       instance=instance)
3322             return
3323 
3324         self._snapshot_instance(context, image_id, instance,
3325                                 task_states.IMAGE_SNAPSHOT)
3326 
3327     def _snapshot_instance(self, context, image_id, instance,
3328                            expected_task_state):
3329         context = context.elevated()
3330 
3331         instance.power_state = self._get_power_state(context, instance)
3332         try:
3333             instance.save()
3334 
3335             LOG.info('instance snapshotting', instance=instance)
3336 
3337             if instance.power_state != power_state.RUNNING:
3338                 state = instance.power_state
3339                 running = power_state.RUNNING
3340                 LOG.warning('trying to snapshot a non-running instance: '
3341                             '(state: %(state)s expected: %(running)s)',
3342                             {'state': state, 'running': running},
3343                             instance=instance)
3344 
3345             self._notify_about_instance_usage(
3346                 context, instance, "snapshot.start")
3347             compute_utils.notify_about_instance_snapshot(context, instance,
3348                 self.host, phase=fields.NotificationPhase.START,
3349                 snapshot_image_id=image_id)
3350 
3351             def update_task_state(task_state,
3352                                   expected_state=expected_task_state):
3353                 instance.task_state = task_state
3354                 instance.save(expected_task_state=expected_state)
3355 
3356             with timeutils.StopWatch() as timer:
3357                 self.driver.snapshot(context, instance, image_id,
3358                                      update_task_state)
3359             LOG.info('Took %0.2f seconds to snapshot the instance on '
3360                      'the hypervisor.', timer.elapsed(), instance=instance)
3361 
3362             instance.task_state = None
3363             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3364 
3365             self._notify_about_instance_usage(context, instance,
3366                                               "snapshot.end")
3367             compute_utils.notify_about_instance_snapshot(context, instance,
3368                 self.host, phase=fields.NotificationPhase.END,
3369                 snapshot_image_id=image_id)
3370         except (exception.InstanceNotFound,
3371                 exception.UnexpectedDeletingTaskStateError):
3372             # the instance got deleted during the snapshot
3373             # Quickly bail out of here
3374             msg = 'Instance disappeared during snapshot'
3375             LOG.debug(msg, instance=instance)
3376             try:
3377                 image = self.image_api.get(context, image_id)
3378                 if image['status'] != 'active':
3379                     self.image_api.delete(context, image_id)
3380             except Exception:
3381                 LOG.warning("Error while trying to clean up image %s",
3382                             image_id, instance=instance)
3383         except exception.ImageNotFound:
3384             instance.task_state = None
3385             instance.save()
3386             LOG.warning("Image not found during snapshot", instance=instance)
3387 
3388     def _post_interrupted_snapshot_cleanup(self, context, instance):
3389         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3390 
3391     @messaging.expected_exceptions(NotImplementedError)
3392     @wrap_exception()
3393     def volume_snapshot_create(self, context, instance, volume_id,
3394                                create_info):
3395         self.driver.volume_snapshot_create(context, instance, volume_id,
3396                                            create_info)
3397 
3398     @messaging.expected_exceptions(NotImplementedError)
3399     @wrap_exception()
3400     def volume_snapshot_delete(self, context, instance, volume_id,
3401                                snapshot_id, delete_info):
3402         self.driver.volume_snapshot_delete(context, instance, volume_id,
3403                                            snapshot_id, delete_info)
3404 
3405     @wrap_instance_fault
3406     def _rotate_backups(self, context, instance, backup_type, rotation):
3407         """Delete excess backups associated to an instance.
3408 
3409         Instances are allowed a fixed number of backups (the rotation number);
3410         this method deletes the oldest backups that exceed the rotation
3411         threshold.
3412 
3413         :param context: security context
3414         :param instance: Instance dict
3415         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3416         :param rotation: int representing how many backups to keep around;
3417             None if rotation shouldn't be used (as in the case of snapshots)
3418         """
3419         filters = {'property-image_type': 'backup',
3420                    'property-backup_type': backup_type,
3421                    'property-instance_uuid': instance.uuid}
3422 
3423         images = self.image_api.get_all(context, filters=filters,
3424                                         sort_key='created_at', sort_dir='desc')
3425         num_images = len(images)
3426         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3427                   {'num_images': num_images, 'rotation': rotation},
3428                   instance=instance)
3429 
3430         if num_images > rotation:
3431             # NOTE(sirp): this deletes all backups that exceed the rotation
3432             # limit
3433             excess = len(images) - rotation
3434             LOG.debug("Rotating out %d backups", excess,
3435                       instance=instance)
3436             for i in range(excess):
3437                 image = images.pop()
3438                 image_id = image['id']
3439                 LOG.debug("Deleting image %s", image_id,
3440                           instance=instance)
3441                 try:
3442                     self.image_api.delete(context, image_id)
3443                 except exception.ImageNotFound:
3444                     LOG.info("Failed to find image %(image_id)s to "
3445                              "delete", {'image_id': image_id},
3446                              instance=instance)
3447                 except (exception.ImageDeleteConflict, Exception) as exc:
3448                     LOG.info("Failed to delete image %(image_id)s during "
3449                              "deleting excess backups. "
3450                              "Continuing for next image.. %(exc)s",
3451                              {'image_id': image_id, 'exc': exc},
3452                              instance=instance)
3453 
3454     @wrap_exception()
3455     @reverts_task_state
3456     @wrap_instance_event(prefix='compute')
3457     @wrap_instance_fault
3458     def set_admin_password(self, context, instance, new_pass):
3459         """Set the root/admin password for an instance on this host.
3460 
3461         This is generally only called by API password resets after an
3462         image has been built.
3463 
3464         @param context: Nova auth context.
3465         @param instance: Nova instance object.
3466         @param new_pass: The admin password for the instance.
3467         """
3468 
3469         context = context.elevated()
3470         if new_pass is None:
3471             # Generate a random password
3472             new_pass = utils.generate_password()
3473 
3474         current_power_state = self._get_power_state(context, instance)
3475         expected_state = power_state.RUNNING
3476 
3477         if current_power_state != expected_state:
3478             instance.task_state = None
3479             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3480             _msg = _('instance %s is not running') % instance.uuid
3481             raise exception.InstancePasswordSetFailed(
3482                 instance=instance.uuid, reason=_msg)
3483 
3484         try:
3485             self.driver.set_admin_password(instance, new_pass)
3486             LOG.info("Admin password set", instance=instance)
3487             instance.task_state = None
3488             instance.save(
3489                 expected_task_state=task_states.UPDATING_PASSWORD)
3490         except exception.InstanceAgentNotEnabled:
3491             with excutils.save_and_reraise_exception():
3492                 LOG.debug('Guest agent is not enabled for the instance.',
3493                           instance=instance)
3494                 instance.task_state = None
3495                 instance.save(
3496                     expected_task_state=task_states.UPDATING_PASSWORD)
3497         except exception.SetAdminPasswdNotSupported:
3498             with excutils.save_and_reraise_exception():
3499                 LOG.info('set_admin_password is not supported '
3500                          'by this driver or guest instance.',
3501                          instance=instance)
3502                 instance.task_state = None
3503                 instance.save(
3504                     expected_task_state=task_states.UPDATING_PASSWORD)
3505         except NotImplementedError:
3506             LOG.warning('set_admin_password is not implemented '
3507                         'by this driver or guest instance.',
3508                         instance=instance)
3509             instance.task_state = None
3510             instance.save(
3511                 expected_task_state=task_states.UPDATING_PASSWORD)
3512             raise NotImplementedError(_('set_admin_password is not '
3513                                         'implemented by this driver or guest '
3514                                         'instance.'))
3515         except exception.UnexpectedTaskStateError:
3516             # interrupted by another (most likely delete) task
3517             # do not retry
3518             raise
3519         except Exception:
3520             # Catch all here because this could be anything.
3521             LOG.exception('set_admin_password failed', instance=instance)
3522             instance.task_state = None
3523             instance.save(
3524                 expected_task_state=task_states.UPDATING_PASSWORD)
3525             # We create a new exception here so that we won't
3526             # potentially reveal password information to the
3527             # API caller.  The real exception is logged above
3528             _msg = _('error setting admin password')
3529             raise exception.InstancePasswordSetFailed(
3530                 instance=instance.uuid, reason=_msg)
3531 
3532     @wrap_exception()
3533     @reverts_task_state
3534     @wrap_instance_fault
3535     def inject_file(self, context, path, file_contents, instance):
3536         """Write a file to the specified path in an instance on this host."""
3537         # NOTE(russellb) Remove this method, as well as the underlying virt
3538         # driver methods, when the compute rpc interface is bumped to 4.x
3539         # as it is no longer used.
3540         context = context.elevated()
3541         current_power_state = self._get_power_state(context, instance)
3542         expected_state = power_state.RUNNING
3543         if current_power_state != expected_state:
3544             LOG.warning('trying to inject a file into a non-running '
3545                         '(state: %(current_state)s expected: '
3546                         '%(expected_state)s)',
3547                         {'current_state': current_power_state,
3548                          'expected_state': expected_state},
3549                         instance=instance)
3550         LOG.info('injecting file to %s', path, instance=instance)
3551         self.driver.inject_file(instance, path, file_contents)
3552 
3553     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3554         """Determine what image should be used to boot the rescue VM."""
3555         # 1. If rescue_image_ref is passed in, use that for rescue.
3556         # 2. Else, use the base image associated with instance's current image.
3557         #       The idea here is to provide the customer with a rescue
3558         #       environment which they are familiar with.
3559         #       So, if they built their instance off of a Debian image,
3560         #       their rescue VM will also be Debian.
3561         # 3. As a last resort, use instance's current image.
3562         if not rescue_image_ref:
3563             system_meta = utils.instance_sys_meta(instance)
3564             rescue_image_ref = system_meta.get('image_base_image_ref')
3565 
3566         if not rescue_image_ref:
3567             LOG.warning('Unable to find a different image to use for '
3568                         'rescue VM, using instance\'s current image',
3569                         instance=instance)
3570             rescue_image_ref = instance.image_ref
3571 
3572         return objects.ImageMeta.from_image_ref(
3573             context, self.image_api, rescue_image_ref)
3574 
3575     @wrap_exception()
3576     @reverts_task_state
3577     @wrap_instance_event(prefix='compute')
3578     @wrap_instance_fault
3579     def rescue_instance(self, context, instance, rescue_password,
3580                         rescue_image_ref, clean_shutdown):
3581         context = context.elevated()
3582         LOG.info('Rescuing', instance=instance)
3583 
3584         admin_password = (rescue_password if rescue_password else
3585                       utils.generate_password())
3586 
3587         network_info = self.network_api.get_instance_nw_info(context, instance)
3588 
3589         rescue_image_meta = self._get_rescue_image(context, instance,
3590                                                    rescue_image_ref)
3591 
3592         extra_usage_info = {'rescue_image_name':
3593                             self._get_image_name(rescue_image_meta)}
3594         self._notify_about_instance_usage(context, instance,
3595                 "rescue.start", extra_usage_info=extra_usage_info,
3596                 network_info=network_info)
3597         compute_utils.notify_about_instance_rescue_action(
3598             context, instance, self.host, rescue_image_ref,
3599             phase=fields.NotificationPhase.START)
3600 
3601         try:
3602             self._power_off_instance(context, instance, clean_shutdown)
3603 
3604             self.driver.rescue(context, instance,
3605                                network_info,
3606                                rescue_image_meta, admin_password)
3607         except Exception as e:
3608             LOG.exception("Error trying to Rescue Instance",
3609                           instance=instance)
3610             self._set_instance_obj_error_state(context, instance)
3611             raise exception.InstanceNotRescuable(
3612                 instance_id=instance.uuid,
3613                 reason=_("Driver Error: %s") % e)
3614 
3615         compute_utils.notify_usage_exists(self.notifier, context, instance,
3616                                           current_period=True)
3617 
3618         instance.vm_state = vm_states.RESCUED
3619         instance.task_state = None
3620         instance.power_state = self._get_power_state(context, instance)
3621         instance.launched_at = timeutils.utcnow()
3622         instance.save(expected_task_state=task_states.RESCUING)
3623 
3624         self._notify_about_instance_usage(context, instance,
3625                 "rescue.end", extra_usage_info=extra_usage_info,
3626                 network_info=network_info)
3627         compute_utils.notify_about_instance_rescue_action(
3628             context, instance, self.host, rescue_image_ref,
3629             phase=fields.NotificationPhase.END)
3630 
3631     @wrap_exception()
3632     @reverts_task_state
3633     @wrap_instance_event(prefix='compute')
3634     @wrap_instance_fault
3635     def unrescue_instance(self, context, instance):
3636         context = context.elevated()
3637         LOG.info('Unrescuing', instance=instance)
3638 
3639         network_info = self.network_api.get_instance_nw_info(context, instance)
3640         self._notify_about_instance_usage(context, instance,
3641                 "unrescue.start", network_info=network_info)
3642         compute_utils.notify_about_instance_action(context, instance,
3643             self.host, action=fields.NotificationAction.UNRESCUE,
3644             phase=fields.NotificationPhase.START)
3645 
3646         with self._error_out_instance_on_exception(context, instance):
3647             self.driver.unrescue(instance,
3648                                  network_info)
3649 
3650         instance.vm_state = vm_states.ACTIVE
3651         instance.task_state = None
3652         instance.power_state = self._get_power_state(context, instance)
3653         instance.save(expected_task_state=task_states.UNRESCUING)
3654 
3655         self._notify_about_instance_usage(context,
3656                                           instance,
3657                                           "unrescue.end",
3658                                           network_info=network_info)
3659         compute_utils.notify_about_instance_action(context, instance,
3660             self.host, action=fields.NotificationAction.UNRESCUE,
3661             phase=fields.NotificationPhase.END)
3662 
3663     @wrap_exception()
3664     @wrap_instance_fault
3665     def change_instance_metadata(self, context, diff, instance):
3666         """Update the metadata published to the instance."""
3667         LOG.debug("Changing instance metadata according to %r",
3668                   diff, instance=instance)
3669         self.driver.change_instance_metadata(context, instance, diff)
3670 
3671     @wrap_exception()
3672     @wrap_instance_event(prefix='compute')
3673     @wrap_instance_fault
3674     def confirm_resize(self, context, instance, migration):
3675         """Confirms a migration/resize and deletes the 'old' instance.
3676 
3677         This is called from the API and runs on the source host.
3678 
3679         Nothing needs to happen on the destination host at this point since
3680         the instance is already running there. This routine just cleans up the
3681         source host.
3682         """
3683         @utils.synchronized(instance.uuid)
3684         def do_confirm_resize(context, instance, migration_id):
3685             # NOTE(wangpan): Get the migration status from db, if it has been
3686             #                confirmed, we do nothing and return here
3687             LOG.debug("Going to confirm migration %s", migration_id,
3688                       instance=instance)
3689             try:
3690                 # TODO(russellb) Why are we sending the migration object just
3691                 # to turn around and look it up from the db again?
3692                 migration = objects.Migration.get_by_id(
3693                                     context.elevated(), migration_id)
3694             except exception.MigrationNotFound:
3695                 LOG.error("Migration %s is not found during confirmation",
3696                           migration_id, instance=instance)
3697                 return
3698 
3699             if migration.status == 'confirmed':
3700                 LOG.info("Migration %s is already confirmed",
3701                          migration_id, instance=instance)
3702                 return
3703             elif migration.status not in ('finished', 'confirming'):
3704                 LOG.warning("Unexpected confirmation status '%(status)s' "
3705                             "of migration %(id)s, exit confirmation process",
3706                             {"status": migration.status, "id": migration_id},
3707                             instance=instance)
3708                 return
3709 
3710             # NOTE(wangpan): Get the instance from db, if it has been
3711             #                deleted, we do nothing and return here
3712             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3713             try:
3714                 instance = objects.Instance.get_by_uuid(
3715                         context, instance.uuid,
3716                         expected_attrs=expected_attrs)
3717             except exception.InstanceNotFound:
3718                 LOG.info("Instance is not found during confirmation",
3719                          instance=instance)
3720                 return
3721 
3722             self._confirm_resize(context, instance, migration=migration)
3723 
3724         do_confirm_resize(context, instance, migration.id)
3725 
3726     def _confirm_resize(self, context, instance, migration=None):
3727         """Destroys the source instance."""
3728         self._notify_about_instance_usage(context, instance,
3729                                           "resize.confirm.start")
3730         compute_utils.notify_about_instance_action(context, instance,
3731             self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3732             phase=fields.NotificationPhase.START)
3733 
3734         with self._error_out_instance_on_exception(context, instance):
3735             # NOTE(danms): delete stashed migration information
3736             old_instance_type = instance.old_flavor
3737             instance.old_flavor = None
3738             instance.new_flavor = None
3739             instance.system_metadata.pop('old_vm_state', None)
3740             instance.save()
3741 
3742             # NOTE(tr3buchet): tear down networks on source host
3743             self.network_api.setup_networks_on_host(context, instance,
3744                                migration.source_compute, teardown=True)
3745 
3746             network_info = self.network_api.get_instance_nw_info(context,
3747                                                                  instance)
3748             # TODO(mriedem): Get BDMs here and pass them to the driver.
3749             self.driver.confirm_migration(context, migration, instance,
3750                                           network_info)
3751 
3752             migration.status = 'confirmed'
3753             with migration.obj_as_admin():
3754                 migration.save()
3755 
3756             rt = self._get_resource_tracker()
3757             rt.drop_move_claim(context, instance, migration.source_node,
3758                                old_instance_type, prefix='old_')
3759             self._delete_allocation_after_move(context, instance, migration,
3760                                                old_instance_type,
3761                                                migration.source_node)
3762             instance.drop_migration_context()
3763 
3764             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3765             # might have manually powered up the instance to confirm the
3766             # resize/migrate, so we need to check the current power state
3767             # on the instance and set the vm_state appropriately. We default
3768             # to ACTIVE because if the power state is not SHUTDOWN, we
3769             # assume _sync_instance_power_state will clean it up.
3770             p_state = instance.power_state
3771             vm_state = None
3772             if p_state == power_state.SHUTDOWN:
3773                 vm_state = vm_states.STOPPED
3774                 LOG.debug("Resized/migrated instance is powered off. "
3775                           "Setting vm_state to '%s'.", vm_state,
3776                           instance=instance)
3777             else:
3778                 vm_state = vm_states.ACTIVE
3779 
3780             instance.vm_state = vm_state
3781             instance.task_state = None
3782             instance.save(expected_task_state=[None, task_states.DELETING])
3783 
3784             self._notify_about_instance_usage(
3785                 context, instance, "resize.confirm.end",
3786                 network_info=network_info)
3787             compute_utils.notify_about_instance_action(context, instance,
3788                    self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3789                    phase=fields.NotificationPhase.END)
3790 
3791     def _delete_allocation_after_move(self, context, instance, migration,
3792                                       flavor, nodename):
3793         rt = self._get_resource_tracker()
3794         cn_uuid = rt.get_node_uuid(nodename)
3795 
3796         if migration.source_node == nodename:
3797             if migration.status in ('confirmed', 'completed'):
3798                 # NOTE(danms): We're finishing on the source node, so try to
3799                 # delete the allocation based on the migration uuid
3800                 deleted = self.reportclient.delete_allocation_for_instance(
3801                     context, migration.uuid)
3802                 if deleted:
3803                     LOG.info(_('Source node %(node)s confirmed migration '
3804                                '%(mig)s; deleted migration-based '
3805                                'allocation'),
3806                              {'node': nodename, 'mig': migration.uuid})
3807                     # NOTE(danms): We succeeded, which means we do not
3808                     # need to do the complex double allocation dance
3809                     return
3810             else:
3811                 # We're reverting (or failed) on the source, so we
3812                 # need to check if our migration holds a claim and if
3813                 # so, avoid doing the legacy behavior below.
3814                 mig_allocs = (
3815                     self.reportclient.get_allocations_for_consumer_by_provider(
3816                         context, cn_uuid, migration.uuid))
3817                 if mig_allocs:
3818                     LOG.info(_('Source node %(node)s reverted migration '
3819                                '%(mig)s; not deleting migration-based '
3820                                'allocation'),
3821                              {'node': nodename, 'mig': migration.uuid})
3822                     return
3823         elif migration.dest_node == nodename:
3824             # NOTE(danms): We're reverting on the destination node
3825             # (and we must not be doing a same-host migration if we
3826             # made it past the check above), so we need to check to
3827             # see if the source did migration-based allocation
3828             # accounting
3829             allocs = (
3830                 self.reportclient.get_allocations_for_consumer_by_provider(
3831                     context, cn_uuid, migration.uuid))
3832             if allocs:
3833                 # NOTE(danms): The source did migration-based allocation
3834                 # accounting, so we should let the source node rejigger
3835                 # the allocations in finish_resize_revert()
3836                 LOG.info(_('Destination node %(node)s reverted migration '
3837                            '%(mig)s; not deleting migration-based '
3838                            'allocation'),
3839                          {'node': nodename, 'mig': migration.uuid})
3840                 return
3841 
3842         # TODO(danms): Remove below this line when we remove compatibility
3843         # for double-accounting migrations (likely rocky)
3844         LOG.info(_('Doing legacy allocation math for migration %(mig)s after '
3845                    'instance move'),
3846                  {'mig': migration.uuid},
3847                  instance=instance)
3848 
3849         # NOTE(jaypipes): This sucks, but due to the fact that confirm_resize()
3850         # only runs on the source host and revert_resize() runs on the
3851         # destination host, we need to do this here. Basically, what we're
3852         # doing here is grabbing the existing allocations for this instance
3853         # from the placement API, dropping the resources in the doubled-up
3854         # allocation set that refer to the source host UUID and calling PUT
3855         # /allocations back to the placement API. The allocation that gets
3856         # PUT'd back to placement will only include the destination host and
3857         # any shared providers in the case of a confirm_resize operation and
3858         # the source host and shared providers for a revert_resize operation..
3859         if not scheduler_utils.remove_allocation_from_compute(
3860                 context, instance, cn_uuid, self.reportclient, flavor):
3861             LOG.error("Failed to save manipulated allocation",
3862                       instance=instance)
3863 
3864     @wrap_exception()
3865     @reverts_task_state
3866     @wrap_instance_event(prefix='compute')
3867     @errors_out_migration
3868     @wrap_instance_fault
3869     def revert_resize(self, context, instance, migration):
3870         """Destroys the new instance on the destination machine.
3871 
3872         Reverts the model changes, and powers on the old instance on the
3873         source machine.
3874 
3875         """
3876         # NOTE(comstud): A revert_resize is essentially a resize back to
3877         # the old size, so we need to send a usage event here.
3878         compute_utils.notify_usage_exists(self.notifier, context, instance,
3879                                           current_period=True)
3880 
3881         with self._error_out_instance_on_exception(context, instance):
3882             # NOTE(tr3buchet): tear down networks on destination host
3883             self.network_api.setup_networks_on_host(context, instance,
3884                                                     teardown=True)
3885 
3886             migration_p = obj_base.obj_to_primitive(migration)
3887             self.network_api.migrate_instance_start(context,
3888                                                     instance,
3889                                                     migration_p)
3890 
3891             network_info = self.network_api.get_instance_nw_info(context,
3892                                                                  instance)
3893             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3894                     context, instance.uuid)
3895             block_device_info = self._get_instance_block_device_info(
3896                                 context, instance, bdms=bdms)
3897 
3898             destroy_disks = not self._is_instance_storage_shared(
3899                 context, instance, host=migration.source_compute)
3900             self.driver.destroy(context, instance, network_info,
3901                                 block_device_info, destroy_disks)
3902 
3903             self._terminate_volume_connections(context, instance, bdms)
3904 
3905             migration.status = 'reverted'
3906             with migration.obj_as_admin():
3907                 migration.save()
3908 
3909             # NOTE(ndipanov): We need to do this here because dropping the
3910             # claim means we lose the migration_context data. We really should
3911             # fix this by moving the drop_move_claim call to the
3912             # finish_revert_resize method as this is racy (revert is dropped,
3913             # but instance resources will be tracked with the new flavor until
3914             # it gets rolled back in finish_revert_resize, which is
3915             # potentially wrong for a period of time).
3916             instance.revert_migration_context()
3917             instance.save()
3918 
3919             rt = self._get_resource_tracker()
3920             rt.drop_move_claim(context, instance, instance.node)
3921             self._delete_allocation_after_move(context, instance, migration,
3922                                                instance.flavor,
3923                                                instance.node)
3924 
3925             # RPC cast back to the source host to finish the revert there.
3926             self.compute_rpcapi.finish_revert_resize(context, instance,
3927                     migration, migration.source_compute)
3928 
3929     @wrap_exception()
3930     @reverts_task_state
3931     @wrap_instance_event(prefix='compute')
3932     @errors_out_migration
3933     @wrap_instance_fault
3934     def finish_revert_resize(self, context, instance, migration):
3935         """Finishes the second half of reverting a resize on the source host.
3936 
3937         Bring the original source instance state back (active/shutoff) and
3938         revert the resized attributes in the database.
3939 
3940         """
3941         with self._error_out_instance_on_exception(context, instance):
3942             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3943                 context, instance.uuid)
3944             self._notify_about_instance_usage(
3945                     context, instance, "resize.revert.start")
3946             compute_utils.notify_about_instance_action(context, instance,
3947                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
3948                     phase=fields.NotificationPhase.START, bdms=bdms)
3949 
3950             # NOTE(mriedem): delete stashed old_vm_state information; we
3951             # default to ACTIVE for backwards compatibility if old_vm_state
3952             # is not set
3953             old_vm_state = instance.system_metadata.pop('old_vm_state',
3954                                                         vm_states.ACTIVE)
3955 
3956             self._set_instance_info(instance, instance.old_flavor)
3957             instance.old_flavor = None
3958             instance.new_flavor = None
3959             instance.host = migration.source_compute
3960             instance.node = migration.source_node
3961             instance.save()
3962 
3963             self._revert_allocation(context, instance, migration)
3964 
3965             self.network_api.setup_networks_on_host(context, instance,
3966                                                     migration.source_compute)
3967             migration_p = obj_base.obj_to_primitive(migration)
3968             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
3969             # source host temporarily. "network_api.migrate_instance_finish"
3970             # will setup the network for the instance on the destination host.
3971             # For revert resize, the instance will back to the source host, the
3972             # setup of the network for instance should be on the source host.
3973             # So set the migration_p['dest_compute'] to source host at here.
3974             migration_p['dest_compute'] = migration.source_compute
3975             self.network_api.migrate_instance_finish(context,
3976                                                      instance,
3977                                                      migration_p)
3978             network_info = self.network_api.get_instance_nw_info(context,
3979                                                                  instance)
3980 
3981             # revert_resize deleted any volume attachments for the instance
3982             # and created new ones to be used on this host, but we
3983             # have to update those attachments with the host connector so the
3984             # BDM.connection_info will get set in the call to
3985             # _get_instance_block_device_info below with refresh_conn_info=True
3986             # and then the volumes can be re-connected via the driver on this
3987             # host.
3988             self._update_volume_attachments(context, instance, bdms)
3989 
3990             block_device_info = self._get_instance_block_device_info(
3991                     context, instance, refresh_conn_info=True, bdms=bdms)
3992 
3993             power_on = old_vm_state != vm_states.STOPPED
3994             self.driver.finish_revert_migration(context, instance,
3995                                        network_info,
3996                                        block_device_info, power_on)
3997 
3998             instance.drop_migration_context()
3999             instance.launched_at = timeutils.utcnow()
4000             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
4001 
4002             # Complete any volume attachments so the volumes are in-use.
4003             self._complete_volume_attachments(context, bdms)
4004 
4005             # if the original vm state was STOPPED, set it back to STOPPED
4006             LOG.info("Updating instance to original state: '%s'",
4007                      old_vm_state, instance=instance)
4008             if power_on:
4009                 instance.vm_state = vm_states.ACTIVE
4010                 instance.task_state = None
4011                 instance.save()
4012             else:
4013                 instance.task_state = task_states.POWERING_OFF
4014                 instance.save()
4015                 self.stop_instance(context, instance=instance,
4016                                    clean_shutdown=True)
4017 
4018             self._notify_about_instance_usage(
4019                     context, instance, "resize.revert.end")
4020             compute_utils.notify_about_instance_action(context, instance,
4021                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4022                     phase=fields.NotificationPhase.END, bdms=bdms)
4023 
4024     def _revert_allocation(self, context, instance, migration):
4025         """Revert an allocation that is held by migration to our instance."""
4026 
4027         # Fetch the original allocation that the instance had on the source
4028         # node, which are now held by the migration
4029         orig_alloc = self.reportclient.get_allocations_for_consumer(
4030             context, migration.uuid)
4031         if not orig_alloc:
4032             # NOTE(danms): This migration did not do per-migration allocation
4033             # accounting, so nothing to do here.
4034             LOG.info('Old-style migration %(mig)s is being reverted; '
4035                      'no migration claims found on original node '
4036                      'to swap.',
4037                      {'mig': migration.uuid},
4038                      instance=instance)
4039             return False
4040 
4041         if len(orig_alloc) > 1:
4042             # NOTE(danms): This may change later if we have other allocations
4043             # against other providers that need to be held by the migration
4044             # as well. Perhaps something like shared storage resources that
4045             # will actually be duplicated during a resize type operation.
4046             LOG.error('New-style migration %(mig)s has allocations against '
4047                       'more than one provider %(rps)s. This should not be '
4048                       'possible, but reverting it anyway.',
4049                       {'mig': migration.uuid,
4050                        'rps': ','.join(orig_alloc.keys())},
4051                       instance=instance)
4052 
4053         # We only have a claim against one provider, it is the source node
4054         cn_uuid = list(orig_alloc.keys())[0]
4055 
4056         # Get just the resources part of the one allocation we need below
4057         orig_alloc = orig_alloc[cn_uuid].get('resources', {})
4058 
4059         # FIXME(danms): This method is flawed in that it asssumes allocations
4060         # against only one provider. So, this may overwite allocations against
4061         # a shared provider, if we had one.
4062         LOG.info('Swapping old allocation on %(node)s held by migration '
4063                  '%(mig)s for instance',
4064                  {'node': cn_uuid, 'mig': migration.uuid},
4065                  instance=instance)
4066         # TODO(cdent): Should we be doing anything with return values here?
4067         self.reportclient.set_and_clear_allocations(
4068             context, cn_uuid, instance.uuid, orig_alloc, instance.project_id,
4069             instance.user_id, consumer_to_clear=migration.uuid)
4070         return True
4071 
4072     def _prep_resize(self, context, image, instance, instance_type,
4073                      filter_properties, node, migration, clean_shutdown=True):
4074 
4075         if not filter_properties:
4076             filter_properties = {}
4077 
4078         if not instance.host:
4079             self._set_instance_obj_error_state(context, instance)
4080             msg = _('Instance has no source host')
4081             raise exception.MigrationError(reason=msg)
4082 
4083         same_host = instance.host == self.host
4084         # if the flavor IDs match, it's migrate; otherwise resize
4085         if same_host and instance_type.id == instance['instance_type_id']:
4086             # check driver whether support migrate to same host
4087             if not self.driver.capabilities.get(
4088                     'supports_migrate_to_same_host', False):
4089                 raise exception.UnableToMigrateToSelf(
4090                     instance_id=instance.uuid, host=self.host)
4091 
4092         # NOTE(danms): Stash the new instance_type to avoid having to
4093         # look it up in the database later
4094         instance.new_flavor = instance_type
4095         # NOTE(mriedem): Stash the old vm_state so we can set the
4096         # resized/reverted instance back to the same state later.
4097         vm_state = instance.vm_state
4098         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4099         instance.system_metadata['old_vm_state'] = vm_state
4100         instance.save()
4101 
4102         limits = filter_properties.get('limits', {})
4103         rt = self._get_resource_tracker()
4104         with rt.resize_claim(context, instance, instance_type, node,
4105                              migration, image_meta=image,
4106                              limits=limits) as claim:
4107             LOG.info('Migrating', instance=instance)
4108             # RPC cast to the source host to start the actual resize/migration.
4109             self.compute_rpcapi.resize_instance(
4110                     context, instance, claim.migration, image,
4111                     instance_type, clean_shutdown)
4112 
4113     @wrap_exception()
4114     @reverts_task_state
4115     @wrap_instance_event(prefix='compute')
4116     @wrap_instance_fault
4117     def prep_resize(self, context, image, instance, instance_type,
4118                     request_spec, filter_properties, node,
4119                     clean_shutdown, migration, host_list):
4120         """Initiates the process of moving a running instance to another host.
4121 
4122         Possibly changes the VCPU, RAM and disk size in the process.
4123 
4124         This is initiated from conductor and runs on the destination host.
4125 
4126         The main purpose of this method is performing some checks on the
4127         destination host and making a claim for resources. If the claim fails
4128         then a reschedule to another host may be attempted which involves
4129         calling back to conductor to start the process over again.
4130         """
4131         if node is None:
4132             node = self._get_nodename(instance, refresh=True)
4133 
4134         with self._error_out_instance_on_exception(context, instance), \
4135                  errors_out_migration_ctxt(migration):
4136             compute_utils.notify_usage_exists(self.notifier, context, instance,
4137                                               current_period=True)
4138             self._notify_about_instance_usage(
4139                     context, instance, "resize.prep.start")
4140             compute_utils.notify_about_resize_prep_instance(
4141                 context, instance, self.host,
4142                 fields.NotificationPhase.START, instance_type)
4143             try:
4144                 self._prep_resize(context, image, instance,
4145                                   instance_type, filter_properties,
4146                                   node, migration, clean_shutdown)
4147             except Exception:
4148                 # Since we hit a failure, we're either rescheduling or dead
4149                 # and either way we need to cleanup any allocations created
4150                 # by the scheduler for the destination node.
4151                 if migration and not self._revert_allocation(
4152                         context, instance, migration):
4153                     # We did not do a migration-based
4154                     # allocation. Note that for a resize to the
4155                     # same host, the scheduler will merge the
4156                     # flavors, so here we'd be subtracting the new
4157                     # flavor from the allocated resources on this
4158                     # node.
4159                     # FIXME(danms): Remove this in Rocky
4160                     rt = self._get_resource_tracker()
4161                     rt.delete_allocation_for_failed_resize(
4162                         instance, node, instance_type)
4163                 # try to re-schedule the resize elsewhere:
4164                 exc_info = sys.exc_info()
4165                 self._reschedule_resize_or_reraise(context, image, instance,
4166                         exc_info, instance_type, request_spec,
4167                         filter_properties, host_list)
4168             finally:
4169                 extra_usage_info = dict(
4170                         new_instance_type=instance_type.name,
4171                         new_instance_type_id=instance_type.id)
4172 
4173                 self._notify_about_instance_usage(
4174                     context, instance, "resize.prep.end",
4175                     extra_usage_info=extra_usage_info)
4176                 compute_utils.notify_about_resize_prep_instance(
4177                     context, instance, self.host,
4178                     fields.NotificationPhase.END, instance_type)
4179 
4180     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
4181             instance_type, request_spec, filter_properties, host_list):
4182         """Try to re-schedule the resize or re-raise the original error to
4183         error out the instance.
4184         """
4185         if not request_spec:
4186             request_spec = {}
4187         if not filter_properties:
4188             filter_properties = {}
4189 
4190         rescheduled = False
4191         instance_uuid = instance.uuid
4192 
4193         try:
4194             reschedule_method = self.compute_task_api.resize_instance
4195             scheduler_hint = dict(filter_properties=filter_properties)
4196             method_args = (instance, None, scheduler_hint, instance_type)
4197             task_state = task_states.RESIZE_PREP
4198 
4199             rescheduled = self._reschedule(context, request_spec,
4200                     filter_properties, instance, reschedule_method,
4201                     method_args, task_state, exc_info, host_list=host_list)
4202         except Exception as error:
4203             rescheduled = False
4204             LOG.exception("Error trying to reschedule",
4205                           instance_uuid=instance_uuid)
4206             compute_utils.add_instance_fault_from_exc(context,
4207                     instance, error,
4208                     exc_info=sys.exc_info())
4209             self._notify_about_instance_usage(context, instance,
4210                     'resize.error', fault=error)
4211             compute_utils.notify_about_instance_action(
4212                 context, instance, self.host,
4213                 action=fields.NotificationAction.RESIZE,
4214                 phase=fields.NotificationPhase.ERROR,
4215                 exception=error)
4216         if rescheduled:
4217             self._log_original_error(exc_info, instance_uuid)
4218             compute_utils.add_instance_fault_from_exc(context,
4219                     instance, exc_info[1], exc_info=exc_info)
4220             self._notify_about_instance_usage(context, instance,
4221                     'resize.error', fault=exc_info[1])
4222             compute_utils.notify_about_instance_action(
4223                 context, instance, self.host,
4224                 action=fields.NotificationAction.RESIZE,
4225                 phase=fields.NotificationPhase.ERROR,
4226                 exception=exc_info[1])
4227         else:
4228             # not re-scheduling
4229             six.reraise(*exc_info)
4230 
4231     @wrap_exception()
4232     @reverts_task_state
4233     @wrap_instance_event(prefix='compute')
4234     @wrap_instance_fault
4235     def resize_instance(self, context, instance, image,
4236                         migration, instance_type, clean_shutdown):
4237         """Starts the migration of a running instance to another host.
4238 
4239         This is initiated from the destination host's ``prep_resize`` routine
4240         and runs on the source host.
4241         """
4242         try:
4243             self._resize_instance(context, instance, image, migration,
4244                                   instance_type, clean_shutdown)
4245         except Exception:
4246             with excutils.save_and_reraise_exception():
4247                 self._revert_allocation(context, instance, migration)
4248 
4249     def _resize_instance(self, context, instance, image,
4250                          migration, instance_type, clean_shutdown):
4251         with self._error_out_instance_on_exception(context, instance), \
4252              errors_out_migration_ctxt(migration):
4253             network_info = self.network_api.get_instance_nw_info(context,
4254                                                                  instance)
4255 
4256             migration.status = 'migrating'
4257             with migration.obj_as_admin():
4258                 migration.save()
4259 
4260             instance.task_state = task_states.RESIZE_MIGRATING
4261             instance.save(expected_task_state=task_states.RESIZE_PREP)
4262 
4263             self._notify_about_instance_usage(
4264                 context, instance, "resize.start", network_info=network_info)
4265 
4266             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4267                     context, instance.uuid)
4268 
4269             compute_utils.notify_about_instance_action(context, instance,
4270                    self.host, action=fields.NotificationAction.RESIZE,
4271                    phase=fields.NotificationPhase.START, bdms=bdms)
4272 
4273             block_device_info = self._get_instance_block_device_info(
4274                                 context, instance, bdms=bdms)
4275 
4276             timeout, retry_interval = self._get_power_off_values(context,
4277                                             instance, clean_shutdown)
4278             disk_info = self.driver.migrate_disk_and_power_off(
4279                     context, instance, migration.dest_host,
4280                     instance_type, network_info,
4281                     block_device_info,
4282                     timeout, retry_interval)
4283 
4284             self._terminate_volume_connections(context, instance, bdms)
4285 
4286             migration_p = obj_base.obj_to_primitive(migration)
4287             self.network_api.migrate_instance_start(context,
4288                                                     instance,
4289                                                     migration_p)
4290 
4291             migration.status = 'post-migrating'
4292             with migration.obj_as_admin():
4293                 migration.save()
4294 
4295             instance.host = migration.dest_compute
4296             instance.node = migration.dest_node
4297             instance.task_state = task_states.RESIZE_MIGRATED
4298             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4299 
4300             # RPC cast to the destination host to finish the resize/migration.
4301             self.compute_rpcapi.finish_resize(context, instance,
4302                     migration, image, disk_info, migration.dest_compute)
4303 
4304         self._notify_about_instance_usage(context, instance, "resize.end",
4305                                           network_info=network_info)
4306 
4307         compute_utils.notify_about_instance_action(context, instance,
4308                self.host, action=fields.NotificationAction.RESIZE,
4309                phase=fields.NotificationPhase.END, bdms=bdms)
4310         self.instance_events.clear_events_for_instance(instance)
4311 
4312     def _terminate_volume_connections(self, context, instance, bdms):
4313         connector = None
4314         for bdm in bdms:
4315             if bdm.is_volume:
4316                 if bdm.attachment_id:
4317                     # NOTE(jdg): So here's the thing, the idea behind the new
4318                     # attach API's was to have a new code fork/path that we
4319                     # followed, we're not going to do that so we have to do
4320                     # some extra work in here to make it *behave* just like the
4321                     # old code. Cinder doesn't allow disconnect/reconnect (you
4322                     # just delete the attachment and get a new one)
4323                     # attachments in the new attach code so we have to do
4324                     # a delete and create without a connector (reserve),
4325                     # in other words, beware
4326                     attachment_id = self.volume_api.attachment_create(
4327                         context, bdm.volume_id, instance.uuid)['id']
4328                     self.volume_api.attachment_delete(context,
4329                                                       bdm.attachment_id)
4330                     bdm.attachment_id = attachment_id
4331                     bdm.save()
4332 
4333                 else:
4334                     if connector is None:
4335                         connector = self.driver.get_volume_connector(instance)
4336                     self.volume_api.terminate_connection(context,
4337                                                          bdm.volume_id,
4338                                                          connector)
4339 
4340     @staticmethod
4341     def _set_instance_info(instance, instance_type):
4342         instance.instance_type_id = instance_type.id
4343         instance.memory_mb = instance_type.memory_mb
4344         instance.vcpus = instance_type.vcpus
4345         instance.root_gb = instance_type.root_gb
4346         instance.ephemeral_gb = instance_type.ephemeral_gb
4347         instance.flavor = instance_type
4348 
4349     def _update_volume_attachments(self, context, instance, bdms):
4350         """Updates volume attachments using the virt driver host connector.
4351 
4352         :param context: nova.context.RequestContext - user request context
4353         :param instance: nova.objects.Instance
4354         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4355                      device mappings for the given instance
4356         """
4357         if bdms:
4358             connector = None
4359             for bdm in bdms:
4360                 if bdm.is_volume and bdm.attachment_id:
4361                     if connector is None:
4362                         connector = self.driver.get_volume_connector(instance)
4363                     self.volume_api.attachment_update(
4364                         context, bdm.attachment_id, connector, bdm.device_name)
4365 
4366     def _complete_volume_attachments(self, context, bdms):
4367         """Completes volume attachments for the instance
4368 
4369         :param context: nova.context.RequestContext - user request context
4370         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4371                      device mappings for the given instance
4372         """
4373         if bdms:
4374             for bdm in bdms:
4375                 if bdm.is_volume and bdm.attachment_id:
4376                     self.volume_api.attachment_complete(
4377                         context, bdm.attachment_id)
4378 
4379     def _finish_resize(self, context, instance, migration, disk_info,
4380                        image_meta, bdms):
4381         resize_instance = False
4382         old_instance_type_id = migration['old_instance_type_id']
4383         new_instance_type_id = migration['new_instance_type_id']
4384         old_instance_type = instance.get_flavor()
4385         # NOTE(mriedem): Get the old_vm_state so we know if we should
4386         # power on the instance. If old_vm_state is not set we need to default
4387         # to ACTIVE for backwards compatibility
4388         old_vm_state = instance.system_metadata.get('old_vm_state',
4389                                                     vm_states.ACTIVE)
4390         instance.old_flavor = old_instance_type
4391 
4392         if old_instance_type_id != new_instance_type_id:
4393             instance_type = instance.get_flavor('new')
4394             self._set_instance_info(instance, instance_type)
4395             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4396                 if old_instance_type[key] != instance_type[key]:
4397                     resize_instance = True
4398                     break
4399         instance.apply_migration_context()
4400 
4401         # NOTE(tr3buchet): setup networks on destination host
4402         self.network_api.setup_networks_on_host(context, instance,
4403                                                 migration['dest_compute'])
4404 
4405         migration_p = obj_base.obj_to_primitive(migration)
4406         self.network_api.migrate_instance_finish(context,
4407                                                  instance,
4408                                                  migration_p)
4409 
4410         network_info = self.network_api.get_instance_nw_info(context, instance)
4411 
4412         instance.task_state = task_states.RESIZE_FINISH
4413         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4414 
4415         self._notify_about_instance_usage(
4416             context, instance, "finish_resize.start",
4417             network_info=network_info)
4418         compute_utils.notify_about_instance_action(context, instance,
4419                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4420                phase=fields.NotificationPhase.START, bdms=bdms)
4421 
4422         # We need to update any volume attachments using the destination
4423         # host connector so that we can update the BDM.connection_info
4424         # before calling driver.finish_migration otherwise the driver
4425         # won't know how to connect the volumes to this host.
4426         # Note that _get_instance_block_device_info with
4427         # refresh_conn_info=True will update the BDM.connection_info value
4428         # in the database so we must do this before calling that method.
4429         self._update_volume_attachments(context, instance, bdms)
4430 
4431         block_device_info = self._get_instance_block_device_info(
4432             context, instance, refresh_conn_info=True, bdms=bdms)
4433 
4434         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4435         # automatically power on the instance after it's migrated
4436         power_on = old_vm_state != vm_states.STOPPED
4437 
4438         try:
4439             self.driver.finish_migration(context, migration, instance,
4440                                          disk_info,
4441                                          network_info,
4442                                          image_meta, resize_instance,
4443                                          block_device_info, power_on)
4444         except Exception:
4445             with excutils.save_and_reraise_exception():
4446                 if old_instance_type_id != new_instance_type_id:
4447                     self._set_instance_info(instance,
4448                                             old_instance_type)
4449 
4450         # Now complete any volume attachments that were previously updated.
4451         self._complete_volume_attachments(context, bdms)
4452 
4453         migration.status = 'finished'
4454         with migration.obj_as_admin():
4455             migration.save()
4456 
4457         instance.vm_state = vm_states.RESIZED
4458         instance.task_state = None
4459         instance.launched_at = timeutils.utcnow()
4460         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4461 
4462         return network_info
4463 
4464     @wrap_exception()
4465     @reverts_task_state
4466     @wrap_instance_event(prefix='compute')
4467     @wrap_instance_fault
4468     def finish_resize(self, context, disk_info, image, instance,
4469                       migration):
4470         """Completes the migration process.
4471 
4472         Sets up the newly transferred disk and turns on the instance at its
4473         new host machine.
4474 
4475         """
4476         try:
4477             self._finish_resize_helper(context, disk_info, image, instance,
4478                                        migration)
4479         except Exception:
4480             with excutils.save_and_reraise_exception():
4481                 self._revert_allocation(context, instance, migration)
4482 
4483     def _finish_resize_helper(self, context, disk_info, image, instance,
4484                               migration):
4485         """Completes the migration process.
4486 
4487         The caller must revert the instance's allocations if the migration
4488         process failed.
4489         """
4490         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4491             context, instance.uuid)
4492 
4493         with self._error_out_instance_on_exception(context, instance), \
4494              errors_out_migration_ctxt(migration):
4495             image_meta = objects.ImageMeta.from_dict(image)
4496             network_info = self._finish_resize(context, instance, migration,
4497                                                disk_info, image_meta, bdms)
4498 
4499         self._update_scheduler_instance_info(context, instance)
4500         self._notify_about_instance_usage(
4501             context, instance, "finish_resize.end",
4502             network_info=network_info)
4503         compute_utils.notify_about_instance_action(context, instance,
4504                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4505                phase=fields.NotificationPhase.END, bdms=bdms)
4506 
4507     @wrap_exception()
4508     @wrap_instance_fault
4509     def add_fixed_ip_to_instance(self, context, network_id, instance):
4510         """Calls network_api to add new fixed_ip to instance
4511         then injects the new network info and resets instance networking.
4512 
4513         """
4514         self._notify_about_instance_usage(
4515                 context, instance, "create_ip.start")
4516 
4517         network_info = self.network_api.add_fixed_ip_to_instance(context,
4518                                                                  instance,
4519                                                                  network_id)
4520         self._inject_network_info(context, instance, network_info)
4521         self.reset_network(context, instance)
4522 
4523         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4524         instance.updated_at = timeutils.utcnow()
4525         instance.save()
4526 
4527         self._notify_about_instance_usage(
4528             context, instance, "create_ip.end", network_info=network_info)
4529 
4530     @wrap_exception()
4531     @wrap_instance_fault
4532     def remove_fixed_ip_from_instance(self, context, address, instance):
4533         """Calls network_api to remove existing fixed_ip from instance
4534         by injecting the altered network info and resetting
4535         instance networking.
4536         """
4537         self._notify_about_instance_usage(
4538                 context, instance, "delete_ip.start")
4539 
4540         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4541                                                                       instance,
4542                                                                       address)
4543         self._inject_network_info(context, instance, network_info)
4544         self.reset_network(context, instance)
4545 
4546         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4547         instance.updated_at = timeutils.utcnow()
4548         instance.save()
4549 
4550         self._notify_about_instance_usage(
4551             context, instance, "delete_ip.end", network_info=network_info)
4552 
4553     @wrap_exception()
4554     @reverts_task_state
4555     @wrap_instance_event(prefix='compute')
4556     @wrap_instance_fault
4557     def pause_instance(self, context, instance):
4558         """Pause an instance on this host."""
4559         context = context.elevated()
4560         LOG.info('Pausing', instance=instance)
4561         self._notify_about_instance_usage(context, instance, 'pause.start')
4562         compute_utils.notify_about_instance_action(context, instance,
4563                self.host, action=fields.NotificationAction.PAUSE,
4564                phase=fields.NotificationPhase.START)
4565         self.driver.pause(instance)
4566         instance.power_state = self._get_power_state(context, instance)
4567         instance.vm_state = vm_states.PAUSED
4568         instance.task_state = None
4569         instance.save(expected_task_state=task_states.PAUSING)
4570         self._notify_about_instance_usage(context, instance, 'pause.end')
4571         compute_utils.notify_about_instance_action(context, instance,
4572                self.host, action=fields.NotificationAction.PAUSE,
4573                phase=fields.NotificationPhase.END)
4574 
4575     @wrap_exception()
4576     @reverts_task_state
4577     @wrap_instance_event(prefix='compute')
4578     @wrap_instance_fault
4579     def unpause_instance(self, context, instance):
4580         """Unpause a paused instance on this host."""
4581         context = context.elevated()
4582         LOG.info('Unpausing', instance=instance)
4583         self._notify_about_instance_usage(context, instance, 'unpause.start')
4584         compute_utils.notify_about_instance_action(context, instance,
4585             self.host, action=fields.NotificationAction.UNPAUSE,
4586             phase=fields.NotificationPhase.START)
4587         self.driver.unpause(instance)
4588         instance.power_state = self._get_power_state(context, instance)
4589         instance.vm_state = vm_states.ACTIVE
4590         instance.task_state = None
4591         instance.save(expected_task_state=task_states.UNPAUSING)
4592         self._notify_about_instance_usage(context, instance, 'unpause.end')
4593         compute_utils.notify_about_instance_action(context, instance,
4594             self.host, action=fields.NotificationAction.UNPAUSE,
4595             phase=fields.NotificationPhase.END)
4596 
4597     @wrap_exception()
4598     def host_power_action(self, context, action):
4599         """Reboots, shuts down or powers up the host."""
4600         return self.driver.host_power_action(action)
4601 
4602     @wrap_exception()
4603     def host_maintenance_mode(self, context, host, mode):
4604         """Start/Stop host maintenance window. On start, it triggers
4605         guest VMs evacuation.
4606         """
4607         return self.driver.host_maintenance_mode(host, mode)
4608 
4609     @wrap_exception()
4610     def set_host_enabled(self, context, enabled):
4611         """Sets the specified host's ability to accept new instances."""
4612         return self.driver.set_host_enabled(enabled)
4613 
4614     @wrap_exception()
4615     def get_host_uptime(self, context):
4616         """Returns the result of calling "uptime" on the target host."""
4617         return self.driver.get_host_uptime()
4618 
4619     @wrap_exception()
4620     @wrap_instance_fault
4621     def get_diagnostics(self, context, instance):
4622         """Retrieve diagnostics for an instance on this host."""
4623         current_power_state = self._get_power_state(context, instance)
4624         if current_power_state == power_state.RUNNING:
4625             LOG.info("Retrieving diagnostics", instance=instance)
4626             return self.driver.get_diagnostics(instance)
4627         else:
4628             raise exception.InstanceInvalidState(
4629                 attr='power state',
4630                 instance_uuid=instance.uuid,
4631                 state=power_state.STATE_MAP[instance.power_state],
4632                 method='get_diagnostics')
4633 
4634     @wrap_exception()
4635     @wrap_instance_fault
4636     def get_instance_diagnostics(self, context, instance):
4637         """Retrieve diagnostics for an instance on this host."""
4638         current_power_state = self._get_power_state(context, instance)
4639         if current_power_state == power_state.RUNNING:
4640             LOG.info("Retrieving diagnostics", instance=instance)
4641             return self.driver.get_instance_diagnostics(instance)
4642         else:
4643             raise exception.InstanceInvalidState(
4644                 attr='power state',
4645                 instance_uuid=instance.uuid,
4646                 state=power_state.STATE_MAP[instance.power_state],
4647                 method='get_diagnostics')
4648 
4649     @wrap_exception()
4650     @reverts_task_state
4651     @wrap_instance_event(prefix='compute')
4652     @wrap_instance_fault
4653     def suspend_instance(self, context, instance):
4654         """Suspend the given instance."""
4655         context = context.elevated()
4656 
4657         # Store the old state
4658         instance.system_metadata['old_vm_state'] = instance.vm_state
4659         self._notify_about_instance_usage(context, instance, 'suspend.start')
4660         compute_utils.notify_about_instance_action(context, instance,
4661                 self.host, action=fields.NotificationAction.SUSPEND,
4662                 phase=fields.NotificationPhase.START)
4663         with self._error_out_instance_on_exception(context, instance,
4664              instance_state=instance.vm_state):
4665             self.driver.suspend(context, instance)
4666         instance.power_state = self._get_power_state(context, instance)
4667         instance.vm_state = vm_states.SUSPENDED
4668         instance.task_state = None
4669         instance.save(expected_task_state=task_states.SUSPENDING)
4670         self._notify_about_instance_usage(context, instance, 'suspend.end')
4671         compute_utils.notify_about_instance_action(context, instance,
4672                 self.host, action=fields.NotificationAction.SUSPEND,
4673                 phase=fields.NotificationPhase.END)
4674 
4675     @wrap_exception()
4676     @reverts_task_state
4677     @wrap_instance_event(prefix='compute')
4678     @wrap_instance_fault
4679     def resume_instance(self, context, instance):
4680         """Resume the given suspended instance."""
4681         context = context.elevated()
4682         LOG.info('Resuming', instance=instance)
4683 
4684         self._notify_about_instance_usage(context, instance, 'resume.start')
4685 
4686         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4687             context, instance.uuid)
4688         block_device_info = self._get_instance_block_device_info(
4689             context, instance, bdms=bdms)
4690 
4691         compute_utils.notify_about_instance_action(context, instance,
4692             self.host, action=fields.NotificationAction.RESUME,
4693             phase=fields.NotificationPhase.START, bdms=bdms)
4694 
4695         network_info = self.network_api.get_instance_nw_info(context, instance)
4696 
4697         with self._error_out_instance_on_exception(context, instance,
4698              instance_state=instance.vm_state):
4699             self.driver.resume(context, instance, network_info,
4700                                block_device_info)
4701 
4702         instance.power_state = self._get_power_state(context, instance)
4703 
4704         # We default to the ACTIVE state for backwards compatibility
4705         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4706                                                          vm_states.ACTIVE)
4707 
4708         instance.task_state = None
4709         instance.save(expected_task_state=task_states.RESUMING)
4710         self._notify_about_instance_usage(context, instance, 'resume.end')
4711         compute_utils.notify_about_instance_action(context, instance,
4712             self.host, action=fields.NotificationAction.RESUME,
4713             phase=fields.NotificationPhase.END, bdms=bdms)
4714 
4715     @wrap_exception()
4716     @reverts_task_state
4717     @wrap_instance_event(prefix='compute')
4718     @wrap_instance_fault
4719     def shelve_instance(self, context, instance, image_id,
4720                         clean_shutdown):
4721         """Shelve an instance.
4722 
4723         This should be used when you want to take a snapshot of the instance.
4724         It also adds system_metadata that can be used by a periodic task to
4725         offload the shelved instance after a period of time.
4726 
4727         :param context: request context
4728         :param instance: an Instance object
4729         :param image_id: an image id to snapshot to.
4730         :param clean_shutdown: give the GuestOS a chance to stop
4731         """
4732 
4733         @utils.synchronized(instance.uuid)
4734         def do_shelve_instance():
4735             self._shelve_instance(context, instance, image_id, clean_shutdown)
4736         do_shelve_instance()
4737 
4738     def _shelve_instance(self, context, instance, image_id,
4739                          clean_shutdown):
4740         LOG.info('Shelving', instance=instance)
4741         offload = CONF.shelved_offload_time == 0
4742         if offload:
4743             # Get the BDMs early so we can pass them into versioned
4744             # notifications since _shelve_offload_instance needs the
4745             # BDMs anyway.
4746             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4747                 context, instance.uuid)
4748         else:
4749             bdms = None
4750         compute_utils.notify_usage_exists(self.notifier, context, instance,
4751                                           current_period=True)
4752         self._notify_about_instance_usage(context, instance, 'shelve.start')
4753         compute_utils.notify_about_instance_action(context, instance,
4754                 self.host, action=fields.NotificationAction.SHELVE,
4755                 phase=fields.NotificationPhase.START, bdms=bdms)
4756 
4757         def update_task_state(task_state, expected_state=task_states.SHELVING):
4758             shelving_state_map = {
4759                     task_states.IMAGE_PENDING_UPLOAD:
4760                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4761                     task_states.IMAGE_UPLOADING:
4762                         task_states.SHELVING_IMAGE_UPLOADING,
4763                     task_states.SHELVING: task_states.SHELVING}
4764             task_state = shelving_state_map[task_state]
4765             expected_state = shelving_state_map[expected_state]
4766             instance.task_state = task_state
4767             instance.save(expected_task_state=expected_state)
4768 
4769         self._power_off_instance(context, instance, clean_shutdown)
4770         self.driver.snapshot(context, instance, image_id, update_task_state)
4771 
4772         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4773         instance.system_metadata['shelved_image_id'] = image_id
4774         instance.system_metadata['shelved_host'] = self.host
4775         instance.vm_state = vm_states.SHELVED
4776         instance.task_state = None
4777         if CONF.shelved_offload_time == 0:
4778             instance.task_state = task_states.SHELVING_OFFLOADING
4779         instance.power_state = self._get_power_state(context, instance)
4780         instance.save(expected_task_state=[
4781                 task_states.SHELVING,
4782                 task_states.SHELVING_IMAGE_UPLOADING])
4783 
4784         self._notify_about_instance_usage(context, instance, 'shelve.end')
4785         compute_utils.notify_about_instance_action(context, instance,
4786                 self.host, action=fields.NotificationAction.SHELVE,
4787                 phase=fields.NotificationPhase.END, bdms=bdms)
4788 
4789         if offload:
4790             self._shelve_offload_instance(context, instance,
4791                                           clean_shutdown=False, bdms=bdms)
4792 
4793     @wrap_exception()
4794     @reverts_task_state
4795     @wrap_instance_event(prefix='compute')
4796     @wrap_instance_fault
4797     def shelve_offload_instance(self, context, instance, clean_shutdown):
4798         """Remove a shelved instance from the hypervisor.
4799 
4800         This frees up those resources for use by other instances, but may lead
4801         to slower unshelve times for this instance.  This method is used by
4802         volume backed instances since restoring them doesn't involve the
4803         potentially large download of an image.
4804 
4805         :param context: request context
4806         :param instance: nova.objects.instance.Instance
4807         :param clean_shutdown: give the GuestOS a chance to stop
4808         """
4809 
4810         @utils.synchronized(instance.uuid)
4811         def do_shelve_offload_instance():
4812             self._shelve_offload_instance(context, instance, clean_shutdown)
4813         do_shelve_offload_instance()
4814 
4815     def _shelve_offload_instance(self, context, instance, clean_shutdown,
4816                                  bdms=None):
4817         LOG.info('Shelve offloading', instance=instance)
4818         if bdms is None:
4819             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4820                 context, instance.uuid)
4821         self._notify_about_instance_usage(context, instance,
4822                 'shelve_offload.start')
4823         compute_utils.notify_about_instance_action(context, instance,
4824                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4825                 phase=fields.NotificationPhase.START, bdms=bdms)
4826 
4827         self._power_off_instance(context, instance, clean_shutdown)
4828         current_power_state = self._get_power_state(context, instance)
4829 
4830         self.network_api.cleanup_instance_network_on_host(context, instance,
4831                                                           instance.host)
4832         network_info = self.network_api.get_instance_nw_info(context, instance)
4833 
4834         block_device_info = self._get_instance_block_device_info(context,
4835                                                                  instance,
4836                                                                  bdms=bdms)
4837         self.driver.destroy(context, instance, network_info,
4838                 block_device_info)
4839 
4840         # the instance is going to be removed from the host so we want to
4841         # terminate all the connections with the volume server and the host
4842         self._terminate_volume_connections(context, instance, bdms)
4843 
4844         instance.power_state = current_power_state
4845         # NOTE(mriedem): The vm_state has to be set before updating the
4846         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
4847         # values cannot be nulled out until after updating the resource tracker
4848         # though.
4849         instance.vm_state = vm_states.SHELVED_OFFLOADED
4850         instance.task_state = None
4851         instance.save(expected_task_state=[task_states.SHELVING,
4852                                            task_states.SHELVING_OFFLOADING])
4853 
4854         # NOTE(ndipanov): Free resources from the resource tracker
4855         self._update_resource_tracker(context, instance)
4856 
4857         rt = self._get_resource_tracker()
4858         rt.delete_allocation_for_shelve_offloaded_instance(context, instance)
4859 
4860         # NOTE(sfinucan): RPC calls should no longer be attempted against this
4861         # instance, so ensure any calls result in errors
4862         self._nil_out_instance_obj_host_and_node(instance)
4863         instance.save(expected_task_state=None)
4864 
4865         self._delete_scheduler_instance_info(context, instance.uuid)
4866         self._notify_about_instance_usage(context, instance,
4867                 'shelve_offload.end')
4868         compute_utils.notify_about_instance_action(context, instance,
4869                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4870                 phase=fields.NotificationPhase.END, bdms=bdms)
4871 
4872     @wrap_exception()
4873     @reverts_task_state
4874     @wrap_instance_event(prefix='compute')
4875     @wrap_instance_fault
4876     def unshelve_instance(self, context, instance, image,
4877                           filter_properties, node):
4878         """Unshelve the instance.
4879 
4880         :param context: request context
4881         :param instance: a nova.objects.instance.Instance object
4882         :param image: an image to build from.  If None we assume a
4883             volume backed instance.
4884         :param filter_properties: dict containing limits, retry info etc.
4885         :param node: target compute node
4886         """
4887         if filter_properties is None:
4888             filter_properties = {}
4889 
4890         @utils.synchronized(instance.uuid)
4891         def do_unshelve_instance():
4892             self._unshelve_instance(context, instance, image,
4893                                     filter_properties, node)
4894         do_unshelve_instance()
4895 
4896     def _unshelve_instance_key_scrub(self, instance):
4897         """Remove data from the instance that may cause side effects."""
4898         cleaned_keys = dict(
4899                 key_data=instance.key_data,
4900                 auto_disk_config=instance.auto_disk_config)
4901         instance.key_data = None
4902         instance.auto_disk_config = False
4903         return cleaned_keys
4904 
4905     def _unshelve_instance_key_restore(self, instance, keys):
4906         """Restore previously scrubbed keys before saving the instance."""
4907         instance.update(keys)
4908 
4909     def _unshelve_instance(self, context, instance, image, filter_properties,
4910                            node):
4911         LOG.info('Unshelving', instance=instance)
4912         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4913                 context, instance.uuid)
4914 
4915         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4916         compute_utils.notify_about_instance_action(context, instance,
4917                 self.host, action=fields.NotificationAction.UNSHELVE,
4918                 phase=fields.NotificationPhase.START, bdms=bdms)
4919 
4920         instance.task_state = task_states.SPAWNING
4921         instance.save()
4922 
4923         block_device_info = self._prep_block_device(context, instance, bdms)
4924         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4925 
4926         if node is None:
4927             node = self._get_nodename(instance)
4928 
4929         rt = self._get_resource_tracker()
4930         limits = filter_properties.get('limits', {})
4931 
4932         allocations = self.reportclient.get_allocations_for_consumer(
4933             context, instance.uuid)
4934 
4935         shelved_image_ref = instance.image_ref
4936         if image:
4937             instance.image_ref = image['id']
4938             image_meta = objects.ImageMeta.from_dict(image)
4939         else:
4940             image_meta = objects.ImageMeta.from_dict(
4941                 utils.get_image_from_system_metadata(
4942                     instance.system_metadata))
4943 
4944         self.network_api.setup_instance_network_on_host(context, instance,
4945                                                         self.host)
4946         network_info = self.network_api.get_instance_nw_info(context, instance)
4947         try:
4948             with rt.instance_claim(context, instance, node, limits):
4949                 self.driver.spawn(context, instance, image_meta,
4950                                   injected_files=[],
4951                                   admin_password=None,
4952                                   allocations=allocations,
4953                                   network_info=network_info,
4954                                   block_device_info=block_device_info)
4955         except Exception:
4956             with excutils.save_and_reraise_exception(logger=LOG):
4957                 LOG.exception('Instance failed to spawn',
4958                               instance=instance)
4959                 # Cleanup allocations created by the scheduler on this host
4960                 # since we failed to spawn the instance. We do this both if
4961                 # the instance claim failed with ComputeResourcesUnavailable
4962                 # or if we did claim but the spawn failed, because aborting the
4963                 # instance claim will not remove the allocations.
4964                 rt.reportclient.delete_allocation_for_instance(context,
4965                                                                instance.uuid)
4966                 # FIXME: Umm, shouldn't we be rolling back port bindings too?
4967                 self._terminate_volume_connections(context, instance, bdms)
4968                 # The reverts_task_state decorator on unshelve_instance will
4969                 # eventually save these updates.
4970                 self._nil_out_instance_obj_host_and_node(instance)
4971 
4972         if image:
4973             instance.image_ref = shelved_image_ref
4974             self._delete_snapshot_of_shelved_instance(context, instance,
4975                                                       image['id'])
4976 
4977         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4978         self._update_instance_after_spawn(context, instance)
4979         # Delete system_metadata for a shelved instance
4980         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4981 
4982         instance.save(expected_task_state=task_states.SPAWNING)
4983         self._update_scheduler_instance_info(context, instance)
4984         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4985         compute_utils.notify_about_instance_action(context, instance,
4986                 self.host, action=fields.NotificationAction.UNSHELVE,
4987                 phase=fields.NotificationPhase.END, bdms=bdms)
4988 
4989     @messaging.expected_exceptions(NotImplementedError)
4990     @wrap_instance_fault
4991     def reset_network(self, context, instance):
4992         """Reset networking on the given instance."""
4993         LOG.debug('Reset network', instance=instance)
4994         self.driver.reset_network(instance)
4995 
4996     def _inject_network_info(self, context, instance, network_info):
4997         """Inject network info for the given instance."""
4998         LOG.debug('Inject network info', instance=instance)
4999         LOG.debug('network_info to inject: |%s|', network_info,
5000                   instance=instance)
5001 
5002         self.driver.inject_network_info(instance,
5003                                         network_info)
5004 
5005     @wrap_instance_fault
5006     def inject_network_info(self, context, instance):
5007         """Inject network info, but don't return the info."""
5008         network_info = self.network_api.get_instance_nw_info(context, instance)
5009         self._inject_network_info(context, instance, network_info)
5010 
5011     @messaging.expected_exceptions(NotImplementedError,
5012                                    exception.ConsoleNotAvailable,
5013                                    exception.InstanceNotFound)
5014     @wrap_exception()
5015     @wrap_instance_fault
5016     def get_console_output(self, context, instance, tail_length):
5017         """Send the console output for the given instance."""
5018         context = context.elevated()
5019         LOG.info("Get console output", instance=instance)
5020         output = self.driver.get_console_output(context, instance)
5021 
5022         if type(output) is six.text_type:
5023             output = six.b(output)
5024 
5025         if tail_length is not None:
5026             output = self._tail_log(output, tail_length)
5027 
5028         return output.decode('ascii', 'replace')
5029 
5030     def _tail_log(self, log, length):
5031         try:
5032             length = int(length)
5033         except ValueError:
5034             length = 0
5035 
5036         if length == 0:
5037             return b''
5038         else:
5039             return b'\n'.join(log.split(b'\n')[-int(length):])
5040 
5041     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5042                                    exception.InstanceNotReady,
5043                                    exception.InstanceNotFound,
5044                                    exception.ConsoleTypeUnavailable,
5045                                    NotImplementedError)
5046     @wrap_exception()
5047     @wrap_instance_fault
5048     def get_vnc_console(self, context, console_type, instance):
5049         """Return connection information for a vnc console."""
5050         context = context.elevated()
5051         LOG.debug("Getting vnc console", instance=instance)
5052         token = uuidutils.generate_uuid()
5053 
5054         if not CONF.vnc.enabled:
5055             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5056 
5057         if console_type == 'novnc':
5058             # For essex, novncproxy_base_url must include the full path
5059             # including the html file (like http://myhost/vnc_auto.html)
5060             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
5061         elif console_type == 'xvpvnc':
5062             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
5063         else:
5064             raise exception.ConsoleTypeInvalid(console_type=console_type)
5065 
5066         try:
5067             # Retrieve connect info from driver, and then decorate with our
5068             # access info token
5069             console = self.driver.get_vnc_console(context, instance)
5070             connect_info = console.get_connection_info(token, access_url)
5071         except exception.InstanceNotFound:
5072             if instance.vm_state != vm_states.BUILDING:
5073                 raise
5074             raise exception.InstanceNotReady(instance_id=instance.uuid)
5075 
5076         return connect_info
5077 
5078     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5079                                    exception.InstanceNotReady,
5080                                    exception.InstanceNotFound,
5081                                    exception.ConsoleTypeUnavailable,
5082                                    NotImplementedError)
5083     @wrap_exception()
5084     @wrap_instance_fault
5085     def get_spice_console(self, context, console_type, instance):
5086         """Return connection information for a spice console."""
5087         context = context.elevated()
5088         LOG.debug("Getting spice console", instance=instance)
5089         token = uuidutils.generate_uuid()
5090 
5091         if not CONF.spice.enabled:
5092             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5093 
5094         if console_type == 'spice-html5':
5095             # For essex, spicehtml5proxy_base_url must include the full path
5096             # including the html file (like http://myhost/spice_auto.html)
5097             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
5098                                           token)
5099         else:
5100             raise exception.ConsoleTypeInvalid(console_type=console_type)
5101 
5102         try:
5103             # Retrieve connect info from driver, and then decorate with our
5104             # access info token
5105             console = self.driver.get_spice_console(context, instance)
5106             connect_info = console.get_connection_info(token, access_url)
5107         except exception.InstanceNotFound:
5108             if instance.vm_state != vm_states.BUILDING:
5109                 raise
5110             raise exception.InstanceNotReady(instance_id=instance.uuid)
5111 
5112         return connect_info
5113 
5114     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5115                                    exception.InstanceNotReady,
5116                                    exception.InstanceNotFound,
5117                                    exception.ConsoleTypeUnavailable,
5118                                    NotImplementedError)
5119     @wrap_exception()
5120     @wrap_instance_fault
5121     def get_rdp_console(self, context, console_type, instance):
5122         """Return connection information for a RDP console."""
5123         context = context.elevated()
5124         LOG.debug("Getting RDP console", instance=instance)
5125         token = uuidutils.generate_uuid()
5126 
5127         if not CONF.rdp.enabled:
5128             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5129 
5130         if console_type == 'rdp-html5':
5131             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
5132                                           token)
5133         else:
5134             raise exception.ConsoleTypeInvalid(console_type=console_type)
5135 
5136         try:
5137             # Retrieve connect info from driver, and then decorate with our
5138             # access info token
5139             console = self.driver.get_rdp_console(context, instance)
5140             connect_info = console.get_connection_info(token, access_url)
5141         except exception.InstanceNotFound:
5142             if instance.vm_state != vm_states.BUILDING:
5143                 raise
5144             raise exception.InstanceNotReady(instance_id=instance.uuid)
5145 
5146         return connect_info
5147 
5148     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5149                                    exception.InstanceNotReady,
5150                                    exception.InstanceNotFound,
5151                                    exception.ConsoleTypeUnavailable,
5152                                    NotImplementedError)
5153     @wrap_exception()
5154     @wrap_instance_fault
5155     def get_mks_console(self, context, console_type, instance):
5156         """Return connection information for a MKS console."""
5157         context = context.elevated()
5158         LOG.debug("Getting MKS console", instance=instance)
5159         token = uuidutils.generate_uuid()
5160 
5161         if not CONF.mks.enabled:
5162             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5163 
5164         if console_type == 'webmks':
5165             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
5166                                           token)
5167         else:
5168             raise exception.ConsoleTypeInvalid(console_type=console_type)
5169 
5170         try:
5171             # Retrieve connect info from driver, and then decorate with our
5172             # access info token
5173             console = self.driver.get_mks_console(context, instance)
5174             connect_info = console.get_connection_info(token, access_url)
5175         except exception.InstanceNotFound:
5176             if instance.vm_state != vm_states.BUILDING:
5177                 raise
5178             raise exception.InstanceNotReady(instance_id=instance.uuid)
5179 
5180         return connect_info
5181 
5182     @messaging.expected_exceptions(
5183         exception.ConsoleTypeInvalid,
5184         exception.InstanceNotReady,
5185         exception.InstanceNotFound,
5186         exception.ConsoleTypeUnavailable,
5187         exception.SocketPortRangeExhaustedException,
5188         exception.ImageSerialPortNumberInvalid,
5189         exception.ImageSerialPortNumberExceedFlavorValue,
5190         NotImplementedError)
5191     @wrap_exception()
5192     @wrap_instance_fault
5193     def get_serial_console(self, context, console_type, instance):
5194         """Returns connection information for a serial console."""
5195 
5196         LOG.debug("Getting serial console", instance=instance)
5197 
5198         if not CONF.serial_console.enabled:
5199             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5200 
5201         context = context.elevated()
5202 
5203         token = uuidutils.generate_uuid()
5204         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
5205 
5206         try:
5207             # Retrieve connect info from driver, and then decorate with our
5208             # access info token
5209             console = self.driver.get_serial_console(context, instance)
5210             connect_info = console.get_connection_info(token, access_url)
5211         except exception.InstanceNotFound:
5212             if instance.vm_state != vm_states.BUILDING:
5213                 raise
5214             raise exception.InstanceNotReady(instance_id=instance.uuid)
5215 
5216         return connect_info
5217 
5218     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5219                                    exception.InstanceNotReady,
5220                                    exception.InstanceNotFound)
5221     @wrap_exception()
5222     @wrap_instance_fault
5223     def validate_console_port(self, ctxt, instance, port, console_type):
5224         if console_type == "spice-html5":
5225             console_info = self.driver.get_spice_console(ctxt, instance)
5226         elif console_type == "rdp-html5":
5227             console_info = self.driver.get_rdp_console(ctxt, instance)
5228         elif console_type == "serial":
5229             console_info = self.driver.get_serial_console(ctxt, instance)
5230         elif console_type == "webmks":
5231             console_info = self.driver.get_mks_console(ctxt, instance)
5232         else:
5233             console_info = self.driver.get_vnc_console(ctxt, instance)
5234 
5235         return console_info.port == port
5236 
5237     @wrap_exception()
5238     @reverts_task_state
5239     @wrap_instance_fault
5240     def reserve_block_device_name(self, context, instance, device,
5241                                   volume_id, disk_bus, device_type, tag,
5242                                   multiattach):
5243         if (tag and not
5244                 self.driver.capabilities.get('supports_tagged_attach_volume',
5245                                              False)):
5246             raise exception.VolumeTaggedAttachNotSupported()
5247 
5248         if (multiattach and not
5249                 self.driver.capabilities.get('supports_multiattach', False)):
5250             raise exception.MultiattachNotSupportedByVirtDriver(
5251                 volume_id=volume_id)
5252 
5253         @utils.synchronized(instance.uuid)
5254         def do_reserve():
5255             bdms = (
5256                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5257                     context, instance.uuid))
5258 
5259             # NOTE(ndipanov): We need to explicitly set all the fields on the
5260             #                 object so that obj_load_attr does not fail
5261             new_bdm = objects.BlockDeviceMapping(
5262                     context=context,
5263                     source_type='volume', destination_type='volume',
5264                     instance_uuid=instance.uuid, boot_index=None,
5265                     volume_id=volume_id,
5266                     device_name=device, guest_format=None,
5267                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5268 
5269             new_bdm.device_name = self._get_device_name_for_instance(
5270                     instance, bdms, new_bdm)
5271 
5272             # NOTE(vish): create bdm here to avoid race condition
5273             new_bdm.create()
5274             return new_bdm
5275 
5276         return do_reserve()
5277 
5278     @wrap_exception()
5279     @wrap_instance_event(prefix='compute')
5280     @wrap_instance_fault
5281     def attach_volume(self, context, instance, bdm):
5282         """Attach a volume to an instance."""
5283         driver_bdm = driver_block_device.convert_volume(bdm)
5284 
5285         @utils.synchronized(instance.uuid)
5286         def do_attach_volume(context, instance, driver_bdm):
5287             try:
5288                 return self._attach_volume(context, instance, driver_bdm)
5289             except Exception:
5290                 with excutils.save_and_reraise_exception():
5291                     bdm.destroy()
5292 
5293         do_attach_volume(context, instance, driver_bdm)
5294 
5295     def _attach_volume(self, context, instance, bdm):
5296         context = context.elevated()
5297         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5298                  {'volume_id': bdm.volume_id,
5299                   'mountpoint': bdm['mount_device']},
5300                  instance=instance)
5301         compute_utils.notify_about_volume_attach_detach(
5302             context, instance, self.host,
5303             action=fields.NotificationAction.VOLUME_ATTACH,
5304             phase=fields.NotificationPhase.START,
5305             volume_id=bdm.volume_id)
5306         try:
5307             bdm.attach(context, instance, self.volume_api, self.driver,
5308                        do_driver_attach=True)
5309         except Exception as e:
5310             with excutils.save_and_reraise_exception():
5311                 LOG.exception("Failed to attach %(volume_id)s "
5312                               "at %(mountpoint)s",
5313                               {'volume_id': bdm.volume_id,
5314                                'mountpoint': bdm['mount_device']},
5315                               instance=instance)
5316                 if bdm['attachment_id']:
5317                     self.volume_api.attachment_delete(context,
5318                                                       bdm['attachment_id'])
5319                 else:
5320                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5321                 compute_utils.notify_about_volume_attach_detach(
5322                     context, instance, self.host,
5323                     action=fields.NotificationAction.VOLUME_ATTACH,
5324                     phase=fields.NotificationPhase.ERROR,
5325                     exception=e,
5326                     volume_id=bdm.volume_id)
5327 
5328         info = {'volume_id': bdm.volume_id}
5329         self._notify_about_instance_usage(
5330             context, instance, "volume.attach", extra_usage_info=info)
5331         compute_utils.notify_about_volume_attach_detach(
5332             context, instance, self.host,
5333             action=fields.NotificationAction.VOLUME_ATTACH,
5334             phase=fields.NotificationPhase.END,
5335             volume_id=bdm.volume_id)
5336 
5337     def _notify_volume_usage_detach(self, context, instance, bdm):
5338         if CONF.volume_usage_poll_interval <= 0:
5339             return
5340 
5341         vol_stats = []
5342         mp = bdm.device_name
5343         # Handle bootable volumes which will not contain /dev/
5344         if '/dev/' in mp:
5345             mp = mp[5:]
5346         try:
5347             vol_stats = self.driver.block_stats(instance, mp)
5348         except NotImplementedError:
5349             return
5350 
5351         LOG.debug("Updating volume usage cache with totals", instance=instance)
5352         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5353         vol_usage = objects.VolumeUsage(context)
5354         vol_usage.volume_id = bdm.volume_id
5355         vol_usage.instance_uuid = instance.uuid
5356         vol_usage.project_id = instance.project_id
5357         vol_usage.user_id = instance.user_id
5358         vol_usage.availability_zone = instance.availability_zone
5359         vol_usage.curr_reads = rd_req
5360         vol_usage.curr_read_bytes = rd_bytes
5361         vol_usage.curr_writes = wr_req
5362         vol_usage.curr_write_bytes = wr_bytes
5363         vol_usage.save(update_totals=True)
5364         self.notifier.info(context, 'volume.usage',
5365                            compute_utils.usage_volume_info(vol_usage))
5366 
5367     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5368                        attachment_id=None):
5369         """Detach a volume from an instance.
5370 
5371         :param context: security context
5372         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5373         :param instance: the Instance object to detach the volume from
5374         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5375                             as deleted. Disabling this is useful for operations
5376                             like rebuild, when we don't want to destroy BDM
5377         :param attachment_id: The volume attachment_id for the given instance
5378                               and volume.
5379         """
5380         volume_id = bdm.volume_id
5381         compute_utils.notify_about_volume_attach_detach(
5382             context, instance, self.host,
5383             action=fields.NotificationAction.VOLUME_DETACH,
5384             phase=fields.NotificationPhase.START,
5385             volume_id=volume_id)
5386 
5387         self._notify_volume_usage_detach(context, instance, bdm)
5388 
5389         LOG.info('Detaching volume %(volume_id)s',
5390                  {'volume_id': volume_id}, instance=instance)
5391 
5392         driver_bdm = driver_block_device.convert_volume(bdm)
5393         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5394                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5395 
5396         info = dict(volume_id=volume_id)
5397         self._notify_about_instance_usage(
5398             context, instance, "volume.detach", extra_usage_info=info)
5399         compute_utils.notify_about_volume_attach_detach(
5400             context, instance, self.host,
5401             action=fields.NotificationAction.VOLUME_DETACH,
5402             phase=fields.NotificationPhase.END,
5403             volume_id=volume_id)
5404 
5405         if 'tag' in bdm and bdm.tag:
5406             self._delete_disk_metadata(instance, bdm)
5407         if destroy_bdm:
5408             bdm.destroy()
5409 
5410     def _delete_disk_metadata(self, instance, bdm):
5411         for device in instance.device_metadata.devices:
5412             if isinstance(device, objects.DiskMetadata):
5413                 if 'serial' in device:
5414                     if device.serial == bdm.volume_id:
5415                         instance.device_metadata.devices.remove(device)
5416                         instance.save()
5417                         break
5418                 else:
5419                     # NOTE(artom) We log the entire device object because all
5420                     # fields are nullable and may not be set
5421                     LOG.warning('Unable to determine whether to clean up '
5422                                 'device metadata for disk %s', device,
5423                                 instance=instance)
5424 
5425     @wrap_exception()
5426     @wrap_instance_event(prefix='compute')
5427     @wrap_instance_fault
5428     def detach_volume(self, context, volume_id, instance, attachment_id):
5429         """Detach a volume from an instance.
5430 
5431         :param context: security context
5432         :param volume_id: the volume id
5433         :param instance: the Instance object to detach the volume from
5434         :param attachment_id: The volume attachment_id for the given instance
5435                               and volume.
5436 
5437         """
5438         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5439                 context, volume_id, instance.uuid)
5440         self._detach_volume(context, bdm, instance,
5441                             attachment_id=attachment_id)
5442 
5443     def _init_volume_connection(self, context, new_volume,
5444                                 old_volume_id, connector, bdm,
5445                                 new_attachment_id, mountpoint):
5446         new_volume_id = new_volume['id']
5447         if new_attachment_id is None:
5448             # We're dealing with an old-style attachment so initialize the
5449             # connection so we can get the connection_info.
5450             new_cinfo = self.volume_api.initialize_connection(context,
5451                                                               new_volume_id,
5452                                                               connector)
5453         else:
5454             # Check for multiattach on the new volume and if True, check to
5455             # see if the virt driver supports multiattach.
5456             # TODO(mriedem): This is copied from DriverVolumeBlockDevice
5457             # and should be consolidated into some common code at some point.
5458             vol_multiattach = new_volume.get('multiattach', False)
5459             virt_multiattach = self.driver.capabilities.get(
5460                 'supports_multiattach', False)
5461             if vol_multiattach and not virt_multiattach:
5462                 raise exception.MultiattachNotSupportedByVirtDriver(
5463                     volume_id=new_volume_id)
5464 
5465             # This is a new style attachment and the API created the new
5466             # volume attachment and passed the id to the compute over RPC.
5467             # At this point we need to update the new volume attachment with
5468             # the host connector, which will give us back the new attachment
5469             # connection_info.
5470             new_cinfo = self.volume_api.attachment_update(
5471                 context, new_attachment_id, connector,
5472                 mountpoint)['connection_info']
5473 
5474             if vol_multiattach:
5475                 # This will be used by the volume driver to determine the
5476                 # proper disk configuration.
5477                 new_cinfo['multiattach'] = True
5478 
5479         old_cinfo = jsonutils.loads(bdm['connection_info'])
5480         if old_cinfo and 'serial' not in old_cinfo:
5481             old_cinfo['serial'] = old_volume_id
5482         # NOTE(lyarwood): serial is not always present in the returned
5483         # connection_info so set it if it is missing as we do in
5484         # DriverVolumeBlockDevice.attach().
5485         if 'serial' not in new_cinfo:
5486             new_cinfo['serial'] = new_volume_id
5487         return (old_cinfo, new_cinfo)
5488 
5489     def _swap_volume(self, context, instance, bdm, connector,
5490                      old_volume_id, new_volume, resize_to,
5491                      new_attachment_id, is_cinder_migration):
5492         new_volume_id = new_volume['id']
5493         mountpoint = bdm['device_name']
5494         failed = False
5495         new_cinfo = None
5496         try:
5497             old_cinfo, new_cinfo = self._init_volume_connection(
5498                 context, new_volume, old_volume_id, connector,
5499                 bdm, new_attachment_id, mountpoint)
5500             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5501             # currently implementing swap_volume, will modify the contents of
5502             # new_cinfo when connect_volume is called. This is then saved to
5503             # the BDM in swap_volume for future use outside of this flow.
5504             LOG.debug("swap_volume: Calling driver volume swap with "
5505                       "connection infos: new: %(new_cinfo)s; "
5506                       "old: %(old_cinfo)s",
5507                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo},
5508                       instance=instance)
5509             self.driver.swap_volume(context, old_cinfo, new_cinfo, instance,
5510                                     mountpoint, resize_to)
5511             if new_attachment_id:
5512                 self.volume_api.attachment_complete(context, new_attachment_id)
5513             LOG.debug("swap_volume: Driver volume swap returned, new "
5514                       "connection_info is now : %(new_cinfo)s",
5515                       {'new_cinfo': new_cinfo})
5516         except Exception as ex:
5517             failed = True
5518             with excutils.save_and_reraise_exception():
5519                 compute_utils.notify_about_volume_swap(
5520                     context, instance, self.host,
5521                     fields.NotificationPhase.ERROR,
5522                     old_volume_id, new_volume_id, ex)
5523                 if new_cinfo:
5524                     msg = ("Failed to swap volume %(old_volume_id)s "
5525                            "for %(new_volume_id)s")
5526                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5527                                         'new_volume_id': new_volume_id},
5528                                   instance=instance)
5529                 else:
5530                     msg = ("Failed to connect to volume %(volume_id)s "
5531                            "with volume at %(mountpoint)s")
5532                     LOG.exception(msg, {'volume_id': new_volume_id,
5533                                         'mountpoint': bdm['device_name']},
5534                                   instance=instance)
5535 
5536                 # The API marked the volume as 'detaching' for the old volume
5537                 # so we need to roll that back so the volume goes back to
5538                 # 'in-use' state.
5539                 self.volume_api.roll_detaching(context, old_volume_id)
5540 
5541                 if new_attachment_id is None:
5542                     # The API reserved the new volume so it would be in
5543                     # 'attaching' status, so we need to unreserve it so it
5544                     # goes back to 'available' status.
5545                     self.volume_api.unreserve_volume(context, new_volume_id)
5546                 else:
5547                     # This is a new style attachment for the new volume, which
5548                     # was created in the API. We just need to delete it here
5549                     # to put the new volume back into 'available' status.
5550                     self.volume_api.attachment_delete(
5551                         context, new_attachment_id)
5552         finally:
5553             # TODO(mriedem): This finally block is terribly confusing and is
5554             # trying to do too much. We should consider removing the finally
5555             # block and move whatever needs to happen on success and failure
5556             # into the blocks above for clarity, even if it means a bit of
5557             # redundant code.
5558             conn_volume = new_volume_id if failed else old_volume_id
5559             if new_cinfo:
5560                 LOG.debug("swap_volume: removing Cinder connection "
5561                           "for volume %(volume)s", {'volume': conn_volume},
5562                           instance=instance)
5563                 if bdm.attachment_id is None:
5564                     # This is the pre-3.44 flow for new-style volume
5565                     # attachments so just terminate the connection.
5566                     self.volume_api.terminate_connection(context,
5567                                                          conn_volume,
5568                                                          connector)
5569                 else:
5570                     # This is a new style volume attachment. If we failed, then
5571                     # the new attachment was already deleted above in the
5572                     # exception block and we have nothing more to do here. If
5573                     # swap_volume was successful in the driver, then we need to
5574                     # "detach" the original attachment by deleting it.
5575                     if not failed:
5576                         self.volume_api.attachment_delete(
5577                             context, bdm.attachment_id)
5578 
5579             # Need to make some decisions based on whether this was
5580             # a Cinder initiated migration or not. The callback to
5581             # migration completion isn't needed in the case of a
5582             # nova initiated simple swap of two volume
5583             # "volume-update" call so skip that. The new attachment
5584             # scenarios will give us a new attachment record and
5585             # that's what we want.
5586             if bdm.attachment_id and not is_cinder_migration:
5587                 # we don't callback to cinder
5588                 comp_ret = {'save_volume_id': new_volume_id}
5589             else:
5590                 # NOTE(lyarwood): The following call to
5591                 # os-migrate-volume-completion returns a dict containing
5592                 # save_volume_id, this volume id has two possible values :
5593                 # 1. old_volume_id if we are migrating (retyping) volumes
5594                 # 2. new_volume_id if we are swapping between two existing
5595                 #    volumes
5596                 # This volume id is later used to update the volume_id and
5597                 # connection_info['serial'] of the BDM.
5598                 comp_ret = self.volume_api.migrate_volume_completion(
5599                                                           context,
5600                                                           old_volume_id,
5601                                                           new_volume_id,
5602                                                           error=failed)
5603                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5604                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5605                           instance=instance)
5606 
5607         return (comp_ret, new_cinfo)
5608 
5609     @wrap_exception()
5610     @wrap_instance_event(prefix='compute')
5611     @wrap_instance_fault
5612     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
5613                     new_attachment_id):
5614         """Swap volume for an instance."""
5615         context = context.elevated()
5616 
5617         compute_utils.notify_about_volume_swap(
5618             context, instance, self.host,
5619             fields.NotificationPhase.START,
5620             old_volume_id, new_volume_id)
5621 
5622         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5623                 context, old_volume_id, instance.uuid)
5624         connector = self.driver.get_volume_connector(instance)
5625 
5626         resize_to = 0
5627         old_volume = self.volume_api.get(context, old_volume_id)
5628         # Yes this is a tightly-coupled state check of what's going on inside
5629         # cinder, but we need this while we still support old (v1/v2) and
5630         # new style attachments (v3.44). Once we drop support for old style
5631         # attachments we could think about cleaning up the cinder-initiated
5632         # swap volume API flows.
5633         is_cinder_migration = (
5634             True if old_volume['status'] in ('retyping',
5635                                              'migrating') else False)
5636         old_vol_size = old_volume['size']
5637         new_volume = self.volume_api.get(context, new_volume_id)
5638         new_vol_size = new_volume['size']
5639         if new_vol_size > old_vol_size:
5640             resize_to = new_vol_size
5641 
5642         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5643                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5644                  instance=instance)
5645         comp_ret, new_cinfo = self._swap_volume(context,
5646                                                 instance,
5647                                                 bdm,
5648                                                 connector,
5649                                                 old_volume_id,
5650                                                 new_volume,
5651                                                 resize_to,
5652                                                 new_attachment_id,
5653                                                 is_cinder_migration)
5654 
5655         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5656         # correct volume_id returned by Cinder.
5657         save_volume_id = comp_ret['save_volume_id']
5658         new_cinfo['serial'] = save_volume_id
5659         values = {
5660             'connection_info': jsonutils.dumps(new_cinfo),
5661             'source_type': 'volume',
5662             'destination_type': 'volume',
5663             'snapshot_id': None,
5664             'volume_id': save_volume_id,
5665             'no_device': None}
5666 
5667         if resize_to:
5668             values['volume_size'] = resize_to
5669 
5670         if new_attachment_id is not None:
5671             # This was a volume swap for a new-style attachment so we
5672             # need to update the BDM attachment_id for the new attachment.
5673             values['attachment_id'] = new_attachment_id
5674 
5675         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5676                   "%(updates)s", {'volume_id': bdm.volume_id,
5677                                   'updates': values},
5678                   instance=instance)
5679         bdm.update(values)
5680         bdm.save()
5681 
5682         compute_utils.notify_about_volume_swap(
5683             context, instance, self.host,
5684             fields.NotificationPhase.END,
5685             old_volume_id, new_volume_id)
5686 
5687     @wrap_exception()
5688     def remove_volume_connection(self, context, volume_id, instance):
5689         """Remove the volume connection on this host
5690 
5691         Detach the volume from this instance on this host, and if this is
5692         the cinder v2 flow, call cinder to terminate the connection.
5693         """
5694         try:
5695             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5696                     context, volume_id, instance.uuid)
5697             driver_bdm = driver_block_device.convert_volume(bdm)
5698             driver_bdm.driver_detach(context, instance,
5699                                      self.volume_api, self.driver)
5700             if bdm.attachment_id is None:
5701                 # cinder v2 api flow
5702                 connector = self.driver.get_volume_connector(instance)
5703                 self.volume_api.terminate_connection(context, volume_id,
5704                                                      connector)
5705         except exception.NotFound:
5706             pass
5707 
5708     @wrap_exception()
5709     @wrap_instance_event(prefix='compute')
5710     @wrap_instance_fault
5711     def attach_interface(self, context, instance, network_id, port_id,
5712                          requested_ip, tag):
5713         """Use hotplug to add an network adapter to an instance."""
5714         if not self.driver.capabilities.get('supports_attach_interface',
5715                                             False):
5716             raise exception.AttachInterfaceNotSupported(
5717                 instance_uuid=instance.uuid)
5718         if (tag and not
5719             self.driver.capabilities.get('supports_tagged_attach_interface',
5720                                          False)):
5721             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5722 
5723         compute_utils.notify_about_instance_action(
5724             context, instance, self.host,
5725             action=fields.NotificationAction.INTERFACE_ATTACH,
5726             phase=fields.NotificationPhase.START)
5727 
5728         bind_host_id = self.driver.network_binding_host_id(context, instance)
5729         network_info = self.network_api.allocate_port_for_instance(
5730             context, instance, port_id, network_id, requested_ip,
5731             bind_host_id=bind_host_id, tag=tag)
5732         if len(network_info) != 1:
5733             LOG.error('allocate_port_for_instance returned %(ports)s '
5734                       'ports', {'ports': len(network_info)})
5735             # TODO(elod.illes): an instance.interface_attach.error notification
5736             # should be sent here
5737             raise exception.InterfaceAttachFailed(
5738                     instance_uuid=instance.uuid)
5739         image_meta = objects.ImageMeta.from_instance(instance)
5740 
5741         try:
5742             self.driver.attach_interface(context, instance, image_meta,
5743                                          network_info[0])
5744         except exception.NovaException as ex:
5745             port_id = network_info[0].get('id')
5746             LOG.warning("attach interface failed , try to deallocate "
5747                         "port %(port_id)s, reason: %(msg)s",
5748                         {'port_id': port_id, 'msg': ex},
5749                         instance=instance)
5750             try:
5751                 self.network_api.deallocate_port_for_instance(
5752                     context, instance, port_id)
5753             except Exception:
5754                 LOG.warning("deallocate port %(port_id)s failed",
5755                             {'port_id': port_id}, instance=instance)
5756 
5757             compute_utils.notify_about_instance_action(
5758                 context, instance, self.host,
5759                 action=fields.NotificationAction.INTERFACE_ATTACH,
5760                 phase=fields.NotificationPhase.ERROR,
5761                 exception=ex)
5762 
5763             raise exception.InterfaceAttachFailed(
5764                 instance_uuid=instance.uuid)
5765 
5766         compute_utils.notify_about_instance_action(
5767             context, instance, self.host,
5768             action=fields.NotificationAction.INTERFACE_ATTACH,
5769             phase=fields.NotificationPhase.END)
5770 
5771         return network_info[0]
5772 
5773     @wrap_exception()
5774     @wrap_instance_event(prefix='compute')
5775     @wrap_instance_fault
5776     def detach_interface(self, context, instance, port_id):
5777         """Detach a network adapter from an instance."""
5778         network_info = instance.info_cache.network_info
5779         condemned = None
5780         for vif in network_info:
5781             if vif['id'] == port_id:
5782                 condemned = vif
5783                 break
5784         if condemned is None:
5785             raise exception.PortNotFound(_("Port %s is not "
5786                                            "attached") % port_id)
5787 
5788         compute_utils.notify_about_instance_action(
5789             context, instance, self.host,
5790             action=fields.NotificationAction.INTERFACE_DETACH,
5791             phase=fields.NotificationPhase.START)
5792 
5793         try:
5794             self.driver.detach_interface(context, instance, condemned)
5795         except exception.NovaException as ex:
5796             # If the instance was deleted before the interface was detached,
5797             # just log it at debug.
5798             log_level = (logging.DEBUG
5799                          if isinstance(ex, exception.InstanceNotFound)
5800                          else logging.WARNING)
5801             LOG.log(log_level,
5802                     "Detach interface failed, port_id=%(port_id)s, reason: "
5803                     "%(msg)s", {'port_id': port_id, 'msg': ex},
5804                     instance=instance)
5805             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5806         else:
5807             try:
5808                 self.network_api.deallocate_port_for_instance(
5809                     context, instance, port_id)
5810             except Exception as ex:
5811                 with excutils.save_and_reraise_exception():
5812                     # Since this is a cast operation, log the failure for
5813                     # triage.
5814                     LOG.warning('Failed to deallocate port %(port_id)s '
5815                                 'for instance. Error: %(error)s',
5816                                 {'port_id': port_id, 'error': ex},
5817                                 instance=instance)
5818 
5819         compute_utils.notify_about_instance_action(
5820             context, instance, self.host,
5821             action=fields.NotificationAction.INTERFACE_DETACH,
5822             phase=fields.NotificationPhase.END)
5823 
5824     def _get_compute_info(self, context, host):
5825         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5826             context, host)
5827 
5828     @wrap_exception()
5829     def check_instance_shared_storage(self, ctxt, instance, data):
5830         """Check if the instance files are shared
5831 
5832         :param ctxt: security context
5833         :param instance: dict of instance data
5834         :param data: result of driver.check_instance_shared_storage_local
5835 
5836         Returns True if instance disks located on shared storage and
5837         False otherwise.
5838         """
5839         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5840 
5841     @wrap_exception()
5842     @wrap_instance_event(prefix='compute')
5843     @wrap_instance_fault
5844     def check_can_live_migrate_destination(self, ctxt, instance,
5845                                            block_migration, disk_over_commit):
5846         """Check if it is possible to execute live migration.
5847 
5848         This runs checks on the destination host, and then calls
5849         back to the source host to check the results.
5850 
5851         :param context: security context
5852         :param instance: dict of instance data
5853         :param block_migration: if true, prepare for block migration
5854                                 if None, calculate it in driver
5855         :param disk_over_commit: if true, allow disk over commit
5856                                  if None, ignore disk usage checking
5857         :returns: a dict containing migration info
5858         """
5859         return self._do_check_can_live_migrate_destination(ctxt, instance,
5860                                                             block_migration,
5861                                                             disk_over_commit)
5862 
5863     def _do_check_can_live_migrate_destination(self, ctxt, instance,
5864                                                block_migration,
5865                                                disk_over_commit):
5866         src_compute_info = obj_base.obj_to_primitive(
5867             self._get_compute_info(ctxt, instance.host))
5868         dst_compute_info = obj_base.obj_to_primitive(
5869             self._get_compute_info(ctxt, CONF.host))
5870         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5871             instance, src_compute_info, dst_compute_info,
5872             block_migration, disk_over_commit)
5873         LOG.debug('destination check data is %s', dest_check_data)
5874         try:
5875             migrate_data = self.compute_rpcapi.\
5876                                 check_can_live_migrate_source(ctxt, instance,
5877                                                               dest_check_data)
5878         finally:
5879             self.driver.cleanup_live_migration_destination_check(ctxt,
5880                     dest_check_data)
5881         return migrate_data
5882 
5883     @wrap_exception()
5884     @wrap_instance_event(prefix='compute')
5885     @wrap_instance_fault
5886     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5887         """Check if it is possible to execute live migration.
5888 
5889         This checks if the live migration can succeed, based on the
5890         results from check_can_live_migrate_destination.
5891 
5892         :param ctxt: security context
5893         :param instance: dict of instance data
5894         :param dest_check_data: result of check_can_live_migrate_destination
5895         :returns: a dict containing migration info
5896         """
5897         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5898             ctxt, instance.uuid)
5899         is_volume_backed = compute_utils.is_volume_backed_instance(
5900             ctxt, instance, bdms)
5901         dest_check_data.is_volume_backed = is_volume_backed
5902         block_device_info = self._get_instance_block_device_info(
5903                             ctxt, instance, refresh_conn_info=False, bdms=bdms)
5904         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5905                                                            dest_check_data,
5906                                                            block_device_info)
5907         LOG.debug('source check data is %s', result)
5908         return result
5909 
5910     @wrap_exception()
5911     @wrap_instance_event(prefix='compute')
5912     @wrap_instance_fault
5913     def pre_live_migration(self, context, instance, block_migration, disk,
5914                            migrate_data):
5915         """Preparations for live migration at dest host.
5916 
5917         :param context: security context
5918         :param instance: dict of instance data
5919         :param block_migration: if true, prepare for block migration
5920         :param disk: disk info of instance
5921         :param migrate_data: A dict or LiveMigrateData object holding data
5922                              required for live migration without shared
5923                              storage.
5924         :returns: migrate_data containing additional migration info
5925         """
5926         LOG.debug('pre_live_migration data is %s', migrate_data)
5927 
5928         migrate_data.old_vol_attachment_ids = {}
5929         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5930             context, instance.uuid)
5931         try:
5932             connector = self.driver.get_volume_connector(instance)
5933             for bdm in bdms:
5934                 if bdm.is_volume and bdm.attachment_id is not None:
5935                     # This bdm uses the new cinder v3.44 API.
5936                     # We will create a new attachment for this
5937                     # volume on this migration destination host. The old
5938                     # attachment will be deleted on the source host
5939                     # when the migration succeeds. The old attachment_id
5940                     # is stored in dict with the key being the bdm.volume_id
5941                     # so it can be restored on rollback.
5942                     #
5943                     # Also note that attachment_update is not needed as we
5944                     # are providing the connector in the create call.
5945                     attach_ref = self.volume_api.attachment_create(
5946                         context, bdm.volume_id, bdm.instance_uuid,
5947                         connector=connector, mountpoint=bdm.device_name)
5948 
5949                     # save current attachment so we can detach it on success,
5950                     # or restore it on a rollback.
5951                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
5952                         bdm.attachment_id
5953 
5954                     # update the bdm with the new attachment_id.
5955                     bdm.attachment_id = attach_ref['id']
5956                     bdm.save()
5957         except Exception:
5958             # If we raise, migrate_data with the updated attachment ids
5959             # will not be returned to the source host for rollback.
5960             # So we need to rollback new attachments here.
5961             with excutils.save_and_reraise_exception():
5962                 old_attachments = migrate_data.old_vol_attachment_ids
5963                 for bdm in bdms:
5964                     if (bdm.is_volume and bdm.attachment_id is not None and
5965                             bdm.volume_id in old_attachments):
5966                         self.volume_api.attachment_delete(context,
5967                                                           bdm.attachment_id)
5968                         bdm.attachment_id = old_attachments[bdm.volume_id]
5969                         bdm.save()
5970 
5971         block_device_info = self._get_instance_block_device_info(
5972                             context, instance, refresh_conn_info=True,
5973                             bdms=bdms)
5974 
5975         network_info = self.network_api.get_instance_nw_info(context, instance)
5976         self._notify_about_instance_usage(
5977                      context, instance, "live_migration.pre.start",
5978                      network_info=network_info)
5979         compute_utils.notify_about_instance_action(
5980             context, instance, self.host,
5981             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
5982             phase=fields.NotificationPhase.START)
5983 
5984         migrate_data = self.driver.pre_live_migration(context,
5985                                        instance,
5986                                        block_device_info,
5987                                        network_info,
5988                                        disk,
5989                                        migrate_data)
5990         LOG.debug('driver pre_live_migration data is %s', migrate_data)
5991 
5992         # Volume connections are complete, tell cinder that all the
5993         # attachments have completed.
5994         for bdm in bdms:
5995             if bdm.is_volume and bdm.attachment_id is not None:
5996                 self.volume_api.attachment_complete(context,
5997                                                     bdm.attachment_id)
5998 
5999         # NOTE(tr3buchet): setup networks on destination host
6000         self.network_api.setup_networks_on_host(context, instance,
6001                                                          self.host)
6002 
6003         # Creating filters to hypervisors and firewalls.
6004         # An example is that nova-instance-instance-xxx,
6005         # which is written to libvirt.xml(Check "virsh nwfilter-list")
6006         # This nwfilter is necessary on the destination host.
6007         # In addition, this method is creating filtering rule
6008         # onto destination host.
6009         self.driver.ensure_filtering_rules_for_instance(instance,
6010                                             network_info)
6011 
6012         self._notify_about_instance_usage(
6013                      context, instance, "live_migration.pre.end",
6014                      network_info=network_info)
6015         compute_utils.notify_about_instance_action(
6016             context, instance, self.host,
6017             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6018             phase=fields.NotificationPhase.END)
6019 
6020         LOG.debug('pre_live_migration result data is %s', migrate_data)
6021         return migrate_data
6022 
6023     def _do_live_migration(self, context, dest, instance, block_migration,
6024                            migration, migrate_data):
6025         # NOTE(danms): We should enhance the RT to account for migrations
6026         # and use the status field to denote when the accounting has been
6027         # done on source/destination. For now, this is just here for status
6028         # reporting
6029         self._set_migration_status(migration, 'preparing')
6030 
6031         try:
6032             if ('block_migration' in migrate_data and
6033                     migrate_data.block_migration):
6034                 block_device_info = self._get_instance_block_device_info(
6035                     context, instance)
6036                 disk = self.driver.get_instance_disk_info(
6037                     instance, block_device_info=block_device_info)
6038             else:
6039                 disk = None
6040 
6041             migrate_data = self.compute_rpcapi.pre_live_migration(
6042                 context, instance,
6043                 block_migration, disk, dest, migrate_data)
6044         except Exception:
6045             with excutils.save_and_reraise_exception():
6046                 LOG.exception('Pre live migration failed at %s',
6047                               dest, instance=instance)
6048                 self._set_migration_status(migration, 'error')
6049                 # Make sure we set this for _rollback_live_migration()
6050                 # so it can find it, as expected if it was called later
6051                 migrate_data.migration = migration
6052                 self._rollback_live_migration(context, instance, dest,
6053                                               migrate_data)
6054 
6055         self._set_migration_status(migration, 'running')
6056 
6057         if migrate_data:
6058             migrate_data.migration = migration
6059         LOG.debug('live_migration data is %s', migrate_data)
6060         try:
6061             self.driver.live_migration(context, instance, dest,
6062                                        self._post_live_migration,
6063                                        self._rollback_live_migration,
6064                                        block_migration, migrate_data)
6065         except Exception:
6066             LOG.exception('Live migration failed.', instance=instance)
6067             with excutils.save_and_reraise_exception():
6068                 # Put instance and migration into error state,
6069                 # as its almost certainly too late to rollback
6070                 self._set_migration_status(migration, 'error')
6071                 # first refresh instance as it may have got updated by
6072                 # post_live_migration_at_destination
6073                 instance.refresh()
6074                 self._set_instance_obj_error_state(context, instance,
6075                                                    clean_task_state=True)
6076 
6077     @wrap_exception()
6078     @wrap_instance_event(prefix='compute')
6079     @wrap_instance_fault
6080     def live_migration(self, context, dest, instance, block_migration,
6081                        migration, migrate_data):
6082         """Executing live migration.
6083 
6084         :param context: security context
6085         :param dest: destination host
6086         :param instance: a nova.objects.instance.Instance object
6087         :param block_migration: if true, prepare for block migration
6088         :param migration: an nova.objects.Migration object
6089         :param migrate_data: implementation specific params
6090 
6091         """
6092         self._set_migration_status(migration, 'queued')
6093 
6094         def dispatch_live_migration(*args, **kwargs):
6095             with self._live_migration_semaphore:
6096                 self._do_live_migration(*args, **kwargs)
6097 
6098         # NOTE(danms): We spawn here to return the RPC worker thread back to
6099         # the pool. Since what follows could take a really long time, we don't
6100         # want to tie up RPC workers.
6101         utils.spawn_n(dispatch_live_migration,
6102                       context, dest, instance,
6103                       block_migration, migration,
6104                       migrate_data)
6105 
6106     @wrap_exception()
6107     @wrap_instance_event(prefix='compute')
6108     @wrap_instance_fault
6109     def live_migration_force_complete(self, context, instance):
6110         """Force live migration to complete.
6111 
6112         :param context: Security context
6113         :param instance: The instance that is being migrated
6114         """
6115 
6116         self._notify_about_instance_usage(
6117             context, instance, 'live.migration.force.complete.start')
6118         self.driver.live_migration_force_complete(instance)
6119         self._notify_about_instance_usage(
6120             context, instance, 'live.migration.force.complete.end')
6121 
6122     @wrap_exception()
6123     @wrap_instance_event(prefix='compute')
6124     @wrap_instance_fault
6125     def live_migration_abort(self, context, instance, migration_id):
6126         """Abort an in-progress live migration.
6127 
6128         :param context: Security context
6129         :param instance: The instance that is being migrated
6130         :param migration_id: ID of in-progress live migration
6131 
6132         """
6133         migration = objects.Migration.get_by_id(context, migration_id)
6134         if migration.status != 'running':
6135             raise exception.InvalidMigrationState(migration_id=migration_id,
6136                     instance_uuid=instance.uuid,
6137                     state=migration.status,
6138                     method='abort live migration')
6139 
6140         self._notify_about_instance_usage(
6141             context, instance, 'live.migration.abort.start')
6142         compute_utils.notify_about_instance_action(
6143             context, instance, self.host,
6144             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6145             phase=fields.NotificationPhase.START)
6146         self.driver.live_migration_abort(instance)
6147         self._notify_about_instance_usage(
6148             context, instance, 'live.migration.abort.end')
6149         compute_utils.notify_about_instance_action(
6150             context, instance, self.host,
6151             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6152             phase=fields.NotificationPhase.END)
6153 
6154     def _live_migration_cleanup_flags(self, migrate_data):
6155         """Determine whether disks or instance path need to be cleaned up after
6156         live migration (at source on success, at destination on rollback)
6157 
6158         Block migration needs empty image at destination host before migration
6159         starts, so if any failure occurs, any empty images has to be deleted.
6160 
6161         Also Volume backed live migration w/o shared storage needs to delete
6162         newly created instance-xxx dir on the destination as a part of its
6163         rollback process
6164 
6165         :param migrate_data: implementation specific data
6166         :returns: (bool, bool) -- do_cleanup, destroy_disks
6167         """
6168         # NOTE(pkoniszewski): block migration specific params are set inside
6169         # migrate_data objects for drivers that expose block live migration
6170         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6171         # cleanup is not needed.
6172         is_shared_block_storage = True
6173         is_shared_instance_path = True
6174         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6175             is_shared_block_storage = migrate_data.is_shared_block_storage
6176             is_shared_instance_path = migrate_data.is_shared_instance_path
6177         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6178             is_shared_block_storage = not migrate_data.block_migration
6179             is_shared_instance_path = not migrate_data.block_migration
6180         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6181             is_shared_instance_path = migrate_data.is_shared_instance_path
6182             is_shared_block_storage = migrate_data.is_shared_instance_path
6183 
6184         # No instance booting at source host, but instance dir
6185         # must be deleted for preparing next block migration
6186         # must be deleted for preparing next live migration w/o shared storage
6187         do_cleanup = not is_shared_instance_path
6188         destroy_disks = not is_shared_block_storage
6189 
6190         return (do_cleanup, destroy_disks)
6191 
6192     @wrap_exception()
6193     @wrap_instance_fault
6194     def _post_live_migration(self, ctxt, instance,
6195                             dest, block_migration=False, migrate_data=None):
6196         """Post operations for live migration.
6197 
6198         This method is called from live_migration
6199         and mainly updating database record.
6200 
6201         :param ctxt: security context
6202         :param instance: instance dict
6203         :param dest: destination host
6204         :param block_migration: if true, prepare for block migration
6205         :param migrate_data: if not None, it is a dict which has data
6206         required for live migration without shared storage
6207 
6208         """
6209         LOG.info('_post_live_migration() is started..',
6210                  instance=instance)
6211 
6212         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6213                 ctxt, instance.uuid)
6214 
6215         # Cleanup source host post live-migration
6216         block_device_info = self._get_instance_block_device_info(
6217                             ctxt, instance, bdms=bdms)
6218         self.driver.post_live_migration(ctxt, instance, block_device_info,
6219                                         migrate_data)
6220 
6221         # Detaching volumes.
6222         connector = self.driver.get_volume_connector(instance)
6223         for bdm in bdms:
6224             if bdm.is_volume:
6225                 if bdm.attachment_id is None:
6226                     # Prior to cinder v3.44:
6227                     # We don't want to actually mark the volume detached, or
6228                     # delete the bdm, just remove the connection from this
6229                     # host.
6230                     #
6231                     # remove the volume connection without detaching from
6232                     # hypervisor because the instance is not running anymore
6233                     # on the current host
6234                     self.volume_api.terminate_connection(ctxt, bdm.volume_id,
6235                                                          connector)
6236                 else:
6237                     # cinder v3.44 api flow - delete the old attachment
6238                     # for the source host
6239                     old_attachment_id = \
6240                         migrate_data.old_vol_attachment_ids[bdm.volume_id]
6241                     self.volume_api.attachment_delete(ctxt, old_attachment_id)
6242 
6243         # Releasing vlan.
6244         # (not necessary in current implementation?)
6245 
6246         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
6247 
6248         self._notify_about_instance_usage(ctxt, instance,
6249                                           "live_migration._post.start",
6250                                           network_info=network_info)
6251         # Releasing security group ingress rule.
6252         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
6253                   instance=instance)
6254         self.driver.unfilter_instance(instance,
6255                                       network_info)
6256 
6257         migration = {'source_compute': self.host,
6258                      'dest_compute': dest, }
6259         self.network_api.migrate_instance_start(ctxt,
6260                                                 instance,
6261                                                 migration)
6262 
6263         destroy_vifs = False
6264         try:
6265             self.driver.post_live_migration_at_source(ctxt, instance,
6266                                                       network_info)
6267         except NotImplementedError as ex:
6268             LOG.debug(ex, instance=instance)
6269             # For all hypervisors other than libvirt, there is a possibility
6270             # they are unplugging networks from source node in the cleanup
6271             # method
6272             destroy_vifs = True
6273 
6274         # NOTE(danms): Save source node before calling post method on
6275         # destination, which will update it
6276         source_node = instance.node
6277 
6278         # Define domain at destination host, without doing it,
6279         # pause/suspend/terminate do not work.
6280         post_at_dest_success = True
6281         try:
6282             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
6283                     instance, block_migration, dest)
6284         except Exception as error:
6285             post_at_dest_success = False
6286             # We don't want to break _post_live_migration() if
6287             # post_live_migration_at_destination() fails as it should never
6288             # affect cleaning up source node.
6289             LOG.exception("Post live migration at destination %s failed",
6290                           dest, instance=instance, error=error)
6291 
6292         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6293                 migrate_data)
6294 
6295         if do_cleanup:
6296             LOG.debug('Calling driver.cleanup from _post_live_migration',
6297                       instance=instance)
6298             self.driver.cleanup(ctxt, instance, network_info,
6299                                 destroy_disks=destroy_disks,
6300                                 migrate_data=migrate_data,
6301                                 destroy_vifs=destroy_vifs)
6302 
6303         self.instance_events.clear_events_for_instance(instance)
6304 
6305         # NOTE(timello): make sure we update available resources on source
6306         # host even before next periodic task.
6307         self.update_available_resource(ctxt)
6308 
6309         self._update_scheduler_instance_info(ctxt, instance)
6310         self._notify_about_instance_usage(ctxt, instance,
6311                                           "live_migration._post.end",
6312                                           network_info=network_info)
6313         if post_at_dest_success:
6314             LOG.info('Migrating instance to %s finished successfully.',
6315                      dest, instance=instance)
6316 
6317         if migrate_data and migrate_data.obj_attr_is_set('migration'):
6318             migrate_data.migration.status = 'completed'
6319             migrate_data.migration.save()
6320             migration = migrate_data.migration
6321             rc = self.scheduler_client.reportclient
6322             # Check to see if our migration has its own allocations
6323             allocs = rc.get_allocations_for_consumer(ctxt, migration.uuid)
6324         else:
6325             # We didn't have data on a migration, which means we can't
6326             # look up to see if we had new-style migration-based
6327             # allocations. This should really only happen in cases of
6328             # a buggy virt driver or some really old component in the
6329             # system. Log a warning so we know it happened.
6330             allocs = None
6331             LOG.warning('Live migration ended with no migrate_data '
6332                         'record. Unable to clean up migration-based '
6333                         'allocations which is almost certainly not '
6334                         'an expected situation.')
6335 
6336         if allocs:
6337             # We had a migration-based allocation that we need to handle
6338             self._delete_allocation_after_move(ctxt,
6339                                                instance,
6340                                                migrate_data.migration,
6341                                                instance.flavor,
6342                                                source_node)
6343         else:
6344             # No migration-based allocations, so do the old thing and
6345             # attempt to clean up any doubled per-instance allocation
6346             rt = self._get_resource_tracker()
6347             rt.delete_allocation_for_migrated_instance(
6348                 ctxt, instance, source_node)
6349 
6350     def _consoles_enabled(self):
6351         """Returns whether a console is enable."""
6352         return (CONF.vnc.enabled or CONF.spice.enabled or
6353                 CONF.rdp.enabled or CONF.serial_console.enabled or
6354                 CONF.mks.enabled)
6355 
6356     @wrap_exception()
6357     @wrap_instance_event(prefix='compute')
6358     @wrap_instance_fault
6359     def post_live_migration_at_destination(self, context, instance,
6360                                            block_migration):
6361         """Post operations for live migration .
6362 
6363         :param context: security context
6364         :param instance: Instance dict
6365         :param block_migration: if true, prepare for block migration
6366 
6367         """
6368         LOG.info('Post operation of migration started',
6369                  instance=instance)
6370 
6371         # NOTE(tr3buchet): setup networks on destination host
6372         #                  this is called a second time because
6373         #                  multi_host does not create the bridge in
6374         #                  plug_vifs
6375         self.network_api.setup_networks_on_host(context, instance,
6376                                                          self.host)
6377         migration = {'source_compute': instance.host,
6378                      'dest_compute': self.host, }
6379         self.network_api.migrate_instance_finish(context,
6380                                                  instance,
6381                                                  migration)
6382 
6383         network_info = self.network_api.get_instance_nw_info(context, instance)
6384         self._notify_about_instance_usage(
6385                      context, instance, "live_migration.post.dest.start",
6386                      network_info=network_info)
6387         compute_utils.notify_about_instance_action(context, instance,
6388                 self.host,
6389                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6390                 phase=fields.NotificationPhase.START)
6391         block_device_info = self._get_instance_block_device_info(context,
6392                                                                  instance)
6393 
6394         try:
6395             self.driver.post_live_migration_at_destination(
6396                 context, instance, network_info, block_migration,
6397                 block_device_info)
6398         except Exception:
6399             with excutils.save_and_reraise_exception():
6400                 instance.vm_state = vm_states.ERROR
6401                 LOG.error('Unexpected error during post live migration at '
6402                           'destination host.', instance=instance)
6403         finally:
6404             # Restore instance state and update host
6405             current_power_state = self._get_power_state(context, instance)
6406             node_name = None
6407             prev_host = instance.host
6408             try:
6409                 compute_node = self._get_compute_info(context, self.host)
6410                 node_name = compute_node.hypervisor_hostname
6411             except exception.ComputeHostNotFound:
6412                 LOG.exception('Failed to get compute_info for %s', self.host)
6413             finally:
6414                 instance.host = self.host
6415                 instance.power_state = current_power_state
6416                 instance.task_state = None
6417                 instance.node = node_name
6418                 instance.progress = 0
6419                 instance.save(expected_task_state=task_states.MIGRATING)
6420 
6421         # NOTE(tr3buchet): tear down networks on source host
6422         self.network_api.setup_networks_on_host(context, instance,
6423                                                 prev_host, teardown=True)
6424         # NOTE(vish): this is necessary to update dhcp
6425         self.network_api.setup_networks_on_host(context, instance, self.host)
6426         self._notify_about_instance_usage(
6427                      context, instance, "live_migration.post.dest.end",
6428                      network_info=network_info)
6429         compute_utils.notify_about_instance_action(context, instance,
6430                 self.host,
6431                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6432                 phase=fields.NotificationPhase.END)
6433 
6434     @wrap_exception()
6435     @wrap_instance_fault
6436     def _rollback_live_migration(self, context, instance,
6437                                  dest, migrate_data=None,
6438                                  migration_status='error'):
6439         """Recovers Instance/volume state from migrating -> running.
6440 
6441         :param context: security context
6442         :param instance: nova.objects.instance.Instance object
6443         :param dest:
6444             This method is called from live migration src host.
6445             This param specifies destination host.
6446         :param migrate_data:
6447             if not none, contains implementation specific data.
6448         :param migration_status:
6449             Contains the status we want to set for the migration object
6450 
6451         """
6452         if (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
6453               migrate_data.obj_attr_is_set('migration')):
6454             migration = migrate_data.migration
6455         else:
6456             migration = None
6457 
6458         if migration:
6459             # Remove allocations created in Placement for the dest node.
6460             # If migration is None, we must be so old we don't have placement,
6461             # so no need to do something else.
6462             self._revert_allocation(context, instance, migration)
6463         else:
6464             LOG.error('Unable to revert allocations during live migration '
6465                       'rollback; compute driver did not provide migrate_data',
6466                       instance=instance)
6467 
6468         instance.task_state = None
6469         instance.progress = 0
6470         instance.save(expected_task_state=[task_states.MIGRATING])
6471 
6472         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
6473         self.network_api.setup_networks_on_host(context, instance, self.host)
6474 
6475         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6476                 context, instance.uuid)
6477         for bdm in bdms:
6478             if bdm.is_volume:
6479                 # remove the connection on the destination host
6480                 self.compute_rpcapi.remove_volume_connection(
6481                         context, instance, bdm.volume_id, dest)
6482 
6483                 if bdm.attachment_id:
6484                     # 3.44 cinder api flow. Set the bdm's
6485                     # attachment_id to the old attachment of the source
6486                     # host. If old_attachments is not there, then
6487                     # there was an error before the new attachment was made.
6488                     old_attachments = migrate_data.old_vol_attachment_ids \
6489                         if 'old_vol_attachment_ids' in migrate_data else None
6490                     if old_attachments and bdm.volume_id in old_attachments:
6491                         self.volume_api.attachment_delete(context,
6492                                                           bdm.attachment_id)
6493                         bdm.attachment_id = old_attachments[bdm.volume_id]
6494                         bdm.save()
6495 
6496         self._notify_about_instance_usage(context, instance,
6497                                           "live_migration._rollback.start")
6498         compute_utils.notify_about_instance_action(context, instance,
6499                 self.host,
6500                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6501                 phase=fields.NotificationPhase.START,
6502                 bdms=bdms)
6503 
6504         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6505                 migrate_data)
6506 
6507         if do_cleanup:
6508             self.compute_rpcapi.rollback_live_migration_at_destination(
6509                     context, instance, dest, destroy_disks=destroy_disks,
6510                     migrate_data=migrate_data)
6511 
6512         self._notify_about_instance_usage(context, instance,
6513                                           "live_migration._rollback.end")
6514         compute_utils.notify_about_instance_action(context, instance,
6515 
6516                 self.host,
6517                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6518                 phase=fields.NotificationPhase.END,
6519                 bdms=bdms)
6520 
6521         self._set_migration_status(migration, migration_status)
6522 
6523     @wrap_exception()
6524     @wrap_instance_event(prefix='compute')
6525     @wrap_instance_fault
6526     def rollback_live_migration_at_destination(self, context, instance,
6527                                                destroy_disks,
6528                                                migrate_data):
6529         """Cleaning up image directory that is created pre_live_migration.
6530 
6531         :param context: security context
6532         :param instance: a nova.objects.instance.Instance object sent over rpc
6533         :param destroy_disks: whether to destroy volumes or not
6534         :param migrate_data: contains migration info
6535         """
6536         network_info = self.network_api.get_instance_nw_info(context, instance)
6537         self._notify_about_instance_usage(
6538                       context, instance, "live_migration.rollback.dest.start",
6539                       network_info=network_info)
6540         try:
6541             # NOTE(tr3buchet): tear down networks on destination host
6542             self.network_api.setup_networks_on_host(context, instance,
6543                                                     self.host, teardown=True)
6544         except Exception:
6545             with excutils.save_and_reraise_exception():
6546                 # NOTE(tdurakov): even if teardown networks fails driver
6547                 # should try to rollback live migration on destination.
6548                 LOG.exception('An error occurred while deallocating network.',
6549                               instance=instance)
6550         finally:
6551             # always run this even if setup_networks_on_host fails
6552             # NOTE(vish): The mapping is passed in so the driver can disconnect
6553             #             from remote volumes if necessary
6554             block_device_info = self._get_instance_block_device_info(context,
6555                                                                      instance)
6556             self.driver.rollback_live_migration_at_destination(
6557                 context, instance, network_info, block_device_info,
6558                 destroy_disks=destroy_disks, migrate_data=migrate_data)
6559 
6560         self._notify_about_instance_usage(
6561                         context, instance, "live_migration.rollback.dest.end",
6562                         network_info=network_info)
6563 
6564     @periodic_task.periodic_task(
6565         spacing=CONF.heal_instance_info_cache_interval)
6566     def _heal_instance_info_cache(self, context):
6567         """Called periodically.  On every call, try to update the
6568         info_cache's network information for another instance by
6569         calling to the network manager.
6570 
6571         This is implemented by keeping a cache of uuids of instances
6572         that live on this host.  On each call, we pop one off of a
6573         list, pull the DB record, and try the call to the network API.
6574         If anything errors don't fail, as it's possible the instance
6575         has been deleted, etc.
6576         """
6577         heal_interval = CONF.heal_instance_info_cache_interval
6578         if not heal_interval:
6579             return
6580 
6581         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
6582         instance = None
6583 
6584         LOG.debug('Starting heal instance info cache')
6585 
6586         if not instance_uuids:
6587             # The list of instances to heal is empty so rebuild it
6588             LOG.debug('Rebuilding the list of instances to heal')
6589             db_instances = objects.InstanceList.get_by_host(
6590                 context, self.host, expected_attrs=[], use_slave=True)
6591             for inst in db_instances:
6592                 # We don't want to refresh the cache for instances
6593                 # which are building or deleting so don't put them
6594                 # in the list. If they are building they will get
6595                 # added to the list next time we build it.
6596                 if (inst.vm_state == vm_states.BUILDING):
6597                     LOG.debug('Skipping network cache update for instance '
6598                               'because it is Building.', instance=inst)
6599                     continue
6600                 if (inst.task_state == task_states.DELETING):
6601                     LOG.debug('Skipping network cache update for instance '
6602                               'because it is being deleted.', instance=inst)
6603                     continue
6604 
6605                 if not instance:
6606                     # Save the first one we find so we don't
6607                     # have to get it again
6608                     instance = inst
6609                 else:
6610                     instance_uuids.append(inst['uuid'])
6611 
6612             self._instance_uuids_to_heal = instance_uuids
6613         else:
6614             # Find the next valid instance on the list
6615             while instance_uuids:
6616                 try:
6617                     inst = objects.Instance.get_by_uuid(
6618                             context, instance_uuids.pop(0),
6619                             expected_attrs=['system_metadata', 'info_cache',
6620                                             'flavor'],
6621                             use_slave=True)
6622                 except exception.InstanceNotFound:
6623                     # Instance is gone.  Try to grab another.
6624                     continue
6625 
6626                 # Check the instance hasn't been migrated
6627                 if inst.host != self.host:
6628                     LOG.debug('Skipping network cache update for instance '
6629                               'because it has been migrated to another '
6630                               'host.', instance=inst)
6631                 # Check the instance isn't being deleting
6632                 elif inst.task_state == task_states.DELETING:
6633                     LOG.debug('Skipping network cache update for instance '
6634                               'because it is being deleted.', instance=inst)
6635                 else:
6636                     instance = inst
6637                     break
6638 
6639         if instance:
6640             # We have an instance now to refresh
6641             try:
6642                 # Call to network API to get instance info.. this will
6643                 # force an update to the instance's info_cache
6644                 self.network_api.get_instance_nw_info(context, instance)
6645                 LOG.debug('Updated the network info_cache for instance',
6646                           instance=instance)
6647             except exception.InstanceNotFound:
6648                 # Instance is gone.
6649                 LOG.debug('Instance no longer exists. Unable to refresh',
6650                           instance=instance)
6651                 return
6652             except exception.InstanceInfoCacheNotFound:
6653                 # InstanceInfoCache is gone.
6654                 LOG.debug('InstanceInfoCache no longer exists. '
6655                           'Unable to refresh', instance=instance)
6656             except Exception:
6657                 LOG.error('An error occurred while refreshing the network '
6658                           'cache.', instance=instance, exc_info=True)
6659         else:
6660             LOG.debug("Didn't find any instances for network info cache "
6661                       "update.")
6662 
6663     @periodic_task.periodic_task
6664     def _poll_rebooting_instances(self, context):
6665         if CONF.reboot_timeout > 0:
6666             filters = {'task_state':
6667                        [task_states.REBOOTING,
6668                         task_states.REBOOT_STARTED,
6669                         task_states.REBOOT_PENDING],
6670                        'host': self.host}
6671             rebooting = objects.InstanceList.get_by_filters(
6672                 context, filters, expected_attrs=[], use_slave=True)
6673 
6674             to_poll = []
6675             for instance in rebooting:
6676                 if timeutils.is_older_than(instance.updated_at,
6677                                            CONF.reboot_timeout):
6678                     to_poll.append(instance)
6679 
6680             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
6681 
6682     @periodic_task.periodic_task
6683     def _poll_rescued_instances(self, context):
6684         if CONF.rescue_timeout > 0:
6685             filters = {'vm_state': vm_states.RESCUED,
6686                        'host': self.host}
6687             rescued_instances = objects.InstanceList.get_by_filters(
6688                 context, filters, expected_attrs=["system_metadata"],
6689                 use_slave=True)
6690 
6691             to_unrescue = []
6692             for instance in rescued_instances:
6693                 if timeutils.is_older_than(instance.launched_at,
6694                                            CONF.rescue_timeout):
6695                     to_unrescue.append(instance)
6696 
6697             for instance in to_unrescue:
6698                 self.compute_api.unrescue(context, instance)
6699 
6700     @periodic_task.periodic_task
6701     def _poll_unconfirmed_resizes(self, context):
6702         if CONF.resize_confirm_window == 0:
6703             return
6704 
6705         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
6706                 context, CONF.resize_confirm_window, self.host,
6707                 use_slave=True)
6708 
6709         migrations_info = dict(migration_count=len(migrations),
6710                 confirm_window=CONF.resize_confirm_window)
6711 
6712         if migrations_info["migration_count"] > 0:
6713             LOG.info("Found %(migration_count)d unconfirmed migrations "
6714                      "older than %(confirm_window)d seconds",
6715                      migrations_info)
6716 
6717         def _set_migration_to_error(migration, reason, **kwargs):
6718             LOG.warning("Setting migration %(migration_id)s to error: "
6719                         "%(reason)s",
6720                         {'migration_id': migration['id'], 'reason': reason},
6721                         **kwargs)
6722             migration.status = 'error'
6723             with migration.obj_as_admin():
6724                 migration.save()
6725 
6726         for migration in migrations:
6727             instance_uuid = migration.instance_uuid
6728             LOG.info("Automatically confirming migration "
6729                      "%(migration_id)s for instance %(instance_uuid)s",
6730                      {'migration_id': migration.id,
6731                       'instance_uuid': instance_uuid})
6732             expected_attrs = ['metadata', 'system_metadata']
6733             try:
6734                 instance = objects.Instance.get_by_uuid(context,
6735                             instance_uuid, expected_attrs=expected_attrs,
6736                             use_slave=True)
6737             except exception.InstanceNotFound:
6738                 reason = (_("Instance %s not found") %
6739                           instance_uuid)
6740                 _set_migration_to_error(migration, reason)
6741                 continue
6742             if instance.vm_state == vm_states.ERROR:
6743                 reason = _("In ERROR state")
6744                 _set_migration_to_error(migration, reason,
6745                                         instance=instance)
6746                 continue
6747             # race condition: The instance in DELETING state should not be
6748             # set the migration state to error, otherwise the instance in
6749             # to be deleted which is in RESIZED state
6750             # will not be able to confirm resize
6751             if instance.task_state in [task_states.DELETING,
6752                                        task_states.SOFT_DELETING]:
6753                 msg = ("Instance being deleted or soft deleted during resize "
6754                        "confirmation. Skipping.")
6755                 LOG.debug(msg, instance=instance)
6756                 continue
6757 
6758             # race condition: This condition is hit when this method is
6759             # called between the save of the migration record with a status of
6760             # finished and the save of the instance object with a state of
6761             # RESIZED. The migration record should not be set to error.
6762             if instance.task_state == task_states.RESIZE_FINISH:
6763                 msg = ("Instance still resizing during resize "
6764                        "confirmation. Skipping.")
6765                 LOG.debug(msg, instance=instance)
6766                 continue
6767 
6768             vm_state = instance.vm_state
6769             task_state = instance.task_state
6770             if vm_state != vm_states.RESIZED or task_state is not None:
6771                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
6772                            "RESIZED/None") %
6773                           {'vm_state': vm_state,
6774                            'task_state': task_state})
6775                 _set_migration_to_error(migration, reason,
6776                                         instance=instance)
6777                 continue
6778             try:
6779                 self.compute_api.confirm_resize(context, instance,
6780                                                 migration=migration)
6781             except Exception as e:
6782                 LOG.info("Error auto-confirming resize: %s. "
6783                          "Will retry later.", e, instance=instance)
6784 
6785     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
6786     def _poll_shelved_instances(self, context):
6787 
6788         if CONF.shelved_offload_time <= 0:
6789             return
6790 
6791         filters = {'vm_state': vm_states.SHELVED,
6792                    'task_state': None,
6793                    'host': self.host}
6794         shelved_instances = objects.InstanceList.get_by_filters(
6795             context, filters=filters, expected_attrs=['system_metadata'],
6796             use_slave=True)
6797 
6798         to_gc = []
6799         for instance in shelved_instances:
6800             sys_meta = instance.system_metadata
6801             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
6802             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
6803                 to_gc.append(instance)
6804 
6805         for instance in to_gc:
6806             try:
6807                 instance.task_state = task_states.SHELVING_OFFLOADING
6808                 instance.save(expected_task_state=(None,))
6809                 self.shelve_offload_instance(context, instance,
6810                                              clean_shutdown=False)
6811             except Exception:
6812                 LOG.exception('Periodic task failed to offload instance.',
6813                               instance=instance)
6814 
6815     @periodic_task.periodic_task
6816     def _instance_usage_audit(self, context):
6817         if not CONF.instance_usage_audit:
6818             return
6819 
6820         begin, end = utils.last_completed_audit_period()
6821         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
6822                                self.host):
6823             return
6824 
6825         instances = objects.InstanceList.get_active_by_window_joined(
6826             context, begin, end, host=self.host,
6827             expected_attrs=['system_metadata', 'info_cache', 'metadata',
6828                             'flavor'],
6829             use_slave=True)
6830         num_instances = len(instances)
6831         errors = 0
6832         successes = 0
6833         LOG.info("Running instance usage audit for host %(host)s "
6834                  "from %(begin_time)s to %(end_time)s. "
6835                  "%(number_instances)s instances.",
6836                  {'host': self.host,
6837                   'begin_time': begin,
6838                   'end_time': end,
6839                   'number_instances': num_instances})
6840         start_time = time.time()
6841         task_log = objects.TaskLog(context)
6842         task_log.task_name = 'instance_usage_audit'
6843         task_log.period_beginning = begin
6844         task_log.period_ending = end
6845         task_log.host = self.host
6846         task_log.task_items = num_instances
6847         task_log.message = 'Instance usage audit started...'
6848         task_log.begin_task()
6849         for instance in instances:
6850             try:
6851                 compute_utils.notify_usage_exists(
6852                     self.notifier, context, instance,
6853                     ignore_missing_network_data=False)
6854                 successes += 1
6855             except Exception:
6856                 LOG.exception('Failed to generate usage '
6857                               'audit for instance '
6858                               'on host %s', self.host,
6859                               instance=instance)
6860                 errors += 1
6861         task_log.errors = errors
6862         task_log.message = (
6863             'Instance usage audit ran for host %s, %s instances in %s seconds.'
6864             % (self.host, num_instances, time.time() - start_time))
6865         task_log.end_task()
6866 
6867     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
6868     def _poll_bandwidth_usage(self, context):
6869 
6870         if not self._bw_usage_supported:
6871             return
6872 
6873         prev_time, start_time = utils.last_completed_audit_period()
6874 
6875         curr_time = time.time()
6876         if (curr_time - self._last_bw_usage_poll >
6877                 CONF.bandwidth_poll_interval):
6878             self._last_bw_usage_poll = curr_time
6879             LOG.info("Updating bandwidth usage cache")
6880             cells_update_interval = CONF.cells.bandwidth_update_interval
6881             if (cells_update_interval > 0 and
6882                    curr_time - self._last_bw_usage_cell_update >
6883                            cells_update_interval):
6884                 self._last_bw_usage_cell_update = curr_time
6885                 update_cells = True
6886             else:
6887                 update_cells = False
6888 
6889             instances = objects.InstanceList.get_by_host(context,
6890                                                               self.host,
6891                                                               use_slave=True)
6892             try:
6893                 bw_counters = self.driver.get_all_bw_counters(instances)
6894             except NotImplementedError:
6895                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
6896                 # implemented yet.  If they don't it doesn't break anything,
6897                 # they just don't get the info in the usage events.
6898                 # NOTE(PhilDay): Record that its not supported so we can
6899                 # skip fast on future calls rather than waste effort getting
6900                 # the list of instances.
6901                 LOG.info("Bandwidth usage not supported by %(driver)s.",
6902                          {'driver': CONF.compute_driver})
6903                 self._bw_usage_supported = False
6904                 return
6905 
6906             refreshed = timeutils.utcnow()
6907             for bw_ctr in bw_counters:
6908                 # Allow switching of greenthreads between queries.
6909                 greenthread.sleep(0)
6910                 bw_in = 0
6911                 bw_out = 0
6912                 last_ctr_in = None
6913                 last_ctr_out = None
6914                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6915                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6916                     start_period=start_time, use_slave=True)
6917                 if usage:
6918                     bw_in = usage.bw_in
6919                     bw_out = usage.bw_out
6920                     last_ctr_in = usage.last_ctr_in
6921                     last_ctr_out = usage.last_ctr_out
6922                 else:
6923                     usage = (objects.BandwidthUsage.
6924                              get_by_instance_uuid_and_mac(
6925                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6926                         start_period=prev_time, use_slave=True))
6927                     if usage:
6928                         last_ctr_in = usage.last_ctr_in
6929                         last_ctr_out = usage.last_ctr_out
6930 
6931                 if last_ctr_in is not None:
6932                     if bw_ctr['bw_in'] < last_ctr_in:
6933                         # counter rollover
6934                         bw_in += bw_ctr['bw_in']
6935                     else:
6936                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6937 
6938                 if last_ctr_out is not None:
6939                     if bw_ctr['bw_out'] < last_ctr_out:
6940                         # counter rollover
6941                         bw_out += bw_ctr['bw_out']
6942                     else:
6943                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6944 
6945                 objects.BandwidthUsage(context=context).create(
6946                                               bw_ctr['uuid'],
6947                                               bw_ctr['mac_address'],
6948                                               bw_in,
6949                                               bw_out,
6950                                               bw_ctr['bw_in'],
6951                                               bw_ctr['bw_out'],
6952                                               start_period=start_time,
6953                                               last_refreshed=refreshed,
6954                                               update_cells=update_cells)
6955 
6956     def _get_host_volume_bdms(self, context, use_slave=False):
6957         """Return all block device mappings on a compute host."""
6958         compute_host_bdms = []
6959         instances = objects.InstanceList.get_by_host(context, self.host,
6960             use_slave=use_slave)
6961         for instance in instances:
6962             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6963                     context, instance.uuid, use_slave=use_slave)
6964             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6965             compute_host_bdms.append(dict(instance=instance,
6966                                           instance_bdms=instance_bdms))
6967 
6968         return compute_host_bdms
6969 
6970     def _update_volume_usage_cache(self, context, vol_usages):
6971         """Updates the volume usage cache table with a list of stats."""
6972         for usage in vol_usages:
6973             # Allow switching of greenthreads between queries.
6974             greenthread.sleep(0)
6975             vol_usage = objects.VolumeUsage(context)
6976             vol_usage.volume_id = usage['volume']
6977             vol_usage.instance_uuid = usage['instance'].uuid
6978             vol_usage.project_id = usage['instance'].project_id
6979             vol_usage.user_id = usage['instance'].user_id
6980             vol_usage.availability_zone = usage['instance'].availability_zone
6981             vol_usage.curr_reads = usage['rd_req']
6982             vol_usage.curr_read_bytes = usage['rd_bytes']
6983             vol_usage.curr_writes = usage['wr_req']
6984             vol_usage.curr_write_bytes = usage['wr_bytes']
6985             vol_usage.save()
6986             self.notifier.info(context, 'volume.usage',
6987                                compute_utils.usage_volume_info(vol_usage))
6988 
6989     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
6990     def _poll_volume_usage(self, context):
6991         if CONF.volume_usage_poll_interval == 0:
6992             return
6993 
6994         compute_host_bdms = self._get_host_volume_bdms(context,
6995                                                        use_slave=True)
6996         if not compute_host_bdms:
6997             return
6998 
6999         LOG.debug("Updating volume usage cache")
7000         try:
7001             vol_usages = self.driver.get_all_volume_usage(context,
7002                                                           compute_host_bdms)
7003         except NotImplementedError:
7004             return
7005 
7006         self._update_volume_usage_cache(context, vol_usages)
7007 
7008     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
7009                                  run_immediately=True)
7010     def _sync_power_states(self, context):
7011         """Align power states between the database and the hypervisor.
7012 
7013         To sync power state data we make a DB call to get the number of
7014         virtual machines known by the hypervisor and if the number matches the
7015         number of virtual machines known by the database, we proceed in a lazy
7016         loop, one database record at a time, checking if the hypervisor has the
7017         same power state as is in the database.
7018         """
7019         db_instances = objects.InstanceList.get_by_host(context, self.host,
7020                                                         expected_attrs=[],
7021                                                         use_slave=True)
7022 
7023         num_vm_instances = self.driver.get_num_instances()
7024         num_db_instances = len(db_instances)
7025 
7026         if num_vm_instances != num_db_instances:
7027             LOG.warning("While synchronizing instance power states, found "
7028                         "%(num_db_instances)s instances in the database "
7029                         "and %(num_vm_instances)s instances on the "
7030                         "hypervisor.",
7031                         {'num_db_instances': num_db_instances,
7032                          'num_vm_instances': num_vm_instances})
7033 
7034         def _sync(db_instance):
7035             # NOTE(melwitt): This must be synchronized as we query state from
7036             #                two separate sources, the driver and the database.
7037             #                They are set (in stop_instance) and read, in sync.
7038             @utils.synchronized(db_instance.uuid)
7039             def query_driver_power_state_and_sync():
7040                 self._query_driver_power_state_and_sync(context, db_instance)
7041 
7042             try:
7043                 query_driver_power_state_and_sync()
7044             except Exception:
7045                 LOG.exception("Periodic sync_power_state task had an "
7046                               "error while processing an instance.",
7047                               instance=db_instance)
7048 
7049             self._syncs_in_progress.pop(db_instance.uuid)
7050 
7051         for db_instance in db_instances:
7052             # process syncs asynchronously - don't want instance locking to
7053             # block entire periodic task thread
7054             uuid = db_instance.uuid
7055             if uuid in self._syncs_in_progress:
7056                 LOG.debug('Sync already in progress for %s', uuid)
7057             else:
7058                 LOG.debug('Triggering sync for uuid %s', uuid)
7059                 self._syncs_in_progress[uuid] = True
7060                 self._sync_power_pool.spawn_n(_sync, db_instance)
7061 
7062     def _query_driver_power_state_and_sync(self, context, db_instance):
7063         if db_instance.task_state is not None:
7064             LOG.info("During sync_power_state the instance has a "
7065                      "pending task (%(task)s). Skip.",
7066                      {'task': db_instance.task_state}, instance=db_instance)
7067             return
7068         # No pending tasks. Now try to figure out the real vm_power_state.
7069         try:
7070             vm_instance = self.driver.get_info(db_instance)
7071             vm_power_state = vm_instance.state
7072         except exception.InstanceNotFound:
7073             vm_power_state = power_state.NOSTATE
7074         # Note(maoy): the above get_info call might take a long time,
7075         # for example, because of a broken libvirt driver.
7076         try:
7077             self._sync_instance_power_state(context,
7078                                             db_instance,
7079                                             vm_power_state,
7080                                             use_slave=True)
7081         except exception.InstanceNotFound:
7082             # NOTE(hanlind): If the instance gets deleted during sync,
7083             # silently ignore.
7084             pass
7085 
7086     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
7087                                    use_slave=False):
7088         """Align instance power state between the database and hypervisor.
7089 
7090         If the instance is not found on the hypervisor, but is in the database,
7091         then a stop() API will be called on the instance.
7092         """
7093 
7094         # We re-query the DB to get the latest instance info to minimize
7095         # (not eliminate) race condition.
7096         db_instance.refresh(use_slave=use_slave)
7097         db_power_state = db_instance.power_state
7098         vm_state = db_instance.vm_state
7099 
7100         if self.host != db_instance.host:
7101             # on the sending end of nova-compute _sync_power_state
7102             # may have yielded to the greenthread performing a live
7103             # migration; this in turn has changed the resident-host
7104             # for the VM; However, the instance is still active, it
7105             # is just in the process of migrating to another host.
7106             # This implies that the compute source must relinquish
7107             # control to the compute destination.
7108             LOG.info("During the sync_power process the "
7109                      "instance has moved from "
7110                      "host %(src)s to host %(dst)s",
7111                      {'src': db_instance.host,
7112                       'dst': self.host},
7113                      instance=db_instance)
7114             return
7115         elif db_instance.task_state is not None:
7116             # on the receiving end of nova-compute, it could happen
7117             # that the DB instance already report the new resident
7118             # but the actual VM has not showed up on the hypervisor
7119             # yet. In this case, let's allow the loop to continue
7120             # and run the state sync in a later round
7121             LOG.info("During sync_power_state the instance has a "
7122                      "pending task (%(task)s). Skip.",
7123                      {'task': db_instance.task_state},
7124                      instance=db_instance)
7125             return
7126 
7127         orig_db_power_state = db_power_state
7128         if vm_power_state != db_power_state:
7129             LOG.info('During _sync_instance_power_state the DB '
7130                      'power_state (%(db_power_state)s) does not match '
7131                      'the vm_power_state from the hypervisor '
7132                      '(%(vm_power_state)s). Updating power_state in the '
7133                      'DB to match the hypervisor.',
7134                      {'db_power_state': db_power_state,
7135                       'vm_power_state': vm_power_state},
7136                      instance=db_instance)
7137             # power_state is always updated from hypervisor to db
7138             db_instance.power_state = vm_power_state
7139             db_instance.save()
7140             db_power_state = vm_power_state
7141 
7142         # Note(maoy): Now resolve the discrepancy between vm_state and
7143         # vm_power_state. We go through all possible vm_states.
7144         if vm_state in (vm_states.BUILDING,
7145                         vm_states.RESCUED,
7146                         vm_states.RESIZED,
7147                         vm_states.SUSPENDED,
7148                         vm_states.ERROR):
7149             # TODO(maoy): we ignore these vm_state for now.
7150             pass
7151         elif vm_state == vm_states.ACTIVE:
7152             # The only rational power state should be RUNNING
7153             if vm_power_state in (power_state.SHUTDOWN,
7154                                   power_state.CRASHED):
7155                 LOG.warning("Instance shutdown by itself. Calling the "
7156                             "stop API. Current vm_state: %(vm_state)s, "
7157                             "current task_state: %(task_state)s, "
7158                             "original DB power_state: %(db_power_state)s, "
7159                             "current VM power_state: %(vm_power_state)s",
7160                             {'vm_state': vm_state,
7161                              'task_state': db_instance.task_state,
7162                              'db_power_state': orig_db_power_state,
7163                              'vm_power_state': vm_power_state},
7164                             instance=db_instance)
7165                 try:
7166                     # Note(maoy): here we call the API instead of
7167                     # brutally updating the vm_state in the database
7168                     # to allow all the hooks and checks to be performed.
7169                     if db_instance.shutdown_terminate:
7170                         self.compute_api.delete(context, db_instance)
7171                     else:
7172                         self.compute_api.stop(context, db_instance)
7173                 except Exception:
7174                     # Note(maoy): there is no need to propagate the error
7175                     # because the same power_state will be retrieved next
7176                     # time and retried.
7177                     # For example, there might be another task scheduled.
7178                     LOG.exception("error during stop() in sync_power_state.",
7179                                   instance=db_instance)
7180             elif vm_power_state == power_state.SUSPENDED:
7181                 LOG.warning("Instance is suspended unexpectedly. Calling "
7182                             "the stop API.", instance=db_instance)
7183                 try:
7184                     self.compute_api.stop(context, db_instance)
7185                 except Exception:
7186                     LOG.exception("error during stop() in sync_power_state.",
7187                                   instance=db_instance)
7188             elif vm_power_state == power_state.PAUSED:
7189                 # Note(maoy): a VM may get into the paused state not only
7190                 # because the user request via API calls, but also
7191                 # due to (temporary) external instrumentations.
7192                 # Before the virt layer can reliably report the reason,
7193                 # we simply ignore the state discrepancy. In many cases,
7194                 # the VM state will go back to running after the external
7195                 # instrumentation is done. See bug 1097806 for details.
7196                 LOG.warning("Instance is paused unexpectedly. Ignore.",
7197                             instance=db_instance)
7198             elif vm_power_state == power_state.NOSTATE:
7199                 # Occasionally, depending on the status of the hypervisor,
7200                 # which could be restarting for example, an instance may
7201                 # not be found.  Therefore just log the condition.
7202                 LOG.warning("Instance is unexpectedly not found. Ignore.",
7203                             instance=db_instance)
7204         elif vm_state == vm_states.STOPPED:
7205             if vm_power_state not in (power_state.NOSTATE,
7206                                       power_state.SHUTDOWN,
7207                                       power_state.CRASHED):
7208                 LOG.warning("Instance is not stopped. Calling "
7209                             "the stop API. Current vm_state: %(vm_state)s,"
7210                             " current task_state: %(task_state)s, "
7211                             "original DB power_state: %(db_power_state)s, "
7212                             "current VM power_state: %(vm_power_state)s",
7213                             {'vm_state': vm_state,
7214                              'task_state': db_instance.task_state,
7215                              'db_power_state': orig_db_power_state,
7216                              'vm_power_state': vm_power_state},
7217                             instance=db_instance)
7218                 try:
7219                     # NOTE(russellb) Force the stop, because normally the
7220                     # compute API would not allow an attempt to stop a stopped
7221                     # instance.
7222                     self.compute_api.force_stop(context, db_instance)
7223                 except Exception:
7224                     LOG.exception("error during stop() in sync_power_state.",
7225                                   instance=db_instance)
7226         elif vm_state == vm_states.PAUSED:
7227             if vm_power_state in (power_state.SHUTDOWN,
7228                                   power_state.CRASHED):
7229                 LOG.warning("Paused instance shutdown by itself. Calling "
7230                             "the stop API.", instance=db_instance)
7231                 try:
7232                     self.compute_api.force_stop(context, db_instance)
7233                 except Exception:
7234                     LOG.exception("error during stop() in sync_power_state.",
7235                                   instance=db_instance)
7236         elif vm_state in (vm_states.SOFT_DELETED,
7237                           vm_states.DELETED):
7238             if vm_power_state not in (power_state.NOSTATE,
7239                                       power_state.SHUTDOWN):
7240                 # Note(maoy): this should be taken care of periodically in
7241                 # _cleanup_running_deleted_instances().
7242                 LOG.warning("Instance is not (soft-)deleted.",
7243                             instance=db_instance)
7244 
7245     @periodic_task.periodic_task
7246     def _reclaim_queued_deletes(self, context):
7247         """Reclaim instances that are queued for deletion."""
7248         interval = CONF.reclaim_instance_interval
7249         if interval <= 0:
7250             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
7251             return
7252 
7253         filters = {'vm_state': vm_states.SOFT_DELETED,
7254                    'task_state': None,
7255                    'host': self.host}
7256         instances = objects.InstanceList.get_by_filters(
7257             context, filters,
7258             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
7259             use_slave=True)
7260         for instance in instances:
7261             if self._deleted_old_enough(instance, interval):
7262                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7263                         context, instance.uuid)
7264                 LOG.info('Reclaiming deleted instance', instance=instance)
7265                 try:
7266                     self._delete_instance(context, instance, bdms)
7267                 except Exception as e:
7268                     LOG.warning("Periodic reclaim failed to delete "
7269                                 "instance: %s",
7270                                 e, instance=instance)
7271 
7272     def _get_nodename(self, instance, refresh=False):
7273         """Helper method to get the name of the first available node
7274         on this host. This method should not be used with any operations
7275         on ironic instances since it does not handle multiple nodes.
7276         """
7277         node = self.driver.get_available_nodes(refresh=refresh)[0]
7278         LOG.debug("No node specified, defaulting to %s", node,
7279                   instance=instance)
7280         return node
7281 
7282     def update_available_resource_for_node(self, context, nodename):
7283 
7284         rt = self._get_resource_tracker()
7285         try:
7286             rt.update_available_resource(context, nodename)
7287         except exception.ComputeHostNotFound:
7288             # NOTE(comstud): We can get to this case if a node was
7289             # marked 'deleted' in the DB and then re-added with a
7290             # different auto-increment id. The cached resource
7291             # tracker tried to update a deleted record and failed.
7292             # Don't add this resource tracker to the new dict, so
7293             # that this will resolve itself on the next run.
7294             LOG.info("Compute node '%s' not found in "
7295                      "update_available_resource.", nodename)
7296             # TODO(jaypipes): Yes, this is inefficient to throw away all of the
7297             # compute nodes to force a rebuild, but this is only temporary
7298             # until Ironic baremetal node resource providers are tracked
7299             # properly in the report client and this is a tiny edge case
7300             # anyway.
7301             self._resource_tracker = None
7302             return
7303         except Exception:
7304             LOG.exception("Error updating resources for node %(node)s.",
7305                           {'node': nodename})
7306 
7307     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
7308     def update_available_resource(self, context, startup=False):
7309         """See driver.get_available_resource()
7310 
7311         Periodic process that keeps that the compute host's understanding of
7312         resource availability and usage in sync with the underlying hypervisor.
7313 
7314         :param context: security context
7315         :param startup: True if this is being called when the nova-compute
7316             service is starting, False otherwise.
7317         """
7318 
7319         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
7320                                                             use_slave=True,
7321                                                             startup=startup)
7322         nodenames = set(self.driver.get_available_nodes())
7323         for nodename in nodenames:
7324             self.update_available_resource_for_node(context, nodename)
7325 
7326         # Delete orphan compute node not reported by driver but still in db
7327         for cn in compute_nodes_in_db:
7328             if cn.hypervisor_hostname not in nodenames:
7329                 LOG.info("Deleting orphan compute node %(id)s "
7330                          "hypervisor host is %(hh)s, "
7331                          "nodes are %(nodes)s",
7332                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
7333                           'nodes': nodenames})
7334                 cn.destroy()
7335                 # Delete the corresponding resource provider in placement,
7336                 # along with any associated allocations and inventory.
7337                 # TODO(cdent): Move use of reportclient into resource tracker.
7338                 self.scheduler_client.reportclient.delete_resource_provider(
7339                     context, cn, cascade=True)
7340 
7341     def _get_compute_nodes_in_db(self, context, use_slave=False,
7342                                  startup=False):
7343         try:
7344             return objects.ComputeNodeList.get_all_by_host(context, self.host,
7345                                                            use_slave=use_slave)
7346         except exception.NotFound:
7347             if startup:
7348                 LOG.warning(
7349                     "No compute node record found for host %s. If this is "
7350                     "the first time this service is starting on this "
7351                     "host, then you can ignore this warning.", self.host)
7352             else:
7353                 LOG.error("No compute node record for host %s", self.host)
7354             return []
7355 
7356     @periodic_task.periodic_task(
7357         spacing=CONF.running_deleted_instance_poll_interval)
7358     def _cleanup_running_deleted_instances(self, context):
7359         """Cleanup any instances which are erroneously still running after
7360         having been deleted.
7361 
7362         Valid actions to take are:
7363 
7364             1. noop - do nothing
7365             2. log - log which instances are erroneously running
7366             3. reap - shutdown and cleanup any erroneously running instances
7367             4. shutdown - power off *and disable* any erroneously running
7368                           instances
7369 
7370         The use-case for this cleanup task is: for various reasons, it may be
7371         possible for the database to show an instance as deleted but for that
7372         instance to still be running on a host machine (see bug
7373         https://bugs.launchpad.net/nova/+bug/911366).
7374 
7375         This cleanup task is a cross-hypervisor utility for finding these
7376         zombied instances and either logging the discrepancy (likely what you
7377         should do in production), or automatically reaping the instances (more
7378         appropriate for dev environments).
7379         """
7380         action = CONF.running_deleted_instance_action
7381 
7382         if action == "noop":
7383             return
7384 
7385         # NOTE(sirp): admin contexts don't ordinarily return deleted records
7386         with utils.temporary_mutation(context, read_deleted="yes"):
7387             for instance in self._running_deleted_instances(context):
7388                 if action == "log":
7389                     LOG.warning("Detected instance with name label "
7390                                 "'%s' which is marked as "
7391                                 "DELETED but still present on host.",
7392                                 instance.name, instance=instance)
7393 
7394                 elif action == 'shutdown':
7395                     LOG.info("Powering off instance with name label "
7396                              "'%s' which is marked as "
7397                              "DELETED but still present on host.",
7398                              instance.name, instance=instance)
7399                     try:
7400                         try:
7401                             # disable starting the instance
7402                             self.driver.set_bootable(instance, False)
7403                         except NotImplementedError:
7404                             LOG.debug("set_bootable is not implemented "
7405                                       "for the current driver")
7406                         # and power it off
7407                         self.driver.power_off(instance)
7408                     except Exception:
7409                         LOG.warning("Failed to power off instance",
7410                                     instance=instance, exc_info=True)
7411 
7412                 elif action == 'reap':
7413                     LOG.info("Destroying instance with name label "
7414                              "'%s' which is marked as "
7415                              "DELETED but still present on host.",
7416                              instance.name, instance=instance)
7417                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7418                         context, instance.uuid, use_slave=True)
7419                     self.instance_events.clear_events_for_instance(instance)
7420                     try:
7421                         self._shutdown_instance(context, instance, bdms,
7422                                                 notify=False)
7423                         self._cleanup_volumes(context, instance, bdms)
7424                     except Exception as e:
7425                         LOG.warning("Periodic cleanup failed to delete "
7426                                     "instance: %s",
7427                                     e, instance=instance)
7428                 else:
7429                     raise Exception(_("Unrecognized value '%s'"
7430                                       " for CONF.running_deleted_"
7431                                       "instance_action") % action)
7432 
7433     def _running_deleted_instances(self, context):
7434         """Returns a list of instances nova thinks is deleted,
7435         but the hypervisor thinks is still running.
7436         """
7437         timeout = CONF.running_deleted_instance_timeout
7438         filters = {'deleted': True,
7439                    'soft_deleted': False}
7440         instances = self._get_instances_on_driver(context, filters)
7441         return [i for i in instances if self._deleted_old_enough(i, timeout)]
7442 
7443     def _deleted_old_enough(self, instance, timeout):
7444         deleted_at = instance.deleted_at
7445         if deleted_at:
7446             deleted_at = deleted_at.replace(tzinfo=None)
7447         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
7448 
7449     @contextlib.contextmanager
7450     def _error_out_instance_on_exception(self, context, instance,
7451                                          instance_state=vm_states.ACTIVE):
7452         instance_uuid = instance.uuid
7453         try:
7454             yield
7455         except NotImplementedError as error:
7456             with excutils.save_and_reraise_exception():
7457                 LOG.info("Setting instance back to %(state)s after: "
7458                          "%(error)s",
7459                          {'state': instance_state, 'error': error},
7460                          instance_uuid=instance_uuid)
7461                 self._instance_update(context, instance,
7462                                       vm_state=instance_state,
7463                                       task_state=None)
7464         except exception.InstanceFaultRollback as error:
7465             LOG.info("Setting instance back to ACTIVE after: %s",
7466                      error, instance_uuid=instance_uuid)
7467             self._instance_update(context, instance,
7468                                   vm_state=vm_states.ACTIVE,
7469                                   task_state=None)
7470             raise error.inner_exception
7471         except Exception:
7472             LOG.exception('Setting instance vm_state to ERROR',
7473                           instance_uuid=instance_uuid)
7474             with excutils.save_and_reraise_exception():
7475                 self._set_instance_obj_error_state(context, instance)
7476 
7477     @wrap_exception()
7478     def add_aggregate_host(self, context, aggregate, host, slave_info):
7479         """Notify hypervisor of change (for hypervisor pools)."""
7480         try:
7481             self.driver.add_to_aggregate(context, aggregate, host,
7482                                          slave_info=slave_info)
7483         except NotImplementedError:
7484             LOG.debug('Hypervisor driver does not support '
7485                       'add_aggregate_host')
7486         except exception.AggregateError:
7487             with excutils.save_and_reraise_exception():
7488                 self.driver.undo_aggregate_operation(
7489                                     context,
7490                                     aggregate.delete_host,
7491                                     aggregate, host)
7492 
7493     @wrap_exception()
7494     def remove_aggregate_host(self, context, host, slave_info, aggregate):
7495         """Removes a host from a physical hypervisor pool."""
7496         try:
7497             self.driver.remove_from_aggregate(context, aggregate, host,
7498                                               slave_info=slave_info)
7499         except NotImplementedError:
7500             LOG.debug('Hypervisor driver does not support '
7501                       'remove_aggregate_host')
7502         except (exception.AggregateError,
7503                 exception.InvalidAggregateAction) as e:
7504             with excutils.save_and_reraise_exception():
7505                 self.driver.undo_aggregate_operation(
7506                                     context,
7507                                     aggregate.add_host,
7508                                     aggregate, host,
7509                                     isinstance(e, exception.AggregateError))
7510 
7511     def _process_instance_event(self, instance, event):
7512         _event = self.instance_events.pop_instance_event(instance, event)
7513         if _event:
7514             LOG.debug('Processing event %(event)s',
7515                       {'event': event.key}, instance=instance)
7516             _event.send(event)
7517         else:
7518             # If it's a network-vif-unplugged event and the instance is being
7519             # deleted then we don't need to make this a warning as it's
7520             # expected. There are other things which could trigger this like
7521             # detaching an interface, but we don't have a task state for that.
7522             if (event.name == 'network-vif-unplugged' and
7523                     instance.task_state == task_states.DELETING):
7524                 LOG.debug('Received event %s for instance which is being '
7525                           'deleted.', event.key, instance=instance)
7526             else:
7527                 LOG.warning('Received unexpected event %(event)s for '
7528                             'instance with vm_state %(vm_state)s and '
7529                             'task_state %(task_state)s.',
7530                             {'event': event.key,
7531                              'vm_state': instance.vm_state,
7532                              'task_state': instance.task_state},
7533                             instance=instance)
7534 
7535     def _process_instance_vif_deleted_event(self, context, instance,
7536                                             deleted_vif_id):
7537         # If an attached port is deleted by neutron, it needs to
7538         # be detached from the instance.
7539         # And info cache needs to be updated.
7540         network_info = instance.info_cache.network_info
7541         for index, vif in enumerate(network_info):
7542             if vif['id'] == deleted_vif_id:
7543                 LOG.info('Neutron deleted interface %(intf)s; '
7544                          'detaching it from the instance and '
7545                          'deleting it from the info cache',
7546                          {'intf': vif['id']},
7547                          instance=instance)
7548                 del network_info[index]
7549                 base_net_api.update_instance_cache_with_nw_info(
7550                                  self.network_api, context,
7551                                  instance,
7552                                  nw_info=network_info)
7553                 try:
7554                     self.driver.detach_interface(context, instance, vif)
7555                 except NotImplementedError:
7556                     # Not all virt drivers support attach/detach of interfaces
7557                     # yet (like Ironic), so just ignore this.
7558                     pass
7559                 except exception.NovaException as ex:
7560                     LOG.warning("Detach interface failed, "
7561                                 "port_id=%(port_id)s, reason: %(msg)s",
7562                                 {'port_id': deleted_vif_id, 'msg': ex},
7563                                 instance=instance)
7564                 break
7565 
7566     @wrap_instance_event(prefix='compute')
7567     @wrap_instance_fault
7568     def extend_volume(self, context, instance, extended_volume_id):
7569 
7570         # If an attached volume is extended by cinder, it needs to
7571         # be extended by virt driver so host can detect its new size.
7572         # And bdm needs to be updated.
7573         LOG.debug('Handling volume-extended event for volume %(vol)s',
7574                   {'vol': extended_volume_id}, instance=instance)
7575 
7576         try:
7577             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
7578                    context, extended_volume_id, instance.uuid)
7579         except exception.NotFound:
7580             LOG.warning('Extend volume failed, '
7581                         'volume %(vol)s is not attached to instance.',
7582                         {'vol': extended_volume_id},
7583                         instance=instance)
7584             return
7585 
7586         LOG.info('Cinder extended volume %(vol)s; '
7587                  'extending it to detect new size',
7588                  {'vol': extended_volume_id},
7589                  instance=instance)
7590         volume = self.volume_api.get(context, bdm.volume_id)
7591 
7592         if bdm.connection_info is None:
7593             LOG.warning('Extend volume failed, '
7594                         'attached volume %(vol)s has no connection_info',
7595                         {'vol': extended_volume_id},
7596                         instance=instance)
7597             return
7598 
7599         connection_info = jsonutils.loads(bdm.connection_info)
7600         bdm.volume_size = volume['size']
7601         bdm.save()
7602 
7603         if not self.driver.capabilities.get('supports_extend_volume', False):
7604             raise exception.ExtendVolumeNotSupported()
7605 
7606         try:
7607             self.driver.extend_volume(connection_info,
7608                                       instance)
7609         except Exception as ex:
7610             LOG.warning('Extend volume failed, '
7611                         'volume_id=%(volume_id)s, reason: %(msg)s',
7612                         {'volume_id': extended_volume_id, 'msg': ex},
7613                         instance=instance)
7614             raise
7615 
7616     @wrap_exception()
7617     def external_instance_event(self, context, instances, events):
7618         # NOTE(danms): Some event types are handled by the manager, such
7619         # as when we're asked to update the instance's info_cache. If it's
7620         # not one of those, look for some thread(s) waiting for the event and
7621         # unblock them if so.
7622         for event in events:
7623             instance = [inst for inst in instances
7624                         if inst.uuid == event.instance_uuid][0]
7625             LOG.debug('Received event %(event)s',
7626                       {'event': event.key},
7627                       instance=instance)
7628             if event.name == 'network-changed':
7629                 try:
7630                     self.network_api.get_instance_nw_info(context, instance)
7631                 except exception.NotFound as e:
7632                     LOG.info('Failed to process external instance event '
7633                              '%(event)s due to: %(error)s',
7634                              {'event': event.key, 'error': six.text_type(e)},
7635                              instance=instance)
7636             elif event.name == 'network-vif-deleted':
7637                 try:
7638                     self._process_instance_vif_deleted_event(context,
7639                                                              instance,
7640                                                              event.tag)
7641                 except exception.NotFound as e:
7642                     LOG.info('Failed to process external instance event '
7643                              '%(event)s due to: %(error)s',
7644                              {'event': event.key, 'error': six.text_type(e)},
7645                              instance=instance)
7646             elif event.name == 'volume-extended':
7647                 self.extend_volume(context, instance, event.tag)
7648             else:
7649                 self._process_instance_event(instance, event)
7650 
7651     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
7652                                  external_process_ok=True)
7653     def _run_image_cache_manager_pass(self, context):
7654         """Run a single pass of the image cache manager."""
7655 
7656         if not self.driver.capabilities.get("has_imagecache", False):
7657             return
7658 
7659         # Determine what other nodes use this storage
7660         storage_users.register_storage_use(CONF.instances_path, CONF.host)
7661         nodes = storage_users.get_storage_users(CONF.instances_path)
7662 
7663         # Filter all_instances to only include those nodes which share this
7664         # storage path.
7665         # TODO(mikal): this should be further refactored so that the cache
7666         # cleanup code doesn't know what those instances are, just a remote
7667         # count, and then this logic should be pushed up the stack.
7668         filters = {'deleted': False,
7669                    'soft_deleted': True,
7670                    'host': nodes}
7671         filtered_instances = objects.InstanceList.get_by_filters(context,
7672                                  filters, expected_attrs=[], use_slave=True)
7673 
7674         self.driver.manage_image_cache(context, filtered_instances)
7675 
7676     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7677     def _run_pending_deletes(self, context):
7678         """Retry any pending instance file deletes."""
7679         LOG.debug('Cleaning up deleted instances')
7680         filters = {'deleted': True,
7681                    'soft_deleted': False,
7682                    'host': CONF.host,
7683                    'cleaned': False}
7684         attrs = ['system_metadata']
7685         with utils.temporary_mutation(context, read_deleted='yes'):
7686             instances = objects.InstanceList.get_by_filters(
7687                 context, filters, expected_attrs=attrs, use_slave=True)
7688         LOG.debug('There are %d instances to clean', len(instances))
7689 
7690         # TODO(raj_singh): Remove this if condition when min value is
7691         # introduced to "maximum_instance_delete_attempts" cfg option.
7692         if CONF.maximum_instance_delete_attempts < 1:
7693             LOG.warning('Future versions of Nova will restrict the '
7694                         '"maximum_instance_delete_attempts" config option '
7695                         'to values >=1. Update your configuration file to '
7696                         'mitigate future upgrade issues.')
7697 
7698         for instance in instances:
7699             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
7700             LOG.debug('Instance has had %(attempts)s of %(max)s '
7701                       'cleanup attempts',
7702                       {'attempts': attempts,
7703                        'max': CONF.maximum_instance_delete_attempts},
7704                       instance=instance)
7705             if attempts < CONF.maximum_instance_delete_attempts:
7706                 success = self.driver.delete_instance_files(instance)
7707 
7708                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
7709                 if success:
7710                     instance.cleaned = True
7711                 with utils.temporary_mutation(context, read_deleted='yes'):
7712                     instance.save()
7713 
7714     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
7715     def _cleanup_incomplete_migrations(self, context):
7716         """Delete instance files on failed resize/revert-resize operation
7717 
7718         During resize/revert-resize operation, if that instance gets deleted
7719         in-between then instance files might remain either on source or
7720         destination compute node because of race condition.
7721         """
7722         LOG.debug('Cleaning up deleted instances with incomplete migration ')
7723         migration_filters = {'host': CONF.host,
7724                              'status': 'error'}
7725         migrations = objects.MigrationList.get_by_filters(context,
7726                                                           migration_filters)
7727 
7728         if not migrations:
7729             return
7730 
7731         inst_uuid_from_migrations = set([migration.instance_uuid for migration
7732                                          in migrations])
7733 
7734         inst_filters = {'deleted': True, 'soft_deleted': False,
7735                         'uuid': inst_uuid_from_migrations}
7736         attrs = ['info_cache', 'security_groups', 'system_metadata']
7737         with utils.temporary_mutation(context, read_deleted='yes'):
7738             instances = objects.InstanceList.get_by_filters(
7739                 context, inst_filters, expected_attrs=attrs, use_slave=True)
7740 
7741         for instance in instances:
7742             if instance.host != CONF.host:
7743                 for migration in migrations:
7744                     if instance.uuid == migration.instance_uuid:
7745                         # Delete instance files if not cleanup properly either
7746                         # from the source or destination compute nodes when
7747                         # the instance is deleted during resizing.
7748                         self.driver.delete_instance_files(instance)
7749                         try:
7750                             migration.status = 'failed'
7751                             with migration.obj_as_admin():
7752                                 migration.save()
7753                         except exception.MigrationNotFound:
7754                             LOG.warning("Migration %s is not found.",
7755                                         migration.id,
7756                                         instance=instance)
7757                         break
7758 
7759     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7760                                    exception.QemuGuestAgentNotEnabled,
7761                                    exception.NovaException,
7762                                    NotImplementedError)
7763     @wrap_exception()
7764     def quiesce_instance(self, context, instance):
7765         """Quiesce an instance on this host."""
7766         context = context.elevated()
7767         image_meta = objects.ImageMeta.from_instance(instance)
7768         self.driver.quiesce(context, instance, image_meta)
7769 
7770     def _wait_for_snapshots_completion(self, context, mapping):
7771         for mapping_dict in mapping:
7772             if mapping_dict.get('source_type') == 'snapshot':
7773 
7774                 def _wait_snapshot():
7775                     snapshot = self.volume_api.get_snapshot(
7776                         context, mapping_dict['snapshot_id'])
7777                     if snapshot.get('status') != 'creating':
7778                         raise loopingcall.LoopingCallDone()
7779 
7780                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
7781                 timer.start(interval=0.5).wait()
7782 
7783     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
7784                                    exception.QemuGuestAgentNotEnabled,
7785                                    exception.NovaException,
7786                                    NotImplementedError)
7787     @wrap_exception()
7788     def unquiesce_instance(self, context, instance, mapping=None):
7789         """Unquiesce an instance on this host.
7790 
7791         If snapshots' image mapping is provided, it waits until snapshots are
7792         completed before unqueiscing.
7793         """
7794         context = context.elevated()
7795         if mapping:
7796             try:
7797                 self._wait_for_snapshots_completion(context, mapping)
7798             except Exception as error:
7799                 LOG.exception("Exception while waiting completion of "
7800                               "volume snapshots: %s",
7801                               error, instance=instance)
7802         image_meta = objects.ImageMeta.from_instance(instance)
7803         self.driver.unquiesce(context, instance, image_meta)
