I want you to act as a code reviewer of Nova in OpenStack. Please review the code below to detect security defects. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are found, please state '''No security defects are detected in the code'''.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import binascii
30 import contextlib
31 import functools
32 import inspect
33 import sys
34 import time
35 import traceback
36 
37 from cinderclient import exceptions as cinder_exception
38 from cursive import exception as cursive_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 import futurist
44 from keystoneauth1 import exceptions as keystone_exception
45 from oslo_log import log as logging
46 import oslo_messaging as messaging
47 from oslo_serialization import jsonutils
48 from oslo_service import loopingcall
49 from oslo_service import periodic_task
50 from oslo_utils import excutils
51 from oslo_utils import strutils
52 from oslo_utils import timeutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova import compute
59 from nova.compute import build_results
60 from nova.compute import claims
61 from nova.compute import power_state
62 from nova.compute import resource_tracker
63 from nova.compute import rpcapi as compute_rpcapi
64 from nova.compute import task_states
65 from nova.compute import utils as compute_utils
66 from nova.compute.utils import wrap_instance_event
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova.console import rpcapi as console_rpcapi
71 import nova.context
72 from nova import exception
73 from nova import exception_wrapper
74 from nova import hooks
75 from nova.i18n import _
76 from nova import image
77 from nova import manager
78 from nova import network
79 from nova.network import base_api as base_net_api
80 from nova.network import model as network_model
81 from nova.network.security_group import openstack_driver
82 from nova import objects
83 from nova.objects import base as obj_base
84 from nova.objects import fields
85 from nova.objects import instance as obj_instance
86 from nova.objects import migrate_data as migrate_data_obj
87 from nova.pci import whitelist
88 from nova import rpc
89 from nova import safe_utils
90 from nova.scheduler.client import query
91 from nova import utils
92 from nova.virt import block_device as driver_block_device
93 from nova.virt import configdrive
94 from nova.virt import driver
95 from nova.virt import event as virtevent
96 from nova.virt import storage_users
97 from nova.virt import virtapi
98 from nova.volume import cinder
99 
100 CONF = nova.conf.CONF
101 
102 LOG = logging.getLogger(__name__)
103 
104 get_notifier = functools.partial(rpc.get_notifier, service='compute')
105 wrap_exception = functools.partial(exception_wrapper.wrap_exception,
106                                    get_notifier=get_notifier,
107                                    binary='nova-compute')
108 
109 
110 @contextlib.contextmanager
111 def errors_out_migration_ctxt(migration):
112     """Context manager to error out migration on failure."""
113 
114     try:
115         yield
116     except Exception:
117         with excutils.save_and_reraise_exception():
118             if migration:
119                 # We may have been passed None for our migration if we're
120                 # receiving from an older client. The migration will be
121                 # errored via the legacy path.
122                 migration.status = 'error'
123                 try:
124                     with migration.obj_as_admin():
125                         migration.save()
126                 except Exception:
127                     LOG.debug(
128                         'Error setting migration status for instance %s.',
129                         migration.instance_uuid, exc_info=True)
130 
131 
132 @utils.expects_func_args('migration')
133 def errors_out_migration(function):
134     """Decorator to error out migration on failure."""
135 
136     @functools.wraps(function)
137     def decorated_function(self, context, *args, **kwargs):
138         wrapped_func = safe_utils.get_wrapped_function(function)
139         keyed_args = inspect.getcallargs(wrapped_func, self, context,
140                                          *args, **kwargs)
141         migration = keyed_args['migration']
142         with errors_out_migration_ctxt(migration):
143             return function(self, context, *args, **kwargs)
144 
145     return decorated_function
146 
147 
148 @utils.expects_func_args('instance')
149 def reverts_task_state(function):
150     """Decorator to revert task_state on failure."""
151 
152     @functools.wraps(function)
153     def decorated_function(self, context, *args, **kwargs):
154         try:
155             return function(self, context, *args, **kwargs)
156         except exception.UnexpectedTaskStateError as e:
157             # Note(maoy): unexpected task state means the current
158             # task is preempted. Do not clear task state in this
159             # case.
160             with excutils.save_and_reraise_exception():
161                 LOG.info("Task possibly preempted: %s",
162                          e.format_message())
163         except Exception:
164             with excutils.save_and_reraise_exception():
165                 wrapped_func = safe_utils.get_wrapped_function(function)
166                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
167                                                  *args, **kwargs)
168                 # NOTE(mriedem): 'instance' must be in keyed_args because we
169                 # have utils.expects_func_args('instance') decorating this
170                 # method.
171                 instance = keyed_args['instance']
172                 original_task_state = instance.task_state
173                 try:
174                     self._instance_update(context, instance, task_state=None)
175                     LOG.info("Successfully reverted task state from %s on "
176                              "failure for instance.",
177                              original_task_state, instance=instance)
178                 except exception.InstanceNotFound:
179                     # We might delete an instance that failed to build shortly
180                     # after it errored out this is an expected case and we
181                     # should not trace on it.
182                     pass
183                 except Exception as e:
184                     LOG.warning("Failed to revert task state for instance. "
185                                 "Error: %s", e, instance=instance)
186 
187     return decorated_function
188 
189 
190 @utils.expects_func_args('instance')
191 def wrap_instance_fault(function):
192     """Wraps a method to catch exceptions related to instances.
193 
194     This decorator wraps a method to catch any exceptions having to do with
195     an instance that may get thrown. It then logs an instance fault in the db.
196     """
197 
198     @functools.wraps(function)
199     def decorated_function(self, context, *args, **kwargs):
200         try:
201             return function(self, context, *args, **kwargs)
202         except exception.InstanceNotFound:
203             raise
204         except Exception as e:
205             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
206             # we will get a KeyError exception which will cover up the real
207             # exception. So, we update kwargs with the values from args first.
208             # then, we can get 'instance' from kwargs easily.
209             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
210 
211             with excutils.save_and_reraise_exception():
212                 compute_utils.add_instance_fault_from_exc(context,
213                         kwargs['instance'], e, sys.exc_info())
214 
215     return decorated_function
216 
217 
218 @utils.expects_func_args('image_id', 'instance')
219 def delete_image_on_error(function):
220     """Used for snapshot related method to ensure the image created in
221     compute.api is deleted when an error occurs.
222     """
223 
224     @functools.wraps(function)
225     def decorated_function(self, context, image_id, instance,
226                            *args, **kwargs):
227         try:
228             return function(self, context, image_id, instance,
229                             *args, **kwargs)
230         except Exception:
231             with excutils.save_and_reraise_exception():
232                 LOG.debug("Cleaning up image %s", image_id,
233                           exc_info=True, instance=instance)
234                 try:
235                     self.image_api.delete(context, image_id)
236                 except exception.ImageNotFound:
237                     # Since we're trying to cleanup an image, we don't care if
238                     # if it's already gone.
239                     pass
240                 except Exception:
241                     LOG.exception("Error while trying to clean up image %s",
242                                   image_id, instance=instance)
243 
244     return decorated_function
245 
246 
247 # TODO(danms): Remove me after Icehouse
248 # TODO(alaski): Actually remove this after Newton, assuming a major RPC bump
249 # NOTE(mikal): if the method being decorated has more than one decorator, then
250 # put this one first. Otherwise the various exception handling decorators do
251 # not function correctly.
252 def object_compat(function):
253     """Wraps a method that expects a new-world instance
254 
255     This provides compatibility for callers passing old-style dict
256     instances.
257     """
258 
259     @functools.wraps(function)
260     def decorated_function(self, context, *args, **kwargs):
261         def _load_instance(instance_or_dict):
262             if isinstance(instance_or_dict, dict):
263                 # try to get metadata and system_metadata for most cases but
264                 # only attempt to load those if the db instance already has
265                 # those fields joined
266                 metas = [meta for meta in ('metadata', 'system_metadata')
267                          if meta in instance_or_dict]
268                 instance = objects.Instance._from_db_object(
269                     context, objects.Instance(), instance_or_dict,
270                     expected_attrs=metas)
271                 instance._context = context
272                 return instance
273             return instance_or_dict
274 
275         try:
276             kwargs['instance'] = _load_instance(kwargs['instance'])
277         except KeyError:
278             args = (_load_instance(args[0]),) + args[1:]
279 
280         migration = kwargs.get('migration')
281         if isinstance(migration, dict):
282             migration = objects.Migration._from_db_object(
283                     context.elevated(), objects.Migration(),
284                     migration)
285             kwargs['migration'] = migration
286 
287         return function(self, context, *args, **kwargs)
288 
289     return decorated_function
290 
291 
292 class InstanceEvents(object):
293     def __init__(self):
294         self._events = {}
295 
296     @staticmethod
297     def _lock_name(instance):
298         return '%s-%s' % (instance.uuid, 'events')
299 
300     def prepare_for_instance_event(self, instance, name, tag):
301         """Prepare to receive an event for an instance.
302 
303         This will register an event for the given instance that we will
304         wait on later. This should be called before initiating whatever
305         action will trigger the event. The resulting eventlet.event.Event
306         object should be wait()'d on to ensure completion.
307 
308         :param instance: the instance for which the event will be generated
309         :param name: the name of the event we're expecting
310         :param tag: the tag associated with the event we're expecting
311         :returns: an event object that should be wait()'d on
312         """
313         if self._events is None:
314             # NOTE(danms): We really should have a more specific error
315             # here, but this is what we use for our default error case
316             raise exception.NovaException('In shutdown, no new events '
317                                           'can be scheduled')
318 
319         @utils.synchronized(self._lock_name(instance))
320         def _create_or_get_event():
321             instance_events = self._events.setdefault(instance.uuid, {})
322             return instance_events.setdefault((name, tag),
323                                               eventlet.event.Event())
324         LOG.debug('Preparing to wait for external event %(name)s-%(tag)s',
325                   {'name': name, 'tag': tag}, instance=instance)
326         return _create_or_get_event()
327 
328     def pop_instance_event(self, instance, event):
329         """Remove a pending event from the wait list.
330 
331         This will remove a pending event from the wait list so that it
332         can be used to signal the waiters to wake up.
333 
334         :param instance: the instance for which the event was generated
335         :param event: the nova.objects.external_event.InstanceExternalEvent
336                       that describes the event
337         :returns: the eventlet.event.Event object on which the waiters
338                   are blocked
339         """
340         no_events_sentinel = object()
341         no_matching_event_sentinel = object()
342 
343         @utils.synchronized(self._lock_name(instance))
344         def _pop_event():
345             if self._events is None:
346                 LOG.debug('Unexpected attempt to pop events during shutdown',
347                           instance=instance)
348                 return no_events_sentinel
349             events = self._events.get(instance.uuid)
350             if not events:
351                 return no_events_sentinel
352             _event = events.pop((event.name, event.tag), None)
353             if not events:
354                 del self._events[instance.uuid]
355             if _event is None:
356                 return no_matching_event_sentinel
357             return _event
358 
359         result = _pop_event()
360         if result is no_events_sentinel:
361             LOG.debug('No waiting events found dispatching %(event)s',
362                       {'event': event.key},
363                       instance=instance)
364             return None
365         elif result is no_matching_event_sentinel:
366             LOG.debug('No event matching %(event)s in %(events)s',
367                       {'event': event.key,
368                        'events': self._events.get(instance.uuid, {}).keys()},
369                       instance=instance)
370             return None
371         else:
372             return result
373 
374     def clear_events_for_instance(self, instance):
375         """Remove all pending events for an instance.
376 
377         This will remove all events currently pending for an instance
378         and return them (indexed by event name).
379 
380         :param instance: the instance for which events should be purged
381         :returns: a dictionary of {event_name: eventlet.event.Event}
382         """
383         @utils.synchronized(self._lock_name(instance))
384         def _clear_events():
385             if self._events is None:
386                 LOG.debug('Unexpected attempt to clear events during shutdown',
387                           instance=instance)
388                 return dict()
389             # NOTE(danms): We have historically returned the raw internal
390             # format here, which is {event.key: [events, ...])} so just
391             # trivially convert it here.
392             return {'%s-%s' % k: e
393                     for k, e in self._events.pop(instance.uuid, {}).items()}
394         return _clear_events()
395 
396     def cancel_all_events(self):
397         if self._events is None:
398             LOG.debug('Unexpected attempt to cancel events during shutdown.')
399             return
400         our_events = self._events
401         # NOTE(danms): Block new events
402         self._events = None
403 
404         for instance_uuid, events in our_events.items():
405             for (name, tag), eventlet_event in events.items():
406                 LOG.debug('Canceling in-flight event %(name)s-%(tag)s for '
407                           'instance %(instance_uuid)s',
408                           {'name': name,
409                            'tag': tag,
410                            'instance_uuid': instance_uuid})
411                 event = objects.InstanceExternalEvent(
412                     instance_uuid=instance_uuid,
413                     name=name, status='failed',
414                     tag=tag, data={})
415                 eventlet_event.send(event)
416 
417 
418 class ComputeVirtAPI(virtapi.VirtAPI):
419     def __init__(self, compute):
420         super(ComputeVirtAPI, self).__init__()
421         self._compute = compute
422 
423     def _default_error_callback(self, event_name, instance):
424         raise exception.NovaException(_('Instance event failed'))
425 
426     @contextlib.contextmanager
427     def wait_for_instance_event(self, instance, event_names, deadline=300,
428                                 error_callback=None):
429         """Plan to wait for some events, run some code, then wait.
430 
431         This context manager will first create plans to wait for the
432         provided event_names, yield, and then wait for all the scheduled
433         events to complete.
434 
435         Note that this uses an eventlet.timeout.Timeout to bound the
436         operation, so callers should be prepared to catch that
437         failure and handle that situation appropriately.
438 
439         If the event is not received by the specified timeout deadline,
440         eventlet.timeout.Timeout is raised.
441 
442         If the event is received but did not have a 'completed'
443         status, a NovaException is raised.  If an error_callback is
444         provided, instead of raising an exception as detailed above
445         for the failure case, the callback will be called with the
446         event_name and instance, and can return True to continue
447         waiting for the rest of the events, False to stop processing,
448         or raise an exception which will bubble up to the waiter.
449 
450         :param instance: The instance for which an event is expected
451         :param event_names: A list of event names. Each element is a
452                             tuple of strings to indicate (name, tag),
453                             where name is required, but tag may be None.
454         :param deadline: Maximum number of seconds we should wait for all
455                          of the specified events to arrive.
456         :param error_callback: A function to be called if an event arrives
457 
458         """
459 
460         if error_callback is None:
461             error_callback = self._default_error_callback
462         events = {}
463         for event_name in event_names:
464             name, tag = event_name
465             event_name = objects.InstanceExternalEvent.make_key(name, tag)
466             try:
467                 events[event_name] = (
468                     self._compute.instance_events.prepare_for_instance_event(
469                         instance, name, tag))
470             except exception.NovaException:
471                 error_callback(event_name, instance)
472                 # NOTE(danms): Don't wait for any of the events. They
473                 # should all be canceled and fired immediately below,
474                 # but don't stick around if not.
475                 deadline = 0
476         yield
477         with eventlet.timeout.Timeout(deadline):
478             for event_name, event in events.items():
479                 actual_event = event.wait()
480                 if actual_event.status == 'completed':
481                     continue
482                 decision = error_callback(event_name, instance)
483                 if decision is False:
484                     break
485 
486 
487 class ComputeManager(manager.Manager):
488     """Manages the running instances from creation to destruction."""
489 
490     target = messaging.Target(version='5.1')
491 
492     def __init__(self, compute_driver=None, *args, **kwargs):
493         """Load configuration options and connect to the hypervisor."""
494         self.virtapi = ComputeVirtAPI(self)
495         self.network_api = network.API()
496         self.volume_api = cinder.API()
497         self.image_api = image.API()
498         self._last_host_check = 0
499         self._last_bw_usage_poll = 0
500         self._bw_usage_supported = True
501         self._last_bw_usage_cell_update = 0
502         self.compute_api = compute.API()
503         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
504         self.conductor_api = conductor.API()
505         self.compute_task_api = conductor.ComputeTaskAPI()
506         self.is_neutron_security_groups = (
507             openstack_driver.is_neutron_security_groups())
508         self.cells_rpcapi = cells_rpcapi.CellsAPI()
509         self.query_client = query.SchedulerQueryClient()
510         self.instance_events = InstanceEvents()
511         self._sync_power_pool = eventlet.GreenPool(
512             size=CONF.sync_power_state_pool_size)
513         self._syncs_in_progress = {}
514         self.send_instance_updates = (
515             CONF.filter_scheduler.track_instance_changes)
516         if CONF.max_concurrent_builds != 0:
517             self._build_semaphore = eventlet.semaphore.Semaphore(
518                 CONF.max_concurrent_builds)
519         else:
520             self._build_semaphore = compute_utils.UnlimitedSemaphore()
521         if max(CONF.max_concurrent_live_migrations, 0) != 0:
522             self._live_migration_executor = futurist.GreenThreadPoolExecutor(
523                 max_workers=CONF.max_concurrent_live_migrations)
524         else:
525             if CONF.max_concurrent_live_migrations < 0:
526                 LOG.warning('The value of the max_concurrent_live_migrations '
527                             'config option is less than 0. '
528                             'It is treated as 0 and will raise ValueError '
529                             'in a future release.')
530             self._live_migration_executor = futurist.GreenThreadPoolExecutor()
531         # This is a dict, keyed by instance uuid, to a two-item tuple of
532         # migration object and Future for the queued live migration.
533         self._waiting_live_migrations = {}
534 
535         super(ComputeManager, self).__init__(service_name="compute",
536                                              *args, **kwargs)
537 
538         # NOTE(russellb) Load the driver last.  It may call back into the
539         # compute manager via the virtapi, so we want it to be fully
540         # initialized before that happens.
541         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
542         self.use_legacy_block_device_info = \
543                             self.driver.need_legacy_block_device_info
544         self.rt = resource_tracker.ResourceTracker(self.host, self.driver)
545         self.reportclient = self.rt.reportclient
546 
547     def reset(self):
548         LOG.info('Reloading compute RPC API')
549         compute_rpcapi.LAST_VERSION = None
550         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
551         self.reportclient.clear_provider_cache()
552 
553     def _update_resource_tracker(self, context, instance):
554         """Let the resource tracker know that an instance has changed state."""
555 
556         if instance.host == self.host:
557             self.rt.update_usage(context, instance, instance.node)
558 
559     def _instance_update(self, context, instance, **kwargs):
560         """Update an instance in the database using kwargs as value."""
561 
562         for k, v in kwargs.items():
563             setattr(instance, k, v)
564         instance.save()
565         self._update_resource_tracker(context, instance)
566 
567     def _nil_out_instance_obj_host_and_node(self, instance):
568         # NOTE(jwcroppe): We don't do instance.save() here for performance
569         # reasons; a call to this is expected to be immediately followed by
570         # another call that does instance.save(), thus avoiding two writes
571         # to the database layer.
572         instance.host = None
573         instance.node = None
574         # If the instance is not on a host, it's not in an aggregate and
575         # therefore is not in an availability zone.
576         instance.availability_zone = None
577 
578     def _set_instance_obj_error_state(self, context, instance,
579                                       clean_task_state=False):
580         try:
581             instance.vm_state = vm_states.ERROR
582             if clean_task_state:
583                 instance.task_state = None
584             instance.save()
585         except exception.InstanceNotFound:
586             LOG.debug('Instance has been destroyed from under us while '
587                       'trying to set it to ERROR', instance=instance)
588 
589     def _get_instances_on_driver(self, context, filters=None):
590         """Return a list of instance records for the instances found
591         on the hypervisor which satisfy the specified filters. If filters=None
592         return a list of instance records for all the instances found on the
593         hypervisor.
594         """
595         if not filters:
596             filters = {}
597         try:
598             driver_uuids = self.driver.list_instance_uuids()
599             if len(driver_uuids) == 0:
600                 # Short circuit, don't waste a DB call
601                 return objects.InstanceList()
602             filters['uuid'] = driver_uuids
603             local_instances = objects.InstanceList.get_by_filters(
604                 context, filters, use_slave=True)
605             return local_instances
606         except NotImplementedError:
607             pass
608 
609         # The driver doesn't support uuids listing, so we'll have
610         # to brute force.
611         driver_instances = self.driver.list_instances()
612         # NOTE(mjozefcz): In this case we need to apply host filter.
613         # Without this all instance data would be fetched from db.
614         filters['host'] = self.host
615         instances = objects.InstanceList.get_by_filters(context, filters,
616                                                         use_slave=True)
617         name_map = {instance.name: instance for instance in instances}
618         local_instances = []
619         for driver_instance in driver_instances:
620             instance = name_map.get(driver_instance)
621             if not instance:
622                 continue
623             local_instances.append(instance)
624         return local_instances
625 
626     def _destroy_evacuated_instances(self, context):
627         """Destroys evacuated instances.
628 
629         While nova-compute was down, the instances running on it could be
630         evacuated to another host. This method looks for evacuation migration
631         records where this is the source host and which were either started
632         (accepted), in-progress (pre-migrating) or migrated (done). From those
633         migration records, local instances reported by the hypervisor are
634         compared to the instances for the migration records and those local
635         guests are destroyed, along with instance allocation records in
636         Placement for this node.
637         """
638         filters = {
639             'source_compute': self.host,
640             # NOTE(mriedem): Migration records that have been accepted are
641             # included in case the source node comes back up while instances
642             # are being evacuated to another host. We don't want the same
643             # instance being reported from multiple hosts.
644             # NOTE(lyarwood): pre-migrating is also included here as the
645             # source compute can come back online shortly after the RT
646             # claims on the destination that in-turn moves the migration to
647             # pre-migrating. If the evacuate fails on the destination host,
648             # the user can rebuild the instance (in ERROR state) on the source
649             # host.
650             'status': ['accepted', 'pre-migrating', 'done'],
651             'migration_type': 'evacuation',
652         }
653         with utils.temporary_mutation(context, read_deleted='yes'):
654             evacuations = objects.MigrationList.get_by_filters(context,
655                                                                filters)
656         if not evacuations:
657             return
658         evacuations = {mig.instance_uuid: mig for mig in evacuations}
659 
660         # TODO(mriedem): We could optimize by pre-loading the joined fields
661         # we know we'll use, like info_cache and flavor.
662         local_instances = self._get_instances_on_driver(context)
663         evacuated = [inst for inst in local_instances
664                      if inst.uuid in evacuations]
665 
666         # NOTE(gibi): We are called from init_host and at this point the
667         # compute_nodes of the resource tracker has not been populated yet so
668         # we cannot rely on the resource tracker here.
669         compute_nodes = {}
670 
671         for instance in evacuated:
672             migration = evacuations[instance.uuid]
673             LOG.info('Deleting instance as it has been evacuated from '
674                      'this host', instance=instance)
675             try:
676                 network_info = self.network_api.get_instance_nw_info(
677                     context, instance)
678                 bdi = self._get_instance_block_device_info(context,
679                                                            instance)
680                 destroy_disks = not (self._is_instance_storage_shared(
681                     context, instance))
682             except exception.InstanceNotFound:
683                 network_info = network_model.NetworkInfo()
684                 bdi = {}
685                 LOG.info('Instance has been marked deleted already, '
686                          'removing it from the hypervisor.',
687                          instance=instance)
688                 # always destroy disks if the instance was deleted
689                 destroy_disks = True
690             self.driver.destroy(context, instance,
691                                 network_info,
692                                 bdi, destroy_disks)
693 
694             # delete the allocation of the evacuated instance from this host
695             if migration.source_node not in compute_nodes:
696                 try:
697                     cn_uuid = objects.ComputeNode.get_by_host_and_nodename(
698                         context, self.host, migration.source_node).uuid
699                     compute_nodes[migration.source_node] = cn_uuid
700                 except exception.ComputeHostNotFound:
701                     LOG.error("Failed to clean allocation of evacuated "
702                               "instance as the source node %s is not found",
703                               migration.source_node, instance=instance)
704                     continue
705             cn_uuid = compute_nodes[migration.source_node]
706 
707             # If the instance was deleted in the interim, assume its
708             # allocations were properly cleaned up (either by its hosting
709             # compute service or the API).
710             if (not instance.deleted and
711                     not self.reportclient.
712                         remove_provider_tree_from_instance_allocation(
713                             context, instance.uuid, cn_uuid)):
714                 LOG.error("Failed to clean allocation of evacuated instance "
715                           "on the source node %s",
716                           cn_uuid, instance=instance)
717 
718             migration.status = 'completed'
719             migration.save()
720         return evacuations
721 
722     def _is_instance_storage_shared(self, context, instance, host=None):
723         shared_storage = True
724         data = None
725         try:
726             data = self.driver.check_instance_shared_storage_local(context,
727                                                        instance)
728             if data:
729                 shared_storage = (self.compute_rpcapi.
730                                   check_instance_shared_storage(context,
731                                   instance, data, host=host))
732         except NotImplementedError:
733             LOG.debug('Hypervisor driver does not support '
734                       'instance shared storage check, '
735                       'assuming it\'s not on shared storage',
736                       instance=instance)
737             shared_storage = False
738         except Exception:
739             LOG.exception('Failed to check if instance shared',
740                           instance=instance)
741         finally:
742             if data:
743                 self.driver.check_instance_shared_storage_cleanup(context,
744                                                                   data)
745         return shared_storage
746 
747     def _complete_partial_deletion(self, context, instance):
748         """Complete deletion for instances in DELETED status but not marked as
749         deleted in the DB
750         """
751         instance.destroy()
752         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
753                 context, instance.uuid)
754         self._complete_deletion(context,
755                                 instance)
756         self._notify_about_instance_usage(context, instance, "delete.end")
757         compute_utils.notify_about_instance_action(context, instance,
758                 self.host, action=fields.NotificationAction.DELETE,
759                 phase=fields.NotificationPhase.END, bdms=bdms)
760 
761     def _complete_deletion(self, context, instance):
762         self._update_resource_tracker(context, instance)
763 
764         self.reportclient.delete_allocation_for_instance(context,
765                                                          instance.uuid)
766 
767         self._clean_instance_console_tokens(context, instance)
768         self._delete_scheduler_instance_info(context, instance.uuid)
769 
770     def _init_instance(self, context, instance):
771         """Initialize this instance during service init."""
772 
773         # NOTE(danms): If the instance appears to not be owned by this
774         # host, it may have been evacuated away, but skipped by the
775         # evacuation cleanup code due to configuration. Thus, if that
776         # is a possibility, don't touch the instance in any way, but
777         # log the concern. This will help avoid potential issues on
778         # startup due to misconfiguration.
779         if instance.host != self.host:
780             LOG.warning('Instance %(uuid)s appears to not be owned '
781                         'by this host, but by %(host)s. Startup '
782                         'processing is being skipped.',
783                         {'uuid': instance.uuid,
784                          'host': instance.host})
785             return
786 
787         # Instances that are shut down, or in an error state can not be
788         # initialized and are not attempted to be recovered. The exception
789         # to this are instances that are in RESIZE_MIGRATING or DELETING,
790         # which are dealt with further down.
791         if (instance.vm_state == vm_states.SOFT_DELETED or
792             (instance.vm_state == vm_states.ERROR and
793             instance.task_state not in
794             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
795             LOG.debug("Instance is in %s state.",
796                       instance.vm_state, instance=instance)
797             return
798 
799         if instance.vm_state == vm_states.DELETED:
800             try:
801                 self._complete_partial_deletion(context, instance)
802             except Exception:
803                 # we don't want that an exception blocks the init_host
804                 LOG.exception('Failed to complete a deletion',
805                               instance=instance)
806             return
807 
808         if (instance.vm_state == vm_states.BUILDING or
809             instance.task_state in [task_states.SCHEDULING,
810                                     task_states.BLOCK_DEVICE_MAPPING,
811                                     task_states.NETWORKING,
812                                     task_states.SPAWNING]):
813             # NOTE(dave-mcnally) compute stopped before instance was fully
814             # spawned so set to ERROR state. This is safe to do as the state
815             # may be set by the api but the host is not so if we get here the
816             # instance has already been scheduled to this particular host.
817             LOG.debug("Instance failed to spawn correctly, "
818                       "setting to ERROR state", instance=instance)
819             instance.task_state = None
820             instance.vm_state = vm_states.ERROR
821             instance.save()
822             return
823 
824         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
825             instance.task_state in [task_states.REBUILDING,
826                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
827                                     task_states.REBUILD_SPAWNING]):
828             # NOTE(jichenjc) compute stopped before instance was fully
829             # spawned so set to ERROR state. This is consistent to BUILD
830             LOG.debug("Instance failed to rebuild correctly, "
831                       "setting to ERROR state", instance=instance)
832             instance.task_state = None
833             instance.vm_state = vm_states.ERROR
834             instance.save()
835             return
836 
837         if (instance.vm_state != vm_states.ERROR and
838             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
839                                     task_states.IMAGE_PENDING_UPLOAD,
840                                     task_states.IMAGE_UPLOADING,
841                                     task_states.IMAGE_SNAPSHOT]):
842             LOG.debug("Instance in transitional state %s at start-up "
843                       "clearing task state",
844                       instance.task_state, instance=instance)
845             try:
846                 self._post_interrupted_snapshot_cleanup(context, instance)
847             except Exception:
848                 # we don't want that an exception blocks the init_host
849                 LOG.exception('Failed to cleanup snapshot.', instance=instance)
850             instance.task_state = None
851             instance.save()
852 
853         if (instance.vm_state != vm_states.ERROR and
854             instance.task_state in [task_states.RESIZE_PREP]):
855             LOG.debug("Instance in transitional state %s at start-up "
856                       "clearing task state",
857                       instance['task_state'], instance=instance)
858             instance.task_state = None
859             instance.save()
860 
861         if instance.task_state == task_states.DELETING:
862             try:
863                 LOG.info('Service started deleting the instance during '
864                          'the previous run, but did not finish. Restarting'
865                          ' the deletion now.', instance=instance)
866                 instance.obj_load_attr('metadata')
867                 instance.obj_load_attr('system_metadata')
868                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
869                         context, instance.uuid)
870                 self._delete_instance(context, instance, bdms)
871             except Exception:
872                 # we don't want that an exception blocks the init_host
873                 LOG.exception('Failed to complete a deletion',
874                               instance=instance)
875                 self._set_instance_obj_error_state(context, instance)
876             return
877 
878         current_power_state = self._get_power_state(context, instance)
879         try_reboot, reboot_type = self._retry_reboot(context, instance,
880                                                      current_power_state)
881 
882         if try_reboot:
883             LOG.debug("Instance in transitional state (%(task_state)s) at "
884                       "start-up and power state is (%(power_state)s), "
885                       "triggering reboot",
886                       {'task_state': instance.task_state,
887                        'power_state': current_power_state},
888                       instance=instance)
889 
890             # NOTE(mikal): if the instance was doing a soft reboot that got as
891             # far as shutting down the instance but not as far as starting it
892             # again, then we've just become a hard reboot. That means the
893             # task state for the instance needs to change so that we're in one
894             # of the expected task states for a hard reboot.
895             if (instance.task_state in task_states.soft_reboot_states and
896                 reboot_type == 'HARD'):
897                 instance.task_state = task_states.REBOOT_PENDING_HARD
898                 instance.save()
899 
900             self.reboot_instance(context, instance, block_device_info=None,
901                                  reboot_type=reboot_type)
902             return
903 
904         elif (current_power_state == power_state.RUNNING and
905               instance.task_state in [task_states.REBOOT_STARTED,
906                                       task_states.REBOOT_STARTED_HARD,
907                                       task_states.PAUSING,
908                                       task_states.UNPAUSING]):
909             LOG.warning("Instance in transitional state "
910                         "(%(task_state)s) at start-up and power state "
911                         "is (%(power_state)s), clearing task state",
912                         {'task_state': instance.task_state,
913                          'power_state': current_power_state},
914                         instance=instance)
915             instance.task_state = None
916             instance.vm_state = vm_states.ACTIVE
917             instance.save()
918         elif (current_power_state == power_state.PAUSED and
919               instance.task_state == task_states.UNPAUSING):
920             LOG.warning("Instance in transitional state "
921                         "(%(task_state)s) at start-up and power state "
922                         "is (%(power_state)s), clearing task state "
923                         "and unpausing the instance",
924                         {'task_state': instance.task_state,
925                          'power_state': current_power_state},
926                         instance=instance)
927             try:
928                 self.unpause_instance(context, instance)
929             except NotImplementedError:
930                 # Some virt driver didn't support pause and unpause
931                 pass
932             except Exception:
933                 LOG.exception('Failed to unpause instance', instance=instance)
934             return
935 
936         if instance.task_state == task_states.POWERING_OFF:
937             try:
938                 LOG.debug("Instance in transitional state %s at start-up "
939                           "retrying stop request",
940                           instance.task_state, instance=instance)
941                 self.stop_instance(context, instance, True)
942             except Exception:
943                 # we don't want that an exception blocks the init_host
944                 LOG.exception('Failed to stop instance', instance=instance)
945             return
946 
947         if instance.task_state == task_states.POWERING_ON:
948             try:
949                 LOG.debug("Instance in transitional state %s at start-up "
950                           "retrying start request",
951                           instance.task_state, instance=instance)
952                 self.start_instance(context, instance)
953             except Exception:
954                 # we don't want that an exception blocks the init_host
955                 LOG.exception('Failed to start instance', instance=instance)
956             return
957 
958         net_info = instance.get_network_info()
959         try:
960             self.driver.plug_vifs(instance, net_info)
961         except NotImplementedError as e:
962             LOG.debug(e, instance=instance)
963         except exception.VirtualInterfacePlugException:
964             # NOTE(mriedem): If we get here, it could be because the vif_type
965             # in the cache is "binding_failed" or "unbound".  The only way to
966             # fix this is to try and bind the ports again, which would be
967             # expensive here on host startup. We could add a check to
968             # _heal_instance_info_cache to handle this, but probably only if
969             # the instance task_state is None.
970             LOG.exception('Virtual interface plugging failed for instance. '
971                           'The port binding:host_id may need to be manually '
972                           'updated.', instance=instance)
973             self._set_instance_obj_error_state(context, instance)
974             return
975 
976         if instance.task_state == task_states.RESIZE_MIGRATING:
977             # We crashed during resize/migration, so roll back for safety
978             try:
979                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
980                 # not in system_metadata we default to True for backwards
981                 # compatibility
982                 power_on = (instance.system_metadata.get('old_vm_state') !=
983                             vm_states.STOPPED)
984 
985                 block_dev_info = self._get_instance_block_device_info(context,
986                                                                       instance)
987 
988                 self.driver.finish_revert_migration(context,
989                     instance, net_info, block_dev_info, power_on)
990 
991             except Exception:
992                 LOG.exception('Failed to revert crashed migration',
993                               instance=instance)
994             finally:
995                 LOG.info('Instance found in migrating state during '
996                          'startup. Resetting task_state',
997                          instance=instance)
998                 instance.task_state = None
999                 instance.save()
1000         if instance.task_state == task_states.MIGRATING:
1001             # Live migration did not complete, but instance is on this
1002             # host, so reset the state.
1003             instance.task_state = None
1004             instance.save(expected_task_state=[task_states.MIGRATING])
1005 
1006         db_state = instance.power_state
1007         drv_state = self._get_power_state(context, instance)
1008         expect_running = (db_state == power_state.RUNNING and
1009                           drv_state != db_state)
1010 
1011         LOG.debug('Current state is %(drv_state)s, state in DB is '
1012                   '%(db_state)s.',
1013                   {'drv_state': drv_state, 'db_state': db_state},
1014                   instance=instance)
1015 
1016         if expect_running and CONF.resume_guests_state_on_host_boot:
1017             self._resume_guests_state(context, instance, net_info)
1018         elif drv_state == power_state.RUNNING:
1019             # VMwareAPI drivers will raise an exception
1020             try:
1021                 self.driver.ensure_filtering_rules_for_instance(
1022                                        instance, net_info)
1023             except NotImplementedError:
1024                 LOG.debug('Hypervisor driver does not support '
1025                           'firewall rules', instance=instance)
1026 
1027     def _resume_guests_state(self, context, instance, net_info):
1028         LOG.info('Rebooting instance after nova-compute restart.',
1029                  instance=instance)
1030         block_device_info = \
1031             self._get_instance_block_device_info(context, instance)
1032 
1033         try:
1034             self.driver.resume_state_on_host_boot(
1035                 context, instance, net_info, block_device_info)
1036         except NotImplementedError:
1037             LOG.warning('Hypervisor driver does not support '
1038                         'resume guests', instance=instance)
1039         except Exception:
1040             # NOTE(vish): The instance failed to resume, so we set the
1041             #             instance to error and attempt to continue.
1042             LOG.warning('Failed to resume instance',
1043                         instance=instance)
1044             self._set_instance_obj_error_state(context, instance)
1045 
1046     def _retry_reboot(self, context, instance, current_power_state):
1047         current_task_state = instance.task_state
1048         retry_reboot = False
1049         reboot_type = compute_utils.get_reboot_type(current_task_state,
1050                                                     current_power_state)
1051 
1052         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1053                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1054         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1055                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1056         started_not_running = (current_task_state in
1057                                [task_states.REBOOT_STARTED,
1058                                 task_states.REBOOT_STARTED_HARD] and
1059                                current_power_state != power_state.RUNNING)
1060 
1061         if pending_soft or pending_hard or started_not_running:
1062             retry_reboot = True
1063 
1064         return retry_reboot, reboot_type
1065 
1066     def handle_lifecycle_event(self, event):
1067         LOG.info("VM %(state)s (Lifecycle Event)",
1068                  {'state': event.get_name()},
1069                  instance_uuid=event.get_instance_uuid())
1070         context = nova.context.get_admin_context(read_deleted='yes')
1071         vm_power_state = None
1072         event_transition = event.get_transition()
1073         if event_transition == virtevent.EVENT_LIFECYCLE_STOPPED:
1074             vm_power_state = power_state.SHUTDOWN
1075         elif event_transition == virtevent.EVENT_LIFECYCLE_STARTED:
1076             vm_power_state = power_state.RUNNING
1077         elif event_transition in (
1078                 virtevent.EVENT_LIFECYCLE_PAUSED,
1079                 virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED,
1080                 virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED):
1081             vm_power_state = power_state.PAUSED
1082         elif event_transition == virtevent.EVENT_LIFECYCLE_RESUMED:
1083             vm_power_state = power_state.RUNNING
1084         elif event_transition == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1085             vm_power_state = power_state.SUSPENDED
1086         else:
1087             LOG.warning("Unexpected lifecycle event: %d", event_transition)
1088 
1089         migrate_finish_statuses = {
1090             # This happens on the source node and indicates live migration
1091             # entered post-copy mode.
1092             virtevent.EVENT_LIFECYCLE_POSTCOPY_STARTED: 'running (post-copy)',
1093             # Suspended for offline migration.
1094             virtevent.EVENT_LIFECYCLE_MIGRATION_COMPLETED: 'running'
1095         }
1096 
1097         expected_attrs = []
1098         if event_transition in migrate_finish_statuses:
1099             # Join on info_cache since that's needed in migrate_instance_start.
1100             expected_attrs.append('info_cache')
1101         instance = objects.Instance.get_by_uuid(context,
1102                                                 event.get_instance_uuid(),
1103                                                 expected_attrs=expected_attrs)
1104 
1105         # Note(lpetrut): The event may be delayed, thus not reflecting
1106         # the current instance power state. In that case, ignore the event.
1107         current_power_state = self._get_power_state(context, instance)
1108         if current_power_state == vm_power_state:
1109             LOG.debug('Synchronizing instance power state after lifecycle '
1110                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1111                       'current task_state: %(task_state)s, current DB '
1112                       'power_state: %(db_power_state)s, VM power_state: '
1113                       '%(vm_power_state)s',
1114                       {'event': event.get_name(),
1115                        'vm_state': instance.vm_state,
1116                        'task_state': instance.task_state,
1117                        'db_power_state': instance.power_state,
1118                        'vm_power_state': vm_power_state},
1119                       instance_uuid=instance.uuid)
1120             self._sync_instance_power_state(context,
1121                                             instance,
1122                                             vm_power_state)
1123 
1124         # The following checks are for live migration. We want to activate
1125         # the port binding for the destination host before the live migration
1126         # is resumed on the destination host in order to reduce network
1127         # downtime. Otherwise the ports are bound to the destination host
1128         # in post_live_migration_at_destination.
1129         # TODO(danms): Explore options for using a different live migration
1130         # specific callback for this instead of piggy-backing on the
1131         # handle_lifecycle_event callback.
1132         if (instance.task_state == task_states.MIGRATING and
1133                 event_transition in migrate_finish_statuses):
1134             status = migrate_finish_statuses[event_transition]
1135             try:
1136                 migration = objects.Migration.get_by_instance_and_status(
1137                             context, instance.uuid, status)
1138                 LOG.debug('Binding ports to destination host: %s',
1139                           migration.dest_compute, instance=instance)
1140                 # For neutron, migrate_instance_start will activate the
1141                 # destination host port bindings, if there are any created by
1142                 # conductor before live migration started.
1143                 self.network_api.migrate_instance_start(
1144                     context, instance, migration)
1145             except exception.MigrationNotFoundByStatus:
1146                 LOG.warning("Unable to find migration record with status "
1147                             "'%s' for instance. Port binding will happen in "
1148                             "post live migration.", status, instance=instance)
1149 
1150     def handle_events(self, event):
1151         if isinstance(event, virtevent.LifecycleEvent):
1152             try:
1153                 self.handle_lifecycle_event(event)
1154             except exception.InstanceNotFound:
1155                 LOG.debug("Event %s arrived for non-existent instance. The "
1156                           "instance was probably deleted.", event)
1157         else:
1158             LOG.debug("Ignoring event %s", event)
1159 
1160     def init_virt_events(self):
1161         if CONF.workarounds.handle_virt_lifecycle_events:
1162             self.driver.register_event_listener(self.handle_events)
1163         else:
1164             # NOTE(mriedem): If the _sync_power_states periodic task is
1165             # disabled we should emit a warning in the logs.
1166             if CONF.sync_power_state_interval < 0:
1167                 LOG.warning('Instance lifecycle events from the compute '
1168                             'driver have been disabled. Note that lifecycle '
1169                             'changes to an instance outside of the compute '
1170                             'service will not be synchronized '
1171                             'automatically since the _sync_power_states '
1172                             'periodic task is also disabled.')
1173             else:
1174                 LOG.info('Instance lifecycle events from the compute '
1175                          'driver have been disabled. Note that lifecycle '
1176                          'changes to an instance outside of the compute '
1177                          'service will only be synchronized by the '
1178                          '_sync_power_states periodic task.')
1179 
1180     def init_host(self):
1181         """Initialization for a standalone compute service."""
1182 
1183         if CONF.pci.passthrough_whitelist:
1184             # Simply loading the PCI passthrough whitelist will do a bunch of
1185             # validation that would otherwise wait until the PciDevTracker is
1186             # constructed when updating available resources for the compute
1187             # node(s) in the resource tracker, effectively killing that task.
1188             # So load up the whitelist when starting the compute service to
1189             # flush any invalid configuration early so we can kill the service
1190             # if the configuration is wrong.
1191             whitelist.Whitelist(CONF.pci.passthrough_whitelist)
1192 
1193         nova.conf.neutron.register_dynamic_opts(CONF)
1194 
1195         # Override the number of concurrent disk operations allowed if the
1196         # user has specified a limit.
1197         if CONF.compute.max_concurrent_disk_ops != 0:
1198             compute_utils.disk_ops_semaphore = \
1199                 eventlet.semaphore.BoundedSemaphore(
1200                     CONF.compute.max_concurrent_disk_ops)
1201 
1202         self.driver.init_host(host=self.host)
1203         context = nova.context.get_admin_context()
1204         instances = objects.InstanceList.get_by_host(
1205             context, self.host, expected_attrs=['info_cache', 'metadata'])
1206 
1207         if CONF.defer_iptables_apply:
1208             self.driver.filter_defer_apply_on()
1209 
1210         self.init_virt_events()
1211 
1212         try:
1213             # checking that instance was not already evacuated to other host
1214             evacuated_instances = self._destroy_evacuated_instances(context)
1215 
1216             # Initialise instances on the host that are not evacuating
1217             for instance in instances:
1218                 if (not evacuated_instances or
1219                         instance.uuid not in evacuated_instances):
1220                     self._init_instance(context, instance)
1221 
1222         finally:
1223             if CONF.defer_iptables_apply:
1224                 self.driver.filter_defer_apply_off()
1225             if instances:
1226                 # We only send the instance info to the scheduler on startup
1227                 # if there is anything to send, otherwise this host might
1228                 # not be mapped yet in a cell and the scheduler may have
1229                 # issues dealing with the information. Later changes to
1230                 # instances on this host will update the scheduler, or the
1231                 # _sync_scheduler_instance_info periodic task will.
1232                 self._update_scheduler_instance_info(context, instances)
1233 
1234     def cleanup_host(self):
1235         self.driver.register_event_listener(None)
1236         self.instance_events.cancel_all_events()
1237         self.driver.cleanup_host(host=self.host)
1238         self._cleanup_live_migrations_in_pool()
1239 
1240     def _cleanup_live_migrations_in_pool(self):
1241         # Shutdown the pool so we don't get new requests.
1242         self._live_migration_executor.shutdown(wait=False)
1243         # For any queued migrations, cancel the migration and update
1244         # its status.
1245         for migration, future in self._waiting_live_migrations.values():
1246             # If we got here before the Future was submitted then we need
1247             # to move on since there isn't anything we can do.
1248             if future is None:
1249                 continue
1250             if future.cancel():
1251                 self._set_migration_status(migration, 'cancelled')
1252                 LOG.info('Successfully cancelled queued live migration.',
1253                          instance_uuid=migration.instance_uuid)
1254             else:
1255                 LOG.warning('Unable to cancel live migration.',
1256                             instance_uuid=migration.instance_uuid)
1257         self._waiting_live_migrations.clear()
1258 
1259     def pre_start_hook(self):
1260         """After the service is initialized, but before we fully bring
1261         the service up by listening on RPC queues, make sure to update
1262         our available resources (and indirectly our available nodes).
1263         """
1264         self.update_available_resource(nova.context.get_admin_context(),
1265                                        startup=True)
1266 
1267     def _get_power_state(self, context, instance):
1268         """Retrieve the power state for the given instance."""
1269         LOG.debug('Checking state', instance=instance)
1270         try:
1271             return self.driver.get_info(instance).state
1272         except exception.InstanceNotFound:
1273             return power_state.NOSTATE
1274 
1275     def get_console_topic(self, context):
1276         """Retrieves the console host for a project on this host.
1277 
1278         Currently this is just set in the flags for each compute host.
1279 
1280         """
1281         # TODO(mdragon): perhaps make this variable by console_type?
1282         return '%s.%s' % (console_rpcapi.RPC_TOPIC, CONF.console_host)
1283 
1284     @wrap_exception()
1285     def get_console_pool_info(self, context, console_type):
1286         return self.driver.get_console_pool_info(console_type)
1287 
1288     @wrap_exception()
1289     def refresh_instance_security_rules(self, context, instance):
1290         """Tell the virtualization driver to refresh security rules for
1291         an instance.
1292 
1293         Passes straight through to the virtualization driver.
1294 
1295         Synchronize the call because we may still be in the middle of
1296         creating the instance.
1297         """
1298         @utils.synchronized(instance.uuid)
1299         def _sync_refresh():
1300             try:
1301                 return self.driver.refresh_instance_security_rules(instance)
1302             except NotImplementedError:
1303                 LOG.debug('Hypervisor driver does not support '
1304                           'security groups.', instance=instance)
1305 
1306         return _sync_refresh()
1307 
1308     def _await_block_device_map_created(self, context, vol_id):
1309         # TODO(yamahata): creating volume simultaneously
1310         #                 reduces creation time?
1311         # TODO(yamahata): eliminate dumb polling
1312         start = time.time()
1313         retries = CONF.block_device_allocate_retries
1314         if retries < 0:
1315             LOG.warning("Treating negative config value (%(retries)s) for "
1316                         "'block_device_retries' as 0.",
1317                         {'retries': retries})
1318         # (1) treat  negative config value as 0
1319         # (2) the configured value is 0, one attempt should be made
1320         # (3) the configured value is > 0, then the total number attempts
1321         #      is (retries + 1)
1322         attempts = 1
1323         if retries >= 1:
1324             attempts = retries + 1
1325         for attempt in range(1, attempts + 1):
1326             volume = self.volume_api.get(context, vol_id)
1327             volume_status = volume['status']
1328             if volume_status not in ['creating', 'downloading']:
1329                 if volume_status == 'available':
1330                     return attempt
1331                 LOG.warning("Volume id: %(vol_id)s finished being "
1332                             "created but its status is %(vol_status)s.",
1333                             {'vol_id': vol_id,
1334                              'vol_status': volume_status})
1335                 break
1336             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1337         raise exception.VolumeNotCreated(volume_id=vol_id,
1338                                          seconds=int(time.time() - start),
1339                                          attempts=attempt,
1340                                          volume_status=volume_status)
1341 
1342     def _decode_files(self, injected_files):
1343         """Base64 decode the list of files to inject."""
1344         if not injected_files:
1345             return []
1346 
1347         def _decode(f):
1348             path, contents = f
1349             # Py3 raises binascii.Error instead of TypeError as in Py27
1350             try:
1351                 decoded = base64.b64decode(contents)
1352                 return path, decoded
1353             except (TypeError, binascii.Error):
1354                 raise exception.Base64Exception(path=path)
1355 
1356         return [_decode(f) for f in injected_files]
1357 
1358     def _validate_instance_group_policy(self, context, instance,
1359                                         scheduler_hints):
1360         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1361         # However, there is a race condition with the enforcement of
1362         # the policy.  Since more than one instance may be scheduled at the
1363         # same time, it's possible that more than one instance with an
1364         # anti-affinity policy may end up here.  It's also possible that
1365         # multiple instances with an affinity policy could end up on different
1366         # hosts.  This is a validation step to make sure that starting the
1367         # instance here doesn't violate the policy.
1368         group_hint = scheduler_hints.get('group')
1369         if not group_hint:
1370             return
1371 
1372         # The RequestSpec stores scheduler_hints as key=list pairs so we need
1373         # to check the type on the value and pull the single entry out. The
1374         # API request schema validates that the 'group' hint is a single value.
1375         if isinstance(group_hint, list):
1376             group_hint = group_hint[0]
1377 
1378         @utils.synchronized(group_hint)
1379         def _do_validation(context, instance, group_hint):
1380             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1381             if group.policy and 'anti-affinity' == group.policy:
1382                 instances_uuids = objects.InstanceList.get_uuids_by_host(
1383                     context, self.host)
1384                 ins_on_host = set(instances_uuids)
1385                 members = set(group.members)
1386                 # Determine the set of instance group members on this host
1387                 # which are not the instance in question. This is used to
1388                 # determine how many other members from the same anti-affinity
1389                 # group can be on this host.
1390                 members_on_host = ins_on_host & members - set([instance.uuid])
1391                 rules = group.rules
1392                 if rules and 'max_server_per_host' in rules:
1393                     max_server = rules['max_server_per_host']
1394                 else:
1395                     max_server = 1
1396                 if len(members_on_host) >= max_server:
1397                     msg = _("Anti-affinity instance group policy "
1398                             "was violated.")
1399                     raise exception.RescheduledException(
1400                             instance_uuid=instance.uuid,
1401                             reason=msg)
1402             elif group.policy and 'affinity' == group.policy:
1403                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1404                 if group_hosts and self.host not in group_hosts:
1405                     msg = _("Affinity instance group policy was violated.")
1406                     raise exception.RescheduledException(
1407                             instance_uuid=instance.uuid,
1408                             reason=msg)
1409 
1410         if not CONF.workarounds.disable_group_policy_check_upcall:
1411             _do_validation(context, instance, group_hint)
1412 
1413     def _log_original_error(self, exc_info, instance_uuid):
1414         LOG.error('Error: %s', exc_info[1], instance_uuid=instance_uuid,
1415                   exc_info=exc_info)
1416 
1417     # TODO(mriedem): This method is confusing and only ever used for resize
1418     # reschedules; remove it and merge into _reschedule_resize_or_reraise.
1419     def _reschedule(self, context, request_spec, filter_properties,
1420             instance, reschedule_method, method_args, task_state,
1421             exc_info=None, host_list=None):
1422         """Attempt to re-schedule a compute operation."""
1423 
1424         instance_uuid = instance.uuid
1425         retry = filter_properties.get('retry')
1426         if not retry:
1427             # no retry information, do not reschedule.
1428             LOG.debug("Retry info not present, will not reschedule",
1429                       instance_uuid=instance_uuid)
1430             return
1431 
1432         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1433                   {'method': reschedule_method.__name__,
1434                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1435 
1436         # reset the task state:
1437         self._instance_update(context, instance, task_state=task_state)
1438 
1439         if exc_info:
1440             # stringify to avoid circular ref problem in json serialization:
1441             retry['exc'] = traceback.format_exception_only(exc_info[0],
1442                                     exc_info[1])
1443 
1444         reschedule_method(context, *method_args, request_spec=request_spec,
1445                           host_list=host_list)
1446         return True
1447 
1448     @periodic_task.periodic_task
1449     def _check_instance_build_time(self, context):
1450         """Ensure that instances are not stuck in build."""
1451         timeout = CONF.instance_build_timeout
1452         if timeout == 0:
1453             return
1454 
1455         filters = {'vm_state': vm_states.BUILDING,
1456                    'host': self.host}
1457 
1458         building_insts = objects.InstanceList.get_by_filters(context,
1459                            filters, expected_attrs=[], use_slave=True)
1460 
1461         for instance in building_insts:
1462             if timeutils.is_older_than(instance.created_at, timeout):
1463                 self._set_instance_obj_error_state(context, instance)
1464                 LOG.warning("Instance build timed out. Set to error "
1465                             "state.", instance=instance)
1466 
1467     def _check_instance_exists(self, context, instance):
1468         """Ensure an instance with the same name is not already present."""
1469         if self.driver.instance_exists(instance):
1470             raise exception.InstanceExists(name=instance.name)
1471 
1472     def _allocate_network_async(self, context, instance, requested_networks,
1473                                 macs, security_groups, is_vpn,
1474                                 resource_provider_mapping):
1475         """Method used to allocate networks in the background.
1476 
1477         Broken out for testing.
1478         """
1479         # First check to see if we're specifically not supposed to allocate
1480         # networks because if so, we can exit early.
1481         if requested_networks and requested_networks.no_allocate:
1482             LOG.debug("Not allocating networking since 'none' was specified.",
1483                       instance=instance)
1484             return network_model.NetworkInfo([])
1485 
1486         LOG.debug("Allocating IP information in the background.",
1487                   instance=instance)
1488         retries = CONF.network_allocate_retries
1489         attempts = retries + 1
1490         retry_time = 1
1491         bind_host_id = self.driver.network_binding_host_id(context, instance)
1492         for attempt in range(1, attempts + 1):
1493             try:
1494                 nwinfo = self.network_api.allocate_for_instance(
1495                         context, instance, vpn=is_vpn,
1496                         requested_networks=requested_networks,
1497                         macs=macs,
1498                         security_groups=security_groups,
1499                         bind_host_id=bind_host_id,
1500                         resource_provider_mapping=resource_provider_mapping)
1501                 LOG.debug('Instance network_info: |%s|', nwinfo,
1502                           instance=instance)
1503                 instance.system_metadata['network_allocated'] = 'True'
1504                 # NOTE(JoshNang) do not save the instance here, as it can cause
1505                 # races. The caller shares a reference to instance and waits
1506                 # for this async greenthread to finish before calling
1507                 # instance.save().
1508                 return nwinfo
1509             except Exception:
1510                 exc_info = sys.exc_info()
1511                 log_info = {'attempt': attempt,
1512                             'attempts': attempts}
1513                 if attempt == attempts:
1514                     LOG.exception('Instance failed network setup '
1515                                   'after %(attempts)d attempt(s)',
1516                                   log_info)
1517                     six.reraise(*exc_info)
1518                 LOG.warning('Instance failed network setup '
1519                             '(attempt %(attempt)d of %(attempts)d)',
1520                             log_info, instance=instance)
1521                 time.sleep(retry_time)
1522                 retry_time *= 2
1523                 if retry_time > 30:
1524                     retry_time = 30
1525         # Not reached.
1526 
1527     def _build_networks_for_instance(self, context, instance,
1528             requested_networks, security_groups, resource_provider_mapping):
1529 
1530         # If we're here from a reschedule the network may already be allocated.
1531         if strutils.bool_from_string(
1532                 instance.system_metadata.get('network_allocated', 'False')):
1533             # NOTE(alex_xu): The network_allocated is True means the network
1534             # resource already allocated at previous scheduling, and the
1535             # network setup is cleanup at previous. After rescheduling, the
1536             # network resource need setup on the new host.
1537             self.network_api.setup_instance_network_on_host(
1538                 context, instance, instance.host)
1539             return self.network_api.get_instance_nw_info(context, instance)
1540 
1541         if not self.is_neutron_security_groups:
1542             security_groups = []
1543 
1544         macs = self.driver.macs_for_instance(instance)
1545         network_info = self._allocate_network(context, instance,
1546                 requested_networks, macs, security_groups,
1547                 resource_provider_mapping)
1548 
1549         return network_info
1550 
1551     def _allocate_network(self, context, instance, requested_networks, macs,
1552                           security_groups, resource_provider_mapping):
1553         """Start network allocation asynchronously.  Return an instance
1554         of NetworkInfoAsyncWrapper that can be used to retrieve the
1555         allocated networks when the operation has finished.
1556         """
1557         # NOTE(comstud): Since we're allocating networks asynchronously,
1558         # this task state has little meaning, as we won't be in this
1559         # state for very long.
1560         instance.vm_state = vm_states.BUILDING
1561         instance.task_state = task_states.NETWORKING
1562         instance.save(expected_task_state=[None])
1563 
1564         is_vpn = False
1565         return network_model.NetworkInfoAsyncWrapper(
1566                 self._allocate_network_async, context, instance,
1567                 requested_networks, macs, security_groups, is_vpn,
1568                 resource_provider_mapping)
1569 
1570     def _default_root_device_name(self, instance, image_meta, root_bdm):
1571         """Gets a default root device name from the driver.
1572 
1573         :param nova.objects.Instance instance:
1574             The instance for which to get the root device name.
1575         :param nova.objects.ImageMeta image_meta:
1576             The metadata of the image of the instance.
1577         :param nova.objects.BlockDeviceMapping root_bdm:
1578             The description of the root device.
1579         :returns: str -- The default root device name.
1580         :raises: InternalError, TooManyDiskDevices
1581         """
1582         try:
1583             return self.driver.default_root_device_name(instance,
1584                                                         image_meta,
1585                                                         root_bdm)
1586         except NotImplementedError:
1587             return compute_utils.get_next_device_name(instance, [])
1588 
1589     def _default_device_names_for_instance(self, instance,
1590                                            root_device_name,
1591                                            *block_device_lists):
1592         """Default the missing device names in the BDM from the driver.
1593 
1594         :param nova.objects.Instance instance:
1595             The instance for which to get default device names.
1596         :param str root_device_name: The root device name.
1597         :param list block_device_lists: List of block device mappings.
1598         :returns: None
1599         :raises: InternalError, TooManyDiskDevices
1600         """
1601         try:
1602             self.driver.default_device_names_for_instance(instance,
1603                                                           root_device_name,
1604                                                           *block_device_lists)
1605         except NotImplementedError:
1606             compute_utils.default_device_names_for_instance(
1607                 instance, root_device_name, *block_device_lists)
1608 
1609     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1610         """Get the next device name from the driver, based on the BDM.
1611 
1612         :param nova.objects.Instance instance:
1613             The instance whose volume is requesting a device name.
1614         :param nova.objects.BlockDeviceMappingList bdms:
1615             The block device mappings for the instance.
1616         :param nova.objects.BlockDeviceMapping block_device_obj:
1617             A block device mapping containing info about the requested block
1618             device.
1619         :returns: The next device name.
1620         :raises: InternalError, TooManyDiskDevices
1621         """
1622         # NOTE(ndipanov): Copy obj to avoid changing the original
1623         block_device_obj = block_device_obj.obj_clone()
1624         try:
1625             return self.driver.get_device_name_for_instance(
1626                 instance, bdms, block_device_obj)
1627         except NotImplementedError:
1628             return compute_utils.get_device_name_for_instance(
1629                 instance, bdms, block_device_obj.get("device_name"))
1630 
1631     def _default_block_device_names(self, instance, image_meta, block_devices):
1632         """Verify that all the devices have the device_name set. If not,
1633         provide a default name.
1634 
1635         It also ensures that there is a root_device_name and is set to the
1636         first block device in the boot sequence (boot_index=0).
1637         """
1638         root_bdm = block_device.get_root_bdm(block_devices)
1639         if not root_bdm:
1640             return
1641 
1642         # Get the root_device_name from the root BDM or the instance
1643         root_device_name = None
1644         update_root_bdm = False
1645 
1646         if root_bdm.device_name:
1647             root_device_name = root_bdm.device_name
1648             instance.root_device_name = root_device_name
1649         elif instance.root_device_name:
1650             root_device_name = instance.root_device_name
1651             root_bdm.device_name = root_device_name
1652             update_root_bdm = True
1653         else:
1654             root_device_name = self._default_root_device_name(instance,
1655                                                               image_meta,
1656                                                               root_bdm)
1657 
1658             instance.root_device_name = root_device_name
1659             root_bdm.device_name = root_device_name
1660             update_root_bdm = True
1661 
1662         if update_root_bdm:
1663             root_bdm.save()
1664 
1665         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1666                             block_devices))
1667         swap = list(filter(block_device.new_format_is_swap,
1668                       block_devices))
1669         block_device_mapping = list(filter(
1670               driver_block_device.is_block_device_mapping, block_devices))
1671 
1672         self._default_device_names_for_instance(instance,
1673                                                 root_device_name,
1674                                                 ephemerals,
1675                                                 swap,
1676                                                 block_device_mapping)
1677 
1678     def _block_device_info_to_legacy(self, block_device_info):
1679         """Convert BDI to the old format for drivers that need it."""
1680 
1681         if self.use_legacy_block_device_info:
1682             ephemerals = driver_block_device.legacy_block_devices(
1683                 driver.block_device_info_get_ephemerals(block_device_info))
1684             mapping = driver_block_device.legacy_block_devices(
1685                 driver.block_device_info_get_mapping(block_device_info))
1686             swap = block_device_info['swap']
1687             if swap:
1688                 swap = swap.legacy()
1689 
1690             block_device_info.update({
1691                 'ephemerals': ephemerals,
1692                 'swap': swap,
1693                 'block_device_mapping': mapping})
1694 
1695     def _add_missing_dev_names(self, bdms, instance):
1696         for bdm in bdms:
1697             if bdm.device_name is not None:
1698                 continue
1699 
1700             device_name = self._get_device_name_for_instance(instance,
1701                                                              bdms, bdm)
1702             values = {'device_name': device_name}
1703             bdm.update(values)
1704             bdm.save()
1705 
1706     def _prep_block_device(self, context, instance, bdms):
1707         """Set up the block device for an instance with error logging."""
1708         try:
1709             self._add_missing_dev_names(bdms, instance)
1710             block_device_info = driver.get_block_device_info(instance, bdms)
1711             mapping = driver.block_device_info_get_mapping(block_device_info)
1712             driver_block_device.attach_block_devices(
1713                 mapping, context, instance, self.volume_api, self.driver,
1714                 wait_func=self._await_block_device_map_created)
1715 
1716             self._block_device_info_to_legacy(block_device_info)
1717             return block_device_info
1718 
1719         except exception.OverQuota as e:
1720             LOG.warning('Failed to create block device for instance due'
1721                         ' to exceeding volume related resource quota.'
1722                         ' Error: %s', e.message, instance=instance)
1723             raise
1724 
1725         except Exception as ex:
1726             LOG.exception('Instance failed block device setup',
1727                           instance=instance)
1728             # InvalidBDM will eventually result in a BuildAbortException when
1729             # booting from volume, and will be recorded as an instance fault.
1730             # Maintain the original exception message which most likely has
1731             # useful details which the standard InvalidBDM error message lacks.
1732             raise exception.InvalidBDM(six.text_type(ex))
1733 
1734     def _update_instance_after_spawn(self, context, instance):
1735         instance.power_state = self._get_power_state(context, instance)
1736         instance.vm_state = vm_states.ACTIVE
1737         instance.task_state = None
1738         instance.launched_at = timeutils.utcnow()
1739         configdrive.update_instance(instance)
1740 
1741     def _update_scheduler_instance_info(self, context, instance):
1742         """Sends an InstanceList with created or updated Instance objects to
1743         the Scheduler client.
1744 
1745         In the case of init_host, the value passed will already be an
1746         InstanceList. Other calls will send individual Instance objects that
1747         have been created or resized. In this case, we create an InstanceList
1748         object containing that Instance.
1749         """
1750         if not self.send_instance_updates:
1751             return
1752         if isinstance(instance, obj_instance.Instance):
1753             instance = objects.InstanceList(objects=[instance])
1754         context = context.elevated()
1755         self.query_client.update_instance_info(context, self.host,
1756                                                instance)
1757 
1758     def _delete_scheduler_instance_info(self, context, instance_uuid):
1759         """Sends the uuid of the deleted Instance to the Scheduler client."""
1760         if not self.send_instance_updates:
1761             return
1762         context = context.elevated()
1763         self.query_client.delete_instance_info(context, self.host,
1764                                                instance_uuid)
1765 
1766     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1767     def _sync_scheduler_instance_info(self, context):
1768         if not self.send_instance_updates:
1769             return
1770         context = context.elevated()
1771         instances = objects.InstanceList.get_by_host(context, self.host,
1772                                                      expected_attrs=[],
1773                                                      use_slave=True)
1774         uuids = [instance.uuid for instance in instances]
1775         self.query_client.sync_instance_info(context, self.host, uuids)
1776 
1777     def _notify_about_instance_usage(self, context, instance, event_suffix,
1778                                      network_info=None, extra_usage_info=None,
1779                                      fault=None):
1780         compute_utils.notify_about_instance_usage(
1781             self.notifier, context, instance, event_suffix,
1782             network_info=network_info,
1783             extra_usage_info=extra_usage_info, fault=fault)
1784 
1785     def _deallocate_network(self, context, instance,
1786                             requested_networks=None):
1787         # If we were told not to allocate networks let's save ourselves
1788         # the trouble of calling the network API.
1789         if requested_networks and requested_networks.no_allocate:
1790             LOG.debug("Skipping network deallocation for instance since "
1791                       "networking was not requested.", instance=instance)
1792             return
1793 
1794         LOG.debug('Deallocating network for instance', instance=instance)
1795         with timeutils.StopWatch() as timer:
1796             self.network_api.deallocate_for_instance(
1797                 context, instance, requested_networks=requested_networks)
1798         # nova-network does an rpc call so we're OK tracking time spent here
1799         LOG.info('Took %0.2f seconds to deallocate network for instance.',
1800                  timer.elapsed(), instance=instance)
1801 
1802     def _get_instance_block_device_info(self, context, instance,
1803                                         refresh_conn_info=False,
1804                                         bdms=None):
1805         """Transform block devices to the driver block_device format."""
1806 
1807         if bdms is None:
1808             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1809                     context, instance.uuid)
1810         block_device_info = driver.get_block_device_info(instance, bdms)
1811 
1812         if not refresh_conn_info:
1813             # if the block_device_mapping has no value in connection_info
1814             # (returned as None), don't include in the mapping
1815             block_device_info['block_device_mapping'] = [
1816                 bdm for bdm in driver.block_device_info_get_mapping(
1817                                     block_device_info)
1818                 if bdm.get('connection_info')]
1819         else:
1820             driver_block_device.refresh_conn_infos(
1821                 driver.block_device_info_get_mapping(block_device_info),
1822                 context, instance, self.volume_api, self.driver)
1823 
1824         self._block_device_info_to_legacy(block_device_info)
1825 
1826         return block_device_info
1827 
1828     def _build_failed(self, node):
1829         if CONF.compute.consecutive_build_service_disable_threshold:
1830             # NOTE(danms): Update our counter, but wait for the next
1831             # update_available_resource() periodic to flush it to the DB
1832             self.rt.build_failed(node)
1833 
1834     def _build_succeeded(self, node):
1835         self.rt.build_succeeded(node)
1836 
1837     @wrap_exception()
1838     @reverts_task_state
1839     @wrap_instance_fault
1840     def build_and_run_instance(self, context, instance, image, request_spec,
1841                      filter_properties, admin_password=None,
1842                      injected_files=None, requested_networks=None,
1843                      security_groups=None, block_device_mapping=None,
1844                      node=None, limits=None, host_list=None):
1845 
1846         @utils.synchronized(instance.uuid)
1847         def _locked_do_build_and_run_instance(*args, **kwargs):
1848             # NOTE(danms): We grab the semaphore with the instance uuid
1849             # locked because we could wait in line to build this instance
1850             # for a while and we want to make sure that nothing else tries
1851             # to do anything with this instance while we wait.
1852             with self._build_semaphore:
1853                 try:
1854                     result = self._do_build_and_run_instance(*args, **kwargs)
1855                 except Exception:
1856                     # NOTE(mriedem): This should really only happen if
1857                     # _decode_files in _do_build_and_run_instance fails, and
1858                     # that's before a guest is spawned so it's OK to remove
1859                     # allocations for the instance for this node from Placement
1860                     # below as there is no guest consuming resources anyway.
1861                     # The _decode_files case could be handled more specifically
1862                     # but that's left for another day.
1863                     result = build_results.FAILED
1864                     raise
1865                 finally:
1866                     if result == build_results.FAILED:
1867                         # Remove the allocation records from Placement for the
1868                         # instance if the build failed. The instance.host is
1869                         # likely set to None in _do_build_and_run_instance
1870                         # which means if the user deletes the instance, it
1871                         # will be deleted in the API, not the compute service.
1872                         # Setting the instance.host to None in
1873                         # _do_build_and_run_instance means that the
1874                         # ResourceTracker will no longer consider this instance
1875                         # to be claiming resources against it, so we want to
1876                         # reflect that same thing in Placement.  No need to
1877                         # call this for a reschedule, as the allocations will
1878                         # have already been removed in
1879                         # self._do_build_and_run_instance().
1880                         self.reportclient.delete_allocation_for_instance(
1881                             context, instance.uuid)
1882 
1883                     if result in (build_results.FAILED,
1884                                   build_results.RESCHEDULED):
1885                         self._build_failed(node)
1886                     else:
1887                         self._build_succeeded(node)
1888 
1889         # NOTE(danms): We spawn here to return the RPC worker thread back to
1890         # the pool. Since what follows could take a really long time, we don't
1891         # want to tie up RPC workers.
1892         utils.spawn_n(_locked_do_build_and_run_instance,
1893                       context, instance, image, request_spec,
1894                       filter_properties, admin_password, injected_files,
1895                       requested_networks, security_groups,
1896                       block_device_mapping, node, limits, host_list)
1897 
1898     def _check_device_tagging(self, requested_networks, block_device_mapping):
1899         tagging_requested = False
1900         if requested_networks:
1901             for net in requested_networks:
1902                 if 'tag' in net and net.tag is not None:
1903                     tagging_requested = True
1904                     break
1905         if block_device_mapping and not tagging_requested:
1906             for bdm in block_device_mapping:
1907                 if 'tag' in bdm and bdm.tag is not None:
1908                     tagging_requested = True
1909                     break
1910         if (tagging_requested and
1911                 not self.driver.capabilities.get('supports_device_tagging',
1912                                                  False)):
1913             raise exception.BuildAbortException('Attempt to boot guest with '
1914                                                 'tagged devices on host that '
1915                                                 'does not support tagging.')
1916 
1917     def _check_trusted_certs(self, instance):
1918         if (instance.trusted_certs and
1919                 not self.driver.capabilities.get('supports_trusted_certs',
1920                                                  False)):
1921             raise exception.BuildAbortException(
1922                 'Trusted image certificates provided on host that does not '
1923                 'support certificate validation.')
1924 
1925     @hooks.add_hook('build_instance')
1926     @wrap_exception()
1927     @reverts_task_state
1928     @wrap_instance_event(prefix='compute')
1929     @wrap_instance_fault
1930     def _do_build_and_run_instance(self, context, instance, image,
1931             request_spec, filter_properties, admin_password, injected_files,
1932             requested_networks, security_groups, block_device_mapping,
1933             node=None, limits=None, host_list=None):
1934 
1935         try:
1936             LOG.debug('Starting instance...', instance=instance)
1937             instance.vm_state = vm_states.BUILDING
1938             instance.task_state = None
1939             instance.save(expected_task_state=
1940                     (task_states.SCHEDULING, None))
1941         except exception.InstanceNotFound:
1942             msg = 'Instance disappeared before build.'
1943             LOG.debug(msg, instance=instance)
1944             return build_results.FAILED
1945         except exception.UnexpectedTaskStateError as e:
1946             LOG.debug(e.format_message(), instance=instance)
1947             return build_results.FAILED
1948 
1949         # b64 decode the files to inject:
1950         decoded_files = self._decode_files(injected_files)
1951 
1952         if limits is None:
1953             limits = {}
1954 
1955         if node is None:
1956             node = self._get_nodename(instance, refresh=True)
1957 
1958         try:
1959             with timeutils.StopWatch() as timer:
1960                 self._build_and_run_instance(context, instance, image,
1961                         decoded_files, admin_password, requested_networks,
1962                         security_groups, block_device_mapping, node, limits,
1963                         filter_properties, request_spec)
1964             LOG.info('Took %0.2f seconds to build instance.',
1965                      timer.elapsed(), instance=instance)
1966             return build_results.ACTIVE
1967         except exception.RescheduledException as e:
1968             retry = filter_properties.get('retry')
1969             if not retry:
1970                 # no retry information, do not reschedule.
1971                 LOG.debug("Retry info not present, will not reschedule",
1972                     instance=instance)
1973                 self._cleanup_allocated_networks(context, instance,
1974                     requested_networks)
1975                 self._cleanup_volumes(context, instance,
1976                     block_device_mapping, raise_exc=False)
1977                 compute_utils.add_instance_fault_from_exc(context,
1978                         instance, e, sys.exc_info(),
1979                         fault_message=e.kwargs['reason'])
1980                 self._nil_out_instance_obj_host_and_node(instance)
1981                 self._set_instance_obj_error_state(context, instance,
1982                                                    clean_task_state=True)
1983                 return build_results.FAILED
1984             LOG.debug(e.format_message(), instance=instance)
1985             # This will be used for logging the exception
1986             retry['exc'] = traceback.format_exception(*sys.exc_info())
1987             # This will be used for setting the instance fault message
1988             retry['exc_reason'] = e.kwargs['reason']
1989             # NOTE(comstud): Deallocate networks if the driver wants
1990             # us to do so.
1991             # NOTE(mriedem): Always deallocate networking when using Neutron.
1992             # This is to unbind any ports that the user supplied in the server
1993             # create request, or delete any ports that nova created which were
1994             # meant to be bound to this host. This check intentionally bypasses
1995             # the result of deallocate_networks_on_reschedule because the
1996             # default value in the driver is False, but that method was really
1997             # only meant for Ironic and should be removed when nova-network is
1998             # removed (since is_neutron() will then always be True).
1999             # NOTE(vladikr): SR-IOV ports should be deallocated to
2000             # allow new sriov pci devices to be allocated on a new host.
2001             # Otherwise, if devices with pci addresses are already allocated
2002             # on the destination host, the instance will fail to spawn.
2003             # info_cache.network_info should be present at this stage.
2004             if (self.driver.deallocate_networks_on_reschedule(instance) or
2005                 utils.is_neutron() or
2006                 self.deallocate_sriov_ports_on_reschedule(instance)):
2007                 self._cleanup_allocated_networks(context, instance,
2008                         requested_networks)
2009             else:
2010                 # NOTE(alex_xu): Network already allocated and we don't
2011                 # want to deallocate them before rescheduling. But we need
2012                 # to cleanup those network resources setup on this host before
2013                 # rescheduling.
2014                 self.network_api.cleanup_instance_network_on_host(
2015                     context, instance, self.host)
2016 
2017             self._nil_out_instance_obj_host_and_node(instance)
2018             instance.task_state = task_states.SCHEDULING
2019             instance.save()
2020             # The instance will have already claimed resources from this host
2021             # before this build was attempted. Now that it has failed, we need
2022             # to unclaim those resources before casting to the conductor, so
2023             # that if there are alternate hosts available for a retry, it can
2024             # claim resources on that new host for the instance.
2025             self.reportclient.delete_allocation_for_instance(context,
2026                                                              instance.uuid)
2027 
2028             self.compute_task_api.build_instances(context, [instance],
2029                     image, filter_properties, admin_password,
2030                     injected_files, requested_networks, security_groups,
2031                     block_device_mapping, request_spec=request_spec,
2032                     host_lists=[host_list])
2033             return build_results.RESCHEDULED
2034         except (exception.InstanceNotFound,
2035                 exception.UnexpectedDeletingTaskStateError):
2036             msg = 'Instance disappeared during build.'
2037             LOG.debug(msg, instance=instance)
2038             self._cleanup_allocated_networks(context, instance,
2039                     requested_networks)
2040             return build_results.FAILED
2041         except Exception as e:
2042             if isinstance(e, exception.BuildAbortException):
2043                 LOG.error(e.format_message(), instance=instance)
2044             else:
2045                 # Should not reach here.
2046                 LOG.exception('Unexpected build failure, not rescheduling '
2047                               'build.', instance=instance)
2048             self._cleanup_allocated_networks(context, instance,
2049                     requested_networks)
2050             self._cleanup_volumes(context, instance,
2051                     block_device_mapping, raise_exc=False)
2052             compute_utils.add_instance_fault_from_exc(context, instance,
2053                     e, sys.exc_info())
2054             self._nil_out_instance_obj_host_and_node(instance)
2055             self._set_instance_obj_error_state(context, instance,
2056                                                clean_task_state=True)
2057             return build_results.FAILED
2058 
2059     def deallocate_sriov_ports_on_reschedule(self, instance):
2060         """Determine if networks are needed to be deallocated before reschedule
2061 
2062         Check the cached network info for any assigned SR-IOV ports.
2063         SR-IOV ports should be deallocated prior to rescheduling
2064         in order to allow new sriov pci devices to be allocated on a new host.
2065         """
2066         info_cache = instance.info_cache
2067 
2068         def _has_sriov_port(vif):
2069             return vif['vnic_type'] in network_model.VNIC_TYPES_SRIOV
2070 
2071         if (info_cache and info_cache.network_info):
2072             for vif in info_cache.network_info:
2073                 if _has_sriov_port(vif):
2074                     return True
2075         return False
2076 
2077     @staticmethod
2078     def _get_scheduler_hints(filter_properties, request_spec=None):
2079         """Helper method to get scheduler hints.
2080 
2081         This method prefers to get the hints out of the request spec, but that
2082         might not be provided. Conductor will pass request_spec down to the
2083         first compute chosen for a build but older computes will not pass
2084         the request_spec to conductor's build_instances method for a
2085         a reschedule, so if we're on a host via a retry, request_spec may not
2086         be provided so we need to fallback to use the filter_properties
2087         to get scheduler hints.
2088         """
2089         hints = {}
2090         if request_spec is not None and 'scheduler_hints' in request_spec:
2091             hints = request_spec.scheduler_hints
2092         if not hints:
2093             hints = filter_properties.get('scheduler_hints') or {}
2094         return hints
2095 
2096     def _build_and_run_instance(self, context, instance, image, injected_files,
2097             admin_password, requested_networks, security_groups,
2098             block_device_mapping, node, limits, filter_properties,
2099             request_spec=None):
2100 
2101         image_name = image.get('name')
2102         self._notify_about_instance_usage(context, instance, 'create.start',
2103                 extra_usage_info={'image_name': image_name})
2104         compute_utils.notify_about_instance_create(
2105             context, instance, self.host,
2106             phase=fields.NotificationPhase.START,
2107             bdms=block_device_mapping)
2108 
2109         # NOTE(mikal): cache the keystone roles associated with the instance
2110         # at boot time for later reference
2111         instance.system_metadata.update(
2112             {'boot_roles': ','.join(context.roles)})
2113 
2114         self._check_device_tagging(requested_networks, block_device_mapping)
2115         self._check_trusted_certs(instance)
2116 
2117         try:
2118             scheduler_hints = self._get_scheduler_hints(filter_properties,
2119                                                         request_spec)
2120             with self.rt.instance_claim(context, instance, node, limits):
2121                 # NOTE(russellb) It's important that this validation be done
2122                 # *after* the resource tracker instance claim, as that is where
2123                 # the host is set on the instance.
2124                 self._validate_instance_group_policy(context, instance,
2125                                                      scheduler_hints)
2126                 image_meta = objects.ImageMeta.from_dict(image)
2127 
2128                 if (request_spec
2129                         and 'requested_resources' in request_spec
2130                         and request_spec.requested_resources is not None):
2131                     request_group_resource_providers_mapping = {
2132                         group.requester_id: group.provider_uuids
2133                         for group in request_spec.requested_resources
2134                     }
2135                 else:
2136                     request_group_resource_providers_mapping = None
2137 
2138                 with self._build_resources(context, instance,
2139                         requested_networks, security_groups, image_meta,
2140                         block_device_mapping,
2141                         request_group_resource_providers_mapping) as resources:
2142                     instance.vm_state = vm_states.BUILDING
2143                     instance.task_state = task_states.SPAWNING
2144                     # NOTE(JoshNang) This also saves the changes to the
2145                     # instance from _allocate_network_async, as they aren't
2146                     # saved in that function to prevent races.
2147                     instance.save(expected_task_state=
2148                             task_states.BLOCK_DEVICE_MAPPING)
2149                     block_device_info = resources['block_device_info']
2150                     network_info = resources['network_info']
2151                     allocs = resources['allocations']
2152                     LOG.debug('Start spawning the instance on the hypervisor.',
2153                               instance=instance)
2154                     with timeutils.StopWatch() as timer:
2155                         self.driver.spawn(context, instance, image_meta,
2156                                           injected_files, admin_password,
2157                                           allocs, network_info=network_info,
2158                                           block_device_info=block_device_info)
2159                     LOG.info('Took %0.2f seconds to spawn the instance on '
2160                              'the hypervisor.', timer.elapsed(),
2161                              instance=instance)
2162         except (exception.InstanceNotFound,
2163                 exception.UnexpectedDeletingTaskStateError) as e:
2164             with excutils.save_and_reraise_exception():
2165                 self._notify_about_instance_usage(context, instance,
2166                     'create.error', fault=e)
2167                 tb = traceback.format_exc()
2168                 compute_utils.notify_about_instance_create(
2169                     context, instance, self.host,
2170                     phase=fields.NotificationPhase.ERROR, exception=e,
2171                     bdms=block_device_mapping, tb=tb)
2172         except exception.ComputeResourcesUnavailable as e:
2173             LOG.debug(e.format_message(), instance=instance)
2174             self._notify_about_instance_usage(context, instance,
2175                     'create.error', fault=e)
2176             tb = traceback.format_exc()
2177             compute_utils.notify_about_instance_create(
2178                     context, instance, self.host,
2179                     phase=fields.NotificationPhase.ERROR, exception=e,
2180                     bdms=block_device_mapping, tb=tb)
2181             raise exception.RescheduledException(
2182                     instance_uuid=instance.uuid, reason=e.format_message())
2183         except exception.BuildAbortException as e:
2184             with excutils.save_and_reraise_exception():
2185                 LOG.debug(e.format_message(), instance=instance)
2186                 self._notify_about_instance_usage(context, instance,
2187                     'create.error', fault=e)
2188                 tb = traceback.format_exc()
2189                 compute_utils.notify_about_instance_create(
2190                     context, instance, self.host,
2191                     phase=fields.NotificationPhase.ERROR, exception=e,
2192                     bdms=block_device_mapping, tb=tb)
2193         except (exception.FixedIpLimitExceeded,
2194                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2195             LOG.warning('No more network or fixed IP to be allocated',
2196                         instance=instance)
2197             self._notify_about_instance_usage(context, instance,
2198                     'create.error', fault=e)
2199             tb = traceback.format_exc()
2200             compute_utils.notify_about_instance_create(
2201                     context, instance, self.host,
2202                     phase=fields.NotificationPhase.ERROR, exception=e,
2203                     bdms=block_device_mapping, tb=tb)
2204             msg = _('Failed to allocate the network(s) with error %s, '
2205                     'not rescheduling.') % e.format_message()
2206             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2207                     reason=msg)
2208         except (exception.VirtualInterfaceCreateException,
2209                 exception.VirtualInterfaceMacAddressException,
2210                 exception.FixedIpInvalidOnHost,
2211                 exception.UnableToAutoAllocateNetwork,
2212                 exception.NetworksWithQoSPolicyNotSupported) as e:
2213             LOG.exception('Failed to allocate network(s)',
2214                           instance=instance)
2215             self._notify_about_instance_usage(context, instance,
2216                     'create.error', fault=e)
2217             tb = traceback.format_exc()
2218             compute_utils.notify_about_instance_create(
2219                     context, instance, self.host,
2220                     phase=fields.NotificationPhase.ERROR, exception=e,
2221                     bdms=block_device_mapping, tb=tb)
2222             msg = _('Failed to allocate the network(s), not rescheduling.')
2223             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2224                     reason=msg)
2225         except (exception.FlavorDiskTooSmall,
2226                 exception.FlavorMemoryTooSmall,
2227                 exception.ImageNotActive,
2228                 exception.ImageUnacceptable,
2229                 exception.InvalidDiskInfo,
2230                 exception.InvalidDiskFormat,
2231                 cursive_exception.SignatureVerificationError,
2232                 exception.CertificateValidationFailed,
2233                 exception.VolumeEncryptionNotSupported,
2234                 exception.InvalidInput,
2235                 # TODO(mriedem): We should be validating RequestedVRamTooHigh
2236                 # in the API during server create and rebuild.
2237                 exception.RequestedVRamTooHigh) as e:
2238             self._notify_about_instance_usage(context, instance,
2239                     'create.error', fault=e)
2240             tb = traceback.format_exc()
2241             compute_utils.notify_about_instance_create(
2242                     context, instance, self.host,
2243                     phase=fields.NotificationPhase.ERROR, exception=e,
2244                     bdms=block_device_mapping, tb=tb)
2245             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2246                     reason=e.format_message())
2247         except Exception as e:
2248             self._notify_about_instance_usage(context, instance,
2249                     'create.error', fault=e)
2250             tb = traceback.format_exc()
2251             compute_utils.notify_about_instance_create(
2252                     context, instance, self.host,
2253                     phase=fields.NotificationPhase.ERROR, exception=e,
2254                     bdms=block_device_mapping, tb=tb)
2255             raise exception.RescheduledException(
2256                     instance_uuid=instance.uuid, reason=six.text_type(e))
2257 
2258         # NOTE(alaski): This is only useful during reschedules, remove it now.
2259         instance.system_metadata.pop('network_allocated', None)
2260 
2261         # If CONF.default_access_ip_network_name is set, grab the
2262         # corresponding network and set the access ip values accordingly.
2263         network_name = CONF.default_access_ip_network_name
2264         if (network_name and not instance.access_ip_v4 and
2265                 not instance.access_ip_v6):
2266             # Note that when there are multiple ips to choose from, an
2267             # arbitrary one will be chosen.
2268             for vif in network_info:
2269                 if vif['network']['label'] == network_name:
2270                     for ip in vif.fixed_ips():
2271                         if not instance.access_ip_v4 and ip['version'] == 4:
2272                             instance.access_ip_v4 = ip['address']
2273                         if not instance.access_ip_v6 and ip['version'] == 6:
2274                             instance.access_ip_v6 = ip['address']
2275                     break
2276 
2277         self._update_instance_after_spawn(context, instance)
2278 
2279         try:
2280             instance.save(expected_task_state=task_states.SPAWNING)
2281         except (exception.InstanceNotFound,
2282                 exception.UnexpectedDeletingTaskStateError) as e:
2283             with excutils.save_and_reraise_exception():
2284                 self._notify_about_instance_usage(context, instance,
2285                     'create.error', fault=e)
2286                 tb = traceback.format_exc()
2287                 compute_utils.notify_about_instance_create(
2288                     context, instance, self.host,
2289                     phase=fields.NotificationPhase.ERROR, exception=e,
2290                     bdms=block_device_mapping, tb=tb)
2291 
2292         self._update_scheduler_instance_info(context, instance)
2293         self._notify_about_instance_usage(context, instance, 'create.end',
2294                 extra_usage_info={'message': _('Success')},
2295                 network_info=network_info)
2296         compute_utils.notify_about_instance_create(context, instance,
2297                 self.host, phase=fields.NotificationPhase.END,
2298                 bdms=block_device_mapping)
2299 
2300     @contextlib.contextmanager
2301     def _build_resources(self, context, instance, requested_networks,
2302                          security_groups, image_meta, block_device_mapping,
2303                          resource_provider_mapping):
2304         resources = {}
2305         network_info = None
2306         try:
2307             LOG.debug('Start building networks asynchronously for instance.',
2308                       instance=instance)
2309             network_info = self._build_networks_for_instance(context, instance,
2310                     requested_networks, security_groups,
2311                     resource_provider_mapping)
2312             resources['network_info'] = network_info
2313         except (exception.InstanceNotFound,
2314                 exception.UnexpectedDeletingTaskStateError):
2315             raise
2316         except exception.UnexpectedTaskStateError as e:
2317             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2318                     reason=e.format_message())
2319         except Exception:
2320             # Because this allocation is async any failures are likely to occur
2321             # when the driver accesses network_info during spawn().
2322             LOG.exception('Failed to allocate network(s)',
2323                           instance=instance)
2324             msg = _('Failed to allocate the network(s), not rescheduling.')
2325             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2326                     reason=msg)
2327 
2328         try:
2329             # Perform any driver preparation work for the driver.
2330             self.driver.prepare_for_spawn(instance)
2331 
2332             # Depending on a virt driver, some network configuration is
2333             # necessary before preparing block devices.
2334             self.driver.prepare_networks_before_block_device_mapping(
2335                 instance, network_info)
2336 
2337             # Verify that all the BDMs have a device_name set and assign a
2338             # default to the ones missing it with the help of the driver.
2339             self._default_block_device_names(instance, image_meta,
2340                                              block_device_mapping)
2341 
2342             LOG.debug('Start building block device mappings for instance.',
2343                       instance=instance)
2344             instance.vm_state = vm_states.BUILDING
2345             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2346             instance.save()
2347 
2348             block_device_info = self._prep_block_device(context, instance,
2349                     block_device_mapping)
2350             resources['block_device_info'] = block_device_info
2351         except (exception.InstanceNotFound,
2352                 exception.UnexpectedDeletingTaskStateError):
2353             with excutils.save_and_reraise_exception():
2354                 # Make sure the async call finishes
2355                 if network_info is not None:
2356                     network_info.wait(do_raise=False)
2357                     self.driver.clean_networks_preparation(instance,
2358                                                            network_info)
2359                 self.driver.failed_spawn_cleanup(instance)
2360         except (exception.UnexpectedTaskStateError,
2361                 exception.OverQuota, exception.InvalidBDM) as e:
2362             # Make sure the async call finishes
2363             if network_info is not None:
2364                 network_info.wait(do_raise=False)
2365                 self.driver.clean_networks_preparation(instance, network_info)
2366             self.driver.failed_spawn_cleanup(instance)
2367             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2368                     reason=e.format_message())
2369         except Exception:
2370             LOG.exception('Failure prepping block device',
2371                           instance=instance)
2372             # Make sure the async call finishes
2373             if network_info is not None:
2374                 network_info.wait(do_raise=False)
2375                 self.driver.clean_networks_preparation(instance, network_info)
2376             self.driver.failed_spawn_cleanup(instance)
2377             msg = _('Failure prepping block device.')
2378             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2379                     reason=msg)
2380 
2381         try:
2382             resources['allocations'] = (
2383                 self.reportclient.get_allocations_for_consumer(context,
2384                                                                instance.uuid))
2385         except Exception:
2386             LOG.exception('Failure retrieving placement allocations',
2387                           instance=instance)
2388             # Make sure the async call finishes
2389             if network_info is not None:
2390                 network_info.wait(do_raise=False)
2391             self.driver.failed_spawn_cleanup(instance)
2392             msg = _('Failure retrieving placement allocations')
2393             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2394                                                 reason=msg)
2395 
2396         try:
2397             yield resources
2398         except Exception as exc:
2399             with excutils.save_and_reraise_exception() as ctxt:
2400                 if not isinstance(exc, (
2401                         exception.InstanceNotFound,
2402                         exception.UnexpectedDeletingTaskStateError)):
2403                     LOG.exception('Instance failed to spawn',
2404                                   instance=instance)
2405                 # Make sure the async call finishes
2406                 if network_info is not None:
2407                     network_info.wait(do_raise=False)
2408                 # if network_info is empty we're likely here because of
2409                 # network allocation failure. Since nothing can be reused on
2410                 # rescheduling it's better to deallocate network to eliminate
2411                 # the chance of orphaned ports in neutron
2412                 deallocate_networks = False if network_info else True
2413                 try:
2414                     self._shutdown_instance(context, instance,
2415                             block_device_mapping, requested_networks,
2416                             try_deallocate_networks=deallocate_networks)
2417                 except Exception as exc2:
2418                     ctxt.reraise = False
2419                     LOG.warning('Could not clean up failed build,'
2420                                 ' not rescheduling. Error: %s',
2421                                 six.text_type(exc2))
2422                     raise exception.BuildAbortException(
2423                             instance_uuid=instance.uuid,
2424                             reason=six.text_type(exc))
2425 
2426     def _cleanup_allocated_networks(self, context, instance,
2427             requested_networks):
2428         try:
2429             self._deallocate_network(context, instance, requested_networks)
2430         except Exception:
2431             LOG.exception('Failed to deallocate networks', instance=instance)
2432             return
2433 
2434         instance.system_metadata['network_allocated'] = 'False'
2435         try:
2436             instance.save()
2437         except exception.InstanceNotFound:
2438             # NOTE(alaski): It's possible that we're cleaning up the networks
2439             # because the instance was deleted.  If that's the case then this
2440             # exception will be raised by instance.save()
2441             pass
2442 
2443     def _try_deallocate_network(self, context, instance,
2444                                 requested_networks=None):
2445 
2446         # During auto-scale cleanup, we could be deleting a large number
2447         # of servers at the same time and overloading parts of the system,
2448         # so we retry a few times in case of connection failures to the
2449         # networking service.
2450         @loopingcall.RetryDecorator(
2451             max_retry_count=3, inc_sleep_time=2, max_sleep_time=12,
2452             exceptions=(keystone_exception.connection.ConnectFailure,))
2453         def _deallocate_network_with_retries():
2454             try:
2455                 self._deallocate_network(
2456                     context, instance, requested_networks)
2457             except keystone_exception.connection.ConnectFailure as e:
2458                 # Provide a warning that something is amiss.
2459                 with excutils.save_and_reraise_exception():
2460                     LOG.warning('Failed to deallocate network for instance; '
2461                                 'retrying. Error: %s', six.text_type(e),
2462                                 instance=instance)
2463 
2464         try:
2465             # tear down allocated network structure
2466             _deallocate_network_with_retries()
2467         except Exception as ex:
2468             with excutils.save_and_reraise_exception():
2469                 LOG.error('Failed to deallocate network for instance. '
2470                           'Error: %s', ex, instance=instance)
2471                 self._set_instance_obj_error_state(context, instance)
2472 
2473     def _get_power_off_values(self, context, instance, clean_shutdown):
2474         """Get the timing configuration for powering down this instance."""
2475         if clean_shutdown:
2476             timeout = compute_utils.get_value_from_system_metadata(instance,
2477                           key='image_os_shutdown_timeout', type=int,
2478                           default=CONF.shutdown_timeout)
2479             retry_interval = CONF.compute.shutdown_retry_interval
2480         else:
2481             timeout = 0
2482             retry_interval = 0
2483 
2484         return timeout, retry_interval
2485 
2486     def _power_off_instance(self, context, instance, clean_shutdown=True):
2487         """Power off an instance on this host."""
2488         timeout, retry_interval = self._get_power_off_values(context,
2489                                         instance, clean_shutdown)
2490         self.driver.power_off(instance, timeout, retry_interval)
2491 
2492     def _shutdown_instance(self, context, instance,
2493                            bdms, requested_networks=None, notify=True,
2494                            try_deallocate_networks=True):
2495         """Shutdown an instance on this host.
2496 
2497         :param:context: security context
2498         :param:instance: a nova.objects.Instance object
2499         :param:bdms: the block devices for the instance to be torn
2500                      down
2501         :param:requested_networks: the networks on which the instance
2502                                    has ports
2503         :param:notify: true if a final usage notification should be
2504                        emitted
2505         :param:try_deallocate_networks: false if we should avoid
2506                                         trying to teardown networking
2507         """
2508         context = context.elevated()
2509         LOG.info('Terminating instance', instance=instance)
2510 
2511         if notify:
2512             self._notify_about_instance_usage(context, instance,
2513                                               "shutdown.start")
2514             compute_utils.notify_about_instance_action(context, instance,
2515                     self.host, action=fields.NotificationAction.SHUTDOWN,
2516                     phase=fields.NotificationPhase.START, bdms=bdms)
2517 
2518         network_info = instance.get_network_info()
2519 
2520         # NOTE(vish) get bdms before destroying the instance
2521         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2522         block_device_info = self._get_instance_block_device_info(
2523             context, instance, bdms=bdms)
2524 
2525         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2526         #                want to keep ip allocated for certain failures
2527         try:
2528             LOG.debug('Start destroying the instance on the hypervisor.',
2529                       instance=instance)
2530             with timeutils.StopWatch() as timer:
2531                 self.driver.destroy(context, instance, network_info,
2532                                     block_device_info)
2533             LOG.info('Took %0.2f seconds to destroy the instance on the '
2534                      'hypervisor.', timer.elapsed(), instance=instance)
2535         except exception.InstancePowerOffFailure:
2536             # if the instance can't power off, don't release the ip
2537             with excutils.save_and_reraise_exception():
2538                 pass
2539         except Exception:
2540             with excutils.save_and_reraise_exception():
2541                 # deallocate ip and fail without proceeding to
2542                 # volume api calls, preserving current behavior
2543                 if try_deallocate_networks:
2544                     self._try_deallocate_network(context, instance,
2545                                                  requested_networks)
2546 
2547         if try_deallocate_networks:
2548             self._try_deallocate_network(context, instance, requested_networks)
2549 
2550         timer.restart()
2551         for bdm in vol_bdms:
2552             try:
2553                 if bdm.attachment_id:
2554                     self.volume_api.attachment_delete(context,
2555                                                       bdm.attachment_id)
2556                 else:
2557                     # NOTE(vish): actual driver detach done in driver.destroy,
2558                     #             so just tell cinder that we are done with it.
2559                     connector = self.driver.get_volume_connector(instance)
2560                     self.volume_api.terminate_connection(context,
2561                                                          bdm.volume_id,
2562                                                          connector)
2563                     self.volume_api.detach(context, bdm.volume_id,
2564                                            instance.uuid)
2565 
2566             except exception.VolumeAttachmentNotFound as exc:
2567                 LOG.debug('Ignoring VolumeAttachmentNotFound: %s', exc,
2568                           instance=instance)
2569             except exception.DiskNotFound as exc:
2570                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2571                           instance=instance)
2572             except exception.VolumeNotFound as exc:
2573                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2574                           instance=instance)
2575             except (cinder_exception.EndpointNotFound,
2576                     keystone_exception.EndpointNotFound) as exc:
2577                 LOG.warning('Ignoring EndpointNotFound for '
2578                             'volume %(volume_id)s: %(exc)s',
2579                             {'exc': exc, 'volume_id': bdm.volume_id},
2580                             instance=instance)
2581             except cinder_exception.ClientException as exc:
2582                 LOG.warning('Ignoring unknown cinder exception for '
2583                             'volume %(volume_id)s: %(exc)s',
2584                             {'exc': exc, 'volume_id': bdm.volume_id},
2585                             instance=instance)
2586             except Exception as exc:
2587                 LOG.warning('Ignoring unknown exception for '
2588                             'volume %(volume_id)s: %(exc)s',
2589                             {'exc': exc, 'volume_id': bdm.volume_id},
2590                             instance=instance)
2591         if vol_bdms:
2592             LOG.info('Took %(time).2f seconds to detach %(num)s volumes '
2593                      'for instance.',
2594                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2595                      instance=instance)
2596 
2597         if notify:
2598             self._notify_about_instance_usage(context, instance,
2599                                               "shutdown.end")
2600             compute_utils.notify_about_instance_action(context, instance,
2601                     self.host, action=fields.NotificationAction.SHUTDOWN,
2602                     phase=fields.NotificationPhase.END, bdms=bdms)
2603 
2604     def _cleanup_volumes(self, context, instance, bdms, raise_exc=True,
2605                          detach=True):
2606         exc_info = None
2607         for bdm in bdms:
2608             if detach and bdm.volume_id:
2609                 try:
2610                     LOG.debug("Detaching volume: %s", bdm.volume_id,
2611                               instance_uuid=instance.uuid)
2612                     destroy = bdm.delete_on_termination
2613                     self._detach_volume(context, bdm, instance,
2614                                         destroy_bdm=destroy)
2615                 except Exception as exc:
2616                     exc_info = sys.exc_info()
2617                     LOG.warning('Failed to detach volume: %(volume_id)s '
2618                                 'due to %(exc)s',
2619                                 {'volume_id': bdm.volume_id, 'exc': exc})
2620 
2621             if bdm.volume_id and bdm.delete_on_termination:
2622                 try:
2623                     LOG.debug("Deleting volume: %s", bdm.volume_id,
2624                               instance_uuid=instance.uuid)
2625                     self.volume_api.delete(context, bdm.volume_id)
2626                 except Exception as exc:
2627                     exc_info = sys.exc_info()
2628                     LOG.warning('Failed to delete volume: %(volume_id)s '
2629                                 'due to %(exc)s',
2630                                 {'volume_id': bdm.volume_id, 'exc': exc})
2631         if exc_info is not None and raise_exc:
2632             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2633 
2634     @hooks.add_hook("delete_instance")
2635     def _delete_instance(self, context, instance, bdms):
2636         """Delete an instance on this host.
2637 
2638         :param context: nova request context
2639         :param instance: nova.objects.instance.Instance object
2640         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2641         """
2642         events = self.instance_events.clear_events_for_instance(instance)
2643         if events:
2644             LOG.debug('Events pending at deletion: %(events)s',
2645                       {'events': ','.join(events.keys())},
2646                       instance=instance)
2647         self._notify_about_instance_usage(context, instance,
2648                                           "delete.start")
2649         compute_utils.notify_about_instance_action(context, instance,
2650                 self.host, action=fields.NotificationAction.DELETE,
2651                 phase=fields.NotificationPhase.START, bdms=bdms)
2652 
2653         self._shutdown_instance(context, instance, bdms)
2654 
2655         # NOTE(vish): We have already deleted the instance, so we have
2656         #             to ignore problems cleaning up the volumes. It
2657         #             would be nice to let the user know somehow that
2658         #             the volume deletion failed, but it is not
2659         #             acceptable to have an instance that can not be
2660         #             deleted. Perhaps this could be reworked in the
2661         #             future to set an instance fault the first time
2662         #             and to only ignore the failure if the instance
2663         #             is already in ERROR.
2664 
2665         # NOTE(ameeda): The volumes already detached during the above
2666         #               _shutdown_instance() call and this is why
2667         #               detach is not requested from _cleanup_volumes()
2668         #               in this case
2669 
2670         self._cleanup_volumes(context, instance, bdms,
2671                 raise_exc=False, detach=False)
2672         # if a delete task succeeded, always update vm state and task
2673         # state without expecting task state to be DELETING
2674         instance.vm_state = vm_states.DELETED
2675         instance.task_state = None
2676         instance.power_state = power_state.NOSTATE
2677         instance.terminated_at = timeutils.utcnow()
2678         instance.save()
2679 
2680         self._complete_deletion(context, instance)
2681         # only destroy the instance in the db if the _complete_deletion
2682         # doesn't raise and therefore allocation is successfully
2683         # deleted in placement
2684         instance.destroy()
2685 
2686         self._notify_about_instance_usage(context, instance, "delete.end")
2687         compute_utils.notify_about_instance_action(context, instance,
2688                 self.host, action=fields.NotificationAction.DELETE,
2689                 phase=fields.NotificationPhase.END, bdms=bdms)
2690 
2691     @wrap_exception()
2692     @reverts_task_state
2693     @wrap_instance_event(prefix='compute')
2694     @wrap_instance_fault
2695     def terminate_instance(self, context, instance, bdms):
2696         """Terminate an instance on this host."""
2697         @utils.synchronized(instance.uuid)
2698         def do_terminate_instance(instance, bdms):
2699             # NOTE(mriedem): If we are deleting the instance while it was
2700             # booting from volume, we could be racing with a database update of
2701             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2702             # to compute here, the BDMs may be stale at this point. So check
2703             # for any volume BDMs that don't have volume_id set and if we
2704             # detect that, we need to refresh the BDM list before proceeding.
2705             # TODO(mriedem): Move this into _delete_instance and make the bdms
2706             # parameter optional.
2707             for bdm in list(bdms):
2708                 if bdm.is_volume and not bdm.volume_id:
2709                     LOG.debug('There are potentially stale BDMs during '
2710                               'delete, refreshing the BlockDeviceMappingList.',
2711                               instance=instance)
2712                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2713                         context, instance.uuid)
2714                     break
2715             try:
2716                 self._delete_instance(context, instance, bdms)
2717             except exception.InstanceNotFound:
2718                 LOG.info("Instance disappeared during terminate",
2719                          instance=instance)
2720             except Exception:
2721                 # As we're trying to delete always go to Error if something
2722                 # goes wrong that _delete_instance can't handle.
2723                 with excutils.save_and_reraise_exception():
2724                     LOG.exception('Setting instance vm_state to ERROR',
2725                                   instance=instance)
2726                     self._set_instance_obj_error_state(context, instance)
2727 
2728         do_terminate_instance(instance, bdms)
2729 
2730     # NOTE(johannes): This is probably better named power_off_instance
2731     # so it matches the driver method, but because of other issues, we
2732     # can't use that name in grizzly.
2733     @wrap_exception()
2734     @reverts_task_state
2735     @wrap_instance_event(prefix='compute')
2736     @wrap_instance_fault
2737     def stop_instance(self, context, instance, clean_shutdown):
2738         """Stopping an instance on this host."""
2739 
2740         @utils.synchronized(instance.uuid)
2741         def do_stop_instance():
2742             current_power_state = self._get_power_state(context, instance)
2743             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2744                       'current task_state: %(task_state)s, current DB '
2745                       'power_state: %(db_power_state)s, current VM '
2746                       'power_state: %(current_power_state)s',
2747                       {'vm_state': instance.vm_state,
2748                        'task_state': instance.task_state,
2749                        'db_power_state': instance.power_state,
2750                        'current_power_state': current_power_state},
2751                       instance_uuid=instance.uuid)
2752 
2753             # NOTE(mriedem): If the instance is already powered off, we are
2754             # possibly tearing down and racing with other operations, so we can
2755             # expect the task_state to be None if something else updates the
2756             # instance and we're not locking it.
2757             expected_task_state = [task_states.POWERING_OFF]
2758             # The list of power states is from _sync_instance_power_state.
2759             if current_power_state in (power_state.NOSTATE,
2760                                        power_state.SHUTDOWN,
2761                                        power_state.CRASHED):
2762                 LOG.info('Instance is already powered off in the '
2763                          'hypervisor when stop is called.',
2764                          instance=instance)
2765                 expected_task_state.append(None)
2766 
2767             self._notify_about_instance_usage(context, instance,
2768                                               "power_off.start")
2769 
2770             compute_utils.notify_about_instance_action(context, instance,
2771                         self.host, action=fields.NotificationAction.POWER_OFF,
2772                         phase=fields.NotificationPhase.START)
2773 
2774             self._power_off_instance(context, instance, clean_shutdown)
2775             instance.power_state = self._get_power_state(context, instance)
2776             instance.vm_state = vm_states.STOPPED
2777             instance.task_state = None
2778             instance.save(expected_task_state=expected_task_state)
2779             self._notify_about_instance_usage(context, instance,
2780                                               "power_off.end")
2781 
2782             compute_utils.notify_about_instance_action(context, instance,
2783                         self.host, action=fields.NotificationAction.POWER_OFF,
2784                         phase=fields.NotificationPhase.END)
2785 
2786         do_stop_instance()
2787 
2788     def _power_on(self, context, instance):
2789         network_info = self.network_api.get_instance_nw_info(context, instance)
2790         block_device_info = self._get_instance_block_device_info(context,
2791                                                                  instance)
2792         self.driver.power_on(context, instance,
2793                              network_info,
2794                              block_device_info)
2795 
2796     def _delete_snapshot_of_shelved_instance(self, context, instance,
2797                                              snapshot_id):
2798         """Delete snapshot of shelved instance."""
2799         try:
2800             self.image_api.delete(context, snapshot_id)
2801         except (exception.ImageNotFound,
2802                 exception.ImageNotAuthorized) as exc:
2803             LOG.warning("Failed to delete snapshot "
2804                         "from shelved instance (%s).",
2805                         exc.format_message(), instance=instance)
2806         except Exception:
2807             LOG.exception("Something wrong happened when trying to "
2808                           "delete snapshot from shelved instance.",
2809                           instance=instance)
2810 
2811     # NOTE(johannes): This is probably better named power_on_instance
2812     # so it matches the driver method, but because of other issues, we
2813     # can't use that name in grizzly.
2814     @wrap_exception()
2815     @reverts_task_state
2816     @wrap_instance_event(prefix='compute')
2817     @wrap_instance_fault
2818     def start_instance(self, context, instance):
2819         """Starting an instance on this host."""
2820         self._notify_about_instance_usage(context, instance, "power_on.start")
2821         compute_utils.notify_about_instance_action(context, instance,
2822             self.host, action=fields.NotificationAction.POWER_ON,
2823             phase=fields.NotificationPhase.START)
2824         self._power_on(context, instance)
2825         instance.power_state = self._get_power_state(context, instance)
2826         instance.vm_state = vm_states.ACTIVE
2827         instance.task_state = None
2828 
2829         # Delete an image(VM snapshot) for a shelved instance
2830         snapshot_id = instance.system_metadata.get('shelved_image_id')
2831         if snapshot_id:
2832             self._delete_snapshot_of_shelved_instance(context, instance,
2833                                                       snapshot_id)
2834 
2835         # Delete system_metadata for a shelved instance
2836         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2837 
2838         instance.save(expected_task_state=task_states.POWERING_ON)
2839         self._notify_about_instance_usage(context, instance, "power_on.end")
2840         compute_utils.notify_about_instance_action(context, instance,
2841             self.host, action=fields.NotificationAction.POWER_ON,
2842             phase=fields.NotificationPhase.END)
2843 
2844     @messaging.expected_exceptions(NotImplementedError,
2845                                    exception.TriggerCrashDumpNotSupported,
2846                                    exception.InstanceNotRunning)
2847     @wrap_exception()
2848     @wrap_instance_event(prefix='compute')
2849     @wrap_instance_fault
2850     def trigger_crash_dump(self, context, instance):
2851         """Trigger crash dump in an instance."""
2852 
2853         self._notify_about_instance_usage(context, instance,
2854                                           "trigger_crash_dump.start")
2855         compute_utils.notify_about_instance_action(context, instance,
2856                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2857                 phase=fields.NotificationPhase.START)
2858 
2859         # This method does not change task_state and power_state because the
2860         # effect of a trigger depends on user's configuration.
2861         self.driver.trigger_crash_dump(instance)
2862 
2863         self._notify_about_instance_usage(context, instance,
2864                                           "trigger_crash_dump.end")
2865         compute_utils.notify_about_instance_action(context, instance,
2866                 self.host, action=fields.NotificationAction.TRIGGER_CRASH_DUMP,
2867                 phase=fields.NotificationPhase.END)
2868 
2869     @wrap_exception()
2870     @reverts_task_state
2871     @wrap_instance_event(prefix='compute')
2872     @wrap_instance_fault
2873     def soft_delete_instance(self, context, instance):
2874         """Soft delete an instance on this host."""
2875         with compute_utils.notify_about_instance_delete(
2876                 self.notifier, context, instance, 'soft_delete',
2877                 source=fields.NotificationSource.COMPUTE):
2878             try:
2879                 self.driver.soft_delete(instance)
2880             except NotImplementedError:
2881                 # Fallback to just powering off the instance if the
2882                 # hypervisor doesn't implement the soft_delete method
2883                 self.driver.power_off(instance)
2884             instance.power_state = self._get_power_state(context, instance)
2885             instance.vm_state = vm_states.SOFT_DELETED
2886             instance.task_state = None
2887             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2888 
2889     @wrap_exception()
2890     @reverts_task_state
2891     @wrap_instance_event(prefix='compute')
2892     @wrap_instance_fault
2893     def restore_instance(self, context, instance):
2894         """Restore a soft-deleted instance on this host."""
2895         self._notify_about_instance_usage(context, instance, "restore.start")
2896         compute_utils.notify_about_instance_action(context, instance,
2897             self.host, action=fields.NotificationAction.RESTORE,
2898             phase=fields.NotificationPhase.START)
2899         try:
2900             self.driver.restore(instance)
2901         except NotImplementedError:
2902             # Fallback to just powering on the instance if the hypervisor
2903             # doesn't implement the restore method
2904             self._power_on(context, instance)
2905         instance.power_state = self._get_power_state(context, instance)
2906         instance.vm_state = vm_states.ACTIVE
2907         instance.task_state = None
2908         instance.save(expected_task_state=task_states.RESTORING)
2909         self._notify_about_instance_usage(context, instance, "restore.end")
2910         compute_utils.notify_about_instance_action(context, instance,
2911             self.host, action=fields.NotificationAction.RESTORE,
2912             phase=fields.NotificationPhase.END)
2913 
2914     @staticmethod
2915     def _set_migration_status(migration, status):
2916         """Set the status, and guard against a None being passed in.
2917 
2918         This is useful as some of the compute RPC calls will not pass
2919         a migration object in older versions. The check can be removed when
2920         we move past 4.x major version of the RPC API.
2921         """
2922         if migration:
2923             migration.status = status
2924             migration.save()
2925 
2926     def _rebuild_default_impl(self, context, instance, image_meta,
2927                               injected_files, admin_password, allocations,
2928                               bdms, detach_block_devices, attach_block_devices,
2929                               network_info=None,
2930                               evacuate=False, block_device_info=None,
2931                               preserve_ephemeral=False):
2932         if preserve_ephemeral:
2933             # The default code path does not support preserving ephemeral
2934             # partitions.
2935             raise exception.PreserveEphemeralNotSupported()
2936 
2937         if evacuate:
2938             detach_block_devices(context, bdms)
2939         else:
2940             self._power_off_instance(context, instance, clean_shutdown=True)
2941             detach_block_devices(context, bdms)
2942             self.driver.destroy(context, instance,
2943                                 network_info=network_info,
2944                                 block_device_info=block_device_info)
2945 
2946         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2947         instance.save(expected_task_state=[task_states.REBUILDING])
2948 
2949         new_block_device_info = attach_block_devices(context, instance, bdms)
2950 
2951         instance.task_state = task_states.REBUILD_SPAWNING
2952         instance.save(
2953             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2954 
2955         with instance.mutated_migration_context():
2956             self.driver.spawn(context, instance, image_meta, injected_files,
2957                               admin_password, allocations,
2958                               network_info=network_info,
2959                               block_device_info=new_block_device_info)
2960 
2961     def _notify_instance_rebuild_error(self, context, instance, error, bdms):
2962         tb = traceback.format_exc()
2963         self._notify_about_instance_usage(context, instance,
2964                                           'rebuild.error', fault=error)
2965         compute_utils.notify_about_instance_rebuild(
2966             context, instance, self.host,
2967             phase=fields.NotificationPhase.ERROR, exception=error, bdms=bdms,
2968             tb=tb)
2969 
2970     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2971     @wrap_exception()
2972     @reverts_task_state
2973     @wrap_instance_event(prefix='compute')
2974     @wrap_instance_fault
2975     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2976                          injected_files, new_pass, orig_sys_metadata,
2977                          bdms, recreate, on_shared_storage,
2978                          preserve_ephemeral, migration,
2979                          scheduled_node, limits, request_spec):
2980         """Destroy and re-make this instance.
2981 
2982         A 'rebuild' effectively purges all existing data from the system and
2983         remakes the VM with given 'metadata' and 'personalities'.
2984 
2985         :param context: `nova.RequestContext` object
2986         :param instance: Instance object
2987         :param orig_image_ref: Original image_ref before rebuild
2988         :param image_ref: New image_ref for rebuild
2989         :param injected_files: Files to inject
2990         :param new_pass: password to set on rebuilt instance
2991         :param orig_sys_metadata: instance system metadata from pre-rebuild
2992         :param bdms: block-device-mappings to use for rebuild
2993         :param recreate: True if the instance is being recreated (e.g. the
2994             hypervisor it was on failed) - cleanup of old state will be
2995             skipped.
2996         :param on_shared_storage: True if instance files on shared storage.
2997                                   If not provided then information from the
2998                                   driver will be used to decide if the instance
2999                                   files are available or not on the target host
3000         :param preserve_ephemeral: True if the default ephemeral storage
3001                                    partition must be preserved on rebuild
3002         :param migration: a Migration object if one was created for this
3003                           rebuild operation (if it's a part of evacuate)
3004         :param scheduled_node: A node of the host chosen by the scheduler. If a
3005                                host was specified by the user, this will be
3006                                None
3007         :param limits: Overcommit limits set by the scheduler. If a host was
3008                        specified by the user, this will be None
3009         :param request_spec: a RequestSpec object used to schedule the instance
3010 
3011         """
3012         # recreate=True means the instance is being evacuated from a failed
3013         # host to a new destination host (this host). The 'recreate' variable
3014         # name is confusing, so rename it to evacuate here at the top, which
3015         # is simpler than renaming a parameter in an RPC versioned method.
3016         evacuate = recreate
3017         context = context.elevated()
3018 
3019         if evacuate:
3020             LOG.info("Evacuating instance", instance=instance)
3021         else:
3022             LOG.info("Rebuilding instance", instance=instance)
3023 
3024         if evacuate:
3025             # This is an evacuation to a new host, so we need to perform a
3026             # resource claim.
3027             rebuild_claim = self.rt.rebuild_claim
3028         else:
3029             # This is a rebuild to the same host, so we don't need to make
3030             # a claim since the instance is already on this host.
3031             rebuild_claim = claims.NopClaim
3032 
3033         if image_ref:
3034             image_meta = objects.ImageMeta.from_image_ref(
3035                 context, self.image_api, image_ref)
3036         elif evacuate:
3037             # For evacuate the API does not send down the image_ref since the
3038             # image does not change so just get it from what was stashed in
3039             # the instance system_metadata when the instance was created (or
3040             # last rebuilt). This also works for volume-backed instances.
3041             image_meta = instance.image_meta
3042         else:
3043             image_meta = objects.ImageMeta()
3044 
3045         # NOTE(mriedem): On an evacuate, we need to update
3046         # the instance's host and node properties to reflect it's
3047         # destination node for the evacuate.
3048         if not scheduled_node:
3049             if evacuate:
3050                 try:
3051                     compute_node = self._get_compute_info(context, self.host)
3052                     scheduled_node = compute_node.hypervisor_hostname
3053                 except exception.ComputeHostNotFound:
3054                     LOG.exception('Failed to get compute_info for %s',
3055                                   self.host)
3056             else:
3057                 scheduled_node = instance.node
3058 
3059         with self._error_out_instance_on_exception(context, instance):
3060             try:
3061                 claim_ctxt = rebuild_claim(
3062                     context, instance, scheduled_node,
3063                     limits=limits, image_meta=image_meta,
3064                     migration=migration)
3065                 self._do_rebuild_instance_with_claim(
3066                     claim_ctxt, context, instance, orig_image_ref,
3067                     image_meta, injected_files, new_pass, orig_sys_metadata,
3068                     bdms, evacuate, on_shared_storage, preserve_ephemeral,
3069                     migration, request_spec)
3070             except (exception.ComputeResourcesUnavailable,
3071                     exception.RescheduledException) as e:
3072                 if isinstance(e, exception.ComputeResourcesUnavailable):
3073                     LOG.debug("Could not rebuild instance on this host, not "
3074                               "enough resources available.", instance=instance)
3075                 else:
3076                     # RescheduledException is raised by the late server group
3077                     # policy check during evacuation if a parallel scheduling
3078                     # violated the policy.
3079                     # We catch the RescheduledException here but we don't have
3080                     # the plumbing to do an actual reschedule so we abort the
3081                     # operation.
3082                     LOG.debug("Could not rebuild instance on this host, "
3083                               "late server group check failed.",
3084                               instance=instance)
3085                 # NOTE(ndipanov): We just abort the build for now and leave a
3086                 # migration record for potential cleanup later
3087                 self._set_migration_status(migration, 'failed')
3088                 # Since the claim failed, we need to remove the allocation
3089                 # created against the destination node. Note that we can only
3090                 # get here when evacuating to a destination node. Rebuilding
3091                 # on the same host (not evacuate) uses the NopClaim which will
3092                 # not raise ComputeResourcesUnavailable.
3093                 self.rt.delete_allocation_for_evacuated_instance(
3094                     context, instance, scheduled_node, node_type='destination')
3095                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3096                 raise exception.BuildAbortException(
3097                     instance_uuid=instance.uuid, reason=e.format_message())
3098             except (exception.InstanceNotFound,
3099                     exception.UnexpectedDeletingTaskStateError) as e:
3100                 LOG.debug('Instance was deleted while rebuilding',
3101                           instance=instance)
3102                 self._set_migration_status(migration, 'failed')
3103                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3104             except Exception as e:
3105                 self._set_migration_status(migration, 'failed')
3106                 if evacuate or scheduled_node is not None:
3107                     self.rt.delete_allocation_for_evacuated_instance(
3108                         context, instance, scheduled_node,
3109                         node_type='destination')
3110                 self._notify_instance_rebuild_error(context, instance, e, bdms)
3111                 raise
3112             else:
3113                 instance.apply_migration_context()
3114                 # NOTE (ndipanov): This save will now update the host and node
3115                 # attributes making sure that next RT pass is consistent since
3116                 # it will be based on the instance and not the migration DB
3117                 # entry.
3118                 instance.host = self.host
3119                 instance.node = scheduled_node
3120                 instance.save()
3121                 instance.drop_migration_context()
3122 
3123                 # NOTE (ndipanov): Mark the migration as done only after we
3124                 # mark the instance as belonging to this host.
3125                 self._set_migration_status(migration, 'done')
3126 
3127     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
3128         """Helper to avoid deep nesting in the top-level method."""
3129 
3130         with claim_context:
3131             self._do_rebuild_instance(*args, **kwargs)
3132 
3133     @staticmethod
3134     def _get_image_name(image_meta):
3135         if image_meta.obj_attr_is_set("name"):
3136             return image_meta.name
3137         else:
3138             return ''
3139 
3140     def _do_rebuild_instance(self, context, instance, orig_image_ref,
3141                              image_meta, injected_files, new_pass,
3142                              orig_sys_metadata, bdms, evacuate,
3143                              on_shared_storage, preserve_ephemeral,
3144                              migration, request_spec):
3145         orig_vm_state = instance.vm_state
3146 
3147         if evacuate:
3148             if request_spec:
3149                 # NOTE(gibi): Do a late check of server group policy as
3150                 # parallel scheduling could violate such policy. This will
3151                 # cause the evacuate to fail as rebuild does not implement
3152                 # reschedule.
3153                 hints = self._get_scheduler_hints({}, request_spec)
3154                 self._validate_instance_group_policy(context, instance, hints)
3155 
3156             if not self.driver.capabilities.get("supports_evacuate", False):
3157                 raise exception.InstanceEvacuateNotSupported
3158 
3159             self._check_instance_exists(context, instance)
3160 
3161             if on_shared_storage is None:
3162                 LOG.debug('on_shared_storage is not provided, using driver '
3163                           'information to decide if the instance needs to '
3164                           'be evacuated')
3165                 on_shared_storage = self.driver.instance_on_disk(instance)
3166 
3167             elif (on_shared_storage !=
3168                     self.driver.instance_on_disk(instance)):
3169                 # To cover case when admin expects that instance files are
3170                 # on shared storage, but not accessible and vice versa
3171                 raise exception.InvalidSharedStorage(
3172                         _("Invalid state of instance files on shared"
3173                             " storage"))
3174 
3175             if on_shared_storage:
3176                 LOG.info('disk on shared storage, evacuating using'
3177                          ' existing disk')
3178             elif instance.image_ref:
3179                 orig_image_ref = instance.image_ref
3180                 LOG.info("disk not on shared storage, evacuating from "
3181                          "image: '%s'", str(orig_image_ref))
3182             else:
3183                 LOG.info('disk on volume, evacuating using existing '
3184                          'volume')
3185 
3186         # We check trusted certs capabilities for both evacuate (rebuild on
3187         # another host) and rebuild (rebuild on the same host) because for
3188         # evacuate we need to make sure an instance with trusted certs can
3189         # have the image verified with those certs during rebuild, and for
3190         # rebuild we could be rebuilding a server that started out with no
3191         # trusted certs on this host, and then was rebuilt with trusted certs
3192         # for a new image, in which case we need to validate that new image
3193         # with the trusted certs during the rebuild.
3194         self._check_trusted_certs(instance)
3195 
3196         # This instance.exists message should contain the original
3197         # image_ref, not the new one.  Since the DB has been updated
3198         # to point to the new one... we have to override it.
3199         orig_image_ref_url = self.image_api.generate_image_url(orig_image_ref,
3200                                                                context)
3201         extra_usage_info = {'image_ref_url': orig_image_ref_url}
3202         compute_utils.notify_usage_exists(
3203                 self.notifier, context, instance, self.host,
3204                 current_period=True, system_metadata=orig_sys_metadata,
3205                 extra_usage_info=extra_usage_info)
3206 
3207         # This message should contain the new image_ref
3208         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
3209         self._notify_about_instance_usage(context, instance,
3210                 "rebuild.start", extra_usage_info=extra_usage_info)
3211         # NOTE: image_name is not included in the versioned notification
3212         # because we already provide the image_uuid in the notification
3213         # payload and the image details can be looked up via the uuid.
3214         compute_utils.notify_about_instance_rebuild(
3215             context, instance, self.host,
3216             phase=fields.NotificationPhase.START,
3217             bdms=bdms)
3218 
3219         instance.power_state = self._get_power_state(context, instance)
3220         instance.task_state = task_states.REBUILDING
3221         instance.save(expected_task_state=[task_states.REBUILDING])
3222 
3223         if evacuate:
3224             self.network_api.setup_networks_on_host(
3225                     context, instance, self.host)
3226             # For nova-network this is needed to move floating IPs
3227             # For neutron this updates the host in the port binding
3228             # TODO(cfriesen): this network_api call and the one above
3229             # are so similar, we should really try to unify them.
3230             self.network_api.setup_instance_network_on_host(
3231                     context, instance, self.host, migration)
3232             # TODO(mriedem): Consider decorating setup_instance_network_on_host
3233             # with @base_api.refresh_cache and then we wouldn't need this
3234             # explicit call to get_instance_nw_info.
3235             network_info = self.network_api.get_instance_nw_info(context,
3236                                                                  instance)
3237         else:
3238             network_info = instance.get_network_info()
3239 
3240         allocations = self.reportclient.get_allocations_for_consumer(
3241             context, instance.uuid)
3242 
3243         if bdms is None:
3244             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3245                     context, instance.uuid)
3246 
3247         block_device_info = \
3248             self._get_instance_block_device_info(
3249                     context, instance, bdms=bdms)
3250 
3251         def detach_block_devices(context, bdms):
3252             for bdm in bdms:
3253                 if bdm.is_volume:
3254                     # NOTE (ildikov): Having the attachment_id set in the BDM
3255                     # means that it's the new Cinder attach/detach flow
3256                     # (available from v3.44). In that case we explicitly
3257                     # attach and detach the volumes through attachment level
3258                     # operations. In this scenario _detach_volume will delete
3259                     # the existing attachment which would make the volume
3260                     # status change to 'available' if we don't pre-create
3261                     # another empty attachment before deleting the old one.
3262                     attachment_id = None
3263                     if bdm.attachment_id:
3264                         attachment_id = self.volume_api.attachment_create(
3265                             context, bdm['volume_id'], instance.uuid)['id']
3266                     self._detach_volume(context, bdm, instance,
3267                                         destroy_bdm=False)
3268                     if attachment_id:
3269                         bdm.attachment_id = attachment_id
3270                         bdm.save()
3271 
3272         files = self._decode_files(injected_files)
3273 
3274         kwargs = dict(
3275             context=context,
3276             instance=instance,
3277             image_meta=image_meta,
3278             injected_files=files,
3279             admin_password=new_pass,
3280             allocations=allocations,
3281             bdms=bdms,
3282             detach_block_devices=detach_block_devices,
3283             attach_block_devices=self._prep_block_device,
3284             block_device_info=block_device_info,
3285             network_info=network_info,
3286             preserve_ephemeral=preserve_ephemeral,
3287             evacuate=evacuate)
3288         try:
3289             with instance.mutated_migration_context():
3290                 self.driver.rebuild(**kwargs)
3291         except NotImplementedError:
3292             # NOTE(rpodolyaka): driver doesn't provide specialized version
3293             # of rebuild, fall back to the default implementation
3294             self._rebuild_default_impl(**kwargs)
3295         self._update_instance_after_spawn(context, instance)
3296         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
3297 
3298         if orig_vm_state == vm_states.STOPPED:
3299             LOG.info("bringing vm to original state: '%s'",
3300                      orig_vm_state, instance=instance)
3301             instance.vm_state = vm_states.ACTIVE
3302             instance.task_state = task_states.POWERING_OFF
3303             instance.progress = 0
3304             instance.save()
3305             self.stop_instance(context, instance, False)
3306         # TODO(melwitt): We should clean up instance console tokens here in the
3307         # case of evacuate. The instance is on a new host and will need to
3308         # establish a new console connection.
3309         self._update_scheduler_instance_info(context, instance)
3310         self._notify_about_instance_usage(
3311                 context, instance, "rebuild.end",
3312                 network_info=network_info,
3313                 extra_usage_info=extra_usage_info)
3314         compute_utils.notify_about_instance_rebuild(
3315             context, instance, self.host,
3316             phase=fields.NotificationPhase.END,
3317             bdms=bdms)
3318 
3319     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
3320                                      block_device_info):
3321         """Handle cases where the virt-layer had to detach non-working volumes
3322         in order to complete an operation.
3323         """
3324         for bdm in block_device_info['block_device_mapping']:
3325             if bdm.get('mount_device') in bad_devices:
3326                 try:
3327                     volume_id = bdm['connection_info']['data']['volume_id']
3328                 except KeyError:
3329                     continue
3330 
3331                 # NOTE(sirp): ideally we'd just call
3332                 # `compute_api.detach_volume` here but since that hits the
3333                 # DB directly, that's off limits from within the
3334                 # compute-manager.
3335                 #
3336                 # API-detach
3337                 LOG.info("Detaching from volume api: %s", volume_id)
3338                 self.volume_api.begin_detaching(context, volume_id)
3339 
3340                 # Manager-detach
3341                 self.detach_volume(context, volume_id, instance)
3342 
3343     @wrap_exception()
3344     @reverts_task_state
3345     @wrap_instance_event(prefix='compute')
3346     @wrap_instance_fault
3347     def reboot_instance(self, context, instance, block_device_info,
3348                         reboot_type):
3349         """Reboot an instance on this host."""
3350         # acknowledge the request made it to the manager
3351         if reboot_type == "SOFT":
3352             instance.task_state = task_states.REBOOT_PENDING
3353             expected_states = task_states.soft_reboot_states
3354         else:
3355             instance.task_state = task_states.REBOOT_PENDING_HARD
3356             expected_states = task_states.hard_reboot_states
3357 
3358         context = context.elevated()
3359         LOG.info("Rebooting instance", instance=instance)
3360 
3361         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3362             context, instance.uuid)
3363         block_device_info = self._get_instance_block_device_info(
3364             context, instance, bdms=bdms)
3365 
3366         network_info = self.network_api.get_instance_nw_info(context, instance)
3367 
3368         self._notify_about_instance_usage(context, instance, "reboot.start")
3369         compute_utils.notify_about_instance_action(
3370             context, instance, self.host,
3371             action=fields.NotificationAction.REBOOT,
3372             phase=fields.NotificationPhase.START,
3373             bdms=bdms
3374         )
3375 
3376         instance.power_state = self._get_power_state(context, instance)
3377         instance.save(expected_task_state=expected_states)
3378 
3379         if instance.power_state != power_state.RUNNING:
3380             state = instance.power_state
3381             running = power_state.RUNNING
3382             LOG.warning('trying to reboot a non-running instance:'
3383                         ' (state: %(state)s expected: %(running)s)',
3384                         {'state': state, 'running': running},
3385                         instance=instance)
3386 
3387         def bad_volumes_callback(bad_devices):
3388             self._handle_bad_volumes_detached(
3389                     context, instance, bad_devices, block_device_info)
3390 
3391         try:
3392             # Don't change it out of rescue mode
3393             if instance.vm_state == vm_states.RESCUED:
3394                 new_vm_state = vm_states.RESCUED
3395             else:
3396                 new_vm_state = vm_states.ACTIVE
3397             new_power_state = None
3398             if reboot_type == "SOFT":
3399                 instance.task_state = task_states.REBOOT_STARTED
3400                 expected_state = task_states.REBOOT_PENDING
3401             else:
3402                 instance.task_state = task_states.REBOOT_STARTED_HARD
3403                 expected_state = task_states.REBOOT_PENDING_HARD
3404             instance.save(expected_task_state=expected_state)
3405             self.driver.reboot(context, instance,
3406                                network_info,
3407                                reboot_type,
3408                                block_device_info=block_device_info,
3409                                bad_volumes_callback=bad_volumes_callback)
3410 
3411         except Exception as error:
3412             with excutils.save_and_reraise_exception() as ctxt:
3413                 exc_info = sys.exc_info()
3414                 # if the reboot failed but the VM is running don't
3415                 # put it into an error state
3416                 new_power_state = self._get_power_state(context, instance)
3417                 if new_power_state == power_state.RUNNING:
3418                     LOG.warning('Reboot failed but instance is running',
3419                                 instance=instance)
3420                     compute_utils.add_instance_fault_from_exc(context,
3421                             instance, error, exc_info)
3422                     self._notify_about_instance_usage(context, instance,
3423                             'reboot.error', fault=error)
3424                     tb = traceback.format_exc()
3425                     compute_utils.notify_about_instance_action(
3426                         context, instance, self.host,
3427                         action=fields.NotificationAction.REBOOT,
3428                         phase=fields.NotificationPhase.ERROR,
3429                         exception=error, bdms=bdms, tb=tb
3430                     )
3431                     ctxt.reraise = False
3432                 else:
3433                     LOG.error('Cannot reboot instance: %s', error,
3434                               instance=instance)
3435                     self._set_instance_obj_error_state(context, instance)
3436 
3437         if not new_power_state:
3438             new_power_state = self._get_power_state(context, instance)
3439         try:
3440             instance.power_state = new_power_state
3441             instance.vm_state = new_vm_state
3442             instance.task_state = None
3443             instance.save()
3444         except exception.InstanceNotFound:
3445             LOG.warning("Instance disappeared during reboot",
3446                         instance=instance)
3447 
3448         self._notify_about_instance_usage(context, instance, "reboot.end")
3449         compute_utils.notify_about_instance_action(
3450             context, instance, self.host,
3451             action=fields.NotificationAction.REBOOT,
3452             phase=fields.NotificationPhase.END,
3453             bdms=bdms
3454         )
3455 
3456     @delete_image_on_error
3457     def _do_snapshot_instance(self, context, image_id, instance):
3458         self._snapshot_instance(context, image_id, instance,
3459                                 task_states.IMAGE_BACKUP)
3460 
3461     @wrap_exception()
3462     @reverts_task_state
3463     @wrap_instance_event(prefix='compute')
3464     @wrap_instance_fault
3465     def backup_instance(self, context, image_id, instance, backup_type,
3466                         rotation):
3467         """Backup an instance on this host.
3468 
3469         :param backup_type: daily | weekly
3470         :param rotation: int representing how many backups to keep around
3471         """
3472         self._do_snapshot_instance(context, image_id, instance)
3473         self._rotate_backups(context, instance, backup_type, rotation)
3474 
3475     @wrap_exception()
3476     @reverts_task_state
3477     @wrap_instance_event(prefix='compute')
3478     @wrap_instance_fault
3479     @delete_image_on_error
3480     def snapshot_instance(self, context, image_id, instance):
3481         """Snapshot an instance on this host.
3482 
3483         :param context: security context
3484         :param image_id: glance.db.sqlalchemy.models.Image.Id
3485         :param instance: a nova.objects.instance.Instance object
3486         """
3487         # NOTE(dave-mcnally) the task state will already be set by the api
3488         # but if the compute manager has crashed/been restarted prior to the
3489         # request getting here the task state may have been cleared so we set
3490         # it again and things continue normally
3491         try:
3492             instance.task_state = task_states.IMAGE_SNAPSHOT
3493             instance.save(
3494                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3495         except exception.InstanceNotFound:
3496             # possibility instance no longer exists, no point in continuing
3497             LOG.debug("Instance not found, could not set state %s "
3498                       "for instance.",
3499                       task_states.IMAGE_SNAPSHOT, instance=instance)
3500             return
3501 
3502         except exception.UnexpectedDeletingTaskStateError:
3503             LOG.debug("Instance being deleted, snapshot cannot continue",
3504                       instance=instance)
3505             return
3506 
3507         self._snapshot_instance(context, image_id, instance,
3508                                 task_states.IMAGE_SNAPSHOT)
3509 
3510     def _snapshot_instance(self, context, image_id, instance,
3511                            expected_task_state):
3512         context = context.elevated()
3513 
3514         instance.power_state = self._get_power_state(context, instance)
3515         try:
3516             instance.save()
3517 
3518             LOG.info('instance snapshotting', instance=instance)
3519 
3520             if instance.power_state != power_state.RUNNING:
3521                 state = instance.power_state
3522                 running = power_state.RUNNING
3523                 LOG.warning('trying to snapshot a non-running instance: '
3524                             '(state: %(state)s expected: %(running)s)',
3525                             {'state': state, 'running': running},
3526                             instance=instance)
3527 
3528             self._notify_about_instance_usage(
3529                 context, instance, "snapshot.start")
3530             compute_utils.notify_about_instance_snapshot(context, instance,
3531                 self.host, phase=fields.NotificationPhase.START,
3532                 snapshot_image_id=image_id)
3533 
3534             def update_task_state(task_state,
3535                                   expected_state=expected_task_state):
3536                 instance.task_state = task_state
3537                 instance.save(expected_task_state=expected_state)
3538 
3539             with timeutils.StopWatch() as timer:
3540                 self.driver.snapshot(context, instance, image_id,
3541                                      update_task_state)
3542             LOG.info('Took %0.2f seconds to snapshot the instance on '
3543                      'the hypervisor.', timer.elapsed(), instance=instance)
3544 
3545             instance.task_state = None
3546             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3547 
3548             self._notify_about_instance_usage(context, instance,
3549                                               "snapshot.end")
3550             compute_utils.notify_about_instance_snapshot(context, instance,
3551                 self.host, phase=fields.NotificationPhase.END,
3552                 snapshot_image_id=image_id)
3553         except (exception.InstanceNotFound,
3554                 exception.UnexpectedDeletingTaskStateError):
3555             # the instance got deleted during the snapshot
3556             # Quickly bail out of here
3557             msg = 'Instance disappeared during snapshot'
3558             LOG.debug(msg, instance=instance)
3559             try:
3560                 image = self.image_api.get(context, image_id)
3561                 if image['status'] != 'active':
3562                     self.image_api.delete(context, image_id)
3563             except exception.ImageNotFound:
3564                 LOG.debug('Image not found during clean up %s', image_id)
3565             except Exception:
3566                 LOG.warning("Error while trying to clean up image %s",
3567                             image_id, instance=instance)
3568         except exception.ImageNotFound:
3569             instance.task_state = None
3570             instance.save()
3571             LOG.warning("Image not found during snapshot", instance=instance)
3572 
3573     def _post_interrupted_snapshot_cleanup(self, context, instance):
3574         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3575 
3576     @messaging.expected_exceptions(NotImplementedError)
3577     @wrap_exception()
3578     def volume_snapshot_create(self, context, instance, volume_id,
3579                                create_info):
3580         self.driver.volume_snapshot_create(context, instance, volume_id,
3581                                            create_info)
3582 
3583     @messaging.expected_exceptions(NotImplementedError)
3584     @wrap_exception()
3585     def volume_snapshot_delete(self, context, instance, volume_id,
3586                                snapshot_id, delete_info):
3587         self.driver.volume_snapshot_delete(context, instance, volume_id,
3588                                            snapshot_id, delete_info)
3589 
3590     @wrap_instance_fault
3591     def _rotate_backups(self, context, instance, backup_type, rotation):
3592         """Delete excess backups associated to an instance.
3593 
3594         Instances are allowed a fixed number of backups (the rotation number);
3595         this method deletes the oldest backups that exceed the rotation
3596         threshold.
3597 
3598         :param context: security context
3599         :param instance: Instance dict
3600         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3601         :param rotation: int representing how many backups to keep around;
3602             None if rotation shouldn't be used (as in the case of snapshots)
3603         """
3604         filters = {'property-image_type': 'backup',
3605                    'property-backup_type': backup_type,
3606                    'property-instance_uuid': instance.uuid}
3607 
3608         images = self.image_api.get_all(context, filters=filters,
3609                                         sort_key='created_at', sort_dir='desc')
3610         num_images = len(images)
3611         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3612                   {'num_images': num_images, 'rotation': rotation},
3613                   instance=instance)
3614 
3615         if num_images > rotation:
3616             # NOTE(sirp): this deletes all backups that exceed the rotation
3617             # limit
3618             excess = len(images) - rotation
3619             LOG.debug("Rotating out %d backups", excess,
3620                       instance=instance)
3621             for i in range(excess):
3622                 image = images.pop()
3623                 image_id = image['id']
3624                 LOG.debug("Deleting image %s", image_id,
3625                           instance=instance)
3626                 try:
3627                     self.image_api.delete(context, image_id)
3628                 except exception.ImageNotFound:
3629                     LOG.info("Failed to find image %(image_id)s to "
3630                              "delete", {'image_id': image_id},
3631                              instance=instance)
3632                 except (exception.ImageDeleteConflict, Exception) as exc:
3633                     LOG.info("Failed to delete image %(image_id)s during "
3634                              "deleting excess backups. "
3635                              "Continuing for next image.. %(exc)s",
3636                              {'image_id': image_id, 'exc': exc},
3637                              instance=instance)
3638 
3639     @wrap_exception()
3640     @reverts_task_state
3641     @wrap_instance_event(prefix='compute')
3642     @wrap_instance_fault
3643     def set_admin_password(self, context, instance, new_pass):
3644         """Set the root/admin password for an instance on this host.
3645 
3646         This is generally only called by API password resets after an
3647         image has been built.
3648 
3649         @param context: Nova auth context.
3650         @param instance: Nova instance object.
3651         @param new_pass: The admin password for the instance.
3652         """
3653 
3654         context = context.elevated()
3655         if new_pass is None:
3656             # Generate a random password
3657             new_pass = utils.generate_password()
3658 
3659         current_power_state = self._get_power_state(context, instance)
3660         expected_state = power_state.RUNNING
3661 
3662         if current_power_state != expected_state:
3663             instance.task_state = None
3664             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3665             _msg = _('instance %s is not running') % instance.uuid
3666             raise exception.InstancePasswordSetFailed(
3667                 instance=instance.uuid, reason=_msg)
3668 
3669         try:
3670             self.driver.set_admin_password(instance, new_pass)
3671             LOG.info("Admin password set", instance=instance)
3672             instance.task_state = None
3673             instance.save(
3674                 expected_task_state=task_states.UPDATING_PASSWORD)
3675         except exception.InstanceAgentNotEnabled:
3676             with excutils.save_and_reraise_exception():
3677                 LOG.debug('Guest agent is not enabled for the instance.',
3678                           instance=instance)
3679                 instance.task_state = None
3680                 instance.save(
3681                     expected_task_state=task_states.UPDATING_PASSWORD)
3682         except exception.SetAdminPasswdNotSupported:
3683             with excutils.save_and_reraise_exception():
3684                 LOG.info('set_admin_password is not supported '
3685                          'by this driver or guest instance.',
3686                          instance=instance)
3687                 instance.task_state = None
3688                 instance.save(
3689                     expected_task_state=task_states.UPDATING_PASSWORD)
3690         except NotImplementedError:
3691             LOG.warning('set_admin_password is not implemented '
3692                         'by this driver or guest instance.',
3693                         instance=instance)
3694             instance.task_state = None
3695             instance.save(
3696                 expected_task_state=task_states.UPDATING_PASSWORD)
3697             raise NotImplementedError(_('set_admin_password is not '
3698                                         'implemented by this driver or guest '
3699                                         'instance.'))
3700         except exception.UnexpectedTaskStateError:
3701             # interrupted by another (most likely delete) task
3702             # do not retry
3703             raise
3704         except Exception:
3705             # Catch all here because this could be anything.
3706             LOG.exception('set_admin_password failed', instance=instance)
3707             # We create a new exception here so that we won't
3708             # potentially reveal password information to the
3709             # API caller.  The real exception is logged above
3710             _msg = _('error setting admin password')
3711             raise exception.InstancePasswordSetFailed(
3712                 instance=instance.uuid, reason=_msg)
3713 
3714     @wrap_exception()
3715     @reverts_task_state
3716     @wrap_instance_fault
3717     def inject_file(self, context, path, file_contents, instance):
3718         """Write a file to the specified path in an instance on this host."""
3719         # NOTE(russellb) Remove this method, as well as the underlying virt
3720         # driver methods, when the compute rpc interface is bumped to 4.x
3721         # as it is no longer used.
3722         context = context.elevated()
3723         current_power_state = self._get_power_state(context, instance)
3724         expected_state = power_state.RUNNING
3725         if current_power_state != expected_state:
3726             LOG.warning('trying to inject a file into a non-running '
3727                         '(state: %(current_state)s expected: '
3728                         '%(expected_state)s)',
3729                         {'current_state': current_power_state,
3730                          'expected_state': expected_state},
3731                         instance=instance)
3732         LOG.info('injecting file to %s', path, instance=instance)
3733         self.driver.inject_file(instance, path, file_contents)
3734 
3735     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3736         """Determine what image should be used to boot the rescue VM."""
3737         # 1. If rescue_image_ref is passed in, use that for rescue.
3738         # 2. Else, use the base image associated with instance's current image.
3739         #       The idea here is to provide the customer with a rescue
3740         #       environment which they are familiar with.
3741         #       So, if they built their instance off of a Debian image,
3742         #       their rescue VM will also be Debian.
3743         # 3. As a last resort, use instance's current image.
3744         if not rescue_image_ref:
3745             system_meta = utils.instance_sys_meta(instance)
3746             rescue_image_ref = system_meta.get('image_base_image_ref')
3747 
3748         if not rescue_image_ref:
3749             LOG.warning('Unable to find a different image to use for '
3750                         'rescue VM, using instance\'s current image',
3751                         instance=instance)
3752             rescue_image_ref = instance.image_ref
3753 
3754         return objects.ImageMeta.from_image_ref(
3755             context, self.image_api, rescue_image_ref)
3756 
3757     @wrap_exception()
3758     @reverts_task_state
3759     @wrap_instance_event(prefix='compute')
3760     @wrap_instance_fault
3761     def rescue_instance(self, context, instance, rescue_password,
3762                         rescue_image_ref, clean_shutdown):
3763         context = context.elevated()
3764         LOG.info('Rescuing', instance=instance)
3765 
3766         admin_password = (rescue_password if rescue_password else
3767                       utils.generate_password())
3768 
3769         network_info = self.network_api.get_instance_nw_info(context, instance)
3770 
3771         rescue_image_meta = self._get_rescue_image(context, instance,
3772                                                    rescue_image_ref)
3773 
3774         extra_usage_info = {'rescue_image_name':
3775                             self._get_image_name(rescue_image_meta)}
3776         self._notify_about_instance_usage(context, instance,
3777                 "rescue.start", extra_usage_info=extra_usage_info,
3778                 network_info=network_info)
3779         compute_utils.notify_about_instance_rescue_action(
3780             context, instance, self.host, rescue_image_ref,
3781             phase=fields.NotificationPhase.START)
3782 
3783         try:
3784             self._power_off_instance(context, instance, clean_shutdown)
3785 
3786             self.driver.rescue(context, instance,
3787                                network_info,
3788                                rescue_image_meta, admin_password)
3789         except Exception as e:
3790             LOG.exception("Error trying to Rescue Instance",
3791                           instance=instance)
3792             self._set_instance_obj_error_state(context, instance)
3793             raise exception.InstanceNotRescuable(
3794                 instance_id=instance.uuid,
3795                 reason=_("Driver Error: %s") % e)
3796 
3797         compute_utils.notify_usage_exists(self.notifier, context, instance,
3798                                           self.host, current_period=True)
3799 
3800         instance.vm_state = vm_states.RESCUED
3801         instance.task_state = None
3802         instance.power_state = self._get_power_state(context, instance)
3803         instance.launched_at = timeutils.utcnow()
3804         instance.save(expected_task_state=task_states.RESCUING)
3805 
3806         self._notify_about_instance_usage(context, instance,
3807                 "rescue.end", extra_usage_info=extra_usage_info,
3808                 network_info=network_info)
3809         compute_utils.notify_about_instance_rescue_action(
3810             context, instance, self.host, rescue_image_ref,
3811             phase=fields.NotificationPhase.END)
3812 
3813     @wrap_exception()
3814     @reverts_task_state
3815     @wrap_instance_event(prefix='compute')
3816     @wrap_instance_fault
3817     def unrescue_instance(self, context, instance):
3818         context = context.elevated()
3819         LOG.info('Unrescuing', instance=instance)
3820 
3821         network_info = self.network_api.get_instance_nw_info(context, instance)
3822         self._notify_about_instance_usage(context, instance,
3823                 "unrescue.start", network_info=network_info)
3824         compute_utils.notify_about_instance_action(context, instance,
3825             self.host, action=fields.NotificationAction.UNRESCUE,
3826             phase=fields.NotificationPhase.START)
3827 
3828         with self._error_out_instance_on_exception(context, instance):
3829             self.driver.unrescue(instance,
3830                                  network_info)
3831 
3832         instance.vm_state = vm_states.ACTIVE
3833         instance.task_state = None
3834         instance.power_state = self._get_power_state(context, instance)
3835         instance.save(expected_task_state=task_states.UNRESCUING)
3836 
3837         self._notify_about_instance_usage(context,
3838                                           instance,
3839                                           "unrescue.end",
3840                                           network_info=network_info)
3841         compute_utils.notify_about_instance_action(context, instance,
3842             self.host, action=fields.NotificationAction.UNRESCUE,
3843             phase=fields.NotificationPhase.END)
3844 
3845     @wrap_exception()
3846     @wrap_instance_fault
3847     def change_instance_metadata(self, context, diff, instance):
3848         """Update the metadata published to the instance."""
3849         LOG.debug("Changing instance metadata according to %r",
3850                   diff, instance=instance)
3851         self.driver.change_instance_metadata(context, instance, diff)
3852 
3853     @wrap_exception()
3854     @wrap_instance_event(prefix='compute')
3855     @wrap_instance_fault
3856     def confirm_resize(self, context, instance, migration):
3857         """Confirms a migration/resize and deletes the 'old' instance.
3858 
3859         This is called from the API and runs on the source host.
3860 
3861         Nothing needs to happen on the destination host at this point since
3862         the instance is already running there. This routine just cleans up the
3863         source host.
3864         """
3865         @utils.synchronized(instance.uuid)
3866         def do_confirm_resize(context, instance, migration_id):
3867             # NOTE(wangpan): Get the migration status from db, if it has been
3868             #                confirmed, we do nothing and return here
3869             LOG.debug("Going to confirm migration %s", migration_id,
3870                       instance=instance)
3871             try:
3872                 # TODO(russellb) Why are we sending the migration object just
3873                 # to turn around and look it up from the db again?
3874                 migration = objects.Migration.get_by_id(
3875                                     context.elevated(), migration_id)
3876             except exception.MigrationNotFound:
3877                 LOG.error("Migration %s is not found during confirmation",
3878                           migration_id, instance=instance)
3879                 return
3880 
3881             if migration.status == 'confirmed':
3882                 LOG.info("Migration %s is already confirmed",
3883                          migration_id, instance=instance)
3884                 return
3885             elif migration.status not in ('finished', 'confirming'):
3886                 LOG.warning("Unexpected confirmation status '%(status)s' "
3887                             "of migration %(id)s, exit confirmation process",
3888                             {"status": migration.status, "id": migration_id},
3889                             instance=instance)
3890                 return
3891 
3892             # NOTE(wangpan): Get the instance from db, if it has been
3893             #                deleted, we do nothing and return here
3894             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3895             try:
3896                 instance = objects.Instance.get_by_uuid(
3897                         context, instance.uuid,
3898                         expected_attrs=expected_attrs)
3899             except exception.InstanceNotFound:
3900                 LOG.info("Instance is not found during confirmation",
3901                          instance=instance)
3902                 return
3903 
3904             self._confirm_resize(context, instance, migration=migration)
3905 
3906         do_confirm_resize(context, instance, migration.id)
3907 
3908     def _confirm_resize(self, context, instance, migration=None):
3909         """Destroys the source instance."""
3910         self._notify_about_instance_usage(context, instance,
3911                                           "resize.confirm.start")
3912         compute_utils.notify_about_instance_action(context, instance,
3913             self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3914             phase=fields.NotificationPhase.START)
3915 
3916         with self._error_out_instance_on_exception(context, instance):
3917             # NOTE(danms): delete stashed migration information
3918             old_instance_type = instance.old_flavor
3919             instance.old_flavor = None
3920             instance.new_flavor = None
3921             instance.system_metadata.pop('old_vm_state', None)
3922             instance.save()
3923 
3924             # NOTE(tr3buchet): tear down networks on source host
3925             self.network_api.setup_networks_on_host(context, instance,
3926                                migration.source_compute, teardown=True)
3927 
3928             network_info = self.network_api.get_instance_nw_info(context,
3929                                                                  instance)
3930             # TODO(mriedem): Get BDMs here and pass them to the driver.
3931             self.driver.confirm_migration(context, migration, instance,
3932                                           network_info)
3933 
3934             migration.status = 'confirmed'
3935             with migration.obj_as_admin():
3936                 migration.save()
3937 
3938             self.rt.drop_move_claim(context, instance, migration.source_node,
3939                                     old_instance_type, prefix='old_')
3940             self._delete_allocation_after_move(context, instance, migration)
3941             instance.drop_migration_context()
3942 
3943             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3944             # might have manually powered up the instance to confirm the
3945             # resize/migrate, so we need to check the current power state
3946             # on the instance and set the vm_state appropriately. We default
3947             # to ACTIVE because if the power state is not SHUTDOWN, we
3948             # assume _sync_instance_power_state will clean it up.
3949             p_state = instance.power_state
3950             vm_state = None
3951             if p_state == power_state.SHUTDOWN:
3952                 vm_state = vm_states.STOPPED
3953                 LOG.debug("Resized/migrated instance is powered off. "
3954                           "Setting vm_state to '%s'.", vm_state,
3955                           instance=instance)
3956             else:
3957                 vm_state = vm_states.ACTIVE
3958 
3959             instance.vm_state = vm_state
3960             instance.task_state = None
3961             instance.save(expected_task_state=[None, task_states.DELETING,
3962                                                task_states.SOFT_DELETING])
3963 
3964             self._notify_about_instance_usage(
3965                 context, instance, "resize.confirm.end",
3966                 network_info=network_info)
3967             compute_utils.notify_about_instance_action(context, instance,
3968                    self.host, action=fields.NotificationAction.RESIZE_CONFIRM,
3969                    phase=fields.NotificationPhase.END)
3970 
3971     def _delete_allocation_after_move(self, context, instance, migration):
3972         """Deletes resource allocations held by the migration record against
3973         the source compute node resource provider after a confirmed cold /
3974         successful live migration.
3975         """
3976         try:
3977             # NOTE(danms): We're finishing on the source node, so try
3978             # to delete the allocation based on the migration uuid
3979             self.reportclient.delete_allocation_for_instance(
3980                 context, migration.uuid)
3981         except exception.AllocationDeleteFailed:
3982             LOG.error('Deleting allocation in placement for migration '
3983                       '%(migration_uuid)s failed. The instance '
3984                       '%(instance_uuid)s will be put to ERROR state '
3985                       'but the allocation held by the migration is '
3986                       'leaked.',
3987                       {'instance_uuid': instance.uuid,
3988                        'migration_uuid': migration.uuid})
3989             raise
3990 
3991     @wrap_exception()
3992     @reverts_task_state
3993     @wrap_instance_event(prefix='compute')
3994     @errors_out_migration
3995     @wrap_instance_fault
3996     def revert_resize(self, context, instance, migration):
3997         """Destroys the new instance on the destination machine.
3998 
3999         Reverts the model changes, and powers on the old instance on the
4000         source machine.
4001 
4002         """
4003         # NOTE(comstud): A revert_resize is essentially a resize back to
4004         # the old size, so we need to send a usage event here.
4005         compute_utils.notify_usage_exists(self.notifier, context, instance,
4006                                           self.host, current_period=True)
4007 
4008         with self._error_out_instance_on_exception(context, instance):
4009             # NOTE(tr3buchet): tear down networks on destination host
4010             self.network_api.setup_networks_on_host(context, instance,
4011                                                     teardown=True)
4012 
4013             migration_p = obj_base.obj_to_primitive(migration)
4014             self.network_api.migrate_instance_start(context,
4015                                                     instance,
4016                                                     migration_p)
4017 
4018             network_info = self.network_api.get_instance_nw_info(context,
4019                                                                  instance)
4020             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4021                     context, instance.uuid)
4022             block_device_info = self._get_instance_block_device_info(
4023                                 context, instance, bdms=bdms)
4024 
4025             destroy_disks = not self._is_instance_storage_shared(
4026                 context, instance, host=migration.source_compute)
4027             self.driver.destroy(context, instance, network_info,
4028                                 block_device_info, destroy_disks)
4029 
4030             self._terminate_volume_connections(context, instance, bdms)
4031 
4032             migration.status = 'reverted'
4033             with migration.obj_as_admin():
4034                 migration.save()
4035 
4036             # NOTE(ndipanov): We need to do this here because dropping the
4037             # claim means we lose the migration_context data. We really should
4038             # fix this by moving the drop_move_claim call to the
4039             # finish_revert_resize method as this is racy (revert is dropped,
4040             # but instance resources will be tracked with the new flavor until
4041             # it gets rolled back in finish_revert_resize, which is
4042             # potentially wrong for a period of time).
4043             instance.revert_migration_context()
4044             instance.save()
4045 
4046             self.rt.drop_move_claim(context, instance, instance.node)
4047 
4048             # RPC cast back to the source host to finish the revert there.
4049             self.compute_rpcapi.finish_revert_resize(context, instance,
4050                     migration, migration.source_compute)
4051 
4052     @wrap_exception()
4053     @reverts_task_state
4054     @wrap_instance_event(prefix='compute')
4055     @errors_out_migration
4056     @wrap_instance_fault
4057     def finish_revert_resize(self, context, instance, migration):
4058         """Finishes the second half of reverting a resize on the source host.
4059 
4060         Bring the original source instance state back (active/shutoff) and
4061         revert the resized attributes in the database.
4062 
4063         """
4064         with self._error_out_instance_on_exception(context, instance):
4065             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4066                 context, instance.uuid)
4067             self._notify_about_instance_usage(
4068                     context, instance, "resize.revert.start")
4069             compute_utils.notify_about_instance_action(context, instance,
4070                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4071                     phase=fields.NotificationPhase.START, bdms=bdms)
4072 
4073             # NOTE(mriedem): delete stashed old_vm_state information; we
4074             # default to ACTIVE for backwards compatibility if old_vm_state
4075             # is not set
4076             old_vm_state = instance.system_metadata.pop('old_vm_state',
4077                                                         vm_states.ACTIVE)
4078 
4079             self._set_instance_info(instance, instance.old_flavor)
4080             instance.old_flavor = None
4081             instance.new_flavor = None
4082             instance.host = migration.source_compute
4083             instance.node = migration.source_node
4084             instance.save()
4085 
4086             try:
4087                 self._revert_allocation(context, instance, migration)
4088             except exception.AllocationMoveFailed:
4089                 LOG.error('Reverting allocation in placement for migration '
4090                           '%(migration_uuid)s failed. The instance '
4091                           '%(instance_uuid)s will be put into ERROR state but '
4092                           'the allocation held by the migration is leaked.',
4093                           {'instance_uuid': instance.uuid,
4094                            'migration_uuid': migration.uuid})
4095                 raise
4096 
4097             self.network_api.setup_networks_on_host(context, instance,
4098                                                     migration.source_compute)
4099             migration_p = obj_base.obj_to_primitive(migration)
4100             # NOTE(hanrong): we need to change migration_p['dest_compute'] to
4101             # source host temporarily. "network_api.migrate_instance_finish"
4102             # will setup the network for the instance on the destination host.
4103             # For revert resize, the instance will back to the source host, the
4104             # setup of the network for instance should be on the source host.
4105             # So set the migration_p['dest_compute'] to source host at here.
4106             migration_p['dest_compute'] = migration.source_compute
4107             self.network_api.migrate_instance_finish(context,
4108                                                      instance,
4109                                                      migration_p)
4110             network_info = self.network_api.get_instance_nw_info(context,
4111                                                                  instance)
4112 
4113             # revert_resize deleted any volume attachments for the instance
4114             # and created new ones to be used on this host, but we
4115             # have to update those attachments with the host connector so the
4116             # BDM.connection_info will get set in the call to
4117             # _get_instance_block_device_info below with refresh_conn_info=True
4118             # and then the volumes can be re-connected via the driver on this
4119             # host.
4120             self._update_volume_attachments(context, instance, bdms)
4121 
4122             block_device_info = self._get_instance_block_device_info(
4123                     context, instance, refresh_conn_info=True, bdms=bdms)
4124 
4125             power_on = old_vm_state != vm_states.STOPPED
4126             self.driver.finish_revert_migration(context, instance,
4127                                        network_info,
4128                                        block_device_info, power_on)
4129 
4130             instance.drop_migration_context()
4131             instance.launched_at = timeutils.utcnow()
4132             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
4133 
4134             # Complete any volume attachments so the volumes are in-use.
4135             self._complete_volume_attachments(context, bdms)
4136 
4137             # if the original vm state was STOPPED, set it back to STOPPED
4138             LOG.info("Updating instance to original state: '%s'",
4139                      old_vm_state, instance=instance)
4140             if power_on:
4141                 instance.vm_state = vm_states.ACTIVE
4142                 instance.task_state = None
4143                 instance.save()
4144             else:
4145                 instance.task_state = task_states.POWERING_OFF
4146                 instance.save()
4147                 self.stop_instance(context, instance=instance,
4148                                    clean_shutdown=True)
4149 
4150             self._notify_about_instance_usage(
4151                     context, instance, "resize.revert.end")
4152             compute_utils.notify_about_instance_action(context, instance,
4153                 self.host, action=fields.NotificationAction.RESIZE_REVERT,
4154                     phase=fields.NotificationPhase.END, bdms=bdms)
4155 
4156     def _revert_allocation(self, context, instance, migration):
4157         """Revert an allocation that is held by migration to our instance."""
4158 
4159         # Fetch the original allocation that the instance had on the source
4160         # node, which are now held by the migration
4161         orig_alloc = self.reportclient.get_allocations_for_consumer(
4162             context, migration.uuid)
4163         if not orig_alloc:
4164             LOG.error('Did not find resource allocations for migration '
4165                       '%s on source node %s. Unable to revert source node '
4166                       'allocations back to the instance.',
4167                       migration.uuid, migration.source_node, instance=instance)
4168             return False
4169 
4170         if len(orig_alloc) > 1:
4171             # NOTE(danms): This may change later if we have other allocations
4172             # against other providers that need to be held by the migration
4173             # as well. Perhaps something like shared storage resources that
4174             # will actually be duplicated during a resize type operation.
4175             LOG.error('Migration %(mig)s has allocations against '
4176                       'more than one provider %(rps)s. This should not be '
4177                       'possible, but reverting it anyway.',
4178                       {'mig': migration.uuid,
4179                        'rps': ','.join(orig_alloc.keys())},
4180                       instance=instance)
4181 
4182         # We only have a claim against one provider, it is the source node
4183         cn_uuid = list(orig_alloc.keys())[0]
4184 
4185         # FIXME(danms): This method is flawed in that it asssumes allocations
4186         # against only one provider. So, this may overwite allocations against
4187         # a shared provider, if we had one.
4188         LOG.info('Swapping old allocation on %(node)s held by migration '
4189                  '%(mig)s for instance',
4190                  {'node': cn_uuid, 'mig': migration.uuid},
4191                  instance=instance)
4192         # TODO(cdent): Should we be doing anything with return values here?
4193         self.reportclient.move_allocations(context, migration.uuid,
4194                                            instance.uuid)
4195         return True
4196 
4197     def _prep_resize(self, context, image, instance, instance_type,
4198                      filter_properties, node, migration, clean_shutdown=True):
4199 
4200         if not filter_properties:
4201             filter_properties = {}
4202 
4203         if not instance.host:
4204             self._set_instance_obj_error_state(context, instance)
4205             msg = _('Instance has no source host')
4206             raise exception.MigrationError(reason=msg)
4207 
4208         same_host = instance.host == self.host
4209         # if the flavor IDs match, it's migrate; otherwise resize
4210         if same_host and instance_type.id == instance['instance_type_id']:
4211             # check driver whether support migrate to same host
4212             if not self.driver.capabilities.get(
4213                     'supports_migrate_to_same_host', False):
4214                 raise exception.UnableToMigrateToSelf(
4215                     instance_id=instance.uuid, host=self.host)
4216 
4217         # NOTE(danms): Stash the new instance_type to avoid having to
4218         # look it up in the database later
4219         instance.new_flavor = instance_type
4220         # NOTE(mriedem): Stash the old vm_state so we can set the
4221         # resized/reverted instance back to the same state later.
4222         vm_state = instance.vm_state
4223         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
4224         instance.system_metadata['old_vm_state'] = vm_state
4225         instance.save()
4226 
4227         limits = filter_properties.get('limits', {})
4228         with self.rt.resize_claim(context, instance, instance_type, node,
4229                                   migration, image_meta=image,
4230                                   limits=limits) as claim:
4231             LOG.info('Migrating', instance=instance)
4232             # RPC cast to the source host to start the actual resize/migration.
4233             self.compute_rpcapi.resize_instance(
4234                     context, instance, claim.migration, image,
4235                     instance_type, clean_shutdown)
4236 
4237     def _send_prep_resize_notifications(
4238             self, context, instance, phase, flavor):
4239         """Send "resize.prep.*" notifications.
4240 
4241         :param context: nova auth request context
4242         :param instance: The instance being resized
4243         :param phase: The phase of the action (NotificationPhase enum)
4244         :param flavor: The (new) flavor for the resize (same as existing
4245             instance.flavor for a cold migration)
4246         """
4247         # Only send notify_usage_exists if it's the "start" phase.
4248         if phase == fields.NotificationPhase.START:
4249             compute_utils.notify_usage_exists(
4250                 self.notifier, context, instance, self.host,
4251                 current_period=True)
4252 
4253         # Send extra usage info about the flavor if it's the "end" phase for
4254         # the legacy unversioned notification.
4255         extra_usage_info = None
4256         if phase == fields.NotificationPhase.END:
4257             extra_usage_info = dict(
4258                 new_instance_type=flavor.name,
4259                 new_instance_type_id=flavor.id)
4260         self._notify_about_instance_usage(
4261             context, instance, "resize.prep.%s" % phase,
4262             extra_usage_info=extra_usage_info)
4263 
4264         # Send the versioned notification.
4265         compute_utils.notify_about_resize_prep_instance(
4266             context, instance, self.host, phase, flavor)
4267 
4268     @wrap_exception()
4269     @reverts_task_state
4270     @wrap_instance_event(prefix='compute')
4271     @wrap_instance_fault
4272     def prep_resize(self, context, image, instance, instance_type,
4273                     request_spec, filter_properties, node,
4274                     clean_shutdown, migration, host_list):
4275         """Initiates the process of moving a running instance to another host.
4276 
4277         Possibly changes the VCPU, RAM and disk size in the process.
4278 
4279         This is initiated from conductor and runs on the destination host.
4280 
4281         The main purpose of this method is performing some checks on the
4282         destination host and making a claim for resources. If the claim fails
4283         then a reschedule to another host may be attempted which involves
4284         calling back to conductor to start the process over again.
4285         """
4286         if node is None:
4287             node = self._get_nodename(instance, refresh=True)
4288 
4289         with self._error_out_instance_on_exception(context, instance), \
4290                  errors_out_migration_ctxt(migration):
4291             self._send_prep_resize_notifications(
4292                 context, instance, fields.NotificationPhase.START,
4293                 instance_type)
4294             try:
4295                 self._prep_resize(context, image, instance,
4296                                   instance_type, filter_properties,
4297                                   node, migration, clean_shutdown)
4298             except Exception:
4299                 # Since we hit a failure, we're either rescheduling or dead
4300                 # and either way we need to cleanup any allocations created
4301                 # by the scheduler for the destination node.
4302                 self._revert_allocation(context, instance, migration)
4303                 # try to re-schedule the resize elsewhere:
4304                 exc_info = sys.exc_info()
4305                 self._reschedule_resize_or_reraise(context, instance,
4306                         exc_info, instance_type, request_spec,
4307                         filter_properties, host_list)
4308             finally:
4309                 self._send_prep_resize_notifications(
4310                     context, instance, fields.NotificationPhase.END,
4311                     instance_type)
4312 
4313     def _reschedule_resize_or_reraise(self, context, instance, exc_info,
4314             instance_type, request_spec, filter_properties, host_list):
4315         """Try to re-schedule the resize or re-raise the original error to
4316         error out the instance.
4317         """
4318         if not filter_properties:
4319             filter_properties = {}
4320 
4321         rescheduled = False
4322         instance_uuid = instance.uuid
4323 
4324         try:
4325             reschedule_method = self.compute_task_api.resize_instance
4326             scheduler_hint = dict(filter_properties=filter_properties)
4327             method_args = (instance, None, scheduler_hint, instance_type)
4328             task_state = task_states.RESIZE_PREP
4329 
4330             rescheduled = self._reschedule(context, request_spec,
4331                     filter_properties, instance, reschedule_method,
4332                     method_args, task_state, exc_info, host_list=host_list)
4333         except Exception as error:
4334             rescheduled = False
4335             LOG.exception("Error trying to reschedule",
4336                           instance_uuid=instance_uuid)
4337             compute_utils.add_instance_fault_from_exc(context,
4338                     instance, error,
4339                     exc_info=sys.exc_info())
4340             self._notify_about_instance_usage(context, instance,
4341                     'resize.error', fault=error)
4342             compute_utils.notify_about_instance_action(
4343                 context, instance, self.host,
4344                 action=fields.NotificationAction.RESIZE,
4345                 phase=fields.NotificationPhase.ERROR,
4346                 exception=error,
4347                 tb=','.join(traceback.format_exception(*exc_info)))
4348         if rescheduled:
4349             self._log_original_error(exc_info, instance_uuid)
4350             compute_utils.add_instance_fault_from_exc(context,
4351                     instance, exc_info[1], exc_info=exc_info)
4352             self._notify_about_instance_usage(context, instance,
4353                     'resize.error', fault=exc_info[1])
4354             compute_utils.notify_about_instance_action(
4355                 context, instance, self.host,
4356                 action=fields.NotificationAction.RESIZE,
4357                 phase=fields.NotificationPhase.ERROR,
4358                 exception=exc_info[1],
4359                 tb=','.join(traceback.format_exception(*exc_info)))
4360         else:
4361             # not re-scheduling
4362             six.reraise(*exc_info)
4363 
4364     @wrap_exception()
4365     @reverts_task_state
4366     @wrap_instance_event(prefix='compute')
4367     @wrap_instance_fault
4368     def resize_instance(self, context, instance, image,
4369                         migration, instance_type, clean_shutdown):
4370         """Starts the migration of a running instance to another host.
4371 
4372         This is initiated from the destination host's ``prep_resize`` routine
4373         and runs on the source host.
4374         """
4375         try:
4376             self._resize_instance(context, instance, image, migration,
4377                                   instance_type, clean_shutdown)
4378         except Exception:
4379             with excutils.save_and_reraise_exception():
4380                 self._revert_allocation(context, instance, migration)
4381 
4382     def _resize_instance(self, context, instance, image,
4383                          migration, instance_type, clean_shutdown):
4384         with self._error_out_instance_on_exception(context, instance), \
4385              errors_out_migration_ctxt(migration):
4386             network_info = self.network_api.get_instance_nw_info(context,
4387                                                                  instance)
4388 
4389             migration.status = 'migrating'
4390             with migration.obj_as_admin():
4391                 migration.save()
4392 
4393             instance.task_state = task_states.RESIZE_MIGRATING
4394             instance.save(expected_task_state=task_states.RESIZE_PREP)
4395 
4396             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4397                     context, instance.uuid)
4398             self._send_resize_instance_notifications(
4399                 context, instance, bdms, network_info,
4400                 fields.NotificationPhase.START)
4401 
4402             block_device_info = self._get_instance_block_device_info(
4403                                 context, instance, bdms=bdms)
4404 
4405             timeout, retry_interval = self._get_power_off_values(context,
4406                                             instance, clean_shutdown)
4407             disk_info = self.driver.migrate_disk_and_power_off(
4408                     context, instance, migration.dest_host,
4409                     instance_type, network_info,
4410                     block_device_info,
4411                     timeout, retry_interval)
4412 
4413             self._terminate_volume_connections(context, instance, bdms)
4414 
4415             migration_p = obj_base.obj_to_primitive(migration)
4416             self.network_api.migrate_instance_start(context,
4417                                                     instance,
4418                                                     migration_p)
4419 
4420             migration.status = 'post-migrating'
4421             with migration.obj_as_admin():
4422                 migration.save()
4423 
4424             instance.host = migration.dest_compute
4425             instance.node = migration.dest_node
4426             instance.task_state = task_states.RESIZE_MIGRATED
4427             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
4428 
4429             # RPC cast to the destination host to finish the resize/migration.
4430             self.compute_rpcapi.finish_resize(context, instance,
4431                     migration, image, disk_info, migration.dest_compute)
4432 
4433         self._send_resize_instance_notifications(
4434             context, instance, bdms, network_info,
4435             fields.NotificationPhase.END)
4436         self.instance_events.clear_events_for_instance(instance)
4437 
4438     def _send_resize_instance_notifications(
4439             self, context, instance, bdms, network_info, phase):
4440         """Send "resize.(start|end)" notifications.
4441 
4442         :param context: nova auth request context
4443         :param instance: The instance being resized
4444         :param bdms: BlockDeviceMappingList for the BDMs associated with the
4445             instance
4446         :param network_info: NetworkInfo for the instance info cache of ports
4447         :param phase: The phase of the action (NotificationPhase enum, either
4448             ``start`` or ``end``)
4449         """
4450         action = fields.NotificationAction.RESIZE
4451         # Send the legacy unversioned notification.
4452         self._notify_about_instance_usage(
4453             context, instance, "%s.%s" % (action, phase),
4454             network_info=network_info)
4455         # Send the versioned notification.
4456         compute_utils.notify_about_instance_action(
4457             context, instance, self.host, action=action, phase=phase,
4458             bdms=bdms)
4459 
4460     def _terminate_volume_connections(self, context, instance, bdms):
4461         connector = None
4462         for bdm in bdms:
4463             if bdm.is_volume:
4464                 if bdm.attachment_id:
4465                     # NOTE(jdg): So here's the thing, the idea behind the new
4466                     # attach API's was to have a new code fork/path that we
4467                     # followed, we're not going to do that so we have to do
4468                     # some extra work in here to make it *behave* just like the
4469                     # old code. Cinder doesn't allow disconnect/reconnect (you
4470                     # just delete the attachment and get a new one)
4471                     # attachments in the new attach code so we have to do
4472                     # a delete and create without a connector (reserve),
4473                     # in other words, beware
4474                     attachment_id = self.volume_api.attachment_create(
4475                         context, bdm.volume_id, instance.uuid)['id']
4476                     self.volume_api.attachment_delete(context,
4477                                                       bdm.attachment_id)
4478                     bdm.attachment_id = attachment_id
4479                     bdm.save()
4480 
4481                 else:
4482                     if connector is None:
4483                         connector = self.driver.get_volume_connector(instance)
4484                     self.volume_api.terminate_connection(context,
4485                                                          bdm.volume_id,
4486                                                          connector)
4487 
4488     @staticmethod
4489     def _set_instance_info(instance, instance_type):
4490         instance.instance_type_id = instance_type.id
4491         instance.memory_mb = instance_type.memory_mb
4492         instance.vcpus = instance_type.vcpus
4493         instance.root_gb = instance_type.root_gb
4494         instance.ephemeral_gb = instance_type.ephemeral_gb
4495         instance.flavor = instance_type
4496 
4497     def _update_volume_attachments(self, context, instance, bdms):
4498         """Updates volume attachments using the virt driver host connector.
4499 
4500         :param context: nova.context.RequestContext - user request context
4501         :param instance: nova.objects.Instance
4502         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4503                      device mappings for the given instance
4504         """
4505         if bdms:
4506             connector = None
4507             for bdm in bdms:
4508                 if bdm.is_volume and bdm.attachment_id:
4509                     if connector is None:
4510                         connector = self.driver.get_volume_connector(instance)
4511                     self.volume_api.attachment_update(
4512                         context, bdm.attachment_id, connector, bdm.device_name)
4513 
4514     def _complete_volume_attachments(self, context, bdms):
4515         """Completes volume attachments for the instance
4516 
4517         :param context: nova.context.RequestContext - user request context
4518         :param bdms: nova.objects.BlockDeviceMappingList - the list of block
4519                      device mappings for the given instance
4520         """
4521         if bdms:
4522             for bdm in bdms:
4523                 if bdm.is_volume and bdm.attachment_id:
4524                     self.volume_api.attachment_complete(
4525                         context, bdm.attachment_id)
4526 
4527     def _finish_resize(self, context, instance, migration, disk_info,
4528                        image_meta, bdms):
4529         resize_instance = False
4530         old_instance_type_id = migration['old_instance_type_id']
4531         new_instance_type_id = migration['new_instance_type_id']
4532         old_instance_type = instance.get_flavor()
4533         # NOTE(mriedem): Get the old_vm_state so we know if we should
4534         # power on the instance. If old_vm_state is not set we need to default
4535         # to ACTIVE for backwards compatibility
4536         old_vm_state = instance.system_metadata.get('old_vm_state',
4537                                                     vm_states.ACTIVE)
4538         instance.old_flavor = old_instance_type
4539 
4540         if old_instance_type_id != new_instance_type_id:
4541             instance_type = instance.get_flavor('new')
4542             self._set_instance_info(instance, instance_type)
4543             for key in ('root_gb', 'swap', 'ephemeral_gb'):
4544                 if old_instance_type[key] != instance_type[key]:
4545                     resize_instance = True
4546                     break
4547         instance.apply_migration_context()
4548 
4549         # NOTE(tr3buchet): setup networks on destination host
4550         self.network_api.setup_networks_on_host(context, instance,
4551                                                 migration['dest_compute'])
4552 
4553         migration_p = obj_base.obj_to_primitive(migration)
4554         self.network_api.migrate_instance_finish(context,
4555                                                  instance,
4556                                                  migration_p)
4557 
4558         network_info = self.network_api.get_instance_nw_info(context, instance)
4559 
4560         instance.task_state = task_states.RESIZE_FINISH
4561         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
4562 
4563         self._notify_about_instance_usage(
4564             context, instance, "finish_resize.start",
4565             network_info=network_info)
4566         compute_utils.notify_about_instance_action(context, instance,
4567                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4568                phase=fields.NotificationPhase.START, bdms=bdms)
4569 
4570         # We need to update any volume attachments using the destination
4571         # host connector so that we can update the BDM.connection_info
4572         # before calling driver.finish_migration otherwise the driver
4573         # won't know how to connect the volumes to this host.
4574         # Note that _get_instance_block_device_info with
4575         # refresh_conn_info=True will update the BDM.connection_info value
4576         # in the database so we must do this before calling that method.
4577         self._update_volume_attachments(context, instance, bdms)
4578 
4579         block_device_info = self._get_instance_block_device_info(
4580             context, instance, refresh_conn_info=True, bdms=bdms)
4581 
4582         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
4583         # automatically power on the instance after it's migrated
4584         power_on = old_vm_state != vm_states.STOPPED
4585 
4586         try:
4587             self.driver.finish_migration(context, migration, instance,
4588                                          disk_info,
4589                                          network_info,
4590                                          image_meta, resize_instance,
4591                                          block_device_info, power_on)
4592         except Exception:
4593             with excutils.save_and_reraise_exception():
4594                 if old_instance_type_id != new_instance_type_id:
4595                     self._set_instance_info(instance,
4596                                             old_instance_type)
4597 
4598         # Now complete any volume attachments that were previously updated.
4599         self._complete_volume_attachments(context, bdms)
4600 
4601         migration.status = 'finished'
4602         with migration.obj_as_admin():
4603             migration.save()
4604 
4605         instance.vm_state = vm_states.RESIZED
4606         instance.task_state = None
4607         instance.launched_at = timeutils.utcnow()
4608         instance.save(expected_task_state=task_states.RESIZE_FINISH)
4609 
4610         return network_info
4611 
4612     @wrap_exception()
4613     @reverts_task_state
4614     @wrap_instance_event(prefix='compute')
4615     @wrap_instance_fault
4616     def finish_resize(self, context, disk_info, image, instance,
4617                       migration):
4618         """Completes the migration process.
4619 
4620         Sets up the newly transferred disk and turns on the instance at its
4621         new host machine.
4622 
4623         """
4624         try:
4625             self._finish_resize_helper(context, disk_info, image, instance,
4626                                        migration)
4627         except Exception:
4628             with excutils.save_and_reraise_exception():
4629                 self._revert_allocation(context, instance, migration)
4630 
4631     def _finish_resize_helper(self, context, disk_info, image, instance,
4632                               migration):
4633         """Completes the migration process.
4634 
4635         The caller must revert the instance's allocations if the migration
4636         process failed.
4637         """
4638         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4639             context, instance.uuid)
4640 
4641         with self._error_out_instance_on_exception(context, instance), \
4642              errors_out_migration_ctxt(migration):
4643             image_meta = objects.ImageMeta.from_dict(image)
4644             network_info = self._finish_resize(context, instance, migration,
4645                                                disk_info, image_meta, bdms)
4646 
4647         # TODO(melwitt): We should clean up instance console tokens here. The
4648         # instance is on a new host and will need to establish a new console
4649         # connection.
4650         self._update_scheduler_instance_info(context, instance)
4651         self._notify_about_instance_usage(
4652             context, instance, "finish_resize.end",
4653             network_info=network_info)
4654         compute_utils.notify_about_instance_action(context, instance,
4655                self.host, action=fields.NotificationAction.RESIZE_FINISH,
4656                phase=fields.NotificationPhase.END, bdms=bdms)
4657 
4658     @wrap_exception()
4659     @wrap_instance_fault
4660     def add_fixed_ip_to_instance(self, context, network_id, instance):
4661         """Calls network_api to add new fixed_ip to instance
4662         then injects the new network info and resets instance networking.
4663 
4664         """
4665         self._notify_about_instance_usage(
4666                 context, instance, "create_ip.start")
4667 
4668         network_info = self.network_api.add_fixed_ip_to_instance(context,
4669                                                                  instance,
4670                                                                  network_id)
4671         self._inject_network_info(context, instance, network_info)
4672         self.reset_network(context, instance)
4673 
4674         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4675         instance.updated_at = timeutils.utcnow()
4676         instance.save()
4677 
4678         self._notify_about_instance_usage(
4679             context, instance, "create_ip.end", network_info=network_info)
4680 
4681     @wrap_exception()
4682     @wrap_instance_fault
4683     def remove_fixed_ip_from_instance(self, context, address, instance):
4684         """Calls network_api to remove existing fixed_ip from instance
4685         by injecting the altered network info and resetting
4686         instance networking.
4687         """
4688         self._notify_about_instance_usage(
4689                 context, instance, "delete_ip.start")
4690 
4691         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4692                                                                       instance,
4693                                                                       address)
4694         self._inject_network_info(context, instance, network_info)
4695         self.reset_network(context, instance)
4696 
4697         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4698         instance.updated_at = timeutils.utcnow()
4699         instance.save()
4700 
4701         self._notify_about_instance_usage(
4702             context, instance, "delete_ip.end", network_info=network_info)
4703 
4704     @wrap_exception()
4705     @reverts_task_state
4706     @wrap_instance_event(prefix='compute')
4707     @wrap_instance_fault
4708     def pause_instance(self, context, instance):
4709         """Pause an instance on this host."""
4710         context = context.elevated()
4711         LOG.info('Pausing', instance=instance)
4712         self._notify_about_instance_usage(context, instance, 'pause.start')
4713         compute_utils.notify_about_instance_action(context, instance,
4714                self.host, action=fields.NotificationAction.PAUSE,
4715                phase=fields.NotificationPhase.START)
4716         self.driver.pause(instance)
4717         instance.power_state = self._get_power_state(context, instance)
4718         instance.vm_state = vm_states.PAUSED
4719         instance.task_state = None
4720         instance.save(expected_task_state=task_states.PAUSING)
4721         self._notify_about_instance_usage(context, instance, 'pause.end')
4722         compute_utils.notify_about_instance_action(context, instance,
4723                self.host, action=fields.NotificationAction.PAUSE,
4724                phase=fields.NotificationPhase.END)
4725 
4726     @wrap_exception()
4727     @reverts_task_state
4728     @wrap_instance_event(prefix='compute')
4729     @wrap_instance_fault
4730     def unpause_instance(self, context, instance):
4731         """Unpause a paused instance on this host."""
4732         context = context.elevated()
4733         LOG.info('Unpausing', instance=instance)
4734         self._notify_about_instance_usage(context, instance, 'unpause.start')
4735         compute_utils.notify_about_instance_action(context, instance,
4736             self.host, action=fields.NotificationAction.UNPAUSE,
4737             phase=fields.NotificationPhase.START)
4738         self.driver.unpause(instance)
4739         instance.power_state = self._get_power_state(context, instance)
4740         instance.vm_state = vm_states.ACTIVE
4741         instance.task_state = None
4742         instance.save(expected_task_state=task_states.UNPAUSING)
4743         self._notify_about_instance_usage(context, instance, 'unpause.end')
4744         compute_utils.notify_about_instance_action(context, instance,
4745             self.host, action=fields.NotificationAction.UNPAUSE,
4746             phase=fields.NotificationPhase.END)
4747 
4748     @wrap_exception()
4749     def host_power_action(self, context, action):
4750         """Reboots, shuts down or powers up the host."""
4751         return self.driver.host_power_action(action)
4752 
4753     @wrap_exception()
4754     def host_maintenance_mode(self, context, host, mode):
4755         """Start/Stop host maintenance window. On start, it triggers
4756         guest VMs evacuation.
4757         """
4758         return self.driver.host_maintenance_mode(host, mode)
4759 
4760     @wrap_exception()
4761     def set_host_enabled(self, context, enabled):
4762         """Sets the specified host's ability to accept new instances."""
4763         return self.driver.set_host_enabled(enabled)
4764 
4765     @wrap_exception()
4766     def get_host_uptime(self, context):
4767         """Returns the result of calling "uptime" on the target host."""
4768         return self.driver.get_host_uptime()
4769 
4770     @wrap_exception()
4771     @wrap_instance_fault
4772     def get_diagnostics(self, context, instance):
4773         """Retrieve diagnostics for an instance on this host."""
4774         current_power_state = self._get_power_state(context, instance)
4775         if current_power_state == power_state.RUNNING:
4776             LOG.info("Retrieving diagnostics", instance=instance)
4777             return self.driver.get_diagnostics(instance)
4778         else:
4779             raise exception.InstanceInvalidState(
4780                 attr='power state',
4781                 instance_uuid=instance.uuid,
4782                 state=power_state.STATE_MAP[instance.power_state],
4783                 method='get_diagnostics')
4784 
4785     @wrap_exception()
4786     @wrap_instance_fault
4787     def get_instance_diagnostics(self, context, instance):
4788         """Retrieve diagnostics for an instance on this host."""
4789         current_power_state = self._get_power_state(context, instance)
4790         if current_power_state == power_state.RUNNING:
4791             LOG.info("Retrieving diagnostics", instance=instance)
4792             return self.driver.get_instance_diagnostics(instance)
4793         else:
4794             raise exception.InstanceInvalidState(
4795                 attr='power state',
4796                 instance_uuid=instance.uuid,
4797                 state=power_state.STATE_MAP[instance.power_state],
4798                 method='get_diagnostics')
4799 
4800     @wrap_exception()
4801     @reverts_task_state
4802     @wrap_instance_event(prefix='compute')
4803     @wrap_instance_fault
4804     def suspend_instance(self, context, instance):
4805         """Suspend the given instance."""
4806         context = context.elevated()
4807 
4808         # Store the old state
4809         instance.system_metadata['old_vm_state'] = instance.vm_state
4810         self._notify_about_instance_usage(context, instance, 'suspend.start')
4811         compute_utils.notify_about_instance_action(context, instance,
4812                 self.host, action=fields.NotificationAction.SUSPEND,
4813                 phase=fields.NotificationPhase.START)
4814         with self._error_out_instance_on_exception(context, instance,
4815              instance_state=instance.vm_state):
4816             self.driver.suspend(context, instance)
4817         instance.power_state = self._get_power_state(context, instance)
4818         instance.vm_state = vm_states.SUSPENDED
4819         instance.task_state = None
4820         instance.save(expected_task_state=task_states.SUSPENDING)
4821         self._notify_about_instance_usage(context, instance, 'suspend.end')
4822         compute_utils.notify_about_instance_action(context, instance,
4823                 self.host, action=fields.NotificationAction.SUSPEND,
4824                 phase=fields.NotificationPhase.END)
4825 
4826     @wrap_exception()
4827     @reverts_task_state
4828     @wrap_instance_event(prefix='compute')
4829     @wrap_instance_fault
4830     def resume_instance(self, context, instance):
4831         """Resume the given suspended instance."""
4832         context = context.elevated()
4833         LOG.info('Resuming', instance=instance)
4834 
4835         self._notify_about_instance_usage(context, instance, 'resume.start')
4836 
4837         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4838             context, instance.uuid)
4839         block_device_info = self._get_instance_block_device_info(
4840             context, instance, bdms=bdms)
4841 
4842         compute_utils.notify_about_instance_action(context, instance,
4843             self.host, action=fields.NotificationAction.RESUME,
4844             phase=fields.NotificationPhase.START, bdms=bdms)
4845 
4846         network_info = self.network_api.get_instance_nw_info(context, instance)
4847 
4848         with self._error_out_instance_on_exception(context, instance,
4849              instance_state=instance.vm_state):
4850             self.driver.resume(context, instance, network_info,
4851                                block_device_info)
4852 
4853         instance.power_state = self._get_power_state(context, instance)
4854 
4855         # We default to the ACTIVE state for backwards compatibility
4856         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4857                                                          vm_states.ACTIVE)
4858 
4859         instance.task_state = None
4860         instance.save(expected_task_state=task_states.RESUMING)
4861         self._notify_about_instance_usage(context, instance, 'resume.end')
4862         compute_utils.notify_about_instance_action(context, instance,
4863             self.host, action=fields.NotificationAction.RESUME,
4864             phase=fields.NotificationPhase.END, bdms=bdms)
4865 
4866     @wrap_exception()
4867     @reverts_task_state
4868     @wrap_instance_event(prefix='compute')
4869     @wrap_instance_fault
4870     def shelve_instance(self, context, instance, image_id,
4871                         clean_shutdown):
4872         """Shelve an instance.
4873 
4874         This should be used when you want to take a snapshot of the instance.
4875         It also adds system_metadata that can be used by a periodic task to
4876         offload the shelved instance after a period of time.
4877 
4878         :param context: request context
4879         :param instance: an Instance object
4880         :param image_id: an image id to snapshot to.
4881         :param clean_shutdown: give the GuestOS a chance to stop
4882         """
4883 
4884         @utils.synchronized(instance.uuid)
4885         def do_shelve_instance():
4886             self._shelve_instance(context, instance, image_id, clean_shutdown)
4887         do_shelve_instance()
4888 
4889     def _shelve_instance(self, context, instance, image_id,
4890                          clean_shutdown):
4891         LOG.info('Shelving', instance=instance)
4892         offload = CONF.shelved_offload_time == 0
4893         if offload:
4894             # Get the BDMs early so we can pass them into versioned
4895             # notifications since _shelve_offload_instance needs the
4896             # BDMs anyway.
4897             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4898                 context, instance.uuid)
4899         else:
4900             bdms = None
4901         compute_utils.notify_usage_exists(self.notifier, context, instance,
4902                                           self.host, current_period=True)
4903         self._notify_about_instance_usage(context, instance, 'shelve.start')
4904         compute_utils.notify_about_instance_action(context, instance,
4905                 self.host, action=fields.NotificationAction.SHELVE,
4906                 phase=fields.NotificationPhase.START, bdms=bdms)
4907 
4908         def update_task_state(task_state, expected_state=task_states.SHELVING):
4909             shelving_state_map = {
4910                     task_states.IMAGE_PENDING_UPLOAD:
4911                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4912                     task_states.IMAGE_UPLOADING:
4913                         task_states.SHELVING_IMAGE_UPLOADING,
4914                     task_states.SHELVING: task_states.SHELVING}
4915             task_state = shelving_state_map[task_state]
4916             expected_state = shelving_state_map[expected_state]
4917             instance.task_state = task_state
4918             instance.save(expected_task_state=expected_state)
4919         # Do not attempt a clean shutdown of a paused guest since some
4920         # hypervisors will fail the clean shutdown if the guest is not
4921         # running.
4922         if instance.power_state == power_state.PAUSED:
4923             clean_shutdown = False
4924         self._power_off_instance(context, instance, clean_shutdown)
4925         self.driver.snapshot(context, instance, image_id, update_task_state)
4926 
4927         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4928         instance.system_metadata['shelved_image_id'] = image_id
4929         instance.system_metadata['shelved_host'] = self.host
4930         instance.vm_state = vm_states.SHELVED
4931         instance.task_state = None
4932         if CONF.shelved_offload_time == 0:
4933             instance.task_state = task_states.SHELVING_OFFLOADING
4934         instance.power_state = self._get_power_state(context, instance)
4935         instance.save(expected_task_state=[
4936                 task_states.SHELVING,
4937                 task_states.SHELVING_IMAGE_UPLOADING])
4938 
4939         self._notify_about_instance_usage(context, instance, 'shelve.end')
4940         compute_utils.notify_about_instance_action(context, instance,
4941                 self.host, action=fields.NotificationAction.SHELVE,
4942                 phase=fields.NotificationPhase.END, bdms=bdms)
4943 
4944         if offload:
4945             self._shelve_offload_instance(context, instance,
4946                                           clean_shutdown=False, bdms=bdms)
4947 
4948     @wrap_exception()
4949     @reverts_task_state
4950     @wrap_instance_event(prefix='compute')
4951     @wrap_instance_fault
4952     def shelve_offload_instance(self, context, instance, clean_shutdown):
4953         """Remove a shelved instance from the hypervisor.
4954 
4955         This frees up those resources for use by other instances, but may lead
4956         to slower unshelve times for this instance.  This method is used by
4957         volume backed instances since restoring them doesn't involve the
4958         potentially large download of an image.
4959 
4960         :param context: request context
4961         :param instance: nova.objects.instance.Instance
4962         :param clean_shutdown: give the GuestOS a chance to stop
4963         """
4964 
4965         @utils.synchronized(instance.uuid)
4966         def do_shelve_offload_instance():
4967             self._shelve_offload_instance(context, instance, clean_shutdown)
4968         do_shelve_offload_instance()
4969 
4970     def _shelve_offload_instance(self, context, instance, clean_shutdown,
4971                                  bdms=None):
4972         LOG.info('Shelve offloading', instance=instance)
4973         if bdms is None:
4974             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4975                 context, instance.uuid)
4976         self._notify_about_instance_usage(context, instance,
4977                 'shelve_offload.start')
4978         compute_utils.notify_about_instance_action(context, instance,
4979                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
4980                 phase=fields.NotificationPhase.START, bdms=bdms)
4981 
4982         self._power_off_instance(context, instance, clean_shutdown)
4983         current_power_state = self._get_power_state(context, instance)
4984 
4985         self.network_api.cleanup_instance_network_on_host(context, instance,
4986                                                           instance.host)
4987         network_info = self.network_api.get_instance_nw_info(context, instance)
4988 
4989         block_device_info = self._get_instance_block_device_info(context,
4990                                                                  instance,
4991                                                                  bdms=bdms)
4992         self.driver.destroy(context, instance, network_info,
4993                 block_device_info)
4994 
4995         # the instance is going to be removed from the host so we want to
4996         # terminate all the connections with the volume server and the host
4997         self._terminate_volume_connections(context, instance, bdms)
4998 
4999         # Free up the resource allocations in the placement service.
5000         # This should happen *before* the vm_state is changed to
5001         # SHELVED_OFFLOADED in case client-side code is polling the API to
5002         # schedule more instances (or unshelve) once this server is offloaded.
5003         self.rt.delete_allocation_for_shelve_offloaded_instance(context,
5004                                                                 instance)
5005 
5006         instance.power_state = current_power_state
5007         # NOTE(mriedem): The vm_state has to be set before updating the
5008         # resource tracker, see vm_states.ALLOW_RESOURCE_REMOVAL. The host/node
5009         # values cannot be nulled out until after updating the resource tracker
5010         # though.
5011         instance.vm_state = vm_states.SHELVED_OFFLOADED
5012         instance.task_state = None
5013         instance.save(expected_task_state=[task_states.SHELVING,
5014                                            task_states.SHELVING_OFFLOADING])
5015 
5016         # NOTE(ndipanov): Free resources from the resource tracker
5017         self._update_resource_tracker(context, instance)
5018 
5019         # NOTE(sfinucan): RPC calls should no longer be attempted against this
5020         # instance, so ensure any calls result in errors
5021         self._nil_out_instance_obj_host_and_node(instance)
5022         instance.save(expected_task_state=None)
5023 
5024         # TODO(melwitt): We should clean up instance console tokens here. The
5025         # instance has no host at this point and will need to establish a new
5026         # console connection in the future after it is unshelved.
5027         self._delete_scheduler_instance_info(context, instance.uuid)
5028         self._notify_about_instance_usage(context, instance,
5029                 'shelve_offload.end')
5030         compute_utils.notify_about_instance_action(context, instance,
5031                 self.host, action=fields.NotificationAction.SHELVE_OFFLOAD,
5032                 phase=fields.NotificationPhase.END, bdms=bdms)
5033 
5034     @wrap_exception()
5035     @reverts_task_state
5036     @wrap_instance_event(prefix='compute')
5037     @wrap_instance_fault
5038     def unshelve_instance(self, context, instance, image,
5039                           filter_properties, node):
5040         """Unshelve the instance.
5041 
5042         :param context: request context
5043         :param instance: a nova.objects.instance.Instance object
5044         :param image: an image to build from.  If None we assume a
5045             volume backed instance.
5046         :param filter_properties: dict containing limits, retry info etc.
5047         :param node: target compute node
5048         """
5049         if filter_properties is None:
5050             filter_properties = {}
5051 
5052         @utils.synchronized(instance.uuid)
5053         def do_unshelve_instance():
5054             self._unshelve_instance(context, instance, image,
5055                                     filter_properties, node)
5056         do_unshelve_instance()
5057 
5058     def _unshelve_instance_key_scrub(self, instance):
5059         """Remove data from the instance that may cause side effects."""
5060         cleaned_keys = dict(
5061                 key_data=instance.key_data,
5062                 auto_disk_config=instance.auto_disk_config)
5063         instance.key_data = None
5064         instance.auto_disk_config = False
5065         return cleaned_keys
5066 
5067     def _unshelve_instance_key_restore(self, instance, keys):
5068         """Restore previously scrubbed keys before saving the instance."""
5069         instance.update(keys)
5070 
5071     def _unshelve_instance(self, context, instance, image, filter_properties,
5072                            node):
5073         LOG.info('Unshelving', instance=instance)
5074         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5075                 context, instance.uuid)
5076 
5077         self._notify_about_instance_usage(context, instance, 'unshelve.start')
5078         compute_utils.notify_about_instance_action(context, instance,
5079                 self.host, action=fields.NotificationAction.UNSHELVE,
5080                 phase=fields.NotificationPhase.START, bdms=bdms)
5081 
5082         instance.task_state = task_states.SPAWNING
5083         instance.save()
5084 
5085         block_device_info = self._prep_block_device(context, instance, bdms)
5086         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
5087 
5088         if node is None:
5089             node = self._get_nodename(instance)
5090 
5091         limits = filter_properties.get('limits', {})
5092 
5093         allocations = self.reportclient.get_allocations_for_consumer(
5094             context, instance.uuid)
5095 
5096         shelved_image_ref = instance.image_ref
5097         if image:
5098             instance.image_ref = image['id']
5099             image_meta = objects.ImageMeta.from_dict(image)
5100         else:
5101             image_meta = objects.ImageMeta.from_dict(
5102                 utils.get_image_from_system_metadata(
5103                     instance.system_metadata))
5104 
5105         self.network_api.setup_instance_network_on_host(context, instance,
5106                                                         self.host)
5107         network_info = self.network_api.get_instance_nw_info(context, instance)
5108         try:
5109             with self.rt.instance_claim(context, instance, node, limits):
5110                 self.driver.spawn(context, instance, image_meta,
5111                                   injected_files=[],
5112                                   admin_password=None,
5113                                   allocations=allocations,
5114                                   network_info=network_info,
5115                                   block_device_info=block_device_info)
5116         except Exception:
5117             with excutils.save_and_reraise_exception(logger=LOG):
5118                 LOG.exception('Instance failed to spawn',
5119                               instance=instance)
5120                 # Cleanup allocations created by the scheduler on this host
5121                 # since we failed to spawn the instance. We do this both if
5122                 # the instance claim failed with ComputeResourcesUnavailable
5123                 # or if we did claim but the spawn failed, because aborting the
5124                 # instance claim will not remove the allocations.
5125                 self.reportclient.delete_allocation_for_instance(context,
5126                                                                  instance.uuid)
5127                 # FIXME: Umm, shouldn't we be rolling back port bindings too?
5128                 self._terminate_volume_connections(context, instance, bdms)
5129                 # The reverts_task_state decorator on unshelve_instance will
5130                 # eventually save these updates.
5131                 self._nil_out_instance_obj_host_and_node(instance)
5132 
5133         if image:
5134             instance.image_ref = shelved_image_ref
5135             self._delete_snapshot_of_shelved_instance(context, instance,
5136                                                       image['id'])
5137 
5138         self._unshelve_instance_key_restore(instance, scrubbed_keys)
5139         self._update_instance_after_spawn(context, instance)
5140         # Delete system_metadata for a shelved instance
5141         compute_utils.remove_shelved_keys_from_system_metadata(instance)
5142 
5143         instance.save(expected_task_state=task_states.SPAWNING)
5144         self._update_scheduler_instance_info(context, instance)
5145         self._notify_about_instance_usage(context, instance, 'unshelve.end')
5146         compute_utils.notify_about_instance_action(context, instance,
5147                 self.host, action=fields.NotificationAction.UNSHELVE,
5148                 phase=fields.NotificationPhase.END, bdms=bdms)
5149 
5150     @messaging.expected_exceptions(NotImplementedError)
5151     @wrap_instance_fault
5152     def reset_network(self, context, instance):
5153         """Reset networking on the given instance."""
5154         LOG.debug('Reset network', instance=instance)
5155         self.driver.reset_network(instance)
5156 
5157     def _inject_network_info(self, context, instance, network_info):
5158         """Inject network info for the given instance."""
5159         LOG.debug('Inject network info', instance=instance)
5160         LOG.debug('network_info to inject: |%s|', network_info,
5161                   instance=instance)
5162 
5163         self.driver.inject_network_info(instance,
5164                                         network_info)
5165 
5166     @wrap_instance_fault
5167     def inject_network_info(self, context, instance):
5168         """Inject network info, but don't return the info."""
5169         network_info = self.network_api.get_instance_nw_info(context, instance)
5170         self._inject_network_info(context, instance, network_info)
5171 
5172     @messaging.expected_exceptions(NotImplementedError,
5173                                    exception.ConsoleNotAvailable,
5174                                    exception.InstanceNotFound)
5175     @wrap_exception()
5176     @wrap_instance_fault
5177     def get_console_output(self, context, instance, tail_length):
5178         """Send the console output for the given instance."""
5179         context = context.elevated()
5180         LOG.info("Get console output", instance=instance)
5181         output = self.driver.get_console_output(context, instance)
5182 
5183         if type(output) is six.text_type:
5184             output = six.b(output)
5185 
5186         if tail_length is not None:
5187             output = self._tail_log(output, tail_length)
5188 
5189         return output.decode('ascii', 'replace')
5190 
5191     def _tail_log(self, log, length):
5192         try:
5193             length = int(length)
5194         except ValueError:
5195             length = 0
5196 
5197         if length == 0:
5198             return b''
5199         else:
5200             return b'\n'.join(log.split(b'\n')[-int(length):])
5201 
5202     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5203                                    exception.InstanceNotReady,
5204                                    exception.InstanceNotFound,
5205                                    exception.ConsoleTypeUnavailable,
5206                                    NotImplementedError)
5207     @wrap_exception()
5208     @wrap_instance_fault
5209     def get_vnc_console(self, context, console_type, instance):
5210         """Return connection information for a vnc console."""
5211         context = context.elevated()
5212         LOG.debug("Getting vnc console", instance=instance)
5213 
5214         if not CONF.vnc.enabled:
5215             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5216 
5217         if console_type == 'novnc':
5218             # For essex, novncproxy_base_url must include the full path
5219             # including the html file (like http://myhost/vnc_auto.html)
5220             access_url_base = CONF.vnc.novncproxy_base_url
5221         elif console_type == 'xvpvnc':
5222             access_url_base = CONF.vnc.xvpvncproxy_base_url
5223         else:
5224             raise exception.ConsoleTypeInvalid(console_type=console_type)
5225 
5226         try:
5227             # Retrieve connect info from driver, and then decorate with our
5228             # access info token
5229             console = self.driver.get_vnc_console(context, instance)
5230             console_auth = objects.ConsoleAuthToken(
5231                 context=context,
5232                 console_type=console_type,
5233                 host=console.host,
5234                 port=console.port,
5235                 internal_access_path=console.internal_access_path,
5236                 instance_uuid=instance.uuid,
5237                 access_url_base=access_url_base,
5238             )
5239             console_auth.authorize(CONF.consoleauth.token_ttl)
5240             connect_info = console.get_connection_info(
5241                 console_auth.token, console_auth.access_url)
5242 
5243         except exception.InstanceNotFound:
5244             if instance.vm_state != vm_states.BUILDING:
5245                 raise
5246             raise exception.InstanceNotReady(instance_id=instance.uuid)
5247 
5248         return connect_info
5249 
5250     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5251                                    exception.InstanceNotReady,
5252                                    exception.InstanceNotFound,
5253                                    exception.ConsoleTypeUnavailable,
5254                                    NotImplementedError)
5255     @wrap_exception()
5256     @wrap_instance_fault
5257     def get_spice_console(self, context, console_type, instance):
5258         """Return connection information for a spice console."""
5259         context = context.elevated()
5260         LOG.debug("Getting spice console", instance=instance)
5261 
5262         if not CONF.spice.enabled:
5263             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5264 
5265         if console_type != 'spice-html5':
5266             raise exception.ConsoleTypeInvalid(console_type=console_type)
5267 
5268         try:
5269             # Retrieve connect info from driver, and then decorate with our
5270             # access info token
5271             console = self.driver.get_spice_console(context, instance)
5272             console_auth = objects.ConsoleAuthToken(
5273                 context=context,
5274                 console_type=console_type,
5275                 host=console.host,
5276                 port=console.port,
5277                 internal_access_path=console.internal_access_path,
5278                 instance_uuid=instance.uuid,
5279                 access_url_base=CONF.spice.html5proxy_base_url,
5280             )
5281             console_auth.authorize(CONF.consoleauth.token_ttl)
5282             connect_info = console.get_connection_info(
5283                 console_auth.token, console_auth.access_url)
5284 
5285         except exception.InstanceNotFound:
5286             if instance.vm_state != vm_states.BUILDING:
5287                 raise
5288             raise exception.InstanceNotReady(instance_id=instance.uuid)
5289 
5290         return connect_info
5291 
5292     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5293                                    exception.InstanceNotReady,
5294                                    exception.InstanceNotFound,
5295                                    exception.ConsoleTypeUnavailable,
5296                                    NotImplementedError)
5297     @wrap_exception()
5298     @wrap_instance_fault
5299     def get_rdp_console(self, context, console_type, instance):
5300         """Return connection information for a RDP console."""
5301         context = context.elevated()
5302         LOG.debug("Getting RDP console", instance=instance)
5303 
5304         if not CONF.rdp.enabled:
5305             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5306 
5307         if console_type != 'rdp-html5':
5308             raise exception.ConsoleTypeInvalid(console_type=console_type)
5309 
5310         try:
5311             # Retrieve connect info from driver, and then decorate with our
5312             # access info token
5313             console = self.driver.get_rdp_console(context, instance)
5314             console_auth = objects.ConsoleAuthToken(
5315                 context=context,
5316                 console_type=console_type,
5317                 host=console.host,
5318                 port=console.port,
5319                 internal_access_path=console.internal_access_path,
5320                 instance_uuid=instance.uuid,
5321                 access_url_base=CONF.rdp.html5_proxy_base_url,
5322             )
5323             console_auth.authorize(CONF.consoleauth.token_ttl)
5324             connect_info = console.get_connection_info(
5325                 console_auth.token, console_auth.access_url)
5326 
5327         except exception.InstanceNotFound:
5328             if instance.vm_state != vm_states.BUILDING:
5329                 raise
5330             raise exception.InstanceNotReady(instance_id=instance.uuid)
5331 
5332         return connect_info
5333 
5334     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5335                                    exception.InstanceNotReady,
5336                                    exception.InstanceNotFound,
5337                                    exception.ConsoleTypeUnavailable,
5338                                    NotImplementedError)
5339     @wrap_exception()
5340     @wrap_instance_fault
5341     def get_mks_console(self, context, console_type, instance):
5342         """Return connection information for a MKS console."""
5343         context = context.elevated()
5344         LOG.debug("Getting MKS console", instance=instance)
5345 
5346         if not CONF.mks.enabled:
5347             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5348 
5349         if console_type != 'webmks':
5350             raise exception.ConsoleTypeInvalid(console_type=console_type)
5351 
5352         try:
5353             # Retrieve connect info from driver, and then decorate with our
5354             # access info token
5355             console = self.driver.get_mks_console(context, instance)
5356             console_auth = objects.ConsoleAuthToken(
5357                 context=context,
5358                 console_type=console_type,
5359                 host=console.host,
5360                 port=console.port,
5361                 internal_access_path=console.internal_access_path,
5362                 instance_uuid=instance.uuid,
5363                 access_url_base=CONF.mks.mksproxy_base_url,
5364             )
5365             console_auth.authorize(CONF.consoleauth.token_ttl)
5366             connect_info = console.get_connection_info(
5367                 console_auth.token, console_auth.access_url)
5368 
5369         except exception.InstanceNotFound:
5370             if instance.vm_state != vm_states.BUILDING:
5371                 raise
5372             raise exception.InstanceNotReady(instance_id=instance.uuid)
5373 
5374         return connect_info
5375 
5376     @messaging.expected_exceptions(
5377         exception.ConsoleTypeInvalid,
5378         exception.InstanceNotReady,
5379         exception.InstanceNotFound,
5380         exception.ConsoleTypeUnavailable,
5381         exception.SocketPortRangeExhaustedException,
5382         exception.ImageSerialPortNumberInvalid,
5383         exception.ImageSerialPortNumberExceedFlavorValue,
5384         NotImplementedError)
5385     @wrap_exception()
5386     @wrap_instance_fault
5387     def get_serial_console(self, context, console_type, instance):
5388         """Returns connection information for a serial console."""
5389 
5390         LOG.debug("Getting serial console", instance=instance)
5391 
5392         if not CONF.serial_console.enabled:
5393             raise exception.ConsoleTypeUnavailable(console_type=console_type)
5394 
5395         context = context.elevated()
5396 
5397         try:
5398             # Retrieve connect info from driver, and then decorate with our
5399             # access info token
5400             console = self.driver.get_serial_console(context, instance)
5401             console_auth = objects.ConsoleAuthToken(
5402                 context=context,
5403                 console_type=console_type,
5404                 host=console.host,
5405                 port=console.port,
5406                 internal_access_path=console.internal_access_path,
5407                 instance_uuid=instance.uuid,
5408                 access_url_base=CONF.serial_console.base_url,
5409             )
5410             console_auth.authorize(CONF.consoleauth.token_ttl)
5411             connect_info = console.get_connection_info(
5412                 console_auth.token, console_auth.access_url)
5413 
5414         except exception.InstanceNotFound:
5415             if instance.vm_state != vm_states.BUILDING:
5416                 raise
5417             raise exception.InstanceNotReady(instance_id=instance.uuid)
5418 
5419         return connect_info
5420 
5421     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
5422                                    exception.InstanceNotReady,
5423                                    exception.InstanceNotFound)
5424     @wrap_exception()
5425     @wrap_instance_fault
5426     def validate_console_port(self, ctxt, instance, port, console_type):
5427         if console_type == "spice-html5":
5428             console_info = self.driver.get_spice_console(ctxt, instance)
5429         elif console_type == "rdp-html5":
5430             console_info = self.driver.get_rdp_console(ctxt, instance)
5431         elif console_type == "serial":
5432             console_info = self.driver.get_serial_console(ctxt, instance)
5433         elif console_type == "webmks":
5434             console_info = self.driver.get_mks_console(ctxt, instance)
5435         else:
5436             console_info = self.driver.get_vnc_console(ctxt, instance)
5437 
5438         # Some drivers may return an int on console_info.port but the port
5439         # variable in this method is a string, so cast to be sure we are
5440         # comparing the correct types.
5441         return str(console_info.port) == port
5442 
5443     @wrap_exception()
5444     @reverts_task_state
5445     @wrap_instance_fault
5446     def reserve_block_device_name(self, context, instance, device,
5447                                   volume_id, disk_bus, device_type, tag,
5448                                   multiattach):
5449         if (tag and not
5450                 self.driver.capabilities.get('supports_tagged_attach_volume',
5451                                              False)):
5452             raise exception.VolumeTaggedAttachNotSupported()
5453 
5454         if (multiattach and not
5455                 self.driver.capabilities.get('supports_multiattach', False)):
5456             raise exception.MultiattachNotSupportedByVirtDriver(
5457                 volume_id=volume_id)
5458 
5459         @utils.synchronized(instance.uuid)
5460         def do_reserve():
5461             bdms = (
5462                 objects.BlockDeviceMappingList.get_by_instance_uuid(
5463                     context, instance.uuid))
5464 
5465             # NOTE(ndipanov): We need to explicitly set all the fields on the
5466             #                 object so that obj_load_attr does not fail
5467             new_bdm = objects.BlockDeviceMapping(
5468                     context=context,
5469                     source_type='volume', destination_type='volume',
5470                     instance_uuid=instance.uuid, boot_index=None,
5471                     volume_id=volume_id,
5472                     device_name=device, guest_format=None,
5473                     disk_bus=disk_bus, device_type=device_type, tag=tag)
5474 
5475             new_bdm.device_name = self._get_device_name_for_instance(
5476                     instance, bdms, new_bdm)
5477 
5478             # NOTE(vish): create bdm here to avoid race condition
5479             new_bdm.create()
5480             return new_bdm
5481 
5482         return do_reserve()
5483 
5484     @wrap_exception()
5485     @wrap_instance_event(prefix='compute')
5486     @wrap_instance_fault
5487     def attach_volume(self, context, instance, bdm):
5488         """Attach a volume to an instance."""
5489         driver_bdm = driver_block_device.convert_volume(bdm)
5490 
5491         @utils.synchronized(instance.uuid)
5492         def do_attach_volume(context, instance, driver_bdm):
5493             try:
5494                 return self._attach_volume(context, instance, driver_bdm)
5495             except Exception:
5496                 with excutils.save_and_reraise_exception():
5497                     bdm.destroy()
5498 
5499         do_attach_volume(context, instance, driver_bdm)
5500 
5501     def _attach_volume(self, context, instance, bdm):
5502         context = context.elevated()
5503         LOG.info('Attaching volume %(volume_id)s to %(mountpoint)s',
5504                  {'volume_id': bdm.volume_id,
5505                   'mountpoint': bdm['mount_device']},
5506                  instance=instance)
5507         compute_utils.notify_about_volume_attach_detach(
5508             context, instance, self.host,
5509             action=fields.NotificationAction.VOLUME_ATTACH,
5510             phase=fields.NotificationPhase.START,
5511             volume_id=bdm.volume_id)
5512         try:
5513             bdm.attach(context, instance, self.volume_api, self.driver,
5514                        do_driver_attach=True)
5515         except Exception as e:
5516             with excutils.save_and_reraise_exception():
5517                 LOG.exception("Failed to attach %(volume_id)s "
5518                               "at %(mountpoint)s",
5519                               {'volume_id': bdm.volume_id,
5520                                'mountpoint': bdm['mount_device']},
5521                               instance=instance)
5522                 if bdm['attachment_id']:
5523                     # Try to delete the attachment to make the volume
5524                     # available again. Note that DriverVolumeBlockDevice
5525                     # may have already deleted the attachment so ignore
5526                     # VolumeAttachmentNotFound.
5527                     try:
5528                         self.volume_api.attachment_delete(
5529                             context, bdm['attachment_id'])
5530                     except exception.VolumeAttachmentNotFound as exc:
5531                         LOG.debug('Ignoring VolumeAttachmentNotFound: %s',
5532                                   exc, instance=instance)
5533                 else:
5534                     self.volume_api.unreserve_volume(context, bdm.volume_id)
5535                 tb = traceback.format_exc()
5536                 compute_utils.notify_about_volume_attach_detach(
5537                     context, instance, self.host,
5538                     action=fields.NotificationAction.VOLUME_ATTACH,
5539                     phase=fields.NotificationPhase.ERROR,
5540                     exception=e,
5541                     volume_id=bdm.volume_id, tb=tb)
5542 
5543         info = {'volume_id': bdm.volume_id}
5544         self._notify_about_instance_usage(
5545             context, instance, "volume.attach", extra_usage_info=info)
5546         compute_utils.notify_about_volume_attach_detach(
5547             context, instance, self.host,
5548             action=fields.NotificationAction.VOLUME_ATTACH,
5549             phase=fields.NotificationPhase.END,
5550             volume_id=bdm.volume_id)
5551 
5552     def _notify_volume_usage_detach(self, context, instance, bdm):
5553         if CONF.volume_usage_poll_interval <= 0:
5554             return
5555 
5556         mp = bdm.device_name
5557         # Handle bootable volumes which will not contain /dev/
5558         if '/dev/' in mp:
5559             mp = mp[5:]
5560         try:
5561             vol_stats = self.driver.block_stats(instance, mp)
5562             if vol_stats is None:
5563                 return
5564         except NotImplementedError:
5565             return
5566 
5567         LOG.debug("Updating volume usage cache with totals", instance=instance)
5568         rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
5569         vol_usage = objects.VolumeUsage(context)
5570         vol_usage.volume_id = bdm.volume_id
5571         vol_usage.instance_uuid = instance.uuid
5572         vol_usage.project_id = instance.project_id
5573         vol_usage.user_id = instance.user_id
5574         vol_usage.availability_zone = instance.availability_zone
5575         vol_usage.curr_reads = rd_req
5576         vol_usage.curr_read_bytes = rd_bytes
5577         vol_usage.curr_writes = wr_req
5578         vol_usage.curr_write_bytes = wr_bytes
5579         vol_usage.save(update_totals=True)
5580         self.notifier.info(context, 'volume.usage', vol_usage.to_dict())
5581         compute_utils.notify_about_volume_usage(context, vol_usage, self.host)
5582 
5583     def _detach_volume(self, context, bdm, instance, destroy_bdm=True,
5584                        attachment_id=None):
5585         """Detach a volume from an instance.
5586 
5587         :param context: security context
5588         :param bdm: nova.objects.BlockDeviceMapping volume bdm to detach
5589         :param instance: the Instance object to detach the volume from
5590         :param destroy_bdm: if True, the corresponding BDM entry will be marked
5591                             as deleted. Disabling this is useful for operations
5592                             like rebuild, when we don't want to destroy BDM
5593         :param attachment_id: The volume attachment_id for the given instance
5594                               and volume.
5595         """
5596         volume_id = bdm.volume_id
5597         compute_utils.notify_about_volume_attach_detach(
5598             context, instance, self.host,
5599             action=fields.NotificationAction.VOLUME_DETACH,
5600             phase=fields.NotificationPhase.START,
5601             volume_id=volume_id)
5602 
5603         self._notify_volume_usage_detach(context, instance, bdm)
5604 
5605         LOG.info('Detaching volume %(volume_id)s',
5606                  {'volume_id': volume_id}, instance=instance)
5607 
5608         driver_bdm = driver_block_device.convert_volume(bdm)
5609         driver_bdm.detach(context, instance, self.volume_api, self.driver,
5610                           attachment_id=attachment_id, destroy_bdm=destroy_bdm)
5611 
5612         info = dict(volume_id=volume_id)
5613         self._notify_about_instance_usage(
5614             context, instance, "volume.detach", extra_usage_info=info)
5615         compute_utils.notify_about_volume_attach_detach(
5616             context, instance, self.host,
5617             action=fields.NotificationAction.VOLUME_DETACH,
5618             phase=fields.NotificationPhase.END,
5619             volume_id=volume_id)
5620 
5621         if 'tag' in bdm and bdm.tag:
5622             self._delete_disk_metadata(instance, bdm)
5623         if destroy_bdm:
5624             bdm.destroy()
5625 
5626     def _delete_disk_metadata(self, instance, bdm):
5627         for device in instance.device_metadata.devices:
5628             if isinstance(device, objects.DiskMetadata):
5629                 if 'serial' in device:
5630                     if device.serial == bdm.volume_id:
5631                         instance.device_metadata.devices.remove(device)
5632                         instance.save()
5633                         break
5634                 else:
5635                     # NOTE(artom) We log the entire device object because all
5636                     # fields are nullable and may not be set
5637                     LOG.warning('Unable to determine whether to clean up '
5638                                 'device metadata for disk %s', device,
5639                                 instance=instance)
5640 
5641     @wrap_exception()
5642     @wrap_instance_event(prefix='compute')
5643     @wrap_instance_fault
5644     def detach_volume(self, context, volume_id, instance, attachment_id):
5645         """Detach a volume from an instance.
5646 
5647         :param context: security context
5648         :param volume_id: the volume id
5649         :param instance: the Instance object to detach the volume from
5650         :param attachment_id: The volume attachment_id for the given instance
5651                               and volume.
5652 
5653         """
5654         @utils.synchronized(instance.uuid)
5655         def do_detach_volume(context, volume_id, instance, attachment_id):
5656             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5657                     context, volume_id, instance.uuid)
5658             self._detach_volume(context, bdm, instance,
5659                                 attachment_id=attachment_id)
5660 
5661         do_detach_volume(context, volume_id, instance, attachment_id)
5662 
5663     def _init_volume_connection(self, context, new_volume,
5664                                 old_volume_id, connector, bdm,
5665                                 new_attachment_id, mountpoint):
5666         new_volume_id = new_volume['id']
5667         if new_attachment_id is None:
5668             # We're dealing with an old-style attachment so initialize the
5669             # connection so we can get the connection_info.
5670             new_cinfo = self.volume_api.initialize_connection(context,
5671                                                               new_volume_id,
5672                                                               connector)
5673         else:
5674             # Check for multiattach on the new volume and if True, check to
5675             # see if the virt driver supports multiattach.
5676             # TODO(mriedem): This is copied from DriverVolumeBlockDevice
5677             # and should be consolidated into some common code at some point.
5678             vol_multiattach = new_volume.get('multiattach', False)
5679             virt_multiattach = self.driver.capabilities.get(
5680                 'supports_multiattach', False)
5681             if vol_multiattach and not virt_multiattach:
5682                 raise exception.MultiattachNotSupportedByVirtDriver(
5683                     volume_id=new_volume_id)
5684 
5685             # This is a new style attachment and the API created the new
5686             # volume attachment and passed the id to the compute over RPC.
5687             # At this point we need to update the new volume attachment with
5688             # the host connector, which will give us back the new attachment
5689             # connection_info.
5690             new_cinfo = self.volume_api.attachment_update(
5691                 context, new_attachment_id, connector,
5692                 mountpoint)['connection_info']
5693 
5694             if vol_multiattach:
5695                 # This will be used by the volume driver to determine the
5696                 # proper disk configuration.
5697                 new_cinfo['multiattach'] = True
5698 
5699         old_cinfo = jsonutils.loads(bdm['connection_info'])
5700         if old_cinfo and 'serial' not in old_cinfo:
5701             old_cinfo['serial'] = old_volume_id
5702         # NOTE(lyarwood): serial is not always present in the returned
5703         # connection_info so set it if it is missing as we do in
5704         # DriverVolumeBlockDevice.attach().
5705         if 'serial' not in new_cinfo:
5706             new_cinfo['serial'] = new_volume_id
5707         return (old_cinfo, new_cinfo)
5708 
5709     def _swap_volume(self, context, instance, bdm, connector,
5710                      old_volume_id, new_volume, resize_to,
5711                      new_attachment_id, is_cinder_migration):
5712         new_volume_id = new_volume['id']
5713         mountpoint = bdm['device_name']
5714         failed = False
5715         new_cinfo = None
5716         try:
5717             old_cinfo, new_cinfo = self._init_volume_connection(
5718                 context, new_volume, old_volume_id, connector,
5719                 bdm, new_attachment_id, mountpoint)
5720             # NOTE(lyarwood): The Libvirt driver, the only virt driver
5721             # currently implementing swap_volume, will modify the contents of
5722             # new_cinfo when connect_volume is called. This is then saved to
5723             # the BDM in swap_volume for future use outside of this flow.
5724             msg = ("swap_volume: Calling driver volume swap with "
5725                    "connection infos: new: %(new_cinfo)s; "
5726                    "old: %(old_cinfo)s" %
5727                    {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo})
5728             # Both new and old info might contain password
5729             LOG.debug(strutils.mask_password(msg), instance=instance)
5730 
5731             self.driver.swap_volume(context, old_cinfo, new_cinfo, instance,
5732                                     mountpoint, resize_to)
5733             if new_attachment_id:
5734                 self.volume_api.attachment_complete(context, new_attachment_id)
5735             msg = ("swap_volume: Driver volume swap returned, new "
5736                    "connection_info is now : %(new_cinfo)s" %
5737                    {'new_cinfo': new_cinfo})
5738             LOG.debug(strutils.mask_password(msg))
5739         except Exception as ex:
5740             failed = True
5741             with excutils.save_and_reraise_exception():
5742                 tb = traceback.format_exc()
5743                 compute_utils.notify_about_volume_swap(
5744                     context, instance, self.host,
5745                     fields.NotificationPhase.ERROR,
5746                     old_volume_id, new_volume_id, ex, tb)
5747                 if new_cinfo:
5748                     msg = ("Failed to swap volume %(old_volume_id)s "
5749                            "for %(new_volume_id)s")
5750                     LOG.exception(msg, {'old_volume_id': old_volume_id,
5751                                         'new_volume_id': new_volume_id},
5752                                   instance=instance)
5753                 else:
5754                     msg = ("Failed to connect to volume %(volume_id)s "
5755                            "with volume at %(mountpoint)s")
5756                     LOG.exception(msg, {'volume_id': new_volume_id,
5757                                         'mountpoint': bdm['device_name']},
5758                                   instance=instance)
5759 
5760                 # The API marked the volume as 'detaching' for the old volume
5761                 # so we need to roll that back so the volume goes back to
5762                 # 'in-use' state.
5763                 self.volume_api.roll_detaching(context, old_volume_id)
5764 
5765                 if new_attachment_id is None:
5766                     # The API reserved the new volume so it would be in
5767                     # 'attaching' status, so we need to unreserve it so it
5768                     # goes back to 'available' status.
5769                     self.volume_api.unreserve_volume(context, new_volume_id)
5770                 else:
5771                     # This is a new style attachment for the new volume, which
5772                     # was created in the API. We just need to delete it here
5773                     # to put the new volume back into 'available' status.
5774                     self.volume_api.attachment_delete(
5775                         context, new_attachment_id)
5776         finally:
5777             # TODO(mriedem): This finally block is terribly confusing and is
5778             # trying to do too much. We should consider removing the finally
5779             # block and move whatever needs to happen on success and failure
5780             # into the blocks above for clarity, even if it means a bit of
5781             # redundant code.
5782             conn_volume = new_volume_id if failed else old_volume_id
5783             if new_cinfo:
5784                 LOG.debug("swap_volume: removing Cinder connection "
5785                           "for volume %(volume)s", {'volume': conn_volume},
5786                           instance=instance)
5787                 if bdm.attachment_id is None:
5788                     # This is the pre-3.44 flow for new-style volume
5789                     # attachments so just terminate the connection.
5790                     self.volume_api.terminate_connection(context,
5791                                                          conn_volume,
5792                                                          connector)
5793                 else:
5794                     # This is a new style volume attachment. If we failed, then
5795                     # the new attachment was already deleted above in the
5796                     # exception block and we have nothing more to do here. If
5797                     # swap_volume was successful in the driver, then we need to
5798                     # "detach" the original attachment by deleting it.
5799                     if not failed:
5800                         self.volume_api.attachment_delete(
5801                             context, bdm.attachment_id)
5802 
5803             # Need to make some decisions based on whether this was
5804             # a Cinder initiated migration or not. The callback to
5805             # migration completion isn't needed in the case of a
5806             # nova initiated simple swap of two volume
5807             # "volume-update" call so skip that. The new attachment
5808             # scenarios will give us a new attachment record and
5809             # that's what we want.
5810             if bdm.attachment_id and not is_cinder_migration:
5811                 # we don't callback to cinder
5812                 comp_ret = {'save_volume_id': new_volume_id}
5813             else:
5814                 # NOTE(lyarwood): The following call to
5815                 # os-migrate-volume-completion returns a dict containing
5816                 # save_volume_id, this volume id has two possible values :
5817                 # 1. old_volume_id if we are migrating (retyping) volumes
5818                 # 2. new_volume_id if we are swapping between two existing
5819                 #    volumes
5820                 # This volume id is later used to update the volume_id and
5821                 # connection_info['serial'] of the BDM.
5822                 comp_ret = self.volume_api.migrate_volume_completion(
5823                                                           context,
5824                                                           old_volume_id,
5825                                                           new_volume_id,
5826                                                           error=failed)
5827                 LOG.debug("swap_volume: Cinder migrate_volume_completion "
5828                           "returned: %(comp_ret)s", {'comp_ret': comp_ret},
5829                           instance=instance)
5830 
5831         return (comp_ret, new_cinfo)
5832 
5833     @wrap_exception()
5834     @wrap_instance_event(prefix='compute')
5835     @wrap_instance_fault
5836     def swap_volume(self, context, old_volume_id, new_volume_id, instance,
5837                     new_attachment_id):
5838         """Swap volume for an instance."""
5839         context = context.elevated()
5840 
5841         compute_utils.notify_about_volume_swap(
5842             context, instance, self.host,
5843             fields.NotificationPhase.START,
5844             old_volume_id, new_volume_id)
5845 
5846         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5847                 context, old_volume_id, instance.uuid)
5848         connector = self.driver.get_volume_connector(instance)
5849 
5850         resize_to = 0
5851         old_volume = self.volume_api.get(context, old_volume_id)
5852         # Yes this is a tightly-coupled state check of what's going on inside
5853         # cinder, but we need this while we still support old (v1/v2) and
5854         # new style attachments (v3.44). Once we drop support for old style
5855         # attachments we could think about cleaning up the cinder-initiated
5856         # swap volume API flows.
5857         is_cinder_migration = (
5858             True if old_volume['status'] in ('retyping',
5859                                              'migrating') else False)
5860         old_vol_size = old_volume['size']
5861         new_volume = self.volume_api.get(context, new_volume_id)
5862         new_vol_size = new_volume['size']
5863         if new_vol_size > old_vol_size:
5864             resize_to = new_vol_size
5865 
5866         LOG.info('Swapping volume %(old_volume)s for %(new_volume)s',
5867                  {'old_volume': old_volume_id, 'new_volume': new_volume_id},
5868                  instance=instance)
5869         comp_ret, new_cinfo = self._swap_volume(context,
5870                                                 instance,
5871                                                 bdm,
5872                                                 connector,
5873                                                 old_volume_id,
5874                                                 new_volume,
5875                                                 resize_to,
5876                                                 new_attachment_id,
5877                                                 is_cinder_migration)
5878 
5879         # NOTE(lyarwood): Update the BDM with the modified new_cinfo and
5880         # correct volume_id returned by Cinder.
5881         save_volume_id = comp_ret['save_volume_id']
5882         new_cinfo['serial'] = save_volume_id
5883         values = {
5884             'connection_info': jsonutils.dumps(new_cinfo),
5885             'source_type': 'volume',
5886             'destination_type': 'volume',
5887             'snapshot_id': None,
5888             'volume_id': save_volume_id,
5889             'no_device': None}
5890 
5891         if resize_to:
5892             values['volume_size'] = resize_to
5893 
5894         if new_attachment_id is not None:
5895             # This was a volume swap for a new-style attachment so we
5896             # need to update the BDM attachment_id for the new attachment.
5897             values['attachment_id'] = new_attachment_id
5898 
5899         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
5900                   "%(updates)s", {'volume_id': bdm.volume_id,
5901                                   'updates': values},
5902                   instance=instance)
5903         bdm.update(values)
5904         bdm.save()
5905 
5906         compute_utils.notify_about_volume_swap(
5907             context, instance, self.host,
5908             fields.NotificationPhase.END,
5909             old_volume_id, new_volume_id)
5910 
5911     @wrap_exception()
5912     def remove_volume_connection(self, context, volume_id, instance):
5913         """Remove the volume connection on this host
5914 
5915         Detach the volume from this instance on this host, and if this is
5916         the cinder v2 flow, call cinder to terminate the connection.
5917         """
5918         try:
5919             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
5920                     context, volume_id, instance.uuid)
5921             driver_bdm = driver_block_device.convert_volume(bdm)
5922             driver_bdm.driver_detach(context, instance,
5923                                      self.volume_api, self.driver)
5924             if bdm.attachment_id is None:
5925                 # cinder v2 api flow
5926                 connector = self.driver.get_volume_connector(instance)
5927                 self.volume_api.terminate_connection(context, volume_id,
5928                                                      connector)
5929         except exception.NotFound:
5930             pass
5931 
5932     @wrap_exception()
5933     @wrap_instance_event(prefix='compute')
5934     @wrap_instance_fault
5935     def attach_interface(self, context, instance, network_id, port_id,
5936                          requested_ip, tag):
5937         """Use hotplug to add an network adapter to an instance."""
5938         if not self.driver.capabilities.get('supports_attach_interface',
5939                                             False):
5940             raise exception.AttachInterfaceNotSupported(
5941                 instance_uuid=instance.uuid)
5942         if (tag and not
5943             self.driver.capabilities.get('supports_tagged_attach_interface',
5944                                          False)):
5945             raise exception.NetworkInterfaceTaggedAttachNotSupported()
5946 
5947         compute_utils.notify_about_instance_action(
5948             context, instance, self.host,
5949             action=fields.NotificationAction.INTERFACE_ATTACH,
5950             phase=fields.NotificationPhase.START)
5951 
5952         bind_host_id = self.driver.network_binding_host_id(context, instance)
5953         network_info = self.network_api.allocate_port_for_instance(
5954             context, instance, port_id, network_id, requested_ip,
5955             bind_host_id=bind_host_id, tag=tag)
5956         if len(network_info) != 1:
5957             LOG.error('allocate_port_for_instance returned %(ports)s '
5958                       'ports', {'ports': len(network_info)})
5959             # TODO(elod.illes): an instance.interface_attach.error notification
5960             # should be sent here
5961             raise exception.InterfaceAttachFailed(
5962                     instance_uuid=instance.uuid)
5963         image_meta = objects.ImageMeta.from_instance(instance)
5964 
5965         try:
5966             self.driver.attach_interface(context, instance, image_meta,
5967                                          network_info[0])
5968         except exception.NovaException as ex:
5969             port_id = network_info[0].get('id')
5970             LOG.warning("attach interface failed , try to deallocate "
5971                         "port %(port_id)s, reason: %(msg)s",
5972                         {'port_id': port_id, 'msg': ex},
5973                         instance=instance)
5974             try:
5975                 # NOTE(gibi): once we support attaching port that has resource
5976                 # request we have to make sure that such allocation is deleted
5977                 # during this cleanup.
5978                 self.network_api.deallocate_port_for_instance(
5979                     context, instance, port_id)
5980             except Exception:
5981                 LOG.warning("deallocate port %(port_id)s failed",
5982                             {'port_id': port_id}, instance=instance)
5983 
5984             tb = traceback.format_exc()
5985             compute_utils.notify_about_instance_action(
5986                 context, instance, self.host,
5987                 action=fields.NotificationAction.INTERFACE_ATTACH,
5988                 phase=fields.NotificationPhase.ERROR,
5989                 exception=ex, tb=tb)
5990 
5991             raise exception.InterfaceAttachFailed(
5992                 instance_uuid=instance.uuid)
5993 
5994         compute_utils.notify_about_instance_action(
5995             context, instance, self.host,
5996             action=fields.NotificationAction.INTERFACE_ATTACH,
5997             phase=fields.NotificationPhase.END)
5998 
5999         return network_info[0]
6000 
6001     @wrap_exception()
6002     @wrap_instance_event(prefix='compute')
6003     @wrap_instance_fault
6004     def detach_interface(self, context, instance, port_id):
6005         """Detach a network adapter from an instance."""
6006         network_info = instance.info_cache.network_info
6007         condemned = None
6008         for vif in network_info:
6009             if vif['id'] == port_id:
6010                 condemned = vif
6011                 break
6012         if condemned is None:
6013             raise exception.PortNotFound(_("Port %s is not "
6014                                            "attached") % port_id)
6015 
6016         compute_utils.notify_about_instance_action(
6017             context, instance, self.host,
6018             action=fields.NotificationAction.INTERFACE_DETACH,
6019             phase=fields.NotificationPhase.START)
6020 
6021         try:
6022             self.driver.detach_interface(context, instance, condemned)
6023         except exception.NovaException as ex:
6024             # If the instance was deleted before the interface was detached,
6025             # just log it at debug.
6026             log_level = (logging.DEBUG
6027                          if isinstance(ex, exception.InstanceNotFound)
6028                          else logging.WARNING)
6029             LOG.log(log_level,
6030                     "Detach interface failed, port_id=%(port_id)s, reason: "
6031                     "%(msg)s", {'port_id': port_id, 'msg': ex},
6032                     instance=instance)
6033             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
6034         else:
6035             try:
6036                 result = self.network_api.deallocate_port_for_instance(
6037                     context, instance, port_id)
6038                 __, port_allocation = result
6039             except Exception as ex:
6040                 with excutils.save_and_reraise_exception():
6041                     # Since this is a cast operation, log the failure for
6042                     # triage.
6043                     LOG.warning('Failed to deallocate port %(port_id)s '
6044                                 'for instance. Error: %(error)s',
6045                                 {'port_id': port_id, 'error': ex},
6046                                 instance=instance)
6047             else:
6048                 # Deallocate the resources in placement that is used by the
6049                 # detached port.
6050                 try:
6051                     client = self.reportclient
6052                     client.remove_resources_from_instance_allocation(
6053                         context, instance.uuid, port_allocation)
6054                 except Exception as ex:
6055                     with excutils.save_and_reraise_exception():
6056                         LOG.warning('Failed to remove resource allocation '
6057                                     'of port %(port_id)s of instance. Error: '
6058                                     '%(error)s',
6059                                     {'port_id': port_id, 'error': ex},
6060                                     instance=instance)
6061 
6062         compute_utils.notify_about_instance_action(
6063             context, instance, self.host,
6064             action=fields.NotificationAction.INTERFACE_DETACH,
6065             phase=fields.NotificationPhase.END)
6066 
6067     def _get_compute_info(self, context, host):
6068         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
6069             context, host)
6070 
6071     @wrap_exception()
6072     def check_instance_shared_storage(self, ctxt, instance, data):
6073         """Check if the instance files are shared
6074 
6075         :param ctxt: security context
6076         :param instance: dict of instance data
6077         :param data: result of driver.check_instance_shared_storage_local
6078 
6079         Returns True if instance disks located on shared storage and
6080         False otherwise.
6081         """
6082         return self.driver.check_instance_shared_storage_remote(ctxt, data)
6083 
6084     @wrap_exception()
6085     @wrap_instance_event(prefix='compute')
6086     @wrap_instance_fault
6087     def check_can_live_migrate_destination(self, ctxt, instance,
6088                                            block_migration, disk_over_commit):
6089         """Check if it is possible to execute live migration.
6090 
6091         This runs checks on the destination host, and then calls
6092         back to the source host to check the results.
6093 
6094         :param context: security context
6095         :param instance: dict of instance data
6096         :param block_migration: if true, prepare for block migration
6097                                 if None, calculate it in driver
6098         :param disk_over_commit: if true, allow disk over commit
6099                                  if None, ignore disk usage checking
6100         :returns: a dict containing migration info
6101         """
6102         src_compute_info = obj_base.obj_to_primitive(
6103             self._get_compute_info(ctxt, instance.host))
6104         dst_compute_info = obj_base.obj_to_primitive(
6105             self._get_compute_info(ctxt, CONF.host))
6106         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
6107             instance, src_compute_info, dst_compute_info,
6108             block_migration, disk_over_commit)
6109         LOG.debug('destination check data is %s', dest_check_data)
6110         try:
6111             migrate_data = self.compute_rpcapi.\
6112                                 check_can_live_migrate_source(ctxt, instance,
6113                                                               dest_check_data)
6114         finally:
6115             self.driver.cleanup_live_migration_destination_check(ctxt,
6116                     dest_check_data)
6117         return migrate_data
6118 
6119     @wrap_exception()
6120     @wrap_instance_event(prefix='compute')
6121     @wrap_instance_fault
6122     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
6123         """Check if it is possible to execute live migration.
6124 
6125         This checks if the live migration can succeed, based on the
6126         results from check_can_live_migrate_destination.
6127 
6128         :param ctxt: security context
6129         :param instance: dict of instance data
6130         :param dest_check_data: result of check_can_live_migrate_destination
6131         :returns: a dict containing migration info
6132         """
6133         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6134             ctxt, instance.uuid)
6135         is_volume_backed = compute_utils.is_volume_backed_instance(
6136             ctxt, instance, bdms)
6137         dest_check_data.is_volume_backed = is_volume_backed
6138         block_device_info = self._get_instance_block_device_info(
6139                             ctxt, instance, refresh_conn_info=False, bdms=bdms)
6140         result = self.driver.check_can_live_migrate_source(ctxt, instance,
6141                                                            dest_check_data,
6142                                                            block_device_info)
6143         LOG.debug('source check data is %s', result)
6144         return result
6145 
6146     @wrap_exception()
6147     @wrap_instance_event(prefix='compute')
6148     @wrap_instance_fault
6149     def pre_live_migration(self, context, instance, block_migration, disk,
6150                            migrate_data):
6151         """Preparations for live migration at dest host.
6152 
6153         :param context: security context
6154         :param instance: dict of instance data
6155         :param block_migration: if true, prepare for block migration
6156         :param disk: disk info of instance
6157         :param migrate_data: A dict or LiveMigrateData object holding data
6158                              required for live migration without shared
6159                              storage.
6160         :returns: migrate_data containing additional migration info
6161         """
6162         LOG.debug('pre_live_migration data is %s', migrate_data)
6163 
6164         migrate_data.old_vol_attachment_ids = {}
6165         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6166             context, instance.uuid)
6167         network_info = self.network_api.get_instance_nw_info(context, instance)
6168         self._notify_about_instance_usage(
6169             context, instance, "live_migration.pre.start",
6170             network_info=network_info)
6171         compute_utils.notify_about_instance_action(
6172             context, instance, self.host,
6173             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6174             phase=fields.NotificationPhase.START, bdms=bdms)
6175 
6176         connector = self.driver.get_volume_connector(instance)
6177         try:
6178             for bdm in bdms:
6179                 if bdm.is_volume and bdm.attachment_id is not None:
6180                     # This bdm uses the new cinder v3.44 API.
6181                     # We will create a new attachment for this
6182                     # volume on this migration destination host. The old
6183                     # attachment will be deleted on the source host
6184                     # when the migration succeeds. The old attachment_id
6185                     # is stored in dict with the key being the bdm.volume_id
6186                     # so it can be restored on rollback.
6187                     #
6188                     # Also note that attachment_update is not needed as we
6189                     # are providing the connector in the create call.
6190                     attach_ref = self.volume_api.attachment_create(
6191                         context, bdm.volume_id, bdm.instance_uuid,
6192                         connector=connector, mountpoint=bdm.device_name)
6193 
6194                     # save current attachment so we can detach it on success,
6195                     # or restore it on a rollback.
6196                     # NOTE(mdbooth): This data is no longer used by the source
6197                     # host since change I0390c9ff. We can't remove it until we
6198                     # are sure the source host has been upgraded.
6199                     migrate_data.old_vol_attachment_ids[bdm.volume_id] = \
6200                         bdm.attachment_id
6201 
6202                     # update the bdm with the new attachment_id.
6203                     bdm.attachment_id = attach_ref['id']
6204                     bdm.save()
6205 
6206             block_device_info = self._get_instance_block_device_info(
6207                                 context, instance, refresh_conn_info=True,
6208                                 bdms=bdms)
6209 
6210             # The driver pre_live_migration will plug vifs on the host. We call
6211             # plug_vifs before calling ensure_filtering_rules_for_instance, to
6212             # ensure bridge is set up.
6213             migrate_data = self.driver.pre_live_migration(context,
6214                                            instance,
6215                                            block_device_info,
6216                                            network_info,
6217                                            disk,
6218                                            migrate_data)
6219             LOG.debug('driver pre_live_migration data is %s', migrate_data)
6220             # driver.pre_live_migration is what plugs vifs on the destination
6221             # host so now we can set the wait_for_vif_plugged flag in the
6222             # migrate_data object which the source compute will use to
6223             # determine if it should wait for a 'network-vif-plugged' event
6224             # from neutron before starting the actual guest transfer in the
6225             # hypervisor
6226             migrate_data.wait_for_vif_plugged = (
6227                 CONF.compute.live_migration_wait_for_vif_plug)
6228 
6229             # NOTE(tr3buchet): setup networks on destination host
6230             self.network_api.setup_networks_on_host(context, instance,
6231                                                              self.host)
6232 
6233             # Creating filters to hypervisors and firewalls.
6234             # An example is that nova-instance-instance-xxx,
6235             # which is written to libvirt.xml(Check "virsh nwfilter-list")
6236             # This nwfilter is necessary on the destination host.
6237             # In addition, this method is creating filtering rule
6238             # onto destination host.
6239             self.driver.ensure_filtering_rules_for_instance(instance,
6240                                                 network_info)
6241         except Exception:
6242             # If we raise, migrate_data with the updated attachment ids
6243             # will not be returned to the source host for rollback.
6244             # So we need to rollback new attachments here.
6245             with excutils.save_and_reraise_exception():
6246                 old_attachments = migrate_data.old_vol_attachment_ids
6247                 for bdm in bdms:
6248                     if (bdm.is_volume and bdm.attachment_id is not None and
6249                             bdm.volume_id in old_attachments):
6250                         self.volume_api.attachment_delete(context,
6251                                                           bdm.attachment_id)
6252                         bdm.attachment_id = old_attachments[bdm.volume_id]
6253                         bdm.save()
6254 
6255         # Volume connections are complete, tell cinder that all the
6256         # attachments have completed.
6257         for bdm in bdms:
6258             if bdm.is_volume and bdm.attachment_id is not None:
6259                 self.volume_api.attachment_complete(context,
6260                                                     bdm.attachment_id)
6261 
6262         self._notify_about_instance_usage(
6263                      context, instance, "live_migration.pre.end",
6264                      network_info=network_info)
6265         compute_utils.notify_about_instance_action(
6266             context, instance, self.host,
6267             action=fields.NotificationAction.LIVE_MIGRATION_PRE,
6268             phase=fields.NotificationPhase.END, bdms=bdms)
6269 
6270         LOG.debug('pre_live_migration result data is %s', migrate_data)
6271         return migrate_data
6272 
6273     @staticmethod
6274     def _neutron_failed_live_migration_callback(event_name, instance):
6275         msg = ('Neutron reported failure during live migration '
6276                'with %(event)s for instance %(uuid)s')
6277         msg_args = {'event': event_name, 'uuid': instance.uuid}
6278         if CONF.vif_plugging_is_fatal:
6279             raise exception.VirtualInterfacePlugException(msg % msg_args)
6280         LOG.error(msg, msg_args)
6281 
6282     @staticmethod
6283     def _get_neutron_events_for_live_migration(instance):
6284         # We don't generate events if CONF.vif_plugging_timeout=0
6285         # meaning that the operator disabled using them.
6286         if CONF.vif_plugging_timeout and utils.is_neutron():
6287             return [('network-vif-plugged', vif['id'])
6288                     for vif in instance.get_network_info()]
6289         else:
6290             return []
6291 
6292     def _cleanup_pre_live_migration(self, context, dest, instance,
6293                                     migration, migrate_data):
6294         """Helper method for when pre_live_migration fails
6295 
6296         Sets the migration status to "error" and rolls back the live migration
6297         setup on the destination host.
6298 
6299         :param context: The user request context.
6300         :type context: nova.context.RequestContext
6301         :param dest: The live migration destination hostname.
6302         :type dest: str
6303         :param instance: The instance being live migrated.
6304         :type instance: nova.objects.Instance
6305         :param migration: The migration record tracking this live migration.
6306         :type migration: nova.objects.Migration
6307         :param migrate_data: Data about the live migration, populated from
6308                              the destination host.
6309         :type migrate_data: Subclass of nova.objects.LiveMigrateData
6310         """
6311         self._set_migration_status(migration, 'error')
6312         # Make sure we set this for _rollback_live_migration()
6313         # so it can find it, as expected if it was called later
6314         migrate_data.migration = migration
6315         self._rollback_live_migration(context, instance, dest,
6316                                       migrate_data)
6317 
6318     def _do_live_migration(self, context, dest, instance, block_migration,
6319                            migration, migrate_data):
6320         # NOTE(danms): We should enhance the RT to account for migrations
6321         # and use the status field to denote when the accounting has been
6322         # done on source/destination. For now, this is just here for status
6323         # reporting
6324         self._set_migration_status(migration, 'preparing')
6325         source_bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6326                 context, instance.uuid)
6327 
6328         class _BreakWaitForInstanceEvent(Exception):
6329             """Used as a signal to stop waiting for the network-vif-plugged
6330             event when we discover that
6331             [compute]/live_migration_wait_for_vif_plug is not set on the
6332             destination.
6333             """
6334             pass
6335 
6336         events = self._get_neutron_events_for_live_migration(instance)
6337         try:
6338             if ('block_migration' in migrate_data and
6339                     migrate_data.block_migration):
6340                 block_device_info = self._get_instance_block_device_info(
6341                     context, instance, bdms=source_bdms)
6342                 disk = self.driver.get_instance_disk_info(
6343                     instance, block_device_info=block_device_info)
6344             else:
6345                 disk = None
6346 
6347             deadline = CONF.vif_plugging_timeout
6348             error_cb = self._neutron_failed_live_migration_callback
6349             # In order to avoid a race with the vif plugging that the virt
6350             # driver does on the destination host, we register our events
6351             # to wait for before calling pre_live_migration. Then if the
6352             # dest host reports back that we shouldn't wait, we can break
6353             # out of the context manager using _BreakWaitForInstanceEvent.
6354             with self.virtapi.wait_for_instance_event(
6355                     instance, events, deadline=deadline,
6356                     error_callback=error_cb):
6357                 with timeutils.StopWatch() as timer:
6358                     migrate_data = self.compute_rpcapi.pre_live_migration(
6359                         context, instance,
6360                         block_migration, disk, dest, migrate_data)
6361                 LOG.info('Took %0.2f seconds for pre_live_migration on '
6362                          'destination host %s.',
6363                          timer.elapsed(), dest, instance=instance)
6364                 wait_for_vif_plugged = (
6365                     'wait_for_vif_plugged' in migrate_data and
6366                     migrate_data.wait_for_vif_plugged)
6367                 if events and not wait_for_vif_plugged:
6368                     raise _BreakWaitForInstanceEvent
6369         except _BreakWaitForInstanceEvent:
6370             if events:
6371                 LOG.debug('Not waiting for events after pre_live_migration: '
6372                           '%s. ', events, instance=instance)
6373             # This is a bit weird, but we need to clear sys.exc_info() so that
6374             # oslo.log formatting does not inadvertently use it later if an
6375             # error message is logged without an explicit exc_info. This is
6376             # only a problem with python 2.
6377             if six.PY2:
6378                 sys.exc_clear()
6379         except exception.VirtualInterfacePlugException:
6380             with excutils.save_and_reraise_exception():
6381                 LOG.exception('Failed waiting for network virtual interfaces '
6382                               'to be plugged on the destination host %s.',
6383                               dest, instance=instance)
6384                 self._cleanup_pre_live_migration(
6385                     context, dest, instance, migration, migrate_data)
6386         except eventlet.timeout.Timeout:
6387             # We only get here if wait_for_vif_plugged is True which means
6388             # live_migration_wait_for_vif_plug=True on the destination host.
6389             msg = (
6390                 'Timed out waiting for events: %(events)s. If these timeouts '
6391                 'are a persistent issue it could mean the networking backend '
6392                 'on host %(dest)s does not support sending these events '
6393                 'unless there are port binding host changes which does not '
6394                 'happen at this point in the live migration process. You may '
6395                 'need to disable the live_migration_wait_for_vif_plug option '
6396                 'on host %(dest)s.')
6397             subs = {'events': events, 'dest': dest}
6398             LOG.warning(msg, subs, instance=instance)
6399             if CONF.vif_plugging_is_fatal:
6400                 self._cleanup_pre_live_migration(
6401                     context, dest, instance, migration, migrate_data)
6402                 raise exception.MigrationError(reason=msg % subs)
6403         except Exception:
6404             with excutils.save_and_reraise_exception():
6405                 LOG.exception('Pre live migration failed at %s',
6406                               dest, instance=instance)
6407                 self._cleanup_pre_live_migration(
6408                     context, dest, instance, migration, migrate_data)
6409 
6410         # NOTE(Kevin_Zheng): Pop the migration from the waiting queue
6411         # if it exist in the queue, then we are good to moving on, if
6412         # not, some other process must have aborted it, then we should
6413         # rollback.
6414         try:
6415             self._waiting_live_migrations.pop(instance.uuid)
6416         except KeyError:
6417             LOG.debug('Migration %s aborted by another process, rollback.',
6418                       migration.uuid, instance=instance)
6419             migrate_data.migration = migration
6420             self._rollback_live_migration(context, instance, dest,
6421                                           migrate_data, 'cancelled')
6422             self._notify_live_migrate_abort_end(context, instance)
6423             return
6424 
6425         self._set_migration_status(migration, 'running')
6426         if migrate_data:
6427             migrate_data.migration = migration
6428 
6429         # NOTE(mdbooth): pre_live_migration will update connection_info and
6430         # attachment_id on all volume BDMS to reflect the new destination
6431         # host attachment. We fetch BDMs before that to retain connection_info
6432         # and attachment_id relating to the source host for post migration
6433         # cleanup.
6434         post_live_migration = functools.partial(self._post_live_migration,
6435                                                 source_bdms=source_bdms)
6436 
6437         LOG.debug('live_migration data is %s', migrate_data)
6438         try:
6439             self.driver.live_migration(context, instance, dest,
6440                                        post_live_migration,
6441                                        self._rollback_live_migration,
6442                                        block_migration, migrate_data)
6443         except Exception:
6444             LOG.exception('Live migration failed.', instance=instance)
6445             with excutils.save_and_reraise_exception():
6446                 # Put instance and migration into error state,
6447                 # as its almost certainly too late to rollback
6448                 self._set_migration_status(migration, 'error')
6449                 # first refresh instance as it may have got updated by
6450                 # post_live_migration_at_destination
6451                 instance.refresh()
6452                 self._set_instance_obj_error_state(context, instance,
6453                                                    clean_task_state=True)
6454 
6455     @wrap_exception()
6456     @wrap_instance_event(prefix='compute')
6457     @wrap_instance_fault
6458     def live_migration(self, context, dest, instance, block_migration,
6459                        migration, migrate_data):
6460         """Executing live migration.
6461 
6462         :param context: security context
6463         :param dest: destination host
6464         :param instance: a nova.objects.instance.Instance object
6465         :param block_migration: if true, prepare for block migration
6466         :param migration: an nova.objects.Migration object
6467         :param migrate_data: implementation specific params
6468 
6469         """
6470         self._set_migration_status(migration, 'queued')
6471         # NOTE(Kevin_Zheng): Submit the live_migration job to the pool and
6472         # put the returned Future object into dict mapped with migration.uuid
6473         # in order to be able to track and abort it in the future.
6474         self._waiting_live_migrations[instance.uuid] = (None, None)
6475         try:
6476             future = self._live_migration_executor.submit(
6477                 self._do_live_migration, context, dest, instance,
6478                 block_migration, migration, migrate_data)
6479             self._waiting_live_migrations[instance.uuid] = (migration, future)
6480         except RuntimeError:
6481             # GreenThreadPoolExecutor.submit will raise RuntimeError if the
6482             # pool is shutdown, which happens in
6483             # _cleanup_live_migrations_in_pool.
6484             LOG.info('Migration %s failed to submit as the compute service '
6485                      'is shutting down.', migration.uuid, instance=instance)
6486             self._set_migration_status(migration, 'error')
6487             raise exception.LiveMigrationNotSubmitted(
6488                 migration_uuid=migration.uuid, instance_uuid=instance.uuid)
6489 
6490     @wrap_exception()
6491     @wrap_instance_event(prefix='compute')
6492     @wrap_instance_fault
6493     def live_migration_force_complete(self, context, instance):
6494         """Force live migration to complete.
6495 
6496         :param context: Security context
6497         :param instance: The instance that is being migrated
6498         """
6499 
6500         self._notify_about_instance_usage(
6501             context, instance, 'live.migration.force.complete.start')
6502         compute_utils.notify_about_instance_action(
6503             context, instance, self.host,
6504             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6505             phase=fields.NotificationPhase.START)
6506         self.driver.live_migration_force_complete(instance)
6507         self._notify_about_instance_usage(
6508             context, instance, 'live.migration.force.complete.end')
6509         compute_utils.notify_about_instance_action(
6510             context, instance, self.host,
6511             action=fields.NotificationAction.LIVE_MIGRATION_FORCE_COMPLETE,
6512             phase=fields.NotificationPhase.END)
6513 
6514     def _notify_live_migrate_abort_end(self, context, instance):
6515         self._notify_about_instance_usage(
6516             context, instance, 'live.migration.abort.end')
6517         compute_utils.notify_about_instance_action(
6518             context, instance, self.host,
6519             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6520             phase=fields.NotificationPhase.END)
6521 
6522     @wrap_exception()
6523     @wrap_instance_event(prefix='compute')
6524     @wrap_instance_fault
6525     def live_migration_abort(self, context, instance, migration_id):
6526         """Abort an in-progress live migration.
6527 
6528         :param context: Security context
6529         :param instance: The instance that is being migrated
6530         :param migration_id: ID of in-progress live migration
6531 
6532         """
6533         self._notify_about_instance_usage(
6534             context, instance, 'live.migration.abort.start')
6535         compute_utils.notify_about_instance_action(
6536             context, instance, self.host,
6537             action=fields.NotificationAction.LIVE_MIGRATION_ABORT,
6538             phase=fields.NotificationPhase.START)
6539         # NOTE(Kevin_Zheng): Pop the migration out from the queue, this might
6540         # lead to 3 scenarios:
6541         # 1. The selected migration is still in queue, and the future.cancel()
6542         #    succeed, then the abort action is succeed, mark the migration
6543         #    status to 'cancelled'.
6544         # 2. The selected migration is still in queue, but the future.cancel()
6545         #    failed, then the _do_live_migration() has started executing, and
6546         #    the migration status is 'preparing', then we just pop it from the
6547         #    queue, and the migration process will handle it later. And the
6548         #    migration status couldn't be 'running' in this scenario because
6549         #    if _do_live_migration has started executing and we've already
6550         #    popped it from the queue and set the migration status to
6551         #    'running' at this point, popping it here will raise KeyError at
6552         #    which point we check if it's running and if so, we abort the old
6553         #    way.
6554         # 3. The selected migration is not in the queue, then the migration
6555         #    status is 'running', let the driver handle it.
6556         try:
6557             migration, future = (
6558                 self._waiting_live_migrations.pop(instance.uuid))
6559             if future and future.cancel():
6560                 # If we got here, we've successfully aborted the queued
6561                 # migration and _do_live_migration won't run so we need
6562                 # to set the migration status to cancelled and send the
6563                 # notification. If Future.cancel() fails, it means
6564                 # _do_live_migration is running and the migration status
6565                 # is preparing, and _do_live_migration() itself will attempt
6566                 # to pop the queued migration, hit a KeyError, and rollback,
6567                 # set the migration to cancelled and send the
6568                 # live.migration.abort.end notification.
6569                 self._set_migration_status(migration, 'cancelled')
6570         except KeyError:
6571             migration = objects.Migration.get_by_id(context, migration_id)
6572             if migration.status != 'running':
6573                 raise exception.InvalidMigrationState(
6574                     migration_id=migration_id, instance_uuid=instance.uuid,
6575                     state=migration.status, method='abort live migration')
6576             self.driver.live_migration_abort(instance)
6577         self._notify_live_migrate_abort_end(context, instance)
6578 
6579     def _live_migration_cleanup_flags(self, migrate_data):
6580         """Determine whether disks or instance path need to be cleaned up after
6581         live migration (at source on success, at destination on rollback)
6582 
6583         Block migration needs empty image at destination host before migration
6584         starts, so if any failure occurs, any empty images has to be deleted.
6585 
6586         Also Volume backed live migration w/o shared storage needs to delete
6587         newly created instance-xxx dir on the destination as a part of its
6588         rollback process
6589 
6590         :param migrate_data: implementation specific data
6591         :returns: (bool, bool) -- do_cleanup, destroy_disks
6592         """
6593         # NOTE(pkoniszewski): block migration specific params are set inside
6594         # migrate_data objects for drivers that expose block live migration
6595         # information (i.e. Libvirt, Xenapi and HyperV). For other drivers
6596         # cleanup is not needed.
6597         do_cleanup = False
6598         destroy_disks = False
6599         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
6600             # No instance booting at source host, but instance dir
6601             # must be deleted for preparing next block migration
6602             # must be deleted for preparing next live migration w/o shared
6603             # storage
6604             do_cleanup = not migrate_data.is_shared_instance_path
6605             destroy_disks = not migrate_data.is_shared_block_storage
6606         elif isinstance(migrate_data, migrate_data_obj.XenapiLiveMigrateData):
6607             do_cleanup = migrate_data.block_migration
6608             destroy_disks = migrate_data.block_migration
6609         elif isinstance(migrate_data, migrate_data_obj.HyperVLiveMigrateData):
6610             # NOTE(claudiub): We need to cleanup any zombie Planned VM.
6611             do_cleanup = True
6612             destroy_disks = not migrate_data.is_shared_instance_path
6613 
6614         return (do_cleanup, destroy_disks)
6615 
6616     @wrap_exception()
6617     @wrap_instance_fault
6618     def _post_live_migration(self, ctxt, instance, dest,
6619                              block_migration=False, migrate_data=None,
6620                              source_bdms=None):
6621         """Post operations for live migration.
6622 
6623         This method is called from live_migration
6624         and mainly updating database record.
6625 
6626         :param ctxt: security context
6627         :param instance: instance dict
6628         :param dest: destination host
6629         :param block_migration: if true, prepare for block migration
6630         :param migrate_data: if not None, it is a dict which has data
6631         :param source_bdms: BDMs prior to modification by the destination
6632                             compute host. Set by _do_live_migration and not
6633                             part of the callback interface, so this is never
6634                             None
6635         required for live migration without shared storage
6636 
6637         """
6638         LOG.info('_post_live_migration() is started..',
6639                  instance=instance)
6640 
6641         # Cleanup source host post live-migration
6642         block_device_info = self._get_instance_block_device_info(
6643                             ctxt, instance, bdms=source_bdms)
6644         self.driver.post_live_migration(ctxt, instance, block_device_info,
6645                                         migrate_data)
6646 
6647         # Detaching volumes.
6648         connector = self.driver.get_volume_connector(instance)
6649         for bdm in source_bdms:
6650             if bdm.is_volume:
6651                 # Detaching volumes is a call to an external API that can fail.
6652                 # If it does, we need to handle it gracefully so that the call
6653                 # to post_live_migration_at_destination - where we set instance
6654                 # host and task state - still happens. We need to rethink the
6655                 # current approach of setting instance host and task state
6656                 # AFTER a whole bunch of things that could fail in unhandled
6657                 # ways, but that is left as a TODO(artom).
6658                 try:
6659                     if bdm.attachment_id is None:
6660                         # Prior to cinder v3.44:
6661                         # We don't want to actually mark the volume detached,
6662                         # or delete the bdm, just remove the connection from
6663                         # this host.
6664                         #
6665                         # remove the volume connection without detaching from
6666                         # hypervisor because the instance is not running
6667                         # anymore on the current host
6668                         self.volume_api.terminate_connection(ctxt,
6669                                                              bdm.volume_id,
6670                                                              connector)
6671                     else:
6672                         # cinder v3.44 api flow - delete the old attachment
6673                         # for the source host
6674                         self.volume_api.attachment_delete(ctxt,
6675                                                           bdm.attachment_id)
6676 
6677                 except Exception as e:
6678                     if bdm.attachment_id is None:
6679                         LOG.error('Connection for volume %s not terminated on '
6680                                   'source host %s during post_live_migration: '
6681                                    '%s', bdm.volume_id, self.host,
6682                                    six.text_type(e), instance=instance)
6683                     else:
6684                         LOG.error('Volume attachment %s not deleted on source '
6685                                   'host %s during post_live_migration: %s',
6686                                   bdm.attachment_id, self.host,
6687                                   six.text_type(e), instance=instance)
6688 
6689         # Releasing vlan.
6690         # (not necessary in current implementation?)
6691 
6692         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
6693 
6694         self._notify_about_instance_usage(ctxt, instance,
6695                                           "live_migration._post.start",
6696                                           network_info=network_info)
6697         compute_utils.notify_about_instance_action(
6698             ctxt, instance, self.host,
6699             action=fields.NotificationAction.LIVE_MIGRATION_POST,
6700             phase=fields.NotificationPhase.START)
6701         # Releasing security group ingress rule.
6702         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
6703                   instance=instance)
6704         self.driver.unfilter_instance(instance,
6705                                       network_info)
6706 
6707         migration = {'source_compute': self.host,
6708                      'dest_compute': dest, }
6709         # For neutron, migrate_instance_start will activate the destination
6710         # host port bindings, if there are any created by conductor before live
6711         # migration started.
6712         self.network_api.migrate_instance_start(ctxt,
6713                                                 instance,
6714                                                 migration)
6715 
6716         destroy_vifs = False
6717         try:
6718             # It's possible that the vif type changed on the destination
6719             # host and is already bound and active, so we need to use the
6720             # stashed source vifs in migrate_data.vifs (if present) to unplug
6721             # on the source host.
6722             unplug_nw_info = network_info
6723             if migrate_data and 'vifs' in migrate_data:
6724                 nw_info = []
6725                 for migrate_vif in migrate_data.vifs:
6726                     nw_info.append(migrate_vif.source_vif)
6727                 unplug_nw_info = network_model.NetworkInfo.hydrate(nw_info)
6728                 LOG.debug('Calling driver.post_live_migration_at_source '
6729                           'with original source VIFs from migrate_data: %s',
6730                           unplug_nw_info, instance=instance)
6731             self.driver.post_live_migration_at_source(ctxt, instance,
6732                                                       unplug_nw_info)
6733         except NotImplementedError as ex:
6734             LOG.debug(ex, instance=instance)
6735             # For all hypervisors other than libvirt, there is a possibility
6736             # they are unplugging networks from source node in the cleanup
6737             # method
6738             destroy_vifs = True
6739 
6740         # NOTE(danms): Save source node before calling post method on
6741         # destination, which will update it
6742         source_node = instance.node
6743 
6744         # Define domain at destination host, without doing it,
6745         # pause/suspend/terminate do not work.
6746         post_at_dest_success = True
6747         try:
6748             self.compute_rpcapi.post_live_migration_at_destination(ctxt,
6749                     instance, block_migration, dest)
6750         except Exception as error:
6751             post_at_dest_success = False
6752             # We don't want to break _post_live_migration() if
6753             # post_live_migration_at_destination() fails as it should never
6754             # affect cleaning up source node.
6755             LOG.exception("Post live migration at destination %s failed",
6756                           dest, instance=instance, error=error)
6757 
6758         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6759                 migrate_data)
6760 
6761         if do_cleanup:
6762             LOG.debug('Calling driver.cleanup from _post_live_migration',
6763                       instance=instance)
6764             self.driver.cleanup(ctxt, instance, unplug_nw_info,
6765                                 destroy_disks=destroy_disks,
6766                                 migrate_data=migrate_data,
6767                                 destroy_vifs=destroy_vifs)
6768 
6769         self.instance_events.clear_events_for_instance(instance)
6770 
6771         # NOTE(timello): make sure we update available resources on source
6772         # host even before next periodic task.
6773         self.update_available_resource(ctxt)
6774 
6775         self._update_scheduler_instance_info(ctxt, instance)
6776         self._notify_about_instance_usage(ctxt, instance,
6777                                           "live_migration._post.end",
6778                                           network_info=network_info)
6779         compute_utils.notify_about_instance_action(
6780             ctxt, instance, self.host,
6781             action=fields.NotificationAction.LIVE_MIGRATION_POST,
6782             phase=fields.NotificationPhase.END)
6783         if post_at_dest_success:
6784             LOG.info('Migrating instance to %s finished successfully.',
6785                      dest, instance=instance)
6786 
6787         self._clean_instance_console_tokens(ctxt, instance)
6788         if migrate_data and migrate_data.obj_attr_is_set('migration'):
6789             migrate_data.migration.status = 'completed'
6790             migrate_data.migration.save()
6791             self._delete_allocation_after_move(ctxt,
6792                                                instance,
6793                                                migrate_data.migration)
6794         else:
6795             # We didn't have data on a migration, which means we can't
6796             # look up to see if we had new-style migration-based
6797             # allocations. This should really only happen in cases of
6798             # a buggy virt driver. Log a warning so we know it happened.
6799             LOG.warning('Live migration ended with no migrate_data '
6800                         'record. Unable to clean up migration-based '
6801                         'allocations for node %s which is almost certainly '
6802                         'not an expected situation.', source_node,
6803                         instance=instance)
6804 
6805     def _consoles_enabled(self):
6806         """Returns whether a console is enable."""
6807         return (CONF.vnc.enabled or CONF.spice.enabled or
6808                 CONF.rdp.enabled or CONF.serial_console.enabled or
6809                 CONF.mks.enabled)
6810 
6811     def _clean_instance_console_tokens(self, ctxt, instance):
6812         """Clean console tokens stored for an instance."""
6813         # If the database backend isn't in use, don't bother trying to clean
6814         # tokens. The database backend is not supported for cells v1.
6815         if not CONF.cells.enable and self._consoles_enabled():
6816             objects.ConsoleAuthToken.\
6817                 clean_console_auths_for_instance(ctxt, instance.uuid)
6818 
6819     @wrap_exception()
6820     @wrap_instance_event(prefix='compute')
6821     @wrap_instance_fault
6822     def post_live_migration_at_destination(self, context, instance,
6823                                            block_migration):
6824         """Post operations for live migration .
6825 
6826         :param context: security context
6827         :param instance: Instance dict
6828         :param block_migration: if true, prepare for block migration
6829 
6830         """
6831         LOG.info('Post operation of migration started',
6832                  instance=instance)
6833 
6834         # NOTE(tr3buchet): setup networks on destination host
6835         #                  this is called a second time because
6836         #                  multi_host does not create the bridge in
6837         #                  plug_vifs
6838         # NOTE(mriedem): This is a no-op for neutron.
6839         self.network_api.setup_networks_on_host(context, instance,
6840                                                          self.host)
6841         migration = {'source_compute': instance.host,
6842                      'dest_compute': self.host, }
6843         self.network_api.migrate_instance_finish(context,
6844                                                  instance,
6845                                                  migration)
6846 
6847         network_info = self.network_api.get_instance_nw_info(context, instance)
6848         self._notify_about_instance_usage(
6849                      context, instance, "live_migration.post.dest.start",
6850                      network_info=network_info)
6851         compute_utils.notify_about_instance_action(context, instance,
6852                 self.host,
6853                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6854                 phase=fields.NotificationPhase.START)
6855         block_device_info = self._get_instance_block_device_info(context,
6856                                                                  instance)
6857 
6858         try:
6859             self.driver.post_live_migration_at_destination(
6860                 context, instance, network_info, block_migration,
6861                 block_device_info)
6862         except Exception:
6863             with excutils.save_and_reraise_exception():
6864                 instance.vm_state = vm_states.ERROR
6865                 LOG.error('Unexpected error during post live migration at '
6866                           'destination host.', instance=instance)
6867         finally:
6868             # Restore instance state and update host
6869             current_power_state = self._get_power_state(context, instance)
6870             node_name = None
6871             prev_host = instance.host
6872             try:
6873                 compute_node = self._get_compute_info(context, self.host)
6874                 node_name = compute_node.hypervisor_hostname
6875             except exception.ComputeHostNotFound:
6876                 LOG.exception('Failed to get compute_info for %s', self.host)
6877             finally:
6878                 instance.host = self.host
6879                 instance.power_state = current_power_state
6880                 instance.task_state = None
6881                 instance.node = node_name
6882                 instance.progress = 0
6883                 instance.save(expected_task_state=task_states.MIGRATING)
6884 
6885         # NOTE(tr3buchet): tear down networks on source host (nova-net)
6886         # NOTE(mriedem): For neutron, this will delete any inactive source
6887         # host port bindings.
6888         try:
6889             self.network_api.setup_networks_on_host(context, instance,
6890                                                     prev_host, teardown=True)
6891         except exception.PortBindingDeletionFailed as e:
6892             # Removing the inactive port bindings from the source host is not
6893             # critical so just log an error but don't fail.
6894             LOG.error('Network cleanup failed for source host %s during post '
6895                       'live migration. You may need to manually clean up '
6896                       'resources in the network service. Error: %s',
6897                       prev_host, six.text_type(e))
6898         # NOTE(vish): this is necessary to update dhcp for nova-network
6899         # NOTE(mriedem): This is a no-op for neutron.
6900         self.network_api.setup_networks_on_host(context, instance, self.host)
6901         self._notify_about_instance_usage(
6902                      context, instance, "live_migration.post.dest.end",
6903                      network_info=network_info)
6904         compute_utils.notify_about_instance_action(context, instance,
6905                 self.host,
6906                 action=fields.NotificationAction.LIVE_MIGRATION_POST_DEST,
6907                 phase=fields.NotificationPhase.END)
6908 
6909     @wrap_exception()
6910     @wrap_instance_fault
6911     def _rollback_live_migration(self, context, instance,
6912                                  dest, migrate_data=None,
6913                                  migration_status='error'):
6914         """Recovers Instance/volume state from migrating -> running.
6915 
6916         :param context: security context
6917         :param instance: nova.objects.instance.Instance object
6918         :param dest:
6919             This method is called from live migration src host.
6920             This param specifies destination host.
6921         :param migrate_data:
6922             if not none, contains implementation specific data.
6923         :param migration_status:
6924             Contains the status we want to set for the migration object
6925 
6926         """
6927         if (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
6928               migrate_data.obj_attr_is_set('migration')):
6929             migration = migrate_data.migration
6930         else:
6931             migration = None
6932 
6933         if migration:
6934             # Remove allocations created in Placement for the dest node.
6935             # If migration is None, the virt driver didn't pass it which is
6936             # a bug.
6937             self._revert_allocation(context, instance, migration)
6938         else:
6939             LOG.error('Unable to revert allocations during live migration '
6940                       'rollback; compute driver did not provide migrate_data',
6941                       instance=instance)
6942 
6943         instance.task_state = None
6944         instance.progress = 0
6945         instance.save(expected_task_state=[task_states.MIGRATING])
6946 
6947         # NOTE(tr3buchet): setup networks on source host (really it's re-setup
6948         #                  for nova-network)
6949         # NOTE(mriedem): This is a no-op for neutron.
6950         self.network_api.setup_networks_on_host(context, instance, self.host)
6951 
6952         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6953                 context, instance.uuid)
6954         for bdm in bdms:
6955             if bdm.is_volume:
6956                 # remove the connection on the destination host
6957                 self.compute_rpcapi.remove_volume_connection(
6958                         context, instance, bdm.volume_id, dest)
6959 
6960                 if bdm.attachment_id:
6961                     # 3.44 cinder api flow. Set the bdm's
6962                     # attachment_id to the old attachment of the source
6963                     # host. If old_attachments is not there, then
6964                     # there was an error before the new attachment was made.
6965                     old_attachments = migrate_data.old_vol_attachment_ids \
6966                         if 'old_vol_attachment_ids' in migrate_data else None
6967                     if old_attachments and bdm.volume_id in old_attachments:
6968                         self.volume_api.attachment_delete(context,
6969                                                           bdm.attachment_id)
6970                         bdm.attachment_id = old_attachments[bdm.volume_id]
6971                         bdm.save()
6972 
6973         self._notify_about_instance_usage(context, instance,
6974                                           "live_migration._rollback.start")
6975         compute_utils.notify_about_instance_action(context, instance,
6976                 self.host,
6977                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
6978                 phase=fields.NotificationPhase.START,
6979                 bdms=bdms)
6980 
6981         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
6982                 migrate_data)
6983 
6984         if do_cleanup:
6985             self.compute_rpcapi.rollback_live_migration_at_destination(
6986                     context, instance, dest, destroy_disks=destroy_disks,
6987                     migrate_data=migrate_data)
6988         elif utils.is_neutron():
6989             # The port binding profiles need to be cleaned up.
6990             with errors_out_migration_ctxt(migration):
6991                 try:
6992                     # This call will delete any inactive destination host
6993                     # port bindings.
6994                     self.network_api.setup_networks_on_host(
6995                         context, instance, host=dest, teardown=True)
6996                 except exception.PortBindingDeletionFailed as e:
6997                     # Removing the inactive port bindings from the destination
6998                     # host is not critical so just log an error but don't fail.
6999                     LOG.error(
7000                         'Network cleanup failed for destination host %s '
7001                         'during live migration rollback. You may need to '
7002                         'manually clean up resources in the network service. '
7003                         'Error: %s', dest, six.text_type(e))
7004                 except Exception:
7005                     with excutils.save_and_reraise_exception():
7006                         LOG.exception(
7007                             'An error occurred while cleaning up networking '
7008                             'during live migration rollback.',
7009                             instance=instance)
7010 
7011         self._notify_about_instance_usage(context, instance,
7012                                           "live_migration._rollback.end")
7013         compute_utils.notify_about_instance_action(context, instance,
7014                 self.host,
7015                 action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK,
7016                 phase=fields.NotificationPhase.END,
7017                 bdms=bdms)
7018 
7019         self._set_migration_status(migration, migration_status)
7020 
7021     @wrap_exception()
7022     @wrap_instance_event(prefix='compute')
7023     @wrap_instance_fault
7024     def rollback_live_migration_at_destination(self, context, instance,
7025                                                destroy_disks,
7026                                                migrate_data):
7027         """Cleaning up image directory that is created pre_live_migration.
7028 
7029         :param context: security context
7030         :param instance: a nova.objects.instance.Instance object sent over rpc
7031         :param destroy_disks: whether to destroy volumes or not
7032         :param migrate_data: contains migration info
7033         """
7034         network_info = self.network_api.get_instance_nw_info(context, instance)
7035         self._notify_about_instance_usage(
7036                       context, instance, "live_migration.rollback.dest.start",
7037                       network_info=network_info)
7038         compute_utils.notify_about_instance_action(
7039             context, instance, self.host,
7040             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
7041             phase=fields.NotificationPhase.START)
7042         try:
7043             # NOTE(tr3buchet): tear down networks on dest host (nova-net)
7044             # NOTE(mriedem): For neutron, this call will delete any
7045             # destination host port bindings.
7046             # TODO(mriedem): We should eventually remove this call from
7047             # this method (rollback_live_migration_at_destination) since this
7048             # method is only called conditionally based on whether or not the
7049             # instance is running on shared storage. _rollback_live_migration
7050             # already calls this method for neutron if we are running on
7051             # shared storage.
7052             self.network_api.setup_networks_on_host(context, instance,
7053                                                     self.host, teardown=True)
7054         except exception.PortBindingDeletionFailed as e:
7055             # Removing the inactive port bindings from the destination
7056             # host is not critical so just log an error but don't fail.
7057             LOG.error(
7058                 'Network cleanup failed for destination host %s '
7059                 'during live migration rollback. You may need to '
7060                 'manually clean up resources in the network service. '
7061                 'Error: %s', self.host, six.text_type(e))
7062         except Exception:
7063             with excutils.save_and_reraise_exception():
7064                 # NOTE(tdurakov): even if teardown networks fails driver
7065                 # should try to rollback live migration on destination.
7066                 LOG.exception('An error occurred while deallocating network.',
7067                               instance=instance)
7068         finally:
7069             # always run this even if setup_networks_on_host fails
7070             # NOTE(vish): The mapping is passed in so the driver can disconnect
7071             #             from remote volumes if necessary
7072             block_device_info = self._get_instance_block_device_info(context,
7073                                                                      instance)
7074             self.driver.rollback_live_migration_at_destination(
7075                 context, instance, network_info, block_device_info,
7076                 destroy_disks=destroy_disks, migrate_data=migrate_data)
7077 
7078         self._notify_about_instance_usage(
7079                         context, instance, "live_migration.rollback.dest.end",
7080                         network_info=network_info)
7081         compute_utils.notify_about_instance_action(
7082             context, instance, self.host,
7083             action=fields.NotificationAction.LIVE_MIGRATION_ROLLBACK_DEST,
7084             phase=fields.NotificationPhase.END)
7085 
7086     @periodic_task.periodic_task(
7087         spacing=CONF.heal_instance_info_cache_interval)
7088     def _heal_instance_info_cache(self, context):
7089         """Called periodically.  On every call, try to update the
7090         info_cache's network information for another instance by
7091         calling to the network manager.
7092 
7093         This is implemented by keeping a cache of uuids of instances
7094         that live on this host.  On each call, we pop one off of a
7095         list, pull the DB record, and try the call to the network API.
7096         If anything errors don't fail, as it's possible the instance
7097         has been deleted, etc.
7098         """
7099         heal_interval = CONF.heal_instance_info_cache_interval
7100         if not heal_interval:
7101             return
7102 
7103         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
7104         instance = None
7105 
7106         LOG.debug('Starting heal instance info cache')
7107 
7108         if not instance_uuids:
7109             # The list of instances to heal is empty so rebuild it
7110             LOG.debug('Rebuilding the list of instances to heal')
7111             db_instances = objects.InstanceList.get_by_host(
7112                 context, self.host, expected_attrs=[], use_slave=True)
7113             for inst in db_instances:
7114                 # We don't want to refresh the cache for instances
7115                 # which are building or deleting so don't put them
7116                 # in the list. If they are building they will get
7117                 # added to the list next time we build it.
7118                 if (inst.vm_state == vm_states.BUILDING):
7119                     LOG.debug('Skipping network cache update for instance '
7120                               'because it is Building.', instance=inst)
7121                     continue
7122                 if (inst.task_state == task_states.DELETING):
7123                     LOG.debug('Skipping network cache update for instance '
7124                               'because it is being deleted.', instance=inst)
7125                     continue
7126 
7127                 if not instance:
7128                     # Save the first one we find so we don't
7129                     # have to get it again
7130                     instance = inst
7131                 else:
7132                     instance_uuids.append(inst['uuid'])
7133 
7134             self._instance_uuids_to_heal = instance_uuids
7135         else:
7136             # Find the next valid instance on the list
7137             while instance_uuids:
7138                 try:
7139                     inst = objects.Instance.get_by_uuid(
7140                             context, instance_uuids.pop(0),
7141                             expected_attrs=['system_metadata', 'info_cache',
7142                                             'flavor'],
7143                             use_slave=True)
7144                 except exception.InstanceNotFound:
7145                     # Instance is gone.  Try to grab another.
7146                     continue
7147 
7148                 # Check the instance hasn't been migrated
7149                 if inst.host != self.host:
7150                     LOG.debug('Skipping network cache update for instance '
7151                               'because it has been migrated to another '
7152                               'host.', instance=inst)
7153                 # Check the instance isn't being deleting
7154                 elif inst.task_state == task_states.DELETING:
7155                     LOG.debug('Skipping network cache update for instance '
7156                               'because it is being deleted.', instance=inst)
7157                 else:
7158                     instance = inst
7159                     break
7160 
7161         if instance:
7162             # We have an instance now to refresh
7163             try:
7164                 # Call to network API to get instance info.. this will
7165                 # force an update to the instance's info_cache
7166                 self.network_api.get_instance_nw_info(
7167                     context, instance, force_refresh=True)
7168                 LOG.debug('Updated the network info_cache for instance',
7169                           instance=instance)
7170             except exception.InstanceNotFound:
7171                 # Instance is gone.
7172                 LOG.debug('Instance no longer exists. Unable to refresh',
7173                           instance=instance)
7174                 return
7175             except exception.InstanceInfoCacheNotFound:
7176                 # InstanceInfoCache is gone.
7177                 LOG.debug('InstanceInfoCache no longer exists. '
7178                           'Unable to refresh', instance=instance)
7179             except Exception:
7180                 LOG.error('An error occurred while refreshing the network '
7181                           'cache.', instance=instance, exc_info=True)
7182         else:
7183             LOG.debug("Didn't find any instances for network info cache "
7184                       "update.")
7185 
7186     @periodic_task.periodic_task
7187     def _poll_rebooting_instances(self, context):
7188         if CONF.reboot_timeout > 0:
7189             filters = {'task_state':
7190                        [task_states.REBOOTING,
7191                         task_states.REBOOT_STARTED,
7192                         task_states.REBOOT_PENDING],
7193                        'host': self.host}
7194             rebooting = objects.InstanceList.get_by_filters(
7195                 context, filters, expected_attrs=[], use_slave=True)
7196 
7197             to_poll = []
7198             for instance in rebooting:
7199                 if timeutils.is_older_than(instance.updated_at,
7200                                            CONF.reboot_timeout):
7201                     to_poll.append(instance)
7202 
7203             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
7204 
7205     @periodic_task.periodic_task
7206     def _poll_rescued_instances(self, context):
7207         if CONF.rescue_timeout > 0:
7208             filters = {'vm_state': vm_states.RESCUED,
7209                        'host': self.host}
7210             rescued_instances = objects.InstanceList.get_by_filters(
7211                 context, filters, expected_attrs=["system_metadata"],
7212                 use_slave=True)
7213 
7214             to_unrescue = []
7215             for instance in rescued_instances:
7216                 if timeutils.is_older_than(instance.launched_at,
7217                                            CONF.rescue_timeout):
7218                     to_unrescue.append(instance)
7219 
7220             for instance in to_unrescue:
7221                 self.compute_api.unrescue(context, instance)
7222 
7223     @periodic_task.periodic_task
7224     def _poll_unconfirmed_resizes(self, context):
7225         if CONF.resize_confirm_window == 0:
7226             return
7227 
7228         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
7229                 context, CONF.resize_confirm_window, self.host,
7230                 use_slave=True)
7231 
7232         migrations_info = dict(migration_count=len(migrations),
7233                 confirm_window=CONF.resize_confirm_window)
7234 
7235         if migrations_info["migration_count"] > 0:
7236             LOG.info("Found %(migration_count)d unconfirmed migrations "
7237                      "older than %(confirm_window)d seconds",
7238                      migrations_info)
7239 
7240         def _set_migration_to_error(migration, reason, **kwargs):
7241             LOG.warning("Setting migration %(migration_id)s to error: "
7242                         "%(reason)s",
7243                         {'migration_id': migration['id'], 'reason': reason},
7244                         **kwargs)
7245             migration.status = 'error'
7246             with migration.obj_as_admin():
7247                 migration.save()
7248 
7249         for migration in migrations:
7250             instance_uuid = migration.instance_uuid
7251             LOG.info("Automatically confirming migration "
7252                      "%(migration_id)s for instance %(instance_uuid)s",
7253                      {'migration_id': migration.id,
7254                       'instance_uuid': instance_uuid})
7255             expected_attrs = ['metadata', 'system_metadata']
7256             try:
7257                 instance = objects.Instance.get_by_uuid(context,
7258                             instance_uuid, expected_attrs=expected_attrs,
7259                             use_slave=True)
7260             except exception.InstanceNotFound:
7261                 reason = (_("Instance %s not found") %
7262                           instance_uuid)
7263                 _set_migration_to_error(migration, reason)
7264                 continue
7265             if instance.vm_state == vm_states.ERROR:
7266                 reason = _("In ERROR state")
7267                 _set_migration_to_error(migration, reason,
7268                                         instance=instance)
7269                 continue
7270             # race condition: The instance in DELETING state should not be
7271             # set the migration state to error, otherwise the instance in
7272             # to be deleted which is in RESIZED state
7273             # will not be able to confirm resize
7274             if instance.task_state in [task_states.DELETING,
7275                                        task_states.SOFT_DELETING]:
7276                 msg = ("Instance being deleted or soft deleted during resize "
7277                        "confirmation. Skipping.")
7278                 LOG.debug(msg, instance=instance)
7279                 continue
7280 
7281             # race condition: This condition is hit when this method is
7282             # called between the save of the migration record with a status of
7283             # finished and the save of the instance object with a state of
7284             # RESIZED. The migration record should not be set to error.
7285             if instance.task_state == task_states.RESIZE_FINISH:
7286                 msg = ("Instance still resizing during resize "
7287                        "confirmation. Skipping.")
7288                 LOG.debug(msg, instance=instance)
7289                 continue
7290 
7291             vm_state = instance.vm_state
7292             task_state = instance.task_state
7293             if vm_state != vm_states.RESIZED or task_state is not None:
7294                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
7295                            "RESIZED/None") %
7296                           {'vm_state': vm_state,
7297                            'task_state': task_state})
7298                 _set_migration_to_error(migration, reason,
7299                                         instance=instance)
7300                 continue
7301             try:
7302                 self.compute_api.confirm_resize(context, instance,
7303                                                 migration=migration)
7304             except Exception as e:
7305                 LOG.info("Error auto-confirming resize: %s. "
7306                          "Will retry later.", e, instance=instance)
7307 
7308     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
7309     def _poll_shelved_instances(self, context):
7310 
7311         if CONF.shelved_offload_time <= 0:
7312             return
7313 
7314         filters = {'vm_state': vm_states.SHELVED,
7315                    'task_state': None,
7316                    'host': self.host}
7317         shelved_instances = objects.InstanceList.get_by_filters(
7318             context, filters=filters, expected_attrs=['system_metadata'],
7319             use_slave=True)
7320 
7321         to_gc = []
7322         for instance in shelved_instances:
7323             sys_meta = instance.system_metadata
7324             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
7325             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
7326                 to_gc.append(instance)
7327 
7328         for instance in to_gc:
7329             try:
7330                 instance.task_state = task_states.SHELVING_OFFLOADING
7331                 instance.save(expected_task_state=(None,))
7332                 self.shelve_offload_instance(context, instance,
7333                                              clean_shutdown=False)
7334             except Exception:
7335                 LOG.exception('Periodic task failed to offload instance.',
7336                               instance=instance)
7337 
7338     @periodic_task.periodic_task
7339     def _instance_usage_audit(self, context):
7340         if not CONF.instance_usage_audit:
7341             return
7342 
7343         begin, end = utils.last_completed_audit_period()
7344         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
7345                                self.host):
7346             return
7347 
7348         instances = objects.InstanceList.get_active_by_window_joined(
7349             context, begin, end, host=self.host,
7350             expected_attrs=['system_metadata', 'info_cache', 'metadata',
7351                             'flavor'],
7352             use_slave=True)
7353         num_instances = len(instances)
7354         errors = 0
7355         successes = 0
7356         LOG.info("Running instance usage audit for host %(host)s "
7357                  "from %(begin_time)s to %(end_time)s. "
7358                  "%(number_instances)s instances.",
7359                  {'host': self.host,
7360                   'begin_time': begin,
7361                   'end_time': end,
7362                   'number_instances': num_instances})
7363         start_time = time.time()
7364         task_log = objects.TaskLog(context)
7365         task_log.task_name = 'instance_usage_audit'
7366         task_log.period_beginning = begin
7367         task_log.period_ending = end
7368         task_log.host = self.host
7369         task_log.task_items = num_instances
7370         task_log.message = 'Instance usage audit started...'
7371         task_log.begin_task()
7372         for instance in instances:
7373             try:
7374                 compute_utils.notify_usage_exists(
7375                     self.notifier, context, instance, self.host,
7376                     ignore_missing_network_data=False)
7377                 successes += 1
7378             except Exception:
7379                 LOG.exception('Failed to generate usage '
7380                               'audit for instance '
7381                               'on host %s', self.host,
7382                               instance=instance)
7383                 errors += 1
7384         task_log.errors = errors
7385         task_log.message = (
7386             'Instance usage audit ran for host %s, %s instances in %s seconds.'
7387             % (self.host, num_instances, time.time() - start_time))
7388         task_log.end_task()
7389 
7390     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
7391     def _poll_bandwidth_usage(self, context):
7392 
7393         if not self._bw_usage_supported:
7394             return
7395 
7396         prev_time, start_time = utils.last_completed_audit_period()
7397 
7398         curr_time = time.time()
7399         if (curr_time - self._last_bw_usage_poll >
7400                 CONF.bandwidth_poll_interval):
7401             self._last_bw_usage_poll = curr_time
7402             LOG.info("Updating bandwidth usage cache")
7403             cells_update_interval = CONF.cells.bandwidth_update_interval
7404             if (cells_update_interval > 0 and
7405                    curr_time - self._last_bw_usage_cell_update >
7406                            cells_update_interval):
7407                 self._last_bw_usage_cell_update = curr_time
7408                 update_cells = True
7409             else:
7410                 update_cells = False
7411 
7412             instances = objects.InstanceList.get_by_host(context,
7413                                                               self.host,
7414                                                               use_slave=True)
7415             try:
7416                 bw_counters = self.driver.get_all_bw_counters(instances)
7417             except NotImplementedError:
7418                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
7419                 # implemented yet.  If they don't it doesn't break anything,
7420                 # they just don't get the info in the usage events.
7421                 # NOTE(PhilDay): Record that its not supported so we can
7422                 # skip fast on future calls rather than waste effort getting
7423                 # the list of instances.
7424                 LOG.info("Bandwidth usage not supported by %(driver)s.",
7425                          {'driver': CONF.compute_driver})
7426                 self._bw_usage_supported = False
7427                 return
7428 
7429             refreshed = timeutils.utcnow()
7430             for bw_ctr in bw_counters:
7431                 # Allow switching of greenthreads between queries.
7432                 greenthread.sleep(0)
7433                 bw_in = 0
7434                 bw_out = 0
7435                 last_ctr_in = None
7436                 last_ctr_out = None
7437                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
7438                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
7439                     start_period=start_time, use_slave=True)
7440                 if usage:
7441                     bw_in = usage.bw_in
7442                     bw_out = usage.bw_out
7443                     last_ctr_in = usage.last_ctr_in
7444                     last_ctr_out = usage.last_ctr_out
7445                 else:
7446                     usage = (objects.BandwidthUsage.
7447                              get_by_instance_uuid_and_mac(
7448                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
7449                         start_period=prev_time, use_slave=True))
7450                     if usage:
7451                         last_ctr_in = usage.last_ctr_in
7452                         last_ctr_out = usage.last_ctr_out
7453 
7454                 if last_ctr_in is not None:
7455                     if bw_ctr['bw_in'] < last_ctr_in:
7456                         # counter rollover
7457                         bw_in += bw_ctr['bw_in']
7458                     else:
7459                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
7460 
7461                 if last_ctr_out is not None:
7462                     if bw_ctr['bw_out'] < last_ctr_out:
7463                         # counter rollover
7464                         bw_out += bw_ctr['bw_out']
7465                     else:
7466                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
7467 
7468                 objects.BandwidthUsage(context=context).create(
7469                                               bw_ctr['uuid'],
7470                                               bw_ctr['mac_address'],
7471                                               bw_in,
7472                                               bw_out,
7473                                               bw_ctr['bw_in'],
7474                                               bw_ctr['bw_out'],
7475                                               start_period=start_time,
7476                                               last_refreshed=refreshed,
7477                                               update_cells=update_cells)
7478 
7479     def _get_host_volume_bdms(self, context, use_slave=False):
7480         """Return all block device mappings on a compute host."""
7481         compute_host_bdms = []
7482         instances = objects.InstanceList.get_by_host(context, self.host,
7483             use_slave=use_slave)
7484         for instance in instances:
7485             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7486                     context, instance.uuid, use_slave=use_slave)
7487             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
7488             compute_host_bdms.append(dict(instance=instance,
7489                                           instance_bdms=instance_bdms))
7490 
7491         return compute_host_bdms
7492 
7493     def _update_volume_usage_cache(self, context, vol_usages):
7494         """Updates the volume usage cache table with a list of stats."""
7495         for usage in vol_usages:
7496             # Allow switching of greenthreads between queries.
7497             greenthread.sleep(0)
7498             vol_usage = objects.VolumeUsage(context)
7499             vol_usage.volume_id = usage['volume']
7500             vol_usage.instance_uuid = usage['instance'].uuid
7501             vol_usage.project_id = usage['instance'].project_id
7502             vol_usage.user_id = usage['instance'].user_id
7503             vol_usage.availability_zone = usage['instance'].availability_zone
7504             vol_usage.curr_reads = usage['rd_req']
7505             vol_usage.curr_read_bytes = usage['rd_bytes']
7506             vol_usage.curr_writes = usage['wr_req']
7507             vol_usage.curr_write_bytes = usage['wr_bytes']
7508             vol_usage.save()
7509             self.notifier.info(context, 'volume.usage', vol_usage.to_dict())
7510             compute_utils.notify_about_volume_usage(context, vol_usage,
7511                                                     self.host)
7512 
7513     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
7514     def _poll_volume_usage(self, context):
7515         if CONF.volume_usage_poll_interval == 0:
7516             return
7517 
7518         compute_host_bdms = self._get_host_volume_bdms(context,
7519                                                        use_slave=True)
7520         if not compute_host_bdms:
7521             return
7522 
7523         LOG.debug("Updating volume usage cache")
7524         try:
7525             vol_usages = self.driver.get_all_volume_usage(context,
7526                                                           compute_host_bdms)
7527         except NotImplementedError:
7528             return
7529 
7530         self._update_volume_usage_cache(context, vol_usages)
7531 
7532     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
7533                                  run_immediately=True)
7534     def _sync_power_states(self, context):
7535         """Align power states between the database and the hypervisor.
7536 
7537         To sync power state data we make a DB call to get the number of
7538         virtual machines known by the hypervisor and if the number matches the
7539         number of virtual machines known by the database, we proceed in a lazy
7540         loop, one database record at a time, checking if the hypervisor has the
7541         same power state as is in the database.
7542         """
7543         db_instances = objects.InstanceList.get_by_host(context, self.host,
7544                                                         expected_attrs=[],
7545                                                         use_slave=True)
7546 
7547         try:
7548             num_vm_instances = self.driver.get_num_instances()
7549         except exception.VirtDriverNotReady as e:
7550             # If the virt driver is not ready, like ironic-api not being up
7551             # yet in the case of ironic, just log it and exit.
7552             LOG.info('Skipping _sync_power_states periodic task due to: %s', e)
7553             return
7554 
7555         num_db_instances = len(db_instances)
7556 
7557         if num_vm_instances != num_db_instances:
7558             LOG.warning("While synchronizing instance power states, found "
7559                         "%(num_db_instances)s instances in the database "
7560                         "and %(num_vm_instances)s instances on the "
7561                         "hypervisor.",
7562                         {'num_db_instances': num_db_instances,
7563                          'num_vm_instances': num_vm_instances})
7564 
7565         def _sync(db_instance):
7566             # NOTE(melwitt): This must be synchronized as we query state from
7567             #                two separate sources, the driver and the database.
7568             #                They are set (in stop_instance) and read, in sync.
7569             @utils.synchronized(db_instance.uuid)
7570             def query_driver_power_state_and_sync():
7571                 self._query_driver_power_state_and_sync(context, db_instance)
7572 
7573             try:
7574                 query_driver_power_state_and_sync()
7575             except Exception:
7576                 LOG.exception("Periodic sync_power_state task had an "
7577                               "error while processing an instance.",
7578                               instance=db_instance)
7579 
7580             self._syncs_in_progress.pop(db_instance.uuid)
7581 
7582         for db_instance in db_instances:
7583             # process syncs asynchronously - don't want instance locking to
7584             # block entire periodic task thread
7585             uuid = db_instance.uuid
7586             if uuid in self._syncs_in_progress:
7587                 LOG.debug('Sync already in progress for %s', uuid)
7588             else:
7589                 LOG.debug('Triggering sync for uuid %s', uuid)
7590                 self._syncs_in_progress[uuid] = True
7591                 self._sync_power_pool.spawn_n(_sync, db_instance)
7592 
7593     def _query_driver_power_state_and_sync(self, context, db_instance):
7594         if db_instance.task_state is not None:
7595             LOG.info("During sync_power_state the instance has a "
7596                      "pending task (%(task)s). Skip.",
7597                      {'task': db_instance.task_state}, instance=db_instance)
7598             return
7599         # No pending tasks. Now try to figure out the real vm_power_state.
7600         try:
7601             vm_instance = self.driver.get_info(db_instance)
7602             vm_power_state = vm_instance.state
7603         except exception.InstanceNotFound:
7604             vm_power_state = power_state.NOSTATE
7605         # Note(maoy): the above get_info call might take a long time,
7606         # for example, because of a broken libvirt driver.
7607         try:
7608             self._sync_instance_power_state(context,
7609                                             db_instance,
7610                                             vm_power_state,
7611                                             use_slave=True)
7612         except exception.InstanceNotFound:
7613             # NOTE(hanlind): If the instance gets deleted during sync,
7614             # silently ignore.
7615             pass
7616 
7617     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
7618                                    use_slave=False):
7619         """Align instance power state between the database and hypervisor.
7620 
7621         If the instance is not found on the hypervisor, but is in the database,
7622         then a stop() API will be called on the instance.
7623         """
7624 
7625         # We re-query the DB to get the latest instance info to minimize
7626         # (not eliminate) race condition.
7627         db_instance.refresh(use_slave=use_slave)
7628         db_power_state = db_instance.power_state
7629         vm_state = db_instance.vm_state
7630 
7631         if self.host != db_instance.host:
7632             # on the sending end of nova-compute _sync_power_state
7633             # may have yielded to the greenthread performing a live
7634             # migration; this in turn has changed the resident-host
7635             # for the VM; However, the instance is still active, it
7636             # is just in the process of migrating to another host.
7637             # This implies that the compute source must relinquish
7638             # control to the compute destination.
7639             LOG.info("During the sync_power process the "
7640                      "instance has moved from "
7641                      "host %(src)s to host %(dst)s",
7642                      {'src': db_instance.host,
7643                       'dst': self.host},
7644                      instance=db_instance)
7645             return
7646         elif db_instance.task_state is not None:
7647             # on the receiving end of nova-compute, it could happen
7648             # that the DB instance already report the new resident
7649             # but the actual VM has not showed up on the hypervisor
7650             # yet. In this case, let's allow the loop to continue
7651             # and run the state sync in a later round
7652             LOG.info("During sync_power_state the instance has a "
7653                      "pending task (%(task)s). Skip.",
7654                      {'task': db_instance.task_state},
7655                      instance=db_instance)
7656             return
7657 
7658         orig_db_power_state = db_power_state
7659         if vm_power_state != db_power_state:
7660             LOG.info('During _sync_instance_power_state the DB '
7661                      'power_state (%(db_power_state)s) does not match '
7662                      'the vm_power_state from the hypervisor '
7663                      '(%(vm_power_state)s). Updating power_state in the '
7664                      'DB to match the hypervisor.',
7665                      {'db_power_state': db_power_state,
7666                       'vm_power_state': vm_power_state},
7667                      instance=db_instance)
7668             # power_state is always updated from hypervisor to db
7669             db_instance.power_state = vm_power_state
7670             db_instance.save()
7671             db_power_state = vm_power_state
7672 
7673         # Note(maoy): Now resolve the discrepancy between vm_state and
7674         # vm_power_state. We go through all possible vm_states.
7675         if vm_state in (vm_states.BUILDING,
7676                         vm_states.RESCUED,
7677                         vm_states.RESIZED,
7678                         vm_states.SUSPENDED,
7679                         vm_states.ERROR):
7680             # TODO(maoy): we ignore these vm_state for now.
7681             pass
7682         elif vm_state == vm_states.ACTIVE:
7683             # The only rational power state should be RUNNING
7684             if vm_power_state in (power_state.SHUTDOWN,
7685                                   power_state.CRASHED):
7686                 LOG.warning("Instance shutdown by itself. Calling the "
7687                             "stop API. Current vm_state: %(vm_state)s, "
7688                             "current task_state: %(task_state)s, "
7689                             "original DB power_state: %(db_power_state)s, "
7690                             "current VM power_state: %(vm_power_state)s",
7691                             {'vm_state': vm_state,
7692                              'task_state': db_instance.task_state,
7693                              'db_power_state': orig_db_power_state,
7694                              'vm_power_state': vm_power_state},
7695                             instance=db_instance)
7696                 try:
7697                     # Note(maoy): here we call the API instead of
7698                     # brutally updating the vm_state in the database
7699                     # to allow all the hooks and checks to be performed.
7700                     if db_instance.shutdown_terminate:
7701                         self.compute_api.delete(context, db_instance)
7702                     else:
7703                         self.compute_api.stop(context, db_instance)
7704                 except Exception:
7705                     # Note(maoy): there is no need to propagate the error
7706                     # because the same power_state will be retrieved next
7707                     # time and retried.
7708                     # For example, there might be another task scheduled.
7709                     LOG.exception("error during stop() in sync_power_state.",
7710                                   instance=db_instance)
7711             elif vm_power_state == power_state.SUSPENDED:
7712                 LOG.warning("Instance is suspended unexpectedly. Calling "
7713                             "the stop API.", instance=db_instance)
7714                 try:
7715                     self.compute_api.stop(context, db_instance)
7716                 except Exception:
7717                     LOG.exception("error during stop() in sync_power_state.",
7718                                   instance=db_instance)
7719             elif vm_power_state == power_state.PAUSED:
7720                 # Note(maoy): a VM may get into the paused state not only
7721                 # because the user request via API calls, but also
7722                 # due to (temporary) external instrumentations.
7723                 # Before the virt layer can reliably report the reason,
7724                 # we simply ignore the state discrepancy. In many cases,
7725                 # the VM state will go back to running after the external
7726                 # instrumentation is done. See bug 1097806 for details.
7727                 LOG.warning("Instance is paused unexpectedly. Ignore.",
7728                             instance=db_instance)
7729             elif vm_power_state == power_state.NOSTATE:
7730                 # Occasionally, depending on the status of the hypervisor,
7731                 # which could be restarting for example, an instance may
7732                 # not be found.  Therefore just log the condition.
7733                 LOG.warning("Instance is unexpectedly not found. Ignore.",
7734                             instance=db_instance)
7735         elif vm_state == vm_states.STOPPED:
7736             if vm_power_state not in (power_state.NOSTATE,
7737                                       power_state.SHUTDOWN,
7738                                       power_state.CRASHED):
7739                 LOG.warning("Instance is not stopped. Calling "
7740                             "the stop API. Current vm_state: %(vm_state)s,"
7741                             " current task_state: %(task_state)s, "
7742                             "original DB power_state: %(db_power_state)s, "
7743                             "current VM power_state: %(vm_power_state)s",
7744                             {'vm_state': vm_state,
7745                              'task_state': db_instance.task_state,
7746                              'db_power_state': orig_db_power_state,
7747                              'vm_power_state': vm_power_state},
7748                             instance=db_instance)
7749                 try:
7750                     # NOTE(russellb) Force the stop, because normally the
7751                     # compute API would not allow an attempt to stop a stopped
7752                     # instance.
7753                     self.compute_api.force_stop(context, db_instance)
7754                 except Exception:
7755                     LOG.exception("error during stop() in sync_power_state.",
7756                                   instance=db_instance)
7757         elif vm_state == vm_states.PAUSED:
7758             if vm_power_state in (power_state.SHUTDOWN,
7759                                   power_state.CRASHED):
7760                 LOG.warning("Paused instance shutdown by itself. Calling "
7761                             "the stop API.", instance=db_instance)
7762                 try:
7763                     self.compute_api.force_stop(context, db_instance)
7764                 except Exception:
7765                     LOG.exception("error during stop() in sync_power_state.",
7766                                   instance=db_instance)
7767         elif vm_state in (vm_states.SOFT_DELETED,
7768                           vm_states.DELETED):
7769             if vm_power_state not in (power_state.NOSTATE,
7770                                       power_state.SHUTDOWN):
7771                 # Note(maoy): this should be taken care of periodically in
7772                 # _cleanup_running_deleted_instances().
7773                 LOG.warning("Instance is not (soft-)deleted.",
7774                             instance=db_instance)
7775 
7776     @periodic_task.periodic_task
7777     def _reclaim_queued_deletes(self, context):
7778         """Reclaim instances that are queued for deletion."""
7779         interval = CONF.reclaim_instance_interval
7780         if interval <= 0:
7781             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
7782             return
7783 
7784         filters = {'vm_state': vm_states.SOFT_DELETED,
7785                    'task_state': None,
7786                    'host': self.host}
7787         instances = objects.InstanceList.get_by_filters(
7788             context, filters,
7789             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
7790             use_slave=True)
7791         for instance in instances:
7792             if self._deleted_old_enough(instance, interval):
7793                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7794                         context, instance.uuid)
7795                 LOG.info('Reclaiming deleted instance', instance=instance)
7796                 try:
7797                     self._delete_instance(context, instance, bdms)
7798                 except Exception as e:
7799                     LOG.warning("Periodic reclaim failed to delete "
7800                                 "instance: %s",
7801                                 e, instance=instance)
7802 
7803     def _get_nodename(self, instance, refresh=False):
7804         """Helper method to get the name of the first available node
7805         on this host. This method should not be used with any operations
7806         on ironic instances since it does not handle multiple nodes.
7807         """
7808         node = self.driver.get_available_nodes(refresh=refresh)[0]
7809         LOG.debug("No node specified, defaulting to %s", node,
7810                   instance=instance)
7811         return node
7812 
7813     def _update_available_resource_for_node(self, context, nodename,
7814                                             startup=False):
7815 
7816         try:
7817             self.rt.update_available_resource(context, nodename,
7818                                               startup=startup)
7819         except exception.ComputeHostNotFound:
7820             LOG.warning("Compute node '%s' not found in "
7821                         "update_available_resource.", nodename)
7822         except exception.ReshapeFailed:
7823             # We're only supposed to get here on startup, if a reshape was
7824             # needed, was attempted, and failed. We want to kill the service.
7825             with excutils.save_and_reraise_exception():
7826                 LOG.critical("Resource provider data migration failed "
7827                              "fatally during startup for node %s.", nodename)
7828         except exception.ReshapeNeeded:
7829             # This exception should only find its way here if the virt driver's
7830             # update_provider_tree raised it incorrectly: either
7831             # a) After the resource tracker already caught it once and
7832             # reinvoked update_provider_tree with allocations. At this point
7833             # the driver is just supposed to *do* the reshape, so if it raises
7834             # ReshapeNeeded, it's a bug, and we want to kill the compute
7835             # service.
7836             # b) On periodic rather than startup (we only allow reshapes to
7837             # happen on startup). In this case we'll just make the logs red and
7838             # go again at the next periodic interval, where the same thing may
7839             # or may not happen again. Depending on the previous and intended
7840             # shape of the providers/inventories, this may not actually cause
7841             # any immediately visible symptoms (in terms of scheduling, etc.)
7842             # If this becomes a problem, we may wish to make it pop immediately
7843             # (e.g. disable the service).
7844             with excutils.save_and_reraise_exception():
7845                 LOG.exception("ReshapeNeeded exception is unexpected here!")
7846         except Exception:
7847             LOG.exception("Error updating resources for node %(node)s.",
7848                           {'node': nodename})
7849 
7850     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
7851     def update_available_resource(self, context, startup=False):
7852         """See driver.get_available_resource()
7853 
7854         Periodic process that keeps that the compute host's understanding of
7855         resource availability and usage in sync with the underlying hypervisor.
7856 
7857         :param context: security context
7858         :param startup: True if this is being called when the nova-compute
7859             service is starting, False otherwise.
7860         """
7861 
7862         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
7863                                                             use_slave=True,
7864                                                             startup=startup)
7865         try:
7866             nodenames = set(self.driver.get_available_nodes())
7867         except exception.VirtDriverNotReady:
7868             LOG.warning("Virt driver is not ready.")
7869             return
7870 
7871         # Delete orphan compute node not reported by driver but still in db
7872         for cn in compute_nodes_in_db:
7873             if cn.hypervisor_hostname not in nodenames:
7874                 LOG.info("Deleting orphan compute node %(id)s "
7875                          "hypervisor host is %(hh)s, "
7876                          "nodes are %(nodes)s",
7877                          {'id': cn.id, 'hh': cn.hypervisor_hostname,
7878                           'nodes': nodenames})
7879                 cn.destroy()
7880                 self.rt.remove_node(cn.hypervisor_hostname)
7881                 # Delete the corresponding resource provider in placement,
7882                 # along with any associated allocations and inventory.
7883                 self.reportclient.delete_resource_provider(context, cn,
7884                                                            cascade=True)
7885 
7886         for nodename in nodenames:
7887             self._update_available_resource_for_node(context, nodename,
7888                                                      startup=startup)
7889 
7890     def _get_compute_nodes_in_db(self, context, use_slave=False,
7891                                  startup=False):
7892         try:
7893             return objects.ComputeNodeList.get_all_by_host(context, self.host,
7894                                                            use_slave=use_slave)
7895         except exception.NotFound:
7896             if startup:
7897                 LOG.warning(
7898                     "No compute node record found for host %s. If this is "
7899                     "the first time this service is starting on this "
7900                     "host, then you can ignore this warning.", self.host)
7901             else:
7902                 LOG.error("No compute node record for host %s", self.host)
7903             return []
7904 
7905     @periodic_task.periodic_task(
7906         spacing=CONF.running_deleted_instance_poll_interval)
7907     def _cleanup_running_deleted_instances(self, context):
7908         """Cleanup any instances which are erroneously still running after
7909         having been deleted.
7910 
7911         Valid actions to take are:
7912 
7913             1. noop - do nothing
7914             2. log - log which instances are erroneously running
7915             3. reap - shutdown and cleanup any erroneously running instances
7916             4. shutdown - power off *and disable* any erroneously running
7917                           instances
7918 
7919         The use-case for this cleanup task is: for various reasons, it may be
7920         possible for the database to show an instance as deleted but for that
7921         instance to still be running on a host machine (see bug
7922         https://bugs.launchpad.net/nova/+bug/911366).
7923 
7924         This cleanup task is a cross-hypervisor utility for finding these
7925         zombied instances and either logging the discrepancy (likely what you
7926         should do in production), or automatically reaping the instances (more
7927         appropriate for dev environments).
7928         """
7929         action = CONF.running_deleted_instance_action
7930 
7931         if action == "noop":
7932             return
7933 
7934         # NOTE(sirp): admin contexts don't ordinarily return deleted records
7935         with utils.temporary_mutation(context, read_deleted="yes"):
7936             for instance in self._running_deleted_instances(context):
7937                 if action == "log":
7938                     LOG.warning("Detected instance with name label "
7939                                 "'%s' which is marked as "
7940                                 "DELETED but still present on host.",
7941                                 instance.name, instance=instance)
7942 
7943                 elif action == 'shutdown':
7944                     LOG.info("Powering off instance with name label "
7945                              "'%s' which is marked as "
7946                              "DELETED but still present on host.",
7947                              instance.name, instance=instance)
7948                     try:
7949                         try:
7950                             # disable starting the instance
7951                             self.driver.set_bootable(instance, False)
7952                         except NotImplementedError:
7953                             LOG.debug("set_bootable is not implemented "
7954                                       "for the current driver")
7955                         # and power it off
7956                         self.driver.power_off(instance)
7957                     except Exception:
7958                         LOG.warning("Failed to power off instance",
7959                                     instance=instance, exc_info=True)
7960 
7961                 elif action == 'reap':
7962                     LOG.info("Destroying instance with name label "
7963                              "'%s' which is marked as "
7964                              "DELETED but still present on host.",
7965                              instance.name, instance=instance)
7966                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
7967                         context, instance.uuid, use_slave=True)
7968                     self.instance_events.clear_events_for_instance(instance)
7969                     try:
7970                         self._shutdown_instance(context, instance, bdms,
7971                                                 notify=False)
7972                         self._cleanup_volumes(context, instance, bdms,
7973                                               detach=False)
7974                     except Exception as e:
7975                         LOG.warning("Periodic cleanup failed to delete "
7976                                     "instance: %s",
7977                                     e, instance=instance)
7978                 else:
7979                     raise Exception(_("Unrecognized value '%s'"
7980                                       " for CONF.running_deleted_"
7981                                       "instance_action") % action)
7982 
7983     def _running_deleted_instances(self, context):
7984         """Returns a list of instances nova thinks is deleted,
7985         but the hypervisor thinks is still running.
7986         """
7987         timeout = CONF.running_deleted_instance_timeout
7988         filters = {'deleted': True,
7989                    'soft_deleted': False}
7990         instances = self._get_instances_on_driver(context, filters)
7991         return [i for i in instances if self._deleted_old_enough(i, timeout)]
7992 
7993     def _deleted_old_enough(self, instance, timeout):
7994         deleted_at = instance.deleted_at
7995         if deleted_at:
7996             deleted_at = deleted_at.replace(tzinfo=None)
7997         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
7998 
7999     @contextlib.contextmanager
8000     def _error_out_instance_on_exception(self, context, instance,
8001                                          instance_state=vm_states.ACTIVE):
8002         instance_uuid = instance.uuid
8003         try:
8004             yield
8005         except NotImplementedError as error:
8006             with excutils.save_and_reraise_exception():
8007                 LOG.info("Setting instance back to %(state)s after: "
8008                          "%(error)s",
8009                          {'state': instance_state, 'error': error},
8010                          instance_uuid=instance_uuid)
8011                 self._instance_update(context, instance,
8012                                       vm_state=instance_state,
8013                                       task_state=None)
8014         except exception.InstanceFaultRollback as error:
8015             LOG.info("Setting instance back to ACTIVE after: %s",
8016                      error, instance_uuid=instance_uuid)
8017             self._instance_update(context, instance,
8018                                   vm_state=vm_states.ACTIVE,
8019                                   task_state=None)
8020             raise error.inner_exception
8021         except Exception:
8022             LOG.exception('Setting instance vm_state to ERROR',
8023                           instance_uuid=instance_uuid)
8024             with excutils.save_and_reraise_exception():
8025                 self._set_instance_obj_error_state(context, instance)
8026 
8027     @wrap_exception()
8028     def add_aggregate_host(self, context, aggregate, host, slave_info):
8029         """Notify hypervisor of change (for hypervisor pools)."""
8030         try:
8031             self.driver.add_to_aggregate(context, aggregate, host,
8032                                          slave_info=slave_info)
8033         except NotImplementedError:
8034             LOG.debug('Hypervisor driver does not support '
8035                       'add_aggregate_host')
8036         except exception.AggregateError:
8037             with excutils.save_and_reraise_exception():
8038                 self.driver.undo_aggregate_operation(
8039                                     context,
8040                                     aggregate.delete_host,
8041                                     aggregate, host)
8042 
8043     @wrap_exception()
8044     def remove_aggregate_host(self, context, host, slave_info, aggregate):
8045         """Removes a host from a physical hypervisor pool."""
8046         try:
8047             self.driver.remove_from_aggregate(context, aggregate, host,
8048                                               slave_info=slave_info)
8049         except NotImplementedError:
8050             LOG.debug('Hypervisor driver does not support '
8051                       'remove_aggregate_host')
8052         except (exception.AggregateError,
8053                 exception.InvalidAggregateAction) as e:
8054             with excutils.save_and_reraise_exception():
8055                 self.driver.undo_aggregate_operation(
8056                                     context,
8057                                     aggregate.add_host,
8058                                     aggregate, host,
8059                                     isinstance(e, exception.AggregateError))
8060 
8061     def _process_instance_event(self, instance, event):
8062         _event = self.instance_events.pop_instance_event(instance, event)
8063         if _event:
8064             LOG.debug('Processing event %(event)s',
8065                       {'event': event.key}, instance=instance)
8066             _event.send(event)
8067         else:
8068             # If it's a network-vif-unplugged event and the instance is being
8069             # deleted then we don't need to make this a warning as it's
8070             # expected. There are other things which could trigger this like
8071             # detaching an interface, but we don't have a task state for that.
8072             if (event.name == 'network-vif-unplugged' and
8073                     instance.task_state == task_states.DELETING):
8074                 LOG.debug('Received event %s for instance which is being '
8075                           'deleted.', event.key, instance=instance)
8076             else:
8077                 LOG.warning('Received unexpected event %(event)s for '
8078                             'instance with vm_state %(vm_state)s and '
8079                             'task_state %(task_state)s.',
8080                             {'event': event.key,
8081                              'vm_state': instance.vm_state,
8082                              'task_state': instance.task_state},
8083                             instance=instance)
8084 
8085     def _process_instance_vif_deleted_event(self, context, instance,
8086                                             deleted_vif_id):
8087         # If an attached port is deleted by neutron, it needs to
8088         # be detached from the instance.
8089         # And info cache needs to be updated.
8090         network_info = instance.info_cache.network_info
8091         for index, vif in enumerate(network_info):
8092             if vif['id'] == deleted_vif_id:
8093                 LOG.info('Neutron deleted interface %(intf)s; '
8094                          'detaching it from the instance and '
8095                          'deleting it from the info cache',
8096                          {'intf': vif['id']},
8097                          instance=instance)
8098                 del network_info[index]
8099                 base_net_api.update_instance_cache_with_nw_info(
8100                                  self.network_api, context,
8101                                  instance,
8102                                  nw_info=network_info)
8103                 try:
8104                     self.driver.detach_interface(context, instance, vif)
8105                 except NotImplementedError:
8106                     # Not all virt drivers support attach/detach of interfaces
8107                     # yet (like Ironic), so just ignore this.
8108                     pass
8109                 except exception.NovaException as ex:
8110                     # If the instance was deleted before the interface was
8111                     # detached, just log it at debug.
8112                     log_level = (logging.DEBUG
8113                                  if isinstance(ex, exception.InstanceNotFound)
8114                                  else logging.WARNING)
8115                     LOG.log(log_level,
8116                             "Detach interface failed, "
8117                             "port_id=%(port_id)s, reason: %(msg)s",
8118                             {'port_id': deleted_vif_id, 'msg': ex},
8119                             instance=instance)
8120                 break
8121 
8122     @wrap_instance_event(prefix='compute')
8123     @wrap_instance_fault
8124     def extend_volume(self, context, instance, extended_volume_id):
8125 
8126         # If an attached volume is extended by cinder, it needs to
8127         # be extended by virt driver so host can detect its new size.
8128         # And bdm needs to be updated.
8129         LOG.debug('Handling volume-extended event for volume %(vol)s',
8130                   {'vol': extended_volume_id}, instance=instance)
8131 
8132         try:
8133             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
8134                    context, extended_volume_id, instance.uuid)
8135         except exception.NotFound:
8136             LOG.warning('Extend volume failed, '
8137                         'volume %(vol)s is not attached to instance.',
8138                         {'vol': extended_volume_id},
8139                         instance=instance)
8140             return
8141 
8142         LOG.info('Cinder extended volume %(vol)s; '
8143                  'extending it to detect new size',
8144                  {'vol': extended_volume_id},
8145                  instance=instance)
8146         volume = self.volume_api.get(context, bdm.volume_id)
8147 
8148         if bdm.connection_info is None:
8149             LOG.warning('Extend volume failed, '
8150                         'attached volume %(vol)s has no connection_info',
8151                         {'vol': extended_volume_id},
8152                         instance=instance)
8153             return
8154 
8155         connection_info = jsonutils.loads(bdm.connection_info)
8156         bdm.volume_size = volume['size']
8157         bdm.save()
8158 
8159         if not self.driver.capabilities.get('supports_extend_volume', False):
8160             raise exception.ExtendVolumeNotSupported()
8161 
8162         try:
8163             self.driver.extend_volume(connection_info,
8164                                       instance)
8165         except Exception as ex:
8166             LOG.warning('Extend volume failed, '
8167                         'volume_id=%(volume_id)s, reason: %(msg)s',
8168                         {'volume_id': extended_volume_id, 'msg': ex},
8169                         instance=instance)
8170             raise
8171 
8172     @wrap_exception()
8173     def external_instance_event(self, context, instances, events):
8174         # NOTE(danms): Some event types are handled by the manager, such
8175         # as when we're asked to update the instance's info_cache. If it's
8176         # not one of those, look for some thread(s) waiting for the event and
8177         # unblock them if so.
8178         for event in events:
8179             instance = [inst for inst in instances
8180                         if inst.uuid == event.instance_uuid][0]
8181             LOG.debug('Received event %(event)s',
8182                       {'event': event.key},
8183                       instance=instance)
8184             if event.name == 'network-changed':
8185                 try:
8186                     LOG.debug('Refreshing instance network info cache due to '
8187                               'event %s.', event.key, instance=instance)
8188                     self.network_api.get_instance_nw_info(
8189                         context, instance, refresh_vif_id=event.tag)
8190                 except exception.NotFound as e:
8191                     LOG.info('Failed to process external instance event '
8192                              '%(event)s due to: %(error)s',
8193                              {'event': event.key, 'error': six.text_type(e)},
8194                              instance=instance)
8195             elif event.name == 'network-vif-deleted':
8196                 try:
8197                     self._process_instance_vif_deleted_event(context,
8198                                                              instance,
8199                                                              event.tag)
8200                 except exception.NotFound as e:
8201                     LOG.info('Failed to process external instance event '
8202                              '%(event)s due to: %(error)s',
8203                              {'event': event.key, 'error': six.text_type(e)},
8204                              instance=instance)
8205             elif event.name == 'volume-extended':
8206                 self.extend_volume(context, instance, event.tag)
8207             else:
8208                 self._process_instance_event(instance, event)
8209 
8210     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
8211                                  external_process_ok=True)
8212     def _run_image_cache_manager_pass(self, context):
8213         """Run a single pass of the image cache manager."""
8214 
8215         if not self.driver.capabilities.get("has_imagecache", False):
8216             return
8217 
8218         # Determine what other nodes use this storage
8219         storage_users.register_storage_use(CONF.instances_path, CONF.host)
8220         nodes = storage_users.get_storage_users(CONF.instances_path)
8221 
8222         # Filter all_instances to only include those nodes which share this
8223         # storage path.
8224         # TODO(mikal): this should be further refactored so that the cache
8225         # cleanup code doesn't know what those instances are, just a remote
8226         # count, and then this logic should be pushed up the stack.
8227         filters = {'deleted': False,
8228                    'soft_deleted': True,
8229                    'host': nodes}
8230         filtered_instances = objects.InstanceList.get_by_filters(context,
8231                                  filters, expected_attrs=[], use_slave=True)
8232 
8233         self.driver.manage_image_cache(context, filtered_instances)
8234 
8235     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8236     def _run_pending_deletes(self, context):
8237         """Retry any pending instance file deletes."""
8238         LOG.debug('Cleaning up deleted instances')
8239         filters = {'deleted': True,
8240                    'soft_deleted': False,
8241                    'host': CONF.host,
8242                    'cleaned': False}
8243         attrs = ['system_metadata']
8244         with utils.temporary_mutation(context, read_deleted='yes'):
8245             instances = objects.InstanceList.get_by_filters(
8246                 context, filters, expected_attrs=attrs, use_slave=True)
8247         LOG.debug('There are %d instances to clean', len(instances))
8248 
8249         for instance in instances:
8250             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
8251             LOG.debug('Instance has had %(attempts)s of %(max)s '
8252                       'cleanup attempts',
8253                       {'attempts': attempts,
8254                        'max': CONF.maximum_instance_delete_attempts},
8255                       instance=instance)
8256             if attempts < CONF.maximum_instance_delete_attempts:
8257                 success = self.driver.delete_instance_files(instance)
8258 
8259                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
8260                 if success:
8261                     instance.cleaned = True
8262                 with utils.temporary_mutation(context, read_deleted='yes'):
8263                     instance.save()
8264 
8265     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8266     def _cleanup_incomplete_migrations(self, context):
8267         """Delete instance files on failed resize/revert-resize operation
8268 
8269         During resize/revert-resize operation, if that instance gets deleted
8270         in-between then instance files might remain either on source or
8271         destination compute node because of race condition.
8272         """
8273         LOG.debug('Cleaning up deleted instances with incomplete migration ')
8274         migration_filters = {'host': CONF.host,
8275                              'status': 'error'}
8276         migrations = objects.MigrationList.get_by_filters(context,
8277                                                           migration_filters)
8278 
8279         if not migrations:
8280             return
8281 
8282         inst_uuid_from_migrations = set([migration.instance_uuid for migration
8283                                          in migrations])
8284 
8285         inst_filters = {'deleted': True, 'soft_deleted': False,
8286                         'uuid': inst_uuid_from_migrations}
8287         attrs = ['info_cache', 'security_groups', 'system_metadata']
8288         with utils.temporary_mutation(context, read_deleted='yes'):
8289             instances = objects.InstanceList.get_by_filters(
8290                 context, inst_filters, expected_attrs=attrs, use_slave=True)
8291 
8292         for instance in instances:
8293             if instance.host != CONF.host:
8294                 for migration in migrations:
8295                     if instance.uuid == migration.instance_uuid:
8296                         # Delete instance files if not cleanup properly either
8297                         # from the source or destination compute nodes when
8298                         # the instance is deleted during resizing.
8299                         self.driver.delete_instance_files(instance)
8300                         try:
8301                             migration.status = 'failed'
8302                             with migration.obj_as_admin():
8303                                 migration.save()
8304                         except exception.MigrationNotFound:
8305                             LOG.warning("Migration %s is not found.",
8306                                         migration.id,
8307                                         instance=instance)
8308                         break
8309 
8310     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8311                                    exception.QemuGuestAgentNotEnabled,
8312                                    exception.NovaException,
8313                                    NotImplementedError)
8314     @wrap_exception()
8315     def quiesce_instance(self, context, instance):
8316         """Quiesce an instance on this host."""
8317         context = context.elevated()
8318         image_meta = objects.ImageMeta.from_instance(instance)
8319         self.driver.quiesce(context, instance, image_meta)
8320 
8321     def _wait_for_snapshots_completion(self, context, mapping):
8322         for mapping_dict in mapping:
8323             if mapping_dict.get('source_type') == 'snapshot':
8324 
8325                 def _wait_snapshot():
8326                     snapshot = self.volume_api.get_snapshot(
8327                         context, mapping_dict['snapshot_id'])
8328                     if snapshot.get('status') != 'creating':
8329                         raise loopingcall.LoopingCallDone()
8330 
8331                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
8332                 timer.start(interval=0.5).wait()
8333 
8334     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
8335                                    exception.QemuGuestAgentNotEnabled,
8336                                    exception.NovaException,
8337                                    NotImplementedError)
8338     @wrap_exception()
8339     def unquiesce_instance(self, context, instance, mapping=None):
8340         """Unquiesce an instance on this host.
8341 
8342         If snapshots' image mapping is provided, it waits until snapshots are
8343         completed before unqueiscing.
8344         """
8345         context = context.elevated()
8346         if mapping:
8347             try:
8348                 self._wait_for_snapshots_completion(context, mapping)
8349             except Exception as error:
8350                 LOG.exception("Exception while waiting completion of "
8351                               "volume snapshots: %s",
8352                               error, instance=instance)
8353         image_meta = objects.ImageMeta.from_instance(instance)
8354         self.driver.unquiesce(context, instance, image_meta)
8355 
8356     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
8357     def _cleanup_expired_console_auth_tokens(self, context):
8358         """Remove expired console auth tokens for this host.
8359 
8360         Console authorization tokens and their connection data are stored
8361         in the database when a user asks for a console connection to an
8362         instance. After a time they expire. We periodically remove any expired
8363         tokens from the database.
8364         """
8365         # If the database backend isn't in use, don't bother looking for
8366         # expired tokens. The database backend is not supported for cells v1.
8367         if not CONF.cells.enable:
8368             objects.ConsoleAuthToken.\
8369                 clean_expired_console_auths_for_host(context, self.host)
