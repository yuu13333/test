I want you to act as a code reviewer of Nova in OpenStack. Please review the code below to detect security defects. If any are found, please describe the security defect in detail and indicate the corresponding line number of code and solution. If none are found, please state '''No security defects are detected in the code'''.

1 # Copyright 2010 United States Government as represented by the
2 # Administrator of the National Aeronautics and Space Administration.
3 # Copyright 2011 Justin Santa Barbara
4 # All Rights Reserved.
5 #
6 #    Licensed under the Apache License, Version 2.0 (the "License"); you may
7 #    not use this file except in compliance with the License. You may obtain
8 #    a copy of the License at
9 #
10 #         http://www.apache.org/licenses/LICENSE-2.0
11 #
12 #    Unless required by applicable law or agreed to in writing, software
13 #    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
14 #    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
15 #    License for the specific language governing permissions and limitations
16 #    under the License.
17 
18 """Handles all processes relating to instances (guest vms).
19 
20 The :py:class:`ComputeManager` class is a :py:class:`nova.manager.Manager` that
21 handles RPC calls relating to creating instances.  It is responsible for
22 building a disk image, launching it via the underlying virtualization driver,
23 responding to calls to check its state, attaching persistent storage, and
24 terminating it.
25 
26 """
27 
28 import base64
29 import contextlib
30 import functools
31 import inspect
32 import socket
33 import sys
34 import time
35 import traceback
36 import uuid
37 
38 from cinderclient import exceptions as cinder_exception
39 import eventlet.event
40 from eventlet import greenthread
41 import eventlet.semaphore
42 import eventlet.timeout
43 from keystoneauth1 import exceptions as keystone_exception
44 from oslo_config import cfg
45 from oslo_log import log as logging
46 import oslo_messaging as messaging
47 from oslo_serialization import jsonutils
48 from oslo_service import loopingcall
49 from oslo_service import periodic_task
50 from oslo_utils import excutils
51 from oslo_utils import strutils
52 from oslo_utils import timeutils
53 import six
54 from six.moves import range
55 
56 from nova import block_device
57 from nova.cells import rpcapi as cells_rpcapi
58 from nova.cloudpipe import pipelib
59 from nova import compute
60 from nova.compute import build_results
61 from nova.compute import claims
62 from nova.compute import power_state
63 from nova.compute import resource_tracker
64 from nova.compute import rpcapi as compute_rpcapi
65 from nova.compute import task_states
66 from nova.compute import utils as compute_utils
67 from nova.compute import vm_states
68 from nova import conductor
69 import nova.conf
70 from nova import consoleauth
71 import nova.context
72 from nova import exception
73 from nova import hooks
74 from nova.i18n import _
75 from nova.i18n import _LE
76 from nova.i18n import _LI
77 from nova.i18n import _LW
78 from nova import image
79 from nova.image import glance
80 from nova import manager
81 from nova import network
82 from nova.network import base_api as base_net_api
83 from nova.network import model as network_model
84 from nova.network.security_group import openstack_driver
85 from nova import objects
86 from nova.objects import base as obj_base
87 from nova.objects import instance as obj_instance
88 from nova.objects import migrate_data as migrate_data_obj
89 from nova import paths
90 from nova import rpc
91 from nova import safe_utils
92 from nova.scheduler import client as scheduler_client
93 from nova import utils
94 from nova.virt import block_device as driver_block_device
95 from nova.virt import configdrive
96 from nova.virt import driver
97 from nova.virt import event as virtevent
98 from nova.virt import storage_users
99 from nova.virt import virtapi
100 from nova import volume
101 from nova.volume import encryptors
102 
103 
104 compute_opts = [
105     cfg.StrOpt('console_host',
106                default=socket.gethostname(),
107                help='Console proxy host to use to connect '
108                     'to instances on this host.'),
109     cfg.StrOpt('default_access_ip_network_name',
110                help='Name of network to use to set access IPs for instances'),
111     cfg.BoolOpt('defer_iptables_apply',
112                 default=False,
113                 help='Whether to batch up the application of IPTables rules'
114                      ' during a host restart and apply all at the end of the'
115                      ' init phase'),
116     cfg.StrOpt('instances_path',
117                default=paths.state_path_def('instances'),
118                help='Where instances are stored on disk'),
119     cfg.BoolOpt('instance_usage_audit',
120                 default=False,
121                 help="Generate periodic compute.instance.exists"
122                      " notifications"),
123     cfg.IntOpt('live_migration_retry_count',
124                default=30,
125                help="Number of 1 second retries needed in live_migration"),
126     cfg.BoolOpt('resume_guests_state_on_host_boot',
127                 default=False,
128                 help='Whether to start guests that were running before the '
129                      'host rebooted'),
130     cfg.IntOpt('network_allocate_retries',
131                default=0,
132                help="Number of times to retry network allocation on failures"),
133     cfg.IntOpt('max_concurrent_builds',
134                default=10,
135                help='Maximum number of instance builds to run concurrently'),
136     cfg.IntOpt('max_concurrent_live_migrations',
137                default=1,
138                help='Maximum number of live migrations to run concurrently. '
139                     'This limit is enforced to avoid outbound live migrations '
140                     'overwhelming the host/network and causing failures. It '
141                     'is not recommended that you change this unless you are '
142                     'very sure that doing so is safe and stable in your '
143                     'environment.'),
144     cfg.IntOpt('block_device_allocate_retries',
145                default=60,
146                help='Number of times to retry block device '
147                     'allocation on failures.\n'
148                     'Starting with Liberty, Cinder can use image volume '
149                     'cache. This may help with block device allocation '
150                     'performance. Look at the cinder '
151                     'image_volume_cache_enabled configuration option.')
152     ]
153 
154 interval_opts = [
155     cfg.IntOpt('bandwidth_poll_interval',
156                default=600,
157                help='Interval to pull network bandwidth usage info. Not '
158                     'supported on all hypervisors. Set to -1 to disable. '
159                     'Setting this to 0 will run at the default rate.'),
160     cfg.IntOpt('sync_power_state_interval',
161                default=600,
162                help='Interval to sync power states between the database and '
163                     'the hypervisor. Set to -1 to disable. '
164                     'Setting this to 0 will run at the default rate.'),
165     cfg.IntOpt("heal_instance_info_cache_interval",
166                default=60,
167                help="Number of seconds between instance network information "
168                     "cache updates"),
169     cfg.IntOpt('reclaim_instance_interval',
170                min=0,
171                default=0,
172                help='Interval in seconds for reclaiming deleted instances. '
173                     'It takes effect only when value is greater than 0.'),
174     cfg.IntOpt('volume_usage_poll_interval',
175                default=0,
176                help='Interval in seconds for gathering volume usages'),
177     cfg.IntOpt('shelved_poll_interval',
178                default=3600,
179                help='Interval in seconds for polling shelved instances to '
180                     'offload. Set to -1 to disable.'
181                     'Setting this to 0 will run at the default rate.'),
182     cfg.IntOpt('shelved_offload_time',
183                default=0,
184                help='Time in seconds before a shelved instance is eligible '
185                     'for removing from a host. -1 never offload, 0 offload '
186                     'immediately when shelved'),
187     cfg.IntOpt('instance_delete_interval',
188                default=300,
189                help='Interval in seconds for retrying failed instance file '
190                     'deletes. Set to -1 to disable. '
191                     'Setting this to 0 will run at the default rate.'),
192     cfg.IntOpt('block_device_allocate_retries_interval',
193                default=3,
194                help='Waiting time interval (seconds) between block'
195                     ' device allocation retries on failures'),
196     cfg.IntOpt('scheduler_instance_sync_interval',
197                default=120,
198                help='Waiting time interval (seconds) between sending the '
199                     'scheduler a list of current instance UUIDs to verify '
200                     'that its view of instances is in sync with nova. If the '
201                     'CONF option `scheduler_tracks_instance_changes` is '
202                     'False, changing this option will have no effect.'),
203     cfg.IntOpt('update_resources_interval',
204                default=0,
205                help='Interval in seconds for updating compute resources. A '
206                     'number less than 0 means to disable the task completely. '
207                     'Leaving this at the default of 0 will cause this to run '
208                     'at the default periodic interval. Setting it to any '
209                     'positive value will cause it to run at approximately '
210                     'that number of seconds.'),
211 ]
212 
213 timeout_opts = [
214     cfg.IntOpt("reboot_timeout",
215                default=0,
216                help="Automatically hard reboot an instance if it has been "
217                     "stuck in a rebooting state longer than N seconds. "
218                     "Set to 0 to disable."),
219     cfg.IntOpt("instance_build_timeout",
220                default=0,
221                help="Amount of time in seconds an instance can be in BUILD "
222                     "before going into ERROR status. "
223                     "Set to 0 to disable."),
224     cfg.IntOpt("rescue_timeout",
225                default=0,
226                help="Automatically unrescue an instance after N seconds. "
227                     "Set to 0 to disable."),
228     cfg.IntOpt("resize_confirm_window",
229                default=0,
230                help="Automatically confirm resizes after N seconds. "
231                     "Set to 0 to disable."),
232     cfg.IntOpt("shutdown_timeout",
233                default=60,
234                help="Total amount of time to wait in seconds for an instance "
235                     "to perform a clean shutdown."),
236 ]
237 
238 running_deleted_opts = [
239     cfg.StrOpt("running_deleted_instance_action",
240                default="reap",
241                choices=('noop', 'log', 'shutdown', 'reap'),
242                help="Action to take if a running deleted instance is detected."
243                     "Set to 'noop' to take no action."),
244     cfg.IntOpt("running_deleted_instance_poll_interval",
245                default=1800,
246                help="Number of seconds to wait between runs of the cleanup "
247                     "task."),
248     cfg.IntOpt("running_deleted_instance_timeout",
249                default=0,
250                help="Number of seconds after being deleted when a running "
251                     "instance should be considered eligible for cleanup."),
252 ]
253 
254 instance_cleaning_opts = [
255     cfg.IntOpt('maximum_instance_delete_attempts',
256                default=5,
257                help='The number of times to attempt to reap an instance\'s '
258                     'files.'),
259 ]
260 
261 CONF = nova.conf.CONF
262 CONF.register_opts(compute_opts)
263 CONF.register_opts(interval_opts)
264 CONF.register_opts(timeout_opts)
265 CONF.register_opts(running_deleted_opts)
266 CONF.register_opts(instance_cleaning_opts)
267 CONF.import_opt('console_topic', 'nova.console.rpcapi')
268 CONF.import_opt('host', 'nova.netconf')
269 CONF.import_opt('enabled', 'nova.spice', group='spice')
270 CONF.import_opt('image_cache_manager_interval', 'nova.virt.imagecache')
271 CONF.import_opt('enabled', 'nova.rdp', group='rdp')
272 CONF.import_opt('html5_proxy_base_url', 'nova.rdp', group='rdp')
273 CONF.import_opt('enabled', 'nova.mks', group='mks')
274 CONF.import_opt('mksproxy_base_url', 'nova.mks', group='mks')
275 CONF.import_opt('destroy_after_evacuate', 'nova.utils', group='workarounds')
276 CONF.import_opt('scheduler_tracks_instance_changes',
277                 'nova.scheduler.host_manager')
278 
279 LOG = logging.getLogger(__name__)
280 
281 get_notifier = functools.partial(rpc.get_notifier, service='compute')
282 wrap_exception = functools.partial(exception.wrap_exception,
283                                    get_notifier=get_notifier)
284 
285 
286 @utils.expects_func_args('migration')
287 def errors_out_migration(function):
288     """Decorator to error out migration on failure."""
289 
290     @functools.wraps(function)
291     def decorated_function(self, context, *args, **kwargs):
292         try:
293             return function(self, context, *args, **kwargs)
294         except Exception as ex:
295             with excutils.save_and_reraise_exception():
296                 wrapped_func = safe_utils.get_wrapped_function(function)
297                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
298                                                  *args, **kwargs)
299                 migration = keyed_args['migration']
300 
301                 # NOTE(rajesht): If InstanceNotFound error is thrown from
302                 # decorated function, migration status should be set to
303                 # 'error', without checking current migration status.
304                 if not isinstance(ex, exception.InstanceNotFound):
305                     status = migration.status
306                     if status not in ['migrating', 'post-migrating']:
307                         return
308 
309                 migration.status = 'error'
310                 try:
311                     with migration.obj_as_admin():
312                         migration.save()
313                 except Exception:
314                     LOG.debug('Error setting migration status '
315                               'for instance %s.',
316                               migration.instance_uuid, exc_info=True)
317 
318     return decorated_function
319 
320 
321 @utils.expects_func_args('instance')
322 def reverts_task_state(function):
323     """Decorator to revert task_state on failure."""
324 
325     @functools.wraps(function)
326     def decorated_function(self, context, *args, **kwargs):
327         try:
328             return function(self, context, *args, **kwargs)
329         except exception.UnexpectedTaskStateError as e:
330             # Note(maoy): unexpected task state means the current
331             # task is preempted. Do not clear task state in this
332             # case.
333             with excutils.save_and_reraise_exception():
334                 LOG.info(_LI("Task possibly preempted: %s"),
335                          e.format_message())
336         except Exception:
337             with excutils.save_and_reraise_exception():
338                 wrapped_func = safe_utils.get_wrapped_function(function)
339                 keyed_args = inspect.getcallargs(wrapped_func, self, context,
340                                                  *args, **kwargs)
341                 # NOTE(mriedem): 'instance' must be in keyed_args because we
342                 # have utils.expects_func_args('instance') decorating this
343                 # method.
344                 instance = keyed_args['instance']
345                 original_task_state = instance.task_state
346                 try:
347                     self._instance_update(context, instance, task_state=None)
348                     LOG.info(_LI("Successfully reverted task state from %s on "
349                                  "failure for instance."), original_task_state,
350                                                            instance=instance)
351                 except exception.InstanceNotFound:
352                     # We might delete an instance that failed to build shortly
353                     # after it errored out this is an expected case and we
354                     # should not trace on it.
355                     pass
356                 except Exception as e:
357                     msg = _LW("Failed to revert task state for instance. "
358                               "Error: %s")
359                     LOG.warning(msg, e, instance=instance)
360 
361     return decorated_function
362 
363 
364 @utils.expects_func_args('instance')
365 def wrap_instance_fault(function):
366     """Wraps a method to catch exceptions related to instances.
367 
368     This decorator wraps a method to catch any exceptions having to do with
369     an instance that may get thrown. It then logs an instance fault in the db.
370     """
371 
372     @functools.wraps(function)
373     def decorated_function(self, context, *args, **kwargs):
374         try:
375             return function(self, context, *args, **kwargs)
376         except exception.InstanceNotFound:
377             raise
378         except Exception as e:
379             # NOTE(gtt): If argument 'instance' is in args rather than kwargs,
380             # we will get a KeyError exception which will cover up the real
381             # exception. So, we update kwargs with the values from args first.
382             # then, we can get 'instance' from kwargs easily.
383             kwargs.update(dict(zip(function.__code__.co_varnames[2:], args)))
384 
385             with excutils.save_and_reraise_exception():
386                 compute_utils.add_instance_fault_from_exc(context,
387                         kwargs['instance'], e, sys.exc_info())
388 
389     return decorated_function
390 
391 
392 @utils.expects_func_args('instance')
393 def wrap_instance_event(function):
394     """Wraps a method to log the event taken on the instance, and result.
395 
396     This decorator wraps a method to log the start and result of an event, as
397     part of an action taken on an instance.
398     """
399 
400     @functools.wraps(function)
401     def decorated_function(self, context, *args, **kwargs):
402         wrapped_func = safe_utils.get_wrapped_function(function)
403         keyed_args = inspect.getcallargs(wrapped_func, self, context, *args,
404                                          **kwargs)
405         instance_uuid = keyed_args['instance']['uuid']
406 
407         event_name = 'compute_{0}'.format(function.__name__)
408         with compute_utils.EventReporter(context, event_name, instance_uuid):
409             return function(self, context, *args, **kwargs)
410 
411     return decorated_function
412 
413 
414 @utils.expects_func_args('image_id', 'instance')
415 def delete_image_on_error(function):
416     """Used for snapshot related method to ensure the image created in
417     compute.api is deleted when an error occurs.
418     """
419 
420     @functools.wraps(function)
421     def decorated_function(self, context, image_id, instance,
422                            *args, **kwargs):
423         try:
424             return function(self, context, image_id, instance,
425                             *args, **kwargs)
426         except Exception:
427             with excutils.save_and_reraise_exception():
428                 LOG.debug("Cleaning up image %s", image_id,
429                           exc_info=True, instance=instance)
430                 try:
431                     self.image_api.delete(context, image_id)
432                 except Exception:
433                     LOG.exception(_LE("Error while trying to clean up "
434                                       "image %s"), image_id,
435                                   instance=instance)
436 
437     return decorated_function
438 
439 
440 # TODO(danms): Remove me after Icehouse
441 # NOTE(mikal): if the method being decorated has more than one decorator, then
442 # put this one first. Otherwise the various exception handling decorators do
443 # not function correctly.
444 def object_compat(function):
445     """Wraps a method that expects a new-world instance
446 
447     This provides compatibility for callers passing old-style dict
448     instances.
449     """
450 
451     @functools.wraps(function)
452     def decorated_function(self, context, *args, **kwargs):
453         def _load_instance(instance_or_dict):
454             if isinstance(instance_or_dict, dict):
455                 # try to get metadata and system_metadata for most cases but
456                 # only attempt to load those if the db instance already has
457                 # those fields joined
458                 metas = [meta for meta in ('metadata', 'system_metadata')
459                          if meta in instance_or_dict]
460                 instance = objects.Instance._from_db_object(
461                     context, objects.Instance(), instance_or_dict,
462                     expected_attrs=metas)
463                 instance._context = context
464                 return instance
465             return instance_or_dict
466 
467         try:
468             kwargs['instance'] = _load_instance(kwargs['instance'])
469         except KeyError:
470             args = (_load_instance(args[0]),) + args[1:]
471 
472         migration = kwargs.get('migration')
473         if isinstance(migration, dict):
474             migration = objects.Migration._from_db_object(
475                     context.elevated(), objects.Migration(),
476                     migration)
477             kwargs['migration'] = migration
478 
479         return function(self, context, *args, **kwargs)
480 
481     return decorated_function
482 
483 
484 class InstanceEvents(object):
485     def __init__(self):
486         self._events = {}
487 
488     @staticmethod
489     def _lock_name(instance):
490         return '%s-%s' % (instance.uuid, 'events')
491 
492     def prepare_for_instance_event(self, instance, event_name):
493         """Prepare to receive an event for an instance.
494 
495         This will register an event for the given instance that we will
496         wait on later. This should be called before initiating whatever
497         action will trigger the event. The resulting eventlet.event.Event
498         object should be wait()'d on to ensure completion.
499 
500         :param instance: the instance for which the event will be generated
501         :param event_name: the name of the event we're expecting
502         :returns: an event object that should be wait()'d on
503         """
504         if self._events is None:
505             # NOTE(danms): We really should have a more specific error
506             # here, but this is what we use for our default error case
507             raise exception.NovaException('In shutdown, no new events '
508                                           'can be scheduled')
509 
510         @utils.synchronized(self._lock_name(instance))
511         def _create_or_get_event():
512             instance_events = self._events.setdefault(instance.uuid, {})
513             return instance_events.setdefault(event_name,
514                                               eventlet.event.Event())
515         LOG.debug('Preparing to wait for external event %(event)s',
516                   {'event': event_name}, instance=instance)
517         return _create_or_get_event()
518 
519     def pop_instance_event(self, instance, event):
520         """Remove a pending event from the wait list.
521 
522         This will remove a pending event from the wait list so that it
523         can be used to signal the waiters to wake up.
524 
525         :param instance: the instance for which the event was generated
526         :param event: the nova.objects.external_event.InstanceExternalEvent
527                       that describes the event
528         :returns: the eventlet.event.Event object on which the waiters
529                   are blocked
530         """
531         no_events_sentinel = object()
532         no_matching_event_sentinel = object()
533 
534         @utils.synchronized(self._lock_name(instance))
535         def _pop_event():
536             if not self._events:
537                 LOG.debug('Unexpected attempt to pop events during shutdown',
538                           instance=instance)
539                 return no_events_sentinel
540             events = self._events.get(instance.uuid)
541             if not events:
542                 return no_events_sentinel
543             _event = events.pop(event.key, None)
544             if not events:
545                 del self._events[instance.uuid]
546             if _event is None:
547                 return no_matching_event_sentinel
548             return _event
549 
550         result = _pop_event()
551         if result is no_events_sentinel:
552             LOG.debug('No waiting events found dispatching %(event)s',
553                       {'event': event.key},
554                       instance=instance)
555             return None
556         elif result is no_matching_event_sentinel:
557             LOG.debug('No event matching %(event)s in %(events)s',
558                       {'event': event.key,
559                        'events': self._events.get(instance.uuid, {}).keys()},
560                       instance=instance)
561             return None
562         else:
563             return result
564 
565     def clear_events_for_instance(self, instance):
566         """Remove all pending events for an instance.
567 
568         This will remove all events currently pending for an instance
569         and return them (indexed by event name).
570 
571         :param instance: the instance for which events should be purged
572         :returns: a dictionary of {event_name: eventlet.event.Event}
573         """
574         @utils.synchronized(self._lock_name(instance))
575         def _clear_events():
576             if self._events is None:
577                 LOG.debug('Unexpected attempt to clear events during shutdown',
578                           instance=instance)
579                 return dict()
580             return self._events.pop(instance.uuid, {})
581         return _clear_events()
582 
583     def cancel_all_events(self):
584         our_events = self._events
585         # NOTE(danms): Block new events
586         self._events = None
587 
588         for instance_uuid, events in our_events.items():
589             for event_name, eventlet_event in events.items():
590                 LOG.debug('Canceling in-flight event %(event)s for '
591                           'instance %(instance_uuid)s',
592                           {'event': event_name,
593                            'instance_uuid': instance_uuid})
594                 name, tag = event_name.rsplit('-', 1)
595                 event = objects.InstanceExternalEvent(
596                     instance_uuid=instance_uuid,
597                     name=name, status='failed',
598                     tag=tag, data={})
599                 eventlet_event.send(event)
600 
601 
602 class ComputeVirtAPI(virtapi.VirtAPI):
603     def __init__(self, compute):
604         super(ComputeVirtAPI, self).__init__()
605         self._compute = compute
606 
607     def _default_error_callback(self, event_name, instance):
608         raise exception.NovaException(_('Instance event failed'))
609 
610     @contextlib.contextmanager
611     def wait_for_instance_event(self, instance, event_names, deadline=300,
612                                 error_callback=None):
613         """Plan to wait for some events, run some code, then wait.
614 
615         This context manager will first create plans to wait for the
616         provided event_names, yield, and then wait for all the scheduled
617         events to complete.
618 
619         Note that this uses an eventlet.timeout.Timeout to bound the
620         operation, so callers should be prepared to catch that
621         failure and handle that situation appropriately.
622 
623         If the event is not received by the specified timeout deadline,
624         eventlet.timeout.Timeout is raised.
625 
626         If the event is received but did not have a 'completed'
627         status, a NovaException is raised.  If an error_callback is
628         provided, instead of raising an exception as detailed above
629         for the failure case, the callback will be called with the
630         event_name and instance, and can return True to continue
631         waiting for the rest of the events, False to stop processing,
632         or raise an exception which will bubble up to the waiter.
633 
634         :param instance: The instance for which an event is expected
635         :param event_names: A list of event names. Each element can be a
636                             string event name or tuple of strings to
637                             indicate (name, tag).
638         :param deadline: Maximum number of seconds we should wait for all
639                          of the specified events to arrive.
640         :param error_callback: A function to be called if an event arrives
641 
642         """
643 
644         if error_callback is None:
645             error_callback = self._default_error_callback
646         events = {}
647         for event_name in event_names:
648             if isinstance(event_name, tuple):
649                 name, tag = event_name
650                 event_name = objects.InstanceExternalEvent.make_key(
651                     name, tag)
652             try:
653                 events[event_name] = (
654                     self._compute.instance_events.prepare_for_instance_event(
655                         instance, event_name))
656             except exception.NovaException:
657                 error_callback(event_name, instance)
658                 # NOTE(danms): Don't wait for any of the events. They
659                 # should all be canceled and fired immediately below,
660                 # but don't stick around if not.
661                 deadline = 0
662         yield
663         with eventlet.timeout.Timeout(deadline):
664             for event_name, event in events.items():
665                 actual_event = event.wait()
666                 if actual_event.status == 'completed':
667                     continue
668                 decision = error_callback(event_name, instance)
669                 if decision is False:
670                     break
671 
672 
673 _SENTINEL = object()
674 
675 
676 class ComputeManager(manager.Manager):
677     """Manages the running instances from creation to destruction."""
678 
679     target = messaging.Target(version='4.11')
680 
681     # How long to wait in seconds before re-issuing a shutdown
682     # signal to an instance during power off.  The overall
683     # time to wait is set by CONF.shutdown_timeout.
684     SHUTDOWN_RETRY_INTERVAL = 10
685 
686     def __init__(self, compute_driver=None, *args, **kwargs):
687         """Load configuration options and connect to the hypervisor."""
688         self.virtapi = ComputeVirtAPI(self)
689         self.network_api = network.API()
690         self.volume_api = volume.API()
691         self.image_api = image.API()
692         self._last_host_check = 0
693         self._last_bw_usage_poll = 0
694         self._bw_usage_supported = True
695         self._last_bw_usage_cell_update = 0
696         self.compute_api = compute.API()
697         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
698         self.conductor_api = conductor.API()
699         self.compute_task_api = conductor.ComputeTaskAPI()
700         self.is_neutron_security_groups = (
701             openstack_driver.is_neutron_security_groups())
702         self.consoleauth_rpcapi = consoleauth.rpcapi.ConsoleAuthAPI()
703         self.cells_rpcapi = cells_rpcapi.CellsAPI()
704         self.scheduler_client = scheduler_client.SchedulerClient()
705         self._resource_tracker_dict = {}
706         self.instance_events = InstanceEvents()
707         self._sync_power_pool = eventlet.GreenPool()
708         self._syncs_in_progress = {}
709         self.send_instance_updates = CONF.scheduler_tracks_instance_changes
710         if CONF.max_concurrent_builds != 0:
711             self._build_semaphore = eventlet.semaphore.Semaphore(
712                 CONF.max_concurrent_builds)
713         else:
714             self._build_semaphore = compute_utils.UnlimitedSemaphore()
715         if max(CONF.max_concurrent_live_migrations, 0) != 0:
716             self._live_migration_semaphore = eventlet.semaphore.Semaphore(
717                 CONF.max_concurrent_live_migrations)
718         else:
719             self._live_migration_semaphore = compute_utils.UnlimitedSemaphore()
720 
721         super(ComputeManager, self).__init__(service_name="compute",
722                                              *args, **kwargs)
723 
724         # NOTE(russellb) Load the driver last.  It may call back into the
725         # compute manager via the virtapi, so we want it to be fully
726         # initialized before that happens.
727         self.driver = driver.load_compute_driver(self.virtapi, compute_driver)
728         self.use_legacy_block_device_info = \
729                             self.driver.need_legacy_block_device_info
730 
731     def reset(self):
732         LOG.info(_LI('Reloading compute RPC API'))
733         compute_rpcapi.LAST_VERSION = None
734         self.compute_rpcapi = compute_rpcapi.ComputeAPI()
735 
736     def _get_resource_tracker(self, nodename):
737         rt = self._resource_tracker_dict.get(nodename)
738         if not rt:
739             if not self.driver.node_is_available(nodename):
740                 raise exception.NovaException(
741                         _("%s is not a valid node managed by this "
742                           "compute host.") % nodename)
743 
744             rt = resource_tracker.ResourceTracker(self.host,
745                                                   self.driver,
746                                                   nodename)
747             self._resource_tracker_dict[nodename] = rt
748         return rt
749 
750     def _update_resource_tracker(self, context, instance):
751         """Let the resource tracker know that an instance has changed state."""
752 
753         if (instance.host == self.host and
754                 self.driver.node_is_available(instance.node)):
755             rt = self._get_resource_tracker(instance.node)
756             rt.update_usage(context, instance)
757 
758     def _instance_update(self, context, instance, **kwargs):
759         """Update an instance in the database using kwargs as value."""
760 
761         for k, v in kwargs.items():
762             setattr(instance, k, v)
763         instance.save()
764         self._update_resource_tracker(context, instance)
765 
766     def _nil_out_instance_obj_host_and_node(self, instance):
767         # NOTE(jwcroppe): We don't do instance.save() here for performance
768         # reasons; a call to this is expected to be immediately followed by
769         # another call that does instance.save(), thus avoiding two writes
770         # to the database layer.
771         instance.host = None
772         instance.node = None
773 
774     def _set_instance_obj_error_state(self, context, instance,
775                                       clean_task_state=False):
776         try:
777             instance.vm_state = vm_states.ERROR
778             if clean_task_state:
779                 instance.task_state = None
780             instance.save()
781         except exception.InstanceNotFound:
782             LOG.debug('Instance has been destroyed from under us while '
783                       'trying to set it to ERROR', instance=instance)
784 
785     def _get_instances_on_driver(self, context, filters=None):
786         """Return a list of instance records for the instances found
787         on the hypervisor which satisfy the specified filters. If filters=None
788         return a list of instance records for all the instances found on the
789         hypervisor.
790         """
791         if not filters:
792             filters = {}
793         try:
794             driver_uuids = self.driver.list_instance_uuids()
795             if len(driver_uuids) == 0:
796                 # Short circuit, don't waste a DB call
797                 return objects.InstanceList()
798             filters['uuid'] = driver_uuids
799             local_instances = objects.InstanceList.get_by_filters(
800                 context, filters, use_slave=True)
801             return local_instances
802         except NotImplementedError:
803             pass
804 
805         # The driver doesn't support uuids listing, so we'll have
806         # to brute force.
807         driver_instances = self.driver.list_instances()
808         instances = objects.InstanceList.get_by_filters(context, filters,
809                                                         use_slave=True)
810         name_map = {instance.name: instance for instance in instances}
811         local_instances = []
812         for driver_instance in driver_instances:
813             instance = name_map.get(driver_instance)
814             if not instance:
815                 continue
816             local_instances.append(instance)
817         return local_instances
818 
819     def _destroy_evacuated_instances(self, context):
820         """Destroys evacuated instances.
821 
822         While nova-compute was down, the instances running on it could be
823         evacuated to another host. Check that the instances reported
824         by the driver are still associated with this host.  If they are
825         not, destroy them, with the exception of instances which are in
826         the MIGRATING, RESIZE_MIGRATING, RESIZE_MIGRATED, RESIZE_FINISH
827         task state or RESIZED vm state.
828         """
829         filters = {
830             'source_compute': self.host,
831             'status': ['accepted', 'done'],
832             'migration_type': 'evacuation',
833         }
834         evacuations = objects.MigrationList.get_by_filters(context, filters)
835         if not evacuations:
836             return
837         evacuations = {mig.instance_uuid: mig for mig in evacuations}
838 
839         filters = {'deleted': False}
840         local_instances = self._get_instances_on_driver(context, filters)
841         evacuated = [inst for inst in local_instances
842                      if inst.uuid in evacuations]
843         for instance in evacuated:
844             migration = evacuations[instance.uuid]
845             LOG.info(_LI('Deleting instance as it has been evacuated from '
846                          'this host'), instance=instance)
847             try:
848                 network_info = self.network_api.get_instance_nw_info(
849                     context, instance)
850                 bdi = self._get_instance_block_device_info(context,
851                                                            instance)
852                 destroy_disks = not (self._is_instance_storage_shared(
853                     context, instance))
854             except exception.InstanceNotFound:
855                 network_info = network_model.NetworkInfo()
856                 bdi = {}
857                 LOG.info(_LI('Instance has been marked deleted already, '
858                              'removing it from the hypervisor.'),
859                          instance=instance)
860                 # always destroy disks if the instance was deleted
861                 destroy_disks = True
862             self.driver.destroy(context, instance,
863                                 network_info,
864                                 bdi, destroy_disks)
865             migration.status = 'completed'
866             migration.save()
867 
868     def _is_instance_storage_shared(self, context, instance, host=None):
869         shared_storage = True
870         data = None
871         try:
872             data = self.driver.check_instance_shared_storage_local(context,
873                                                        instance)
874             if data:
875                 shared_storage = (self.compute_rpcapi.
876                                   check_instance_shared_storage(context,
877                                   instance, data, host=host))
878         except NotImplementedError:
879             LOG.debug('Hypervisor driver does not support '
880                       'instance shared storage check, '
881                       'assuming it\'s not on shared storage',
882                       instance=instance)
883             shared_storage = False
884         except Exception:
885             LOG.exception(_LE('Failed to check if instance shared'),
886                       instance=instance)
887         finally:
888             if data:
889                 self.driver.check_instance_shared_storage_cleanup(context,
890                                                                   data)
891         return shared_storage
892 
893     def _complete_partial_deletion(self, context, instance):
894         """Complete deletion for instances in DELETED status but not marked as
895         deleted in the DB
896         """
897         system_meta = instance.system_metadata
898         instance.destroy()
899         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
900                 context, instance.uuid)
901         quotas = objects.Quotas(context=context)
902         project_id, user_id = objects.quotas.ids_from_instance(context,
903                                                                instance)
904         quotas.reserve(project_id=project_id, user_id=user_id, instances=-1,
905                        cores=-instance.vcpus, ram=-instance.memory_mb)
906         self._complete_deletion(context,
907                                 instance,
908                                 bdms,
909                                 quotas,
910                                 system_meta)
911 
912     def _complete_deletion(self, context, instance, bdms,
913                            quotas, system_meta):
914         if quotas:
915             quotas.commit()
916 
917         # ensure block device mappings are not leaked
918         for bdm in bdms:
919             bdm.destroy()
920 
921         self._notify_about_instance_usage(context, instance, "delete.end",
922                 system_metadata=system_meta)
923 
924         self._clean_instance_console_tokens(context, instance)
925         self._delete_scheduler_instance_info(context, instance.uuid)
926 
927     def _create_reservations(self, context, instance, project_id, user_id):
928         vcpus = instance.vcpus
929         mem_mb = instance.memory_mb
930 
931         quotas = objects.Quotas(context=context)
932         quotas.reserve(project_id=project_id,
933                        user_id=user_id,
934                        instances=-1,
935                        cores=-vcpus,
936                        ram=-mem_mb)
937         return quotas
938 
939     def _init_instance(self, context, instance):
940         '''Initialize this instance during service init.'''
941 
942         # NOTE(danms): If the instance appears to not be owned by this
943         # host, it may have been evacuated away, but skipped by the
944         # evacuation cleanup code due to configuration. Thus, if that
945         # is a possibility, don't touch the instance in any way, but
946         # log the concern. This will help avoid potential issues on
947         # startup due to misconfiguration.
948         if instance.host != self.host:
949             LOG.warning(_LW('Instance %(uuid)s appears to not be owned '
950                             'by this host, but by %(host)s. Startup '
951                             'processing is being skipped.'),
952                         {'uuid': instance.uuid,
953                          'host': instance.host})
954             return
955 
956         # Instances that are shut down, or in an error state can not be
957         # initialized and are not attempted to be recovered. The exception
958         # to this are instances that are in RESIZE_MIGRATING or DELETING,
959         # which are dealt with further down.
960         if (instance.vm_state == vm_states.SOFT_DELETED or
961             (instance.vm_state == vm_states.ERROR and
962             instance.task_state not in
963             (task_states.RESIZE_MIGRATING, task_states.DELETING))):
964             LOG.debug("Instance is in %s state.",
965                       instance.vm_state, instance=instance)
966             return
967 
968         if instance.vm_state == vm_states.DELETED:
969             try:
970                 self._complete_partial_deletion(context, instance)
971             except Exception:
972                 # we don't want that an exception blocks the init_host
973                 msg = _LE('Failed to complete a deletion')
974                 LOG.exception(msg, instance=instance)
975             return
976 
977         if (instance.vm_state == vm_states.BUILDING or
978             instance.task_state in [task_states.SCHEDULING,
979                                     task_states.BLOCK_DEVICE_MAPPING,
980                                     task_states.NETWORKING,
981                                     task_states.SPAWNING]):
982             # NOTE(dave-mcnally) compute stopped before instance was fully
983             # spawned so set to ERROR state. This is safe to do as the state
984             # may be set by the api but the host is not so if we get here the
985             # instance has already been scheduled to this particular host.
986             LOG.debug("Instance failed to spawn correctly, "
987                       "setting to ERROR state", instance=instance)
988             instance.task_state = None
989             instance.vm_state = vm_states.ERROR
990             instance.save()
991             return
992 
993         if (instance.vm_state in [vm_states.ACTIVE, vm_states.STOPPED] and
994             instance.task_state in [task_states.REBUILDING,
995                                     task_states.REBUILD_BLOCK_DEVICE_MAPPING,
996                                     task_states.REBUILD_SPAWNING]):
997             # NOTE(jichenjc) compute stopped before instance was fully
998             # spawned so set to ERROR state. This is consistent to BUILD
999             LOG.debug("Instance failed to rebuild correctly, "
1000                       "setting to ERROR state", instance=instance)
1001             instance.task_state = None
1002             instance.vm_state = vm_states.ERROR
1003             instance.save()
1004             return
1005 
1006         if (instance.vm_state != vm_states.ERROR and
1007             instance.task_state in [task_states.IMAGE_SNAPSHOT_PENDING,
1008                                     task_states.IMAGE_PENDING_UPLOAD,
1009                                     task_states.IMAGE_UPLOADING,
1010                                     task_states.IMAGE_SNAPSHOT]):
1011             LOG.debug("Instance in transitional state %s at start-up "
1012                       "clearing task state",
1013                       instance.task_state, instance=instance)
1014             try:
1015                 self._post_interrupted_snapshot_cleanup(context, instance)
1016             except Exception:
1017                 # we don't want that an exception blocks the init_host
1018                 msg = _LE('Failed to cleanup snapshot.')
1019                 LOG.exception(msg, instance=instance)
1020             instance.task_state = None
1021             instance.save()
1022 
1023         if (instance.vm_state != vm_states.ERROR and
1024             instance.task_state in [task_states.RESIZE_PREP]):
1025             LOG.debug("Instance in transitional state %s at start-up "
1026                       "clearing task state",
1027                       instance['task_state'], instance=instance)
1028             instance.task_state = None
1029             instance.save()
1030 
1031         if instance.task_state == task_states.DELETING:
1032             try:
1033                 LOG.info(_LI('Service started deleting the instance during '
1034                              'the previous run, but did not finish. Restarting'
1035                              ' the deletion now.'), instance=instance)
1036                 instance.obj_load_attr('metadata')
1037                 instance.obj_load_attr('system_metadata')
1038                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1039                         context, instance.uuid)
1040                 project_id, user_id = objects.quotas.ids_from_instance(
1041                     context, instance)
1042                 quotas = self._create_reservations(context, instance,
1043                                                    project_id, user_id)
1044 
1045                 self._delete_instance(context, instance, bdms, quotas)
1046             except Exception:
1047                 # we don't want that an exception blocks the init_host
1048                 msg = _LE('Failed to complete a deletion')
1049                 LOG.exception(msg, instance=instance)
1050                 self._set_instance_obj_error_state(context, instance)
1051             return
1052 
1053         try_reboot, reboot_type = self._retry_reboot(context, instance)
1054         current_power_state = self._get_power_state(context, instance)
1055 
1056         if try_reboot:
1057             LOG.debug("Instance in transitional state (%(task_state)s) at "
1058                       "start-up and power state is (%(power_state)s), "
1059                       "triggering reboot",
1060                       {'task_state': instance.task_state,
1061                        'power_state': current_power_state},
1062                       instance=instance)
1063 
1064             # NOTE(mikal): if the instance was doing a soft reboot that got as
1065             # far as shutting down the instance but not as far as starting it
1066             # again, then we've just become a hard reboot. That means the
1067             # task state for the instance needs to change so that we're in one
1068             # of the expected task states for a hard reboot.
1069             soft_types = [task_states.REBOOT_STARTED,
1070                           task_states.REBOOT_PENDING,
1071                           task_states.REBOOTING]
1072             if instance.task_state in soft_types and reboot_type == 'HARD':
1073                 instance.task_state = task_states.REBOOT_PENDING_HARD
1074                 instance.save()
1075 
1076             self.reboot_instance(context, instance, block_device_info=None,
1077                                  reboot_type=reboot_type)
1078             return
1079 
1080         elif (current_power_state == power_state.RUNNING and
1081               instance.task_state in [task_states.REBOOT_STARTED,
1082                                       task_states.REBOOT_STARTED_HARD,
1083                                       task_states.PAUSING,
1084                                       task_states.UNPAUSING]):
1085             LOG.warning(_LW("Instance in transitional state "
1086                             "(%(task_state)s) at start-up and power state "
1087                             "is (%(power_state)s), clearing task state"),
1088                         {'task_state': instance.task_state,
1089                          'power_state': current_power_state},
1090                         instance=instance)
1091             instance.task_state = None
1092             instance.vm_state = vm_states.ACTIVE
1093             instance.save()
1094         elif (current_power_state == power_state.PAUSED and
1095               instance.task_state == task_states.UNPAUSING):
1096             LOG.warning(_LW("Instance in transitional state "
1097                             "(%(task_state)s) at start-up and power state "
1098                             "is (%(power_state)s), clearing task state "
1099                             "and unpausing the instance"),
1100                         {'task_state': instance.task_state,
1101                          'power_state': current_power_state},
1102                         instance=instance)
1103             try:
1104                 self.unpause_instance(context, instance)
1105             except NotImplementedError:
1106                 # Some virt driver didn't support pause and unpause
1107                 pass
1108             except Exception:
1109                 LOG.exception(_LE('Failed to unpause instance'),
1110                               instance=instance)
1111             return
1112 
1113         if instance.task_state == task_states.POWERING_OFF:
1114             try:
1115                 LOG.debug("Instance in transitional state %s at start-up "
1116                           "retrying stop request",
1117                           instance.task_state, instance=instance)
1118                 self.stop_instance(context, instance, True)
1119             except Exception:
1120                 # we don't want that an exception blocks the init_host
1121                 msg = _LE('Failed to stop instance')
1122                 LOG.exception(msg, instance=instance)
1123             return
1124 
1125         if instance.task_state == task_states.POWERING_ON:
1126             try:
1127                 LOG.debug("Instance in transitional state %s at start-up "
1128                           "retrying start request",
1129                           instance.task_state, instance=instance)
1130                 self.start_instance(context, instance)
1131             except Exception:
1132                 # we don't want that an exception blocks the init_host
1133                 msg = _LE('Failed to start instance')
1134                 LOG.exception(msg, instance=instance)
1135             return
1136 
1137         net_info = compute_utils.get_nw_info_for_instance(instance)
1138         try:
1139             self.driver.plug_vifs(instance, net_info)
1140         except NotImplementedError as e:
1141             LOG.debug(e, instance=instance)
1142         except exception.VirtualInterfacePlugException:
1143             # we don't want an exception to block the init_host
1144             LOG.exception(_LE("Vifs plug failed"), instance=instance)
1145             self._set_instance_obj_error_state(context, instance)
1146             return
1147 
1148         if instance.task_state == task_states.RESIZE_MIGRATING:
1149             # We crashed during resize/migration, so roll back for safety
1150             try:
1151                 # NOTE(mriedem): check old_vm_state for STOPPED here, if it's
1152                 # not in system_metadata we default to True for backwards
1153                 # compatibility
1154                 power_on = (instance.system_metadata.get('old_vm_state') !=
1155                             vm_states.STOPPED)
1156 
1157                 block_dev_info = self._get_instance_block_device_info(context,
1158                                                                       instance)
1159 
1160                 self.driver.finish_revert_migration(context,
1161                     instance, net_info, block_dev_info, power_on)
1162 
1163             except Exception:
1164                 LOG.exception(_LE('Failed to revert crashed migration'),
1165                               instance=instance)
1166             finally:
1167                 LOG.info(_LI('Instance found in migrating state during '
1168                              'startup. Resetting task_state'),
1169                          instance=instance)
1170                 instance.task_state = None
1171                 instance.save()
1172         if instance.task_state == task_states.MIGRATING:
1173             # Live migration did not complete, but instance is on this
1174             # host, so reset the state.
1175             instance.task_state = None
1176             instance.save(expected_task_state=[task_states.MIGRATING])
1177 
1178         db_state = instance.power_state
1179         drv_state = self._get_power_state(context, instance)
1180         expect_running = (db_state == power_state.RUNNING and
1181                           drv_state != db_state)
1182 
1183         LOG.debug('Current state is %(drv_state)s, state in DB is '
1184                   '%(db_state)s.',
1185                   {'drv_state': drv_state, 'db_state': db_state},
1186                   instance=instance)
1187 
1188         if expect_running and CONF.resume_guests_state_on_host_boot:
1189             LOG.info(_LI('Rebooting instance after nova-compute restart.'),
1190                      instance=instance)
1191 
1192             block_device_info = \
1193                 self._get_instance_block_device_info(context, instance)
1194 
1195             try:
1196                 self.driver.resume_state_on_host_boot(
1197                     context, instance, net_info, block_device_info)
1198             except NotImplementedError:
1199                 LOG.warning(_LW('Hypervisor driver does not support '
1200                                 'resume guests'), instance=instance)
1201             except Exception:
1202                 # NOTE(vish): The instance failed to resume, so we set the
1203                 #             instance to error and attempt to continue.
1204                 LOG.warning(_LW('Failed to resume instance'),
1205                             instance=instance)
1206                 self._set_instance_obj_error_state(context, instance)
1207 
1208         elif drv_state == power_state.RUNNING:
1209             # VMwareAPI drivers will raise an exception
1210             try:
1211                 self.driver.ensure_filtering_rules_for_instance(
1212                                        instance, net_info)
1213             except NotImplementedError:
1214                 LOG.debug('Hypervisor driver does not support '
1215                           'firewall rules', instance=instance)
1216 
1217     def _retry_reboot(self, context, instance):
1218         current_power_state = self._get_power_state(context, instance)
1219         current_task_state = instance.task_state
1220         retry_reboot = False
1221         reboot_type = compute_utils.get_reboot_type(current_task_state,
1222                                                     current_power_state)
1223 
1224         pending_soft = (current_task_state == task_states.REBOOT_PENDING and
1225                         instance.vm_state in vm_states.ALLOW_SOFT_REBOOT)
1226         pending_hard = (current_task_state == task_states.REBOOT_PENDING_HARD
1227                         and instance.vm_state in vm_states.ALLOW_HARD_REBOOT)
1228         started_not_running = (current_task_state in
1229                                [task_states.REBOOT_STARTED,
1230                                 task_states.REBOOT_STARTED_HARD] and
1231                                current_power_state != power_state.RUNNING)
1232 
1233         if pending_soft or pending_hard or started_not_running:
1234             retry_reboot = True
1235 
1236         return retry_reboot, reboot_type
1237 
1238     def handle_lifecycle_event(self, event):
1239         LOG.info(_LI("VM %(state)s (Lifecycle Event)"),
1240                  {'state': event.get_name()},
1241                  instance_uuid=event.get_instance_uuid())
1242         context = nova.context.get_admin_context(read_deleted='yes')
1243         instance = objects.Instance.get_by_uuid(context,
1244                                                 event.get_instance_uuid(),
1245                                                 expected_attrs=[])
1246         vm_power_state = None
1247         if event.get_transition() == virtevent.EVENT_LIFECYCLE_STOPPED:
1248             vm_power_state = power_state.SHUTDOWN
1249         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_STARTED:
1250             vm_power_state = power_state.RUNNING
1251         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_PAUSED:
1252             vm_power_state = power_state.PAUSED
1253         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_RESUMED:
1254             vm_power_state = power_state.RUNNING
1255         elif event.get_transition() == virtevent.EVENT_LIFECYCLE_SUSPENDED:
1256             vm_power_state = power_state.SUSPENDED
1257         else:
1258             LOG.warning(_LW("Unexpected power state %d"),
1259                         event.get_transition())
1260 
1261         # Note(lpetrut): The event may be delayed, thus not reflecting
1262         # the current instance power state. In that case, ignore the event.
1263         current_power_state = self._get_power_state(context, instance)
1264         if current_power_state == vm_power_state:
1265             LOG.debug('Synchronizing instance power state after lifecycle '
1266                       'event "%(event)s"; current vm_state: %(vm_state)s, '
1267                       'current task_state: %(task_state)s, current DB '
1268                       'power_state: %(db_power_state)s, VM power_state: '
1269                       '%(vm_power_state)s',
1270                       {'event': event.get_name(),
1271                        'vm_state': instance.vm_state,
1272                        'task_state': instance.task_state,
1273                        'db_power_state': instance.power_state,
1274                        'vm_power_state': vm_power_state},
1275                       instance_uuid=instance.uuid)
1276             self._sync_instance_power_state(context,
1277                                             instance,
1278                                             vm_power_state)
1279 
1280     def handle_events(self, event):
1281         if isinstance(event, virtevent.LifecycleEvent):
1282             try:
1283                 self.handle_lifecycle_event(event)
1284             except exception.InstanceNotFound:
1285                 LOG.debug("Event %s arrived for non-existent instance. The "
1286                           "instance was probably deleted.", event)
1287         else:
1288             LOG.debug("Ignoring event %s", event)
1289 
1290     def init_virt_events(self):
1291         if CONF.workarounds.handle_virt_lifecycle_events:
1292             self.driver.register_event_listener(self.handle_events)
1293         else:
1294             # NOTE(mriedem): If the _sync_power_states periodic task is
1295             # disabled we should emit a warning in the logs.
1296             if CONF.sync_power_state_interval < 0:
1297                 LOG.warning(_LW('Instance lifecycle events from the compute '
1298                              'driver have been disabled. Note that lifecycle '
1299                              'changes to an instance outside of the compute '
1300                              'service will not be synchronized '
1301                              'automatically since the _sync_power_states '
1302                              'periodic task is also disabled.'))
1303             else:
1304                 LOG.info(_LI('Instance lifecycle events from the compute '
1305                              'driver have been disabled. Note that lifecycle '
1306                              'changes to an instance outside of the compute '
1307                              'service will only be synchronized by the '
1308                              '_sync_power_states periodic task.'))
1309 
1310     def init_host(self):
1311         """Initialization for a standalone compute service."""
1312         self.driver.init_host(host=self.host)
1313         context = nova.context.get_admin_context()
1314         instances = objects.InstanceList.get_by_host(
1315             context, self.host, expected_attrs=['info_cache', 'metadata'])
1316 
1317         if CONF.defer_iptables_apply:
1318             self.driver.filter_defer_apply_on()
1319 
1320         self.init_virt_events()
1321 
1322         try:
1323             # checking that instance was not already evacuated to other host
1324             self._destroy_evacuated_instances(context)
1325             for instance in instances:
1326                 self._init_instance(context, instance)
1327         finally:
1328             if CONF.defer_iptables_apply:
1329                 self.driver.filter_defer_apply_off()
1330             self._update_scheduler_instance_info(context, instances)
1331 
1332     def cleanup_host(self):
1333         self.driver.register_event_listener(None)
1334         self.instance_events.cancel_all_events()
1335         self.driver.cleanup_host(host=self.host)
1336 
1337     def pre_start_hook(self):
1338         """After the service is initialized, but before we fully bring
1339         the service up by listening on RPC queues, make sure to update
1340         our available resources (and indirectly our available nodes).
1341         """
1342         self.update_available_resource(nova.context.get_admin_context())
1343 
1344     def _get_power_state(self, context, instance):
1345         """Retrieve the power state for the given instance."""
1346         LOG.debug('Checking state', instance=instance)
1347         try:
1348             return self.driver.get_info(instance).state
1349         except exception.InstanceNotFound:
1350             return power_state.NOSTATE
1351 
1352     def get_console_topic(self, context):
1353         """Retrieves the console host for a project on this host.
1354 
1355         Currently this is just set in the flags for each compute host.
1356 
1357         """
1358         # TODO(mdragon): perhaps make this variable by console_type?
1359         return '%s.%s' % (CONF.console_topic, CONF.console_host)
1360 
1361     @wrap_exception()
1362     def get_console_pool_info(self, context, console_type):
1363         return self.driver.get_console_pool_info(console_type)
1364 
1365     # NOTE(hanlind): This and the virt method it calls can be removed in
1366     # version 5.0 of the RPC API
1367     @wrap_exception()
1368     def refresh_security_group_rules(self, context, security_group_id):
1369         """Tell the virtualization driver to refresh security group rules.
1370 
1371         Passes straight through to the virtualization driver.
1372 
1373         """
1374         return self.driver.refresh_security_group_rules(security_group_id)
1375 
1376     @object_compat
1377     @wrap_exception()
1378     def refresh_instance_security_rules(self, context, instance):
1379         """Tell the virtualization driver to refresh security rules for
1380         an instance.
1381 
1382         Passes straight through to the virtualization driver.
1383 
1384         Synchronise the call because we may still be in the middle of
1385         creating the instance.
1386         """
1387         @utils.synchronized(instance.uuid)
1388         def _sync_refresh():
1389             try:
1390                 return self.driver.refresh_instance_security_rules(instance)
1391             except NotImplementedError:
1392                 LOG.debug('Hypervisor driver does not support '
1393                           'security groups.', instance=instance)
1394 
1395         return _sync_refresh()
1396 
1397     def _await_block_device_map_created(self, context, vol_id):
1398         # TODO(yamahata): creating volume simultaneously
1399         #                 reduces creation time?
1400         # TODO(yamahata): eliminate dumb polling
1401         start = time.time()
1402         retries = CONF.block_device_allocate_retries
1403         if retries < 0:
1404             LOG.warning(_LW("Treating negative config value (%(retries)s) for "
1405                             "'block_device_retries' as 0."),
1406                         {'retries': retries})
1407         # (1) treat  negative config value as 0
1408         # (2) the configured value is 0, one attempt should be made
1409         # (3) the configured value is > 0, then the total number attempts
1410         #      is (retries + 1)
1411         attempts = 1
1412         if retries >= 1:
1413             attempts = retries + 1
1414         for attempt in range(1, attempts + 1):
1415             volume = self.volume_api.get(context, vol_id)
1416             volume_status = volume['status']
1417             if volume_status not in ['creating', 'downloading']:
1418                 if volume_status == 'available':
1419                     return attempt
1420                 LOG.warning(_LW("Volume id: %(vol_id)s finished being "
1421                                 "created but its status is %(vol_status)s."),
1422                             {'vol_id': vol_id,
1423                              'vol_status': volume_status})
1424                 break
1425             greenthread.sleep(CONF.block_device_allocate_retries_interval)
1426         raise exception.VolumeNotCreated(volume_id=vol_id,
1427                                          seconds=int(time.time() - start),
1428                                          attempts=attempt,
1429                                          volume_status=volume_status)
1430 
1431     def _decode_files(self, injected_files):
1432         """Base64 decode the list of files to inject."""
1433         if not injected_files:
1434             return []
1435 
1436         def _decode(f):
1437             path, contents = f
1438             try:
1439                 decoded = base64.b64decode(contents)
1440                 return path, decoded
1441             except TypeError:
1442                 raise exception.Base64Exception(path=path)
1443 
1444         return [_decode(f) for f in injected_files]
1445 
1446     def _validate_instance_group_policy(self, context, instance,
1447             filter_properties):
1448         # NOTE(russellb) Instance group policy is enforced by the scheduler.
1449         # However, there is a race condition with the enforcement of
1450         # the policy.  Since more than one instance may be scheduled at the
1451         # same time, it's possible that more than one instance with an
1452         # anti-affinity policy may end up here.  It's also possible that
1453         # multiple instances with an affinity policy could end up on different
1454         # hosts.  This is a validation step to make sure that starting the
1455         # instance here doesn't violate the policy.
1456 
1457         scheduler_hints = filter_properties.get('scheduler_hints') or {}
1458         group_hint = scheduler_hints.get('group')
1459         if not group_hint:
1460             return
1461 
1462         @utils.synchronized(group_hint)
1463         def _do_validation(context, instance, group_hint):
1464             group = objects.InstanceGroup.get_by_hint(context, group_hint)
1465             if 'anti-affinity' in group.policies:
1466                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1467                 if self.host in group_hosts:
1468                     msg = _("Anti-affinity instance group policy "
1469                             "was violated.")
1470                     raise exception.RescheduledException(
1471                             instance_uuid=instance.uuid,
1472                             reason=msg)
1473             elif 'affinity' in group.policies:
1474                 group_hosts = group.get_hosts(exclude=[instance.uuid])
1475                 if group_hosts and self.host not in group_hosts:
1476                     msg = _("Affinity instance group policy was violated.")
1477                     raise exception.RescheduledException(
1478                             instance_uuid=instance.uuid,
1479                             reason=msg)
1480 
1481         _do_validation(context, instance, group_hint)
1482 
1483     def _log_original_error(self, exc_info, instance_uuid):
1484         LOG.error(_LE('Error: %s'), exc_info[1], instance_uuid=instance_uuid,
1485                   exc_info=exc_info)
1486 
1487     def _reschedule(self, context, request_spec, filter_properties,
1488             instance, reschedule_method, method_args, task_state,
1489             exc_info=None):
1490         """Attempt to re-schedule a compute operation."""
1491 
1492         instance_uuid = instance.uuid
1493         retry = filter_properties.get('retry')
1494         if not retry:
1495             # no retry information, do not reschedule.
1496             LOG.debug("Retry info not present, will not reschedule",
1497                       instance_uuid=instance_uuid)
1498             return
1499 
1500         if not request_spec:
1501             LOG.debug("No request spec, will not reschedule",
1502                       instance_uuid=instance_uuid)
1503             return
1504 
1505         LOG.debug("Re-scheduling %(method)s: attempt %(num)d",
1506                   {'method': reschedule_method.__name__,
1507                    'num': retry['num_attempts']}, instance_uuid=instance_uuid)
1508 
1509         # reset the task state:
1510         self._instance_update(context, instance, task_state=task_state)
1511 
1512         if exc_info:
1513             # stringify to avoid circular ref problem in json serialization:
1514             retry['exc'] = traceback.format_exception_only(exc_info[0],
1515                                     exc_info[1])
1516 
1517         reschedule_method(context, *method_args)
1518         return True
1519 
1520     @periodic_task.periodic_task
1521     def _check_instance_build_time(self, context):
1522         """Ensure that instances are not stuck in build."""
1523         timeout = CONF.instance_build_timeout
1524         if timeout == 0:
1525             return
1526 
1527         filters = {'vm_state': vm_states.BUILDING,
1528                    'host': self.host}
1529 
1530         building_insts = objects.InstanceList.get_by_filters(context,
1531                            filters, expected_attrs=[], use_slave=True)
1532 
1533         for instance in building_insts:
1534             if timeutils.is_older_than(instance.created_at, timeout):
1535                 self._set_instance_obj_error_state(context, instance)
1536                 LOG.warning(_LW("Instance build timed out. Set to error "
1537                                 "state."), instance=instance)
1538 
1539     def _check_instance_exists(self, context, instance):
1540         """Ensure an instance with the same name is not already present."""
1541         if self.driver.instance_exists(instance):
1542             raise exception.InstanceExists(name=instance.name)
1543 
1544     def _allocate_network_async(self, context, instance, requested_networks,
1545                                 macs, security_groups, is_vpn, dhcp_options):
1546         """Method used to allocate networks in the background.
1547 
1548         Broken out for testing.
1549         """
1550         LOG.debug("Allocating IP information in the background.",
1551                   instance=instance)
1552         retries = CONF.network_allocate_retries
1553         if retries < 0:
1554             LOG.warning(_LW("Treating negative config value (%(retries)s) for "
1555                             "'network_allocate_retries' as 0."),
1556                         {'retries': retries})
1557             retries = 0
1558         attempts = retries + 1
1559         retry_time = 1
1560         bind_host_id = self.driver.network_binding_host_id(context, instance)
1561         for attempt in range(1, attempts + 1):
1562             try:
1563                 nwinfo = self.network_api.allocate_for_instance(
1564                         context, instance, vpn=is_vpn,
1565                         requested_networks=requested_networks,
1566                         macs=macs,
1567                         security_groups=security_groups,
1568                         dhcp_options=dhcp_options,
1569                         bind_host_id=bind_host_id)
1570                 LOG.debug('Instance network_info: |%s|', nwinfo,
1571                           instance=instance)
1572                 instance.system_metadata['network_allocated'] = 'True'
1573                 # NOTE(JoshNang) do not save the instance here, as it can cause
1574                 # races. The caller shares a reference to instance and waits
1575                 # for this async greenthread to finish before calling
1576                 # instance.save().
1577                 return nwinfo
1578             except Exception:
1579                 exc_info = sys.exc_info()
1580                 log_info = {'attempt': attempt,
1581                             'attempts': attempts}
1582                 if attempt == attempts:
1583                     LOG.exception(_LE('Instance failed network setup '
1584                                       'after %(attempts)d attempt(s)'),
1585                                   log_info)
1586                     six.reraise(*exc_info)
1587                 LOG.warning(_LW('Instance failed network setup '
1588                                 '(attempt %(attempt)d of %(attempts)d)'),
1589                             log_info, instance=instance)
1590                 time.sleep(retry_time)
1591                 retry_time *= 2
1592                 if retry_time > 30:
1593                     retry_time = 30
1594         # Not reached.
1595 
1596     def _build_networks_for_instance(self, context, instance,
1597             requested_networks, security_groups):
1598 
1599         # If we're here from a reschedule the network may already be allocated.
1600         if strutils.bool_from_string(
1601                 instance.system_metadata.get('network_allocated', 'False')):
1602             # NOTE(alex_xu): The network_allocated is True means the network
1603             # resource already allocated at previous scheduling, and the
1604             # network setup is cleanup at previous. After rescheduling, the
1605             # network resource need setup on the new host.
1606             self.network_api.setup_instance_network_on_host(
1607                 context, instance, instance.host)
1608             return self.network_api.get_instance_nw_info(context, instance)
1609 
1610         if not self.is_neutron_security_groups:
1611             security_groups = []
1612 
1613         macs = self.driver.macs_for_instance(instance)
1614         dhcp_options = self.driver.dhcp_options_for_instance(instance)
1615         network_info = self._allocate_network(context, instance,
1616                 requested_networks, macs, security_groups, dhcp_options)
1617 
1618         return network_info
1619 
1620     def _allocate_network(self, context, instance, requested_networks, macs,
1621                           security_groups, dhcp_options):
1622         """Start network allocation asynchronously.  Return an instance
1623         of NetworkInfoAsyncWrapper that can be used to retrieve the
1624         allocated networks when the operation has finished.
1625         """
1626         # NOTE(comstud): Since we're allocating networks asynchronously,
1627         # this task state has little meaning, as we won't be in this
1628         # state for very long.
1629         instance.vm_state = vm_states.BUILDING
1630         instance.task_state = task_states.NETWORKING
1631         instance.save(expected_task_state=[None])
1632         self._update_resource_tracker(context, instance)
1633 
1634         is_vpn = pipelib.is_vpn_image(instance.image_ref)
1635         return network_model.NetworkInfoAsyncWrapper(
1636                 self._allocate_network_async, context, instance,
1637                 requested_networks, macs, security_groups, is_vpn,
1638                 dhcp_options)
1639 
1640     def _default_root_device_name(self, instance, image_meta, root_bdm):
1641         try:
1642             return self.driver.default_root_device_name(instance,
1643                                                         image_meta,
1644                                                         root_bdm)
1645         except NotImplementedError:
1646             return compute_utils.get_next_device_name(instance, [])
1647 
1648     def _default_device_names_for_instance(self, instance,
1649                                            root_device_name,
1650                                            *block_device_lists):
1651         try:
1652             self.driver.default_device_names_for_instance(instance,
1653                                                           root_device_name,
1654                                                           *block_device_lists)
1655         except NotImplementedError:
1656             compute_utils.default_device_names_for_instance(
1657                 instance, root_device_name, *block_device_lists)
1658 
1659     def _get_device_name_for_instance(self, instance, bdms, block_device_obj):
1660         # NOTE(ndipanov): Copy obj to avoid changing the original
1661         block_device_obj = block_device_obj.obj_clone()
1662         try:
1663             return self.driver.get_device_name_for_instance(
1664                 instance, bdms, block_device_obj)
1665         except NotImplementedError:
1666             return compute_utils.get_device_name_for_instance(
1667                 instance, bdms, block_device_obj.get("device_name"))
1668 
1669     def _default_block_device_names(self, context, instance,
1670                                     image_meta, block_devices):
1671         """Verify that all the devices have the device_name set. If not,
1672         provide a default name.
1673 
1674         It also ensures that there is a root_device_name and is set to the
1675         first block device in the boot sequence (boot_index=0).
1676         """
1677         root_bdm = block_device.get_root_bdm(block_devices)
1678         if not root_bdm:
1679             return
1680 
1681         # Get the root_device_name from the root BDM or the instance
1682         root_device_name = None
1683         update_root_bdm = False
1684 
1685         if root_bdm.device_name:
1686             root_device_name = root_bdm.device_name
1687             instance.root_device_name = root_device_name
1688         elif instance.root_device_name:
1689             root_device_name = instance.root_device_name
1690             root_bdm.device_name = root_device_name
1691             update_root_bdm = True
1692         else:
1693             root_device_name = self._default_root_device_name(instance,
1694                                                               image_meta,
1695                                                               root_bdm)
1696 
1697             instance.root_device_name = root_device_name
1698             root_bdm.device_name = root_device_name
1699             update_root_bdm = True
1700 
1701         if update_root_bdm:
1702             root_bdm.save()
1703 
1704         ephemerals = list(filter(block_device.new_format_is_ephemeral,
1705                             block_devices))
1706         swap = list(filter(block_device.new_format_is_swap,
1707                       block_devices))
1708         block_device_mapping = list(filter(
1709               driver_block_device.is_block_device_mapping, block_devices))
1710 
1711         self._default_device_names_for_instance(instance,
1712                                                 root_device_name,
1713                                                 ephemerals,
1714                                                 swap,
1715                                                 block_device_mapping)
1716 
1717     def _block_device_info_to_legacy(self, block_device_info):
1718         """Convert BDI to the old format for drivers that need it."""
1719 
1720         if self.use_legacy_block_device_info:
1721             ephemerals = driver_block_device.legacy_block_devices(
1722                 driver.block_device_info_get_ephemerals(block_device_info))
1723             mapping = driver_block_device.legacy_block_devices(
1724                 driver.block_device_info_get_mapping(block_device_info))
1725             swap = block_device_info['swap']
1726             if swap:
1727                 swap = swap.legacy()
1728 
1729             block_device_info.update({
1730                 'ephemerals': ephemerals,
1731                 'swap': swap,
1732                 'block_device_mapping': mapping})
1733 
1734     def _check_dev_name(self, bdms, instance):
1735         bdms_no_device_name = [x for x in bdms if x.device_name is None]
1736         for bdm in bdms_no_device_name:
1737             device_name = self._get_device_name_for_instance(instance,
1738                                                              bdms,
1739                                                              bdm)
1740             values = {'device_name': device_name}
1741             bdm.update(values)
1742 
1743     def _prep_block_device(self, context, instance, bdms,
1744                            do_check_attach=True):
1745         """Set up the block device for an instance with error logging."""
1746         try:
1747             self._check_dev_name(bdms, instance)
1748             block_device_info = driver.get_block_device_info(instance, bdms)
1749             mapping = driver.block_device_info_get_mapping(block_device_info)
1750             driver_block_device.attach_block_devices(
1751                 mapping, context, instance, self.volume_api, self.driver,
1752                 do_check_attach=do_check_attach,
1753                 wait_func=self._await_block_device_map_created)
1754 
1755             self._block_device_info_to_legacy(block_device_info)
1756             return block_device_info
1757 
1758         except exception.OverQuota:
1759             msg = _LW('Failed to create block device for instance due to '
1760                       'being over volume resource quota')
1761             LOG.warning(msg, instance=instance)
1762             raise exception.VolumeLimitExceeded()
1763 
1764         except Exception:
1765             LOG.exception(_LE('Instance failed block device setup'),
1766                           instance=instance)
1767             raise exception.InvalidBDM()
1768 
1769     def _update_instance_after_spawn(self, context, instance):
1770         instance.power_state = self._get_power_state(context, instance)
1771         instance.vm_state = vm_states.ACTIVE
1772         instance.task_state = None
1773         instance.launched_at = timeutils.utcnow()
1774         configdrive.update_instance(instance)
1775 
1776     def _update_scheduler_instance_info(self, context, instance):
1777         """Sends an InstanceList with created or updated Instance objects to
1778         the Scheduler client.
1779 
1780         In the case of init_host, the value passed will already be an
1781         InstanceList. Other calls will send individual Instance objects that
1782         have been created or resized. In this case, we create an InstanceList
1783         object containing that Instance.
1784         """
1785         if not self.send_instance_updates:
1786             return
1787         if isinstance(instance, obj_instance.Instance):
1788             instance = objects.InstanceList(objects=[instance])
1789         context = context.elevated()
1790         self.scheduler_client.update_instance_info(context, self.host,
1791                                                    instance)
1792 
1793     def _delete_scheduler_instance_info(self, context, instance_uuid):
1794         """Sends the uuid of the deleted Instance to the Scheduler client."""
1795         if not self.send_instance_updates:
1796             return
1797         context = context.elevated()
1798         self.scheduler_client.delete_instance_info(context, self.host,
1799                                                    instance_uuid)
1800 
1801     @periodic_task.periodic_task(spacing=CONF.scheduler_instance_sync_interval)
1802     def _sync_scheduler_instance_info(self, context):
1803         if not self.send_instance_updates:
1804             return
1805         context = context.elevated()
1806         instances = objects.InstanceList.get_by_host(context, self.host,
1807                                                      expected_attrs=[],
1808                                                      use_slave=True)
1809         uuids = [instance.uuid for instance in instances]
1810         self.scheduler_client.sync_instance_info(context, self.host, uuids)
1811 
1812     def _notify_about_instance_usage(self, context, instance, event_suffix,
1813                                      network_info=None, system_metadata=None,
1814                                      extra_usage_info=None, fault=None):
1815         compute_utils.notify_about_instance_usage(
1816             self.notifier, context, instance, event_suffix,
1817             network_info=network_info,
1818             system_metadata=system_metadata,
1819             extra_usage_info=extra_usage_info, fault=fault)
1820 
1821     def _deallocate_network(self, context, instance,
1822                             requested_networks=None):
1823         LOG.debug('Deallocating network for instance', instance=instance)
1824         with timeutils.StopWatch() as timer:
1825             self.network_api.deallocate_for_instance(
1826                 context, instance, requested_networks=requested_networks)
1827         # nova-network does an rpc call so we're OK tracking time spent here
1828         LOG.info(_LI('Took %0.2f seconds to deallocate network for instance.'),
1829                  timer.elapsed(), instance=instance)
1830 
1831     def _get_instance_block_device_info(self, context, instance,
1832                                         refresh_conn_info=False,
1833                                         bdms=None):
1834         """Transform block devices to the driver block_device format."""
1835 
1836         if not bdms:
1837             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
1838                     context, instance.uuid)
1839         block_device_info = driver.get_block_device_info(instance, bdms)
1840 
1841         if not refresh_conn_info:
1842             # if the block_device_mapping has no value in connection_info
1843             # (returned as None), don't include in the mapping
1844             block_device_info['block_device_mapping'] = [
1845                 bdm for bdm in driver.block_device_info_get_mapping(
1846                                     block_device_info)
1847                 if bdm.get('connection_info')]
1848         else:
1849             driver_block_device.refresh_conn_infos(
1850                 driver.block_device_info_get_mapping(block_device_info),
1851                 context, instance, self.volume_api, self.driver)
1852 
1853         self._block_device_info_to_legacy(block_device_info)
1854 
1855         return block_device_info
1856 
1857     @wrap_exception()
1858     @reverts_task_state
1859     @wrap_instance_fault
1860     def build_and_run_instance(self, context, instance, image, request_spec,
1861                      filter_properties, admin_password=None,
1862                      injected_files=None, requested_networks=None,
1863                      security_groups=None, block_device_mapping=None,
1864                      node=None, limits=None):
1865 
1866         @utils.synchronized(instance.uuid)
1867         def _locked_do_build_and_run_instance(*args, **kwargs):
1868             # NOTE(danms): We grab the semaphore with the instance uuid
1869             # locked because we could wait in line to build this instance
1870             # for a while and we want to make sure that nothing else tries
1871             # to do anything with this instance while we wait.
1872             with self._build_semaphore:
1873                 self._do_build_and_run_instance(*args, **kwargs)
1874 
1875         # NOTE(danms): We spawn here to return the RPC worker thread back to
1876         # the pool. Since what follows could take a really long time, we don't
1877         # want to tie up RPC workers.
1878         utils.spawn_n(_locked_do_build_and_run_instance,
1879                       context, instance, image, request_spec,
1880                       filter_properties, admin_password, injected_files,
1881                       requested_networks, security_groups,
1882                       block_device_mapping, node, limits)
1883 
1884     @hooks.add_hook('build_instance')
1885     @wrap_exception()
1886     @reverts_task_state
1887     @wrap_instance_event
1888     @wrap_instance_fault
1889     def _do_build_and_run_instance(self, context, instance, image,
1890             request_spec, filter_properties, admin_password, injected_files,
1891             requested_networks, security_groups, block_device_mapping,
1892             node=None, limits=None):
1893 
1894         try:
1895             LOG.debug('Starting instance...', context=context,
1896                       instance=instance)
1897             instance.vm_state = vm_states.BUILDING
1898             instance.task_state = None
1899             instance.save(expected_task_state=
1900                     (task_states.SCHEDULING, None))
1901         except exception.InstanceNotFound:
1902             msg = 'Instance disappeared before build.'
1903             LOG.debug(msg, instance=instance)
1904             return build_results.FAILED
1905         except exception.UnexpectedTaskStateError as e:
1906             LOG.debug(e.format_message(), instance=instance)
1907             return build_results.FAILED
1908 
1909         # b64 decode the files to inject:
1910         decoded_files = self._decode_files(injected_files)
1911 
1912         if limits is None:
1913             limits = {}
1914 
1915         if node is None:
1916             node = self.driver.get_available_nodes(refresh=True)[0]
1917             LOG.debug('No node specified, defaulting to %s', node,
1918                       instance=instance)
1919 
1920         try:
1921             with timeutils.StopWatch() as timer:
1922                 self._build_and_run_instance(context, instance, image,
1923                         decoded_files, admin_password, requested_networks,
1924                         security_groups, block_device_mapping, node, limits,
1925                         filter_properties)
1926             LOG.info(_LI('Took %0.2f seconds to build instance.'),
1927                      timer.elapsed(), instance=instance)
1928             return build_results.ACTIVE
1929         except exception.RescheduledException as e:
1930             retry = filter_properties.get('retry')
1931             if not retry:
1932                 # no retry information, do not reschedule.
1933                 LOG.debug("Retry info not present, will not reschedule",
1934                     instance=instance)
1935                 self._cleanup_allocated_networks(context, instance,
1936                     requested_networks)
1937                 compute_utils.add_instance_fault_from_exc(context,
1938                         instance, e, sys.exc_info(),
1939                         fault_message=e.kwargs['reason'])
1940                 self._nil_out_instance_obj_host_and_node(instance)
1941                 self._set_instance_obj_error_state(context, instance,
1942                                                    clean_task_state=True)
1943                 return build_results.FAILED
1944             LOG.debug(e.format_message(), instance=instance)
1945             # This will be used for logging the exception
1946             retry['exc'] = traceback.format_exception(*sys.exc_info())
1947             # This will be used for setting the instance fault message
1948             retry['exc_reason'] = e.kwargs['reason']
1949             # NOTE(comstud): Deallocate networks if the driver wants
1950             # us to do so.
1951             if self.driver.deallocate_networks_on_reschedule(instance):
1952                 self._cleanup_allocated_networks(context, instance,
1953                         requested_networks)
1954             else:
1955                 # NOTE(alex_xu): Network already allocated and we don't
1956                 # want to deallocate them before rescheduling. But we need
1957                 # to cleanup those network resources setup on this host before
1958                 # rescheduling.
1959                 self.network_api.cleanup_instance_network_on_host(
1960                     context, instance, self.host)
1961 
1962             self._nil_out_instance_obj_host_and_node(instance)
1963             instance.task_state = task_states.SCHEDULING
1964             instance.save()
1965 
1966             self.compute_task_api.build_instances(context, [instance],
1967                     image, filter_properties, admin_password,
1968                     injected_files, requested_networks, security_groups,
1969                     block_device_mapping)
1970             return build_results.RESCHEDULED
1971         except (exception.InstanceNotFound,
1972                 exception.UnexpectedDeletingTaskStateError):
1973             msg = 'Instance disappeared during build.'
1974             LOG.debug(msg, instance=instance)
1975             self._cleanup_allocated_networks(context, instance,
1976                     requested_networks)
1977             return build_results.FAILED
1978         except exception.BuildAbortException as e:
1979             LOG.exception(e.format_message(), instance=instance)
1980             self._cleanup_allocated_networks(context, instance,
1981                     requested_networks)
1982             self._cleanup_volumes(context, instance.uuid,
1983                     block_device_mapping, raise_exc=False)
1984             compute_utils.add_instance_fault_from_exc(context, instance,
1985                     e, sys.exc_info())
1986             self._nil_out_instance_obj_host_and_node(instance)
1987             self._set_instance_obj_error_state(context, instance,
1988                                                clean_task_state=True)
1989             return build_results.FAILED
1990         except Exception as e:
1991             # Should not reach here.
1992             msg = _LE('Unexpected build failure, not rescheduling build.')
1993             LOG.exception(msg, instance=instance)
1994             self._cleanup_allocated_networks(context, instance,
1995                     requested_networks)
1996             self._cleanup_volumes(context, instance.uuid,
1997                     block_device_mapping, raise_exc=False)
1998             compute_utils.add_instance_fault_from_exc(context, instance,
1999                     e, sys.exc_info())
2000             self._nil_out_instance_obj_host_and_node(instance)
2001             self._set_instance_obj_error_state(context, instance,
2002                                                clean_task_state=True)
2003             return build_results.FAILED
2004 
2005     def _build_and_run_instance(self, context, instance, image, injected_files,
2006             admin_password, requested_networks, security_groups,
2007             block_device_mapping, node, limits, filter_properties):
2008 
2009         image_name = image.get('name')
2010         self._notify_about_instance_usage(context, instance, 'create.start',
2011                 extra_usage_info={'image_name': image_name})
2012         try:
2013             rt = self._get_resource_tracker(node)
2014             with rt.instance_claim(context, instance, limits):
2015                 # NOTE(russellb) It's important that this validation be done
2016                 # *after* the resource tracker instance claim, as that is where
2017                 # the host is set on the instance.
2018                 self._validate_instance_group_policy(context, instance,
2019                         filter_properties)
2020                 image_meta = objects.ImageMeta.from_dict(image)
2021                 with self._build_resources(context, instance,
2022                         requested_networks, security_groups, image_meta,
2023                         block_device_mapping) as resources:
2024                     instance.vm_state = vm_states.BUILDING
2025                     instance.task_state = task_states.SPAWNING
2026                     # NOTE(JoshNang) This also saves the changes to the
2027                     # instance from _allocate_network_async, as they aren't
2028                     # saved in that function to prevent races.
2029                     instance.save(expected_task_state=
2030                             task_states.BLOCK_DEVICE_MAPPING)
2031                     block_device_info = resources['block_device_info']
2032                     network_info = resources['network_info']
2033                     LOG.debug('Start spawning the instance on the hypervisor.',
2034                               instance=instance)
2035                     with timeutils.StopWatch() as timer:
2036                         self.driver.spawn(context, instance, image_meta,
2037                                           injected_files, admin_password,
2038                                           network_info=network_info,
2039                                           block_device_info=block_device_info)
2040                     LOG.info(_LI('Took %0.2f seconds to spawn the instance on '
2041                                  'the hypervisor.'), timer.elapsed(),
2042                              instance=instance)
2043         except (exception.InstanceNotFound,
2044                 exception.UnexpectedDeletingTaskStateError) as e:
2045             with excutils.save_and_reraise_exception():
2046                 self._notify_about_instance_usage(context, instance,
2047                     'create.end', fault=e)
2048         except exception.ComputeResourcesUnavailable as e:
2049             LOG.debug(e.format_message(), instance=instance)
2050             self._notify_about_instance_usage(context, instance,
2051                     'create.error', fault=e)
2052             raise exception.RescheduledException(
2053                     instance_uuid=instance.uuid, reason=e.format_message())
2054         except exception.BuildAbortException as e:
2055             with excutils.save_and_reraise_exception():
2056                 LOG.debug(e.format_message(), instance=instance)
2057                 self._notify_about_instance_usage(context, instance,
2058                     'create.error', fault=e)
2059         except (exception.FixedIpLimitExceeded,
2060                 exception.NoMoreNetworks, exception.NoMoreFixedIps) as e:
2061             LOG.warning(_LW('No more network or fixed IP to be allocated'),
2062                         instance=instance)
2063             self._notify_about_instance_usage(context, instance,
2064                     'create.error', fault=e)
2065             msg = _('Failed to allocate the network(s) with error %s, '
2066                     'not rescheduling.') % e.format_message()
2067             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2068                     reason=msg)
2069         except (exception.VirtualInterfaceCreateException,
2070                 exception.VirtualInterfaceMacAddressException) as e:
2071             LOG.exception(_LE('Failed to allocate network(s)'),
2072                           instance=instance)
2073             self._notify_about_instance_usage(context, instance,
2074                     'create.error', fault=e)
2075             msg = _('Failed to allocate the network(s), not rescheduling.')
2076             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2077                     reason=msg)
2078         except (exception.FlavorDiskTooSmall,
2079                 exception.FlavorMemoryTooSmall,
2080                 exception.ImageNotActive,
2081                 exception.ImageUnacceptable,
2082                 exception.InvalidDiskInfo) as e:
2083             self._notify_about_instance_usage(context, instance,
2084                     'create.error', fault=e)
2085             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2086                     reason=e.format_message())
2087         except Exception as e:
2088             self._notify_about_instance_usage(context, instance,
2089                     'create.error', fault=e)
2090             raise exception.RescheduledException(
2091                     instance_uuid=instance.uuid, reason=six.text_type(e))
2092 
2093         # NOTE(alaski): This is only useful during reschedules, remove it now.
2094         instance.system_metadata.pop('network_allocated', None)
2095 
2096         # If CONF.default_access_ip_network_name is set, grab the
2097         # corresponding network and set the access ip values accordingly.
2098         network_name = CONF.default_access_ip_network_name
2099         if (network_name and not instance.access_ip_v4 and
2100                 not instance.access_ip_v6):
2101             # Note that when there are multiple ips to choose from, an
2102             # arbitrary one will be chosen.
2103             for vif in network_info:
2104                 if vif['network']['label'] == network_name:
2105                     for ip in vif.fixed_ips():
2106                         if not instance.access_ip_v4 and ip['version'] == 4:
2107                             instance.access_ip_v4 = ip['address']
2108                         if not instance.access_ip_v6 and ip['version'] == 6:
2109                             instance.access_ip_v6 = ip['address']
2110                     break
2111 
2112         self._update_instance_after_spawn(context, instance)
2113 
2114         try:
2115             instance.save(expected_task_state=task_states.SPAWNING)
2116         except (exception.InstanceNotFound,
2117                 exception.UnexpectedDeletingTaskStateError) as e:
2118             with excutils.save_and_reraise_exception():
2119                 self._notify_about_instance_usage(context, instance,
2120                     'create.end', fault=e)
2121 
2122         self._update_scheduler_instance_info(context, instance)
2123         self._notify_about_instance_usage(context, instance, 'create.end',
2124                 extra_usage_info={'message': _('Success')},
2125                 network_info=network_info)
2126 
2127     @contextlib.contextmanager
2128     def _build_resources(self, context, instance, requested_networks,
2129                          security_groups, image_meta, block_device_mapping):
2130         resources = {}
2131         network_info = None
2132         try:
2133             LOG.debug('Start building networks asynchronously for instance.',
2134                       instance=instance)
2135             network_info = self._build_networks_for_instance(context, instance,
2136                     requested_networks, security_groups)
2137             resources['network_info'] = network_info
2138         except (exception.InstanceNotFound,
2139                 exception.UnexpectedDeletingTaskStateError):
2140             raise
2141         except exception.UnexpectedTaskStateError as e:
2142             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2143                     reason=e.format_message())
2144         except Exception:
2145             # Because this allocation is async any failures are likely to occur
2146             # when the driver accesses network_info during spawn().
2147             LOG.exception(_LE('Failed to allocate network(s)'),
2148                           instance=instance)
2149             msg = _('Failed to allocate the network(s), not rescheduling.')
2150             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2151                     reason=msg)
2152 
2153         try:
2154             # Verify that all the BDMs have a device_name set and assign a
2155             # default to the ones missing it with the help of the driver.
2156             self._default_block_device_names(context, instance, image_meta,
2157                     block_device_mapping)
2158 
2159             LOG.debug('Start building block device mappings for instance.',
2160                       instance=instance)
2161             instance.vm_state = vm_states.BUILDING
2162             instance.task_state = task_states.BLOCK_DEVICE_MAPPING
2163             instance.save()
2164 
2165             block_device_info = self._prep_block_device(context, instance,
2166                     block_device_mapping)
2167             resources['block_device_info'] = block_device_info
2168         except (exception.InstanceNotFound,
2169                 exception.UnexpectedDeletingTaskStateError):
2170             with excutils.save_and_reraise_exception():
2171                 # Make sure the async call finishes
2172                 if network_info is not None:
2173                     network_info.wait(do_raise=False)
2174         except (exception.UnexpectedTaskStateError,
2175                 exception.VolumeLimitExceeded,
2176                 exception.InvalidBDM) as e:
2177             # Make sure the async call finishes
2178             if network_info is not None:
2179                 network_info.wait(do_raise=False)
2180             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2181                     reason=e.format_message())
2182         except Exception:
2183             LOG.exception(_LE('Failure prepping block device'),
2184                     instance=instance)
2185             # Make sure the async call finishes
2186             if network_info is not None:
2187                 network_info.wait(do_raise=False)
2188             msg = _('Failure prepping block device.')
2189             raise exception.BuildAbortException(instance_uuid=instance.uuid,
2190                     reason=msg)
2191 
2192         try:
2193             yield resources
2194         except Exception as exc:
2195             with excutils.save_and_reraise_exception() as ctxt:
2196                 if not isinstance(exc, (exception.InstanceNotFound,
2197                     exception.UnexpectedDeletingTaskStateError)):
2198                         LOG.exception(_LE('Instance failed to spawn'),
2199                                 instance=instance)
2200                 # Make sure the async call finishes
2201                 if network_info is not None:
2202                     network_info.wait(do_raise=False)
2203                 # if network_info is empty we're likely here because of
2204                 # network allocation failure. Since nothing can be reused on
2205                 # rescheduling it's better to deallocate network to eliminate
2206                 # the chance of orphaned ports in neutron
2207                 deallocate_networks = False if network_info else True
2208                 try:
2209                     self._shutdown_instance(context, instance,
2210                             block_device_mapping, requested_networks,
2211                             try_deallocate_networks=deallocate_networks)
2212                 except Exception as exc2:
2213                     ctxt.reraise = False
2214                     LOG.warning(_LW('Could not clean up failed build,'
2215                                     ' not rescheduling. Error: %s'),
2216                                 six.text_type(exc2))
2217                     raise exception.BuildAbortException(
2218                             instance_uuid=instance.uuid,
2219                             reason=six.text_type(exc))
2220 
2221     def _cleanup_allocated_networks(self, context, instance,
2222             requested_networks):
2223         try:
2224             self._deallocate_network(context, instance, requested_networks)
2225         except Exception:
2226             msg = _LE('Failed to deallocate networks')
2227             LOG.exception(msg, instance=instance)
2228             return
2229 
2230         instance.system_metadata['network_allocated'] = 'False'
2231         try:
2232             instance.save()
2233         except exception.InstanceNotFound:
2234             # NOTE(alaski): It's possible that we're cleaning up the networks
2235             # because the instance was deleted.  If that's the case then this
2236             # exception will be raised by instance.save()
2237             pass
2238 
2239     def _try_deallocate_network(self, context, instance,
2240                                 requested_networks=None):
2241         try:
2242             # tear down allocated network structure
2243             self._deallocate_network(context, instance, requested_networks)
2244         except Exception:
2245             with excutils.save_and_reraise_exception():
2246                 LOG.error(_LE('Failed to deallocate network for instance.'),
2247                           instance=instance)
2248                 self._set_instance_obj_error_state(context, instance)
2249 
2250     def _get_power_off_values(self, context, instance, clean_shutdown):
2251         """Get the timing configuration for powering down this instance."""
2252         if clean_shutdown:
2253             timeout = compute_utils.get_value_from_system_metadata(instance,
2254                           key='image_os_shutdown_timeout', type=int,
2255                           default=CONF.shutdown_timeout)
2256             retry_interval = self.SHUTDOWN_RETRY_INTERVAL
2257         else:
2258             timeout = 0
2259             retry_interval = 0
2260 
2261         return timeout, retry_interval
2262 
2263     def _power_off_instance(self, context, instance, clean_shutdown=True):
2264         """Power off an instance on this host."""
2265         timeout, retry_interval = self._get_power_off_values(context,
2266                                         instance, clean_shutdown)
2267         self.driver.power_off(instance, timeout, retry_interval)
2268 
2269     def _shutdown_instance(self, context, instance,
2270                            bdms, requested_networks=None, notify=True,
2271                            try_deallocate_networks=True):
2272         """Shutdown an instance on this host.
2273 
2274         :param:context: security context
2275         :param:instance: a nova.objects.Instance object
2276         :param:bdms: the block devices for the instance to be torn
2277                      down
2278         :param:requested_networks: the networks on which the instance
2279                                    has ports
2280         :param:notify: true if a final usage notification should be
2281                        emitted
2282         :param:try_deallocate_networks: false if we should avoid
2283                                         trying to teardown networking
2284         """
2285         context = context.elevated()
2286         LOG.info(_LI('Terminating instance'),
2287                  context=context, instance=instance)
2288 
2289         if notify:
2290             self._notify_about_instance_usage(context, instance,
2291                                               "shutdown.start")
2292 
2293         network_info = compute_utils.get_nw_info_for_instance(instance)
2294 
2295         # NOTE(vish) get bdms before destroying the instance
2296         vol_bdms = [bdm for bdm in bdms if bdm.is_volume]
2297         block_device_info = self._get_instance_block_device_info(
2298             context, instance, bdms=bdms)
2299 
2300         # NOTE(melwitt): attempt driver destroy before releasing ip, may
2301         #                want to keep ip allocated for certain failures
2302         timer = timeutils.StopWatch()
2303         try:
2304             LOG.debug('Start destroying the instance on the hypervisor.',
2305                       instance=instance)
2306             timer.start()
2307             self.driver.destroy(context, instance, network_info,
2308                     block_device_info)
2309             LOG.info(_LI('Took %0.2f seconds to destroy the instance on the '
2310                          'hypervisor.'), timer.elapsed(), instance=instance)
2311         except exception.InstancePowerOffFailure:
2312             # if the instance can't power off, don't release the ip
2313             with excutils.save_and_reraise_exception():
2314                 pass
2315         except Exception:
2316             with excutils.save_and_reraise_exception():
2317                 # deallocate ip and fail without proceeding to
2318                 # volume api calls, preserving current behavior
2319                 if try_deallocate_networks:
2320                     self._try_deallocate_network(context, instance,
2321                                                  requested_networks)
2322 
2323         if try_deallocate_networks:
2324             self._try_deallocate_network(context, instance, requested_networks)
2325 
2326         timer.restart()
2327         for bdm in vol_bdms:
2328             try:
2329                 # NOTE(vish): actual driver detach done in driver.destroy, so
2330                 #             just tell cinder that we are done with it.
2331                 connector = self.driver.get_volume_connector(instance)
2332                 self.volume_api.terminate_connection(context,
2333                                                      bdm.volume_id,
2334                                                      connector)
2335                 self.volume_api.detach(context, bdm.volume_id, instance.uuid)
2336             except exception.DiskNotFound as exc:
2337                 LOG.debug('Ignoring DiskNotFound: %s', exc,
2338                           instance=instance)
2339             except exception.VolumeNotFound as exc:
2340                 LOG.debug('Ignoring VolumeNotFound: %s', exc,
2341                           instance=instance)
2342             except (cinder_exception.EndpointNotFound,
2343                     keystone_exception.EndpointNotFound) as exc:
2344                 LOG.warning(_LW('Ignoring EndpointNotFound: %s'), exc,
2345                             instance=instance)
2346             except cinder_exception.ClientException as exc:
2347                 LOG.warning(_LW('Ignoring Unknown cinder exception: %s'), exc,
2348                             instance=instance)
2349 
2350         if vol_bdms:
2351             LOG.info(_LI('Took %(time).2f seconds to detach %(num)s volumes '
2352                          'for instance.'),
2353                      {'time': timer.elapsed(), 'num': len(vol_bdms)},
2354                      instance=instance)
2355 
2356         if notify:
2357             self._notify_about_instance_usage(context, instance,
2358                                               "shutdown.end")
2359 
2360     def _cleanup_volumes(self, context, instance_uuid, bdms, raise_exc=True):
2361         exc_info = None
2362 
2363         for bdm in bdms:
2364             LOG.debug("terminating bdm %s", bdm,
2365                       instance_uuid=instance_uuid)
2366             if bdm.volume_id and bdm.delete_on_termination:
2367                 try:
2368                     self.volume_api.delete(context, bdm.volume_id)
2369                 except Exception as exc:
2370                     exc_info = sys.exc_info()
2371                     LOG.warning(_LW('Failed to delete volume: %(volume_id)s '
2372                                     'due to %(exc)s'),
2373                                 {'volume_id': bdm.volume_id, 'exc': exc})
2374         if exc_info is not None and raise_exc:
2375             six.reraise(exc_info[0], exc_info[1], exc_info[2])
2376 
2377     @hooks.add_hook("delete_instance")
2378     def _delete_instance(self, context, instance, bdms, quotas):
2379         """Delete an instance on this host.  Commit or rollback quotas
2380         as necessary.
2381 
2382         :param context: nova request context
2383         :param instance: nova.objects.instance.Instance object
2384         :param bdms: nova.objects.block_device.BlockDeviceMappingList object
2385         :param quotas: nova.objects.quotas.Quotas object
2386         """
2387         was_soft_deleted = instance.vm_state == vm_states.SOFT_DELETED
2388         if was_soft_deleted:
2389             # Instances in SOFT_DELETED vm_state have already had quotas
2390             # decremented.
2391             try:
2392                 quotas.rollback()
2393             except Exception:
2394                 pass
2395 
2396         try:
2397             events = self.instance_events.clear_events_for_instance(instance)
2398             if events:
2399                 LOG.debug('Events pending at deletion: %(events)s',
2400                           {'events': ','.join(events.keys())},
2401                           instance=instance)
2402             self._notify_about_instance_usage(context, instance,
2403                                               "delete.start")
2404             self._shutdown_instance(context, instance, bdms)
2405             # NOTE(dims): instance.info_cache.delete() should be called after
2406             # _shutdown_instance in the compute manager as shutdown calls
2407             # deallocate_for_instance so the info_cache is still needed
2408             # at this point.
2409             if instance.info_cache is not None:
2410                 instance.info_cache.delete()
2411             else:
2412                 # NOTE(yoshimatsu): Avoid AttributeError if instance.info_cache
2413                 # is None. When the root cause that instance.info_cache becomes
2414                 # None is fixed, the log level should be reconsidered.
2415                 LOG.warning(_LW("Info cache for instance could not be found. "
2416                                 "Ignore."), instance=instance)
2417 
2418             # NOTE(vish): We have already deleted the instance, so we have
2419             #             to ignore problems cleaning up the volumes. It
2420             #             would be nice to let the user know somehow that
2421             #             the volume deletion failed, but it is not
2422             #             acceptable to have an instance that can not be
2423             #             deleted. Perhaps this could be reworked in the
2424             #             future to set an instance fault the first time
2425             #             and to only ignore the failure if the instance
2426             #             is already in ERROR.
2427             self._cleanup_volumes(context, instance.uuid, bdms,
2428                     raise_exc=False)
2429             # if a delete task succeeded, always update vm state and task
2430             # state without expecting task state to be DELETING
2431             instance.vm_state = vm_states.DELETED
2432             instance.task_state = None
2433             instance.power_state = power_state.NOSTATE
2434             instance.terminated_at = timeutils.utcnow()
2435             instance.save()
2436             self._update_resource_tracker(context, instance)
2437             system_meta = instance.system_metadata
2438             instance.destroy()
2439         except Exception:
2440             with excutils.save_and_reraise_exception():
2441                 quotas.rollback()
2442 
2443         self._complete_deletion(context,
2444                                 instance,
2445                                 bdms,
2446                                 quotas,
2447                                 system_meta)
2448 
2449     @wrap_exception()
2450     @reverts_task_state
2451     @wrap_instance_event
2452     @wrap_instance_fault
2453     def terminate_instance(self, context, instance, bdms, reservations):
2454         """Terminate an instance on this host."""
2455         quotas = objects.Quotas.from_reservations(context,
2456                                                   reservations,
2457                                                   instance=instance)
2458 
2459         @utils.synchronized(instance.uuid)
2460         def do_terminate_instance(instance, bdms):
2461             # NOTE(mriedem): If we are deleting the instance while it was
2462             # booting from volume, we could be racing with a database update of
2463             # the BDM volume_id. Since the compute API passes the BDMs over RPC
2464             # to compute here, the BDMs may be stale at this point. So check
2465             # for any volume BDMs that don't have volume_id set and if we
2466             # detect that, we need to refresh the BDM list before proceeding.
2467             # TODO(mriedem): Move this into _delete_instance and make the bdms
2468             # parameter optional.
2469             for bdm in list(bdms):
2470                 if bdm.is_volume and not bdm.volume_id:
2471                     LOG.debug('There are potentially stale BDMs during '
2472                               'delete, refreshing the BlockDeviceMappingList.',
2473                               instance=instance)
2474                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2475                         context, instance.uuid)
2476                     break
2477             try:
2478                 self._delete_instance(context, instance, bdms, quotas)
2479             except exception.InstanceNotFound:
2480                 LOG.info(_LI("Instance disappeared during terminate"),
2481                          instance=instance)
2482             except Exception:
2483                 # As we're trying to delete always go to Error if something
2484                 # goes wrong that _delete_instance can't handle.
2485                 with excutils.save_and_reraise_exception():
2486                     LOG.exception(_LE('Setting instance vm_state to ERROR'),
2487                                   instance=instance)
2488                     self._set_instance_obj_error_state(context, instance)
2489 
2490         do_terminate_instance(instance, bdms)
2491 
2492     # NOTE(johannes): This is probably better named power_off_instance
2493     # so it matches the driver method, but because of other issues, we
2494     # can't use that name in grizzly.
2495     @wrap_exception()
2496     @reverts_task_state
2497     @wrap_instance_event
2498     @wrap_instance_fault
2499     def stop_instance(self, context, instance, clean_shutdown):
2500         """Stopping an instance on this host."""
2501 
2502         @utils.synchronized(instance.uuid)
2503         def do_stop_instance():
2504             current_power_state = self._get_power_state(context, instance)
2505             LOG.debug('Stopping instance; current vm_state: %(vm_state)s, '
2506                       'current task_state: %(task_state)s, current DB '
2507                       'power_state: %(db_power_state)s, current VM '
2508                       'power_state: %(current_power_state)s',
2509                       {'vm_state': instance.vm_state,
2510                        'task_state': instance.task_state,
2511                        'db_power_state': instance.power_state,
2512                        'current_power_state': current_power_state},
2513                       instance_uuid=instance.uuid)
2514 
2515             # NOTE(mriedem): If the instance is already powered off, we are
2516             # possibly tearing down and racing with other operations, so we can
2517             # expect the task_state to be None if something else updates the
2518             # instance and we're not locking it.
2519             expected_task_state = [task_states.POWERING_OFF]
2520             # The list of power states is from _sync_instance_power_state.
2521             if current_power_state in (power_state.NOSTATE,
2522                                        power_state.SHUTDOWN,
2523                                        power_state.CRASHED):
2524                 LOG.info(_LI('Instance is already powered off in the '
2525                              'hypervisor when stop is called.'),
2526                          instance=instance)
2527                 expected_task_state.append(None)
2528 
2529             self._notify_about_instance_usage(context, instance,
2530                                               "power_off.start")
2531             self._power_off_instance(context, instance, clean_shutdown)
2532             instance.power_state = self._get_power_state(context, instance)
2533             instance.vm_state = vm_states.STOPPED
2534             instance.task_state = None
2535             instance.save(expected_task_state=expected_task_state)
2536             self._notify_about_instance_usage(context, instance,
2537                                               "power_off.end")
2538 
2539         do_stop_instance()
2540 
2541     def _power_on(self, context, instance):
2542         network_info = self.network_api.get_instance_nw_info(context, instance)
2543         block_device_info = self._get_instance_block_device_info(context,
2544                                                                  instance)
2545         self.driver.power_on(context, instance,
2546                              network_info,
2547                              block_device_info)
2548 
2549     def _delete_snapshot_of_shelved_instance(self, context, instance,
2550                                              snapshot_id):
2551         """Delete snapshot of shelved instance."""
2552         try:
2553             self.image_api.delete(context, snapshot_id)
2554         except (exception.ImageNotFound,
2555                 exception.ImageNotAuthorized) as exc:
2556             LOG.warning(_LW("Failed to delete snapshot "
2557                             "from shelved instance (%s)."),
2558                         exc.format_message(), instance=instance)
2559         except Exception:
2560             LOG.exception(_LE("Something wrong happened when trying to "
2561                               "delete snapshot from shelved instance."),
2562                           instance=instance)
2563 
2564     # NOTE(johannes): This is probably better named power_on_instance
2565     # so it matches the driver method, but because of other issues, we
2566     # can't use that name in grizzly.
2567     @wrap_exception()
2568     @reverts_task_state
2569     @wrap_instance_event
2570     @wrap_instance_fault
2571     def start_instance(self, context, instance):
2572         """Starting an instance on this host."""
2573         self._notify_about_instance_usage(context, instance, "power_on.start")
2574         self._power_on(context, instance)
2575         instance.power_state = self._get_power_state(context, instance)
2576         instance.vm_state = vm_states.ACTIVE
2577         instance.task_state = None
2578 
2579         # Delete an image(VM snapshot) for a shelved instance
2580         snapshot_id = instance.system_metadata.get('shelved_image_id')
2581         if snapshot_id:
2582             self._delete_snapshot_of_shelved_instance(context, instance,
2583                                                       snapshot_id)
2584 
2585         # Delete system_metadata for a shelved instance
2586         compute_utils.remove_shelved_keys_from_system_metadata(instance)
2587 
2588         instance.save(expected_task_state=task_states.POWERING_ON)
2589         self._notify_about_instance_usage(context, instance, "power_on.end")
2590 
2591     @messaging.expected_exceptions(NotImplementedError,
2592                                    exception.NMINotSupported,
2593                                    exception.InstanceNotRunning)
2594     @wrap_exception()
2595     @wrap_instance_event
2596     @wrap_instance_fault
2597     def trigger_crash_dump(self, context, instance):
2598         """Trigger crash dump in an instance by injecting NMI."""
2599 
2600         self._notify_about_instance_usage(context, instance,
2601                                           "trigger_crash_dump.start")
2602 
2603         # This method does not change task_state and power_state because the
2604         # effect of an NMI depends on user's configuration.
2605         self.driver.inject_nmi(instance)
2606 
2607         self._notify_about_instance_usage(context, instance,
2608                                           "trigger_crash_dump.end")
2609 
2610     @wrap_exception()
2611     @reverts_task_state
2612     @wrap_instance_event
2613     @wrap_instance_fault
2614     def soft_delete_instance(self, context, instance, reservations):
2615         """Soft delete an instance on this host."""
2616 
2617         quotas = objects.Quotas.from_reservations(context,
2618                                                   reservations,
2619                                                   instance=instance)
2620         try:
2621             self._notify_about_instance_usage(context, instance,
2622                                               "soft_delete.start")
2623             try:
2624                 self.driver.soft_delete(instance)
2625             except NotImplementedError:
2626                 # Fallback to just powering off the instance if the
2627                 # hypervisor doesn't implement the soft_delete method
2628                 self.driver.power_off(instance)
2629             instance.power_state = self._get_power_state(context, instance)
2630             instance.vm_state = vm_states.SOFT_DELETED
2631             instance.task_state = None
2632             instance.save(expected_task_state=[task_states.SOFT_DELETING])
2633         except Exception:
2634             with excutils.save_and_reraise_exception():
2635                 quotas.rollback()
2636         quotas.commit()
2637         self._notify_about_instance_usage(context, instance, "soft_delete.end")
2638 
2639     @wrap_exception()
2640     @reverts_task_state
2641     @wrap_instance_event
2642     @wrap_instance_fault
2643     def restore_instance(self, context, instance):
2644         """Restore a soft-deleted instance on this host."""
2645         self._notify_about_instance_usage(context, instance, "restore.start")
2646         try:
2647             self.driver.restore(instance)
2648         except NotImplementedError:
2649             # Fallback to just powering on the instance if the hypervisor
2650             # doesn't implement the restore method
2651             self._power_on(context, instance)
2652         instance.power_state = self._get_power_state(context, instance)
2653         instance.vm_state = vm_states.ACTIVE
2654         instance.task_state = None
2655         instance.save(expected_task_state=task_states.RESTORING)
2656         self._notify_about_instance_usage(context, instance, "restore.end")
2657 
2658     @staticmethod
2659     def _set_migration_status(migration, status, unless_status=_SENTINEL):
2660         """Set the status, and guard against a None being passed in.
2661 
2662         This is useful as some of the compute RPC calls will not pass
2663         a migration object in older versions. The check can be removed when
2664         we move past 4.x major version of the RPC API.
2665 
2666         If unless_status is passed in - it will guard against clobering a
2667         terminal status (for example 'failed' or 'finished')
2668         """
2669         if migration:
2670             if unless_status is _SENTINEL or migration.status != unless_status:
2671                 migration.status = status
2672                 migration.save()
2673 
2674     def _rebuild_default_impl(self, context, instance, image_meta,
2675                               injected_files, admin_password, bdms,
2676                               detach_block_devices, attach_block_devices,
2677                               network_info=None,
2678                               recreate=False, block_device_info=None,
2679                               preserve_ephemeral=False):
2680         if preserve_ephemeral:
2681             # The default code path does not support preserving ephemeral
2682             # partitions.
2683             raise exception.PreserveEphemeralNotSupported()
2684 
2685         if recreate:
2686             detach_block_devices(context, bdms)
2687         else:
2688             self._power_off_instance(context, instance, clean_shutdown=True)
2689             detach_block_devices(context, bdms)
2690             self.driver.destroy(context, instance,
2691                                 network_info=network_info,
2692                                 block_device_info=block_device_info)
2693 
2694         instance.task_state = task_states.REBUILD_BLOCK_DEVICE_MAPPING
2695         instance.save(expected_task_state=[task_states.REBUILDING])
2696 
2697         new_block_device_info = attach_block_devices(context, instance, bdms)
2698 
2699         instance.task_state = task_states.REBUILD_SPAWNING
2700         instance.save(
2701             expected_task_state=[task_states.REBUILD_BLOCK_DEVICE_MAPPING])
2702 
2703         with instance.mutated_migration_context():
2704             self.driver.spawn(context, instance, image_meta, injected_files,
2705                               admin_password, network_info=network_info,
2706                               block_device_info=new_block_device_info)
2707 
2708     @messaging.expected_exceptions(exception.PreserveEphemeralNotSupported)
2709     @wrap_exception()
2710     @reverts_task_state
2711     @wrap_instance_event
2712     @wrap_instance_fault
2713     def rebuild_instance(self, context, instance, orig_image_ref, image_ref,
2714                          injected_files, new_pass, orig_sys_metadata,
2715                          bdms, recreate, on_shared_storage=None,
2716                          preserve_ephemeral=False, migration=None,
2717                          scheduled_node=None, limits=None):
2718         """Destroy and re-make this instance.
2719 
2720         A 'rebuild' effectively purges all existing data from the system and
2721         remakes the VM with given 'metadata' and 'personalities'.
2722 
2723         :param context: `nova.RequestContext` object
2724         :param instance: Instance object
2725         :param orig_image_ref: Original image_ref before rebuild
2726         :param image_ref: New image_ref for rebuild
2727         :param injected_files: Files to inject
2728         :param new_pass: password to set on rebuilt instance
2729         :param orig_sys_metadata: instance system metadata from pre-rebuild
2730         :param bdms: block-device-mappings to use for rebuild
2731         :param recreate: True if the instance is being recreated (e.g. the
2732             hypervisor it was on failed) - cleanup of old state will be
2733             skipped.
2734         :param on_shared_storage: True if instance files on shared storage.
2735                                   If not provided then information from the
2736                                   driver will be used to decide if the instance
2737                                   files are available or not on the target host
2738         :param preserve_ephemeral: True if the default ephemeral storage
2739                                    partition must be preserved on rebuild
2740         :param migration: a Migration object if one was created for this
2741                           rebuild operation (if it's a part of evacaute)
2742         :param scheduled_node: A node of the host chosen by the scheduler. If a
2743                                host was specified by the user, this will be
2744                                None
2745         :param limits: Overcommit limits set by the scheduler. If a host was
2746                        specified by the user, this will be None
2747         """
2748         context = context.elevated()
2749 
2750         LOG.info(_LI("Rebuilding instance"), context=context,
2751                     instance=instance)
2752         if scheduled_node is not None:
2753             rt = self._get_resource_tracker(scheduled_node)
2754             rebuild_claim = rt.rebuild_claim
2755         else:
2756             rebuild_claim = claims.NopClaim
2757 
2758         image_meta = {}
2759         if image_ref:
2760             image_meta = self.image_api.get(context, image_ref)
2761 
2762         # NOTE(mriedem): On a recreate (evacuate), we need to update
2763         # the instance's host and node properties to reflect it's
2764         # destination node for the recreate.
2765         if not scheduled_node:
2766             try:
2767                 compute_node = self._get_compute_info(context, self.host)
2768                 scheduled_node = compute_node.hypervisor_hostname
2769             except exception.ComputeHostNotFound:
2770                 LOG.exception(_LE('Failed to get compute_info for %s'),
2771                                 self.host)
2772 
2773         with self._error_out_instance_on_exception(context, instance):
2774             try:
2775                 claim_ctxt = rebuild_claim(
2776                     context, instance, limits=limits, image_meta=image_meta,
2777                     migration=migration)
2778                 self._do_rebuild_instance_with_claim(
2779                     claim_ctxt, context, instance, orig_image_ref,
2780                     image_ref, injected_files, new_pass, orig_sys_metadata,
2781                     bdms, recreate, on_shared_storage, preserve_ephemeral)
2782             except exception.ComputeResourcesUnavailable as e:
2783                 LOG.debug("Could not rebuild instance on this host, not "
2784                           "enough resources available.", instance=instance)
2785 
2786                 # NOTE(ndipanov): We just abort the build for now and leave a
2787                 # migration record for potential cleanup later
2788                 self._set_migration_status(migration, 'failed')
2789 
2790                 self._notify_about_instance_usage(context, instance,
2791                         'rebuild.error', fault=e)
2792                 raise exception.BuildAbortException(
2793                     instance_uuid=instance.uuid, reason=e.format_message())
2794             except (exception.InstanceNotFound,
2795                     exception.UnexpectedDeletingTaskStateError) as e:
2796                 LOG.debug('Instance was deleted while rebuilding',
2797                           instance=instance)
2798                 self._set_migration_status(migration, 'failed')
2799                 self._notify_about_instance_usage(context, instance,
2800                         'rebuild.error', fault=e)
2801             except Exception as e:
2802                 self._set_migration_status(migration, 'failed')
2803                 self._notify_about_instance_usage(context, instance,
2804                         'rebuild.error', fault=e)
2805                 raise
2806             else:
2807                 instance.apply_migration_context()
2808                 # NOTE (ndipanov): This save will now update the host and node
2809                 # attributes making sure that next RT pass is consistent since
2810                 # it will be based on the instance and not the migration DB
2811                 # entry.
2812                 instance.host = self.host
2813                 instance.node = scheduled_node
2814                 instance.save()
2815                 instance.drop_migration_context()
2816 
2817                 # NOTE (ndipanov): Mark the migration as done only after we
2818                 # mark the instance as belonging to this host.
2819                 self._set_migration_status(migration, 'done')
2820 
2821     def _do_rebuild_instance_with_claim(self, claim_context, *args, **kwargs):
2822         """Helper to avoid deep nesting in the top-level method."""
2823 
2824         with claim_context:
2825             self._do_rebuild_instance(*args, **kwargs)
2826 
2827     @staticmethod
2828     def _get_image_name(image_meta):
2829         if image_meta.obj_attr_is_set("name"):
2830             return image_meta.name
2831         else:
2832             return ''
2833 
2834     def _do_rebuild_instance(self, context, instance, orig_image_ref,
2835                              image_ref, injected_files, new_pass,
2836                              orig_sys_metadata, bdms, recreate,
2837                              on_shared_storage, preserve_ephemeral):
2838         orig_vm_state = instance.vm_state
2839 
2840         if recreate:
2841             if not self.driver.capabilities["supports_recreate"]:
2842                 raise exception.InstanceRecreateNotSupported
2843 
2844             self._check_instance_exists(context, instance)
2845 
2846             if on_shared_storage is None:
2847                 LOG.debug('on_shared_storage is not provided, using driver'
2848                             'information to decide if the instance needs to'
2849                             'be recreated')
2850                 on_shared_storage = self.driver.instance_on_disk(instance)
2851 
2852             elif (on_shared_storage !=
2853                     self.driver.instance_on_disk(instance)):
2854                 # To cover case when admin expects that instance files are
2855                 # on shared storage, but not accessible and vice versa
2856                 raise exception.InvalidSharedStorage(
2857                         _("Invalid state of instance files on shared"
2858                             " storage"))
2859 
2860             if on_shared_storage:
2861                 LOG.info(_LI('disk on shared storage, recreating using'
2862                                 ' existing disk'))
2863             else:
2864                 image_ref = orig_image_ref = instance.image_ref
2865                 LOG.info(_LI("disk not on shared storage, rebuilding from:"
2866                                 " '%s'"), str(image_ref))
2867 
2868         if image_ref:
2869             image_meta = objects.ImageMeta.from_image_ref(
2870                 context, self.image_api, image_ref)
2871         else:
2872             image_meta = objects.ImageMeta.from_dict({})
2873 
2874         # This instance.exists message should contain the original
2875         # image_ref, not the new one.  Since the DB has been updated
2876         # to point to the new one... we have to override it.
2877         # TODO(jaypipes): Move generate_image_url() into the nova.image.api
2878         orig_image_ref_url = glance.generate_image_url(orig_image_ref)
2879         extra_usage_info = {'image_ref_url': orig_image_ref_url}
2880         compute_utils.notify_usage_exists(
2881                 self.notifier, context, instance,
2882                 current_period=True, system_metadata=orig_sys_metadata,
2883                 extra_usage_info=extra_usage_info)
2884 
2885         # This message should contain the new image_ref
2886         extra_usage_info = {'image_name': self._get_image_name(image_meta)}
2887         self._notify_about_instance_usage(context, instance,
2888                 "rebuild.start", extra_usage_info=extra_usage_info)
2889 
2890         instance.power_state = self._get_power_state(context, instance)
2891         instance.task_state = task_states.REBUILDING
2892         instance.save(expected_task_state=[task_states.REBUILDING])
2893 
2894         if recreate:
2895             # Needed for nova-network, does nothing for neutron
2896             self.network_api.setup_networks_on_host(
2897                     context, instance, self.host)
2898             # For nova-network this is needed to move floating IPs
2899             # For neutron this updates the host in the port binding
2900             # TODO(cfriesen): this network_api call and the one above
2901             # are so similar, we should really try to unify them.
2902             self.network_api.setup_instance_network_on_host(
2903                     context, instance, self.host)
2904 
2905         network_info = compute_utils.get_nw_info_for_instance(instance)
2906         if bdms is None:
2907             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
2908                     context, instance.uuid)
2909 
2910         block_device_info = \
2911             self._get_instance_block_device_info(
2912                     context, instance, bdms=bdms)
2913 
2914         def detach_block_devices(context, bdms):
2915             for bdm in bdms:
2916                 if bdm.is_volume:
2917                     self._detach_volume(context, bdm.volume_id, instance,
2918                                         destroy_bdm=False)
2919 
2920         files = self._decode_files(injected_files)
2921 
2922         kwargs = dict(
2923             context=context,
2924             instance=instance,
2925             image_meta=image_meta,
2926             injected_files=files,
2927             admin_password=new_pass,
2928             bdms=bdms,
2929             detach_block_devices=detach_block_devices,
2930             attach_block_devices=self._prep_block_device,
2931             block_device_info=block_device_info,
2932             network_info=network_info,
2933             preserve_ephemeral=preserve_ephemeral,
2934             recreate=recreate)
2935         try:
2936             with instance.mutated_migration_context():
2937                 self.driver.rebuild(**kwargs)
2938         except NotImplementedError:
2939             # NOTE(rpodolyaka): driver doesn't provide specialized version
2940             # of rebuild, fall back to the default implementation
2941             self._rebuild_default_impl(**kwargs)
2942         self._update_instance_after_spawn(context, instance)
2943         instance.save(expected_task_state=[task_states.REBUILD_SPAWNING])
2944 
2945         if orig_vm_state == vm_states.STOPPED:
2946             LOG.info(_LI("bringing vm to original state: '%s'"),
2947                         orig_vm_state, instance=instance)
2948             instance.vm_state = vm_states.ACTIVE
2949             instance.task_state = task_states.POWERING_OFF
2950             instance.progress = 0
2951             instance.save()
2952             self.stop_instance(context, instance, False)
2953         self._update_scheduler_instance_info(context, instance)
2954         self._notify_about_instance_usage(
2955                 context, instance, "rebuild.end",
2956                 network_info=network_info,
2957                 extra_usage_info=extra_usage_info)
2958 
2959     def _handle_bad_volumes_detached(self, context, instance, bad_devices,
2960                                      block_device_info):
2961         """Handle cases where the virt-layer had to detach non-working volumes
2962         in order to complete an operation.
2963         """
2964         for bdm in block_device_info['block_device_mapping']:
2965             if bdm.get('mount_device') in bad_devices:
2966                 try:
2967                     volume_id = bdm['connection_info']['data']['volume_id']
2968                 except KeyError:
2969                     continue
2970 
2971                 # NOTE(sirp): ideally we'd just call
2972                 # `compute_api.detach_volume` here but since that hits the
2973                 # DB directly, that's off limits from within the
2974                 # compute-manager.
2975                 #
2976                 # API-detach
2977                 LOG.info(_LI("Detaching from volume api: %s"), volume_id)
2978                 volume = self.volume_api.get(context, volume_id)
2979                 self.volume_api.check_detach(context, volume)
2980                 self.volume_api.begin_detaching(context, volume_id)
2981 
2982                 # Manager-detach
2983                 self.detach_volume(context, volume_id, instance)
2984 
2985     @wrap_exception()
2986     @reverts_task_state
2987     @wrap_instance_event
2988     @wrap_instance_fault
2989     def reboot_instance(self, context, instance, block_device_info,
2990                         reboot_type):
2991         """Reboot an instance on this host."""
2992         # acknowledge the request made it to the manager
2993         if reboot_type == "SOFT":
2994             instance.task_state = task_states.REBOOT_PENDING
2995             expected_states = (task_states.REBOOTING,
2996                                task_states.REBOOT_PENDING,
2997                                task_states.REBOOT_STARTED)
2998         else:
2999             instance.task_state = task_states.REBOOT_PENDING_HARD
3000             expected_states = (task_states.REBOOTING_HARD,
3001                                task_states.REBOOT_PENDING_HARD,
3002                                task_states.REBOOT_STARTED_HARD)
3003         context = context.elevated()
3004         LOG.info(_LI("Rebooting instance"), context=context, instance=instance)
3005 
3006         block_device_info = self._get_instance_block_device_info(context,
3007                                                                  instance)
3008 
3009         network_info = self.network_api.get_instance_nw_info(context, instance)
3010 
3011         self._notify_about_instance_usage(context, instance, "reboot.start")
3012 
3013         instance.power_state = self._get_power_state(context, instance)
3014         instance.save(expected_task_state=expected_states)
3015 
3016         if instance.power_state != power_state.RUNNING:
3017             state = instance.power_state
3018             running = power_state.RUNNING
3019             LOG.warning(_LW('trying to reboot a non-running instance:'
3020                             ' (state: %(state)s expected: %(running)s)'),
3021                         {'state': state, 'running': running},
3022                         context=context, instance=instance)
3023 
3024         def bad_volumes_callback(bad_devices):
3025             self._handle_bad_volumes_detached(
3026                     context, instance, bad_devices, block_device_info)
3027 
3028         try:
3029             # Don't change it out of rescue mode
3030             if instance.vm_state == vm_states.RESCUED:
3031                 new_vm_state = vm_states.RESCUED
3032             else:
3033                 new_vm_state = vm_states.ACTIVE
3034             new_power_state = None
3035             if reboot_type == "SOFT":
3036                 instance.task_state = task_states.REBOOT_STARTED
3037                 expected_state = task_states.REBOOT_PENDING
3038             else:
3039                 instance.task_state = task_states.REBOOT_STARTED_HARD
3040                 expected_state = task_states.REBOOT_PENDING_HARD
3041             instance.save(expected_task_state=expected_state)
3042             self.driver.reboot(context, instance,
3043                                network_info,
3044                                reboot_type,
3045                                block_device_info=block_device_info,
3046                                bad_volumes_callback=bad_volumes_callback)
3047 
3048         except Exception as error:
3049             with excutils.save_and_reraise_exception() as ctxt:
3050                 exc_info = sys.exc_info()
3051                 # if the reboot failed but the VM is running don't
3052                 # put it into an error state
3053                 new_power_state = self._get_power_state(context, instance)
3054                 if new_power_state == power_state.RUNNING:
3055                     LOG.warning(_LW('Reboot failed but instance is running'),
3056                                 context=context, instance=instance)
3057                     compute_utils.add_instance_fault_from_exc(context,
3058                             instance, error, exc_info)
3059                     self._notify_about_instance_usage(context, instance,
3060                             'reboot.error', fault=error)
3061                     ctxt.reraise = False
3062                 else:
3063                     LOG.error(_LE('Cannot reboot instance: %s'), error,
3064                               context=context, instance=instance)
3065                     self._set_instance_obj_error_state(context, instance)
3066 
3067         if not new_power_state:
3068             new_power_state = self._get_power_state(context, instance)
3069         try:
3070             instance.power_state = new_power_state
3071             instance.vm_state = new_vm_state
3072             instance.task_state = None
3073             instance.save()
3074         except exception.InstanceNotFound:
3075             LOG.warning(_LW("Instance disappeared during reboot"),
3076                         context=context, instance=instance)
3077 
3078         self._notify_about_instance_usage(context, instance, "reboot.end")
3079 
3080     @delete_image_on_error
3081     def _do_snapshot_instance(self, context, image_id, instance, rotation):
3082         self._snapshot_instance(context, image_id, instance,
3083                                 task_states.IMAGE_BACKUP)
3084 
3085     @wrap_exception()
3086     @reverts_task_state
3087     @wrap_instance_fault
3088     def backup_instance(self, context, image_id, instance, backup_type,
3089                         rotation):
3090         """Backup an instance on this host.
3091 
3092         :param backup_type: daily | weekly
3093         :param rotation: int representing how many backups to keep around
3094         """
3095         self._do_snapshot_instance(context, image_id, instance, rotation)
3096         self._rotate_backups(context, instance, backup_type, rotation)
3097 
3098     @wrap_exception()
3099     @reverts_task_state
3100     @wrap_instance_fault
3101     @delete_image_on_error
3102     def snapshot_instance(self, context, image_id, instance):
3103         """Snapshot an instance on this host.
3104 
3105         :param context: security context
3106         :param instance: a nova.objects.instance.Instance object
3107         :param image_id: glance.db.sqlalchemy.models.Image.Id
3108         """
3109         # NOTE(dave-mcnally) the task state will already be set by the api
3110         # but if the compute manager has crashed/been restarted prior to the
3111         # request getting here the task state may have been cleared so we set
3112         # it again and things continue normally
3113         try:
3114             instance.task_state = task_states.IMAGE_SNAPSHOT
3115             instance.save(
3116                         expected_task_state=task_states.IMAGE_SNAPSHOT_PENDING)
3117         except exception.InstanceNotFound:
3118             # possibility instance no longer exists, no point in continuing
3119             LOG.debug("Instance not found, could not set state %s "
3120                       "for instance.",
3121                       task_states.IMAGE_SNAPSHOT, instance=instance)
3122             return
3123 
3124         except exception.UnexpectedDeletingTaskStateError:
3125             LOG.debug("Instance being deleted, snapshot cannot continue",
3126                       instance=instance)
3127             return
3128 
3129         self._snapshot_instance(context, image_id, instance,
3130                                 task_states.IMAGE_SNAPSHOT)
3131 
3132     def _snapshot_instance(self, context, image_id, instance,
3133                            expected_task_state):
3134         context = context.elevated()
3135 
3136         instance.power_state = self._get_power_state(context, instance)
3137         try:
3138             instance.save()
3139 
3140             LOG.info(_LI('instance snapshotting'), context=context,
3141                   instance=instance)
3142 
3143             if instance.power_state != power_state.RUNNING:
3144                 state = instance.power_state
3145                 running = power_state.RUNNING
3146                 LOG.warning(_LW('trying to snapshot a non-running instance: '
3147                                 '(state: %(state)s expected: %(running)s)'),
3148                             {'state': state, 'running': running},
3149                             instance=instance)
3150 
3151             self._notify_about_instance_usage(
3152                 context, instance, "snapshot.start")
3153 
3154             def update_task_state(task_state,
3155                                   expected_state=expected_task_state):
3156                 instance.task_state = task_state
3157                 instance.save(expected_task_state=expected_state)
3158 
3159             self.driver.snapshot(context, instance, image_id,
3160                                  update_task_state)
3161 
3162             instance.task_state = None
3163             instance.save(expected_task_state=task_states.IMAGE_UPLOADING)
3164 
3165             self._notify_about_instance_usage(context, instance,
3166                                               "snapshot.end")
3167         except (exception.InstanceNotFound,
3168                 exception.UnexpectedDeletingTaskStateError):
3169             # the instance got deleted during the snapshot
3170             # Quickly bail out of here
3171             msg = 'Instance disappeared during snapshot'
3172             LOG.debug(msg, instance=instance)
3173             try:
3174                 image_service = glance.get_default_image_service()
3175                 image = image_service.show(context, image_id)
3176                 if image['status'] != 'active':
3177                     image_service.delete(context, image_id)
3178             except Exception:
3179                 LOG.warning(_LW("Error while trying to clean up image %s"),
3180                             image_id, instance=instance)
3181         except exception.ImageNotFound:
3182             instance.task_state = None
3183             instance.save()
3184             msg = _LW("Image not found during snapshot")
3185             LOG.warn(msg, instance=instance)
3186 
3187     def _post_interrupted_snapshot_cleanup(self, context, instance):
3188         self.driver.post_interrupted_snapshot_cleanup(context, instance)
3189 
3190     @messaging.expected_exceptions(NotImplementedError)
3191     @wrap_exception()
3192     def volume_snapshot_create(self, context, instance, volume_id,
3193                                create_info):
3194         self.driver.volume_snapshot_create(context, instance, volume_id,
3195                                            create_info)
3196 
3197     @messaging.expected_exceptions(NotImplementedError)
3198     @wrap_exception()
3199     def volume_snapshot_delete(self, context, instance, volume_id,
3200                                snapshot_id, delete_info):
3201         self.driver.volume_snapshot_delete(context, instance, volume_id,
3202                                            snapshot_id, delete_info)
3203 
3204     @wrap_instance_fault
3205     def _rotate_backups(self, context, instance, backup_type, rotation):
3206         """Delete excess backups associated to an instance.
3207 
3208         Instances are allowed a fixed number of backups (the rotation number);
3209         this method deletes the oldest backups that exceed the rotation
3210         threshold.
3211 
3212         :param context: security context
3213         :param instance: Instance dict
3214         :param backup_type: a user-defined type, like "daily" or "weekly" etc.
3215         :param rotation: int representing how many backups to keep around;
3216             None if rotation shouldn't be used (as in the case of snapshots)
3217         """
3218         filters = {'property-image_type': 'backup',
3219                    'property-backup_type': backup_type,
3220                    'property-instance_uuid': instance.uuid}
3221 
3222         images = self.image_api.get_all(context, filters=filters,
3223                                         sort_key='created_at', sort_dir='desc')
3224         num_images = len(images)
3225         LOG.debug("Found %(num_images)d images (rotation: %(rotation)d)",
3226                   {'num_images': num_images, 'rotation': rotation},
3227                   instance=instance)
3228 
3229         if num_images > rotation:
3230             # NOTE(sirp): this deletes all backups that exceed the rotation
3231             # limit
3232             excess = len(images) - rotation
3233             LOG.debug("Rotating out %d backups", excess,
3234                       instance=instance)
3235             for i in range(excess):
3236                 image = images.pop()
3237                 image_id = image['id']
3238                 LOG.debug("Deleting image %s", image_id,
3239                           instance=instance)
3240                 self.image_api.delete(context, image_id)
3241 
3242     @wrap_exception()
3243     @reverts_task_state
3244     @wrap_instance_event
3245     @wrap_instance_fault
3246     def set_admin_password(self, context, instance, new_pass):
3247         """Set the root/admin password for an instance on this host.
3248 
3249         This is generally only called by API password resets after an
3250         image has been built.
3251 
3252         @param context: Nova auth context.
3253         @param instance: Nova instance object.
3254         @param new_pass: The admin password for the instance.
3255         """
3256 
3257         context = context.elevated()
3258         if new_pass is None:
3259             # Generate a random password
3260             new_pass = utils.generate_password()
3261 
3262         current_power_state = self._get_power_state(context, instance)
3263         expected_state = power_state.RUNNING
3264 
3265         if current_power_state != expected_state:
3266             instance.task_state = None
3267             instance.save(expected_task_state=task_states.UPDATING_PASSWORD)
3268             _msg = _('instance %s is not running') % instance.uuid
3269             raise exception.InstancePasswordSetFailed(
3270                 instance=instance.uuid, reason=_msg)
3271 
3272         try:
3273             self.driver.set_admin_password(instance, new_pass)
3274             LOG.info(_LI("Root password set"), instance=instance)
3275             instance.task_state = None
3276             instance.save(
3277                 expected_task_state=task_states.UPDATING_PASSWORD)
3278         except NotImplementedError:
3279             LOG.warning(_LW('set_admin_password is not implemented '
3280                             'by this driver or guest instance.'),
3281                         instance=instance)
3282             instance.task_state = None
3283             instance.save(
3284                 expected_task_state=task_states.UPDATING_PASSWORD)
3285             raise NotImplementedError(_('set_admin_password is not '
3286                                         'implemented by this driver or guest '
3287                                         'instance.'))
3288         except exception.UnexpectedTaskStateError:
3289             # interrupted by another (most likely delete) task
3290             # do not retry
3291             raise
3292         except Exception:
3293             # Catch all here because this could be anything.
3294             LOG.exception(_LE('set_admin_password failed'),
3295                           instance=instance)
3296             self._set_instance_obj_error_state(context, instance)
3297             # We create a new exception here so that we won't
3298             # potentially reveal password information to the
3299             # API caller.  The real exception is logged above
3300             _msg = _('error setting admin password')
3301             raise exception.InstancePasswordSetFailed(
3302                 instance=instance.uuid, reason=_msg)
3303 
3304     @wrap_exception()
3305     @reverts_task_state
3306     @wrap_instance_fault
3307     def inject_file(self, context, path, file_contents, instance):
3308         """Write a file to the specified path in an instance on this host."""
3309         # NOTE(russellb) Remove this method, as well as the underlying virt
3310         # driver methods, when the compute rpc interface is bumped to 4.x
3311         # as it is no longer used.
3312         context = context.elevated()
3313         current_power_state = self._get_power_state(context, instance)
3314         expected_state = power_state.RUNNING
3315         if current_power_state != expected_state:
3316             LOG.warning(_LW('trying to inject a file into a non-running '
3317                             '(state: %(current_state)s expected: '
3318                             '%(expected_state)s)'),
3319                         {'current_state': current_power_state,
3320                          'expected_state': expected_state},
3321                         instance=instance)
3322         LOG.info(_LI('injecting file to %s'), path,
3323                     instance=instance)
3324         self.driver.inject_file(instance, path, file_contents)
3325 
3326     def _get_rescue_image(self, context, instance, rescue_image_ref=None):
3327         """Determine what image should be used to boot the rescue VM."""
3328         # 1. If rescue_image_ref is passed in, use that for rescue.
3329         # 2. Else, use the base image associated with instance's current image.
3330         #       The idea here is to provide the customer with a rescue
3331         #       environment which they are familiar with.
3332         #       So, if they built their instance off of a Debian image,
3333         #       their rescue VM will also be Debian.
3334         # 3. As a last resort, use instance's current image.
3335         if not rescue_image_ref:
3336             system_meta = utils.instance_sys_meta(instance)
3337             rescue_image_ref = system_meta.get('image_base_image_ref')
3338 
3339         if not rescue_image_ref:
3340             LOG.warning(_LW('Unable to find a different image to use for '
3341                             'rescue VM, using instance\'s current image'),
3342                         instance=instance)
3343             rescue_image_ref = instance.image_ref
3344 
3345         return objects.ImageMeta.from_image_ref(
3346             context, self.image_api, rescue_image_ref)
3347 
3348     @wrap_exception()
3349     @reverts_task_state
3350     @wrap_instance_event
3351     @wrap_instance_fault
3352     def rescue_instance(self, context, instance, rescue_password,
3353                         rescue_image_ref, clean_shutdown):
3354         context = context.elevated()
3355         LOG.info(_LI('Rescuing'), context=context, instance=instance)
3356 
3357         admin_password = (rescue_password if rescue_password else
3358                       utils.generate_password())
3359 
3360         network_info = self.network_api.get_instance_nw_info(context, instance)
3361 
3362         rescue_image_meta = self._get_rescue_image(context, instance,
3363                                                    rescue_image_ref)
3364 
3365         extra_usage_info = {'rescue_image_name':
3366                             self._get_image_name(rescue_image_meta)}
3367         self._notify_about_instance_usage(context, instance,
3368                 "rescue.start", extra_usage_info=extra_usage_info,
3369                 network_info=network_info)
3370 
3371         try:
3372             self._power_off_instance(context, instance, clean_shutdown)
3373 
3374             self.driver.rescue(context, instance,
3375                                network_info,
3376                                rescue_image_meta, admin_password)
3377         except Exception as e:
3378             LOG.exception(_LE("Error trying to Rescue Instance"),
3379                           instance=instance)
3380             self._set_instance_obj_error_state(context, instance)
3381             raise exception.InstanceNotRescuable(
3382                 instance_id=instance.uuid,
3383                 reason=_("Driver Error: %s") % e)
3384 
3385         compute_utils.notify_usage_exists(self.notifier, context, instance,
3386                                           current_period=True)
3387 
3388         instance.vm_state = vm_states.RESCUED
3389         instance.task_state = None
3390         instance.power_state = self._get_power_state(context, instance)
3391         instance.launched_at = timeutils.utcnow()
3392         instance.save(expected_task_state=task_states.RESCUING)
3393 
3394         self._notify_about_instance_usage(context, instance,
3395                 "rescue.end", extra_usage_info=extra_usage_info,
3396                 network_info=network_info)
3397 
3398     @wrap_exception()
3399     @reverts_task_state
3400     @wrap_instance_event
3401     @wrap_instance_fault
3402     def unrescue_instance(self, context, instance):
3403         context = context.elevated()
3404         LOG.info(_LI('Unrescuing'), context=context, instance=instance)
3405 
3406         network_info = self.network_api.get_instance_nw_info(context, instance)
3407         self._notify_about_instance_usage(context, instance,
3408                 "unrescue.start", network_info=network_info)
3409         with self._error_out_instance_on_exception(context, instance):
3410             self.driver.unrescue(instance,
3411                                  network_info)
3412 
3413         instance.vm_state = vm_states.ACTIVE
3414         instance.task_state = None
3415         instance.power_state = self._get_power_state(context, instance)
3416         instance.save(expected_task_state=task_states.UNRESCUING)
3417 
3418         self._notify_about_instance_usage(context,
3419                                           instance,
3420                                           "unrescue.end",
3421                                           network_info=network_info)
3422 
3423     @wrap_exception()
3424     @wrap_instance_fault
3425     def change_instance_metadata(self, context, diff, instance):
3426         """Update the metadata published to the instance."""
3427         LOG.debug("Changing instance metadata according to %r",
3428                   diff, instance=instance)
3429         self.driver.change_instance_metadata(context, instance, diff)
3430 
3431     @wrap_exception()
3432     @wrap_instance_event
3433     @wrap_instance_fault
3434     def confirm_resize(self, context, instance, reservations, migration):
3435 
3436         quotas = objects.Quotas.from_reservations(context,
3437                                                   reservations,
3438                                                   instance=instance)
3439 
3440         @utils.synchronized(instance.uuid)
3441         def do_confirm_resize(context, instance, migration_id):
3442             # NOTE(wangpan): Get the migration status from db, if it has been
3443             #                confirmed, we do nothing and return here
3444             LOG.debug("Going to confirm migration %s", migration_id,
3445                       context=context, instance=instance)
3446             try:
3447                 # TODO(russellb) Why are we sending the migration object just
3448                 # to turn around and look it up from the db again?
3449                 migration = objects.Migration.get_by_id(
3450                                     context.elevated(), migration_id)
3451             except exception.MigrationNotFound:
3452                 LOG.error(_LE("Migration %s is not found during confirmation"),
3453                           migration_id, context=context, instance=instance)
3454                 quotas.rollback()
3455                 return
3456 
3457             if migration.status == 'confirmed':
3458                 LOG.info(_LI("Migration %s is already confirmed"),
3459                          migration_id, context=context, instance=instance)
3460                 quotas.rollback()
3461                 return
3462             elif migration.status not in ('finished', 'confirming'):
3463                 LOG.warning(_LW("Unexpected confirmation status '%(status)s' "
3464                                 "of migration %(id)s, exit confirmation "
3465                                 "process"),
3466                             {"status": migration.status, "id": migration_id},
3467                             context=context, instance=instance)
3468                 quotas.rollback()
3469                 return
3470 
3471             # NOTE(wangpan): Get the instance from db, if it has been
3472             #                deleted, we do nothing and return here
3473             expected_attrs = ['metadata', 'system_metadata', 'flavor']
3474             try:
3475                 instance = objects.Instance.get_by_uuid(
3476                         context, instance.uuid,
3477                         expected_attrs=expected_attrs)
3478             except exception.InstanceNotFound:
3479                 LOG.info(_LI("Instance is not found during confirmation"),
3480                          context=context, instance=instance)
3481                 quotas.rollback()
3482                 return
3483 
3484             self._confirm_resize(context, instance, quotas,
3485                                  migration=migration)
3486 
3487         do_confirm_resize(context, instance, migration.id)
3488 
3489     def _confirm_resize(self, context, instance, quotas,
3490                         migration=None):
3491         """Destroys the source instance."""
3492         self._notify_about_instance_usage(context, instance,
3493                                           "resize.confirm.start")
3494 
3495         with self._error_out_instance_on_exception(context, instance,
3496                                                    quotas=quotas):
3497             # NOTE(danms): delete stashed migration information
3498             old_instance_type = instance.old_flavor
3499             instance.old_flavor = None
3500             instance.new_flavor = None
3501             instance.system_metadata.pop('old_vm_state', None)
3502             instance.save()
3503 
3504             # NOTE(tr3buchet): tear down networks on source host
3505             self.network_api.setup_networks_on_host(context, instance,
3506                                migration.source_compute, teardown=True)
3507 
3508             network_info = self.network_api.get_instance_nw_info(context,
3509                                                                  instance)
3510             self.driver.confirm_migration(migration, instance,
3511                                           network_info)
3512 
3513             migration.status = 'confirmed'
3514             with migration.obj_as_admin():
3515                 migration.save()
3516 
3517             rt = self._get_resource_tracker(migration.source_node)
3518             rt.drop_move_claim(context, instance, old_instance_type)
3519 
3520             # NOTE(mriedem): The old_vm_state could be STOPPED but the user
3521             # might have manually powered up the instance to confirm the
3522             # resize/migrate, so we need to check the current power state
3523             # on the instance and set the vm_state appropriately. We default
3524             # to ACTIVE because if the power state is not SHUTDOWN, we
3525             # assume _sync_instance_power_state will clean it up.
3526             p_state = instance.power_state
3527             vm_state = None
3528             if p_state == power_state.SHUTDOWN:
3529                 vm_state = vm_states.STOPPED
3530                 LOG.debug("Resized/migrated instance is powered off. "
3531                           "Setting vm_state to '%s'.", vm_state,
3532                           instance=instance)
3533             else:
3534                 vm_state = vm_states.ACTIVE
3535 
3536             instance.vm_state = vm_state
3537             instance.task_state = None
3538             instance.save(expected_task_state=[None, task_states.DELETING])
3539 
3540             self._notify_about_instance_usage(
3541                 context, instance, "resize.confirm.end",
3542                 network_info=network_info)
3543 
3544             quotas.commit()
3545 
3546     @wrap_exception()
3547     @reverts_task_state
3548     @wrap_instance_event
3549     @errors_out_migration
3550     @wrap_instance_fault
3551     def revert_resize(self, context, instance, migration, reservations):
3552         """Destroys the new instance on the destination machine.
3553 
3554         Reverts the model changes, and powers on the old instance on the
3555         source machine.
3556 
3557         """
3558 
3559         quotas = objects.Quotas.from_reservations(context,
3560                                                   reservations,
3561                                                   instance=instance)
3562 
3563         # NOTE(comstud): A revert_resize is essentially a resize back to
3564         # the old size, so we need to send a usage event here.
3565         compute_utils.notify_usage_exists(self.notifier, context, instance,
3566                                           current_period=True)
3567 
3568         with self._error_out_instance_on_exception(context, instance,
3569                                                    quotas=quotas):
3570             # NOTE(tr3buchet): tear down networks on destination host
3571             self.network_api.setup_networks_on_host(context, instance,
3572                                                     teardown=True)
3573 
3574             migration_p = obj_base.obj_to_primitive(migration)
3575             self.network_api.migrate_instance_start(context,
3576                                                     instance,
3577                                                     migration_p)
3578 
3579             network_info = self.network_api.get_instance_nw_info(context,
3580                                                                  instance)
3581             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3582                     context, instance.uuid)
3583             block_device_info = self._get_instance_block_device_info(
3584                                 context, instance, bdms=bdms)
3585 
3586             destroy_disks = not self._is_instance_storage_shared(
3587                 context, instance, host=migration.source_compute)
3588             self.driver.destroy(context, instance, network_info,
3589                                 block_device_info, destroy_disks)
3590 
3591             self._terminate_volume_connections(context, instance, bdms)
3592 
3593             migration.status = 'reverted'
3594             with migration.obj_as_admin():
3595                 migration.save()
3596 
3597             # NOTE(ndipanov): We need to do this here because dropping the
3598             # claim means we lose the migration_context data. We really should
3599             # fix this by moving the drop_move_claim call to the
3600             # finish_revert_resize method as this is racy (revert is dropped,
3601             # but instance resources will be tracked with the new flavor until
3602             # it gets rolled back in finish_revert_resize, which is
3603             # potentially wrong for a period of time).
3604             instance.revert_migration_context()
3605             instance.save()
3606 
3607             rt = self._get_resource_tracker(instance.node)
3608             rt.drop_move_claim(context, instance)
3609 
3610             self.compute_rpcapi.finish_revert_resize(context, instance,
3611                     migration, migration.source_compute,
3612                     quotas.reservations)
3613 
3614     @wrap_exception()
3615     @reverts_task_state
3616     @wrap_instance_event
3617     @errors_out_migration
3618     @wrap_instance_fault
3619     def finish_revert_resize(self, context, instance, reservations, migration):
3620         """Finishes the second half of reverting a resize.
3621 
3622         Bring the original source instance state back (active/shutoff) and
3623         revert the resized attributes in the database.
3624 
3625         """
3626 
3627         quotas = objects.Quotas.from_reservations(context,
3628                                                   reservations,
3629                                                   instance=instance)
3630 
3631         with self._error_out_instance_on_exception(context, instance,
3632                                                    quotas=quotas):
3633             network_info = self.network_api.get_instance_nw_info(context,
3634                                                                  instance)
3635 
3636             self._notify_about_instance_usage(
3637                     context, instance, "resize.revert.start")
3638 
3639             # NOTE(mriedem): delete stashed old_vm_state information; we
3640             # default to ACTIVE for backwards compatibility if old_vm_state
3641             # is not set
3642             old_vm_state = instance.system_metadata.pop('old_vm_state',
3643                                                         vm_states.ACTIVE)
3644 
3645             self._set_instance_info(instance, instance.old_flavor)
3646             instance.old_flavor = None
3647             instance.new_flavor = None
3648             instance.host = migration.source_compute
3649             instance.node = migration.source_node
3650             instance.save()
3651 
3652             migration.dest_compute = migration.source_compute
3653             with migration.obj_as_admin():
3654                 migration.save()
3655 
3656             self.network_api.setup_networks_on_host(context, instance,
3657                                                     migration.source_compute)
3658 
3659             block_device_info = self._get_instance_block_device_info(
3660                     context, instance, refresh_conn_info=True)
3661 
3662             power_on = old_vm_state != vm_states.STOPPED
3663             self.driver.finish_revert_migration(context, instance,
3664                                        network_info,
3665                                        block_device_info, power_on)
3666 
3667             instance.launched_at = timeutils.utcnow()
3668             instance.save(expected_task_state=task_states.RESIZE_REVERTING)
3669 
3670             migration_p = obj_base.obj_to_primitive(migration)
3671             self.network_api.migrate_instance_finish(context,
3672                                                      instance,
3673                                                      migration_p)
3674 
3675             # if the original vm state was STOPPED, set it back to STOPPED
3676             LOG.info(_LI("Updating instance to original state: '%s'"),
3677                      old_vm_state, instance=instance)
3678             if power_on:
3679                 instance.vm_state = vm_states.ACTIVE
3680                 instance.task_state = None
3681                 instance.save()
3682             else:
3683                 instance.task_state = task_states.POWERING_OFF
3684                 instance.save()
3685                 self.stop_instance(context, instance=instance,
3686                                    clean_shutdown=True)
3687 
3688             self._notify_about_instance_usage(
3689                     context, instance, "resize.revert.end")
3690             quotas.commit()
3691 
3692     def _prep_resize(self, context, image, instance, instance_type,
3693             quotas, request_spec, filter_properties, node,
3694             clean_shutdown=True):
3695 
3696         if not filter_properties:
3697             filter_properties = {}
3698 
3699         if not instance.host:
3700             self._set_instance_obj_error_state(context, instance)
3701             msg = _('Instance has no source host')
3702             raise exception.MigrationError(reason=msg)
3703 
3704         same_host = instance.host == self.host
3705         # if the flavor IDs match, it's migrate; otherwise resize
3706         if same_host and instance_type.id == instance['instance_type_id']:
3707             # check driver whether support migrate to same host
3708             if not self.driver.capabilities['supports_migrate_to_same_host']:
3709                 raise exception.UnableToMigrateToSelf(
3710                     instance_id=instance.uuid, host=self.host)
3711 
3712         # NOTE(danms): Stash the new instance_type to avoid having to
3713         # look it up in the database later
3714         instance.new_flavor = instance_type
3715         # NOTE(mriedem): Stash the old vm_state so we can set the
3716         # resized/reverted instance back to the same state later.
3717         vm_state = instance.vm_state
3718         LOG.debug('Stashing vm_state: %s', vm_state, instance=instance)
3719         instance.system_metadata['old_vm_state'] = vm_state
3720         instance.save()
3721 
3722         limits = filter_properties.get('limits', {})
3723         rt = self._get_resource_tracker(node)
3724         with rt.resize_claim(context, instance, instance_type,
3725                              image_meta=image, limits=limits) as claim:
3726             LOG.info(_LI('Migrating'), context=context, instance=instance)
3727             self.compute_rpcapi.resize_instance(
3728                     context, instance, claim.migration, image,
3729                     instance_type, quotas.reservations,
3730                     clean_shutdown)
3731 
3732     @wrap_exception()
3733     @reverts_task_state
3734     @wrap_instance_event
3735     @wrap_instance_fault
3736     def prep_resize(self, context, image, instance, instance_type,
3737                     reservations, request_spec, filter_properties, node,
3738                     clean_shutdown):
3739         """Initiates the process of moving a running instance to another host.
3740 
3741         Possibly changes the RAM and disk size in the process.
3742 
3743         """
3744         if node is None:
3745             node = self.driver.get_available_nodes(refresh=True)[0]
3746             LOG.debug("No node specified, defaulting to %s", node,
3747                       instance=instance)
3748 
3749         # NOTE(melwitt): Remove this in version 5.0 of the RPC API
3750         # Code downstream may expect extra_specs to be populated since it
3751         # is receiving an object, so lookup the flavor to ensure this.
3752         if not isinstance(instance_type, objects.Flavor):
3753             instance_type = objects.Flavor.get_by_id(context,
3754                                                      instance_type['id'])
3755 
3756         quotas = objects.Quotas.from_reservations(context,
3757                                                   reservations,
3758                                                   instance=instance)
3759         with self._error_out_instance_on_exception(context, instance,
3760                                                    quotas=quotas):
3761             compute_utils.notify_usage_exists(self.notifier, context, instance,
3762                                               current_period=True)
3763             self._notify_about_instance_usage(
3764                     context, instance, "resize.prep.start")
3765             try:
3766                 self._prep_resize(context, image, instance,
3767                                   instance_type, quotas,
3768                                   request_spec, filter_properties,
3769                                   node, clean_shutdown)
3770             # NOTE(dgenin): This is thrown in LibvirtDriver when the
3771             #               instance to be migrated is backed by LVM.
3772             #               Remove when LVM migration is implemented.
3773             except exception.MigrationPreCheckError:
3774                 raise
3775             except Exception:
3776                 # try to re-schedule the resize elsewhere:
3777                 exc_info = sys.exc_info()
3778                 self._reschedule_resize_or_reraise(context, image, instance,
3779                         exc_info, instance_type, quotas, request_spec,
3780                         filter_properties)
3781             finally:
3782                 extra_usage_info = dict(
3783                         new_instance_type=instance_type.name,
3784                         new_instance_type_id=instance_type.id)
3785 
3786                 self._notify_about_instance_usage(
3787                     context, instance, "resize.prep.end",
3788                     extra_usage_info=extra_usage_info)
3789 
3790     def _reschedule_resize_or_reraise(self, context, image, instance, exc_info,
3791             instance_type, quotas, request_spec, filter_properties):
3792         """Try to re-schedule the resize or re-raise the original error to
3793         error out the instance.
3794         """
3795         if not request_spec:
3796             request_spec = {}
3797         if not filter_properties:
3798             filter_properties = {}
3799 
3800         rescheduled = False
3801         instance_uuid = instance.uuid
3802 
3803         try:
3804             reschedule_method = self.compute_task_api.resize_instance
3805             scheduler_hint = dict(filter_properties=filter_properties)
3806             method_args = (instance, None, scheduler_hint, instance_type,
3807                            quotas.reservations)
3808             task_state = task_states.RESIZE_PREP
3809 
3810             rescheduled = self._reschedule(context, request_spec,
3811                     filter_properties, instance, reschedule_method,
3812                     method_args, task_state, exc_info)
3813         except Exception as error:
3814             rescheduled = False
3815             LOG.exception(_LE("Error trying to reschedule"),
3816                           instance_uuid=instance_uuid)
3817             compute_utils.add_instance_fault_from_exc(context,
3818                     instance, error,
3819                     exc_info=sys.exc_info())
3820             self._notify_about_instance_usage(context, instance,
3821                     'resize.error', fault=error)
3822 
3823         if rescheduled:
3824             self._log_original_error(exc_info, instance_uuid)
3825             compute_utils.add_instance_fault_from_exc(context,
3826                     instance, exc_info[1], exc_info=exc_info)
3827             self._notify_about_instance_usage(context, instance,
3828                     'resize.error', fault=exc_info[1])
3829         else:
3830             # not re-scheduling
3831             six.reraise(*exc_info)
3832 
3833     @wrap_exception()
3834     @reverts_task_state
3835     @wrap_instance_event
3836     @errors_out_migration
3837     @wrap_instance_fault
3838     def resize_instance(self, context, instance, image,
3839                         reservations, migration, instance_type,
3840                         clean_shutdown):
3841         """Starts the migration of a running instance to another host."""
3842 
3843         quotas = objects.Quotas.from_reservations(context,
3844                                                   reservations,
3845                                                   instance=instance)
3846         with self._error_out_instance_on_exception(context, instance,
3847                                                    quotas=quotas):
3848             # TODO(chaochin) Remove this until v5 RPC API
3849             # Code downstream may expect extra_specs to be populated since it
3850             # is receiving an object, so lookup the flavor to ensure this.
3851             if (not instance_type or
3852                 not isinstance(instance_type, objects.Flavor)):
3853                 instance_type = objects.Flavor.get_by_id(
3854                     context, migration['new_instance_type_id'])
3855 
3856             network_info = self.network_api.get_instance_nw_info(context,
3857                                                                  instance)
3858 
3859             migration.status = 'migrating'
3860             with migration.obj_as_admin():
3861                 migration.save()
3862 
3863             instance.task_state = task_states.RESIZE_MIGRATING
3864             instance.save(expected_task_state=task_states.RESIZE_PREP)
3865 
3866             self._notify_about_instance_usage(
3867                 context, instance, "resize.start", network_info=network_info)
3868 
3869             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
3870                     context, instance.uuid)
3871             block_device_info = self._get_instance_block_device_info(
3872                                 context, instance, bdms=bdms)
3873 
3874             timeout, retry_interval = self._get_power_off_values(context,
3875                                             instance, clean_shutdown)
3876             disk_info = self.driver.migrate_disk_and_power_off(
3877                     context, instance, migration.dest_host,
3878                     instance_type, network_info,
3879                     block_device_info,
3880                     timeout, retry_interval)
3881 
3882             self._terminate_volume_connections(context, instance, bdms)
3883 
3884             migration_p = obj_base.obj_to_primitive(migration)
3885             self.network_api.migrate_instance_start(context,
3886                                                     instance,
3887                                                     migration_p)
3888 
3889             migration.status = 'post-migrating'
3890             with migration.obj_as_admin():
3891                 migration.save()
3892 
3893             instance.host = migration.dest_compute
3894             instance.node = migration.dest_node
3895             instance.task_state = task_states.RESIZE_MIGRATED
3896             instance.save(expected_task_state=task_states.RESIZE_MIGRATING)
3897 
3898             self.compute_rpcapi.finish_resize(context, instance,
3899                     migration, image, disk_info,
3900                     migration.dest_compute, reservations=quotas.reservations)
3901 
3902             self._notify_about_instance_usage(context, instance, "resize.end",
3903                                               network_info=network_info)
3904             self.instance_events.clear_events_for_instance(instance)
3905 
3906     def _terminate_volume_connections(self, context, instance, bdms):
3907         connector = self.driver.get_volume_connector(instance)
3908         for bdm in bdms:
3909             if bdm.is_volume:
3910                 self.volume_api.terminate_connection(context, bdm.volume_id,
3911                                                      connector)
3912 
3913     @staticmethod
3914     def _set_instance_info(instance, instance_type):
3915         instance.instance_type_id = instance_type.id
3916         instance.memory_mb = instance_type.memory_mb
3917         instance.vcpus = instance_type.vcpus
3918         instance.root_gb = instance_type.root_gb
3919         instance.ephemeral_gb = instance_type.ephemeral_gb
3920         instance.flavor = instance_type
3921 
3922     def _finish_resize(self, context, instance, migration, disk_info,
3923                        image_meta):
3924         resize_instance = False
3925         old_instance_type_id = migration['old_instance_type_id']
3926         new_instance_type_id = migration['new_instance_type_id']
3927         old_instance_type = instance.get_flavor()
3928         # NOTE(mriedem): Get the old_vm_state so we know if we should
3929         # power on the instance. If old_vm_state is not set we need to default
3930         # to ACTIVE for backwards compatibility
3931         old_vm_state = instance.system_metadata.get('old_vm_state',
3932                                                     vm_states.ACTIVE)
3933         instance.old_flavor = old_instance_type
3934 
3935         if old_instance_type_id != new_instance_type_id:
3936             instance_type = instance.get_flavor('new')
3937             self._set_instance_info(instance, instance_type)
3938             for key in ('root_gb', 'swap', 'ephemeral_gb'):
3939                 if old_instance_type[key] != instance_type[key]:
3940                     resize_instance = True
3941                     break
3942         instance.apply_migration_context()
3943 
3944         # NOTE(tr3buchet): setup networks on destination host
3945         self.network_api.setup_networks_on_host(context, instance,
3946                                                 migration['dest_compute'])
3947 
3948         migration_p = obj_base.obj_to_primitive(migration)
3949         self.network_api.migrate_instance_finish(context,
3950                                                  instance,
3951                                                  migration_p)
3952 
3953         network_info = self.network_api.get_instance_nw_info(context, instance)
3954 
3955         instance.task_state = task_states.RESIZE_FINISH
3956         instance.save(expected_task_state=task_states.RESIZE_MIGRATED)
3957 
3958         self._notify_about_instance_usage(
3959             context, instance, "finish_resize.start",
3960             network_info=network_info)
3961 
3962         block_device_info = self._get_instance_block_device_info(
3963                             context, instance, refresh_conn_info=True)
3964 
3965         # NOTE(mriedem): If the original vm_state was STOPPED, we don't
3966         # automatically power on the instance after it's migrated
3967         power_on = old_vm_state != vm_states.STOPPED
3968 
3969         try:
3970             self.driver.finish_migration(context, migration, instance,
3971                                          disk_info,
3972                                          network_info,
3973                                          image_meta, resize_instance,
3974                                          block_device_info, power_on)
3975         except Exception:
3976             with excutils.save_and_reraise_exception():
3977                 if old_instance_type_id != new_instance_type_id:
3978                     self._set_instance_info(instance,
3979                                             old_instance_type)
3980 
3981         migration.status = 'finished'
3982         with migration.obj_as_admin():
3983             migration.save()
3984 
3985         instance.vm_state = vm_states.RESIZED
3986         instance.task_state = None
3987         instance.launched_at = timeutils.utcnow()
3988         instance.save(expected_task_state=task_states.RESIZE_FINISH)
3989 
3990         self._update_scheduler_instance_info(context, instance)
3991         self._notify_about_instance_usage(
3992             context, instance, "finish_resize.end",
3993             network_info=network_info)
3994 
3995     @wrap_exception()
3996     @reverts_task_state
3997     @wrap_instance_event
3998     @errors_out_migration
3999     @wrap_instance_fault
4000     def finish_resize(self, context, disk_info, image, instance,
4001                       reservations, migration):
4002         """Completes the migration process.
4003 
4004         Sets up the newly transferred disk and turns on the instance at its
4005         new host machine.
4006 
4007         """
4008         quotas = objects.Quotas.from_reservations(context,
4009                                                   reservations,
4010                                                   instance=instance)
4011         try:
4012             image_meta = objects.ImageMeta.from_dict(image)
4013             self._finish_resize(context, instance, migration,
4014                                 disk_info, image_meta)
4015             quotas.commit()
4016         except Exception:
4017             LOG.exception(_LE('Setting instance vm_state to ERROR'),
4018                           instance=instance)
4019             with excutils.save_and_reraise_exception():
4020                 try:
4021                     quotas.rollback()
4022                 except Exception:
4023                     LOG.exception(_LE("Failed to rollback quota for failed "
4024                                       "finish_resize"),
4025                                   instance=instance)
4026                 self._set_instance_obj_error_state(context, instance)
4027 
4028     @wrap_exception()
4029     @wrap_instance_fault
4030     def add_fixed_ip_to_instance(self, context, network_id, instance):
4031         """Calls network_api to add new fixed_ip to instance
4032         then injects the new network info and resets instance networking.
4033 
4034         """
4035         self._notify_about_instance_usage(
4036                 context, instance, "create_ip.start")
4037 
4038         network_info = self.network_api.add_fixed_ip_to_instance(context,
4039                                                                  instance,
4040                                                                  network_id)
4041         self._inject_network_info(context, instance, network_info)
4042         self.reset_network(context, instance)
4043 
4044         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4045         instance.updated_at = timeutils.utcnow()
4046         instance.save()
4047 
4048         self._notify_about_instance_usage(
4049             context, instance, "create_ip.end", network_info=network_info)
4050 
4051     @wrap_exception()
4052     @wrap_instance_fault
4053     def remove_fixed_ip_from_instance(self, context, address, instance):
4054         """Calls network_api to remove existing fixed_ip from instance
4055         by injecting the altered network info and resetting
4056         instance networking.
4057         """
4058         self._notify_about_instance_usage(
4059                 context, instance, "delete_ip.start")
4060 
4061         network_info = self.network_api.remove_fixed_ip_from_instance(context,
4062                                                                       instance,
4063                                                                       address)
4064         self._inject_network_info(context, instance, network_info)
4065         self.reset_network(context, instance)
4066 
4067         # NOTE(russellb) We just want to bump updated_at.  See bug 1143466.
4068         instance.updated_at = timeutils.utcnow()
4069         instance.save()
4070 
4071         self._notify_about_instance_usage(
4072             context, instance, "delete_ip.end", network_info=network_info)
4073 
4074     @wrap_exception()
4075     @reverts_task_state
4076     @wrap_instance_event
4077     @wrap_instance_fault
4078     def pause_instance(self, context, instance):
4079         """Pause an instance on this host."""
4080         context = context.elevated()
4081         LOG.info(_LI('Pausing'), context=context, instance=instance)
4082         self._notify_about_instance_usage(context, instance, 'pause.start')
4083         self.driver.pause(instance)
4084         instance.power_state = self._get_power_state(context, instance)
4085         instance.vm_state = vm_states.PAUSED
4086         instance.task_state = None
4087         instance.save(expected_task_state=task_states.PAUSING)
4088         self._notify_about_instance_usage(context, instance, 'pause.end')
4089 
4090     @wrap_exception()
4091     @reverts_task_state
4092     @wrap_instance_event
4093     @wrap_instance_fault
4094     def unpause_instance(self, context, instance):
4095         """Unpause a paused instance on this host."""
4096         context = context.elevated()
4097         LOG.info(_LI('Unpausing'), context=context, instance=instance)
4098         self._notify_about_instance_usage(context, instance, 'unpause.start')
4099         self.driver.unpause(instance)
4100         instance.power_state = self._get_power_state(context, instance)
4101         instance.vm_state = vm_states.ACTIVE
4102         instance.task_state = None
4103         instance.save(expected_task_state=task_states.UNPAUSING)
4104         self._notify_about_instance_usage(context, instance, 'unpause.end')
4105 
4106     @wrap_exception()
4107     def host_power_action(self, context, action):
4108         """Reboots, shuts down or powers up the host."""
4109         return self.driver.host_power_action(action)
4110 
4111     @wrap_exception()
4112     def host_maintenance_mode(self, context, host, mode):
4113         """Start/Stop host maintenance window. On start, it triggers
4114         guest VMs evacuation.
4115         """
4116         return self.driver.host_maintenance_mode(host, mode)
4117 
4118     @wrap_exception()
4119     def set_host_enabled(self, context, enabled):
4120         """Sets the specified host's ability to accept new instances."""
4121         return self.driver.set_host_enabled(enabled)
4122 
4123     @wrap_exception()
4124     def get_host_uptime(self, context):
4125         """Returns the result of calling "uptime" on the target host."""
4126         return self.driver.get_host_uptime()
4127 
4128     @wrap_exception()
4129     @wrap_instance_fault
4130     def get_diagnostics(self, context, instance):
4131         """Retrieve diagnostics for an instance on this host."""
4132         current_power_state = self._get_power_state(context, instance)
4133         if current_power_state == power_state.RUNNING:
4134             LOG.info(_LI("Retrieving diagnostics"), context=context,
4135                       instance=instance)
4136             return self.driver.get_diagnostics(instance)
4137         else:
4138             raise exception.InstanceInvalidState(
4139                 attr='power_state',
4140                 instance_uuid=instance.uuid,
4141                 state=instance.power_state,
4142                 method='get_diagnostics')
4143 
4144     @object_compat
4145     @wrap_exception()
4146     @wrap_instance_fault
4147     def get_instance_diagnostics(self, context, instance):
4148         """Retrieve diagnostics for an instance on this host."""
4149         current_power_state = self._get_power_state(context, instance)
4150         if current_power_state == power_state.RUNNING:
4151             LOG.info(_LI("Retrieving diagnostics"), context=context,
4152                       instance=instance)
4153             diags = self.driver.get_instance_diagnostics(instance)
4154             return diags.serialize()
4155         else:
4156             raise exception.InstanceInvalidState(
4157                 attr='power_state',
4158                 instance_uuid=instance.uuid,
4159                 state=instance.power_state,
4160                 method='get_diagnostics')
4161 
4162     @wrap_exception()
4163     @reverts_task_state
4164     @wrap_instance_event
4165     @wrap_instance_fault
4166     def suspend_instance(self, context, instance):
4167         """Suspend the given instance."""
4168         context = context.elevated()
4169 
4170         # Store the old state
4171         instance.system_metadata['old_vm_state'] = instance.vm_state
4172         self._notify_about_instance_usage(context, instance, 'suspend.start')
4173 
4174         with self._error_out_instance_on_exception(context, instance,
4175              instance_state=instance.vm_state):
4176             self.driver.suspend(context, instance)
4177         instance.power_state = self._get_power_state(context, instance)
4178         instance.vm_state = vm_states.SUSPENDED
4179         instance.task_state = None
4180         instance.save(expected_task_state=task_states.SUSPENDING)
4181         self._notify_about_instance_usage(context, instance, 'suspend.end')
4182 
4183     @wrap_exception()
4184     @reverts_task_state
4185     @wrap_instance_event
4186     @wrap_instance_fault
4187     def resume_instance(self, context, instance):
4188         """Resume the given suspended instance."""
4189         context = context.elevated()
4190         LOG.info(_LI('Resuming'), context=context, instance=instance)
4191 
4192         self._notify_about_instance_usage(context, instance, 'resume.start')
4193         network_info = self.network_api.get_instance_nw_info(context, instance)
4194         block_device_info = self._get_instance_block_device_info(
4195                             context, instance)
4196 
4197         with self._error_out_instance_on_exception(context, instance,
4198              instance_state=instance.vm_state):
4199             self.driver.resume(context, instance, network_info,
4200                                block_device_info)
4201 
4202         instance.power_state = self._get_power_state(context, instance)
4203 
4204         # We default to the ACTIVE state for backwards compatibility
4205         instance.vm_state = instance.system_metadata.pop('old_vm_state',
4206                                                          vm_states.ACTIVE)
4207 
4208         instance.task_state = None
4209         instance.save(expected_task_state=task_states.RESUMING)
4210         self._notify_about_instance_usage(context, instance, 'resume.end')
4211 
4212     @wrap_exception()
4213     @reverts_task_state
4214     @wrap_instance_event
4215     @wrap_instance_fault
4216     def shelve_instance(self, context, instance, image_id,
4217                         clean_shutdown):
4218         """Shelve an instance.
4219 
4220         This should be used when you want to take a snapshot of the instance.
4221         It also adds system_metadata that can be used by a periodic task to
4222         offload the shelved instance after a period of time.
4223 
4224         :param context: request context
4225         :param instance: an Instance object
4226         :param image_id: an image id to snapshot to.
4227         :param clean_shutdown: give the GuestOS a chance to stop
4228         """
4229         compute_utils.notify_usage_exists(self.notifier, context, instance,
4230                                           current_period=True)
4231         self._notify_about_instance_usage(context, instance, 'shelve.start')
4232 
4233         def update_task_state(task_state, expected_state=task_states.SHELVING):
4234             shelving_state_map = {
4235                     task_states.IMAGE_PENDING_UPLOAD:
4236                         task_states.SHELVING_IMAGE_PENDING_UPLOAD,
4237                     task_states.IMAGE_UPLOADING:
4238                         task_states.SHELVING_IMAGE_UPLOADING,
4239                     task_states.SHELVING: task_states.SHELVING}
4240             task_state = shelving_state_map[task_state]
4241             expected_state = shelving_state_map[expected_state]
4242             instance.task_state = task_state
4243             instance.save(expected_task_state=expected_state)
4244 
4245         self._power_off_instance(context, instance, clean_shutdown)
4246         self.driver.snapshot(context, instance, image_id, update_task_state)
4247 
4248         instance.system_metadata['shelved_at'] = timeutils.utcnow().isoformat()
4249         instance.system_metadata['shelved_image_id'] = image_id
4250         instance.system_metadata['shelved_host'] = self.host
4251         instance.vm_state = vm_states.SHELVED
4252         instance.task_state = None
4253         if CONF.shelved_offload_time == 0:
4254             instance.task_state = task_states.SHELVING_OFFLOADING
4255         instance.power_state = self._get_power_state(context, instance)
4256         instance.save(expected_task_state=[
4257                 task_states.SHELVING,
4258                 task_states.SHELVING_IMAGE_UPLOADING])
4259 
4260         self._notify_about_instance_usage(context, instance, 'shelve.end')
4261 
4262         if CONF.shelved_offload_time == 0:
4263             self.shelve_offload_instance(context, instance,
4264                                          clean_shutdown=False)
4265 
4266     @wrap_exception()
4267     @reverts_task_state
4268     @wrap_instance_fault
4269     def shelve_offload_instance(self, context, instance, clean_shutdown):
4270         """Remove a shelved instance from the hypervisor.
4271 
4272         This frees up those resources for use by other instances, but may lead
4273         to slower unshelve times for this instance.  This method is used by
4274         volume backed instances since restoring them doesn't involve the
4275         potentially large download of an image.
4276 
4277         :param context: request context
4278         :param instance: nova.objects.instance.Instance
4279         :param clean_shutdown: give the GuestOS a chance to stop
4280         """
4281         self._notify_about_instance_usage(context, instance,
4282                 'shelve_offload.start')
4283 
4284         self._power_off_instance(context, instance, clean_shutdown)
4285         current_power_state = self._get_power_state(context, instance)
4286 
4287         self.network_api.cleanup_instance_network_on_host(context, instance,
4288                                                           instance.host)
4289         network_info = self.network_api.get_instance_nw_info(context, instance)
4290         block_device_info = self._get_instance_block_device_info(context,
4291                                                                  instance)
4292         self.driver.destroy(context, instance, network_info,
4293                 block_device_info)
4294 
4295         instance.power_state = current_power_state
4296         instance.host = None
4297         instance.node = None
4298         instance.vm_state = vm_states.SHELVED_OFFLOADED
4299         instance.task_state = None
4300         instance.save(expected_task_state=[task_states.SHELVING,
4301                                            task_states.SHELVING_OFFLOADING])
4302         # NOTE(ndipanov): This frees the resources with the resource_tracker
4303         self._update_resource_tracker(context, instance)
4304 
4305         self._delete_scheduler_instance_info(context, instance.uuid)
4306         self._notify_about_instance_usage(context, instance,
4307                 'shelve_offload.end')
4308 
4309     @wrap_exception()
4310     @reverts_task_state
4311     @wrap_instance_event
4312     @wrap_instance_fault
4313     def unshelve_instance(self, context, instance, image,
4314                           filter_properties, node):
4315         """Unshelve the instance.
4316 
4317         :param context: request context
4318         :param instance: a nova.objects.instance.Instance object
4319         :param image: an image to build from.  If None we assume a
4320             volume backed instance.
4321         :param filter_properties: dict containing limits, retry info etc.
4322         :param node: target compute node
4323         """
4324         if filter_properties is None:
4325             filter_properties = {}
4326 
4327         @utils.synchronized(instance.uuid)
4328         def do_unshelve_instance():
4329             self._unshelve_instance(context, instance, image,
4330                                     filter_properties, node)
4331         do_unshelve_instance()
4332 
4333     def _unshelve_instance_key_scrub(self, instance):
4334         """Remove data from the instance that may cause side effects."""
4335         cleaned_keys = dict(
4336                 key_data=instance.key_data,
4337                 auto_disk_config=instance.auto_disk_config)
4338         instance.key_data = None
4339         instance.auto_disk_config = False
4340         return cleaned_keys
4341 
4342     def _unshelve_instance_key_restore(self, instance, keys):
4343         """Restore previously scrubbed keys before saving the instance."""
4344         instance.update(keys)
4345 
4346     def _unshelve_instance(self, context, instance, image, filter_properties,
4347                            node):
4348         self._notify_about_instance_usage(context, instance, 'unshelve.start')
4349         instance.task_state = task_states.SPAWNING
4350         instance.save()
4351 
4352         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
4353                 context, instance.uuid)
4354         block_device_info = self._prep_block_device(context, instance, bdms,
4355                                                     do_check_attach=False)
4356         scrubbed_keys = self._unshelve_instance_key_scrub(instance)
4357 
4358         if node is None:
4359             node = self.driver.get_available_nodes()[0]
4360             LOG.debug('No node specified, defaulting to %s', node,
4361                       instance=instance)
4362 
4363         rt = self._get_resource_tracker(node)
4364         limits = filter_properties.get('limits', {})
4365 
4366         shelved_image_ref = instance.image_ref
4367         if image:
4368             instance.image_ref = image['id']
4369             image_meta = objects.ImageMeta.from_dict(image)
4370         else:
4371             image_meta = objects.ImageMeta.from_dict(
4372                 utils.get_image_from_system_metadata(
4373                     instance.system_metadata))
4374 
4375         self.network_api.setup_instance_network_on_host(context, instance,
4376                                                         self.host)
4377         network_info = self.network_api.get_instance_nw_info(context, instance)
4378         try:
4379             with rt.instance_claim(context, instance, limits):
4380                 self.driver.spawn(context, instance, image_meta,
4381                                   injected_files=[],
4382                                   admin_password=None,
4383                                   network_info=network_info,
4384                                   block_device_info=block_device_info)
4385         except Exception:
4386             with excutils.save_and_reraise_exception():
4387                 LOG.exception(_LE('Instance failed to spawn'),
4388                               instance=instance)
4389 
4390         if image:
4391             instance.image_ref = shelved_image_ref
4392             self._delete_snapshot_of_shelved_instance(context, instance,
4393                                                       image['id'])
4394 
4395         self._unshelve_instance_key_restore(instance, scrubbed_keys)
4396         self._update_instance_after_spawn(context, instance)
4397         # Delete system_metadata for a shelved instance
4398         compute_utils.remove_shelved_keys_from_system_metadata(instance)
4399 
4400         instance.save(expected_task_state=task_states.SPAWNING)
4401         self._update_scheduler_instance_info(context, instance)
4402         self._notify_about_instance_usage(context, instance, 'unshelve.end')
4403 
4404     @messaging.expected_exceptions(NotImplementedError)
4405     @wrap_instance_fault
4406     def reset_network(self, context, instance):
4407         """Reset networking on the given instance."""
4408         LOG.debug('Reset network', context=context, instance=instance)
4409         self.driver.reset_network(instance)
4410 
4411     def _inject_network_info(self, context, instance, network_info):
4412         """Inject network info for the given instance."""
4413         LOG.debug('Inject network info', context=context, instance=instance)
4414         LOG.debug('network_info to inject: |%s|', network_info,
4415                   instance=instance)
4416 
4417         self.driver.inject_network_info(instance,
4418                                         network_info)
4419 
4420     @wrap_instance_fault
4421     def inject_network_info(self, context, instance):
4422         """Inject network info, but don't return the info."""
4423         network_info = self.network_api.get_instance_nw_info(context, instance)
4424         self._inject_network_info(context, instance, network_info)
4425 
4426     @messaging.expected_exceptions(NotImplementedError,
4427                                    exception.InstanceNotFound)
4428     @wrap_exception()
4429     @wrap_instance_fault
4430     def get_console_output(self, context, instance, tail_length):
4431         """Send the console output for the given instance."""
4432         context = context.elevated()
4433         LOG.info(_LI("Get console output"), context=context,
4434                   instance=instance)
4435         output = self.driver.get_console_output(context, instance)
4436 
4437         if type(output) is six.text_type:
4438             # the console output will be bytes.
4439             output = six.b(output)
4440 
4441         if tail_length is not None:
4442             output = self._tail_log(output, tail_length)
4443 
4444         return output.decode('utf-8', 'replace').encode('ascii', 'replace')
4445 
4446     def _tail_log(self, log, length):
4447         try:
4448             length = int(length)
4449         except ValueError:
4450             length = 0
4451 
4452         if length == 0:
4453             return b''
4454         else:
4455             return b'\n'.join(log.split(b'\n')[-int(length):])
4456 
4457     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4458                                    exception.InstanceNotReady,
4459                                    exception.InstanceNotFound,
4460                                    exception.ConsoleTypeUnavailable,
4461                                    NotImplementedError)
4462     @wrap_exception()
4463     @wrap_instance_fault
4464     def get_vnc_console(self, context, console_type, instance):
4465         """Return connection information for a vnc console."""
4466         context = context.elevated()
4467         LOG.debug("Getting vnc console", instance=instance)
4468         token = str(uuid.uuid4())
4469 
4470         if not CONF.vnc.enabled:
4471             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4472 
4473         if console_type == 'novnc':
4474             # For essex, novncproxy_base_url must include the full path
4475             # including the html file (like http://myhost/vnc_auto.html)
4476             access_url = '%s?token=%s' % (CONF.vnc.novncproxy_base_url, token)
4477         elif console_type == 'xvpvnc':
4478             access_url = '%s?token=%s' % (CONF.vnc.xvpvncproxy_base_url, token)
4479         else:
4480             raise exception.ConsoleTypeInvalid(console_type=console_type)
4481 
4482         try:
4483             # Retrieve connect info from driver, and then decorate with our
4484             # access info token
4485             console = self.driver.get_vnc_console(context, instance)
4486             connect_info = console.get_connection_info(token, access_url)
4487         except exception.InstanceNotFound:
4488             if instance.vm_state != vm_states.BUILDING:
4489                 raise
4490             raise exception.InstanceNotReady(instance_id=instance.uuid)
4491 
4492         return connect_info
4493 
4494     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4495                                    exception.InstanceNotReady,
4496                                    exception.InstanceNotFound,
4497                                    exception.ConsoleTypeUnavailable,
4498                                    NotImplementedError)
4499     @wrap_exception()
4500     @wrap_instance_fault
4501     def get_spice_console(self, context, console_type, instance):
4502         """Return connection information for a spice console."""
4503         context = context.elevated()
4504         LOG.debug("Getting spice console", instance=instance)
4505         token = str(uuid.uuid4())
4506 
4507         if not CONF.spice.enabled:
4508             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4509 
4510         if console_type == 'spice-html5':
4511             # For essex, spicehtml5proxy_base_url must include the full path
4512             # including the html file (like http://myhost/spice_auto.html)
4513             access_url = '%s?token=%s' % (CONF.spice.html5proxy_base_url,
4514                                           token)
4515         else:
4516             raise exception.ConsoleTypeInvalid(console_type=console_type)
4517 
4518         try:
4519             # Retrieve connect info from driver, and then decorate with our
4520             # access info token
4521             console = self.driver.get_spice_console(context, instance)
4522             connect_info = console.get_connection_info(token, access_url)
4523         except exception.InstanceNotFound:
4524             if instance.vm_state != vm_states.BUILDING:
4525                 raise
4526             raise exception.InstanceNotReady(instance_id=instance.uuid)
4527 
4528         return connect_info
4529 
4530     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4531                                    exception.InstanceNotReady,
4532                                    exception.InstanceNotFound,
4533                                    exception.ConsoleTypeUnavailable,
4534                                    NotImplementedError)
4535     @wrap_exception()
4536     @wrap_instance_fault
4537     def get_rdp_console(self, context, console_type, instance):
4538         """Return connection information for a RDP console."""
4539         context = context.elevated()
4540         LOG.debug("Getting RDP console", instance=instance)
4541         token = str(uuid.uuid4())
4542 
4543         if not CONF.rdp.enabled:
4544             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4545 
4546         if console_type == 'rdp-html5':
4547             access_url = '%s?token=%s' % (CONF.rdp.html5_proxy_base_url,
4548                                           token)
4549         else:
4550             raise exception.ConsoleTypeInvalid(console_type=console_type)
4551 
4552         try:
4553             # Retrieve connect info from driver, and then decorate with our
4554             # access info token
4555             console = self.driver.get_rdp_console(context, instance)
4556             connect_info = console.get_connection_info(token, access_url)
4557         except exception.InstanceNotFound:
4558             if instance.vm_state != vm_states.BUILDING:
4559                 raise
4560             raise exception.InstanceNotReady(instance_id=instance.uuid)
4561 
4562         return connect_info
4563 
4564     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4565                                    exception.InstanceNotReady,
4566                                    exception.InstanceNotFound,
4567                                    exception.ConsoleTypeUnavailable,
4568                                    NotImplementedError)
4569     @wrap_exception()
4570     @wrap_instance_fault
4571     def get_mks_console(self, context, console_type, instance):
4572         """Return connection information for a MKS console."""
4573         context = context.elevated()
4574         LOG.debug("Getting MKS console", instance=instance)
4575         token = str(uuid.uuid4())
4576 
4577         if not CONF.mks.enabled:
4578             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4579 
4580         if console_type == 'webmks':
4581             access_url = '%s?token=%s' % (CONF.mks.mksproxy_base_url,
4582                                           token)
4583         else:
4584             raise exception.ConsoleTypeInvalid(console_type=console_type)
4585 
4586         try:
4587             # Retrieve connect info from driver, and then decorate with our
4588             # access info token
4589             console = self.driver.get_mks_console(context, instance)
4590             connect_info = console.get_connection_info(token, access_url)
4591         except exception.InstanceNotFound:
4592             if instance.vm_state != vm_states.BUILDING:
4593                 raise
4594             raise exception.InstanceNotReady(instance_id=instance.uuid)
4595 
4596         return connect_info
4597 
4598     @messaging.expected_exceptions(
4599         exception.ConsoleTypeInvalid,
4600         exception.InstanceNotReady,
4601         exception.InstanceNotFound,
4602         exception.ConsoleTypeUnavailable,
4603         exception.SocketPortRangeExhaustedException,
4604         exception.ImageSerialPortNumberInvalid,
4605         exception.ImageSerialPortNumberExceedFlavorValue,
4606         NotImplementedError)
4607     @wrap_exception()
4608     @wrap_instance_fault
4609     def get_serial_console(self, context, console_type, instance):
4610         """Returns connection information for a serial console."""
4611 
4612         LOG.debug("Getting serial console", instance=instance)
4613 
4614         if not CONF.serial_console.enabled:
4615             raise exception.ConsoleTypeUnavailable(console_type=console_type)
4616 
4617         context = context.elevated()
4618 
4619         token = str(uuid.uuid4())
4620         access_url = '%s?token=%s' % (CONF.serial_console.base_url, token)
4621 
4622         try:
4623             # Retrieve connect info from driver, and then decorate with our
4624             # access info token
4625             console = self.driver.get_serial_console(context, instance)
4626             connect_info = console.get_connection_info(token, access_url)
4627         except exception.InstanceNotFound:
4628             if instance.vm_state != vm_states.BUILDING:
4629                 raise
4630             raise exception.InstanceNotReady(instance_id=instance.uuid)
4631 
4632         return connect_info
4633 
4634     @messaging.expected_exceptions(exception.ConsoleTypeInvalid,
4635                                    exception.InstanceNotReady,
4636                                    exception.InstanceNotFound)
4637     @wrap_exception()
4638     @wrap_instance_fault
4639     def validate_console_port(self, ctxt, instance, port, console_type):
4640         if console_type == "spice-html5":
4641             console_info = self.driver.get_spice_console(ctxt, instance)
4642         elif console_type == "rdp-html5":
4643             console_info = self.driver.get_rdp_console(ctxt, instance)
4644         elif console_type == "serial":
4645             console_info = self.driver.get_serial_console(ctxt, instance)
4646         elif console_type == "webmks":
4647             console_info = self.driver.get_mks_console(ctxt, instance)
4648         else:
4649             console_info = self.driver.get_vnc_console(ctxt, instance)
4650 
4651         return console_info.port == port
4652 
4653     @wrap_exception()
4654     @reverts_task_state
4655     @wrap_instance_fault
4656     def reserve_block_device_name(self, context, instance, device,
4657                                   volume_id, disk_bus, device_type):
4658         @utils.synchronized(instance.uuid)
4659         def do_reserve():
4660             bdms = (
4661                 objects.BlockDeviceMappingList.get_by_instance_uuid(
4662                     context, instance.uuid))
4663 
4664             # NOTE(ndipanov): We need to explicitly set all the fields on the
4665             #                 object so that obj_load_attr does not fail
4666             new_bdm = objects.BlockDeviceMapping(
4667                     context=context,
4668                     source_type='volume', destination_type='volume',
4669                     instance_uuid=instance.uuid, boot_index=None,
4670                     volume_id=volume_id,
4671                     device_name=device, guest_format=None,
4672                     disk_bus=disk_bus, device_type=device_type)
4673 
4674             new_bdm.device_name = self._get_device_name_for_instance(
4675                     instance, bdms, new_bdm)
4676 
4677             # NOTE(vish): create bdm here to avoid race condition
4678             new_bdm.create()
4679             return new_bdm
4680 
4681         return do_reserve()
4682 
4683     @wrap_exception()
4684     @wrap_instance_fault
4685     def attach_volume(self, context, instance, bdm):
4686         """Attach a volume to an instance."""
4687         driver_bdm = driver_block_device.convert_volume(bdm)
4688 
4689         @utils.synchronized(instance.uuid)
4690         def do_attach_volume(context, instance, driver_bdm):
4691             try:
4692                 return self._attach_volume(context, instance, driver_bdm)
4693             except Exception:
4694                 with excutils.save_and_reraise_exception():
4695                     bdm.destroy()
4696 
4697         do_attach_volume(context, instance, driver_bdm)
4698 
4699     def _attach_volume(self, context, instance, bdm):
4700         context = context.elevated()
4701         LOG.info(_LI('Attaching volume %(volume_id)s to %(mountpoint)s'),
4702                   {'volume_id': bdm.volume_id,
4703                   'mountpoint': bdm['mount_device']},
4704                  context=context, instance=instance)
4705         try:
4706             bdm.attach(context, instance, self.volume_api, self.driver,
4707                        do_check_attach=False, do_driver_attach=True)
4708         except Exception:
4709             with excutils.save_and_reraise_exception():
4710                 LOG.exception(_LE("Failed to attach %(volume_id)s "
4711                                   "at %(mountpoint)s"),
4712                               {'volume_id': bdm.volume_id,
4713                                'mountpoint': bdm['mount_device']},
4714                               context=context, instance=instance)
4715                 self.volume_api.unreserve_volume(context, bdm.volume_id)
4716 
4717         info = {'volume_id': bdm.volume_id}
4718         self._notify_about_instance_usage(
4719             context, instance, "volume.attach", extra_usage_info=info)
4720 
4721     def _driver_detach_volume(self, context, instance, bdm):
4722         """Do the actual driver detach using block device mapping."""
4723         mp = bdm.device_name
4724         volume_id = bdm.volume_id
4725 
4726         LOG.info(_LI('Detach volume %(volume_id)s from mountpoint %(mp)s'),
4727                   {'volume_id': volume_id, 'mp': mp},
4728                   context=context, instance=instance)
4729 
4730         connection_info = jsonutils.loads(bdm.connection_info)
4731         # NOTE(vish): We currently don't use the serial when disconnecting,
4732         #             but added for completeness in case we ever do.
4733         if connection_info and 'serial' not in connection_info:
4734             connection_info['serial'] = volume_id
4735         try:
4736             if not self.driver.instance_exists(instance):
4737                 LOG.warning(_LW('Detaching volume from unknown instance'),
4738                             context=context, instance=instance)
4739 
4740             encryption = encryptors.get_encryption_metadata(
4741                 context, self.volume_api, volume_id, connection_info)
4742 
4743             self.driver.detach_volume(connection_info,
4744                                       instance,
4745                                       mp,
4746                                       encryption=encryption)
4747         except exception.DiskNotFound as err:
4748             LOG.warning(_LW('Ignoring DiskNotFound exception while detaching '
4749                             'volume %(volume_id)s from %(mp)s: %(err)s'),
4750                         {'volume_id': volume_id, 'mp': mp, 'err': err},
4751                         instance=instance)
4752         except Exception:
4753             with excutils.save_and_reraise_exception():
4754                 LOG.exception(_LE('Failed to detach volume %(volume_id)s '
4755                                   'from %(mp)s'),
4756                               {'volume_id': volume_id, 'mp': mp},
4757                               context=context, instance=instance)
4758                 self.volume_api.roll_detaching(context, volume_id)
4759 
4760     def _detach_volume(self, context, volume_id, instance, destroy_bdm=True,
4761                        attachment_id=None):
4762         """Detach a volume from an instance.
4763 
4764         :param context: security context
4765         :param volume_id: the volume id
4766         :param instance: the Instance object to detach the volume from
4767         :param destroy_bdm: if True, the corresponding BDM entry will be marked
4768                             as deleted. Disabling this is useful for operations
4769                             like rebuild, when we don't want to destroy BDM
4770 
4771         """
4772 
4773         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4774                 context, volume_id, instance.uuid)
4775         if CONF.volume_usage_poll_interval > 0:
4776             vol_stats = []
4777             mp = bdm.device_name
4778             # Handle bootable volumes which will not contain /dev/
4779             if '/dev/' in mp:
4780                 mp = mp[5:]
4781             try:
4782                 vol_stats = self.driver.block_stats(instance, mp)
4783             except NotImplementedError:
4784                 pass
4785 
4786             if vol_stats:
4787                 LOG.debug("Updating volume usage cache with totals",
4788                           instance=instance)
4789                 rd_req, rd_bytes, wr_req, wr_bytes, flush_ops = vol_stats
4790                 vol_usage = objects.VolumeUsage(context)
4791                 vol_usage.volume_id = volume_id
4792                 vol_usage.instance_uuid = instance.uuid
4793                 vol_usage.project_id = instance.project_id
4794                 vol_usage.user_id = instance.user_id
4795                 vol_usage.availability_zone = instance.availability_zone
4796                 vol_usage.curr_reads = rd_req
4797                 vol_usage.curr_read_bytes = rd_bytes
4798                 vol_usage.curr_writes = wr_req
4799                 vol_usage.curr_write_bytes = wr_bytes
4800                 vol_usage.save(update_totals=True)
4801                 self.notifier.info(context, 'volume.usage',
4802                                    compute_utils.usage_volume_info(vol_usage))
4803 
4804         self._driver_detach_volume(context, instance, bdm)
4805         connector = self.driver.get_volume_connector(instance)
4806         self.volume_api.terminate_connection(context, volume_id, connector)
4807 
4808         if destroy_bdm:
4809             bdm.destroy()
4810 
4811         info = dict(volume_id=volume_id)
4812         self._notify_about_instance_usage(
4813             context, instance, "volume.detach", extra_usage_info=info)
4814         self.volume_api.detach(context.elevated(), volume_id, instance.uuid,
4815                                attachment_id)
4816 
4817     @wrap_exception()
4818     @wrap_instance_fault
4819     def detach_volume(self, context, volume_id, instance, attachment_id=None):
4820         """Detach a volume from an instance."""
4821 
4822         self._detach_volume(context, volume_id, instance,
4823                             attachment_id=attachment_id)
4824 
4825     def _init_volume_connection(self, context, new_volume_id,
4826                                 old_volume_id, connector, instance, bdm):
4827 
4828         new_cinfo = self.volume_api.initialize_connection(context,
4829                                                           new_volume_id,
4830                                                           connector)
4831         old_cinfo = jsonutils.loads(bdm['connection_info'])
4832         if old_cinfo and 'serial' not in old_cinfo:
4833             old_cinfo['serial'] = old_volume_id
4834         new_cinfo['serial'] = old_cinfo['serial']
4835         return (old_cinfo, new_cinfo)
4836 
4837     def _swap_volume(self, context, instance, bdm, connector,
4838                      old_volume_id, new_volume_id, resize_to):
4839         mountpoint = bdm['device_name']
4840         failed = False
4841         new_cinfo = None
4842         try:
4843             old_cinfo, new_cinfo = self._init_volume_connection(context,
4844                                                                 new_volume_id,
4845                                                                 old_volume_id,
4846                                                                 connector,
4847                                                                 instance,
4848                                                                 bdm)
4849             LOG.debug("swap_volume: Calling driver volume swap with "
4850                       "connection infos: new: %(new_cinfo)s; "
4851                       "old: %(old_cinfo)s",
4852                       {'new_cinfo': new_cinfo, 'old_cinfo': old_cinfo},
4853                       contex=context, instance=instance)
4854             self.driver.swap_volume(old_cinfo, new_cinfo, instance, mountpoint,
4855                                     resize_to)
4856         except Exception:
4857             failed = True
4858             with excutils.save_and_reraise_exception():
4859                 if new_cinfo:
4860                     msg = _LE("Failed to swap volume %(old_volume_id)s "
4861                               "for %(new_volume_id)s")
4862                     LOG.exception(msg, {'old_volume_id': old_volume_id,
4863                                         'new_volume_id': new_volume_id},
4864                                   context=context,
4865                                   instance=instance)
4866                 else:
4867                     msg = _LE("Failed to connect to volume %(volume_id)s "
4868                               "with volume at %(mountpoint)s")
4869                     LOG.exception(msg, {'volume_id': new_volume_id,
4870                                         'mountpoint': bdm['device_name']},
4871                                   context=context,
4872                                   instance=instance)
4873                 self.volume_api.roll_detaching(context, old_volume_id)
4874                 self.volume_api.unreserve_volume(context, new_volume_id)
4875         finally:
4876             conn_volume = new_volume_id if failed else old_volume_id
4877             if new_cinfo:
4878                 LOG.debug("swap_volume: calling Cinder terminate_connection "
4879                           "for %(volume)s", {'volume': conn_volume},
4880                           context=context, instance=instance)
4881                 self.volume_api.terminate_connection(context,
4882                                                      conn_volume,
4883                                                      connector)
4884             # If Cinder initiated the swap, it will keep
4885             # the original ID
4886             comp_ret = self.volume_api.migrate_volume_completion(
4887                                                       context,
4888                                                       old_volume_id,
4889                                                       new_volume_id,
4890                                                       error=failed)
4891             LOG.debug("swap_volume: Cinder migrate_volume_completion "
4892                       "returned: %(comp_ret)s", {'comp_ret': comp_ret},
4893                       context=context, instance=instance)
4894 
4895         return (comp_ret, new_cinfo)
4896 
4897     @wrap_exception()
4898     @reverts_task_state
4899     @wrap_instance_fault
4900     def swap_volume(self, context, old_volume_id, new_volume_id, instance):
4901         """Swap volume for an instance."""
4902         context = context.elevated()
4903 
4904         bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4905                 context, old_volume_id, instance.uuid)
4906         connector = self.driver.get_volume_connector(instance)
4907 
4908         resize_to = 0
4909         old_vol_size = self.volume_api.get(context, old_volume_id)['size']
4910         new_vol_size = self.volume_api.get(context, new_volume_id)['size']
4911         if new_vol_size > old_vol_size:
4912             resize_to = new_vol_size
4913 
4914         LOG.info(_LI('Swapping volume %(old_volume)s for %(new_volume)s'),
4915                   {'old_volume': old_volume_id, 'new_volume': new_volume_id},
4916                   context=context, instance=instance)
4917         comp_ret, new_cinfo = self._swap_volume(context, instance,
4918                                                          bdm,
4919                                                          connector,
4920                                                          old_volume_id,
4921                                                          new_volume_id,
4922                                                          resize_to)
4923 
4924         save_volume_id = comp_ret['save_volume_id']
4925 
4926         # Update bdm
4927         values = {
4928             'connection_info': jsonutils.dumps(new_cinfo),
4929             'delete_on_termination': False,
4930             'source_type': 'volume',
4931             'destination_type': 'volume',
4932             'snapshot_id': None,
4933             'volume_id': save_volume_id,
4934             'no_device': None}
4935 
4936         if resize_to:
4937             values['volume_size'] = resize_to
4938 
4939         LOG.debug("swap_volume: Updating volume %(volume_id)s BDM record with "
4940                   "%(updates)s", {'volume_id': bdm.volume_id,
4941                                   'updates': values},
4942                   context=context, instance=instance)
4943         bdm.update(values)
4944         bdm.save()
4945 
4946     @wrap_exception()
4947     def remove_volume_connection(self, context, volume_id, instance):
4948         """Remove a volume connection using the volume api."""
4949         # NOTE(vish): We don't want to actually mark the volume
4950         #             detached, or delete the bdm, just remove the
4951         #             connection from this host.
4952 
4953         try:
4954             bdm = objects.BlockDeviceMapping.get_by_volume_and_instance(
4955                     context, volume_id, instance.uuid)
4956             self._driver_detach_volume(context, instance, bdm)
4957             connector = self.driver.get_volume_connector(instance)
4958             self.volume_api.terminate_connection(context, volume_id, connector)
4959         except exception.NotFound:
4960             pass
4961 
4962     @wrap_exception()
4963     @wrap_instance_fault
4964     def attach_interface(self, context, instance, network_id, port_id,
4965                          requested_ip):
4966         """Use hotplug to add an network adapter to an instance."""
4967         bind_host_id = self.driver.network_binding_host_id(context, instance)
4968         network_info = self.network_api.allocate_port_for_instance(
4969             context, instance, port_id, network_id, requested_ip,
4970             bind_host_id=bind_host_id)
4971         if len(network_info) != 1:
4972             LOG.error(_LE('allocate_port_for_instance returned %(ports)s '
4973                           'ports'), {'ports': len(network_info)})
4974             raise exception.InterfaceAttachFailed(
4975                     instance_uuid=instance.uuid)
4976         image_meta = objects.ImageMeta.from_instance(instance)
4977 
4978         try:
4979             self.driver.attach_interface(instance, image_meta, network_info[0])
4980         except exception.NovaException as ex:
4981             port_id = network_info[0].get('id')
4982             LOG.warn(_LW("attach interface failed , try to deallocate "
4983                          "port %(port_id)s, reason: %(msg)s"),
4984                      {'port_id': port_id, 'msg': ex},
4985                      instance=instance)
4986             try:
4987                 self.network_api.deallocate_port_for_instance(
4988                     context, instance, port_id)
4989             except Exception:
4990                 LOG.warn(_LW("deallocate port %(port_id)s failed"),
4991                              {'port_id': port_id}, instance=instance)
4992             raise exception.InterfaceAttachFailed(
4993                 instance_uuid=instance.uuid)
4994 
4995         return network_info[0]
4996 
4997     @wrap_exception()
4998     @wrap_instance_fault
4999     def detach_interface(self, context, instance, port_id):
5000         """Detach an network adapter from an instance."""
5001         network_info = instance.info_cache.network_info
5002         condemned = None
5003         for vif in network_info:
5004             if vif['id'] == port_id:
5005                 condemned = vif
5006                 break
5007         if condemned is None:
5008             raise exception.PortNotFound(_("Port %s is not "
5009                                            "attached") % port_id)
5010         try:
5011             self.driver.detach_interface(instance, condemned)
5012         except exception.NovaException as ex:
5013             LOG.warning(_LW("Detach interface failed, port_id=%(port_id)s,"
5014                             " reason: %(msg)s"),
5015                         {'port_id': port_id, 'msg': ex}, instance=instance)
5016             raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)
5017         else:
5018             try:
5019                 self.network_api.deallocate_port_for_instance(
5020                     context, instance, port_id)
5021             except Exception as ex:
5022                 with excutils.save_and_reraise_exception():
5023                     # Since this is a cast operation, log the failure for
5024                     # triage.
5025                     LOG.warning(_LW('Failed to deallocate port %(port_id)s '
5026                                     'for instance. Error: %(error)s'),
5027                                 {'port_id': port_id, 'error': ex},
5028                                 instance=instance)
5029 
5030     def _get_compute_info(self, context, host):
5031         return objects.ComputeNode.get_first_node_by_host_for_old_compat(
5032             context, host)
5033 
5034     @wrap_exception()
5035     def check_instance_shared_storage(self, ctxt, instance, data):
5036         """Check if the instance files are shared
5037 
5038         :param ctxt: security context
5039         :param instance: dict of instance data
5040         :param data: result of driver.check_instance_shared_storage_local
5041 
5042         Returns True if instance disks located on shared storage and
5043         False otherwise.
5044         """
5045         return self.driver.check_instance_shared_storage_remote(ctxt, data)
5046 
5047     @wrap_exception()
5048     @wrap_instance_event
5049     @wrap_instance_fault
5050     def check_can_live_migrate_destination(self, ctxt, instance,
5051                                            block_migration, disk_over_commit,
5052                                            migration=None, scheduled_node=None,
5053                                            limits=None):
5054         """Check if it is possible to execute live migration.
5055 
5056         This runs checks on the destination host, and then calls
5057         back to the source host to check the results.
5058 
5059         :param context: security context
5060         :param instance: dict of instance data
5061         :param block_migration: if true, prepare for block migration
5062         :param disk_over_commit: if true, allow disk over commit
5063         :param migration: the migration object that tracks data about this
5064                           migration
5065         :param scheduled_node: Node chosen by the scheduler
5066         :param scheduled_node: objects.Limits instance that the scheduler
5067                                returne when this host was chosen
5068         :returns: a dict containing migration info
5069         """
5070         if scheduled_node is not None:
5071             rt = self._get_resource_tracker(scheduled_node)
5072             live_mig_claim = rt.live_migration_claim
5073         else:
5074             live_mig_claim = claims.NopClaim
5075         try:
5076             with live_mig_claim(ctxt, instance, migration):
5077                 return self._do_check_can_live_migrate_destination(
5078                     ctxt, instance, block_migration, disk_over_commit)
5079         except exception.ComputeResourcesUnavailable as e:
5080             LOG.debug("Could not claim resources for live migrating the "
5081                       "instance to this host. Not enough resources available.",
5082                       instance=instance)
5083             raise exception.BuildAbortException(instance_uuid=instance.uuid,
5084                                                 reason=e.format_message())
5085 
5086     def _do_check_can_live_migrate_destination(self, ctxt, instance,
5087                                                block_migration,
5088                                                disk_over_commit):
5089         src_compute_info = obj_base.obj_to_primitive(
5090             self._get_compute_info(ctxt, instance.host))
5091         dst_compute_info = obj_base.obj_to_primitive(
5092             self._get_compute_info(ctxt, CONF.host))
5093         dest_check_data = self.driver.check_can_live_migrate_destination(ctxt,
5094             instance, src_compute_info, dst_compute_info,
5095             block_migration, disk_over_commit)
5096         LOG.debug('destination check data is %s', dest_check_data)
5097         try:
5098             migrate_data = self.compute_rpcapi.\
5099                                 check_can_live_migrate_source(ctxt, instance,
5100                                                               dest_check_data)
5101         finally:
5102             self.driver.check_can_live_migrate_destination_cleanup(ctxt,
5103                     dest_check_data)
5104         return migrate_data
5105 
5106     @wrap_exception()
5107     @wrap_instance_event
5108     @wrap_instance_fault
5109     def check_can_live_migrate_source(self, ctxt, instance, dest_check_data):
5110         """Check if it is possible to execute live migration.
5111 
5112         This checks if the live migration can succeed, based on the
5113         results from check_can_live_migrate_destination.
5114 
5115         :param ctxt: security context
5116         :param instance: dict of instance data
5117         :param dest_check_data: result of check_can_live_migrate_destination
5118         :returns: a dict containing migration info
5119         """
5120         is_volume_backed = self.compute_api.is_volume_backed_instance(ctxt,
5121                                                                       instance)
5122         got_migrate_data_object = isinstance(dest_check_data,
5123                                              migrate_data_obj.LiveMigrateData)
5124         if not got_migrate_data_object:
5125             dest_check_data = \
5126                 migrate_data_obj.LiveMigrateData.detect_implementation(
5127                     dest_check_data)
5128         dest_check_data.is_volume_backed = is_volume_backed
5129         block_device_info = self._get_instance_block_device_info(
5130                             ctxt, instance, refresh_conn_info=True)
5131         result = self.driver.check_can_live_migrate_source(ctxt, instance,
5132                                                            dest_check_data,
5133                                                            block_device_info)
5134         if not got_migrate_data_object:
5135             result = result.to_legacy_dict()
5136         LOG.debug('source check data is %s', result)
5137         return result
5138 
5139     @wrap_exception()
5140     @wrap_instance_event
5141     @wrap_instance_fault
5142     def pre_live_migration(self, context, instance, block_migration, disk,
5143                            migrate_data):
5144         """Preparations for live migration at dest host.
5145 
5146         :param context: security context
5147         :param instance: dict of instance data
5148         :param block_migration: if true, prepare for block migration
5149         :param migrate_data: if not None, it is a dict which holds data
5150                              required for live migration without shared
5151                              storage.
5152 
5153         """
5154         LOG.debug('pre_live_migration data is %s', migrate_data)
5155         got_migrate_data_object = isinstance(migrate_data,
5156                                              migrate_data_obj.LiveMigrateData)
5157         if not got_migrate_data_object:
5158             migrate_data = \
5159                 migrate_data_obj.LiveMigrateData.detect_implementation(
5160                     migrate_data)
5161         block_device_info = self._get_instance_block_device_info(
5162                             context, instance, refresh_conn_info=True)
5163 
5164         network_info = self.network_api.get_instance_nw_info(context, instance)
5165         self._notify_about_instance_usage(
5166                      context, instance, "live_migration.pre.start",
5167                      network_info=network_info)
5168 
5169         migrate_data = self.driver.pre_live_migration(context,
5170                                        instance,
5171                                        block_device_info,
5172                                        network_info,
5173                                        disk,
5174                                        migrate_data)
5175         LOG.debug('driver pre_live_migration data is %s' % migrate_data)
5176 
5177         # NOTE(tr3buchet): setup networks on destination host
5178         self.network_api.setup_networks_on_host(context, instance,
5179                                                          self.host)
5180 
5181         # Creating filters to hypervisors and firewalls.
5182         # An example is that nova-instance-instance-xxx,
5183         # which is written to libvirt.xml(Check "virsh nwfilter-list")
5184         # This nwfilter is necessary on the destination host.
5185         # In addition, this method is creating filtering rule
5186         # onto destination host.
5187         self.driver.ensure_filtering_rules_for_instance(instance,
5188                                             network_info)
5189 
5190         self._notify_about_instance_usage(
5191                      context, instance, "live_migration.pre.end",
5192                      network_info=network_info)
5193 
5194         if not got_migrate_data_object and migrate_data:
5195             migrate_data = migrate_data.to_legacy_dict(
5196                 pre_migration_result=True)
5197             migrate_data = migrate_data['pre_live_migration_result']
5198         LOG.debug('pre_live_migration result data is %s', migrate_data)
5199         return migrate_data
5200 
5201     def _do_live_migration(self, context, dest, instance, block_migration,
5202                            migration, migrate_data):
5203         # NOTE(danms): We should enhance the RT to account for migrations
5204         # and use the status field to denote when the accounting has been
5205         # done on source/destination. For now, this is just here for status
5206         # reporting
5207         self._set_migration_status(migration, 'preparing')
5208 
5209         got_migrate_data_object = isinstance(migrate_data,
5210                                              migrate_data_obj.LiveMigrateData)
5211         if not got_migrate_data_object:
5212             migrate_data = \
5213                 migrate_data_obj.LiveMigrateData.detect_implementation(
5214                     migrate_data)
5215 
5216         try:
5217             if block_migration:
5218                 block_device_info = self._get_instance_block_device_info(
5219                     context, instance)
5220                 disk = self.driver.get_instance_disk_info(
5221                     instance, block_device_info=block_device_info)
5222             else:
5223                 disk = None
5224 
5225             migrate_data = self.compute_rpcapi.pre_live_migration(
5226                 context, instance,
5227                 block_migration, disk, dest, migrate_data)
5228         except Exception:
5229             with excutils.save_and_reraise_exception():
5230                 LOG.exception(_LE('Pre live migration failed at %s'),
5231                               dest, instance=instance)
5232                 self._set_migration_status(migration, 'failed')
5233                 self._rollback_live_migration(context, instance, dest,
5234                                               block_migration, migrate_data)
5235 
5236         self._set_migration_status(migration, 'running')
5237 
5238         if migrate_data:
5239             migrate_data.migration = migration
5240         LOG.debug('live_migration data is %s', migrate_data)
5241         try:
5242             self.driver.live_migration(context, instance, dest,
5243                                        self._post_live_migration,
5244                                        self._rollback_live_migration,
5245                                        block_migration, migrate_data)
5246         except Exception:
5247             # Executing live migration
5248             # live_migration might raises exceptions, but
5249             # nothing must be recovered in this version.
5250             LOG.exception(_LE('Live migration failed.'), instance=instance)
5251             with excutils.save_and_reraise_exception():
5252                 self._set_migration_status(migration, 'failed')
5253 
5254     @wrap_exception()
5255     @wrap_instance_event
5256     @wrap_instance_fault
5257     def live_migration(self, context, dest, instance, block_migration,
5258                        migration, migrate_data):
5259         """Executing live migration.
5260 
5261         :param context: security context
5262         :param dest: destination host
5263         :param instance: a nova.objects.instance.Instance object
5264         :param block_migration: if true, prepare for block migration
5265         :param migration: an nova.objects.Migration object
5266         :param migrate_data: implementation specific params
5267 
5268         """
5269         self._set_migration_status(migration, 'queued')
5270 
5271         def dispatch_live_migration(*args, **kwargs):
5272             with self._live_migration_semaphore:
5273                 self._do_live_migration(*args, **kwargs)
5274 
5275         # NOTE(danms): We spawn here to return the RPC worker thread back to
5276         # the pool. Since what follows could take a really long time, we don't
5277         # want to tie up RPC workers.
5278         utils.spawn_n(dispatch_live_migration,
5279                       context, dest, instance,
5280                       block_migration, migration,
5281                       migrate_data)
5282 
5283     @wrap_exception()
5284     @wrap_instance_fault
5285     def live_migration_force_complete(self, context, instance, migration_id):
5286         """Force live migration to complete.
5287 
5288         :param context: Security context
5289         :param instance: The instance that is being migrated
5290         :param migration_id: ID of ongoing migration
5291 
5292         """
5293         migration = objects.Migration.get_by_id(context, migration_id)
5294         if migration.status != 'running':
5295             raise exception.InvalidMigrationState(migration_id=migration_id,
5296                                                   instance_uuid=instance.uuid,
5297                                                   state=migration.status,
5298                                                   method='force complete')
5299 
5300         self._notify_about_instance_usage(
5301             context, instance, 'live.migration.force.complete.start')
5302         self.driver.live_migration_force_complete(instance)
5303         self._notify_about_instance_usage(
5304             context, instance, 'live.migration.force.complete.end')
5305 
5306     @wrap_exception()
5307     @wrap_instance_event
5308     @wrap_instance_fault
5309     def live_migration_abort(self, context, instance, migration_id):
5310         """Abort an in-progress live migration.
5311 
5312         :param context: Security context
5313         :param instance: The instance that is being migrated
5314         :param migration_id: ID of in-progress live migration
5315 
5316         """
5317         migration = objects.Migration.get_by_id(context, migration_id)
5318         if migration.status != 'running':
5319             raise exception.InvalidMigrationState(migration_id=migration_id,
5320                     instance_uuid=instance.uuid,
5321                     state=migration.status,
5322                     method='abort live migration')
5323 
5324         self._notify_about_instance_usage(
5325             context, instance, 'live.migration.abort.start')
5326         self.driver.live_migration_abort(instance)
5327         self._notify_about_instance_usage(
5328             context, instance, 'live.migration.abort.end')
5329 
5330     def _live_migration_cleanup_flags(self, block_migration, migrate_data):
5331         """Determine whether disks or instance path need to be cleaned up after
5332         live migration (at source on success, at destination on rollback)
5333 
5334         Block migration needs empty image at destination host before migration
5335         starts, so if any failure occurs, any empty images has to be deleted.
5336 
5337         Also Volume backed live migration w/o shared storage needs to delete
5338         newly created instance-xxx dir on the destination as a part of its
5339         rollback process
5340 
5341         :param block_migration: if true, it was a block migration
5342         :param migrate_data: implementation specific data
5343         :returns: (bool, bool) -- do_cleanup, destroy_disks
5344         """
5345         # NOTE(angdraug): block migration wouldn't have been allowed if either
5346         #                 block storage or instance path were shared
5347         is_shared_block_storage = not block_migration
5348         is_shared_instance_path = not block_migration
5349         if isinstance(migrate_data, migrate_data_obj.LibvirtLiveMigrateData):
5350             is_shared_block_storage = migrate_data.is_shared_block_storage
5351             is_shared_instance_path = migrate_data.is_shared_instance_path
5352 
5353         # No instance booting at source host, but instance dir
5354         # must be deleted for preparing next block migration
5355         # must be deleted for preparing next live migration w/o shared storage
5356         do_cleanup = block_migration or not is_shared_instance_path
5357         destroy_disks = not is_shared_block_storage
5358 
5359         return (do_cleanup, destroy_disks)
5360 
5361     @wrap_exception()
5362     @wrap_instance_fault
5363     def _post_live_migration(self, ctxt, instance,
5364                             dest, block_migration=False, migrate_data=None):
5365         """Post operations for live migration.
5366 
5367         This method is called from live_migration
5368         and mainly updating database record.
5369 
5370         :param ctxt: security context
5371         :param instance: instance dict
5372         :param dest: destination host
5373         :param block_migration: if true, prepare for block migration
5374         :param migrate_data: if not None, it is a dict which has data
5375         required for live migration without shared storage
5376 
5377         """
5378         LOG.info(_LI('_post_live_migration() is started..'),
5379                  instance=instance)
5380 
5381         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5382                 ctxt, instance.uuid)
5383 
5384         # Cleanup source host post live-migration
5385         block_device_info = self._get_instance_block_device_info(
5386                             ctxt, instance, bdms=bdms)
5387         self.driver.post_live_migration(ctxt, instance, block_device_info,
5388                                         migrate_data)
5389 
5390         # Detaching volumes.
5391         connector = self.driver.get_volume_connector(instance)
5392         for bdm in bdms:
5393             # NOTE(vish): We don't want to actually mark the volume
5394             #             detached, or delete the bdm, just remove the
5395             #             connection from this host.
5396 
5397             # remove the volume connection without detaching from hypervisor
5398             # because the instance is not running anymore on the current host
5399             if bdm.is_volume:
5400                 self.volume_api.terminate_connection(ctxt, bdm.volume_id,
5401                                                      connector)
5402 
5403         # Releasing vlan.
5404         # (not necessary in current implementation?)
5405 
5406         network_info = self.network_api.get_instance_nw_info(ctxt, instance)
5407 
5408         self._notify_about_instance_usage(ctxt, instance,
5409                                           "live_migration._post.start",
5410                                           network_info=network_info)
5411         # Releasing security group ingress rule.
5412         LOG.debug('Calling driver.unfilter_instance from _post_live_migration',
5413                   instance=instance)
5414         self.driver.unfilter_instance(instance,
5415                                       network_info)
5416 
5417         migration = {'source_compute': self.host,
5418                      'dest_compute': dest, }
5419         self.network_api.migrate_instance_start(ctxt,
5420                                                 instance,
5421                                                 migration)
5422 
5423         destroy_vifs = False
5424         try:
5425             self.driver.post_live_migration_at_source(ctxt, instance,
5426                                                       network_info)
5427         except NotImplementedError as ex:
5428             LOG.debug(ex, instance=instance)
5429             # For all hypervisors other than libvirt, there is a possibility
5430             # they are unplugging networks from source node in the cleanup
5431             # method
5432             destroy_vifs = True
5433 
5434         # Define domain at destination host, without doing it,
5435         # pause/suspend/terminate do not work.
5436         self.compute_rpcapi.post_live_migration_at_destination(ctxt,
5437                 instance, block_migration, dest)
5438 
5439         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5440                 block_migration, migrate_data)
5441 
5442         if do_cleanup:
5443             LOG.debug('Calling driver.cleanup from _post_live_migration',
5444                       instance=instance)
5445             self.driver.cleanup(ctxt, instance, network_info,
5446                                 destroy_disks=destroy_disks,
5447                                 migrate_data=migrate_data,
5448                                 destroy_vifs=destroy_vifs)
5449 
5450         self.instance_events.clear_events_for_instance(instance)
5451 
5452         # NOTE(timello): make sure we update available resources on source
5453         # host even before next periodic task.
5454         self.update_available_resource(ctxt)
5455 
5456         self._update_scheduler_instance_info(ctxt, instance)
5457         self._notify_about_instance_usage(ctxt, instance,
5458                                           "live_migration._post.end",
5459                                           network_info=network_info)
5460         LOG.info(_LI('Migrating instance to %s finished successfully.'),
5461                  dest, instance=instance)
5462         LOG.info(_LI("You may see the error \"libvirt: QEMU error: "
5463                      "Domain not found: no domain with matching name.\" "
5464                      "This error can be safely ignored."),
5465                  instance=instance)
5466 
5467         self._clean_instance_console_tokens(ctxt, instance)
5468         if migrate_data and migrate_data.obj_attr_is_set('migration'):
5469             migrate_data.migration.status = 'completed'
5470             migrate_data.migration.save()
5471 
5472     def _consoles_enabled(self):
5473         """Returns whether a console is enable."""
5474         return (CONF.vnc.enabled or CONF.spice.enabled or
5475                 CONF.rdp.enabled or CONF.serial_console.enabled or
5476                 CONF.mks.enabled)
5477 
5478     def _clean_instance_console_tokens(self, ctxt, instance):
5479         """Clean console tokens stored for an instance."""
5480         if self._consoles_enabled():
5481             if CONF.cells.enable:
5482                 self.cells_rpcapi.consoleauth_delete_tokens(
5483                     ctxt, instance.uuid)
5484             else:
5485                 self.consoleauth_rpcapi.delete_tokens_for_instance(
5486                     ctxt, instance.uuid)
5487 
5488     @wrap_exception()
5489     @wrap_instance_event
5490     @wrap_instance_fault
5491     def post_live_migration_at_destination(self, context, instance,
5492                                            block_migration):
5493         """Post operations for live migration .
5494 
5495         :param context: security context
5496         :param instance: Instance dict
5497         :param block_migration: if true, prepare for block migration
5498 
5499         """
5500         LOG.info(_LI('Post operation of migration started'),
5501                  instance=instance)
5502 
5503         # NOTE(tr3buchet): setup networks on destination host
5504         #                  this is called a second time because
5505         #                  multi_host does not create the bridge in
5506         #                  plug_vifs
5507         self.network_api.setup_networks_on_host(context, instance,
5508                                                          self.host)
5509         # TODO(ndipanov): We should be passing the migration over RPC here
5510         # instead
5511         try:
5512             migration = objects.Migration.get_by_instance_and_status(
5513                 context, instance.uuid, 'running')
5514         except exception.MigrationNotFoundByStatus:
5515             LOG.warn(_LW("No migration record found for this instance during "
5516                          "post_live_migrate routine"), instance=instance)
5517             migration = None
5518         self.network_api.migrate_instance_finish(
5519             context, instance,
5520             {'source_compute': instance.host, 'dest_compute': self.host, })
5521 
5522         network_info = self.network_api.get_instance_nw_info(context, instance)
5523         self._notify_about_instance_usage(
5524                      context, instance, "live_migration.post.dest.start",
5525                      network_info=network_info)
5526         block_device_info = self._get_instance_block_device_info(context,
5527                                                                  instance)
5528 
5529         try:
5530             with instance.mutated_migration_context():
5531                 self.driver.post_live_migration_at_destination(
5532                     context, instance, network_info, block_migration,
5533                     block_device_info)
5534         except Exception:
5535             with excutils.save_and_reraise_exception():
5536                 instance.vm_state = vm_states.ERROR
5537                 self._set_migration_status(migration, 'failed')
5538                 LOG.error(_LE('Unexpected error during post live migration at '
5539                                'destination host.'), instance=instance)
5540         finally:
5541             # Restore instance state and update host
5542             current_power_state = self._get_power_state(context, instance)
5543             node_name = None
5544             prev_host = instance.host
5545             try:
5546                 compute_node = self._get_compute_info(context, self.host)
5547                 node_name = compute_node.hypervisor_hostname
5548             except exception.ComputeHostNotFound:
5549                 LOG.exception(_LE('Failed to get compute_info for %s'),
5550                               self.host)
5551             finally:
5552                 instance.apply_migration_context()
5553                 instance.host = self.host
5554                 instance.power_state = current_power_state
5555                 instance.task_state = None
5556                 instance.node = node_name
5557                 instance.save(expected_task_state=task_states.MIGRATING)
5558                 instance.drop_migration_context()
5559                 self._set_migration_status(migration, 'finished',
5560                                            unless_status='failed')
5561 
5562         # NOTE(tr3buchet): tear down networks on source host
5563         self.network_api.setup_networks_on_host(context, instance,
5564                                                 prev_host, teardown=True)
5565         # NOTE(vish): this is necessary to update dhcp
5566         self.network_api.setup_networks_on_host(context, instance, self.host)
5567         self._notify_about_instance_usage(
5568                      context, instance, "live_migration.post.dest.end",
5569                      network_info=network_info)
5570 
5571     @wrap_exception()
5572     @wrap_instance_fault
5573     def _rollback_live_migration(self, context, instance,
5574                                  dest, block_migration, migrate_data=None,
5575                                  migration_status='error'):
5576         """Recovers Instance/volume state from migrating -> running.
5577 
5578         :param context: security context
5579         :param instance: nova.objects.instance.Instance object
5580         :param dest:
5581             This method is called from live migration src host.
5582             This param specifies destination host.
5583         :param block_migration: if true, prepare for block migration
5584         :param migrate_data:
5585             if not none, contains implementation specific data.
5586         :param migration_status:
5587             Contains the status we want to set for the migration object
5588 
5589         """
5590         instance.task_state = None
5591         instance.save(expected_task_state=[task_states.MIGRATING])
5592 
5593         if isinstance(migrate_data, dict):
5594             migration = migrate_data.pop('migration', None)
5595             migrate_data = \
5596                 migrate_data_obj.LiveMigrateData.detect_implementation(
5597                     migrate_data)
5598         elif (isinstance(migrate_data, migrate_data_obj.LiveMigrateData) and
5599               migrate_data.obj_attr_is_set('migration')):
5600             migration = migrate_data.migration
5601         else:
5602             migration = None
5603 
5604         # NOTE(tr3buchet): setup networks on source host (really it's re-setup)
5605         self.network_api.setup_networks_on_host(context, instance, self.host)
5606 
5607         bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
5608                 context, instance.uuid)
5609         for bdm in bdms:
5610             if bdm.is_volume:
5611                 self.compute_rpcapi.remove_volume_connection(
5612                         context, bdm.volume_id, instance, dest)
5613 
5614         self._notify_about_instance_usage(context, instance,
5615                                           "live_migration._rollback.start")
5616 
5617         do_cleanup, destroy_disks = self._live_migration_cleanup_flags(
5618                 block_migration, migrate_data)
5619 
5620         if do_cleanup:
5621             self.compute_rpcapi.rollback_live_migration_at_destination(
5622                     context, instance, dest, destroy_disks=destroy_disks,
5623                     migrate_data=migrate_data)
5624 
5625         self._notify_about_instance_usage(context, instance,
5626                                           "live_migration._rollback.end")
5627 
5628         self._set_migration_status(migration, migration_status)
5629 
5630     @wrap_exception()
5631     @wrap_instance_event
5632     @wrap_instance_fault
5633     def rollback_live_migration_at_destination(self, context, instance,
5634                                                destroy_disks,
5635                                                migrate_data):
5636         """Cleaning up image directory that is created pre_live_migration.
5637 
5638         :param context: security context
5639         :param instance: a nova.objects.instance.Instance object sent over rpc
5640         """
5641         network_info = self.network_api.get_instance_nw_info(context, instance)
5642         self._notify_about_instance_usage(
5643                       context, instance, "live_migration.rollback.dest.start",
5644                       network_info=network_info)
5645         try:
5646             # NOTE(tr3buchet): tear down networks on destination host
5647             self.network_api.setup_networks_on_host(context, instance,
5648                                                     self.host, teardown=True)
5649         except Exception:
5650             with excutils.save_and_reraise_exception():
5651                 # NOTE(tdurakov): even if teardown networks fails driver
5652                 # should try to rollback live migration on destination.
5653                 LOG.exception(
5654                     _LE('An error occurred while deallocating network.'),
5655                     instance=instance)
5656         finally:
5657             # always run this even if setup_networks_on_host fails
5658             # NOTE(vish): The mapping is passed in so the driver can disconnect
5659             #             from remote volumes if necessary
5660             block_device_info = self._get_instance_block_device_info(context,
5661                                                                      instance)
5662             if isinstance(migrate_data, dict):
5663                 migrate_data = \
5664                     migrate_data_obj.LiveMigrateData.detect_implementation(
5665                         migrate_data)
5666             with instance.mutated_migration_context():
5667                 self.driver.rollback_live_migration_at_destination(
5668                     context, instance, network_info, block_device_info,
5669                     destroy_disks=destroy_disks, migrate_data=migrate_data)
5670             # TODO(ndipanov): We should drop the claim here too, as we are
5671             # currently "leaking" resources, but only until the next run of the
5672             # update_available_resource periodic task, since we error the
5673             # migration. For that, we need to be passing migration objects over
5674             # RPC
5675             instance.drop_migration_context()
5676 
5677         self._notify_about_instance_usage(
5678                         context, instance, "live_migration.rollback.dest.end",
5679                         network_info=network_info)
5680 
5681     @periodic_task.periodic_task(
5682         spacing=CONF.heal_instance_info_cache_interval)
5683     def _heal_instance_info_cache(self, context):
5684         """Called periodically.  On every call, try to update the
5685         info_cache's network information for another instance by
5686         calling to the network manager.
5687 
5688         This is implemented by keeping a cache of uuids of instances
5689         that live on this host.  On each call, we pop one off of a
5690         list, pull the DB record, and try the call to the network API.
5691         If anything errors don't fail, as it's possible the instance
5692         has been deleted, etc.
5693         """
5694         heal_interval = CONF.heal_instance_info_cache_interval
5695         if not heal_interval:
5696             return
5697 
5698         instance_uuids = getattr(self, '_instance_uuids_to_heal', [])
5699         instance = None
5700 
5701         LOG.debug('Starting heal instance info cache')
5702 
5703         if not instance_uuids:
5704             # The list of instances to heal is empty so rebuild it
5705             LOG.debug('Rebuilding the list of instances to heal')
5706             db_instances = objects.InstanceList.get_by_host(
5707                 context, self.host, expected_attrs=[], use_slave=True)
5708             for inst in db_instances:
5709                 # We don't want to refresh the cache for instances
5710                 # which are building or deleting so don't put them
5711                 # in the list. If they are building they will get
5712                 # added to the list next time we build it.
5713                 if (inst.vm_state == vm_states.BUILDING):
5714                     LOG.debug('Skipping network cache update for instance '
5715                               'because it is Building.', instance=inst)
5716                     continue
5717                 if (inst.task_state == task_states.DELETING):
5718                     LOG.debug('Skipping network cache update for instance '
5719                               'because it is being deleted.', instance=inst)
5720                     continue
5721 
5722                 if not instance:
5723                     # Save the first one we find so we don't
5724                     # have to get it again
5725                     instance = inst
5726                 else:
5727                     instance_uuids.append(inst['uuid'])
5728 
5729             self._instance_uuids_to_heal = instance_uuids
5730         else:
5731             # Find the next valid instance on the list
5732             while instance_uuids:
5733                 try:
5734                     inst = objects.Instance.get_by_uuid(
5735                             context, instance_uuids.pop(0),
5736                             expected_attrs=['system_metadata', 'info_cache',
5737                                             'flavor'],
5738                             use_slave=True)
5739                 except exception.InstanceNotFound:
5740                     # Instance is gone.  Try to grab another.
5741                     continue
5742 
5743                 # Check the instance hasn't been migrated
5744                 if inst.host != self.host:
5745                     LOG.debug('Skipping network cache update for instance '
5746                               'because it has been migrated to another '
5747                               'host.', instance=inst)
5748                 # Check the instance isn't being deleting
5749                 elif inst.task_state == task_states.DELETING:
5750                     LOG.debug('Skipping network cache update for instance '
5751                               'because it is being deleted.', instance=inst)
5752                 else:
5753                     instance = inst
5754                     break
5755 
5756         if instance:
5757             # We have an instance now to refresh
5758             try:
5759                 # Call to network API to get instance info.. this will
5760                 # force an update to the instance's info_cache
5761                 self.network_api.get_instance_nw_info(context, instance)
5762                 LOG.debug('Updated the network info_cache for instance',
5763                           instance=instance)
5764             except exception.InstanceNotFound:
5765                 # Instance is gone.
5766                 LOG.debug('Instance no longer exists. Unable to refresh',
5767                           instance=instance)
5768                 return
5769             except exception.InstanceInfoCacheNotFound:
5770                 # InstanceInfoCache is gone.
5771                 LOG.debug('InstanceInfoCache no longer exists. '
5772                           'Unable to refresh', instance=instance)
5773             except Exception:
5774                 LOG.error(_LE('An error occurred while refreshing the network '
5775                               'cache.'), instance=instance, exc_info=True)
5776         else:
5777             LOG.debug("Didn't find any instances for network info cache "
5778                       "update.")
5779 
5780     @periodic_task.periodic_task
5781     def _poll_rebooting_instances(self, context):
5782         if CONF.reboot_timeout > 0:
5783             filters = {'task_state':
5784                        [task_states.REBOOTING,
5785                         task_states.REBOOT_STARTED,
5786                         task_states.REBOOT_PENDING],
5787                        'host': self.host}
5788             rebooting = objects.InstanceList.get_by_filters(
5789                 context, filters, expected_attrs=[], use_slave=True)
5790 
5791             to_poll = []
5792             for instance in rebooting:
5793                 if timeutils.is_older_than(instance.updated_at,
5794                                            CONF.reboot_timeout):
5795                     to_poll.append(instance)
5796 
5797             self.driver.poll_rebooting_instances(CONF.reboot_timeout, to_poll)
5798 
5799     @periodic_task.periodic_task
5800     def _poll_rescued_instances(self, context):
5801         if CONF.rescue_timeout > 0:
5802             filters = {'vm_state': vm_states.RESCUED,
5803                        'host': self.host}
5804             rescued_instances = objects.InstanceList.get_by_filters(
5805                 context, filters, expected_attrs=["system_metadata"],
5806                 use_slave=True)
5807 
5808             to_unrescue = []
5809             for instance in rescued_instances:
5810                 if timeutils.is_older_than(instance.launched_at,
5811                                            CONF.rescue_timeout):
5812                     to_unrescue.append(instance)
5813 
5814             for instance in to_unrescue:
5815                 self.compute_api.unrescue(context, instance)
5816 
5817     @periodic_task.periodic_task
5818     def _poll_unconfirmed_resizes(self, context):
5819         if CONF.resize_confirm_window == 0:
5820             return
5821 
5822         migrations = objects.MigrationList.get_unconfirmed_by_dest_compute(
5823                 context, CONF.resize_confirm_window, self.host,
5824                 use_slave=True)
5825 
5826         migrations_info = dict(migration_count=len(migrations),
5827                 confirm_window=CONF.resize_confirm_window)
5828 
5829         if migrations_info["migration_count"] > 0:
5830             LOG.info(_LI("Found %(migration_count)d unconfirmed migrations "
5831                          "older than %(confirm_window)d seconds"),
5832                      migrations_info)
5833 
5834         def _set_migration_to_error(migration, reason, **kwargs):
5835             LOG.warning(_LW("Setting migration %(migration_id)s to error: "
5836                          "%(reason)s"),
5837                      {'migration_id': migration['id'], 'reason': reason},
5838                      **kwargs)
5839             migration.status = 'error'
5840             with migration.obj_as_admin():
5841                 migration.save()
5842 
5843         for migration in migrations:
5844             instance_uuid = migration.instance_uuid
5845             LOG.info(_LI("Automatically confirming migration "
5846                          "%(migration_id)s for instance %(instance_uuid)s"),
5847                      {'migration_id': migration.id,
5848                       'instance_uuid': instance_uuid})
5849             expected_attrs = ['metadata', 'system_metadata']
5850             try:
5851                 instance = objects.Instance.get_by_uuid(context,
5852                             instance_uuid, expected_attrs=expected_attrs,
5853                             use_slave=True)
5854             except exception.InstanceNotFound:
5855                 reason = (_("Instance %s not found") %
5856                           instance_uuid)
5857                 _set_migration_to_error(migration, reason)
5858                 continue
5859             if instance.vm_state == vm_states.ERROR:
5860                 reason = _("In ERROR state")
5861                 _set_migration_to_error(migration, reason,
5862                                         instance=instance)
5863                 continue
5864             # race condition: The instance in DELETING state should not be
5865             # set the migration state to error, otherwise the instance in
5866             # to be deleted which is in RESIZED state
5867             # will not be able to confirm resize
5868             if instance.task_state in [task_states.DELETING,
5869                                        task_states.SOFT_DELETING]:
5870                 msg = ("Instance being deleted or soft deleted during resize "
5871                        "confirmation. Skipping.")
5872                 LOG.debug(msg, instance=instance)
5873                 continue
5874 
5875             # race condition: This condition is hit when this method is
5876             # called between the save of the migration record with a status of
5877             # finished and the save of the instance object with a state of
5878             # RESIZED. The migration record should not be set to error.
5879             if instance.task_state == task_states.RESIZE_FINISH:
5880                 msg = ("Instance still resizing during resize "
5881                        "confirmation. Skipping.")
5882                 LOG.debug(msg, instance=instance)
5883                 continue
5884 
5885             vm_state = instance.vm_state
5886             task_state = instance.task_state
5887             if vm_state != vm_states.RESIZED or task_state is not None:
5888                 reason = (_("In states %(vm_state)s/%(task_state)s, not "
5889                            "RESIZED/None") %
5890                           {'vm_state': vm_state,
5891                            'task_state': task_state})
5892                 _set_migration_to_error(migration, reason,
5893                                         instance=instance)
5894                 continue
5895             try:
5896                 self.compute_api.confirm_resize(context, instance,
5897                                                 migration=migration)
5898             except Exception as e:
5899                 LOG.info(_LI("Error auto-confirming resize: %s. "
5900                              "Will retry later."),
5901                          e, instance=instance)
5902 
5903     @periodic_task.periodic_task(spacing=CONF.shelved_poll_interval)
5904     def _poll_shelved_instances(self, context):
5905 
5906         if CONF.shelved_offload_time <= 0:
5907             return
5908 
5909         filters = {'vm_state': vm_states.SHELVED,
5910                    'task_state': None,
5911                    'host': self.host}
5912         shelved_instances = objects.InstanceList.get_by_filters(
5913             context, filters=filters, expected_attrs=['system_metadata'],
5914             use_slave=True)
5915 
5916         to_gc = []
5917         for instance in shelved_instances:
5918             sys_meta = instance.system_metadata
5919             shelved_at = timeutils.parse_strtime(sys_meta['shelved_at'])
5920             if timeutils.is_older_than(shelved_at, CONF.shelved_offload_time):
5921                 to_gc.append(instance)
5922 
5923         for instance in to_gc:
5924             try:
5925                 instance.task_state = task_states.SHELVING_OFFLOADING
5926                 instance.save(expected_task_state=(None,))
5927                 self.shelve_offload_instance(context, instance,
5928                                              clean_shutdown=False)
5929             except Exception:
5930                 LOG.exception(_LE('Periodic task failed to offload instance.'),
5931                         instance=instance)
5932 
5933     @periodic_task.periodic_task
5934     def _instance_usage_audit(self, context):
5935         if not CONF.instance_usage_audit:
5936             return
5937 
5938         begin, end = utils.last_completed_audit_period()
5939         if objects.TaskLog.get(context, 'instance_usage_audit', begin, end,
5940                                self.host):
5941             return
5942 
5943         instances = objects.InstanceList.get_active_by_window_joined(
5944             context, begin, end, host=self.host,
5945             expected_attrs=['system_metadata', 'info_cache', 'metadata',
5946                             'flavor'],
5947             use_slave=True)
5948         num_instances = len(instances)
5949         errors = 0
5950         successes = 0
5951         LOG.info(_LI("Running instance usage audit for"
5952                      " host %(host)s from %(begin_time)s to "
5953                      "%(end_time)s. %(number_instances)s"
5954                      " instances."),
5955                  {'host': self.host,
5956                   'begin_time': begin,
5957                   'end_time': end,
5958                   'number_instances': num_instances})
5959         start_time = time.time()
5960         task_log = objects.TaskLog(context)
5961         task_log.task_name = 'instance_usage_audit'
5962         task_log.period_beginning = begin
5963         task_log.period_ending = end
5964         task_log.host = self.host
5965         task_log.task_items = num_instances
5966         task_log.message = 'Instance usage audit started...'
5967         task_log.begin_task()
5968         for instance in instances:
5969             try:
5970                 compute_utils.notify_usage_exists(
5971                     self.notifier, context, instance,
5972                     ignore_missing_network_data=False)
5973                 successes += 1
5974             except Exception:
5975                 LOG.exception(_LE('Failed to generate usage '
5976                                   'audit for instance '
5977                                   'on host %s'), self.host,
5978                               instance=instance)
5979                 errors += 1
5980         task_log.errors = errors
5981         task_log.message = (
5982             'Instance usage audit ran for host %s, %s instances in %s seconds.'
5983             % (self.host, num_instances, time.time() - start_time))
5984         task_log.end_task()
5985 
5986     @periodic_task.periodic_task(spacing=CONF.bandwidth_poll_interval)
5987     def _poll_bandwidth_usage(self, context):
5988 
5989         if not self._bw_usage_supported:
5990             return
5991 
5992         prev_time, start_time = utils.last_completed_audit_period()
5993 
5994         curr_time = time.time()
5995         if (curr_time - self._last_bw_usage_poll >
5996                 CONF.bandwidth_poll_interval):
5997             self._last_bw_usage_poll = curr_time
5998             LOG.info(_LI("Updating bandwidth usage cache"))
5999             cells_update_interval = CONF.cells.bandwidth_update_interval
6000             if (cells_update_interval > 0 and
6001                    curr_time - self._last_bw_usage_cell_update >
6002                            cells_update_interval):
6003                 self._last_bw_usage_cell_update = curr_time
6004                 update_cells = True
6005             else:
6006                 update_cells = False
6007 
6008             instances = objects.InstanceList.get_by_host(context,
6009                                                               self.host,
6010                                                               use_slave=True)
6011             try:
6012                 bw_counters = self.driver.get_all_bw_counters(instances)
6013             except NotImplementedError:
6014                 # NOTE(mdragon): Not all hypervisors have bandwidth polling
6015                 # implemented yet.  If they don't it doesn't break anything,
6016                 # they just don't get the info in the usage events.
6017                 # NOTE(PhilDay): Record that its not supported so we can
6018                 # skip fast on future calls rather than waste effort getting
6019                 # the list of instances.
6020                 LOG.info(_LI("Bandwidth usage not supported by "
6021                              "hypervisor."))
6022                 self._bw_usage_supported = False
6023                 return
6024 
6025             refreshed = timeutils.utcnow()
6026             for bw_ctr in bw_counters:
6027                 # Allow switching of greenthreads between queries.
6028                 greenthread.sleep(0)
6029                 bw_in = 0
6030                 bw_out = 0
6031                 last_ctr_in = None
6032                 last_ctr_out = None
6033                 usage = objects.BandwidthUsage.get_by_instance_uuid_and_mac(
6034                     context, bw_ctr['uuid'], bw_ctr['mac_address'],
6035                     start_period=start_time, use_slave=True)
6036                 if usage:
6037                     bw_in = usage.bw_in
6038                     bw_out = usage.bw_out
6039                     last_ctr_in = usage.last_ctr_in
6040                     last_ctr_out = usage.last_ctr_out
6041                 else:
6042                     usage = (objects.BandwidthUsage.
6043                              get_by_instance_uuid_and_mac(
6044                         context, bw_ctr['uuid'], bw_ctr['mac_address'],
6045                         start_period=prev_time, use_slave=True))
6046                     if usage:
6047                         last_ctr_in = usage.last_ctr_in
6048                         last_ctr_out = usage.last_ctr_out
6049 
6050                 if last_ctr_in is not None:
6051                     if bw_ctr['bw_in'] < last_ctr_in:
6052                         # counter rollover
6053                         bw_in += bw_ctr['bw_in']
6054                     else:
6055                         bw_in += (bw_ctr['bw_in'] - last_ctr_in)
6056 
6057                 if last_ctr_out is not None:
6058                     if bw_ctr['bw_out'] < last_ctr_out:
6059                         # counter rollover
6060                         bw_out += bw_ctr['bw_out']
6061                     else:
6062                         bw_out += (bw_ctr['bw_out'] - last_ctr_out)
6063 
6064                 objects.BandwidthUsage(context=context).create(
6065                                               bw_ctr['uuid'],
6066                                               bw_ctr['mac_address'],
6067                                               bw_in,
6068                                               bw_out,
6069                                               bw_ctr['bw_in'],
6070                                               bw_ctr['bw_out'],
6071                                               start_period=start_time,
6072                                               last_refreshed=refreshed,
6073                                               update_cells=update_cells)
6074 
6075     def _get_host_volume_bdms(self, context, use_slave=False):
6076         """Return all block device mappings on a compute host."""
6077         compute_host_bdms = []
6078         instances = objects.InstanceList.get_by_host(context, self.host,
6079             use_slave=use_slave)
6080         for instance in instances:
6081             bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6082                     context, instance.uuid, use_slave=use_slave)
6083             instance_bdms = [bdm for bdm in bdms if bdm.is_volume]
6084             compute_host_bdms.append(dict(instance=instance,
6085                                           instance_bdms=instance_bdms))
6086 
6087         return compute_host_bdms
6088 
6089     def _update_volume_usage_cache(self, context, vol_usages):
6090         """Updates the volume usage cache table with a list of stats."""
6091         for usage in vol_usages:
6092             # Allow switching of greenthreads between queries.
6093             greenthread.sleep(0)
6094             vol_usage = objects.VolumeUsage(context)
6095             vol_usage.volume_id = usage['volume']
6096             vol_usage.instance_uuid = usage['instance'].uuid
6097             vol_usage.project_id = usage['instance'].project_id
6098             vol_usage.user_id = usage['instance'].user_id
6099             vol_usage.availability_zone = usage['instance'].availability_zone
6100             vol_usage.curr_reads = usage['rd_req']
6101             vol_usage.curr_read_bytes = usage['rd_bytes']
6102             vol_usage.curr_writes = usage['wr_req']
6103             vol_usage.curr_write_bytes = usage['wr_bytes']
6104             vol_usage.save()
6105             self.notifier.info(context, 'volume.usage',
6106                                compute_utils.usage_volume_info(vol_usage))
6107 
6108     @periodic_task.periodic_task(spacing=CONF.volume_usage_poll_interval)
6109     def _poll_volume_usage(self, context):
6110         if CONF.volume_usage_poll_interval == 0:
6111             return
6112 
6113         compute_host_bdms = self._get_host_volume_bdms(context,
6114                                                        use_slave=True)
6115         if not compute_host_bdms:
6116             return
6117 
6118         LOG.debug("Updating volume usage cache")
6119         try:
6120             vol_usages = self.driver.get_all_volume_usage(context,
6121                                                           compute_host_bdms)
6122         except NotImplementedError:
6123             return
6124 
6125         self._update_volume_usage_cache(context, vol_usages)
6126 
6127     @periodic_task.periodic_task(spacing=CONF.sync_power_state_interval,
6128                                  run_immediately=True)
6129     def _sync_power_states(self, context):
6130         """Align power states between the database and the hypervisor.
6131 
6132         To sync power state data we make a DB call to get the number of
6133         virtual machines known by the hypervisor and if the number matches the
6134         number of virtual machines known by the database, we proceed in a lazy
6135         loop, one database record at a time, checking if the hypervisor has the
6136         same power state as is in the database.
6137         """
6138         db_instances = objects.InstanceList.get_by_host(context, self.host,
6139                                                         expected_attrs=[],
6140                                                         use_slave=True)
6141 
6142         num_vm_instances = self.driver.get_num_instances()
6143         num_db_instances = len(db_instances)
6144 
6145         if num_vm_instances != num_db_instances:
6146             LOG.warning(_LW("While synchronizing instance power states, found "
6147                             "%(num_db_instances)s instances in the database "
6148                             "and %(num_vm_instances)s instances on the "
6149                             "hypervisor."),
6150                         {'num_db_instances': num_db_instances,
6151                          'num_vm_instances': num_vm_instances})
6152 
6153         def _sync(db_instance):
6154             # NOTE(melwitt): This must be synchronized as we query state from
6155             #                two separate sources, the driver and the database.
6156             #                They are set (in stop_instance) and read, in sync.
6157             @utils.synchronized(db_instance.uuid)
6158             def query_driver_power_state_and_sync():
6159                 self._query_driver_power_state_and_sync(context, db_instance)
6160 
6161             try:
6162                 query_driver_power_state_and_sync()
6163             except Exception:
6164                 LOG.exception(_LE("Periodic sync_power_state task had an "
6165                                   "error while processing an instance."),
6166                               instance=db_instance)
6167 
6168             self._syncs_in_progress.pop(db_instance.uuid)
6169 
6170         for db_instance in db_instances:
6171             # process syncs asynchronously - don't want instance locking to
6172             # block entire periodic task thread
6173             uuid = db_instance.uuid
6174             if uuid in self._syncs_in_progress:
6175                 LOG.debug('Sync already in progress for %s' % uuid)
6176             else:
6177                 LOG.debug('Triggering sync for uuid %s' % uuid)
6178                 self._syncs_in_progress[uuid] = True
6179                 self._sync_power_pool.spawn_n(_sync, db_instance)
6180 
6181     def _query_driver_power_state_and_sync(self, context, db_instance):
6182         if db_instance.task_state is not None:
6183             LOG.info(_LI("During sync_power_state the instance has a "
6184                          "pending task (%(task)s). Skip."),
6185                      {'task': db_instance.task_state}, instance=db_instance)
6186             return
6187         # No pending tasks. Now try to figure out the real vm_power_state.
6188         try:
6189             vm_instance = self.driver.get_info(db_instance)
6190             vm_power_state = vm_instance.state
6191         except exception.InstanceNotFound:
6192             vm_power_state = power_state.NOSTATE
6193         # Note(maoy): the above get_info call might take a long time,
6194         # for example, because of a broken libvirt driver.
6195         try:
6196             self._sync_instance_power_state(context,
6197                                             db_instance,
6198                                             vm_power_state,
6199                                             use_slave=True)
6200         except exception.InstanceNotFound:
6201             # NOTE(hanlind): If the instance gets deleted during sync,
6202             # silently ignore.
6203             pass
6204 
6205     def _sync_instance_power_state(self, context, db_instance, vm_power_state,
6206                                    use_slave=False):
6207         """Align instance power state between the database and hypervisor.
6208 
6209         If the instance is not found on the hypervisor, but is in the database,
6210         then a stop() API will be called on the instance.
6211         """
6212 
6213         # We re-query the DB to get the latest instance info to minimize
6214         # (not eliminate) race condition.
6215         db_instance.refresh(use_slave=use_slave)
6216         db_power_state = db_instance.power_state
6217         vm_state = db_instance.vm_state
6218 
6219         if self.host != db_instance.host:
6220             # on the sending end of nova-compute _sync_power_state
6221             # may have yielded to the greenthread performing a live
6222             # migration; this in turn has changed the resident-host
6223             # for the VM; However, the instance is still active, it
6224             # is just in the process of migrating to another host.
6225             # This implies that the compute source must relinquish
6226             # control to the compute destination.
6227             LOG.info(_LI("During the sync_power process the "
6228                          "instance has moved from "
6229                          "host %(src)s to host %(dst)s"),
6230                      {'src': db_instance.host,
6231                       'dst': self.host},
6232                      instance=db_instance)
6233             return
6234         elif db_instance.task_state is not None:
6235             # on the receiving end of nova-compute, it could happen
6236             # that the DB instance already report the new resident
6237             # but the actual VM has not showed up on the hypervisor
6238             # yet. In this case, let's allow the loop to continue
6239             # and run the state sync in a later round
6240             LOG.info(_LI("During sync_power_state the instance has a "
6241                          "pending task (%(task)s). Skip."),
6242                      {'task': db_instance.task_state},
6243                      instance=db_instance)
6244             return
6245 
6246         orig_db_power_state = db_power_state
6247         if vm_power_state != db_power_state:
6248             LOG.info(_LI('During _sync_instance_power_state the DB '
6249                          'power_state (%(db_power_state)s) does not match '
6250                          'the vm_power_state from the hypervisor '
6251                          '(%(vm_power_state)s). Updating power_state in the '
6252                          'DB to match the hypervisor.'),
6253                      {'db_power_state': db_power_state,
6254                       'vm_power_state': vm_power_state},
6255                      instance=db_instance)
6256             # power_state is always updated from hypervisor to db
6257             db_instance.power_state = vm_power_state
6258             db_instance.save()
6259             db_power_state = vm_power_state
6260 
6261         # Note(maoy): Now resolve the discrepancy between vm_state and
6262         # vm_power_state. We go through all possible vm_states.
6263         if vm_state in (vm_states.BUILDING,
6264                         vm_states.RESCUED,
6265                         vm_states.RESIZED,
6266                         vm_states.SUSPENDED,
6267                         vm_states.ERROR):
6268             # TODO(maoy): we ignore these vm_state for now.
6269             pass
6270         elif vm_state == vm_states.ACTIVE:
6271             # The only rational power state should be RUNNING
6272             if vm_power_state in (power_state.SHUTDOWN,
6273                                   power_state.CRASHED):
6274                 LOG.warning(_LW("Instance shutdown by itself. Calling the "
6275                                 "stop API. Current vm_state: %(vm_state)s, "
6276                                 "current task_state: %(task_state)s, "
6277                                 "original DB power_state: %(db_power_state)s, "
6278                                 "current VM power_state: %(vm_power_state)s"),
6279                             {'vm_state': vm_state,
6280                              'task_state': db_instance.task_state,
6281                              'db_power_state': orig_db_power_state,
6282                              'vm_power_state': vm_power_state},
6283                             instance=db_instance)
6284                 try:
6285                     # Note(maoy): here we call the API instead of
6286                     # brutally updating the vm_state in the database
6287                     # to allow all the hooks and checks to be performed.
6288                     if db_instance.shutdown_terminate:
6289                         self.compute_api.delete(context, db_instance)
6290                     else:
6291                         self.compute_api.stop(context, db_instance)
6292                 except Exception:
6293                     # Note(maoy): there is no need to propagate the error
6294                     # because the same power_state will be retrieved next
6295                     # time and retried.
6296                     # For example, there might be another task scheduled.
6297                     LOG.exception(_LE("error during stop() in "
6298                                       "sync_power_state."),
6299                                   instance=db_instance)
6300             elif vm_power_state == power_state.SUSPENDED:
6301                 LOG.warning(_LW("Instance is suspended unexpectedly. Calling "
6302                                 "the stop API."), instance=db_instance)
6303                 try:
6304                     self.compute_api.stop(context, db_instance)
6305                 except Exception:
6306                     LOG.exception(_LE("error during stop() in "
6307                                       "sync_power_state."),
6308                                   instance=db_instance)
6309             elif vm_power_state == power_state.PAUSED:
6310                 # Note(maoy): a VM may get into the paused state not only
6311                 # because the user request via API calls, but also
6312                 # due to (temporary) external instrumentations.
6313                 # Before the virt layer can reliably report the reason,
6314                 # we simply ignore the state discrepancy. In many cases,
6315                 # the VM state will go back to running after the external
6316                 # instrumentation is done. See bug 1097806 for details.
6317                 LOG.warning(_LW("Instance is paused unexpectedly. Ignore."),
6318                             instance=db_instance)
6319             elif vm_power_state == power_state.NOSTATE:
6320                 # Occasionally, depending on the status of the hypervisor,
6321                 # which could be restarting for example, an instance may
6322                 # not be found.  Therefore just log the condition.
6323                 LOG.warning(_LW("Instance is unexpectedly not found. Ignore."),
6324                             instance=db_instance)
6325         elif vm_state == vm_states.STOPPED:
6326             if vm_power_state not in (power_state.NOSTATE,
6327                                       power_state.SHUTDOWN,
6328                                       power_state.CRASHED):
6329                 LOG.warning(_LW("Instance is not stopped. Calling "
6330                                 "the stop API. Current vm_state: %(vm_state)s,"
6331                                 " current task_state: %(task_state)s, "
6332                                 "original DB power_state: %(db_power_state)s, "
6333                                 "current VM power_state: %(vm_power_state)s"),
6334                             {'vm_state': vm_state,
6335                              'task_state': db_instance.task_state,
6336                              'db_power_state': orig_db_power_state,
6337                              'vm_power_state': vm_power_state},
6338                             instance=db_instance)
6339                 try:
6340                     # NOTE(russellb) Force the stop, because normally the
6341                     # compute API would not allow an attempt to stop a stopped
6342                     # instance.
6343                     self.compute_api.force_stop(context, db_instance)
6344                 except Exception:
6345                     LOG.exception(_LE("error during stop() in "
6346                                       "sync_power_state."),
6347                                   instance=db_instance)
6348         elif vm_state == vm_states.PAUSED:
6349             if vm_power_state in (power_state.SHUTDOWN,
6350                                   power_state.CRASHED):
6351                 LOG.warning(_LW("Paused instance shutdown by itself. Calling "
6352                                 "the stop API."), instance=db_instance)
6353                 try:
6354                     self.compute_api.force_stop(context, db_instance)
6355                 except Exception:
6356                     LOG.exception(_LE("error during stop() in "
6357                                       "sync_power_state."),
6358                                   instance=db_instance)
6359         elif vm_state in (vm_states.SOFT_DELETED,
6360                           vm_states.DELETED):
6361             if vm_power_state not in (power_state.NOSTATE,
6362                                       power_state.SHUTDOWN):
6363                 # Note(maoy): this should be taken care of periodically in
6364                 # _cleanup_running_deleted_instances().
6365                 LOG.warning(_LW("Instance is not (soft-)deleted."),
6366                             instance=db_instance)
6367 
6368     @periodic_task.periodic_task
6369     def _reclaim_queued_deletes(self, context):
6370         """Reclaim instances that are queued for deletion."""
6371         interval = CONF.reclaim_instance_interval
6372         if interval <= 0:
6373             LOG.debug("CONF.reclaim_instance_interval <= 0, skipping...")
6374             return
6375 
6376         # TODO(comstud, jichenjc): Dummy quota object for now See bug 1296414.
6377         # The only case that the quota might be inconsistent is
6378         # the compute node died between set instance state to SOFT_DELETED
6379         # and quota commit to DB. When compute node starts again
6380         # it will have no idea the reservation is committed or not or even
6381         # expired, since it's a rare case, so marked as todo.
6382         quotas = objects.Quotas.from_reservations(context, None)
6383 
6384         filters = {'vm_state': vm_states.SOFT_DELETED,
6385                    'task_state': None,
6386                    'host': self.host}
6387         instances = objects.InstanceList.get_by_filters(
6388             context, filters,
6389             expected_attrs=objects.instance.INSTANCE_DEFAULT_FIELDS,
6390             use_slave=True)
6391         for instance in instances:
6392             if self._deleted_old_enough(instance, interval):
6393                 bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6394                         context, instance.uuid)
6395                 LOG.info(_LI('Reclaiming deleted instance'), instance=instance)
6396                 try:
6397                     self._delete_instance(context, instance, bdms, quotas)
6398                 except Exception as e:
6399                     LOG.warning(_LW("Periodic reclaim failed to delete "
6400                                     "instance: %s"),
6401                                 e, instance=instance)
6402 
6403     @periodic_task.periodic_task(spacing=CONF.update_resources_interval)
6404     def update_available_resource(self, context):
6405         """See driver.get_available_resource()
6406 
6407         Periodic process that keeps that the compute host's understanding of
6408         resource availability and usage in sync with the underlying hypervisor.
6409 
6410         :param context: security context
6411         """
6412         new_resource_tracker_dict = {}
6413 
6414         compute_nodes_in_db = self._get_compute_nodes_in_db(context,
6415                                                             use_slave=True)
6416         nodenames = set(self.driver.get_available_nodes())
6417         for nodename in nodenames:
6418             rt = self._get_resource_tracker(nodename)
6419             try:
6420                 rt.update_available_resource(context)
6421             except exception.ComputeHostNotFound:
6422                 # NOTE(comstud): We can get to this case if a node was
6423                 # marked 'deleted' in the DB and then re-added with a
6424                 # different auto-increment id. The cached resource
6425                 # tracker tried to update a deleted record and failed.
6426                 # Don't add this resource tracker to the new dict, so
6427                 # that this will resolve itself on the next run.
6428                 LOG.info(_LI("Compute node '%s' not found in "
6429                              "update_available_resource."), nodename)
6430                 continue
6431             except Exception:
6432                 LOG.exception(_LE("Error updating resources for node "
6433                               "%(node)s."), {'node': nodename})
6434             new_resource_tracker_dict[nodename] = rt
6435 
6436         # NOTE(comstud): Replace the RT cache before looping through
6437         # compute nodes to delete below, as we can end up doing greenthread
6438         # switches there. Best to have everyone using the newest cache
6439         # ASAP.
6440         self._resource_tracker_dict = new_resource_tracker_dict
6441 
6442         # Delete orphan compute node not reported by driver but still in db
6443         for cn in compute_nodes_in_db:
6444             if cn.hypervisor_hostname not in nodenames:
6445                 LOG.info(_LI("Deleting orphan compute node %s") % cn.id)
6446                 cn.destroy()
6447 
6448     def _get_compute_nodes_in_db(self, context, use_slave=False):
6449         try:
6450             return objects.ComputeNodeList.get_all_by_host(context, self.host,
6451                                                            use_slave=use_slave)
6452         except exception.NotFound:
6453             LOG.error(_LE("No compute node record for host %s"), self.host)
6454             return []
6455 
6456     @periodic_task.periodic_task(
6457         spacing=CONF.running_deleted_instance_poll_interval)
6458     def _cleanup_running_deleted_instances(self, context):
6459         """Cleanup any instances which are erroneously still running after
6460         having been deleted.
6461 
6462         Valid actions to take are:
6463 
6464             1. noop - do nothing
6465             2. log - log which instances are erroneously running
6466             3. reap - shutdown and cleanup any erroneously running instances
6467             4. shutdown - power off *and disable* any erroneously running
6468                           instances
6469 
6470         The use-case for this cleanup task is: for various reasons, it may be
6471         possible for the database to show an instance as deleted but for that
6472         instance to still be running on a host machine (see bug
6473         https://bugs.launchpad.net/nova/+bug/911366).
6474 
6475         This cleanup task is a cross-hypervisor utility for finding these
6476         zombied instances and either logging the discrepancy (likely what you
6477         should do in production), or automatically reaping the instances (more
6478         appropriate for dev environments).
6479         """
6480         action = CONF.running_deleted_instance_action
6481 
6482         if action == "noop":
6483             return
6484 
6485         # NOTE(sirp): admin contexts don't ordinarily return deleted records
6486         with utils.temporary_mutation(context, read_deleted="yes"):
6487             for instance in self._running_deleted_instances(context):
6488                 if action == "log":
6489                     LOG.warning(_LW("Detected instance with name label "
6490                                     "'%s' which is marked as "
6491                                     "DELETED but still present on host."),
6492                                 instance.name, instance=instance)
6493 
6494                 elif action == 'shutdown':
6495                     LOG.info(_LI("Powering off instance with name label "
6496                                  "'%s' which is marked as "
6497                                  "DELETED but still present on host."),
6498                              instance.name, instance=instance)
6499                     try:
6500                         try:
6501                             # disable starting the instance
6502                             self.driver.set_bootable(instance, False)
6503                         except NotImplementedError:
6504                             LOG.debug("set_bootable is not implemented "
6505                                       "for the current driver")
6506                         # and power it off
6507                         self.driver.power_off(instance)
6508                     except Exception:
6509                         msg = _LW("Failed to power off instance")
6510                         LOG.warn(msg, instance=instance, exc_info=True)
6511 
6512                 elif action == 'reap':
6513                     LOG.info(_LI("Destroying instance with name label "
6514                                  "'%s' which is marked as "
6515                                  "DELETED but still present on host."),
6516                              instance.name, instance=instance)
6517                     bdms = objects.BlockDeviceMappingList.get_by_instance_uuid(
6518                         context, instance.uuid, use_slave=True)
6519                     self.instance_events.clear_events_for_instance(instance)
6520                     try:
6521                         self._shutdown_instance(context, instance, bdms,
6522                                                 notify=False)
6523                         self._cleanup_volumes(context, instance.uuid, bdms)
6524                     except Exception as e:
6525                         LOG.warning(_LW("Periodic cleanup failed to delete "
6526                                         "instance: %s"),
6527                                     e, instance=instance)
6528                 else:
6529                     raise Exception(_("Unrecognized value '%s'"
6530                                       " for CONF.running_deleted_"
6531                                       "instance_action") % action)
6532 
6533     def _running_deleted_instances(self, context):
6534         """Returns a list of instances nova thinks is deleted,
6535         but the hypervisor thinks is still running.
6536         """
6537         timeout = CONF.running_deleted_instance_timeout
6538         filters = {'deleted': True,
6539                    'soft_deleted': False,
6540                    'host': self.host}
6541         instances = self._get_instances_on_driver(context, filters)
6542         return [i for i in instances if self._deleted_old_enough(i, timeout)]
6543 
6544     def _deleted_old_enough(self, instance, timeout):
6545         deleted_at = instance.deleted_at
6546         if deleted_at:
6547             deleted_at = deleted_at.replace(tzinfo=None)
6548         return (not deleted_at or timeutils.is_older_than(deleted_at, timeout))
6549 
6550     @contextlib.contextmanager
6551     def _error_out_instance_on_exception(self, context, instance,
6552                                          quotas=None,
6553                                          instance_state=vm_states.ACTIVE):
6554         instance_uuid = instance.uuid
6555         try:
6556             yield
6557         except NotImplementedError as error:
6558             with excutils.save_and_reraise_exception():
6559                 if quotas:
6560                     quotas.rollback()
6561                 LOG.info(_LI("Setting instance back to %(state)s after: "
6562                              "%(error)s"),
6563                          {'state': instance_state, 'error': error},
6564                          instance_uuid=instance_uuid)
6565                 self._instance_update(context, instance,
6566                                       vm_state=instance_state,
6567                                       task_state=None)
6568         except exception.InstanceFaultRollback as error:
6569             if quotas:
6570                 quotas.rollback()
6571             LOG.info(_LI("Setting instance back to ACTIVE after: %s"),
6572                      error, instance_uuid=instance_uuid)
6573             self._instance_update(context, instance,
6574                                   vm_state=vm_states.ACTIVE,
6575                                   task_state=None)
6576             raise error.inner_exception
6577         except Exception:
6578             LOG.exception(_LE('Setting instance vm_state to ERROR'),
6579                           instance_uuid=instance_uuid)
6580             with excutils.save_and_reraise_exception():
6581                 if quotas:
6582                     quotas.rollback()
6583                 self._set_instance_obj_error_state(context, instance)
6584 
6585     @wrap_exception()
6586     def add_aggregate_host(self, context, aggregate, host, slave_info):
6587         """Notify hypervisor of change (for hypervisor pools)."""
6588         try:
6589             self.driver.add_to_aggregate(context, aggregate, host,
6590                                          slave_info=slave_info)
6591         except NotImplementedError:
6592             LOG.debug('Hypervisor driver does not support '
6593                       'add_aggregate_host')
6594         except exception.AggregateError:
6595             with excutils.save_and_reraise_exception():
6596                 self.driver.undo_aggregate_operation(
6597                                     context,
6598                                     aggregate.delete_host,
6599                                     aggregate, host)
6600 
6601     @wrap_exception()
6602     def remove_aggregate_host(self, context, host, slave_info, aggregate):
6603         """Removes a host from a physical hypervisor pool."""
6604         try:
6605             self.driver.remove_from_aggregate(context, aggregate, host,
6606                                               slave_info=slave_info)
6607         except NotImplementedError:
6608             LOG.debug('Hypervisor driver does not support '
6609                       'remove_aggregate_host')
6610         except (exception.AggregateError,
6611                 exception.InvalidAggregateAction) as e:
6612             with excutils.save_and_reraise_exception():
6613                 self.driver.undo_aggregate_operation(
6614                                     context,
6615                                     aggregate.add_host,
6616                                     aggregate, host,
6617                                     isinstance(e, exception.AggregateError))
6618 
6619     def _process_instance_event(self, instance, event):
6620         _event = self.instance_events.pop_instance_event(instance, event)
6621         if _event:
6622             LOG.debug('Processing event %(event)s',
6623                       {'event': event.key}, instance=instance)
6624             _event.send(event)
6625 
6626     def _process_instance_vif_deleted_event(self, context, instance,
6627                                             deleted_vif_id):
6628         # If an attached port is deleted by neutron, it needs to
6629         # be detached from the instance.
6630         # And info cache needs to be updated.
6631         network_info = instance.info_cache.network_info
6632         for index, vif in enumerate(network_info):
6633             if vif['id'] == deleted_vif_id:
6634                 LOG.info(_LI('Neutron deleted interface %(intf)s; '
6635                              'detaching it from the instance and '
6636                              'deleting it from the info cache'),
6637                          {'intf': vif['id']},
6638                          instance=instance)
6639                 del network_info[index]
6640                 base_net_api.update_instance_cache_with_nw_info(
6641                                  self.network_api, context,
6642                                  instance,
6643                                  nw_info=network_info)
6644                 try:
6645                     self.driver.detach_interface(instance, vif)
6646                 except exception.NovaException as ex:
6647                     LOG.warning(_LW("Detach interface failed, "
6648                                     "port_id=%(port_id)s, reason: %(msg)s"),
6649                                 {'port_id': deleted_vif_id, 'msg': ex},
6650                                 instance=instance)
6651                 break
6652 
6653     @wrap_exception()
6654     def external_instance_event(self, context, instances, events):
6655         # NOTE(danms): Some event types are handled by the manager, such
6656         # as when we're asked to update the instance's info_cache. If it's
6657         # not one of those, look for some thread(s) waiting for the event and
6658         # unblock them if so.
6659         for event in events:
6660             instance = [inst for inst in instances
6661                         if inst.uuid == event.instance_uuid][0]
6662             LOG.debug('Received event %(event)s',
6663                       {'event': event.key},
6664                       instance=instance)
6665             if event.name == 'network-changed':
6666                 try:
6667                     self.network_api.get_instance_nw_info(context, instance)
6668                 except exception.NotFound as e:
6669                     LOG.info(_LI('Failed to process external instance event '
6670                                  '%(event)s due to: %(error)s'),
6671                              {'event': event.key, 'error': six.text_type(e)},
6672                              instance=instance)
6673             elif event.name == 'network-vif-deleted':
6674                 self._process_instance_vif_deleted_event(context,
6675                                                          instance,
6676                                                          event.tag)
6677             else:
6678                 self._process_instance_event(instance, event)
6679 
6680     @periodic_task.periodic_task(spacing=CONF.image_cache_manager_interval,
6681                                  external_process_ok=True)
6682     def _run_image_cache_manager_pass(self, context):
6683         """Run a single pass of the image cache manager."""
6684 
6685         if not self.driver.capabilities["has_imagecache"]:
6686             return
6687 
6688         # Determine what other nodes use this storage
6689         storage_users.register_storage_use(CONF.instances_path, CONF.host)
6690         nodes = storage_users.get_storage_users(CONF.instances_path)
6691 
6692         # Filter all_instances to only include those nodes which share this
6693         # storage path.
6694         # TODO(mikal): this should be further refactored so that the cache
6695         # cleanup code doesn't know what those instances are, just a remote
6696         # count, and then this logic should be pushed up the stack.
6697         filters = {'deleted': False,
6698                    'soft_deleted': True,
6699                    'host': nodes}
6700         filtered_instances = objects.InstanceList.get_by_filters(context,
6701                                  filters, expected_attrs=[], use_slave=True)
6702 
6703         self.driver.manage_image_cache(context, filtered_instances)
6704 
6705     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6706     def _run_pending_deletes(self, context):
6707         """Retry any pending instance file deletes."""
6708         LOG.debug('Cleaning up deleted instances')
6709         filters = {'deleted': True,
6710                    'soft_deleted': False,
6711                    'host': CONF.host,
6712                    'cleaned': False}
6713         attrs = ['info_cache', 'security_groups', 'system_metadata']
6714         with utils.temporary_mutation(context, read_deleted='yes'):
6715             instances = objects.InstanceList.get_by_filters(
6716                 context, filters, expected_attrs=attrs, use_slave=True)
6717         LOG.debug('There are %d instances to clean', len(instances))
6718 
6719         for instance in instances:
6720             attempts = int(instance.system_metadata.get('clean_attempts', '0'))
6721             LOG.debug('Instance has had %(attempts)s of %(max)s '
6722                       'cleanup attempts',
6723                       {'attempts': attempts,
6724                        'max': CONF.maximum_instance_delete_attempts},
6725                       instance=instance)
6726             if attempts < CONF.maximum_instance_delete_attempts:
6727                 success = self.driver.delete_instance_files(instance)
6728 
6729                 instance.system_metadata['clean_attempts'] = str(attempts + 1)
6730                 if success:
6731                     instance.cleaned = True
6732                 with utils.temporary_mutation(context, read_deleted='yes'):
6733                     instance.save()
6734 
6735     @periodic_task.periodic_task(spacing=CONF.instance_delete_interval)
6736     def _cleanup_incomplete_migrations(self, context):
6737         """Delete instance files on failed resize/revert-resize operation
6738 
6739         During resize/revert-resize operation, if that instance gets deleted
6740         in-between then instance files might remain either on source or
6741         destination compute node because of race condition.
6742         """
6743         LOG.debug('Cleaning up deleted instances with incomplete migration ')
6744         migration_filters = {'host': CONF.host,
6745                              'status': 'error'}
6746         migrations = objects.MigrationList.get_by_filters(context,
6747                                                           migration_filters)
6748 
6749         if not migrations:
6750             return
6751 
6752         inst_uuid_from_migrations = set([migration.instance_uuid for migration
6753                                          in migrations])
6754 
6755         inst_filters = {'deleted': True, 'soft_deleted': False,
6756                         'uuid': inst_uuid_from_migrations, 'host': CONF.host}
6757         attrs = ['info_cache', 'security_groups', 'system_metadata']
6758         with utils.temporary_mutation(context, read_deleted='yes'):
6759             instances = objects.InstanceList.get_by_filters(
6760                 context, inst_filters, expected_attrs=attrs, use_slave=True)
6761 
6762         for instance in instances:
6763             for migration in migrations:
6764                 if instance.uuid == migration.instance_uuid:
6765                     # Delete instance files if not cleanup properly either
6766                     # from the source or destination compute nodes when
6767                     # the instance is deleted during resizing.
6768                     self.driver.delete_instance_files(instance)
6769                     try:
6770                         migration.status = 'failed'
6771                         with migration.obj_as_admin():
6772                             migration.save()
6773                     except exception.MigrationNotFound:
6774                         LOG.warning(_LW("Migration %s is not found."),
6775                                     migration.id, context=context,
6776                                     instance=instance)
6777                     break
6778 
6779     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
6780                                    exception.QemuGuestAgentNotEnabled,
6781                                    exception.NovaException,
6782                                    NotImplementedError)
6783     @wrap_exception()
6784     def quiesce_instance(self, context, instance):
6785         """Quiesce an instance on this host."""
6786         context = context.elevated()
6787         image_meta = objects.ImageMeta.from_instance(instance)
6788         self.driver.quiesce(context, instance, image_meta)
6789 
6790     def _wait_for_snapshots_completion(self, context, mapping):
6791         for mapping_dict in mapping:
6792             if mapping_dict.get('source_type') == 'snapshot':
6793 
6794                 def _wait_snapshot():
6795                     snapshot = self.volume_api.get_snapshot(
6796                         context, mapping_dict['snapshot_id'])
6797                     if snapshot.get('status') != 'creating':
6798                         raise loopingcall.LoopingCallDone()
6799 
6800                 timer = loopingcall.FixedIntervalLoopingCall(_wait_snapshot)
6801                 timer.start(interval=0.5).wait()
6802 
6803     @messaging.expected_exceptions(exception.InstanceQuiesceNotSupported,
6804                                    exception.QemuGuestAgentNotEnabled,
6805                                    exception.NovaException,
6806                                    NotImplementedError)
6807     @wrap_exception()
6808     def unquiesce_instance(self, context, instance, mapping=None):
6809         """Unquiesce an instance on this host.
6810 
6811         If snapshots' image mapping is provided, it waits until snapshots are
6812         completed before unqueiscing.
6813         """
6814         context = context.elevated()
6815         if mapping:
6816             try:
6817                 self._wait_for_snapshots_completion(context, mapping)
6818             except Exception as error:
6819                 LOG.exception(_LE("Exception while waiting completion of "
6820                                   "volume snapshots: %s"),
6821                               error, instance=instance)
6822         image_meta = objects.ImageMeta.from_instance(instance)
6823         self.driver.unquiesce(context, instance, image_meta)
